data = [
    {
        "authors": [
            "Fabrizio Sebastiani"
        ],
        "references": [
            "01e036ec-11c7-4251-98cc-13d11b59d0f0",
            "0500ddbe-e274-477b-bb6b-54a7269e4577",
            "05268346-81e5-4a59-b6e6-9e7d0ca204eb",
            "0bcf0b45-5d17-4f84-9912-0d35660c4403",
            "0e4d2a3c-f426-434d-981c-6acaf25430d9",
            "0e8681ad-3687-4fd2-8dd6-7991dc6e4068",
            "0f6a4fe2-14a0-4991-8a0f-daf425bb6838",
            "0fdd6fc4-a6ff-4e7b-858c-2daedb168b17",
            "12926501-efe2-4ab3-a7cb-f632a1ac4e64",
            "1437fd93-6c89-45aa-a937-3c555d089289",
            "14d121c5-3655-473a-a6a5-0a27932f6ade",
            "1a8e6293-8d68-4544-916a-66e329ba73b7",
            "1b7418af-1aba-4090-bad4-0dd0e900f5aa",
            "1ce7a9a3-91c4-45d6-984a-e1d240fd81aa",
            "1ec45041-b11f-4785-b9ee-ed99eb029ddc",
            "1f54b4c0-e85f-40bf-a3fe-2fd708c71064",
            "23f66d97-4abf-479f-8af5-ec833d850a24",
            "245e4043-ccdb-457a-9be1-e120c7a94753",
            "25f9dfdb-4cb7-4dd2-9b42-90992fd5d8b8",
            "261aefde-fbe5-494f-afd7-c771aff03127",
            "27d381c3-27e0-4c31-89fa-6639b3e06449",
            "28d80fb2-745b-4c03-a8dc-829c46ddf3fb",
            "2d691e6d-df41-4fdc-b226-8068e19d5b34",
            "328e6d1a-73c4-48da-ac29-d671a581cf86",
            "33be9d6d-dab6-45fc-89d9-022149720d24",
            "367d33bc-55f2-4ac9-8adb-72c681914286",
            "38500fe9-7c31-4a6a-aa20-fc96325f2946",
            "3876df95-6893-442c-aeea-09de7c344874",
            "3a77b2e4-44c5-47db-97fd-40dadcca1e02",
            "3b013a2d-ff3b-4ded-bbfa-e36fd67669e7",
            "3d189262-70db-4a04-87bc-9099e6c46e8c",
            "3f394e9d-c50a-4505-9b76-458f5e8be345",
            "4564dd59-3ed0-4987-9dd9-3e30d2dcdb28",
            "49fb51f7-ea3f-4071-82f6-0b8b9571b223",
            "4bf13cbb-9026-4e4a-90da-64104415c0b3",
            "4c4b67d4-ef63-4eab-9fb6-ce2e64dec16e",
            "4d6a41b2-ba88-4c41-b19d-3badcccc2b2f",
            "4edb6ffa-799a-4556-9041-652eabb18a8b",
            "514444a0-7178-4d68-9914-fd018d94fa16",
            "51c8135d-1673-4fa8-9842-a65c4183ac73",
            "51eb4778-5546-45f1-8990-4a527d8b6d33",
            "529f0775-01b2-4f1e-9d89-fc5227058019",
            "52c01d07-28bb-4a1c-98da-1482a380f6db",
            "5465d7f9-4818-4f79-a434-73907d7ae423",
            "55170d49-f3e8-437a-b0ea-a14ba8d5319e",
            "55514f7e-209f-4f0b-ae46-cf5f2b4d70e7",
            "55ab17e9-5c62-4157-adc9-28935eed7120",
            "5694495a-ded0-44ef-ac1d-3e6e0482d90d",
            "57b03a88-b12e-41e3-b3a9-e6ecdaf12730",
            "58110599-9a6d-44ba-9e5f-b9a92d52b820",
            "58913a76-a718-4493-a5e9-2fa8aa3ef52b",
            "5b6620cd-3df0-4309-a24d-b120be89242c",
            "64578cea-4946-4321-9970-c4b5c43c48ee",
            "67288135-af65-4979-99ef-75e7d603e190",
            "67964a4a-b4c6-445d-88d0-2bdc37c3a5ba",
            "68520ece-23ee-457f-b7a4-f08216c717fd",
            "6d15cd37-496d-44e1-8bfb-004621255173",
            "6e206624-7a7f-4ee9-91c8-d78003892706",
            "73f6b15e-509c-4f2f-9160-35cab954ce59",
            "75ec0b95-65c5-48c9-ae1b-a44c6c378bec",
            "7fd22f4f-deba-415c-ae7c-cdbe5dba2f55",
            "7fd6fe96-a556-4353-8c6a-763dc81514f6",
            "847195a1-97a7-4986-95a2-a5575aa20b09",
            "866d201b-b373-47a7-9860-0f185d90dbe2",
            "87e6130e-51b7-4239-b166-709c0c7ccb26",
            "8828ba95-7026-4085-9803-7cce05949493",
            "8c0baa91-d32e-478b-89e3-d7c636db2e76",
            "92d0da63-d882-4d22-b5d2-5c41306bda51",
            "9519ccab-8cda-40ff-bd55-b61857c27b56",
            "96d6d9b9-6d69-4c9a-b3f5-c8083966d55c",
            "979fbf34-d977-4a5e-a727-a1038c4d7f97",
            "9bdbf6d6-db2b-4114-969a-37b4e03993b0",
            "9c9be0c6-ab2a-467e-b499-dfb3fd207029",
            "9f4995af-e704-48ab-8717-6972a3d4455b",
            "a12b3831-01ce-48e0-a9b4-d56530df528c",
            "a1e8ab1e-6df3-4383-b708-b5b5c29b4b7f",
            "a506f179-4c89-4cfc-a719-c374b2671279",
            "a5e45f48-d860-4cd5-a638-6122a2d331fe",
            "a677a749-cb49-4d5e-a2d8-2078230e4f88",
            "ab339474-ea21-443b-893f-96ae09e65a2e",
            "b9111683-1151-4542-8a10-d1eeb730087e",
            "b923a531-5949-4b42-966c-5dd551c30585",
            "bb74ee29-c9bd-4ed8-978c-295045e24594",
            "bb98580e-953d-467f-8aa1-f0fd204cdb5c",
            "bbf63075-ea5d-4b47-b13d-961493788d35",
            "bc66f6be-1038-4deb-a11e-35f51f0937d4",
            "bc95970b-34c5-4860-a832-41bc04a50889",
            "c04cc3bb-dd4a-4abd-b55b-3d3ebaccfba5",
            "c08dcfdd-2903-4a29-be58-4747740baa58",
            "c0af1514-af65-4d85-af68-de3409fc6532",
            "c12af7c5-ea9e-41b8-8d0a-eab301f8d270",
            "c13bf4d6-b7f2-4a7e-abf6-d798782b75ea",
            "c285808d-767a-4900-bb93-72679186d815",
            "c28ea43f-078a-4b68-a690-5a0ec70a983e",
            "c2cce1cf-b653-430b-b5e4-b5141484f09c",
            "c3e99ff5-57f9-4012-8b92-48c8d26bf232",
            "c476f0a8-d3db-43c6-940d-de9c8c9291bd",
            "c4beaa25-a712-4854-803d-fa0d74149e84",
            "d129ed23-bb3d-4ae3-8122-30e2f5baa419",
            "d1a51572-839b-4ae1-97c3-ad045ea6425a",
            "d59fdaf0-3972-4f10-a74f-e8f22a231afb",
            "da0f35bf-8a7b-4d2e-8626-0a098a4bc854",
            "dd7be56b-cc00-41d7-9bf7-99aafe03b600",
            "dedf3259-acc0-41b0-9581-ba89abd14c00",
            "e246b3ef-605d-46c4-9e21-294de09b70ea",
            "e91a0a81-da9c-4009-9007-18ba9b8595b2",
            "e9a10bb1-bcd7-48c4-af6b-df754852d14c",
            "e9abffef-c6bf-44da-a673-be480773dbbb",
            "ec115dba-62a8-45da-8df7-b41d4bf7cc9e",
            "ec508672-6090-4ac3-8939-69e27e9cb977",
            "ed660ea2-fad8-4bd1-8c0b-8c0679eb1657",
            "f291765d-169d-49de-8972-a0c9692159f7",
            "f644253d-4748-4ef1-847b-c6a41a231c90",
            "fa81a051-0f8e-4f10-a172-acd5a8923e23",
            "fb2d9162-7ff8-44b4-b73f-f822783dcafe",
            "fe18f1d7-1c3d-43ce-8b51-acc0e769b1db",
            "febb53cc-a472-4f7e-afac-c530e7010051",
            "ff78f8f6-0559-4be7-a7e1-0e8bb742ecda"
        ],
        "keyword": [
            "classifier",
            "approach",
            "learning",
            "documents",
            "texts",
            "problem",
            "machine",
            "experts",
            "domain",
            "discusses"
        ],
        "group": [
            {
                "4bf13cbb-9026-4e4a-90da-64104415c0b3": {
                    "authors": [
                        "Yu-Hwan Kim",
                        "Shang-Yoon Hahn",
                        "Byoung-Tak Zhang"
                    ],
                    "references": [
                        "01e036ec-11c7-4251-98cc-13d11b59d0f0",
                        "056e5059-9864-479b-8a2a-fb1cd3d2dd32",
                        "0f115eea-2272-431f-9f21-6d6789b2bbc9",
                        "17f811d8-8607-4270-bbec-1cc7883edd68",
                        "1d48d76c-e82c-4ba5-a354-5db0b1ce05da",
                        "23f66d97-4abf-479f-8af5-ec833d850a24",
                        "3704f939-09a2-4e9f-b851-1261bcd310df",
                        "4564dd59-3ed0-4987-9dd9-3e30d2dcdb28",
                        "47dc4a6a-9062-4c2e-a782-b48c3fab7e26",
                        "514444a0-7178-4d68-9914-fd018d94fa16",
                        "58110599-9a6d-44ba-9e5f-b9a92d52b820",
                        "852d4703-36db-4c8c-814c-6cd2273b536b",
                        "9519ccab-8cda-40ff-bd55-b61857c27b56",
                        "bb74ee29-c9bd-4ed8-978c-295045e24594",
                        "c2cce1cf-b653-430b-b5e4-b5141484f09c",
                        "cd91d375-b151-4f9e-a8b8-ab65713e8559",
                        "da360cf7-3063-410f-be72-4e6d676e2b9a"
                    ],
                    "keyword": [
                        "methods",
                        "text",
                        "filtering",
                        "boosting",
                        "algorithms",
                        "weight",
                        "term",
                        "naive",
                        "learning",
                        "information"
                    ],
                    "group": [],
                    "_id": "4bf13cbb-9026-4e4a-90da-64104415c0b3",
                    "abstract": "Several machine learning algorithms have recently been used for text categorization and filtering. In particular, boosting methods such as AdaBoost have shown good performance applied to real text data. However, most of existing boosting algorithms are based on classifiers that use binary-valued features. Thus, they do not fully make use of the weight information provided by standard term weighting methods. In this paper, we present a boosting-based learning method for text filtering that uses naive Bayes classifiers as a weak learner. The use of naive Bayes allows the boosting algorithm to utilize term frequency information while maintaining probabilistically accurate confidence ratio. Applied to TREC-7 and TREC-8 filtering track documents, the proposed method obtained a significant improvement in LF1, LF2, F1 and F3 measures compared to the best results submitted by other TREC entries.",
                    "title": "Text filtering by boosting naive Bayes classifiers",
                    "venue": "international acm sigir conference on research and development in information retrieval",
                    "year": 2000,
                    "__v": 1,
                    "citationCount": 35,
                    "result": 6.620101417359644
                },
                "4d6a41b2-ba88-4c41-b19d-3badcccc2b2f": {
                    "authors": [
                        "Elizabeth D. Liddy",
                        "Woojin Paik",
                        "Edmund S. Yu"
                    ],
                    "references": [
                        "3b013a2d-ff3b-4ded-bbfa-e36fd67669e7",
                        "607c1c39-b28b-450f-bcfa-04429cf53496",
                        "6d582fdc-b040-4c48-80d8-02c7cfd37fa2",
                        "bd934599-3139-448a-8d2b-e82fda6c26e0",
                        "dce0242a-1847-4ccd-862b-8684bbd36a86",
                        "df1a0d04-0e77-4546-92e8-19e23c91847e"
                    ],
                    "keyword": [
                        "documents",
                        "text",
                        "set",
                        "profile",
                        "relevant",
                        "determine",
                        "categorization",
                        "word",
                        "task",
                        "system"
                    ],
                    "group": [],
                    "_id": "4d6a41b2-ba88-4c41-b19d-3badcccc2b2f",
                    "abstract": "The text categorization module described here provides a front-end filtering function for the larger DR-LINK text retrieval system [Liddy and Myaeing 1993]. The model evaluates a large incoming stream of documents to determine which documents are sufficiently similar to a profile at the broad subject level to warrant more refined representation and matching. To accomplish this task, each substantive word in a text is first categorized using a feature set based on the semantic Subject Field Codes (SFCs) assigned to individual word senses in a machine-readable dictionary. When tested on 50 user profiles and 550 megabytes of documents, results indicate that the feature set that is the basis of the text categorization module and the algorithm that establishes the boundary of categories  of potentially relevant documents accomplish their tasks with a high level of performance.  This means that the category of potentially relevant documents for most profiles would contain at least 80% of all documents later determined to be relevant to the profile. The number of documents in this set would be uniquely determined by the system's category-boundary predictor, and this set is likely to contain less than 5% of the incoming stream of documents.",
                    "title": "Text categorization for multiple users based on semantic features from a machine-readable dictionary",
                    "venue": "ACM Transactions on Information Systems",
                    "year": 1994,
                    "__v": 1,
                    "citationCount": 12,
                    "result": 6.165808001127045
                },
                "51eb4778-5546-45f1-8990-4a527d8b6d33": {
                    "authors": [
                        "Dieter Merkl"
                    ],
                    "references": [
                        "06c11d6e-7bce-40ed-8eca-10a14dc05f14",
                        "1ce7a9a3-91c4-45d6-984a-e1d240fd81aa",
                        "1e31b3fa-84b6-43a2-92a5-601e6537caa2",
                        "28dc7c8d-7258-4bc5-ad19-71fc1d43070f",
                        "33d6dabd-c086-4a6e-939a-c322b6ada724",
                        "366a2502-8abc-4930-9223-40b231f3e5cf",
                        "3768f051-0b9e-4a83-9ba9-e5dc23b0d253",
                        "5a6d6209-cdfa-4ff6-bb59-3f6257a3300e",
                        "61b0409b-a35f-4d75-9b1c-86a8bbc018ae",
                        "7dae2e19-c309-4989-bc10-abed74be85de",
                        "7dc194ef-bddc-4d84-95d8-12ae89aa7e77",
                        "8468d5c9-45ac-4e18-90c8-29a0441394a9",
                        "95bf88a0-1a04-48ec-be11-d26f315cf6b7",
                        "a506f179-4c89-4cfc-a719-c374b2671279",
                        "a77be36a-397e-4fe1-b282-48c1c2339dd3",
                        "ac14afe6-de4d-4056-b2ac-0f6e36f369a2",
                        "b1d4a29a-85ce-43c5-ac61-e4f3d101f37e",
                        "b496c280-dea5-4081-93a6-a8721313ef6e",
                        "cce39908-91ee-4583-9787-0eefcf048a11",
                        "dc14ea30-fb55-464f-bf23-b9c309b7cb12",
                        "f7b04b0b-3beb-4e9f-aa37-836e52067e22"
                    ],
                    "keyword": [
                        "document",
                        "map",
                        "collection",
                        "selforganizing",
                        "user",
                        "neural",
                        "network",
                        "metaphor",
                        "intuitive",
                        "information"
                    ],
                    "group": [],
                    "_id": "51eb4778-5546-45f1-8990-4a527d8b6d33",
                    "abstract": "The self-organizing map has already found appreciation for document classification in the information retrieval community. The map display is a highly effective and intuitive metaphor for orientation in the information space established by a document collection. In this paper we discuss ways for using self-organizing maps for document classification. Furthermore, we argue in favor of paying more attention to the fact that document collections lend themselves naturally to a hierarchical structure defined by the subject matter of the documents. We take advantage of this fact by using a hierarchically organized neural network, built up from a number of independent self-organizing maps in order to enable the true establishment of a document taxonomy. As a highly convenient side effect of using such an architecture, the time needed for training is reduced substantially and the user is provided with an even more intuitive metaphor for visualization. Since the single layers of self-organizing maps represent different aspects of the document collection at different levels of detail, the neural network shows the document collection in a form comparable to an atlas where the user may easily select the most appropriate degree of granularity depending on the actual focus of interest during the exploration of the document collection.",
                    "title": "Text classification with self-organizing maps: Some lessons learned",
                    "venue": "Neurocomputing",
                    "year": 1998,
                    "__v": 1,
                    "citationCount": 57,
                    "result": 5.597257996998248
                },
                "529f0775-01b2-4f1e-9d89-fc5227058019": {
                    "authors": [
                        "Soumen Chakrabarti",
                        "Byron Dom",
                        "Prabhakar Raghavan",
                        "Sridhar Rajagopalan",
                        "David Gibson",
                        "Jon M. Kleinberg"
                    ],
                    "references": [
                        "2256cad0-cf03-42da-bcf3-4a89be0ebf8e",
                        "7dce00bc-8d45-4886-a341-63b5039217a7",
                        "8f6cafa9-28c3-424e-87bd-c28c8e57a44f",
                        "96dc598a-fd41-420f-adc7-5498bc4830de",
                        "a5f0deb7-ce61-46d5-8cc2-b8362fd63db3",
                        "b9a25393-edf2-4e39-8252-64d332f225dd",
                        "c7e4e04b-45da-4bae-8c8a-d17ca0087361",
                        "ff269dbf-6570-4409-8cab-6ac142450d05"
                    ],
                    "keyword": [
                        "resources",
                        "list",
                        "arc",
                        "evaluation",
                        "compiling",
                        "yahoo",
                        "topic",
                        "manually",
                        "infoseek",
                        "human"
                    ],
                    "group": [],
                    "_id": "529f0775-01b2-4f1e-9d89-fc5227058019",
                    "abstract": "We describe the design, prototyping and evaluation of ARC, a system for automatically compiling a list of authoritative Web resources on any (sufficiently broad) topic. The goal of ARC is to compile resource lists similar to those provided by Yahoo! or Infoseek. The fundamental difference is that these services construct lists either manually or through a combination of human and automated effort, while ARC operates fully automatically. We describe the evaluation of ARC, Yahoo!, and Infoseek resource lists by a panel of human users. This evaluation suggests that the resources found by ARC frequently fare almost as well as, and sometimes better than, lists of resources that are manually compiled or classified into a topic. We also provide examples of ARC resource lists for the reader to examine.",
                    "title": "Automatic resource compilation by analyzing hyperlink structure and associated text",
                    "venue": "international world wide web conferences",
                    "year": 1998,
                    "__v": 1,
                    "citationCount": 387,
                    "result": 2.7523615273615274
                },
                "52c01d07-28bb-4a1c-98da-1482a380f6db": {
                    "authors": [
                        "Fabio Crestani",
                        "Mounia Lalmas",
                        "Cornelis Joost van Rijsbergen",
                        "Iain C. Campbell"
                    ],
                    "references": [
                        "0fdd6fc4-a6ff-4e7b-858c-2daedb168b17",
                        "1784e34b-ead3-49e2-af69-d30fc2f39f44",
                        "24be4a77-20c6-4540-8a2b-d18e39b30fa5",
                        "364032f5-7850-4435-aeef-57f0dabe49d0",
                        "366a2502-8abc-4930-9223-40b231f3e5cf",
                        "3696310e-9cfc-4196-9af5-980cb49108ae",
                        "3728c934-bf52-4967-9dfb-c0f51b18c4b4",
                        "49fb51f7-ea3f-4071-82f6-0b8b9571b223",
                        "50195a52-8a1b-4818-b6d5-5446a3558266",
                        "556a6f2e-2737-40f0-aec1-9a13a2fdb1ef",
                        "5b6620cd-3df0-4309-a24d-b120be89242c",
                        "5c081357-b0cb-42eb-b06d-95bd629a834c",
                        "5cafea2a-aef1-4458-aee4-fe55d3fb11d8",
                        "5d623037-6181-4248-92e7-bd2cda4c788e",
                        "60b6238d-ab16-4a79-96f1-45e432e1a125",
                        "62b0f667-369d-46e3-9483-ce5ebdda6f6e",
                        "7263c0cf-2d93-4c9f-9bcf-c5dac2434627",
                        "7e2520dd-d1b5-48c1-aa55-88e09feab2c0",
                        "894abe0d-19ac-44cc-9e25-d8f4ce1ee44f",
                        "9173ae92-14d3-4e0d-9f8a-d2e449b81f2d",
                        "938893b1-0e6b-4b58-9ff6-0e5b6b1414e0",
                        "99a2d996-0af1-460a-b339-81f9804c5af2",
                        "9bdbf6d6-db2b-4114-969a-37b4e03993b0",
                        "a12f0a41-7745-4249-9ef2-428afd84e08e",
                        "a1e8ab1e-6df3-4383-b708-b5b5c29b4b7f",
                        "a45e0fbe-2fd8-43cb-b1f0-730e986fcf63",
                        "b7452dc8-806a-484d-abd7-d2065e0e9db9",
                        "bae23982-9b64-4407-92c2-7c06c86c52dd",
                        "bae3dbf3-c241-4e3f-94be-8b4f5becbe06",
                        "bd610772-fbd3-4c0b-9a70-ac4dbf5394ee",
                        "c825366e-3bc6-44aa-a07c-9d882d94f74f",
                        "c920c4ca-5417-48f8-8a83-27f54d7f277f",
                        "c9826214-50da-4385-bba6-38ec36e14e77",
                        "d07d5161-b4e7-436d-85a7-31450709cb5e",
                        "d31b4077-f784-409d-a52a-26a8b9173142",
                        "d3e00e7e-1c64-4d7a-b2b2-1ad98ba4c706",
                        "dacc4283-2823-4b85-aa89-661bd83b34eb",
                        "df9cd4e6-8db3-47ad-b8c9-6121544916ed",
                        "e48e9792-3613-4b93-8b47-3f21077806e1",
                        "e51d0983-3fce-47e3-9fa2-e851d1054303",
                        "f05265b4-dae3-4239-acc2-9874878af143",
                        "f5fcdbe8-02dd-4888-8155-3f8887af0ca0",
                        "f759b3c4-705d-4918-9281-a54cb7db31a4"
                    ],
                    "keyword": [
                        "approaches",
                        "retrieval",
                        "modeling",
                        "information",
                        "surveys",
                        "research",
                        "proposed",
                        "probablistic",
                        "probabilistic",
                        "principles"
                    ],
                    "group": [],
                    "_id": "52c01d07-28bb-4a1c-98da-1482a380f6db",
                    "abstract": "This article surveys probablistic approaches to modeling information retrieval. The basic concepts of probabilistic approaches to information retrieval are outlined and the principles and assumptions upon which the approaches are based are presented. The various models proposed in the development of IR are described, classified, and compared using a common formalism. New approaches that constitute the basis of future research are described.",
                    "title": "“Is this document relevant?…probably”: a survey of probabilistic models in information retrieval",
                    "venue": "ACM Computing Surveys",
                    "year": 1998,
                    "__v": 1,
                    "citationCount": 88,
                    "result": 7.361158738295749
                },
                "55170d49-f3e8-437a-b0ea-a14ba8d5319e": {
                    "authors": [
                        "Johannes Fürnkranz"
                    ],
                    "references": [
                        "3cd0202c-838a-4f77-a540-493822511b7e",
                        "4a48d1c0-8255-49d4-8800-66fa0cf7560d",
                        "6f349b59-6adf-4c74-8234-24e753d80044",
                        "a5f0deb7-ce61-46d5-8cc2-b8362fd63db3",
                        "d8ddd4ae-16ab-4702-b4f5-65aff0e33533",
                        "ee746464-b6d4-47c6-afbb-8b8e0faa0bcd"
                    ],
                    "keyword": [
                        "page",
                        "information",
                        "set",
                        "hypothesis",
                        "www",
                        "working",
                        "webpages",
                        "utility",
                        "structural",
                        "science"
                    ],
                    "group": [],
                    "_id": "55170d49-f3e8-437a-b0ea-a14ba8d5319e",
                    "abstract": "In this paper, we report on a set of experiments that explore the utility of making use of the structural information of WWW documents. Our working hypothesis is that it is often easier to classify a hypertext page using information provided on pages that point to it instead of using information that is provided on the page itself. We present experimental evidence that confirms this hypothesis on a set of Web-pages that relate to Computer Science Departments.",
                    "title": "Exploiting Structural Information for Text Classification on the WWW",
                    "venue": "intelligent data analysis",
                    "year": 1999,
                    "__v": 1,
                    "citationCount": 66,
                    "result": 2.3892770628064746
                },
                "55514f7e-209f-4f0b-ae46-cf5f2b4d70e7": {
                    "authors": [
                        "Carl Sable",
                        "Vasileios Hatzivassiloglou"
                    ],
                    "references": [
                        "0b2459a7-da6c-437d-88c9-0bd7778d6fca",
                        "0c35895c-9f13-4678-80f3-9310652446e0",
                        "14bba136-a316-4f06-8d17-ede27def9d50",
                        "16088d1a-5061-4460-a562-239f2c64854a",
                        "16fb90c7-64db-4630-81a8-1cbe11b50f63",
                        "1ce7a9a3-91c4-45d6-984a-e1d240fd81aa",
                        "1ed2cc94-3d0b-4718-80b6-2528e814c921",
                        "33d6dabd-c086-4a6e-939a-c322b6ada724",
                        "36ac5e32-e7ee-4d46-8c07-2c3f583f6163",
                        "514444a0-7178-4d68-9914-fd018d94fa16",
                        "63a1e0be-afc5-413e-aa27-d3eb26a891ac",
                        "65a76574-1ea8-4b1d-8d29-efe42d06446c",
                        "75ec0b95-65c5-48c9-ae1b-a44c6c378bec",
                        "7fcaefe0-fb4f-46fd-967e-504961ce4c04",
                        "7fcd070a-78a8-4798-a090-934c04dd6d16",
                        "8a27e5c5-cc00-42c4-9c1f-8127bc94451d",
                        "8f7965b1-3854-42fd-9c6e-76b58f8813f5",
                        "9c01e781-9714-46b5-ba51-da4140753b8c",
                        "b49c1e2b-0cd0-4950-a724-00c698e5b49d",
                        "bb74ee29-c9bd-4ed8-978c-295045e24594",
                        "bbf5e5eb-cd31-45b3-bfd9-d2fa07d4bd8b",
                        "d5321e41-3281-4557-ac5a-5c0389818822",
                        "ed59a2e5-7330-4e07-9edf-cc80872135d0",
                        "f815f346-6707-4036-b766-0a0ca290809f",
                        "f9759d6e-a74f-4d6c-ae70-ffe454771288",
                        "fb5b7aa5-5d68-45b9-be8b-36d217d940d7",
                        "fcc644ff-fc5d-44b3-bf4c-ccd2c34a423c"
                    ],
                    "keyword": [
                        "features",
                        "effectively",
                        "classification",
                        "tfidf",
                        "text",
                        "task",
                        "news",
                        "multimedia",
                        "information",
                        "images"
                    ],
                    "group": [],
                    "_id": "55514f7e-209f-4f0b-ae46-cf5f2b4d70e7",
                    "abstract": "The rapid expansion of multimedia digital collections brings to the fore the need for classifying not only text documents but their embedded non-textual parts as well. We propose a model for basing classifica- tion of multimedia on broad, non-topical features, and show how information on targeted nearby pieces of text can be used to effectively classify photographs on a first such feature, distinguishing between indoor and outdoor images. We examine several variations to a TF*IDF- based approach for this task, empirically analyze their effects, and evaluate our system on a large collection of images from current news newsgroups. In addition, we investigate alternative classification and evaluation methods, and the effects that secondary features have on indoor/outdoor classification. Using density estimation over the raw TF*IDF values, we obtain a classification accuracy of 82%, a number that outperforms baseline es- timates and earlier, image-based approaches, at least in the domain of news articles, and that nears the accuracy of humans who perform the same task with access to com- parable information.",
                    "title": "Text-based approaches for non-topical image categorization",
                    "venue": "International Journal on Digital Libraries",
                    "year": 2000,
                    "__v": 1,
                    "citationCount": 8,
                    "result": 4.374147559541378
                },
                "67288135-af65-4979-99ef-75e7d603e190": {
                    "authors": [
                        "David D. Lewis"
                    ],
                    "references": [
                        "0c35895c-9f13-4678-80f3-9310652446e0",
                        "0fdd6fc4-a6ff-4e7b-858c-2daedb168b17",
                        "1ec45041-b11f-4785-b9ee-ed99eb029ddc",
                        "20ab59f4-7419-4337-ba06-258e878b3e24",
                        "3efa7da1-3b69-437a-94cc-67c1cf772d34",
                        "51c8135d-1673-4fa8-9842-a65c4183ac73",
                        "576ad9bd-86e7-4453-9cc3-5f9f7268b881",
                        "5859ab7b-d98f-4a05-b563-5faebd3abde5",
                        "58913a76-a718-4493-a5e9-2fa8aa3ef52b",
                        "9a3f79eb-555c-4d06-aa73-e892ee547734",
                        "9bdbf6d6-db2b-4114-969a-37b4e03993b0",
                        "a9ce5107-6998-4ce8-a2f9-368b8d21219b",
                        "aa06df17-dffa-4ddf-8974-036894760488",
                        "bd934599-3139-448a-8d2b-e82fda6c26e0",
                        "c2af3bf6-afd6-4854-bbee-6572b7d90b02",
                        "f165601a-a57a-4040-9323-08e818ef8ddb"
                    ],
                    "keyword": [
                        "text",
                        "indexing",
                        "term",
                        "effectiveness",
                        "clustering",
                        "syntactic",
                        "study",
                        "representation",
                        "properties",
                        "present"
                    ],
                    "group": [],
                    "_id": "67288135-af65-4979-99ef-75e7d603e190",
                    "abstract": "Syntactic phrase indexing and term clustering have been widely explored as text representation techniques for text retrieval. In this paper we study the properties of phrasal and clustered indexing languages on a text categorization task, enabling us to study their properties in isolation from query interpretation issues. We show that optimal effectiveness occurs when using only a small proportion of the indexing terms available, and that effectiveness peaks at a higher feature set size and lower effectiveness level for a syntactic phrase indexing than for word-based indexing. We also present results suggesting that traditional term clustering method are unlikely to provide significantly improved text representations. An improved probabilistic text categorization method is also presented.",
                    "title": "An evaluation of phrasal and clustered representations on a text categorization task",
                    "venue": "international acm sigir conference on research and development in information retrieval",
                    "year": 1992,
                    "__v": 2,
                    "citationCount": 217,
                    "result": 7.915060314875345
                },
                "67964a4a-b4c6-445d-88d0-2bdc37c3a5ba": {
                    "authors": [
                        "Soumen Chakrabarti",
                        "Byron Dom",
                        "Rakesh Agrawal",
                        "Prabhakar Raghavan"
                    ],
                    "references": [
                        "05f5fba9-e7ca-4c46-be79-df57944a8b41",
                        "1ce7a9a3-91c4-45d6-984a-e1d240fd81aa",
                        "234e66a9-10a1-41b7-9bc5-5615de1de1e3",
                        "27d381c3-27e0-4c31-89fa-6639b3e06449",
                        "4aaa373d-ccf1-4c6e-b830-1460e64e685f",
                        "4d1aed47-fdee-4293-bf4f-25adf2667125",
                        "56fd65de-2906-4521-9f3f-0e19c0d3f213",
                        "60c814e2-c4d1-47d7-9a5a-68f4141505ae",
                        "62549bc2-e0b3-46e8-8d32-390dded105d5",
                        "62b0f667-369d-46e3-9483-ce5ebdda6f6e",
                        "70caa088-db95-482e-8d60-b1b95ae48081",
                        "8a2f73ca-f2f6-402c-811c-a0caaef944dc",
                        "9566bd1c-79e4-4f6f-b641-4076386e1966",
                        "95ab1af8-1541-453a-aaa8-89ccaf4179ea",
                        "9ae0142d-b12f-42b1-ac48-d655fdec233f",
                        "9f4995af-e704-48ab-8717-6972a3d4455b",
                        "ac14afe6-de4d-4056-b2ac-0f6e36f369a2",
                        "b9111683-1151-4542-8a10-d1eeb730087e",
                        "c385db5b-803b-4d88-b756-f7cc417bbfb0",
                        "da0f35bf-8a7b-4d2e-8626-0a098a4bc854",
                        "dedf3259-acc0-41b0-9581-ba89abd14c00",
                        "e75d8e62-a86d-4241-953f-1b315005d920",
                        "ebbb2a5f-f83e-49e0-a62c-d3c80bec1b77",
                        "febb53cc-a472-4f7e-afac-c530e7010051"
                    ],
                    "keyword": [
                        "documents",
                        "topic",
                        "databases",
                        "classifier",
                        "words",
                        "taxonomies",
                        "system",
                        "searching",
                        "organize",
                        "large"
                    ],
                    "group": [],
                    "_id": "67964a4a-b4c6-445d-88d0-2bdc37c3a5ba",
                    "abstract": "We explore how to organize large text databases hierarchically by topic to aid better searching, browsing and filtering. Many corpora, such as internet directories, digital libraries, and patent databases are manually organized into topic hierarchies, also called taxonomies. Similar to indices for relational data, taxonomies make search and access more efficient. However, the exponential growth in the volume of on-line textual information makes it nearly impossible to maintain such taxonomic organization for large, fast-changing corpora by hand. We describe an automatic system that starts with a small sample of the corpus in which topics have been assigned by hand, and then updates the database with new documents as the corpus grows, assigning topics to these new documents with high speed and accuracy. To do this, we use techniques from statistical pattern recognition to efficiently separate the feature words, or discriminants, from thenoise words at each node of the taxonomy. Using these, we build a multilevel classifier. At each node, this classifier can ignore the large number of “noise” words in a document. Thus, the classifier has a small model size and is very fast. Owing to the use of context-sensitive features, the classifier is very accurate. As a by-product, we can compute for each document a set of terms that occur significantly more often in it than in the classes to which it belongs. We describe the design and implementation of our system, stressing how to exploit standard, efficient relational operations like sorts and joins. We report on experiences with the Reuters newswire benchmark, the US patent database, and web document samples from Yahoo!. We discuss applications where our system can improve searching and filtering capabilities.",
                    "title": "Scalable feature selection, classification and signature generation for organizing large text databases into hierarchical topic taxonomies",
                    "venue": "very large data bases",
                    "year": 1998,
                    "__v": 2,
                    "citationCount": 97,
                    "result": 6.428479197771322
                },
                "68520ece-23ee-457f-b7a4-f08216c717fd": {
                    "authors": [
                        "William W. Cohen",
                        "Haym Hirsh"
                    ],
                    "references": [
                        "0895c22d-37c5-4c8f-9202-a32ebd2cb0c0",
                        "2d691e6d-df41-4fdc-b226-8068e19d5b34",
                        "4a48d1c0-8255-49d4-8800-66fa0cf7560d",
                        "5f3ac3fd-6e1d-4dbf-8d72-22909a10a280",
                        "76c1da70-2949-47c3-aefa-9d703c884cd3",
                        "90f1fc54-bc22-4cbf-90b0-0b220f507b37",
                        "b123d7d1-cced-41cc-a8fc-c710a8f8a736",
                        "d8ddd4ae-16ab-4702-b4f5-65aff0e33533"
                    ],
                    "keyword": [
                        "whirl",
                        "tasks",
                        "joins",
                        "general",
                        "classification",
                        "soft",
                        "show",
                        "inductive",
                        "c4",
                        "based"
                    ],
                    "group": [],
                    "_id": "68520ece-23ee-457f-b7a4-f08216c717fd",
                    "abstract": "WHIRL is an extension of relational databases that can perform \"soft joins\" based on the similarity of textual identifiers; these soft joins extend the traditional operation of joining tables based on the equivalence of atomic values. This paper evaluates WHIRL on a number of inductive classification tasks using data from the World Wide Web. We show that although WHIRL is designed for more general similarity-based reasoning tasks, it is competitive with mature inductive classification systems on these classification tasks. In particular, WHIRL generally achieves lower generalization error than C4.5, RIPPER, and several nearest-neighbor methods. WHIRL is also fast—up to 500 times faster than C4.5 on some benchmark problems. We also show that WHIRL can be efficiently used to select from a large pool of unlabeled items those that can be classified correctly with high confidence.",
                    "title": "Joins that generalize: text classification using WHIRL",
                    "venue": "knowledge discovery and data mining",
                    "year": 1998,
                    "__v": 2,
                    "citationCount": 45,
                    "result": 3.134307312273414
                },
                "6d15cd37-496d-44e1-8bfb-004621255173": {
                    "authors": [
                        "Kagan Tumer",
                        "Joydeep Ghosh"
                    ],
                    "references": [
                        "01a0f16e-3899-41ac-83cc-9e99a57b919e",
                        "0f115eea-2272-431f-9f21-6d6789b2bbc9",
                        "17d88dfa-a5b8-47dd-9fb6-8779e5091c85",
                        "20fb61d7-108f-4045-a45f-1c7db93c3476",
                        "2f19b45c-a8d4-4e9b-9475-6b3b31672922",
                        "3213ae6b-6091-41e6-9a25-5eeb48600d90",
                        "380e23c7-5122-4f33-81ae-0242742150a9",
                        "6c68311c-2745-446f-9c09-df4632392a78",
                        "80b153d5-1b0d-4d12-8571-f0d6a6a9a5c8",
                        "842c30d5-98b6-463d-9a23-4841a3e07eb9",
                        "84806dbe-fa0e-47c0-b1f2-00fb2eed25a7",
                        "88d51d98-1e04-48b5-9b34-56a8a23986f6",
                        "987c2f02-9da0-45fd-a8a4-5a5015ed2af6",
                        "a69db56c-d735-4843-8300-5048fbf266e7",
                        "b889d6ec-330d-406f-87b6-ea34804fadfd",
                        "d1be087d-9526-482a-8bc1-70eff3318e64",
                        "e62ff43e-b9cf-4db3-91ad-8e1e74384a7c",
                        "ea3e7ab3-e7c2-4007-93db-5c459bf3f42e",
                        "f5e47128-e82f-4feb-999d-08d7a4f87f47"
                    ],
                    "keyword": [
                        "classifiers",
                        "combining",
                        "method",
                        "training",
                        "selection",
                        "reducing",
                        "ensemble",
                        "data",
                        "correlation"
                    ],
                    "group": [],
                    "_id": "6d15cd37-496d-44e1-8bfb-004621255173",
                    "abstract": "Using an ensemble of classifiers, instead of a single classifier, can lead to improved generalization. The gains obtained by combining, however, are often affected more by the selection of what is presented to the combiner than by the actual combining method that is chosen. In this paper, we focus on data selection and classifier training methods, in order to 'prepare' classifiers for combining. We review a combining framework for classification problems that quantifies the need for reducing the correlation among individual classifiers. Then, we discuss several methods that make the classifiers in an ensemble more complementary. Experimental results are provided to illustrate the benefits and pitfalls of reducing the correlation among classifiers, especially when the training data are in limited supply.",
                    "title": "Error Correlation and Error Reduction in Ensemble Classifiers",
                    "venue": "Connection Science",
                    "year": 1996,
                    "__v": 1,
                    "citationCount": 284,
                    "result": 5.087369063684853
                },
                "6e206624-7a7f-4ee9-91c8-d78003892706": {
                    "authors": [
                        "Kostas Tzeras",
                        "Stephan Hartmann"
                    ],
                    "references": [
                        "0fdd6fc4-a6ff-4e7b-858c-2daedb168b17",
                        "3b6582f9-238b-4f0b-b08c-200006c08aaf",
                        "51c8135d-1673-4fa8-9842-a65c4183ac73",
                        "d3e00e7e-1c64-4d7a-b2b2-1ad98ba4c706"
                    ],
                    "keyword": [
                        "indexing",
                        "terms",
                        "network",
                        "model",
                        "documents",
                        "descriptors",
                        "subject",
                        "set",
                        "manually",
                        "field"
                    ],
                    "group": [],
                    "_id": "6e206624-7a7f-4ee9-91c8-d78003892706",
                    "abstract": "In this paper, a Bayesian inference network model for automatic indexing with index terms (descriptors) from a prescribed vocabulary is presented. It requires an indexing dictionary with rules mapping terms of the respective subject field onto descriptors and inverted lists for terms occuring in a set of documents of the subject field and descriptors manually assigned to these documents. The indexing dictionary can be derived automatically from a set of manually indexed documents. An application of the network model is described, followed by an indexing example and some experimental results about the indexing performance of the network model.",
                    "title": "Automatic indexing based on Bayesian inference networks",
                    "venue": "international acm sigir conference on research and development in information retrieval",
                    "year": 1993,
                    "__v": 1,
                    "citationCount": 56,
                    "result": 4.520693101625303
                },
                "73f6b15e-509c-4f2f-9160-35cab954ce59": {
                    "authors": [
                        "Hinrich Schütze"
                    ],
                    "references": [
                        "013bad43-9c5b-4eab-b0d6-c43d160a348c",
                        "0761dd7a-2983-49ed-99ba-55d01ad52742",
                        "1017d9d4-9a4c-423d-ad40-6d9bebbd6b31",
                        "12c253c7-3370-4e51-9661-08387e32ba34",
                        "1de20f03-68b6-41a2-8dd1-7be9eb1f6f20",
                        "25ba4997-7f75-4ea3-97ed-85fb0b13d70d",
                        "30b9ff17-94d7-4b9f-8c36-086e277c64d7",
                        "39b2a9da-bc2f-4fe6-82a7-4bd1ed02487a",
                        "407ceb18-464f-4ab3-b731-68f7681fb26d",
                        "558dee29-ba49-4949-bbb8-ac8bb76541fd",
                        "56fd65de-2906-4521-9f3f-0e19c0d3f213",
                        "65c36d83-107a-46bf-a891-b6e43bce3273",
                        "69df0789-a06f-4166-9c34-93047de2673d",
                        "6b345e6a-d750-4f6c-b8e3-80b69d491557",
                        "6ff708cd-67c6-46a2-8670-36ccc78bbcc9",
                        "83faaeef-4488-4241-a0f1-1a0e88f16f6d",
                        "8c53ed72-c152-4669-8e48-b56557e2615f",
                        "91890426-e2a0-4130-aab6-a2b1381a1471",
                        "94497779-0b6c-4474-aac0-ffc629dc7a20",
                        "9566bd1c-79e4-4f6f-b641-4076386e1966",
                        "9ea84f5d-9bf2-4f30-8f9c-b7e71de58fd4",
                        "a506f179-4c89-4cfc-a719-c374b2671279",
                        "ac14afe6-de4d-4056-b2ac-0f6e36f369a2",
                        "b890b439-6915-4b95-bdaa-62c4cd66388b",
                        "bae03845-4ba1-4868-8a8e-e9ef0154fd63",
                        "c3e8c0e1-fb5a-427c-819b-e09e02520341",
                        "c5ebc174-30f8-41ff-a9e7-5434cdec979d",
                        "cc3bd164-3ef6-4c95-b910-d41a518e3b8c",
                        "e75d8e62-a86d-4241-953f-1b315005d920",
                        "f8310857-4b0d-491c-8ada-1997c65689d5",
                        "fc22752e-cd79-4d7a-b92f-668e16c92962",
                        "fee9e830-b9ff-46b4-9069-1de16eea42b9"
                    ],
                    "keyword": [
                        "word",
                        "similar",
                        "senses",
                        "training",
                        "space",
                        "contexts",
                        "clustering",
                        "ambiguous",
                        "paper",
                        "discrimination"
                    ],
                    "group": [],
                    "_id": "73f6b15e-509c-4f2f-9160-35cab954ce59",
                    "abstract": "This paper presents context-group discrimination, a disambiguation algorithm based on clustering. Senses are interpreted as groups (or clusters) of similar contexts of the ambiguous word. Words, contexts, and senses are represented in Word Space, a high-dimensional, real-valued space in which closeness corresponds to semantic similarity. Similarity in Word Space is based on second-order co-occurrence: two tokens (or contexts) of the ambiguous word are assigned to the same sense cluster if the words they co-occur with in turn occur with similar words in a training corpus. The algorithm is automatic and unsupervised in both training and application: senses are induced from a corpus without labeled training instances or other external knowledge sources. The paper demonstrates good performance of context-group discrimination for a sample of natural and artificial ambiguous words.",
                    "title": "Automatic word sense discrimination",
                    "venue": "Computational Linguistics",
                    "year": 1998,
                    "__v": 2,
                    "citationCount": 481,
                    "result": 6.181989978764129
                },
                "7fd22f4f-deba-415c-ae7c-cdbe5dba2f55": {
                    "authors": [
                        "Gianni Amati",
                        "Fabio Crestani"
                    ],
                    "references": [
                        "050f3d56-45c0-4c32-86fb-db2fe9b5fb88",
                        "1b7418af-1aba-4090-bad4-0dd0e900f5aa",
                        "23f66d97-4abf-479f-8af5-ec833d850a24",
                        "2a06cd01-485a-4ccf-a0b9-d7ee9f329122",
                        "34fb014b-1029-4565-a7b8-4a4813bb9063",
                        "52c01d07-28bb-4a1c-98da-1482a380f6db",
                        "5499177f-8a78-46bb-897b-69ab3ec91785",
                        "58913a76-a718-4493-a5e9-2fa8aa3ef52b",
                        "721edbab-399c-4aed-bd0a-4b0a8bdf304e",
                        "8c2183ba-4b42-49ab-993c-238e9db9ee1d",
                        "99a2d996-0af1-460a-b339-81f9804c5af2",
                        "9bdbf6d6-db2b-4114-969a-37b4e03993b0",
                        "a45e0fbe-2fd8-43cb-b1f0-730e986fcf63",
                        "c12af7c5-ea9e-41b8-8d0a-eab301f8d270",
                        "c4beaa25-a712-4854-803d-fa0d74149e84",
                        "da22867d-4d40-4ff0-abcd-f21544141e07",
                        "dc644023-cd3f-4aa9-ac7b-6f8f40645eda",
                        "e75d8e62-a86d-4241-953f-1b315005d920"
                    ],
                    "keyword": [
                        "information",
                        "systems",
                        "model",
                        "filter",
                        "users",
                        "relevance",
                        "learning",
                        "interests",
                        "describe",
                        "adaptive"
                    ],
                    "group": [],
                    "_id": "7fd22f4f-deba-415c-ae7c-cdbe5dba2f55",
                    "abstract": "New methods and new systems are needed to filter or to selectively distribute the increasing volume of electronic information being produced nowadays. An eAective information filtering system is one that provides the exact information that fulfills user’s interests with the minimum eAort by the user to describe it. Such a system will have to be adaptive to the user changing interest. In this paper we describe and evaluate a learning model for information filtering which is an adaptation of the generalized probabilistic model of Information Retrieval. The model is based on the concept of ‘uncertainty sampling’, a technique that allows for relevance feedback both on relevant and nonrelevant documents. The proposed learning model is the core of a prototype information filtering system called ProFile. # 1999 Elsevier Science Ltd. All rights reserved.",
                    "title": "Probabilistic learning for selective dissemination of information",
                    "venue": "Information Processing and Management",
                    "year": 1999,
                    "__v": 2,
                    "citationCount": 7,
                    "result": 6.67293947605513
                },
                "8828ba95-7026-4085-9803-7cce05949493": {
                    "authors": [
                        "Paolo Frasconi",
                        "Giovanni Soda",
                        "Alessandro Vullo"
                    ],
                    "references": [
                        "0500ddbe-e274-477b-bb6b-54a7269e4577",
                        "25f9dfdb-4cb7-4dd2-9b42-90992fd5d8b8",
                        "261aefde-fbe5-494f-afd7-c771aff03127",
                        "27d381c3-27e0-4c31-89fa-6639b3e06449",
                        "2d691e6d-df41-4fdc-b226-8068e19d5b34",
                        "367d33bc-55f2-4ac9-8adb-72c681914286",
                        "3cc7d99b-2563-47ab-a83a-3555a2bf2736",
                        "5c994317-6b61-4bbf-804e-694da117eb8d",
                        "9f4995af-e704-48ab-8717-6972a3d4455b",
                        "a8110bb3-072b-45e7-a5ee-72218e958a84",
                        "ad3a4ba4-5b88-4d61-9ba5-263cda996e9c",
                        "b099c046-5bfa-43b4-aa43-46fa47ba482c",
                        "d3e00e7e-1c64-4d7a-b2b2-1ad98ba4c706",
                        "dc06bc07-843e-4336-99f8-e561dc4fc3a1",
                        "dfb8a5e6-8046-4dcf-b6f3-be079bd26a8b",
                        "e0f04143-6efa-4507-86f9-6c3bb8243c0a",
                        "eb50f7e8-255a-4a28-baa9-d7d4003de8f8",
                        "ed660ea2-fad8-4bd1-8c0b-8c0679eb1657"
                    ],
                    "keyword": [
                        "page",
                        "sequences",
                        "document",
                        "classifying",
                        "text",
                        "scanned",
                        "naive",
                        "models",
                        "isolated",
                        "information"
                    ],
                    "group": [],
                    "_id": "8828ba95-7026-4085-9803-7cce05949493",
                    "abstract": "Text categorization is typically formulated as a concept learning prob lem where each instance is a single isolated document. In this paper we are interested in a more general formulation where documents are organized as page sequences, as naturally occurring in digital libraries of scanned books and magazines. We describe a method for classifying pages of sequential OCR text documents into one of several assigned categories and suggest that taking into account contextual information provided by the whole page sequence can significantly improve classification accuracy. The proposed architecture relies on hidden Markov models whose emissions are bag-of-words according to a multinomial word event model, as in the generative portion of the Naive Bayes classifier. Our results on a collection of scanned journals from the Making of America project confirm the importance of using whole page sequences. Empirical evaluation indicates that the error rate (as obtained by running a plain Naive Bayes classifier on isolated page) can be roughly reduced by half if contextual information is incorporated.",
                    "title": "Text categorization for multi-page documents: a hybrid naive Bayes HMM approach",
                    "venue": "acm/ieee joint conference on digital libraries",
                    "year": 2001,
                    "__v": 1,
                    "citationCount": 19,
                    "result": 6.208193296240997
                },
                "92d0da63-d882-4d22-b5d2-5c41306bda51": {
                    "authors": [
                        "Kamal Nigam",
                        "Andrew McCallum",
                        "Sebastian Thrun",
                        "Tom M. Mitchell"
                    ],
                    "references": [
                        "01e036ec-11c7-4251-98cc-13d11b59d0f0",
                        "1b7418af-1aba-4090-bad4-0dd0e900f5aa",
                        "36313bb8-e0c2-4900-a399-3e772f9f51dc",
                        "592e8a18-27bf-4561-89d2-01afb204534d",
                        "6ce645b9-765d-4660-9df1-5d6ac65040b5",
                        "8a62056a-f757-40ec-91de-e29769a612a6",
                        "9384fdc2-ca2a-4706-b0cc-23efbc7d9e6e",
                        "96d6d9b9-6d69-4c9a-b3f5-c8083966d55c",
                        "9f4995af-e704-48ab-8717-6972a3d4455b",
                        "bb74ee29-c9bd-4ed8-978c-295045e24594",
                        "d5f75cb3-4d88-4471-af2e-d1d4a3dc14fa",
                        "e89a739f-120a-4a4a-a8af-ced66ce482c9",
                        "ee746464-b6d4-47c6-afbb-8b8e0faa0bcd"
                    ],
                    "keyword": [
                        "unlabeled",
                        "labels",
                        "documents",
                        "training",
                        "text",
                        "classifiers",
                        "shows",
                        "data",
                        "small",
                        "large"
                    ],
                    "group": [],
                    "_id": "92d0da63-d882-4d22-b5d2-5c41306bda51",
                    "abstract": "In many important text classification problems, acquiring class labels for training documents is costly, while gathering large quantities of unlabeled data is cheap. This paper shows that the accuracy of text classifiers trained with a small number of labeled documents can be improved by augmenting this small training set with a large pool of unlabeled documents. We present a theoretical argument showing that, under common assumptions, unlabeled data contain information about the target function. We then introduce an algorithm for learning from labeled and unlabeled text based on the combination of Expectation-Maximization with a naive Bayes classifier. The algorithm first trains a classifier using the available labeled documents, and probabilistically labels the unlabeled documents; it then trains a new classifier using the labels for all the documents, and iterates to convergence. Experimental results, obtained using text from three different realworld tasks, show that the use of unlabeled data reduces classification error by up to 33%.",
                    "title": "Learning to classify text from labeled and unlabeled documents",
                    "venue": "national conference on artificial intelligence",
                    "year": 1998,
                    "__v": 2,
                    "citationCount": 171,
                    "result": 6.48527553996673
                },
                "96d6d9b9-6d69-4c9a-b3f5-c8083966d55c": {
                    "authors": [
                        "Pedro M. Domingos",
                        "Michael J. Pazzani"
                    ],
                    "references": [
                        "29a79d67-73a4-4990-9880-f9cc5b56c6f2",
                        "340c101a-7317-4ba9-b642-a91eb2e456a7",
                        "3a90b5d2-3377-4ffa-9545-9ef332679370",
                        "3b2d19a3-29b8-4983-832a-08e489f13f38",
                        "47b2f222-c6c2-4cb2-9aa0-07e7f7b8fea4",
                        "485598b2-ed73-4670-a44d-b0844f923fa4",
                        "4935259d-fca4-454d-9128-6dfed1c72357",
                        "4ca9b504-fdf7-4963-89a1-170608086f35",
                        "60ac157b-ad14-49c3-a901-6673c71cdb9d",
                        "62549bc2-e0b3-46e8-8d32-390dded105d5",
                        "7f60f284-50e8-4bf3-92c5-db7ef4975434",
                        "86dafb65-1d2e-42d9-8982-4d520b6da774",
                        "9d391f89-9fbd-438a-bbba-57f8fe085e0c",
                        "ac28de8d-4445-4d2d-a134-7f0e835ebca9",
                        "ad4af6f6-2bb4-47c5-9e26-e3877f28b4d8",
                        "cda06ad5-1cad-4bb7-834f-cd5693ad277a",
                        "d5f75cb3-4d88-4471-af2e-d1d4a3dc14fa",
                        "d6f92f3a-fff7-4312-be70-72f61e92913d",
                        "df1f94be-7bf8-4696-b0b5-42a02e06275c",
                        "e1662082-8ddd-4df1-90a9-c1f30382b3d0",
                        "ed748247-965b-4857-a004-7531209fa975",
                        "f76331c6-7be5-4f61-bbb1-25ea462536e6",
                        "f9de53f4-b2fe-46eb-888d-7497862b5354",
                        "fa70488d-1d06-4967-8c8e-c678cf1052c8"
                    ],
                    "keyword": [
                        "optimal",
                        "classifier",
                        "bayesian",
                        "attributes",
                        "showing",
                        "independent",
                        "domains",
                        "assumption",
                        "article"
                    ],
                    "group": [],
                    "_id": "96d6d9b9-6d69-4c9a-b3f5-c8083966d55c",
                    "abstract": "The simple Bayesian classifier is known to be optimal when attributes are independent given the class, but the question of whether other sufficient conditions for its optimality exist has so far not been explored. Empirical results showing that it performs surprisingly well in many domains containing clear attribute dependences suggest that the answer to this question may be positive. This article shows that, although the Bayesian classifier‘s probability estimates are only optimal under quadratic loss if the independence assumption holds, the classifier itself can be optimal under zero-one loss (misclassification rate) even when this assumption is violated by a wide margin. The region of quadratic-loss optimality of the Bayesian classifier is in fact a second-order infinitesimal fraction of the region of zero-one optimality. This implies that the Bayesian classifier has a much greater range of applicability than previously thought. For example, in this article it is shown to be optimal for learning conjunctions and disjunctions, even though they violate the independence assumption. Further, studies in artificial domains show that it will often outperform more powerful classifiers for common training set sizes and numbers of attributes, even if its bias is a priori much less appropriate to the domain. This article‘s results also imply that detecting attribute dependence is not necessarily the best way to extend the Bayesian classifier, and this is also verified empirically.",
                    "title": "On the Optimality of the Simple Bayesian Classifier under Zero-One Loss",
                    "venue": "Machine Learning",
                    "year": 1997,
                    "__v": 2,
                    "citationCount": 1021,
                    "result": 6.279674410556763
                },
                "979fbf34-d977-4a5e-a727-a1038c4d7f97": {
                    "authors": [
                        "Stephen Robertson",
                        "P. A. Harding"
                    ],
                    "references": [
                        "421b1c82-6d80-445e-94b1-8a583f03ee66",
                        "9bdbf6d6-db2b-4114-969a-37b4e03993b0",
                        "e1eb9e5d-9834-409d-b49a-96d6b8635df6"
                    ],
                    "keyword": [
                        "model",
                        "previously",
                        "method",
                        "indexing",
                        "coefficient",
                        "adhesion",
                        "work",
                        "suggesting",
                        "sense",
                        "relevance"
                    ],
                    "group": [],
                    "_id": "979fbf34-d977-4a5e-a727-a1038c4d7f97",
                    "abstract": "A probabilistic model previously used in relevance feedback is adapted for use in automatic indexing of documents (in the sense of imitating human indexers). The model fits with previous work in this area (the ‘adhesion coefficient’ method), in effect merely suggesting a different way of arriving at the adhesion coefficients. Methods for the application of the model are proposed. The independence assumptions used in the model are interpreted, and the possibility of a dependence model is discussed.",
                    "title": "PROBABILISTIC AUTOMATIC INDEXING BY LEARNING FROM HUMAN INDEXERS",
                    "venue": "Journal of Documentation",
                    "year": 1984,
                    "__v": 1,
                    "citationCount": 5,
                    "result": 3.5009069664891665
                },
                "9bdbf6d6-db2b-4114-969a-37b4e03993b0": {
                    "authors": [
                        "Stephen Robertson",
                        "K. Sparck Jones"
                    ],
                    "references": [
                        "4fe3d9ff-4ae4-4728-80d4-1d04d76a22f4",
                        "726363bc-9dc5-4c50-bb04-967f94e22e32",
                        "a768a676-fff6-4c1e-8164-2e072789019a"
                    ],
                    "keyword": [
                        "weight",
                        "relevance",
                        "terms",
                        "techniques",
                        "search",
                        "methods",
                        "information",
                        "general",
                        "theory",
                        "theoretical"
                    ],
                    "group": [],
                    "_id": "9bdbf6d6-db2b-4114-969a-37b4e03993b0",
                    "abstract": "Abstract#R##N##R##N#This paper examines statistical techniques for exploiting relevance information to weight search terms. These techniques are presented as a natural extension of weighting methods using information about the distribution of index terms in documents in general. A series of relevance weighting functions is derived and is justified by theoretical considerations. In particular, it is shown that specific weighted search methods are implied by a general probabilistic theory of retrieval. Different applications of relevance weighting are illustrated by experimental results for test collections.",
                    "title": "Relevance weighting of search terms",
                    "venue": "Journal of The American Society for Information Science",
                    "year": 1976,
                    "__v": 1,
                    "citationCount": 948,
                    "result": 3.75722218957513
                },
                "9c9be0c6-ab2a-467e-b499-dfb3fd207029": {
                    "authors": [
                        "Wai Lam",
                        "Miguel E. Ruiz",
                        "Padmini Srinivasan"
                    ],
                    "references": [
                        "050f3d56-45c0-4c32-86fb-db2fe9b5fb88",
                        "29cc6b55-f56e-47f3-be02-5fb050498f1c",
                        "2d691e6d-df41-4fdc-b226-8068e19d5b34",
                        "328e6d1a-73c4-48da-ac29-d671a581cf86",
                        "33d6dabd-c086-4a6e-939a-c322b6ada724",
                        "38ba97da-b9ad-40d5-9e66-b8a37d4748af",
                        "3b013a2d-ff3b-4ded-bbfa-e36fd67669e7",
                        "444e6653-d197-4b94-bae4-d8fc60168ed4",
                        "63e270a4-bcec-42f4-85c2-ea6d4cc7b3d2",
                        "8c0baa91-d32e-478b-89e3-d7c636db2e76",
                        "bb74ee29-c9bd-4ed8-978c-295045e24594",
                        "c13bf4d6-b7f2-4a7e-abf6-d798782b75ea",
                        "d1a51572-839b-4ae1-97c3-ad045ea6425a",
                        "febb53cc-a472-4f7e-afac-c530e7010051"
                    ],
                    "keyword": [
                        "retrieval",
                        "categorization",
                        "performance",
                        "automatic",
                        "text",
                        "approach",
                        "learning",
                        "investigate",
                        "document",
                        "demonstrate"
                    ],
                    "group": [],
                    "_id": "9c9be0c6-ab2a-467e-b499-dfb3fd207029",
                    "abstract": "We develop an automatic text categorization approach and investigate its application to text retrieval. The categorization approach is derived from a combination of a learning paradigm known as instance-based learning and an advanced document retrieval technique known as retrieval feedback. We demonstrate the effectiveness of our categorization approach using two real-world document collections from the MEDLINE database. Next, we investigate the application of automatic categorization to text retrieval. Our experiments clearly indicate that automatic categorization improves the retrieval performance compared with no categorization. We also demonstrate that the retrieval performance using automatic categorization achieves the same retrieval quality as the performance using manual categorization. Furthermore, detailed analysis of the retrieval performance on each individual test query is provided.",
                    "title": "Automatic text categorization and its application to text retrieval",
                    "venue": "IEEE Transactions on Knowledge and Data Engineering",
                    "year": 1999,
                    "__v": 2,
                    "citationCount": 63,
                    "result": 8.277653952543758
                },
                "a1e8ab1e-6df3-4383-b708-b5b5c29b4b7f": {
                    "authors": [
                        "S. K. M. Wong",
                        "Yiyu Yao"
                    ],
                    "references": [
                        "05986be7-7cdd-4fa0-bad5-cdd3506709e3",
                        "0b9943ae-7302-4fa2-9991-3bedeeb9fb15",
                        "0d013280-f884-461f-90bc-8c857a983d2b",
                        "21ad906d-f874-4d06-9de5-5a3702d36f1b",
                        "3127f547-c48d-4e55-a9c8-2dfc9a905419",
                        "333a550a-acbb-4b5d-8c1e-18db1049c014",
                        "366a2502-8abc-4930-9223-40b231f3e5cf",
                        "5cafea2a-aef1-4458-aee4-fe55d3fb11d8",
                        "894abe0d-19ac-44cc-9e25-d8f4ce1ee44f",
                        "9173ae92-14d3-4e0d-9f8a-d2e449b81f2d",
                        "938893b1-0e6b-4b58-9ff6-0e5b6b1414e0",
                        "9bdbf6d6-db2b-4114-969a-37b4e03993b0",
                        "b30ac9e1-8884-48cb-95b8-21b1d600ac7d",
                        "bad5026e-a9d0-46be-ab72-64027d1f6c4c",
                        "bae23982-9b64-4407-92c2-7c06c86c52dd",
                        "bae3dbf3-c241-4e3f-94be-8b4f5becbe06",
                        "be4d9059-a8d3-45b2-8199-b03fdc4beb4d",
                        "cbc32474-bb22-4892-a46d-7d1315ce6636",
                        "d3e00e7e-1c64-4d7a-b2b2-1ad98ba4c706",
                        "dacc4283-2823-4b85-aa89-661bd83b34eb",
                        "e6a052fb-5459-40fb-8aa9-afef148cb67b",
                        "e75d8e62-a86d-4241-953f-1b315005d920",
                        "fd0caead-422f-4c26-bc60-8574f1754272"
                    ],
                    "keyword": [
                        "models",
                        "retrieval",
                        "probabilistic",
                        "probability",
                        "information",
                        "inference",
                        "framework",
                        "article"
                    ],
                    "group": [],
                    "_id": "a1e8ab1e-6df3-4383-b708-b5b5c29b4b7f",
                    "abstract": "This article examines and extends the logical models of information retrieval in the context of probability theory. The fundamental notions of term weights and relevance are given probabilistic interpretations. A unified framework is developed for modeling the retrieval process with probabilistic inference. This new approach provides a common conceptual and mathematical basis for many retrieval models, such as the Boolean, fuzzy set, vector space, and conventional probabilistic models. Within this framework, the underlying assumptions employed by each model are identified, and the inherent relationships between these models are analyzed. Although this article is mainly a theoretical analysis of probabilistic inference for information retrieval, practical methods for estimating the required probabilities are provided by simple examples.",
                    "title": "On modeling information retrieval with probabilistic inference",
                    "venue": "ACM Transactions on Information Systems",
                    "year": 1995,
                    "__v": 1,
                    "citationCount": 110,
                    "result": 3.8057601198717315
                },
                "a506f179-4c89-4cfc-a719-c374b2671279": {
                    "authors": [
                        "Peter Willett"
                    ],
                    "references": [
                        "03156a4a-00fe-434a-8603-eeac9050c7d6",
                        "031a5abb-2674-43b3-995a-e2e54b31391d",
                        "03fc3f61-108e-4e06-98da-08fe3d506b53",
                        "078a2756-906c-4d3a-9e0c-1a5da10b5840",
                        "0f95fa59-3ce8-45f0-85c9-9b278e772c13",
                        "1ec45041-b11f-4785-b9ee-ed99eb029ddc",
                        "1f522f6c-11f7-4469-9e83-3fe163c39843",
                        "25d1fff5-d82f-4983-bfb5-5d20283d4002",
                        "2a2c0e77-5e48-4033-9f4a-85a4ad66a0c1",
                        "3331b3d7-9ab0-47b9-8433-77f377b3c602",
                        "401f5e6f-0f6e-4415-8003-426aea537d53",
                        "44b54aab-e9a0-423c-aa2b-698f78731fe0",
                        "4a0ed5de-0ab2-49b9-ad1b-77557d1eea56",
                        "5047e6e2-35f9-46a3-8b2e-5846f7bd50bf",
                        "549f525d-c61b-4f27-9b5e-897873a4feb5",
                        "5859ab7b-d98f-4a05-b563-5faebd3abde5",
                        "6f0a32a4-2eb1-4723-9a18-399605977eb1",
                        "6fd10047-5293-45f2-bb2c-8b9bdaee9642",
                        "717d1041-a807-4e21-8f26-14ee59b58c93",
                        "78cc655b-a126-42d3-a369-08942bb4d7a8",
                        "7a64555f-ee8d-4981-8273-bf9b3d477c3b",
                        "7baa75c2-279a-48f9-8673-7cfdfefacc77",
                        "7e13ce86-9884-4e96-9ac2-d75355963dc7",
                        "90a7f1a7-6399-4f8e-8abd-843263e9e54c",
                        "9a3f79eb-555c-4d06-aa73-e892ee547734",
                        "9bdbf6d6-db2b-4114-969a-37b4e03993b0",
                        "9f1a54e6-2b9e-4ac4-84b9-c606d1fb8eb9",
                        "a19d15d0-59ff-4ba9-8200-d0db9b234c8b",
                        "adf7d983-9784-4e80-b790-5340fa166d99",
                        "b0343204-ca89-4f23-bba1-ea37217cac0a",
                        "bb77684b-66b6-4f6d-b30c-115e2bcf82cb",
                        "c09f3f03-de7b-4785-9284-df5d0693f098",
                        "c623522a-0b9e-4c21-917c-1109bb1f109b",
                        "c7f40ba2-aa31-4507-a1c0-648c57ed9c7b",
                        "ca130ec9-f49f-4245-8cc7-8d69199fed71",
                        "cb42b262-cfba-40cb-b337-5fed91a7fff2",
                        "cbc32474-bb22-4892-a46d-7d1315ce6636",
                        "e41f6fda-3db0-4a29-883c-a88686d57162",
                        "e75d8e62-a86d-4241-953f-1b315005d920",
                        "f7bedc1e-11aa-4be9-abb0-82942ffeb04c"
                    ],
                    "keyword": [
                        "clustering",
                        "document",
                        "methods",
                        "retrieval",
                        "suggested",
                        "strategies",
                        "similarities",
                        "search",
                        "results",
                        "research"
                    ],
                    "group": [],
                    "_id": "a506f179-4c89-4cfc-a719-c374b2671279",
                    "abstract": "This article reviews recent research into the use of hierarchic agglomerative clustering methods for document retrieval. After an introduction to the calculation of interdocument similarities and to clustering methods that are appropriate for document clustering, the article discusses algorithms that can be used to allow the implementation of these methods on databases of nontrivial size. The validation of document hierarchies is described using tests based on the theory of random graphs and on empirical characteristics of document collections that are to be clustered. A range of search strategies is available for retrieval from document hierarchies and the results are presented of a series of research projects that have used these strategies to search the clusters resulting from several different types of hierarchic agglomerative clustering method. It is suggested that the complete linkage method is probably the most effective method in terms of retrieval performance; however, it is also difficult to implement in an efficient manner. Other applications of document clustering techniques are discussed briefly; experimental evidence suggests that nearest neighbor clusters, possibly represented as a network model, provide a reasonably efficient and effective means of including interdocument similarity information in document retrieval systems.",
                    "title": "Recent trends in hierarchic document clustering: a critical review",
                    "venue": "Information Processing and Management",
                    "year": 1988,
                    "__v": 2,
                    "citationCount": 347,
                    "result": 6.344343101436298
                },
                "ab339474-ea21-443b-893f-96ae09e65a2e": {
                    "authors": [
                        "Brett L. Kessler",
                        "Geoffrey Nunberg",
                        "Hinrich Schütze"
                    ],
                    "references": [
                        "7870231d-c710-4aa1-9ad3-ae121e3b488e",
                        "90ca3ecc-702a-45ab-af75-8c5851ce7bb9"
                    ],
                    "keyword": [
                        "genre",
                        "surface",
                        "structural",
                        "detection",
                        "cues",
                        "based",
                        "users",
                        "topical",
                        "theory",
                        "text"
                    ],
                    "group": [],
                    "_id": "ab339474-ea21-443b-893f-96ae09e65a2e",
                    "abstract": "As the text databases available to users become larger and more heterogeneous, genre becomes increasingly important for computational linguistics as a complement to topical and structural principles of classification. We propose a theory of genres as bundles of facets, which correlate with various surface cues, and argue that genre detection based on surface cues is as successful as detection based on deeper structural properties.",
                    "title": "Automatic Detection of Text Genre",
                    "venue": "meeting of the association for computational linguistics",
                    "year": 1997,
                    "__v": 2,
                    "citationCount": 158,
                    "result": 3.286358086358087
                },
                "bb98580e-953d-467f-8aa1-f0fd204cdb5c": {
                    "authors": [
                        "Daniel R. Tauritz",
                        "Joost N. Kok",
                        "Ida G. Sprinkhuizen-Kuyper"
                    ],
                    "references": [
                        "23f66d97-4abf-479f-8af5-ec833d850a24",
                        "33d6dabd-c086-4a6e-939a-c322b6ada724",
                        "56e41682-117e-41ba-b8a0-e646765733bb",
                        "78d5be0f-2b17-4cd3-82aa-c344a5e1e5a1",
                        "e2aad705-f18e-468f-8e85-82b88d82f9be"
                    ],
                    "keyword": [
                        "filtering",
                        "information",
                        "changing",
                        "adapt",
                        "weighted",
                        "user",
                        "trigram",
                        "streams",
                        "evolutionary",
                        "environment"
                    ],
                    "group": [],
                    "_id": "bb98580e-953d-467f-8aa1-f0fd204cdb5c",
                    "abstract": "Information Filtering is concerned with filtering data streams in such a way as to leave only pertinent data (information) to be perused. When the data streams are produced in a changing environment the filtering has to adapt too in order to remain eAective. Adaptive Information Filtering (AIF) is concerned with filtering in changing environments. The changes may occur both on the transmission side (the nature of the streams can change), and on the reception side (the interest of a user can change). Weighted trigram analysis is a quick and flexible technique for describing the contents of a document. A novel application of evolutionary computation is its use in Adaptive Information Filtering for optimizing various parameters, notably the weights associated with trigrams. The research described in this paper combines weighted trigram analysis, clustering, and a special two-pool evolutionary algorithm, to create an Adaptive Information Filtering system with such useful properties as domain independence, spelling error insensitivity, adaptability, and optimal use of user feedback while minimizing the amount of user feedback required to function properly. We designed a special evolutionary algorithm with a two-pool strategy for this changing environment. ” 2000 Elsevier Science Inc. All rights reserved.",
                    "title": "Adaptive information filtering using evolutionary computation",
                    "venue": "Information Sciences",
                    "year": 2000,
                    "__v": 2,
                    "citationCount": 18,
                    "result": 4.687277054949038
                },
                "bc66f6be-1038-4deb-a11e-35f51f0937d4": {
                    "authors": [
                        "Norbert Fuhr",
                        "Ulrich Pfeifer"
                    ],
                    "references": [
                        "05986be7-7cdd-4fa0-bad5-cdd3506709e3",
                        "0fdd6fc4-a6ff-4e7b-858c-2daedb168b17",
                        "3328d1fd-485a-4605-8f72-848eea7ad8d1",
                        "441fc627-1bb6-4861-8281-e77aa95870c4",
                        "51c8135d-1673-4fa8-9842-a65c4183ac73",
                        "556a6f2e-2737-40f0-aec1-9a13a2fdb1ef",
                        "5b6620cd-3df0-4309-a24d-b120be89242c",
                        "5d623037-6181-4248-92e7-bd2cda4c788e",
                        "73492acc-f0c9-495d-8b4d-5917f29d74e1",
                        "979fbf34-d977-4a5e-a727-a1038c4d7f97",
                        "9bdbf6d6-db2b-4114-969a-37b4e03993b0",
                        "c28ea43f-078a-4b68-a690-5a0ec70a983e",
                        "fd49370f-c4c1-4e5d-a753-e079e2d3fb7d"
                    ],
                    "keyword": [
                        "probabilistic",
                        "model",
                        "approaches",
                        "regression",
                        "logistic",
                        "concepts",
                        "combines",
                        "yielding",
                        "vocabulary",
                        "variants"
                    ],
                    "group": [],
                    "_id": "bc66f6be-1038-4deb-a11e-35f51f0937d4",
                    "abstract": "We show that former approaches in probabilistic information retrieval are based on one or two of the three concepts  abstraction, inductive learning , and  probabilistic assumptions , and we propose a new approach which combines all three concepts. This approach is illustrated for the case of indexing with a controlled vocabulary. For this purpose, we describe a new probabilistic model first, which is then combined with logistic regression, thus yielding a generalization of the original model. Experimental results for the pure theoretical model as well as for heuristic variants are given. Furthermore, linear and logistic regression are compared.",
                    "title": "Probabilistic information retrieval as a combination of abstraction, inductive learning, and probabilistic assumptions",
                    "venue": "ACM Transactions on Information Systems",
                    "year": 1994,
                    "__v": 1,
                    "citationCount": 24,
                    "result": 6.618884831650483
                },
                "c04cc3bb-dd4a-4abd-b55b-3d3ebaccfba5": {
                    "authors": [
                        "Gerard Escudero",
                        "Lluís Màrquez",
                        "German Rigau"
                    ],
                    "references": [
                        "056e5059-9864-479b-8a2a-fb1cd3d2dd32",
                        "35c68a87-b192-4879-9238-6aed38284a96",
                        "35f5afaa-80b5-411f-8fac-5d575a4257b2",
                        "3704f939-09a2-4e9f-b851-1261bcd310df",
                        "4a75ee64-7fb7-4e4b-9f69-3f243900825d",
                        "4c7d3402-9b26-4857-a999-49ccb3b5cc46",
                        "72a56003-90e2-4226-9aa6-529f2b79c0b6",
                        "852d4703-36db-4c8c-814c-6cd2273b536b",
                        "96c6e601-8010-476d-9ea4-f13118313dac",
                        "a9a79a49-3063-4d7f-a353-34df2a8175a1",
                        "aa9af505-b437-4081-ba4a-97f0355a7f9e",
                        "becc43bc-a7b6-46e1-817e-553c84a4a6dd",
                        "c1185068-2bef-48cb-ab84-acb6fa66bb69",
                        "c3c33123-e11e-4e76-ab25-a012099ec6e4",
                        "ca46649f-54c3-4138-ac4b-abd784e99f0d",
                        "db26488d-78be-44b1-a343-e896f43c5d29",
                        "dc704db6-53b5-4c5f-9a02-91ee32f08385",
                        "f98f3e2b-d93b-4c34-bb55-f2acc0cddab6"
                    ],
                    "keyword": [
                        "word",
                        "boosting",
                        "algorithm",
                        "wsd",
                        "approach"
                    ],
                    "group": [],
                    "_id": "c04cc3bb-dd4a-4abd-b55b-3d3ebaccfba5",
                    "abstract": "In this paper Schapire and Singer's AdaBoost.MH boosting algorithm is applied to the Word Sense Disambiguation (WSD) problem. Initial experiments on a set of 15 selected polysemous words show that the boosting approach surpasses Naive Bayes and Exemplar-based approaches, which represent state-of-the-art accuracy on supervised WSD. In order to make boosting practical for a real learning domain of thousands of words, several ways of accelerating the algorithm by reducing the feature space are studied. The best variant, which we call LazyBoosting, is tested on the largest sense-tagged corpus available containing 192,800 examples of the 191 most frequent and ambiguous English words. Again, boosting compares favourably to the other benchmark algorithms.",
                    "title": "Boosting Applied to Word Sense Disambiguation",
                    "venue": "Lecture Notes in Computer Science",
                    "year": 2000,
                    "__v": 1,
                    "citationCount": 56,
                    "result": 2.2216117216117213
                },
                "c2cce1cf-b653-430b-b5e4-b5141484f09c": {
                    "authors": [
                        "David D. Lewis"
                    ],
                    "references": [
                        "02906fce-6d39-46fc-b7cc-564042504aab",
                        "4fe3d9ff-4ae4-4728-80d4-1d04d76a22f4",
                        "92637b2b-dba4-4e30-8726-d03fa76c7c85",
                        "bc66f6be-1038-4deb-a11e-35f51f0937d4",
                        "ed660ea2-fad8-4bd1-8c0b-8c0679eb1657"
                    ],
                    "keyword": [
                        "systems",
                        "ranking",
                        "text",
                        "documents",
                        "retrieval",
                        "ir",
                        "information",
                        "effectiveness"
                    ],
                    "group": [],
                    "_id": "c2cce1cf-b653-430b-b5e4-b5141484f09c",
                    "abstract": "Text retrieval systems typically produce a ranking of documents and let a user decide how far down that ranking to go. In contrast, programs that filter text streams, software that categorizes documents, agents which alert users, and many other IR systems must make decisions without human input or supervision. It is important to define what constitutes good effectiveness for these autonomous systems, tune the systems to achieve the highest possible effectiveness, and estimate how the effectiveness changes as new data is processed. We show how to do this for binary text classification systems, emphasizing that different goals for the system le ad to different optimal behaviors. Optimizing and estimating effectiveness is greatly aided if classifiers that explicitly estimate the probability of class membership are used. Ranked retrieval is the information retrieval (IR) researc her’s favorite tool for dealing with information overload. Ranked retrieval systems display documents in order of probability of releva nce or some similar measure. Users see the best documents first, anddecide how far down the ranking to go in examining the available information. The central role played by ranking in this appr oach has led researchers to evaluate IR systems primarily, often exclusively, on the quality of their rankings. (See, for instance , the TREC evaluations [1].) In some IR applications, however, ranking is not enough: A company provides an SDI (selective dissemination of information) service which filters newswire feeds. Relevant articles are faxed each morning to clients. Interaction between customer and system takes place infrequently. The cost of resources (tying up phone lines, fax machine paper, etc.) is a factor to consider in operating the system. A text categorization system assigns controlled vocabulary categories to incoming documents as they are stored in a text database. Cost cutting has eliminated manual checking of category assignments.",
                    "title": "Evaluating and optimizing autonomous text classification systems",
                    "venue": "international acm sigir conference on research and development in information retrieval",
                    "year": 1995,
                    "__v": 2,
                    "citationCount": 155,
                    "result": 5.118380381665526
                },
                "e9abffef-c6bf-44da-a673-be480773dbbb": {
                    "authors": [
                        "Gerard Salton",
                        "A. Wong",
                        "Chung-Shu Yang"
                    ],
                    "references": [
                        "4deb6643-8815-4985-b9c5-525fdfd94fb1"
                    ],
                    "keyword": [
                        "space",
                        "indexing",
                        "document",
                        "density",
                        "retrieval",
                        "pattern",
                        "entities",
                        "vocabulary",
                        "typical",
                        "system"
                    ],
                    "group": [],
                    "_id": "e9abffef-c6bf-44da-a673-be480773dbbb",
                    "abstract": "In a document retrieval, or other pattern matching environment where stored entities (documents) are compared with each other or with incoming patterns (search requests), it appears that the best indexing (property) space is one where each entity lies as far away from the others as possible; in these circumstances the value of an indexing system may be expressible as a function of the density of the object space; in particular, retrieval performance may correlate inversely with space density. An approach based on space density computations is used to choose an optimum indexing vocabulary for a collection of documents. Typical evaluation results are shown, demonstating the usefulness of the model.",
                    "title": "A vector space model for automatic indexing",
                    "venue": "Communications of The ACM",
                    "year": 1975,
                    "__v": 2,
                    "citationCount": 2507,
                    "result": 4.887525219878163
                },
                "f644253d-4748-4ef1-847b-c6a41a231c90": {
                    "authors": [
                        "Harris Drucker",
                        "Donghui Wu",
                        "Vladimir Vapnik"
                    ],
                    "references": [
                        "01e036ec-11c7-4251-98cc-13d11b59d0f0",
                        "3704f939-09a2-4e9f-b851-1261bcd310df",
                        "8af54182-bed5-4224-b11d-a5ec3bbbb069",
                        "9519ccab-8cda-40ff-bd55-b61857c27b56",
                        "bb74ee29-c9bd-4ed8-978c-295045e24594",
                        "d8ddd4ae-16ab-4702-b4f5-65aff0e33533"
                    ],
                    "keyword": [
                        "svm",
                        "sets",
                        "data",
                        "features",
                        "trees",
                        "tested",
                        "performed",
                        "boosting",
                        "algorithms",
                        "vector"
                    ],
                    "group": [],
                    "_id": "f644253d-4748-4ef1-847b-c6a41a231c90",
                    "abstract": "We study the use of support vector machines (SVM) in classifying e-mail as spam or nonspam by comparing it to three other classification algorithms: Ripper, Rocchio, and boosting decision trees. These four algorithms were tested on two different data sets: one data set where the number of features were constrained to the 1000 best features and another data set where the dimensionality was over 7000. SVM performed best when using binary features. For both data sets, boosting trees and SVM had acceptable test performance in terms of accuracy and speed. However, SVM had significantly less training time.",
                    "title": "Support vector machines for spam categorization",
                    "venue": "IEEE Transactions on Neural Networks",
                    "year": 1999,
                    "__v": 2,
                    "citationCount": 502,
                    "result": 3.0793241293989047
                },
                "ff78f8f6-0559-4be7-a7e1-0e8bb742ecda": {
                    "authors": [
                        "Fabrizio Sebastiani",
                        "Alessandro Sperduti",
                        "Nicola Valdambrini"
                    ],
                    "references": [
                        "01e036ec-11c7-4251-98cc-13d11b59d0f0",
                        "0bcf0b45-5d17-4f84-9912-0d35660c4403",
                        "168f05e4-d428-4184-bfd5-e53bfd6644c4",
                        "245e4043-ccdb-457a-9be1-e120c7a94753",
                        "290e0375-d2ad-4bec-a94f-f05e1580125b",
                        "310cbba4-d88d-4bf4-a4f2-738f91b5f8c8",
                        "328e6d1a-73c4-48da-ac29-d671a581cf86",
                        "3c2b6887-7b44-42c2-bf79-ac44c38a5eb7",
                        "3f394e9d-c50a-4505-9b76-458f5e8be345",
                        "55ab17e9-5c62-4157-adc9-28935eed7120",
                        "852d4703-36db-4c8c-814c-6cd2273b536b",
                        "9519ccab-8cda-40ff-bd55-b61857c27b56",
                        "9f4995af-e704-48ab-8717-6972a3d4455b",
                        "c2cce1cf-b653-430b-b5e4-b5141484f09c",
                        "db26488d-78be-44b1-a343-e896f43c5d29",
                        "e9a10bb1-bcd7-48c4-af6b-df754852d14c"
                    ],
                    "keyword": [
                        "trained",
                        "classifiers",
                        "sc",
                        "adaboost",
                        "mhkr",
                        "categorization",
                        "boosting",
                        "text",
                        "proven",
                        "performers"
                    ],
                    "group": [],
                    "_id": "ff78f8f6-0559-4be7-a7e1-0e8bb742ecda",
                    "abstract": "We describe an improved boosting algorithm, called {\\sc AdaBoost.MH$^{KR}$}, and its application to text categorization. Boosting is a method for supervised learning which has successfully been applied to many different domains, and that has proven one of the best performers in text categorization exercises so far. Boosting is based on the idea of relying on the collective judgment of a committee of classifiers that are trained sequentially. In training the $i$-th classifier special emphasis is placed on the correct categorization of the training documents which have proven harder for the previously trained classifiers. {\\sc AdaBoost.MH$^{KR}$} is based on the idea to build, at every iteration of the learning phase, not a single classifier but a sub-committee of the $K$ classifiers which, at that iteration, look the most promising. We report the results of systematic experimentation of this method performed on the standard {\\sf Reuters-21578} benchmark. These experiments have shown that {\\sc AdaBoost.MH$^{KR}$} is both more efficient to train and more effective than the original {\\sc AdaBoost.MH$^{R}$} algorithm.",
                    "title": "An improved boosting algorithm and its application to text categorization",
                    "venue": "conference on information and knowledge management",
                    "year": 2000,
                    "__v": 2,
                    "citationCount": 38,
                    "result": 6.253455164153332
                }
            }
        ],
        "_id": "4adb467d-dacf-4019-b0d5-28ce1f323cf4",
        "abstract": "The automated categorization (or classification) of texts into predefined categories has witnessed a booming interest in the last 10 years, due to the increased availability of documents in digital form and the ensuing need to organize them. In the research community the dominant approach to this problem is based on machine learning techniques: a general inductive process automatically builds a classifier by learning, from a set of preclassified documents, the characteristics of the categories. The advantages of this approach over the knowledge engineering approach (consisting in the manual definition of a classifier by domain experts) are a very good effectiveness, considerable savings in terms of expert labor power, and straightforward portability to different domains. This survey discusses the main approaches to text categorization that fall within the machine learning paradigm. We will discuss in detail issues pertaining to three different problems, namely, document representation, classifier construction, and classifier evaluation.",
        "title": "Machine learning in automated text categorization",
        "venue": "ACM Computing Surveys",
        "year": 2002,
        "__v": 2,
        "citationCount": 2709
    },
    {
        "authors": [
            "Ion Stoica",
            "Robert Morris",
            "David Liben-Nowell",
            "David R. Karger",
            "M. Frans Kaashoek",
            "Frank Dabek",
            "Hari Balakrishnan"
        ],
        "references": [
            "1cc64868-4f72-4939-aed4-fc8fb0b45118",
            "48740ddd-afd1-4331-8af7-224ef5d19ed7",
            "59084791-6ebd-4d0d-8f93-2c1da8d47490",
            "6aac8d9c-34bd-42d9-b887-b0a3bd697ee6",
            "6eff83a4-db80-40ea-8c9f-8bda5f506c29",
            "a369afee-a619-4e9a-9250-5fd2b06e8a05",
            "aa89fd2a-319e-48b1-b0ab-099acbe37617",
            "abf003a2-6485-41f0-a111-88b80412d539",
            "b7d7ec53-f079-4bd7-a795-8b6fe77f2db6",
            "b948f5db-4dc3-4151-a9bd-62a3f5be739e",
            "c0ea675b-2479-48ae-817e-3ecedd175ecf",
            "c37c70cb-3956-4249-934d-848845f2f444",
            "e1263ada-afda-498c-a37d-9b545293118a",
            "e4ee2d81-7629-4445-b4f3-55ef57bd42fd",
            "ea44a1ae-ddfe-4694-8df1-0ec69182ec11",
            "f14df1ed-e3e9-4348-9040-fc06e3411b95",
            "f49921e2-fb25-48d1-aaf2-1afcfeb8b268",
            "fad8fc34-ff78-45ac-bc30-ca9e4173740f"
        ],
        "keyword": [
            "node",
            "chord",
            "key",
            "data",
            "system",
            "stores",
            "problem",
            "maps",
            "location",
            "item"
        ],
        "group": [
            {
                "59084791-6ebd-4d0d-8f93-2c1da8d47490": {
                    "authors": [
                        "Paul V. Mockapetris",
                        "Kevin J. Dunlap"
                    ],
                    "references": [
                        "9b65b2b8-9750-48b5-8f3c-790a85a0de96",
                        "aa18f452-d13c-4301-89c7-ca2bb0b89e85"
                    ],
                    "keyword": [
                        "service",
                        "ideas",
                        "evolution",
                        "dns",
                        "users",
                        "usages",
                        "unique",
                        "today",
                        "system",
                        "surprises"
                    ],
                    "group": [],
                    "_id": "59084791-6ebd-4d0d-8f93-2c1da8d47490",
                    "abstract": "The Domain Name System (DNS) provides name service for the DARPA Internet. It is one of the largest name services in operation today, serves a highly diverse community of hosts, users, and networks, and uses a unique combination of hierarchies, caching, and datagram access.  This paper examines the ideas behind the initial design of the DNS in 1983, discusses the evolution of these ideas into the current implementations and usages, notes conspicuous surprises, successes and shortcomings, and attempts to predict its future evolution.",
                    "title": "Development of the Domain Name System",
                    "venue": "acm special interest group on data communication",
                    "year": 1988,
                    "__v": 2,
                    "citationCount": 161,
                    "result": 3.857886557886558
                },
                "6aac8d9c-34bd-42d9-b887-b0a3bd697ee6": {
                    "authors": [
                        "Maarten van Steen",
                        "Franz J. Hauck",
                        "Gerco Ballintijn",
                        "Andrew S. Tanenbaum"
                    ],
                    "references": [
                        "22dc34f7-bd6a-4f3f-822c-6fe8d6d2bf43",
                        "24829bb4-274a-447b-b7a6-71695fb2e28d",
                        "2b02cc9c-4d97-41ca-94b7-503df0e53134",
                        "38ba7e7b-315a-4617-80fd-0556ee730c5d",
                        "3df02e7b-67df-4f8e-9031-5cf7d7f54a69",
                        "40b5fc96-9009-4201-8b6f-7ccb8e389165",
                        "4e8c7d2e-b6fb-42d5-b543-cba29b4fca7c",
                        "5320bc98-beb8-4b2c-b906-3a05df4e018c",
                        "553e719c-81cd-4191-9c68-f0adf7c15361",
                        "5983f4cf-0d99-444b-8b95-9c635bf20d20",
                        "5c7e3099-b047-4152-bb6d-de884f94cafc",
                        "5e43bfa1-e1fa-428f-847f-b1b575380d14",
                        "5e8be929-7c33-4976-b583-2b41790fe4be",
                        "61058526-954d-4e68-8f11-db9c4dab0689",
                        "747c0c4a-1e59-4af3-a9a6-ad0d081a49ce",
                        "7f1dc63a-9064-4768-a30d-3383d52aa81e",
                        "89ba9c4f-5643-4643-9a65-47bc724723b4",
                        "e9ad62a7-612c-4581-ac73-8b008c5f797a"
                    ],
                    "keyword": [
                        "objects",
                        "location",
                        "distributed",
                        "addresses",
                        "worldwide",
                        "set",
                        "service",
                        "operations",
                        "lookup",
                        "highly"
                    ],
                    "group": [],
                    "_id": "6aac8d9c-34bd-42d9-b887-b0a3bd697ee6",
                    "abstract": "We describe the algorithmic design of a worldwide location service for distributed objects. A distributed object can reside at multiple locations at the same time, and offers a set of addresses to allow client processes to contact it. Objects may be highly mobile like, for example, software agents or Web applets. The proposed location service supports regular updates of an object's set of contact addresses, as well as efficient look-up operations. Our design is based on a worldwide distributed search tree in which addresses are stored at different levels, depending on the migration pattern of the object. By exploiting an object's relative stability with respect to a region, combined with the use of pointer caches, look-up operations can be made highly efficient.",
                    "title": "Algorithmic Design of the Globe Wide-Area Location Service",
                    "venue": "The Computer Journal",
                    "year": 1998,
                    "__v": 2,
                    "citationCount": 16,
                    "result": 3.563869463869464
                },
                "a369afee-a619-4e9a-9250-5fd2b06e8a05": {
                    "authors": [
                        "David G. Andersen",
                        "Hari Balakrishnan",
                        "M. Frans Kaashoek",
                        "Robert Morris"
                    ],
                    "references": [
                        "01a09d2c-f8d3-40e4-bfee-211533b3f526",
                        "030d5be6-55f2-4776-85fd-c8924e5fac85",
                        "05b6c845-f269-4f70-86ff-a2d89b60e6b5",
                        "1642f59c-10a1-40da-abb1-0934ef864108",
                        "2915a22c-b1dd-46e9-9082-40793a90abf9",
                        "3d02b614-3aa0-4647-9e95-8e3fde4c4371",
                        "4152f693-19b7-4de5-bd38-d25341487814",
                        "436b5fcd-6488-4a4c-b41a-85130718b39a",
                        "4b5c9003-da3b-4a1c-9ddd-0262278668e5",
                        "5de99dee-6647-4ebf-b20b-fe970cfd062b",
                        "69c181d4-c63d-4951-bce6-e44733a2f3c5",
                        "71e44140-b60b-4385-b0f5-31c33c7b5ccc",
                        "8df0f1e0-c75c-4c63-81d9-b8ab58daa4fd",
                        "8ed0c977-c4e4-4183-8ec3-b2fc7bea41cf",
                        "96562dc6-4016-4259-bb10-e29d0e09e6b8",
                        "b3cae739-ffac-48c0-b164-11b3088cc22c",
                        "b893a5b5-0e77-44b8-9cd9-6157c96558af",
                        "c3feb1e8-16d7-43af-946a-7ef9b37ca2bd"
                    ],
                    "keyword": [
                        "ron",
                        "routing",
                        "internet",
                        "path",
                        "improving",
                        "detect",
                        "transfers",
                        "recover",
                        "nodes",
                        "fault"
                    ],
                    "group": [],
                    "_id": "a369afee-a619-4e9a-9250-5fd2b06e8a05",
                    "abstract": "A Resilient Overlay Network (RON) is an architecture that allows distributed Internet applications to detect and recover from path outages and periods of degraded performance within several seconds, improving over today's wide-area routing protocols that take at least several minutes to recover. A RON is an application-layer overlay on top of the existing Internet routing substrate. The RON nodes monitor the functioning and quality of the Internet paths among themselves, and use this information to decide whether to route packets directly over the Internet or by way of other RON nodes, optimizing application-specific routing metrics.Results from two sets of measurements of a working RON deployed at sites scattered across the Internet demonstrate the benefits of our architecture. For instance, over a 64-hour sampling period in March 2001 across a twelve-node RON, there were 32 significant outages, each lasting over thirty minutes, over the 132 measured paths. RON's routing mechanism was able to detect, recover, and route around  all  of them, in less than twenty seconds on average, showing that its methods for fault detection and recovery work well at discovering alternate paths in the Internet. Furthermore, RON was able to improve the loss rate, latency, or throughput perceived by data transfers; for example, about 5% of the transfers doubled their TCP throughput and 5% of our transfers saw their loss probability reduced by 0.05. We found that forwarding packets via at most one intermediate RON node is sufficient to overcome faults and improve performance in most cases. These improvements, particularly in the area of fault detection and recovery, demonstrate the benefits of moving some of the control over routing into the hands of end-systems.",
                    "title": "Resilient overlay networks",
                    "venue": "symposium on operating systems principles",
                    "year": 2001,
                    "__v": 2,
                    "citationCount": 1043,
                    "result": 3.93963258963259
                },
                "abf003a2-6485-41f0-a111-88b80412d539": {
                    "authors": [
                        "J. Lawrence Carter",
                        "Mark N. Wegman"
                    ],
                    "references": [
                        "011d7883-14a9-438c-98af-df7374058a85",
                        "7b3d6a35-46aa-4344-9064-ede233b33010",
                        "a662a4e7-415e-417e-8a8f-fe085d7e487f",
                        "b069183c-3f8c-42dd-a95e-c59dc26b3f74",
                        "f13a2155-7026-4da7-8147-b6a3d152c089"
                    ],
                    "keyword": [
                        "input",
                        "function",
                        "hash",
                        "algorithm",
                        "retrieval",
                        "class",
                        "time",
                        "suitable",
                        "storage",
                        "sequence"
                    ],
                    "group": [],
                    "_id": "abf003a2-6485-41f0-a111-88b80412d539",
                    "abstract": "Abstract   This paper gives an  input independent  average linear time algorithm for storage and retrieval on keys. The algorithm makes a random choice of hash function from a suitable class of hash functions. Given any sequence of inputs the expected time (averaging over all functions in the class) to store and retrieve elements is linear in the length of the sequence. The number of references to the data base required by the algorithm for any input is extremely close to the theoretical minimum for any possible hash function with randomly distributed inputs. We present three suitable classes of hash functions which also can be evaluated rapidly. The ability to analyze the cost of storage and retrieval without worrying about the distribution of the input allows as corollaries improvements on the bounds of several algorithms.",
                    "title": "Universal classes of hash functions",
                    "venue": "Journal of Computer and System Sciences",
                    "year": 1979,
                    "__v": 1,
                    "citationCount": 928,
                    "result": 2.9197136197136198
                },
                "b7d7ec53-f079-4bd7-a795-8b6fe77f2db6": {
                    "authors": [
                        "Frank Dabek",
                        "M. Frans Kaashoek",
                        "David R. Karger",
                        "Robert Morris",
                        "Ion Stoica"
                    ],
                    "references": [
                        "1c729f22-9928-4703-92a0-8819569a1bbb",
                        "1cc64868-4f72-4939-aed4-fc8fb0b45118",
                        "1dda408f-2203-4793-bfa8-2fab15bce7cf",
                        "48740ddd-afd1-4331-8af7-224ef5d19ed7",
                        "4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4",
                        "5e354aca-2d93-43f7-8e80-6bc4eb96e7d9",
                        "5fa0709f-7330-417f-8da7-3ab31d91da5b",
                        "6eff83a4-db80-40ea-8c9f-8bda5f506c29",
                        "786e7d9f-6e9a-47e5-8482-7ee37809b922",
                        "9f65fe84-a2e3-420a-8fe4-7253e4605422",
                        "a369afee-a619-4e9a-9250-5fd2b06e8a05",
                        "b1ab8eee-7043-4f04-b440-5765752d4845",
                        "b90c5640-8e10-4f65-9193-c28af80f45e2",
                        "bd61df44-c80e-406c-8c4e-9c13635ce4f5",
                        "c0ea675b-2479-48ae-817e-3ecedd175ecf",
                        "cb0dcdc4-3c84-4301-891b-42535ac74f8c",
                        "cf67f4c1-ff76-4210-ba80-0356733c5be7",
                        "e1263ada-afda-498c-a37d-9b545293118a",
                        "f14df1ed-e3e9-4348-9040-fc06e3411b95"
                    ],
                    "keyword": [
                        "cfs",
                        "servers",
                        "system",
                        "block",
                        "file",
                        "dhash",
                        "storage",
                        "robustness"
                    ],
                    "group": [],
                    "_id": "b7d7ec53-f079-4bd7-a795-8b6fe77f2db6",
                    "abstract": "The Cooperative File System (CFS) is a new peer-to-peer read-only storage system that provides provable guarantees for the efficiency, robustness, and load-balance of file storage and retrieval. CFS does this with a completely decentralized architecture that can scale to large systems. CFS servers provide a distributed hash table (DHash) for block storage. CFS clients interpret DHash blocks as a file system. DHash distributes and caches blocks at a fine granularity to achieve load balance, uses replication for robustness, and decreases latency with server selection. DHash finds blocks using the Chord location protocol, which operates in time logarithmic in the number of servers.CFS is implemented using the SFS file system toolkit and runs on Linux, OpenBSD, and FreeBSD. Experience on a globally deployed prototype shows that CFS delivers data to clients as fast as FTP. Controlled tests show that CFS is scalable: with 4,096 servers, looking up a block of data involves contacting only seven servers. The tests also demonstrate nearly perfect robustness and unimpaired performance even when as many as half the servers fail.",
                    "title": "Wide-area cooperative storage with CFS",
                    "venue": "symposium on operating systems principles",
                    "year": 2001,
                    "__v": 2,
                    "citationCount": 784,
                    "result": 8.17907647907648
                },
                "e1263ada-afda-498c-a37d-9b545293118a": {
                    "authors": [
                        "Sylvia Ratnasamy",
                        "Paul Francis",
                        "Mark Handley",
                        "Richard M. Karp",
                        "Scott Shenker"
                    ],
                    "references": [
                        "00ade209-5974-42c1-9089-a3741481d9c7",
                        "0695070f-320e-4d26-9c68-2c8faa20c944",
                        "0a094924-1b25-43cc-ac8b-dd8cf90a8f78",
                        "1545dfd3-2c25-4ff1-b43c-df4a2a501d06",
                        "1cc64868-4f72-4939-aed4-fc8fb0b45118",
                        "31c5e39a-3f24-4d20-bf8c-3d00036baf95",
                        "39adcd6c-0b60-430c-99ab-21cd9e98b385",
                        "42c70869-0dad-4629-93b5-a2d9e29071a7",
                        "4743d708-b82d-42ec-adaa-a8bf2f23cc38",
                        "483cb980-c968-48e6-b848-714ed2937f98",
                        "48740ddd-afd1-4331-8af7-224ef5d19ed7",
                        "4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4",
                        "88c35cd8-dd49-44f8-9674-96974c8f3650",
                        "c0ea675b-2479-48ae-817e-3ecedd175ecf",
                        "c8771a57-de9c-44b7-966c-1ff156d3091f",
                        "d06f8723-1b89-4684-99c9-c1045ddfb85c",
                        "e4ee2d81-7629-4445-b4f3-55ef57bd42fd",
                        "ec7d1720-3285-4729-b819-b4c58a826ec8",
                        "f6fc4443-7a98-4f9f-92e8-e4e5d94521a7"
                    ],
                    "keyword": [
                        "systems",
                        "scalable",
                        "hash",
                        "functionality",
                        "distributed",
                        "valuable",
                        "values",
                        "tablelike",
                        "tables",
                        "software"
                    ],
                    "group": [
                        null
                    ],
                    "_id": "e1263ada-afda-498c-a37d-9b545293118a",
                    "abstract": "Hash tables - which map \"keys\" onto \"values\" - are an essential building block in modern software systems. We believe a similar functionality would be equally valuable to large distributed systems. In this paper, we introduce the concept of a Content-Addressable Network (CAN) as a distributed infrastructure that provides hash table-like functionality on Internet-like scales. The CAN is scalable, fault-tolerant and completely self-organizing, and we demonstrate its scalability, robustness and low-latency properties through simulation.",
                    "title": "A scalable content-addressable network",
                    "venue": "acm special interest group on data communication",
                    "year": 2001,
                    "__v": 3,
                    "citationCount": 3635,
                    "result": 7.533288641183379
                },
                "e4ee2d81-7629-4445-b4f3-55ef57bd42fd": {
                    "authors": [
                        "Jinyang Li",
                        "John Jannotti",
                        "Douglas S. J. De Couto",
                        "David R. Karger",
                        "Robert Morris"
                    ],
                    "references": [
                        "0d4d0363-07b5-43b6-976d-955e96044709",
                        "1545dfd3-2c25-4ff1-b43c-df4a2a501d06",
                        "39adcd6c-0b60-430c-99ab-21cd9e98b385",
                        "60fb0dc2-bde3-4714-948e-de0ed12ab460",
                        "6eff83a4-db80-40ea-8c9f-8bda5f506c29",
                        "7c9f8cd8-d0ef-4954-b4db-4a6c803459c2",
                        "83a2eb55-b330-4e0c-8dc9-05e9466d5028",
                        "9de43d04-c7fa-48a9-b092-67c2888745d4",
                        "c7b0d60b-9956-4254-b6d3-26fb1f8782bb",
                        "e3af190a-754d-415d-a32d-f1d9999c599f",
                        "ff4259bb-5b84-4f51-b975-146794715d22"
                    ],
                    "keyword": [
                        "node",
                        "location",
                        "gls",
                        "mobile",
                        "networks",
                        "servers",
                        "queries",
                        "predefined",
                        "geographic"
                    ],
                    "group": [],
                    "_id": "e4ee2d81-7629-4445-b4f3-55ef57bd42fd",
                    "abstract": "GLS is a new distributed location service which tracks mobile node locations. GLS combined with geographic forwarding allows the construction of ad hoc mobile networks that scale to a larger number of nodes than possible with previous work. GLS is decentralized and runs on the mobile nodes themselves, requiring no fixed infrastructure. Each mobile node periodically updates a small set of other nodes (its location servers) with its current location. A node sends its position updates to its location servers without knowing their actual identities, assisted by a predefined ordering of node identifiers and a predefined geographic hierarchy. Queries for a mobile node's location also use the predefined identifier ordering and spatial hierarchy to find a location server for that node.  Experiments using the  ns  simulator for up to 600 mobile nodes show that the storage and bandwidth requirements of GLS grow slowly with the size of the network. Furthermore, GLS tolerates node failures well: each failure has only a limited effect and query performance degrades gracefully as nodes fail and restart. The query performance of GLS is also relatively insensitive to node speeds. Simple geographic forwarding combined with GLS compares favorably with Dynamic Source Routing (DSR): in larger networks (over 200 nodes) our approach delivers more packets, but consumes fewer network resources.",
                    "title": "A scalable location service for geographic ad hoc routing",
                    "venue": "acm ieee international conference on mobile computing and networking",
                    "year": 2000,
                    "__v": 2,
                    "citationCount": 786,
                    "result": 4.259018759018759
                },
                "ea44a1ae-ddfe-4694-8df1-0ec69182ec11": {
                    "authors": [
                        "Sameer Ajmani",
                        "Dwaine E. Clarke",
                        "Chuang-Hue Moh",
                        "Steven Richman"
                    ],
                    "references": [
                        "151d2005-6170-4201-8cee-ea3870353ab7",
                        "16828a9e-92bc-4160-89eb-a1b30bd06410",
                        "1cc64868-4f72-4939-aed4-fc8fb0b45118",
                        "1e440687-918b-46c1-ba06-2e05472261b4",
                        "4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4",
                        "5fad6d18-3991-4cd2-9bf4-1c50821095aa",
                        "6eff83a4-db80-40ea-8c9f-8bda5f506c29",
                        "7507e0d5-e5d3-4b54-b83e-8ce26c720ae0",
                        "8d697cd1-10e1-460b-a797-c7c41d4b3646",
                        "9d11aa6c-586e-40dc-a475-094bf043431f",
                        "a83ce62d-7b67-4121-b8d6-d142d630056e",
                        "b7d7ec53-f079-4bd7-a795-8b6fe77f2db6",
                        "b869c249-f61a-416c-90d7-16ad4a3a1dff",
                        "c42097c1-59a6-4105-87d7-104d486ca211",
                        "e1263ada-afda-498c-a37d-9b545293118a",
                        "e7dd5f64-2732-4426-a522-f3572fddde97",
                        "eb02194b-fa72-4f3e-a259-1dd36cd4839d",
                        "f14df1ed-e3e9-4348-9040-fc06e3411b95"
                    ],
                    "keyword": [],
                    "group": [],
                    "_id": "ea44a1ae-ddfe-4694-8df1-0ec69182ec11",
                    "abstract": "We present ConChord, a large-scale certificate distribution system built on a peer-to-peer distributed hash table. ConChord provides load-balanced storage while eliminating many of the administrative difficulties of traditional, hierarchical server architectures.ConChord is specifically designed to support SDSI, a fully-decentralized public key infrastructure that allows principals to define local names and link their namespaces to delegate trust. We discuss the particular challenges ConChord must address to support SDSI efficiently, and we present novel algorithms and distributed data structures to address them. Experiments show that our techniques are effective and practical for large SDSI name hierarchies.",
                    "title": "ConChord: Cooperative SDSI Certificate Storage and Name Resolution",
                    "venue": "international workshop on peer-to-peer systems",
                    "year": 2002,
                    "__v": 0,
                    "citationCount": 18,
                    "result": 2.7777777777777777
                },
                "f14df1ed-e3e9-4348-9040-fc06e3411b95": {
                    "authors": [
                        "Antony I. T. Rowstron",
                        "Peter Druschel"
                    ],
                    "references": [
                        "0f290b24-96ae-48f7-9304-9209bba8db17",
                        "1cc64868-4f72-4939-aed4-fc8fb0b45118",
                        "309f5d34-0bb0-4ffc-aa87-fdffb67dddf6",
                        "39adcd6c-0b60-430c-99ab-21cd9e98b385",
                        "40fb7878-7a6e-4fc1-af74-a73c1261c20b",
                        "42c70869-0dad-4629-93b5-a2d9e29071a7",
                        "48740ddd-afd1-4331-8af7-224ef5d19ed7",
                        "4ae3d80b-ce75-4c33-8abb-c5358ec01a6d",
                        "4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4",
                        "4ff9d356-904f-4ad9-835a-bc3ccf6febd9",
                        "5e354aca-2d93-43f7-8e80-6bc4eb96e7d9",
                        "5e43bfa1-e1fa-428f-847f-b1b575380d14",
                        "6500989e-b1e1-4b02-a921-21ec25685b73",
                        "747c0c4a-1e59-4af3-a9a6-ad0d081a49ce",
                        "b7d7ec53-f079-4bd7-a795-8b6fe77f2db6",
                        "c0ea675b-2479-48ae-817e-3ecedd175ecf",
                        "c8771a57-de9c-44b7-966c-1ff156d3091f",
                        "d81c71d5-dd57-46e3-92e0-daf7a7bbb065",
                        "e1263ada-afda-498c-a37d-9b545293118a",
                        "e4ee2d81-7629-4445-b4f3-55ef57bd42fd",
                        "eb02194b-fa72-4f3e-a259-1dd36cd4839d"
                    ],
                    "keyword": [
                        "nodes",
                        "pastry",
                        "network",
                        "routing",
                        "scalable",
                        "nodeid",
                        "message",
                        "failures"
                    ],
                    "group": [
                        null
                    ],
                    "_id": "f14df1ed-e3e9-4348-9040-fc06e3411b95",
                    "abstract": "This paper presents the design and evaluation of Pastry, a scalable, distributed object location and routing substrate for wide-area peer-to-peer ap- plications. Pastry performs application-level routing and object location in a po- tentially very large overlay network of nodes connected via the Internet. It can be used to support a variety of peer-to-peer applications, including global data storage, data sharing, group communication and naming. Each node in the Pastry network has a unique identifier (nodeId). When presented with a message and a key, a Pastry node efficiently routes the message to the node with a nodeId that is numerically closest to the key, among all currently live Pastry nodes. Each Pastry node keeps track of its immediate neighbors in the nodeId space, and notifies applications of new node arrivals, node failures and recoveries. Pastry takes into account network locality; it seeks to minimize the distance messages travel, according to a to scalar proximity metric like the number of IP routing hops. Pastry is completely decentralized, scalable, and self-organizing; it automatically adapts to the arrival, departure and failure of nodes. Experimental results obtained with a prototype implementation on an emulated network of up to 100,000 nodes confirm Pastry's scalability and efficiency, its ability to self-organize and adapt to node failures, and its good network locality properties.",
                    "title": "Pastry: Scalable, Decentralized Object Location, and Routing for Large-Scale Peer-to-Peer Systems",
                    "venue": "Lecture Notes in Computer Science",
                    "year": 2001,
                    "__v": 3,
                    "citationCount": 4022,
                    "result": 7.23073038073038
                },
                "f49921e2-fb25-48d1-aaf2-1afcfeb8b268": {
                    "authors": [
                        "David Liben-Nowell",
                        "Hari Balakrishnan",
                        "David R. Karger"
                    ],
                    "references": [
                        "1cc64868-4f72-4939-aed4-fc8fb0b45118",
                        "32b2b6e0-71a1-45ec-be83-0d79c0e9d4ea",
                        "48740ddd-afd1-4331-8af7-224ef5d19ed7",
                        "4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4",
                        "6eff83a4-db80-40ea-8c9f-8bda5f506c29",
                        "7502e770-12f7-4fd1-8cd6-f54f456f7aa8",
                        "90caa8e6-80d7-4cb6-9953-361bca34ec25",
                        "b7d7ec53-f079-4bd7-a795-8b6fe77f2db6",
                        "d06f8723-1b89-4684-99c9-c1045ddfb85c",
                        "e1263ada-afda-498c-a37d-9b545293118a",
                        "f9636795-26d0-4e59-8fd6-f56024fecb00"
                    ],
                    "keyword": [
                        "rate",
                        "networks",
                        "system",
                        "p2p",
                        "chord",
                        "state",
                        "nodes",
                        "maintains",
                        "joins",
                        "give"
                    ],
                    "group": [],
                    "_id": "f49921e2-fb25-48d1-aaf2-1afcfeb8b268",
                    "abstract": "In this paper, we give a theoretical analysis of peer-to-peer (P2P) networks operating in the face of concurrent joins and unexpected departures. We focus on Chord, a recently developed P2P system that implements a distributed hash table abstraction, and study the process by which Chord maintains its distributed state as nodes join and leave the system. We argue that traditional performance measures based on run-time are uninformative for a  continually running  P2P network, and that the  rate  at which nodes in the network need to participate to maintain system state is a more useful metric. We give a general lower bound on this rate for a network to remain connected, and prove that an appropriately modified version of Chord's maintenance rate is within a logarithmic factor of the optimum rate.",
                    "title": "Analysis of the evolution of peer-to-peer systems",
                    "venue": "principles of distributed computing",
                    "year": 2002,
                    "__v": 2,
                    "citationCount": 226,
                    "result": 10.495598845598845
                },
                "fad8fc34-ff78-45ac-bc30-ca9e4173740f": {
                    "authors": [
                        "T. S. Eugene Ng",
                        "Hui Zhang"
                    ],
                    "references": [
                        "4743d708-b82d-42ec-adaa-a8bf2f23cc38"
                    ],
                    "keyword": [
                        "internet",
                        "network",
                        "geometric",
                        "distance",
                        "predict",
                        "positioning",
                        "hosts",
                        "gnp",
                        "coordinates",
                        "approach"
                    ],
                    "group": [],
                    "_id": "fad8fc34-ff78-45ac-bc30-ca9e4173740f",
                    "abstract": "We propose a new approach to predict Internet network distance called Global Network Positioning (GNP). This approach models the Internet as a geometric space and distributedly computes geometric coordinates to characterize the positions of hosts in the Internet. By conducting Internet experiments, we show that the geometric distances implied by the GNP hosts coordinates can accurately predict the Internet network distances.",
                    "title": "Towards global network positioning",
                    "venue": "acm special interest group on data communication",
                    "year": 2001,
                    "__v": 2,
                    "citationCount": 69,
                    "result": 4.632098946804829
                }
            }
        ],
        "_id": "4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4",
        "abstract": "A fundamental problem that confronts peer-to-peer applications is the efficient location of the node that stores a desired data item. This paper presents  Chord , a distributed lookup protocol that addresses this problem. Chord provides support for just one operation: given a key, it maps the key onto a node. Data location can be easily implemented on top of Chord by associating a key with each data item, and storing the key/data pair at the node to which the key maps. Chord adapts efficiently as nodes join and leave the system, and can answer queries even if the system is continuously changing. Results from theoretical analysis and simulations show that Chord is scalable: Communication cost and the state maintained by each node scale logarithmically with the number of Chord nodes.",
        "title": "Chord: a scalable peer-to-peer lookup protocol for Internet applications",
        "venue": "IEEE\\/ACM Transactions on Networking",
        "year": 2003,
        "__v": 3,
        "citationCount": 5975
    },
    {
        "authors": [
            "Rong-En Fan",
            "Kai-Wei Chang",
            "Cho-Jui Hsieh",
            "Xiang-Rui Wang",
            "Chih-Jen Lin"
        ],
        "references": [
            "8bfb1563-5f31-4127-a98c-8d36c630fce8",
            "c1b6b493-01ef-420f-be44-7bacfe34e846",
            "eadb0f66-1fb0-4b1c-9b8b-76cf5edbfad1",
            "eef64a27-8e9a-40b2-865f-0cca306fdc31",
            "f006e236-59ad-4647-a59f-4f46dc2c85be"
        ],
        "keyword": [
            "users",
            "supports",
            "linear",
            "library",
            "liblinear",
            "vector",
            "tools",
            "sparse",
            "source",
            "sets"
        ],
        "group": [
            {
                "8bfb1563-5f31-4127-a98c-8d36c630fce8": {
                    "authors": [
                        "Thorsten Joachims"
                    ],
                    "references": [
                        "0cba8ef9-d3db-4ce1-9933-463ed71f5153",
                        "2237ab73-a42a-4d5d-807c-5ab6e6abbc95",
                        "24b021c0-31cf-4277-8512-5616c3238ba2",
                        "27002288-c316-4416-97b4-a6d582ec83b2",
                        "9764de87-e34e-4ea1-8de3-12d9bffc4f55",
                        "a246e432-612a-4481-95b5-29ba3db6369b",
                        "b5ed7586-8f67-4e79-ac6b-f8cd6422650a",
                        "be003015-ba80-4492-ab82-76b91a70c71e",
                        "c1b6b493-01ef-420f-be44-7bacfe34e846",
                        "c671681a-2e91-4d53-8953-53c766668dba",
                        "c7553d0c-160f-49d7-9bff-ec5d6b3fc043",
                        "ccec85e2-c888-4f5a-b0c1-3acf27fa9030",
                        "cfea40f7-7c61-497c-8be7-284aa479552d",
                        "dd5a3ef5-9d44-4dde-bcdb-dc4d17c69073",
                        "fa81a051-0f8e-4f10-a172-acd5a8923e23"
                    ],
                    "keyword": [
                        "problems",
                        "large",
                        "algorithm",
                        "training",
                        "svms",
                        "svm",
                        "number",
                        "machines",
                        "linear",
                        "features"
                    ],
                    "group": [],
                    "_id": "8bfb1563-5f31-4127-a98c-8d36c630fce8",
                    "abstract": "Linear Support Vector Machines (SVMs) have become one of the most prominent machine learning techniques for high-dimensional sparse data commonly encountered in applications like text classification, word-sense disambiguation, and drug design. These applications involve a large number of examples  n  as well as a large number of features  N , while each example has only  s   N  non-zero features. This paper presents a Cutting Plane Algorithm for training linear SVMs that provably has training time  0(s,n)  for classification problems and  o ( sn  log ( n ))for ordinal regression problems. The algorithm is based on an alternative, but equivalent formulation of the SVM optimization problem. Empirically, the Cutting-Plane Algorithm is several orders of magnitude faster than decomposition methods like svm light for large datasets.",
                    "title": "Training linear SVMs in linear time",
                    "venue": "knowledge discovery and data mining",
                    "year": 2006,
                    "__v": 1,
                    "citationCount": 879,
                    "result": 7.307226107226108
                },
                "c1b6b493-01ef-420f-be44-7bacfe34e846": {
                    "authors": [
                        "Chih-Chung Chang",
                        "Chih-Jen Lin"
                    ],
                    "references": [
                        "036a2a1b-8729-431d-b260-3d6b33c6c6a4",
                        "078b095c-7687-43f2-a0bf-30ea78f787db",
                        "11f27d27-6bd9-4691-834e-9864871a65f4",
                        "1f556c88-b553-4c75-b243-92d8200f8149",
                        "2d768672-0070-4a38-87c8-f0cce1dd2f44",
                        "33184e74-4574-4856-a969-e497fdc2fec8",
                        "41087d29-5163-4a9f-b55a-3f407b8a040d",
                        "4317334f-595f-45be-a095-efe8f258b558",
                        "50dd56db-151d-4d62-8576-65f0ef6f381b",
                        "5ffac6f9-2456-42cf-830c-9049ce37c899",
                        "633e2247-d487-4ae7-b6ab-a17a075b83aa",
                        "7c6a970a-0d6f-4e4b-b50e-6c6fbd23a9ab",
                        "7f03746d-ba06-4b34-828e-683192e9ee42",
                        "8b26f4a9-380f-432d-aea1-66a86ce407e8",
                        "8c0ec27c-e654-4e0e-8c49-9b427117a98e",
                        "90925435-d33a-4abd-892d-abbe52e547c4",
                        "92a420a1-f54b-4cdd-b5a4-2669ac2e7c5d",
                        "962d4022-ff67-4067-a544-828604d8db52",
                        "9764de87-e34e-4ea1-8de3-12d9bffc4f55",
                        "97bfd03c-335a-4f39-89d3-cf0a22769383",
                        "a2e5c222-c380-42d7-8846-cbc232f46a69",
                        "a5d347a7-9984-45f4-821e-df7356477185",
                        "b532d930-ad51-4a05-9c5c-9a75d6b021a2",
                        "b90f9310-726f-4116-9322-6fc01ab598fd",
                        "bb693c93-e418-46ea-8b38-9c53df27bdf2",
                        "cdbd2ef9-d4b1-4dff-9037-3ea84627424d",
                        "dd5a3ef5-9d44-4dde-bcdb-dc4d17c69073",
                        "f006e236-59ad-4647-a59f-4f46dc2c85be",
                        "feff8862-f47d-4591-a7cb-b62d7efc81a2"
                    ],
                    "keyword": [
                        "libsvm",
                        "svm",
                        "machines",
                        "details",
                        "year",
                        "wide",
                        "vector",
                        "users",
                        "theoretical",
                        "svms"
                    ],
                    "group": [
                        null
                    ],
                    "_id": "c1b6b493-01ef-420f-be44-7bacfe34e846",
                    "abstract": "LIBSVM is a library for Support Vector Machines (SVMs). We have been actively developing this package since the year 2000. The goal is to help users to easily apply SVM to their applications. LIBSVM has gained wide popularity in machine learning and many other areas. In this article, we present all implementation details of LIBSVM. Issues such as solving SVM optimization problems theoretical convergence multiclass classification probability estimates and parameter selection are discussed in detail.",
                    "title": "LIBSVM: A library for support vector machines",
                    "venue": "ACM Transactions on Intelligent Systems and Technology",
                    "year": 2011,
                    "__v": 3,
                    "citationCount": 13475,
                    "result": 8.753283644460117
                },
                "eadb0f66-1fb0-4b1c-9b8b-76cf5edbfad1": {
                    "authors": [
                        "Cho-Jui Hsieh",
                        "Kai-Wei Chang",
                        "Chih-Jen Lin",
                        "S. Sathiya Keerthi",
                        "S. Sundararajan"
                    ],
                    "references": [
                        "0ed949f7-7118-45fa-8a4c-63fcf9f4bd8f",
                        "21873321-4d54-456b-b858-ac914b7e6db4",
                        "2190c590-c037-4170-9a93-a9d0c4468077",
                        "27002288-c316-4416-97b4-a6d582ec83b2",
                        "500961bc-9b1a-4010-a6cc-a6bae9b0e406",
                        "5959890a-1153-4bc3-b9f6-ec3ee3825eec",
                        "5ffac6f9-2456-42cf-830c-9049ce37c899",
                        "8bfb1563-5f31-4127-a98c-8d36c630fce8",
                        "b90f9310-726f-4116-9322-6fc01ab598fd",
                        "c1b6b493-01ef-420f-be44-7bacfe34e846",
                        "f006e236-59ad-4647-a59f-4f46dc2c85be",
                        "f8b62fcc-2912-427c-a1d8-786f58209193"
                    ],
                    "keyword": [
                        "svm",
                        "method",
                        "linear",
                        "descent",
                        "data",
                        "coordinate",
                        "vector",
                        "tron",
                        "tools",
                        "support"
                    ],
                    "group": [],
                    "_id": "eadb0f66-1fb0-4b1c-9b8b-76cf5edbfad1",
                    "abstract": "In many applications, data appear with a huge number of instances as well as features. Linear Support Vector Machines (SVM) is one of the most popular tools to deal with such large-scale sparse data. This paper presents a novel dual coordinate descent method for linear SVM with L1-and L2-loss functions. The proposed method is simple and reaches an  e -accurate solution in  O (log(1/ e )) iterations. Experiments indicate that our method is much faster than state of the art solvers such as Pegasos, TRON, SVM perf , and a recent primal coordinate descent implementation.",
                    "title": "A dual coordinate descent method for large-scale linear SVM",
                    "venue": "international conference on machine learning",
                    "year": 2008,
                    "__v": 2,
                    "citationCount": 343,
                    "result": 13.1628990290755
                },
                "eef64a27-8e9a-40b2-865f-0cca306fdc31": {
                    "authors": [
                        "S. Sathiya Keerthi",
                        "S. Sundararajan",
                        "Kai-Wei Chang",
                        "Cho-Jui Hsieh",
                        "Chih-Jen Lin"
                    ],
                    "references": [
                        "1b7418af-1aba-4090-bad4-0dd0e900f5aa",
                        "2237ab73-a42a-4d5d-807c-5ab6e6abbc95",
                        "51c81c66-8666-4756-9383-4fd2db5472b3",
                        "5959890a-1153-4bc3-b9f6-ec3ee3825eec",
                        "7fbbef81-7c36-4a5d-9e92-e7c59e7b82b7",
                        "834f73f1-7468-499e-bbf6-67810694bcc8",
                        "8bfb1563-5f31-4127-a98c-8d36c630fce8",
                        "a5d347a7-9984-45f4-821e-df7356477185",
                        "b5ed7586-8f67-4e79-ac6b-f8cd6422650a",
                        "cf93558f-c1b2-4292-8284-1be8d4316af1",
                        "eadb0f66-1fb0-4b1c-9b8b-76cf5edbfad1",
                        "f006e236-59ad-4647-a59f-4f46dc2c85be",
                        "f33acc76-f25e-446f-a834-9d898907b326",
                        "feff8862-f47d-4591-a7cb-b62d7efc81a2"
                    ],
                    "keyword": [
                        "training",
                        "method",
                        "dual",
                        "vector",
                        "variables",
                        "traverse",
                        "time",
                        "text",
                        "support",
                        "state"
                    ],
                    "group": [],
                    "_id": "eef64a27-8e9a-40b2-865f-0cca306fdc31",
                    "abstract": "Efficient training of direct multi-class formulations of linear Support Vector Machines is very useful in applications such as text classification with a huge number examples as well as features. This paper presents a fast dual method for this training. The main idea is to sequentially traverse through the training set and optimize the dual variables associated with one example at a time. The speed of training is enhanced further by shrinking and cooling heuristics. Experiments indicate that our method is much faster than state of the art solvers such as bundle, cutting plane and exponentiated gradient methods.",
                    "title": "A sequential dual method for large scale multi-class linear svms",
                    "venue": "knowledge discovery and data mining",
                    "year": 2008,
                    "__v": 2,
                    "citationCount": 81,
                    "result": 11.297480297480298
                }
            }
        ],
        "_id": "4cbd7765-c47a-4004-a5f8-c2da7c7d1c7b",
        "abstract": "LIBLINEAR is an open source library for large-scale linear classification. It supports logistic regression and linear support vector machines. We provide easy-to-use command-line tools and library calls for users and developers. Comprehensive documents are available for both beginners and advanced users. Experiments demonstrate that LIBLINEAR is very efficient on large sparse data sets.",
        "title": "LIBLINEAR: A Library for Large Linear Classification",
        "venue": "Journal of Machine Learning Research",
        "year": 2008,
        "__v": 2,
        "citationCount": 2507
    },
    {
        "authors": [
            "Isabelle Guyon",
            "André Elisseeff"
        ],
        "references": [
            "00686a4c-9370-453a-a25e-6f8415bb3dcb",
            "0781e713-d8ca-4f62-89e8-3047b77dd6e6",
            "15c30ca5-6af6-4acf-b8c5-f2c0e18e6ad8",
            "19d8e565-399d-47a8-bd30-8ff4fe857892",
            "1f684a47-9d17-43a2-93fd-fc04170ee56b",
            "2bd9968a-1e0b-4a11-85a2-19edcf0ee77d",
            "3b4ee100-c0b9-46a4-902b-b8190ef436e8",
            "3fff50e3-6a11-415b-8c8d-6f2c651f658d",
            "4335d1c6-7731-4208-a669-64a932d7805e",
            "4419a7b8-4585-42ab-8713-d28969940448",
            "46c9b8ec-b728-4901-83da-a6e7d4bee165",
            "4746dd3a-008d-4529-be20-578d0f90408c",
            "48a90b30-c40f-40a8-aea4-c5c59b6c611f",
            "4c3fd4d5-c23d-4a24-84cd-21d45208941e",
            "5f8f7c01-a1b8-4f84-b75f-e06768f1ddce",
            "685b313d-8a77-481e-9456-e405a1d29549",
            "69530d71-f2ba-42b6-97dd-42a71316f6a4",
            "69df0789-a06f-4166-9c34-93047de2673d",
            "6c2fee35-a596-416a-bd8a-a7966324f71e",
            "80f32ec0-5100-407e-9e42-a6710b921397",
            "8f72a5f3-5ae7-474a-a85c-7142eba278cc",
            "95fdc823-57bc-4e49-8e5b-8fac0c4cfb7f",
            "967012b4-dd43-4a03-adbd-46cace52c671",
            "9981fac3-aca8-42ce-827d-453ed01176a0",
            "9fa61eb1-0984-4492-955a-4f7aedbdc368",
            "bdd8b9ba-232e-42ed-9fcb-4f57c6f4efba",
            "ce028c76-6040-4f87-b8e7-d6741ce9d1c4",
            "d99d5225-5b3d-406d-9da1-96223bd50daa",
            "df328bfc-4d7e-4aba-b171-0eea8ecdd146",
            "f006e236-59ad-4647-a59f-4f46dc2c85be",
            "fb5dc6a4-869b-42e4-bf81-1ddaff7cc9f7"
        ],
        "keyword": [
            "feature",
            "variable",
            "selection",
            "providing",
            "processing",
            "predictors",
            "objective",
            "methods",
            "areas"
        ],
        "group": [
            {
                "5f8f7c01-a1b8-4f84-b75f-e06768f1ddce": {
                    "authors": [
                        "Jason Weston",
                        "André Elisseeff",
                        "Bernhard Schölkopf",
                        "Michael E. Tipping"
                    ],
                    "references": [
                        "0781e713-d8ca-4f62-89e8-3047b77dd6e6",
                        "08dcb9a2-1d9e-4094-a9ed-144d4343167e",
                        "1f73723c-b904-4d93-8045-d8de3772fb27",
                        "404775ac-d2d2-4a0b-8195-9458da97105b",
                        "50dd56db-151d-4d62-8576-65f0ef6f381b",
                        "5ffac6f9-2456-42cf-830c-9049ce37c899",
                        "8bb47288-c305-4131-9a23-3635d1bc15ad",
                        "95fdc823-57bc-4e49-8e5b-8fac0c4cfb7f",
                        "9be38f21-45a0-4712-80bc-a88ba7efc6c1",
                        "9fa61eb1-0984-4492-955a-4f7aedbdc368",
                        "d99d5225-5b3d-406d-9da1-96223bd50daa",
                        "e2fad125-5b57-4f2a-a3b6-9cd0dcbbafc8",
                        "f006e236-59ad-4647-a59f-4f46dc2c85be"
                    ],
                    "keyword": [
                        "minimization",
                        "zeronorm",
                        "variable",
                        "training",
                        "simple",
                        "selection",
                        "method",
                        "learning",
                        "feature",
                        "discuss"
                    ],
                    "group": [],
                    "_id": "5f8f7c01-a1b8-4f84-b75f-e06768f1ddce",
                    "abstract": "We explore the use of the so-called zero-norm of the parameters of linear models in learning. Minimization of such a quantity has many uses in a machine learning context: for variable or feature selection, minimizing training error and ensuring sparsity in solutions. We derive a simple but practical method for achieving these goals and discuss its relationship to existing techniques of minimizing the zero-norm. The method boils down to implementing a simple modification of vanilla SVM, namely via an iterative multiplicative rescaling of the training data. Applications we investigate which aid our discussion include variable and feature selection on biological microarray data, and multicategory classification.",
                    "title": "Use of the zero norm with linear models and kernel methods",
                    "venue": "Journal of Machine Learning Research",
                    "year": 2003,
                    "__v": 2,
                    "citationCount": 301,
                    "result": 11.099846133260197
                },
                "685b313d-8a77-481e-9456-e405a1d29549": {
                    "authors": [
                        "Ron Kohavi",
                        "George H. John"
                    ],
                    "references": [
                        "0587052d-9988-4c3f-8f82-3ffcf8da7c86",
                        "0cc7f81d-3960-4e11-ab65-5406091a49d8",
                        "0f115eea-2272-431f-9f21-6d6789b2bbc9",
                        "0f240e79-dd13-4510-a19a-64586438f8d5",
                        "119792fb-54c1-49f5-8648-13d24b19ecf5",
                        "1570e0c2-bcf6-4f5a-92db-d1b0936d68d3",
                        "245e4043-ccdb-457a-9be1-e120c7a94753",
                        "34ea7fc5-8b5a-46d6-aa41-155442792ab0",
                        "36313bb8-e0c2-4900-a399-3e772f9f51dc",
                        "36338d50-6305-4d9f-9065-cde919913bfb",
                        "3a90b5d2-3377-4ffa-9545-9ef332679370",
                        "3b85426c-08c7-4299-af41-3d0140325e56",
                        "43e502f4-87f2-4672-9217-823cf6c56e56",
                        "485598b2-ed73-4670-a44d-b0844f923fa4",
                        "4b0df874-c029-4993-9c36-50e795192cfb",
                        "4de0dbe7-3582-4125-94be-d0c36ea097fc",
                        "522e1bb9-8ec7-448b-a6ea-7e08b3b6b205",
                        "60ac157b-ad14-49c3-a901-6673c71cdb9d",
                        "62549bc2-e0b3-46e8-8d32-390dded105d5",
                        "6a6b9aa6-683f-4c7c-b06e-9c3018d10fd3",
                        "6aae8997-db46-40ef-a668-78ba5736c756",
                        "6b991684-bcc5-42ea-b160-fe79470d112b",
                        "6c68311c-2745-446f-9c09-df4632392a78",
                        "755fce0d-fa7f-438e-b0b7-aa21f0a74458",
                        "7a4f827a-aced-46e7-987d-5ad7f3016c32",
                        "7e4a176e-5c7c-475a-b9fa-c1a5c5635a27",
                        "7ef53f8d-34c3-4e75-ac28-d3b86ae8fa3a",
                        "80bcd4d1-c1cd-43a7-bc4d-42e274324933",
                        "91b55919-de45-4ecb-8de2-7405faea114e",
                        "9263339a-c88a-4151-baff-0e3a562420ff",
                        "936187f8-f6c2-412c-bdd2-0b4f5d60f8df",
                        "9c01a502-04f3-4adb-9bde-f06253818cb9",
                        "9eee3b9a-cd39-4db4-8b35-151667483add",
                        "9f1396bc-5579-40ca-abcd-17771eaba7b6",
                        "a4589cfe-15e7-4c34-9349-d002d1d2c9df",
                        "a9a79a49-3063-4d7f-a353-34df2a8175a1",
                        "ac237969-3fd5-4303-83b7-a67e02afe976",
                        "adab43f8-fd25-46c6-960d-54bd988c5aaa",
                        "b2159ee7-ace1-4e4d-982e-e6c9eb554a3e",
                        "b49c1e2b-0cd0-4950-a724-00c698e5b49d",
                        "b4fb7dd0-46d6-4db0-825d-0c01fa3e44ba",
                        "b9214a76-78e7-484b-83ae-939f30e58583",
                        "bdba5fe6-dc9e-4e25-b49a-1bff29f3f0c8",
                        "c8ca0fbb-6cf7-4678-bdbc-d52a93446d31",
                        "ca3e323a-57d3-4d3d-835f-c5d9c0c1001a",
                        "ce028c76-6040-4f87-b8e7-d6741ce9d1c4",
                        "cf740e2c-f5bf-4e0c-8375-2948d6dff2c7",
                        "d584301a-e949-47a8-ae15-232ec53aa62b",
                        "d7c2d469-53c2-4216-9af3-22dc6b4ccb1c",
                        "da4534a6-897c-4431-89ef-cd326bfaf9a8",
                        "da9219cb-fa1c-4241-a9eb-108c6699a80f",
                        "db26488d-78be-44b1-a343-e896f43c5d29",
                        "e1662082-8ddd-4df1-90a9-c1f30382b3d0",
                        "e899cb89-58db-44be-99d7-1d318183ffc1",
                        "ead81f2f-a99d-4e65-a0aa-735699199454",
                        "ed748247-965b-4857-a004-7531209fa975",
                        "eef1ec6d-1aed-47a3-831d-b0feb5432851",
                        "f17bdf85-6dc4-48ec-8946-c2613678abfb",
                        "f6ea2106-9ff3-4a2b-a195-6f81979f942d",
                        "f76331c6-7be5-4f61-bbb1-25ea462536e6",
                        "fc603eb6-d237-4584-842c-c80805f31370",
                        "fcb41378-32f7-4aab-8458-fc5a99d74f92"
                    ],
                    "keyword": [
                        "subset",
                        "feature",
                        "selection",
                        "algorithm",
                        "wrapper",
                        "approach",
                        "training",
                        "set",
                        "relevant",
                        "problem"
                    ],
                    "group": [],
                    "_id": "685b313d-8a77-481e-9456-e405a1d29549",
                    "abstract": "Copyright (c) 1997 Elsevier Science B.V. All rights reserved. In the feature subset selection problem, a learning algorithm is faced with the problem of selecting a relevant subset of features upon which to focus its attention, while ignoring the rest. To achieve the best possible performance with a particular learning algorithm on a particular training set, a feature subset selection method should consider how the algorithm and the training set interact. We explore the relation between optimal feature subset selection and relevance. Our wrapper method searches for an optimal feature subset tailored to a particular algorithm and a domain. We study the strengths and weaknesses of the wrapper approach and show a series of improved designs. We compare the wrapper approach to induction without feature subset selection and to Relief, a filter approach to feature subset selection. Significant improvement in accuracy is achieved for some datasets for the two families of induction algorithms used: decision trees and Naive-Bayes.",
                    "title": "Wrappers for feature subset selection",
                    "venue": "Artificial Intelligence",
                    "year": 1997,
                    "__v": 1,
                    "citationCount": 2579,
                    "result": 8.11189574182933
                },
                "69df0789-a06f-4166-9c34-93047de2673d": {
                    "authors": [
                        "Fernando Pereira",
                        "Naftali Tishby",
                        "Lillian Lee"
                    ],
                    "references": [
                        "0c35895c-9f13-4678-80f3-9310652446e0",
                        "25b75899-1e9e-4ef6-bf15-0c941aeddf17",
                        "558dee29-ba49-4949-bbb8-ac8bb76541fd",
                        "5bbfa679-39a5-4510-ba76-3e376fe669bd"
                    ],
                    "keyword": [
                        "clustering",
                        "words",
                        "distribution",
                        "contexts",
                        "represented",
                        "relative",
                        "models",
                        "evaluate",
                        "data",
                        "annealing"
                    ],
                    "group": [],
                    "_id": "69df0789-a06f-4166-9c34-93047de2673d",
                    "abstract": "We describe and evaluate experimentally a method for clustering words according to their distribution in particular syntactic contexts. Words are represented by the relative frequency distributions of contexts in which they appear, and relative entropy between those distributions is used as the similarity measure for clustering. Clusters are represented by average context distributions derived from the given words according to their probabilities of cluster membership. In many cases, the clusters can be thought of as encoding coarse sense distinctions. Deterministic annealing is used to find lowest distortion sets of clusters: as the annealing parameter increases, existing clusters become unstable and subdivide, yielding a hierarchical \"soft\" clustering of the data. Clusters are used as the basis for class models of word coocurrence, and the models evaluated with respect to held-out test data.",
                    "title": "DISTRIBUTIONAL CLUSTERING OF ENGLISH WORDS",
                    "venue": "meeting of the association for computational linguistics",
                    "year": 1993,
                    "__v": 2,
                    "citationCount": 502,
                    "result": 5.754102820124493
                },
                "80f32ec0-5100-407e-9e42-a6710b921397": {
                    "authors": [
                        "H. Stoppiglia",
                        "Gérard Dreyfus",
                        "Rémi Dubois",
                        "Yacine Oussar"
                    ],
                    "references": [
                        "0781e713-d8ca-4f62-89e8-3047b77dd6e6",
                        "35e4e06f-abbe-4d27-aa7b-1400e0e7034d",
                        "3d86fcf7-5465-411c-9caa-bc48785b1c4b",
                        "7233a003-b1fe-4e5e-918a-00d05252a7ff",
                        "75794ffa-9b17-477d-b438-9f75f6764b03",
                        "8f2470ab-a088-4d2b-944c-dcf99f097e77",
                        "9fa61eb1-0984-4492-955a-4f7aedbdc368",
                        "a1574ea3-db42-480a-b759-efe11b890d3e",
                        "a530b2e9-d9af-464a-a9ea-aea3031b5b95",
                        "c5320f25-0999-4d6b-952b-e1d13261906a",
                        "c7996cb4-308f-4e3f-919e-531863439521",
                        "eccf5ead-6924-4b03-84a5-0247d40e42c9"
                    ],
                    "keyword": [
                        "tests",
                        "statistical",
                        "method",
                        "classical",
                        "target",
                        "suitable",
                        "successfully",
                        "selection",
                        "respect",
                        "relaxed"
                    ],
                    "group": [],
                    "_id": "80f32ec0-5100-407e-9e42-a6710b921397",
                    "abstract": "We describe a feature selection method that can be applied directly to models that are linear with respect to their parameters, and indirectly to others. It is independent of the target machine. It is closely related to classical statistical hypothesis tests, but it is more intuitive, hence more suitable for use by engineers who are not statistics experts. Furthermore, some assumptions of classical tests are relaxed. The method has been used successfully in a number of applications that are briefly described.",
                    "title": "Ranking a random feature for variable and feature selection",
                    "venue": "Journal of Machine Learning Research",
                    "year": 2003,
                    "__v": 2,
                    "citationCount": 77,
                    "result": 7.853069515568267
                },
                "8f72a5f3-5ae7-474a-a85c-7142eba278cc": {
                    "authors": [
                        "Inderjit S. Dhillon",
                        "Subramanyam Mallela",
                        "Rahul Kumar"
                    ],
                    "references": [
                        "15c30ca5-6af6-4acf-b8c5-f2c0e18e6ad8",
                        "27d381c3-27e0-4c31-89fa-6639b3e06449",
                        "28903e7b-aa3b-4840-b634-916029ed6c77",
                        "4d1aed47-fdee-4293-bf4f-25adf2667125",
                        "514444a0-7178-4d68-9914-fd018d94fa16",
                        "57a4c414-6c90-4977-abab-ccf563e92c6b",
                        "5ee29884-b069-47f6-86fc-33b46ba77696",
                        "69db5ada-da30-4768-b722-60a54c2e510f",
                        "69df0789-a06f-4166-9c34-93047de2673d",
                        "69f00f82-45eb-4e2b-b239-5526d80f11ea",
                        "93c046f1-d93a-48d6-80ba-982b1f0dd1c9",
                        "96d6d9b9-6d69-4c9a-b3f5-c8083966d55c",
                        "9b4e6c65-da64-4ffe-8f2b-810d7f1efb54",
                        "9f4995af-e704-48ab-8717-6972a3d4455b",
                        "ab68780d-3419-4b9f-be4a-354c01e6ca6c",
                        "ac14afe6-de4d-4056-b2ac-0f6e36f369a2",
                        "bc5c976a-7b0b-4c26-a882-b2839f905d31",
                        "c285808d-767a-4900-bb93-72679186d815",
                        "c3e99ff5-57f9-4012-8b92-48c8d26bf232",
                        "e75d8e62-a86d-4241-953f-1b315005d920",
                        "f006e236-59ad-4647-a59f-4f46dc2c85be",
                        "f0afe524-ef53-4872-9ff5-5f973d9aab75",
                        "f30f8929-2bb1-4e80-97b6-fc969d431aaf",
                        "f4fdd596-0dc6-4c3d-80ae-fda72729d228",
                        "fa81a051-0f8e-4f10-a172-acd5a8923e23"
                    ],
                    "keyword": [
                        "clustering",
                        "text",
                        "feature",
                        "classification",
                        "algorithm",
                        "words",
                        "divisive"
                    ],
                    "group": [],
                    "_id": "8f72a5f3-5ae7-474a-a85c-7142eba278cc",
                    "abstract": "High dimensionality of text can be a deterrent in applying complex learners such as Support Vector Machines to the task of text classification. Feature clustering is a powerful alternative to feature selection for reducing the dimensionality of text data. In this paper we propose a new information-theoretic divisive algorithm for feature/word clustering and apply it to text classification. Existing techniques for such \"distributional clustering\" of words are agglomerative in nature and result in (i) sub-optimal word clusters and (ii) high computational cost. In order to explicitly capture the optimality of word clusters in an information theoretic framework, we first derive a global criterion for feature clustering. We then present a fast, divisive algorithm that monotonically decreases this objective function value. We show that our algorithm minimizes the \"within-cluster Jensen-Shannon divergence\" while simultaneously maximizing the \"between-cluster Jensen-Shannon divergence\". In comparison to the previously proposed agglomerative strategies our divisive algorithm is much faster and achieves comparable or higher classification accuracies. We further show that feature clustering is an effective technique for building smaller class models in hierarchical classification. We present detailed experimental results using Naive Bayes and Support Vector Machines on the 20Newsgroups data set and a 3-level hierarchy of HTML documents collected from the Open Directory project (www.dmoz.org).",
                    "title": "A divisive information theoretic feature clustering algorithm for text classification",
                    "venue": "Journal of Machine Learning Research",
                    "year": 2003,
                    "__v": 2,
                    "citationCount": 199,
                    "result": 5.491198501277897
                },
                "95fdc823-57bc-4e49-8e5b-8fac0c4cfb7f": {
                    "authors": [
                        "Avrim Blum",
                        "Pat Langley"
                    ],
                    "references": [
                        "0cff5d73-afc6-47e3-9906-7f21e4cab620",
                        "0ddbfee1-8cc2-49f6-be79-59276f496884",
                        "17964919-da15-4d08-9f7d-1731a39f1f5e",
                        "1defeff4-5a9b-491d-84b0-30b990d6c121",
                        "245e4043-ccdb-457a-9be1-e120c7a94753",
                        "2fb1b055-2eb3-4016-92e5-41e882d8bf57",
                        "2fff0bf2-3304-4057-be74-8c6235116e21",
                        "32518a4c-fbc3-470f-8024-cb7a65f1fe3f",
                        "3374e2de-0a88-49f4-a5a3-56ceb7dfb823",
                        "340c101a-7317-4ba9-b642-a91eb2e456a7",
                        "36c3e386-cc87-4d6d-a8b6-fd8343b23c8b",
                        "3c35d94a-ddb2-460e-a66d-6010ecd1d331",
                        "4de0dbe7-3582-4125-94be-d0c36ea097fc",
                        "4e80450b-37ed-440c-87cc-d17d27e0d892",
                        "502704c9-2881-41c2-95f6-132d5b8939d5",
                        "505f493b-e09d-444d-9ee2-5e5db6a5b8ac",
                        "5880d47f-8b99-416d-a743-28d6b49f7ba9",
                        "5899eb6c-2e22-4d79-a2be-15fe67911177",
                        "5bb08be4-365a-4e4a-8cc2-92d399ad4bb1",
                        "5cd74e0b-f25c-4aaf-8327-7ec949c7d098",
                        "5da28397-677c-4d92-9ac9-a1f2bf061016",
                        "5fce2337-58b4-433e-9bc5-1ae1c4a5467f",
                        "62549bc2-e0b3-46e8-8d32-390dded105d5",
                        "66e1bf85-a2cc-4c97-847c-e803243f4c66",
                        "685b313d-8a77-481e-9456-e405a1d29549",
                        "6aae8997-db46-40ef-a668-78ba5736c756",
                        "6c2fee35-a596-416a-bd8a-a7966324f71e",
                        "6ca7ce19-1c90-4641-a8b1-6556d4b5d0cc",
                        "6fe13464-786c-4668-8c16-5b0461042e78",
                        "7a10be82-6113-4f60-9e37-f35f2d9423c5",
                        "86dafb65-1d2e-42d9-8982-4d520b6da774",
                        "8735c7ea-f5c6-4310-b250-bc0d1bf5e834",
                        "91b55919-de45-4ecb-8de2-7405faea114e",
                        "996c7ee1-b8de-4dc7-8ec4-6f403f00d3bc",
                        "9eee3b9a-cd39-4db4-8b35-151667483add",
                        "a5f31bf3-3f2c-430a-b68f-0c2521c130c6",
                        "a8f17d49-3bef-4ccb-8e4c-6fc27d99a8db",
                        "ac28de8d-4445-4d2d-a134-7f0e835ebca9",
                        "b2159ee7-ace1-4e4d-982e-e6c9eb554a3e",
                        "b4fb7dd0-46d6-4db0-825d-0c01fa3e44ba",
                        "ba44ae01-0d02-4831-b637-48885d606c37",
                        "c41aed07-fe73-431b-8a8c-700731db9088",
                        "c61bad33-aa9f-4a6e-ab8b-8e7eaa835492",
                        "c9d7e50e-26d6-41f1-aa09-f49fc546af36",
                        "cda06ad5-1cad-4bb7-834f-cd5693ad277a",
                        "ce028c76-6040-4f87-b8e7-d6741ce9d1c4",
                        "d0c44a36-4572-4101-815d-150d53d8a057",
                        "d6f92f3a-fff7-4312-be70-72f61e92913d",
                        "da9219cb-fa1c-4241-a9eb-108c6699a80f",
                        "e0cbdcfd-80c2-4ec2-9c0b-0bcb85843511",
                        "e1d4d2dc-35dc-46d9-9773-a3964a3d831c",
                        "ea2509ad-3494-4bb9-9fdd-6381b491cfa0",
                        "ed748247-965b-4857-a004-7531209fa975",
                        "eef1ec6d-1aed-47a3-831d-b0feb5432851",
                        "f51b782d-815b-4b0d-b9d6-8e676b413969",
                        "f6ea2106-9ff3-4a2b-a195-6f81979f942d",
                        "fc603eb6-d237-4584-842c-c80805f31370"
                    ],
                    "keyword": [
                        "work",
                        "selecting",
                        "relevant",
                        "problem",
                        "methods",
                        "machine",
                        "learning",
                        "topics",
                        "theoretical",
                        "survey"
                    ],
                    "group": [],
                    "_id": "95fdc823-57bc-4e49-8e5b-8fac0c4cfb7f",
                    "abstract": "Copyright (c) 1997 Elsevier Science B.V. All rights reserved. In this survey, we review work in machine learning on methods for handling data sets containing large amounts of irrelevant information. We focus on two key issues: the problem of selecting relevant features, and the problem of selecting relevant examples. We describe the advances that have been made on these topics in both empirical and theoretical work in machine learning, and we present a general framework that we use to compare different methods. We close with some challenges for future work in this area.",
                    "title": "Selection of relevant features and examples in machine learning",
                    "venue": "Artificial Intelligence",
                    "year": 1997,
                    "__v": 1,
                    "citationCount": 948,
                    "result": 9.694484018650101
                },
                "967012b4-dd43-4a03-adbd-46cace52c671": {
                    "authors": [
                        "Isabelle Rivals",
                        "L. Personnaz"
                    ],
                    "references": [
                        "27fc8cc7-699b-470f-a4bc-ac33a6a43492",
                        "3fff50e3-6a11-415b-8c8d-6f2c651f658d",
                        "403f457c-0864-48fb-901c-a6f5a091091f",
                        "4a97f187-c6d3-40d8-8eb9-1855dd056ac3",
                        "69d384ee-3503-4c0e-b01e-8cacbb246c2e",
                        "93fe1faf-3d71-49b5-a61a-bf099986e36b",
                        "9cb473ab-91b5-4044-8b3d-822175bec685",
                        "bac2a905-bef2-45e1-9c24-5969af59e6fb"
                    ],
                    "keyword": [
                        "network",
                        "phases",
                        "tests",
                        "selection",
                        "problem",
                        "neurons",
                        "neural",
                        "model",
                        "hidden",
                        "candidates"
                    ],
                    "group": [],
                    "_id": "967012b4-dd43-4a03-adbd-46cace52c671",
                    "abstract": "This paper presents a model selection procedure which stresses the importance of the classic polynomial models as tools for evaluating the complexity of a given modeling problem, and for removing non-significant input variables. If the complexity of the problem makes a neural network necessary, the selection among neural candidates can be performed in two phases. In an additive phase, the most important one, candidate neural networks with an increasing number of hidden neurons are trained. The addition of hidden neurons is stopped when the effect of the round-off errors becomes significant, so that, for instance, confidence intervals cannot be accurately estimated. This phase leads to a set of approved candidate networks. In a subsequent subtractive phase, a selection among approved networks is performed using statistical Fisher tests. The series of tests starts from a possibly too large unbiased network (the full network), and ends with the smallest unbiased network whose input variables and hidden neurons all have a significant contribution to the regression estimate. This method was successfully tested against the real-world regression problems proposed at the NIPS2000 Unlabeled Data Supervised Learning Competition; two of them are included here as illustrative examples.",
                    "title": "Mlps (mono layer polynomials and multi layer perceptrons) for nonlinear modeling",
                    "venue": "Journal of Machine Learning Research",
                    "year": 2003,
                    "__v": 2,
                    "citationCount": 19,
                    "result": 6.079348550458607
                },
                "9981fac3-aca8-42ce-827d-453ed01176a0": {
                    "authors": [
                        "Amir Globerson",
                        "Naftali Tishby"
                    ],
                    "references": [
                        "01f443e7-ea4c-48a7-8081-745c3fa62769",
                        "15c30ca5-6af6-4acf-b8c5-f2c0e18e6ad8",
                        "179fd669-6c22-4cdb-999b-a18e1062a8d0",
                        "1b258de4-2daa-494c-942a-925608edeb05",
                        "4880e88e-c3c0-48a3-a240-318311335502",
                        "4ff3e7c9-937f-476f-b109-c01fddaaa57f",
                        "514444a0-7178-4d68-9914-fd018d94fa16",
                        "6610284f-1f5a-4460-95d6-b0ad690e171d",
                        "80769a30-7f7f-43d8-8d28-63f978811611",
                        "829f9b1f-d04f-49e8-aab7-2c278dff5427",
                        "8df9247b-f5a5-4580-b3ab-46e08286b93a",
                        "ac14afe6-de4d-4056-b2ac-0f6e36f369a2",
                        "bba5b861-70a6-47d8-96aa-e2722d016253",
                        "d3844efa-a3fd-4d3f-a630-b8bf21ba45bb"
                    ],
                    "keyword": [
                        "information",
                        "feature",
                        "data",
                        "method",
                        "extract",
                        "reduction",
                        "functions"
                    ],
                    "group": [],
                    "_id": "9981fac3-aca8-42ce-827d-453ed01176a0",
                    "abstract": "Dimensionality reduction of empirical co-occurrence data is a fundamental problem in unsupervised learning. It is also a well studied problem in statistics known as the analysis of cross-classified data. One principled approach to this problem is to represent the data in low dimension with minimal loss of (mutual) information contained in the original data. In this paper we introduce an information theoretic nonlinear method for finding such a most informative dimension reduction. In contrast with previously introduced clustering based approaches, here we extract continuous feature functions directly from the co-occurrence matrix. In a sense, we automatically extract functions of the variables that serve as approximate sufficient statistics for a sample of one variable about the other one. Our method is different from dimensionality reduction methods which are based on a specific, sometimes arbitrary, metric or embedding. Another interpretation of our method is as generalized - multi-dimensional - non-linear regression, where rather than fitting one regression function through two dimensional data, we extract d-regression functions whose expectation values capture the information among the variables. It thus presents a new learning paradigm that unifies aspects from both supervised and unsupervised learning. The resulting dimension reduction can be described by two conjugate d-dimensional differential manifolds that are coupled through Maximum Entropy I-projections. The Riemannian metrics of these manifolds are determined by the observed expectation values of our extracted features. Following this geometric interpretation we present an iterative information projection algorithm for finding such features and prove its convergence. Our algorithm is similar to the method of \"association analysis\" in statistics, though the feature extraction context as well as the information theoretic and geometric interpretation are new. The algorithm is illustrated by various synthetic co-occurrence data. It is then demonstrated for text categorization and information retrieval and proves effective in selecting a small set of features, often improving performance over the original feature set.",
                    "title": "Sufficient dimensionality reduction",
                    "venue": "Journal of Machine Learning Research",
                    "year": 2003,
                    "__v": 2,
                    "citationCount": 31,
                    "result": 6.57746864501833
                },
                "9fa61eb1-0984-4492-955a-4f7aedbdc368": {
                    "authors": [
                        "Isabelle Guyon",
                        "Jason Weston",
                        "Stephen D. Barnhill",
                        "Vladimir Vapnik"
                    ],
                    "references": [
                        "07398a91-b607-4d52-ad00-586caceb0ac9",
                        "0781e713-d8ca-4f62-89e8-3047b77dd6e6",
                        "08dcb9a2-1d9e-4094-a9ed-144d4343167e",
                        "1e37aa02-2911-45db-867f-bc2043492c08",
                        "2bd9968a-1e0b-4a11-85a2-19edcf0ee77d",
                        "404775ac-d2d2-4a0b-8195-9458da97105b",
                        "4c3fd4d5-c23d-4a24-84cd-21d45208941e",
                        "50d6ceff-8829-44e3-a8a0-96b69b1805b4",
                        "50dd56db-151d-4d62-8576-65f0ef6f381b",
                        "685b313d-8a77-481e-9456-e405a1d29549",
                        "94898e1d-1e50-41ab-9dcc-2c2e030cddd0",
                        "95fdc823-57bc-4e49-8e5b-8fac0c4cfb7f",
                        "dc92e76f-e502-44a0-898b-a3e12d7fabe9",
                        "e85a4f52-0e1c-447b-98b4-33ec8b9ee6f3",
                        "ec039631-17e8-4794-bc48-2840c96ba044",
                        "f006e236-59ad-4647-a59f-4f46dc2c85be"
                    ],
                    "keyword": [
                        "genes",
                        "methods",
                        "cancerous",
                        "tissue",
                        "selection",
                        "yield",
                        "normal",
                        "microarrays",
                        "baseline"
                    ],
                    "group": [],
                    "_id": "9fa61eb1-0984-4492-955a-4f7aedbdc368",
                    "abstract": "DNA micro-arrays now permit scientists to screen thousands of genes simultaneously and determine whether those genes are active, hyperactive or silent in normal or cancerous tissue. Because these new micro-array devices generate bewildering amounts of raw data, new analytical methods must be developed to sort out whether cancer tissues have distinctive signatures of gene expression over normal tissues or other types of cancer tissues.#R##N##R##N#In this paper, we address the problem of selection of a small subset of genes from broad patterns of gene expression data, recorded on DNA micro-arrays. Using available training examples from cancer and normal patients, we build a classifier suitable for genetic diagnosis, as well as drug discovery. Previous attempts to address this problem select genes with correlation techniques. We propose a new method of gene selection utilizing Support Vector Machine methods based on Recursive Feature Elimination (RFE). We demonstrate experimentally that the genes selected by our techniques yield better classification performance and are biologically relevant to cancer.#R##N##R##N#In contrast with the baseline method, our method eliminates gene redundancy automatically and yields better and more compact gene subsets. In patients with leukemia our method discovered 2 genes that yield zero leave-one-out error, while 64 genes are necessary for the baseline method to get the best result (one leave-one-out error). In the colon cancer database, using only 4 genes our method is 98% accurate, while the baseline method is only 86% accurate.",
                    "title": "Gene Selection for Cancer Classification using Support Vector Machines",
                    "venue": "Machine Learning",
                    "year": 2002,
                    "__v": 2,
                    "citationCount": 2006,
                    "result": 7.124637605090515
                }
            }
        ],
        "_id": "4fb87930-7f6c-4f03-ae22-32445138ec83",
        "abstract": "Variable and feature selection have become the focus of much research in areas of application for which datasets with tens or hundreds of thousands of variables are available. These areas include text processing of internet documents, gene expression array analysis, and combinatorial chemistry. The objective of variable selection is three-fold: improving the prediction performance of the predictors, providing faster and more cost-effective predictors, and providing a better understanding of the underlying process that generated the data. The contributions of this special issue cover a wide range of aspects of such problems: providing a better definition of the objective function, feature construction, feature ranking, multivariate feature selection, efficient search methods, and feature validity assessment methods.",
        "title": "An introduction to variable and feature selection",
        "venue": "Journal of Machine Learning Research",
        "year": 2003,
        "__v": 3,
        "citationCount": 3396
    },
    {
        "authors": [
            "Herbert Bay",
            "Andreas Ess",
            "Tinne Tuytelaars",
            "Luc J. Van Gool"
        ],
        "references": [
            "0b86c956-29dc-4979-b046-f2ec971d8ac8",
            "21c67dad-f0eb-4479-afe7-fdf4a71eef01",
            "2d6c9f60-ea78-44a8-b5f9-6964575dd196",
            "2fa58737-dfec-48e8-a1d5-dc96c510d44f",
            "34758e0a-3def-447b-9c5e-e82a206426b5",
            "36800655-b2ff-4eb7-9070-c6be304c4baa",
            "472cc3e6-8149-41ef-b4c4-fa9e6a60b66f",
            "473cf1a4-9f42-4e6d-b34f-77787f329079",
            "497e3634-6d30-49d5-b10e-a84036394e14",
            "509e1ae2-768b-4417-bebe-d90cf1e0fdae",
            "5f84f09f-7644-447c-89e1-8dc9ee334197",
            "6018a516-8149-4bce-bc33-5449d86e58c2",
            "60285266-7da2-474e-b05a-b380c836f665",
            "62d0a064-3808-4bc0-99bd-f007359ce651",
            "63e5ce6e-5850-45a2-8fbc-6b459352c516",
            "68df2442-9f08-4dc4-80ef-fcf5fede8332",
            "6c38b3b4-7562-493d-a40c-fe70abf039a7",
            "6fe37c18-8dc5-4baa-b6e0-5546353907bb",
            "774c108a-4002-4123-861f-edd3b7ccb0e7",
            "8d8e7d51-3223-4776-bf6a-40306774b8a1",
            "9f5f1500-0df7-4675-8290-b47979bcad38",
            "a3426b1b-ac85-47a0-85f8-c2649ad6c8dc",
            "a5254ae0-1ce1-4390-b9f8-8d5a3dcb1e62",
            "b944f77f-113b-4a02-ae5e-d4a124b8fd5b",
            "c455fb04-4566-4648-ad6f-3cf2245e507c",
            "dda32e99-40c9-4d5f-8982-51e4b1dca885",
            "e649a9fd-f6d9-4aac-b428-29b82c20a484",
            "ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d",
            "f225f439-4389-4312-a503-f8c1b0aa02de",
            "fa02eaed-b311-4f13-9b98-cc0617aafae2",
            "ffa029cf-7240-4723-8339-51fac57f9f28"
        ],
        "keyword": [
            "surf",
            "detector",
            "descriptor",
            "images",
            "robust",
            "leading",
            "description",
            "computed",
            "article"
        ],
        "group": [
            {
                "21c67dad-f0eb-4479-afe7-fdf4a71eef01": {
                    "authors": [
                        "Krystian Mikolajczyk",
                        "Tinne Tuytelaars",
                        "C. Schmid",
                        "Andrew Zisserman",
                        "Jir i Matas",
                        "Frederik Schaffalitzky",
                        "Timor Kadir",
                        "L. Van Gool"
                    ],
                    "references": [
                        "085204a8-62ca-4a3c-8098-4f75d62d1ae4",
                        "0aae4e44-abdb-4948-9462-61f6e52162ba",
                        "0bc5747a-2caf-4996-a55b-6ec5e7273636",
                        "0d287faa-99bb-42df-98a7-24fcd601b9a4",
                        "1dc84769-ff4c-4de6-a1c9-8d3af9299701",
                        "21a8e8fd-0172-4e9a-8474-7024eb0bf979",
                        "2beaa150-6293-4f05-ba04-8e001993e766",
                        "2d6c9f60-ea78-44a8-b5f9-6964575dd196",
                        "2dfac644-329c-46f4-a508-749ccb2d7c85",
                        "34758e0a-3def-447b-9c5e-e82a206426b5",
                        "4e58f9b5-8562-4f17-830f-f055449867fc",
                        "50212652-4999-4f13-82d6-a37eb2862a73",
                        "509e1ae2-768b-4417-bebe-d90cf1e0fdae",
                        "5149d3c0-5ac9-47ba-9fb0-3d2ef757b0e8",
                        "5172d9aa-41cc-40dc-949a-cde3d9f05f31",
                        "5f1992df-975f-49e7-bd88-aee0740317cf",
                        "6018a516-8149-4bce-bc33-5449d86e58c2",
                        "60285266-7da2-474e-b05a-b380c836f665",
                        "6842d04f-2b92-4298-aee8-92babc53f7c4",
                        "6fe37c18-8dc5-4baa-b6e0-5546353907bb",
                        "7283fa2b-1f6a-4138-a3da-4bf69809a1a9",
                        "776d4b4d-d49f-439f-9db5-7c5c3ce68db3",
                        "7ab7b36d-baae-4b21-89fc-69389fcabc44",
                        "8ab773a4-49b4-4755-a070-4ab1b1710690",
                        "8d8e7d51-3223-4776-bf6a-40306774b8a1",
                        "9b480902-c7fd-4d9f-ac9c-3c2fe3aa9c2c",
                        "a0be9da4-c423-4f87-a387-822fe304aa03",
                        "ab7b7857-e48d-4b94-8bfa-bc9ed61d5853",
                        "b25e7392-e9f9-4600-8ab0-a76252f1633a",
                        "b3e60214-b54c-4e8f-9315-a6975c760f4c",
                        "b944f77f-113b-4a02-ae5e-d4a124b8fd5b",
                        "b9e63aeb-aa46-40a0-9b06-01e2270cea70",
                        "c455fb04-4566-4648-ad6f-3cf2245e507c",
                        "cf9198ae-7e03-401f-a52b-94689ba30a36",
                        "ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d",
                        "fc9638b8-572c-4b23-aab2-92e2dd3b79f8",
                        "ffa029cf-7240-4723-8339-51fac57f9f28"
                    ],
                    "keyword": [],
                    "group": [],
                    "_id": "21c67dad-f0eb-4479-afe7-fdf4a71eef01",
                    "abstract": "The paper gives a snapshot of the state of the art in affine covariant region detectors, and compares their performance on a set of test images under varying imaging conditions. Six types of detectors are included: detectors based on affine normalization around Harris (Mikolajczyk and Schmid, 2002; Schaffalitzky and Zisserman, 2002) and Hessian points (Mikolajczyk and Schmid, 2002), a detector of `maximally stable extremal regions', proposed by Matas et al. (2002); an edge-based region detector (Tuytelaars and Van Gool, 1999) and a detector based on intensity extrema (Tuytelaars and Van Gool, 2000), and a detector of `salient regions', proposed by Kadir, Zisserman and Brady (2004). The performance is measured against changes in viewpoint, scale, illumination, defocus and image compression.#R##N##R##N#The objective of this paper is also to establish a reference test set of images and performance software, so that future detectors can be evaluated in the same framework.",
                    "title": "A Comparison of Affine Region Detectors",
                    "venue": "International Journal of Computer Vision",
                    "year": 2005,
                    "__v": 0,
                    "citationCount": 1317,
                    "result": 3.548387096774194
                },
                "509e1ae2-768b-4417-bebe-d90cf1e0fdae": {
                    "authors": [
                        "Krystian Mikolajczyk",
                        "Cordelia Schmid"
                    ],
                    "references": [
                        "1c016f4a-20fb-44b5-84ad-96c10cb8e61b",
                        "1dc84769-ff4c-4de6-a1c9-8d3af9299701",
                        "2beaa150-6293-4f05-ba04-8e001993e766",
                        "2d6c9f60-ea78-44a8-b5f9-6964575dd196",
                        "2fa2e5ba-11d3-4691-91e1-807b8ef7d8a5",
                        "36800655-b2ff-4eb7-9070-c6be304c4baa",
                        "457f15ab-c8e1-461d-b768-e044d88f1917",
                        "5c179e67-426d-402e-bfbf-1893059ab7cf",
                        "5f1992df-975f-49e7-bd88-aee0740317cf",
                        "6018a516-8149-4bce-bc33-5449d86e58c2",
                        "6b98de8f-f857-417c-9667-de061bd05872",
                        "7a9f04e3-2883-4204-8fb3-7db1ce5ddc09",
                        "a0be9da4-c423-4f87-a387-822fe304aa03"
                    ],
                    "keyword": [
                        "scale",
                        "points",
                        "invariant",
                        "results",
                        "method",
                        "local",
                        "interest",
                        "image",
                        "select",
                        "rotation"
                    ],
                    "group": [],
                    "_id": "509e1ae2-768b-4417-bebe-d90cf1e0fdae",
                    "abstract": "This paper presents a new method for detecting scale invariant interest points. The method is based on two recent results on scale space: (1) Interest points can be adapted to scale and give repeatable results (geometrically stable). (2) Local extrema over scale of normalized derivatives indicate the presence of characteristic local structures. Our method first computes a multi-scale representation for the Harris interest point detector. We then select points at which a local measure (the Laplacian) is maximal over scales. This allows a selection of distinctive points for which the characteristic scale is known. These points are invariant to scale, rotation and translation as well as robust to illumination changes and limited changes of viewpoint. For indexing, the image is characterized by a set of scale invariant points; the scale associated with each point allows the computation of a scale invariant descriptor. Our descriptors are, in addition, invariant to image rotation, of affine illumination changes and robust to small perspective deformations. Experimental results for indexing show an excellent performance up to a scale factor of 4 for a database with more than 5000 images.",
                    "title": "Indexing based on scale invariant interest points",
                    "venue": "international conference on computer vision",
                    "year": 2001,
                    "__v": 2,
                    "citationCount": 444,
                    "result": 6.464629688253976
                },
                "5f84f09f-7644-447c-89e1-8dc9ee334197": {
                    "authors": [
                        "Matthew A. Brown",
                        "David G. Lowe"
                    ],
                    "references": [
                        "16d59a75-441a-440d-963d-5a283c15ccff",
                        "27dfa95c-90d4-4d56-b987-0d2721b4b9b0",
                        "2d6c9f60-ea78-44a8-b5f9-6964575dd196",
                        "33711daf-2a44-4f42-8466-c7801f29959b",
                        "509e1ae2-768b-4417-bebe-d90cf1e0fdae",
                        "5149d3c0-5ac9-47ba-9fb0-3d2ef757b0e8",
                        "5dcd5949-faa9-4af3-8c6f-b285dd3b6566",
                        "5f1992df-975f-49e7-bd88-aee0740317cf",
                        "6018a516-8149-4bce-bc33-5449d86e58c2",
                        "8ac30372-c1ac-48bc-8370-cc550fc41d91",
                        "e46bb6ea-7b67-4edf-8cd4-a51ce64cff19"
                    ],
                    "keyword": [
                        "matching",
                        "images",
                        "points'",
                        "interest",
                        "form",
                        "features",
                        "descriptors",
                        "work",
                        "robustly",
                        "reject"
                    ],
                    "group": [],
                    "_id": "5f84f09f-7644-447c-89e1-8dc9ee334197",
                    "abstract": "This paper approaches the problem of ¯nding correspondences between images in which there are large changes in viewpoint, scale and illumi- nation. Recent work has shown that scale-space `interest points' may be found with good repeatability in spite of such changes. Further- more, the high entropy of the surrounding image regions means that local descriptors are highly discriminative for matching. For descrip- tors at interest points to be robustly matched between images, they must be as far as possible invariant to the imaging process. In this work we introduce a family of features which use groups of interest points to form geometrically invariant descriptors of image regions. Feature descriptors are formed by resampling the image rel- ative to canonical frames de¯ned by the points. In addition to robust matching, a key advantage of this approach is that each match implies a hypothesis of the local 2D (projective) transformation. This allows us to immediately reject most of the false matches using a Hough trans- form. We reject remaining outliers using RANSAC and the epipolar constraint. Results show that dense feature matching can be achieved in a few seconds of computation on 1GHz Pentium III machines.",
                    "title": "Invariant Features from Interest Point Groups",
                    "venue": "british machine vision conference",
                    "year": 2002,
                    "__v": 1,
                    "citationCount": 174,
                    "result": 8.697301694610196
                },
                "6018a516-8149-4bce-bc33-5449d86e58c2": {
                    "authors": [
                        "David G. Lowe"
                    ],
                    "references": [
                        "01a0f825-a308-455b-93fc-e62defc0e3b0",
                        "035f8537-61a7-4c4f-b9fe-120f913a38b0",
                        "5dcd5949-faa9-4af3-8c6f-b285dd3b6566",
                        "5ebbd1f5-dfe5-4eec-9883-b8b5efea366c",
                        "5f1992df-975f-49e7-bd88-aee0740317cf",
                        "78dd7c1a-bc00-4993-bd41-8e5da9a7fe5b",
                        "8678514b-e795-4972-b891-c0d31d0d46cf",
                        "899de8c7-9cd9-4dd5-82f1-ad9acb801f8e",
                        "92551b72-99c5-4882-801c-a419e4eb705e",
                        "a00704dc-a2fa-4267-b7a6-427167d99521",
                        "caeecc11-ec92-47d8-b112-c43b88dd4491",
                        "e46bb6ea-7b67-4edf-8cd4-a51ce64cff19",
                        "ee11b7f0-4aeb-4e0f-a808-2126f1590163"
                    ],
                    "keyword": [
                        "image",
                        "object",
                        "features",
                        "scaling",
                        "recognition",
                        "partially",
                        "multiple",
                        "matches",
                        "local",
                        "keys"
                    ],
                    "group": [],
                    "_id": "6018a516-8149-4bce-bc33-5449d86e58c2",
                    "abstract": "An object recognition system has been developed that uses a new class of local image features. The features are invariant to image scaling, translation, and rotation, and partially invariant to illumination changes and affine or 3D projection. These features share similar properties with neurons in inferior temporal cortex that are used for object recognition in primate vision. Features are efficiently detected through a staged filtering approach that identifies stable points in scale space. Image keys are created that allow for local geometric deformations by representing blurred image gradients in multiple orientation planes and at multiple scales. The keys are used as input to a nearest neighbor indexing method that identifies candidate object matches. Final verification of each match is achieved by finding a low residual least squares solution for the unknown model parameters. Experimental results show that robust object recognition can be achieved in cluttered partially occluded images with a computation time of under 2 seconds.",
                    "title": "Object recognition from local scale-invariant features",
                    "venue": "international conference on computer vision",
                    "year": 1999,
                    "__v": 2,
                    "citationCount": 4272,
                    "result": 5.420827701710054
                },
                "60285266-7da2-474e-b05a-b380c836f665": {
                    "authors": [
                        "Jiri Matas",
                        "Ondrej Chum",
                        "M. Urban",
                        "Tomas Pajdla"
                    ],
                    "references": [
                        "1dc84769-ff4c-4de6-a1c9-8d3af9299701",
                        "2beaa150-6293-4f05-ba04-8e001993e766",
                        "509e1ae2-768b-4417-bebe-d90cf1e0fdae",
                        "5f1992df-975f-49e7-bd88-aee0740317cf",
                        "5fadd790-4d5c-4a63-9d0c-39661713cf69",
                        "6018a516-8149-4bce-bc33-5449d86e58c2",
                        "63dbad19-24d8-4646-8e6a-65d85a5c2af3",
                        "7a9f04e3-2883-4204-8fb3-7db1ce5ddc09",
                        "7ab7b36d-baae-4b21-89fc-69389fcabc44",
                        "8f9d2434-c08a-43e5-8152-d41f2784ddc2",
                        "a0be9da4-c423-4f87-a387-822fe304aa03",
                        "beb947f3-b954-4bb9-8379-e33474f07c6d",
                        "ceb9e934-951e-47d6-a256-9ed1bb44b4b6",
                        "e86ce68d-0d77-4f44-a212-518e7d8f394b",
                        "ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d"
                    ],
                    "keyword": [
                        "regions",
                        "images",
                        "extremal",
                        "correspondences",
                        "robust",
                        "problem",
                        "mser",
                        "measure",
                        "invariant",
                        "establishing"
                    ],
                    "group": [],
                    "_id": "60285266-7da2-474e-b05a-b380c836f665",
                    "abstract": "The wide-baseline stereo problem, i.e. the problem of establishing correspondences between a pair of images taken from different viewpoints is studied.#R##N##R##N#A new set of image elements that are put into correspondence, the so called extremal regions, is introduced. Extremal regions possess highly desirable properties: the set is closed under (1) continuous (and thus projective) transformation of image coordinates and (2) monotonic transformation of image intensities. An efficient (near linear complexity) and practically fast detection algorithm (near frame rate) is presented for an affinely invariant stable subset of extremal regions, the maximally stable extremal regions (MSER).#R##N##R##N#A new robust similarity measure for establishing tentative correspondences is proposed. The robustness ensures that invariants from multiple measurement regions (regions obtained by invariant constructions from extremal regions), some that are significantly larger (and hence discriminative) than the MSERs, may be used to establish tentative correspondences.#R##N##R##N#The high utility of MSERs, multiple measurement regions and the robust metric is demonstrated in wide-baseline experiments on image pairs from both indoor and outdoor scenes. Significant change of scale (3.5×), illumination conditions, out-of-plane rotation, occlusion, locally anisotropic scale change and 3D translation of the viewpoint are all present in the test problems. Good estimates of epipolar geometry (average distance from corresponding points to the epipolar line below 0.09 of the inter-pixel distance) are obtained.",
                    "title": "Robust wide-baseline stereo from maximally stable extremal regions",
                    "venue": "Image and Vision Computing",
                    "year": 2004,
                    "__v": 2,
                    "citationCount": 1575,
                    "result": 7.065531563782317
                },
                "62d0a064-3808-4bc0-99bd-f007359ce651": {
                    "authors": [
                        "Patrice Y. Simard",
                        "Léon Bottou",
                        "Patrick Haffner",
                        "Yann LeCun"
                    ],
                    "references": [
                        "3baa1754-b5f7-41cc-a23e-91850cd97f8f"
                    ],
                    "keyword": [
                        "convolution",
                        "signal",
                        "feature",
                        "extraction",
                        "speed",
                        "resulting",
                        "order",
                        "impulse",
                        "functions",
                        "computational"
                    ],
                    "group": [],
                    "_id": "62d0a064-3808-4bc0-99bd-f007359ce651",
                    "abstract": "Signal processing and pattern recognition algorithms make extensive use of convolution. In many cases, computational accuracy is not as important as computational speed. In feature extraction, for instance, the features of interest in a signal are usually quite distorted. This form of noise justifies some level of quantization in order to achieve faster feature extraction. Our approach consists of approximating regions of the signal with low degree polynomials, and then differentiating the resulting signals in order to obtain impulse functions (or derivatives of impulse functions). With this representation, convolution becomes extremely simple and can be implemented quite effectively. The true convolution can be recovered by integrating the result of the convolution. This method yields substantial speed up in feature extraction and is applicable to convolutional neural networks.",
                    "title": "Boxlets: A Fast Convolution Algorithm for Signal Processing and Neural Networks",
                    "venue": "neural information processing systems",
                    "year": 1999,
                    "__v": 2,
                    "citationCount": 40,
                    "result": 5.732603327185371
                },
                "63e5ce6e-5850-45a2-8fbc-6b459352c516": {
                    "authors": [
                        "Philippe C. Cattin",
                        "Herbert Bay",
                        "Luc J. Van Gool",
                        "Gábor Székely"
                    ],
                    "references": [
                        "496a5db0-a93e-4911-a94e-c4a78a4de5d5",
                        "582e7685-2970-497a-8b1b-fbca49a53218",
                        "6421b691-4ea2-4b53-9705-64cd5ca65d7d",
                        "8d8e7d51-3223-4776-bf6a-40306774b8a1",
                        "97d777a0-5d8b-4e90-8e4c-1f5d29355577",
                        "a9c6e620-124a-4a4d-a9ec-b3bb1ca3cbfe",
                        "b944f77f-113b-4a02-ae5e-d4a124b8fd5b",
                        "c130c214-3045-4e3b-8c9e-a43cb72613fc",
                        "c1f56d66-3a1a-483d-9fb9-3b6ce3b1d3b7",
                        "c71540c7-c13a-4b6e-8fa4-25d4d785ba93",
                        "f10c3e7c-bb91-404e-9965-ed690a43f4c7",
                        "f225f439-4389-4312-a503-f8c1b0aa02de",
                        "f699812f-0e8b-403a-8a6f-59479e4ad7cd"
                    ],
                    "keyword": [
                        "retina",
                        "image",
                        "system",
                        "present",
                        "photocoagulation",
                        "laser",
                        "blending",
                        "automatic",
                        "approach"
                    ],
                    "group": [],
                    "_id": "63e5ce6e-5850-45a2-8fbc-6b459352c516",
                    "abstract": "Laser photocoagulation is a proven procedure to treat various pathologies of the retina. Challenges such as motion compensation, correct energy dosage, and avoiding incidental damage are responsible for the still low success rate. They can be overcome with improved instrumentation, such as a fully automatic laser photocoagulation system.#R##N##R##N#In this paper, we present a core image processing element of such a system, namely a novel approach for retina mosaicing. Our method relies on recent developments in region detection and feature description to automatically fuse retina images. In contrast to the state-of-the-art the proposed approach works even for retina images with no discernable vascularity. Moreover, an efficient scheme to determine the blending masks of arbitrarily overlapping images for multi-band blending is presented.",
                    "title": "Retina mosaicing using local features",
                    "venue": "medical image computing and computer-assisted intervention",
                    "year": 2006,
                    "__v": 2,
                    "citationCount": 25,
                    "result": 6.1983576922760975
                },
                "68df2442-9f08-4dc4-80ef-fcf5fede8332": {
                    "authors": [
                        "Maarten Vergauwen",
                        "Luc J. Van Gool"
                    ],
                    "references": [
                        "11e33722-01d2-4382-8691-a5572081eaa6",
                        "1bfed65b-0df9-469c-9827-85ccd31061a2",
                        "200578c4-1ee6-4a41-8d31-f870696c667e",
                        "48edda1a-6c7a-439c-be80-0923bf1326c6",
                        "5fda5f10-7c36-497e-b8b9-31e3a13daf6a",
                        "79b1d107-508c-494c-97f7-f649e258cbfd",
                        "8c18cc4d-cec9-4ab9-aa5f-077eb359fc40",
                        "b72ef385-f390-497c-812d-85d77963045c",
                        "b944f77f-113b-4a02-ae5e-d4a124b8fd5b",
                        "c3536067-1afd-4882-9e0d-5327930262b0",
                        "e301ac2e-eecd-438e-b74c-90b0f0632f3c",
                        "e587d844-dc82-4625-bb44-4b9d8d2e8927",
                        "eec6ee6f-6117-4722-80d9-7dcb67a992a1"
                    ],
                    "keyword": [
                        "reconstruction",
                        "3d",
                        "field",
                        "year",
                        "user",
                        "service",
                        "server",
                        "running",
                        "images",
                        "heritage"
                    ],
                    "group": [],
                    "_id": "68df2442-9f08-4dc4-80ef-fcf5fede8332",
                    "abstract": "The use of 3D information in the field of cultural heritage is increasing year by year. From this field comes a large demand for cheaper and more flexible ways of 3D reconstruction. This paper describes a web-based 3D reconstruction service, developed to relieve those needs of the cultural heritage field. This service consists of a pipeline that starts with the user uploading images of an object or scene(s) he wants to reconstruct in 3D. The automatic reconstruction process, running on a server connected to a cluster of computers, computes the camera calibration, as well as dense depth (or range-) maps for the images. This result can be downloaded from an ftp server and visualized with a specific tool running on the user’s PC.",
                    "title": "Web-based 3D Reconstruction Service",
                    "venue": "machine vision applications",
                    "year": 2006,
                    "__v": 2,
                    "citationCount": 85,
                    "result": 4.146439792176313
                },
                "6c38b3b4-7562-493d-a40c-fe70abf039a7": {
                    "authors": [
                        "David Nister",
                        "Henrik Stewenius"
                    ],
                    "references": [
                        "0aae4e44-abdb-4948-9462-61f6e52162ba",
                        "0d287faa-99bb-42df-98a7-24fcd601b9a4",
                        "1f556c88-b553-4c75-b243-92d8200f8149",
                        "21c67dad-f0eb-4479-afe7-fdf4a71eef01",
                        "33711daf-2a44-4f42-8466-c7801f29959b",
                        "60285266-7da2-474e-b05a-b380c836f665",
                        "7729fafc-7053-4dd8-ac08-78232e0f2a74",
                        "85336978-6cf2-4e87-b949-d13e7a22cf9e",
                        "8d8e7d51-3223-4776-bf6a-40306774b8a1",
                        "adf6fdf9-01a0-4051-9d99-965f4a5baa4d",
                        "b944f77f-113b-4a02-ae5e-d4a124b8fd5b",
                        "b9e63aeb-aa46-40a0-9b06-01e2270cea70",
                        "dda32e99-40c9-4d5f-8982-51e4b1dca885",
                        "e7fe111a-3c9f-454c-9255-f8283407df2b",
                        "ffa029cf-7240-4723-8339-51fac57f9f28"
                    ],
                    "keyword": [
                        "vocabulary",
                        "tree",
                        "scheme",
                        "quantized",
                        "quality",
                        "efficiently",
                        "show",
                        "retrieval",
                        "regions",
                        "recognition"
                    ],
                    "group": [],
                    "_id": "6c38b3b4-7562-493d-a40c-fe70abf039a7",
                    "abstract": "A recognition scheme that scales efficiently to a large number of objects is presented. The efficiency and quality is exhibited in a live demonstration that recognizes CD-covers from a database of 40000 images of popular music CDs. The scheme builds upon popular techniques of indexing descriptors extracted from local regions, and is robust to background clutter and occlusion. The local region descriptors are hierarchically quantized in a vocabulary tree. The vocabulary tree allows a larger and more discriminatory vocabulary to be used efficiently, which we show experimentally leads to a dramatic improvement in retrieval quality. The most significant property of the scheme is that the tree directly defines the quantization. The quantization and the indexing are therefore fully integrated, essentially being one and the same. The recognition quality is evaluated through retrieval on a database with ground truth, showing the power of the vocabulary tree approach, going as high as 1 million images.",
                    "title": "Scalable Recognition with a Vocabulary Tree",
                    "venue": "computer vision and pattern recognition",
                    "year": 2006,
                    "__v": 2,
                    "citationCount": 1886,
                    "result": 4.272552031565315
                },
                "6fe37c18-8dc5-4baa-b6e0-5546353907bb": {
                    "authors": [
                        "Krystian Mikolajczyk",
                        "Cordelia Schmid"
                    ],
                    "references": [
                        "00a4e16f-6b65-4ad2-bedc-b19d9cbc2cfe",
                        "09346dc3-f4d0-43a4-8f0b-27e02bcd336e",
                        "0aae4e44-abdb-4948-9462-61f6e52162ba",
                        "0d287faa-99bb-42df-98a7-24fcd601b9a4",
                        "19195bc1-7aff-4dd3-91cc-25402c343a19",
                        "21a8e8fd-0172-4e9a-8474-7024eb0bf979",
                        "21c67dad-f0eb-4479-afe7-fdf4a71eef01",
                        "2d6c9f60-ea78-44a8-b5f9-6964575dd196",
                        "33711daf-2a44-4f42-8466-c7801f29959b",
                        "34758e0a-3def-447b-9c5e-e82a206426b5",
                        "36800655-b2ff-4eb7-9070-c6be304c4baa",
                        "509e1ae2-768b-4417-bebe-d90cf1e0fdae",
                        "5149d3c0-5ac9-47ba-9fb0-3d2ef757b0e8",
                        "5f1992df-975f-49e7-bd88-aee0740317cf",
                        "6018a516-8149-4bce-bc33-5449d86e58c2",
                        "60285266-7da2-474e-b05a-b380c836f665",
                        "608a581a-0e03-435a-9067-c0e0982567af",
                        "683dd26d-5c59-4feb-9fbd-2bcf3cc1942f",
                        "853b29ea-c6d1-497e-bad3-b608d370e7e2",
                        "a5254ae0-1ce1-4390-b9f8-8d5a3dcb1e62",
                        "b4685927-0ad9-466b-b2c6-2e1764475726",
                        "b592576f-ff29-4a68-9b2f-8a8ad02e9c70",
                        "b944f77f-113b-4a02-ae5e-d4a124b8fd5b",
                        "c455fb04-4566-4648-ad6f-3cf2245e507c",
                        "e2204e92-e6dc-4884-9bbc-200029491fc7",
                        "e927dff1-6ed4-45fd-8852-eb804e11e665",
                        "ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d",
                        "fc9638b8-572c-4b23-aab2-92e2dd3b79f8"
                    ],
                    "keyword": [
                        "descriptors",
                        "point",
                        "performance",
                        "interest",
                        "filters",
                        "detector",
                        "van",
                        "steerable",
                        "sift",
                        "rate"
                    ],
                    "group": [],
                    "_id": "6fe37c18-8dc5-4baa-b6e0-5546353907bb",
                    "abstract": "In this paper we compare the performance of interest point descriptors. Many different descriptors have been proposed in the literature. However, it is unclear which descriptors are more appropriate and how their performance depends on the interest point detector. The descriptors should be distinctive and at the same time robust to changes in viewing conditions as well as to errors of the point detector. Our evaluation uses as criterion detection rate with respect to false positive rate and is carried out for different image transformations. We compare SIFT descriptors (Lowe, 1999), steerable filters (Freeman and Adelson, 1991), differential invariants (Koenderink ad van Doorn, 1987), complex filters (Schaffalitzky and Zisserman, 2002), moment invariants (Van Gool et al., 1996) and cross-correlation for different types of interest points. In this evaluation, we observe that the ranking of the descriptors does not depend on the point detector and that SIFT descriptors perform best. Steerable filters come second ; they can be considered a good choice given the low dimensionality.",
                    "title": "A performance evaluation of local descriptors",
                    "venue": "computer vision and pattern recognition",
                    "year": 2003,
                    "__v": 2,
                    "citationCount": 683,
                    "result": 10.457084178845893
                },
                "774c108a-4002-4123-861f-edd3b7ccb0e7": {
                    "authors": [
                        "Lmj Luc Florack",
                        "ter Bm Bart Haar Romeny",
                        "Jan J. Koenderink",
                        "Max A. Viergever"
                    ],
                    "references": [
                        "14582bca-c63d-4f41-8e8e-dedffb742728",
                        "2fa2e5ba-11d3-4691-91e1-807b8ef7d8a5",
                        "497e3634-6d30-49d5-b10e-a84036394e14",
                        "5c9b1df4-f013-469d-8074-0b636194e7d9",
                        "9fc5a75c-5e2c-4458-afcb-6edbe4c0e5ae",
                        "d6547624-0f9f-45ae-a9d0-6216206d94c4",
                        "e8abc562-f052-4e80-9b06-fda552286c29"
                    ],
                    "keyword": [
                        "grayvalue",
                        "invariants",
                        "image",
                        "transformations",
                        "structure",
                        "set",
                        "propose",
                        "order",
                        "mapped",
                        "invertible"
                    ],
                    "group": [],
                    "_id": "774c108a-4002-4123-861f-edd3b7ccb0e7",
                    "abstract": "We consider the group of invertible image gray-value transformations and propose a generating equation for a complete set of differential gray-value invariants up to any order. Such invariants describe the image's geometrical structure independent of how its gray-values are mapped (contrast or brightness adjustments).",
                    "title": "General intensity transformations and differential invariants",
                    "venue": "Journal of Mathematical Imaging and Vision",
                    "year": 1994,
                    "__v": 2,
                    "citationCount": 70,
                    "result": 5.1577886230466135
                },
                "8d8e7d51-3223-4776-bf6a-40306774b8a1": {
                    "authors": [
                        "Krystian Mikolajczyk",
                        "Cordelia Schmid"
                    ],
                    "references": [
                        "00a4e16f-6b65-4ad2-bedc-b19d9cbc2cfe",
                        "09346dc3-f4d0-43a4-8f0b-27e02bcd336e",
                        "0aae4e44-abdb-4948-9462-61f6e52162ba",
                        "0d287faa-99bb-42df-98a7-24fcd601b9a4",
                        "19195bc1-7aff-4dd3-91cc-25402c343a19",
                        "21a8e8fd-0172-4e9a-8474-7024eb0bf979",
                        "21c67dad-f0eb-4479-afe7-fdf4a71eef01",
                        "2d6c9f60-ea78-44a8-b5f9-6964575dd196",
                        "33711daf-2a44-4f42-8466-c7801f29959b",
                        "34758e0a-3def-447b-9c5e-e82a206426b5",
                        "36800655-b2ff-4eb7-9070-c6be304c4baa",
                        "37031566-2033-44cb-a87e-91a9bb37996f",
                        "3b744649-d7a0-46c3-b242-9e0060d8ecfa",
                        "4e58f9b5-8562-4f17-830f-f055449867fc",
                        "509e1ae2-768b-4417-bebe-d90cf1e0fdae",
                        "5149d3c0-5ac9-47ba-9fb0-3d2ef757b0e8",
                        "568f1994-f91e-413e-92fd-87dbbb9642a8",
                        "5f1992df-975f-49e7-bd88-aee0740317cf",
                        "6018a516-8149-4bce-bc33-5449d86e58c2",
                        "60285266-7da2-474e-b05a-b380c836f665",
                        "608a581a-0e03-435a-9067-c0e0982567af",
                        "683dd26d-5c59-4feb-9fbd-2bcf3cc1942f",
                        "6fe37c18-8dc5-4baa-b6e0-5546353907bb",
                        "72c27d5a-23c5-4d1b-a000-280b87b368ee",
                        "7ab7b36d-baae-4b21-89fc-69389fcabc44",
                        "853b29ea-c6d1-497e-bad3-b608d370e7e2",
                        "a5254ae0-1ce1-4390-b9f8-8d5a3dcb1e62",
                        "a8c6ead3-d61a-4f6a-a702-08743f19eec9",
                        "b4685927-0ad9-466b-b2c6-2e1764475726",
                        "b592576f-ff29-4a68-9b2f-8a8ad02e9c70",
                        "b944f77f-113b-4a02-ae5e-d4a124b8fd5b",
                        "c455fb04-4566-4648-ad6f-3cf2245e507c",
                        "e2204e92-e6dc-4884-9bbc-200029491fc7",
                        "e927dff1-6ed4-45fd-8852-eb804e11e665",
                        "ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d",
                        "fc9638b8-572c-4b23-aab2-92e2dd3b79f8",
                        "ffa029cf-7240-4723-8339-51fac57f9f28"
                    ],
                    "keyword": [
                        "descriptors",
                        "regions",
                        "performance",
                        "interest",
                        "detector",
                        "filters",
                        "al"
                    ],
                    "group": [],
                    "_id": "8d8e7d51-3223-4776-bf6a-40306774b8a1",
                    "abstract": "In this paper, we compare the performance of descriptors computed for local interest regions, as, for example, extracted by the Harris-Affine detector [Mikolajczyk, K and Schmid, C, 2004]. Many different descriptors have been proposed in the literature. It is unclear which descriptors are more appropriate and how their performance depends on the interest region detector. The descriptors should be distinctive and at the same time robust to changes in viewing conditions as well as to errors of the detector. Our evaluation uses as criterion recall with respect to precision and is carried out for different image transformations. We compare shape context [Belongie, S, et al., April 2002], steerable filters [Freeman, W and Adelson, E, Setp. 1991], PCA-SIFT [Ke, Y and Sukthankar, R, 2004], differential invariants [Koenderink, J and van Doorn, A, 1987], spin images [Lazebnik, S, et al., 2003], SIFT [Lowe, D. G., 1999], complex filters [Schaffalitzky, F and Zisserman, A, 2002], moment invariants [Van Gool, L, et al., 1996], and cross-correlation for different types of interest regions. We also propose an extension of the SIFT descriptor and show that it outperforms the original method. Furthermore, we observe that the ranking of the descriptors is mostly independent of the interest region detector and that the SIFT-based descriptors perform best. Moments and steerable filters show the best performance among the low dimensional descriptors.",
                    "title": "A performance evaluation of local descriptors",
                    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "year": 2005,
                    "__v": 2,
                    "citationCount": 2762,
                    "result": 10.046018362941364
                },
                "9f5f1500-0df7-4675-8290-b47979bcad38": {
                    "authors": [
                        "Frédéric Jurie",
                        "Cordelia Schmid"
                    ],
                    "references": [
                        "05e9a0b4-d794-424b-86fc-2a72fed3f7ad",
                        "27dfa95c-90d4-4d56-b987-0d2721b4b9b0",
                        "2958fc5c-15e8-45e7-8da8-d2e0fa46f0c7",
                        "37031566-2033-44cb-a87e-91a9bb37996f",
                        "473cf1a4-9f42-4e6d-b34f-77787f329079",
                        "509e1ae2-768b-4417-bebe-d90cf1e0fdae",
                        "5ae4ef7f-b13a-4e78-8afd-1e2d22259b87",
                        "6018a516-8149-4bce-bc33-5449d86e58c2",
                        "7455b947-c9e1-47da-be49-00ed922e9888",
                        "87c6d06a-66ed-4867-b789-2d114525063c",
                        "97df7134-9cbf-43ea-9809-472115004999",
                        "b3e60214-b54c-4e8f-9315-a6975c760f4c",
                        "b592576f-ff29-4a68-9b2f-8a8ad02e9c70",
                        "bdf72301-5372-485f-840b-ceb885b95b8b",
                        "c455fb04-4566-4648-ad6f-3cf2245e507c",
                        "c8f80ea6-4602-458c-9a70-daf1c646c89b",
                        "cd90e104-f991-4cce-92d8-70c719e84ebe"
                    ],
                    "keyword": [
                        "local",
                        "image",
                        "detecting",
                        "regions",
                        "circle",
                        "term",
                        "support",
                        "shape",
                        "scale",
                        "position"
                    ],
                    "group": [],
                    "_id": "9f5f1500-0df7-4675-8290-b47979bcad38",
                    "abstract": "We introduce a new class of distinguished regions based on detecting the most salient convex local arrangements of contours in the image. The regions are used in a similar way to the local interest points extracted from gray-level images, but they capture shape rather than texture. Local convexity is characterized by measuring the extent to which the detected image contours support circle or arc-like local structures at each position and scale in the image. Our saliency measure combines two cost functions defined on the tangential edges near the circle: a tangential-gradient energy term, and an entropy term that ensures local support from a wide range of angular positions around the circle. The detected regions are invariant to scale changes and rotations, and robust against clutter, occlusions and spurious edge detections. Experimental results show very good performance for both shape matching and recognition of object categories.",
                    "title": "Scale-invariant shape features for recognition of object categories",
                    "venue": "computer vision and pattern recognition",
                    "year": 2004,
                    "__v": 2,
                    "citationCount": 106,
                    "result": 6.822665727694192
                },
                "a3426b1b-ac85-47a0-85f8-c2649ad6c8dc": {
                    "authors": [
                        "Alexander Neubeck",
                        "L. Van Gool"
                    ],
                    "references": [
                        "0aae4e44-abdb-4948-9462-61f6e52162ba",
                        "42b341f5-d865-4788-9df3-bd0c975d963e",
                        "b944f77f-113b-4a02-ae5e-d4a124b8fd5b",
                        "ffa029cf-7240-4723-8339-51fac57f9f28"
                    ],
                    "keyword": [
                        "algorithms",
                        "vision",
                        "preprocessing",
                        "nms",
                        "computer",
                        "work",
                        "time",
                        "task",
                        "suppression",
                        "straightforward"
                    ],
                    "group": [],
                    "_id": "a3426b1b-ac85-47a0-85f8-c2649ad6c8dc",
                    "abstract": "In this work we scrutinize a low level computer vision task - non-maximum suppression (NMS) - which is a crucial preprocessing step in many computer vision applications. Especially in real time scenarios, efficient algorithms for such preprocessing algorithms, which operate on the full image resolution, are important. In the case of NMS, it seems that merely the straightforward implementation or slight improvements are known. We show that these are far from being optimal, and derive several algorithms ranging from easy-to-implement to highly-efficient.",
                    "title": "Efficient Non-Maximum Suppression",
                    "venue": "international conference on pattern recognition",
                    "year": 2006,
                    "__v": 2,
                    "citationCount": 68,
                    "result": 5.080612325803902
                },
                "a5254ae0-1ce1-4390-b9f8-8d5a3dcb1e62": {
                    "authors": [
                        "Yan Ke",
                        "Rahul Sukthankar"
                    ],
                    "references": [
                        "28005624-c0e8-4c62-b585-6e362c3dc8d5",
                        "34758e0a-3def-447b-9c5e-e82a206426b5",
                        "36800655-b2ff-4eb7-9070-c6be304c4baa",
                        "509e1ae2-768b-4417-bebe-d90cf1e0fdae",
                        "6018a516-8149-4bce-bc33-5449d86e58c2",
                        "608a581a-0e03-435a-9067-c0e0982567af",
                        "6fe37c18-8dc5-4baa-b6e0-5546353907bb",
                        "7ab7b36d-baae-4b21-89fc-69389fcabc44",
                        "aec2ffaf-e691-4884-9304-7d7e14733b2e",
                        "b944f77f-113b-4a02-ae5e-d4a124b8fd5b",
                        "c455fb04-4566-4648-ad6f-3cf2245e507c",
                        "d7b1fba1-b5f8-4377-88a8-d2fc69f723b7"
                    ],
                    "keyword": [
                        "image",
                        "sift",
                        "descriptor",
                        "local",
                        "results",
                        "representation",
                        "gradient",
                        "feature",
                        "deformations",
                        "component"
                    ],
                    "group": [],
                    "_id": "a5254ae0-1ce1-4390-b9f8-8d5a3dcb1e62",
                    "abstract": "Stable local feature detection and representation is a fundamental component of many image registration and object recognition algorithms. Mikolajczyk and Schmid (June 2003) recently evaluated a variety of approaches and identified the SIFT [D. G. Lowe, 1999] algorithm as being the most resistant to common image deformations. This paper examines (and improves upon) the local image descriptor used by SIFT. Like SIFT, our descriptors encode the salient aspects of the image gradient in the feature point's neighborhood; however, instead of using SIFT's smoothed weighted histograms, we apply principal components analysis (PCA) to the normalized gradient patch. Our experiments demonstrate that the PCA-based local descriptors are more distinctive, more robust to image deformations, and more compact than the standard SIFT representation. We also present results showing that using these descriptors in an image retrieval application results in increased accuracy and faster matching.",
                    "title": "PCA-SIFT: a more distinctive representation for local image descriptors",
                    "venue": "computer vision and pattern recognition",
                    "year": 2004,
                    "__v": 2,
                    "citationCount": 1138,
                    "result": 8.97264980707386
                },
                "b944f77f-113b-4a02-ae5e-d4a124b8fd5b": {
                    "authors": [
                        "David G. Lowe"
                    ],
                    "references": [
                        "00a4e16f-6b65-4ad2-bedc-b19d9cbc2cfe",
                        "01a0f825-a308-455b-93fc-e62defc0e3b0",
                        "035f8537-61a7-4c4f-b9fe-120f913a38b0",
                        "03a42efa-a19c-4b19-a881-9c7ff63865ce",
                        "05c3e696-6add-4b0d-b867-e6f1c98deb9b",
                        "2fa2e5ba-11d3-4691-91e1-807b8ef7d8a5",
                        "32d9eaee-c68f-4479-aa67-837d3cc91a05",
                        "34758e0a-3def-447b-9c5e-e82a206426b5",
                        "5437c0a0-8f20-49c3-86e5-9d860f3e4f04",
                        "5dcd5949-faa9-4af3-8c6f-b285dd3b6566",
                        "5f1992df-975f-49e7-bd88-aee0740317cf",
                        "5f84f09f-7644-447c-89e1-8dc9ee334197",
                        "6018a516-8149-4bce-bc33-5449d86e58c2",
                        "60285266-7da2-474e-b05a-b380c836f665",
                        "768eea6d-8e82-4bbf-8bdd-1f2338ded29f",
                        "791e9257-d7a0-41fe-b471-bde48f3c4a04",
                        "7ab7b36d-baae-4b21-89fc-69389fcabc44",
                        "7b3f5f5b-a965-4656-9a6f-2f9740625176",
                        "899de8c7-9cd9-4dd5-82f1-ad9acb801f8e",
                        "a00704dc-a2fa-4267-b7a6-427167d99521",
                        "a0fa7ae2-61e5-48a9-be10-86440416129f",
                        "a748e0f4-ee6f-41ad-a2a5-1a5a6751086d",
                        "b3e60214-b54c-4e8f-9315-a6975c760f4c",
                        "b4685927-0ad9-466b-b2c6-2e1764475726",
                        "c455fb04-4566-4648-ad6f-3cf2245e507c",
                        "ccdefe89-9b16-4c22-8bb8-bd314ccad6e1",
                        "d20995f6-529c-41c6-b75e-a169b005fb5c",
                        "d9b9f667-9d8a-4723-a6c4-c19b941acd46",
                        "df9fe96c-752e-49be-a8c4-8b098ab51e22",
                        "ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d",
                        "f6272ea9-0360-47ed-90a5-651ea958143f"
                    ],
                    "keyword": [
                        "features",
                        "object",
                        "matching",
                        "recognition",
                        "perform",
                        "images",
                        "single",
                        "robust",
                        "paper",
                        "invariant"
                    ],
                    "group": [
                        null
                    ],
                    "_id": "b944f77f-113b-4a02-ae5e-d4a124b8fd5b",
                    "abstract": "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance.",
                    "title": "Distinctive Image Features from Scale-Invariant Keypoints",
                    "venue": "International Journal of Computer Vision",
                    "year": 2004,
                    "__v": 3,
                    "citationCount": 16229,
                    "result": 8.393967544157297
                },
                "c455fb04-4566-4648-ad6f-3cf2245e507c": {
                    "authors": [
                        "Rob Fergus",
                        "Pietro Perona",
                        "Andrew Zisserman"
                    ],
                    "references": [
                        "2d6c9f60-ea78-44a8-b5f9-6964575dd196",
                        "473cf1a4-9f42-4e6d-b34f-77787f329079",
                        "509e1ae2-768b-4417-bebe-d90cf1e0fdae",
                        "613841ae-c925-4aee-9c2e-8675213e4bbf",
                        "bf664a72-1007-43e6-8dff-f1b0de9b5740",
                        "c591c440-b19b-4d7b-b067-cd8c366b7d6d",
                        "c7f93552-c1ef-4ae4-b1f5-2317e1c9d904",
                        "ccdefe89-9b16-4c22-8bb8-bd314ccad6e1",
                        "d5e5a24d-f80e-4f1a-b48b-22403b653276",
                        "d6e37fb1-5f7e-448e-847b-7d1f1271c574",
                        "d7b1fba1-b5f8-4377-88a8-d2fc69f723b7",
                        "df152036-9859-492f-998f-1ff9769b6d95",
                        "e649a9fd-f6d9-4aac-b428-29b82c20a484",
                        "ef35a024-f5f3-4a7b-b6f6-61d9167385e6",
                        "f111ff97-89a3-4df6-8f02-962d7b4fe985"
                    ],
                    "keyword": [
                        "object",
                        "models",
                        "scale",
                        "flexible",
                        "manner",
                        "learn",
                        "image",
                        "class"
                    ],
                    "group": [],
                    "_id": "c455fb04-4566-4648-ad6f-3cf2245e507c",
                    "abstract": "We present a method to learn and recognize object class models from unlabeled and unsegmented cluttered scenes in a scale invariant manner. Objects are modeled as flexible constellations of parts. A probabilistic representation is used for all aspects of the object: shape, appearance, occlusion and relative scale. An entropy-based feature detector is used to select regions and their scale within the image. In learning the parameters of the scale-invariant object model are estimated. This is done using expectation-maximization in a maximum-likelihood setting. In recognition, this model is used in a Bayesian manner to classify images. The flexible nature of the model is demonstrated by excellent results over a range of datasets including geometrically constrained classes (e.g. faces, cars) and flexible objects (such as animals).",
                    "title": "Object class recognition by unsupervised scale-invariant learning",
                    "venue": "computer vision and pattern recognition",
                    "year": 2003,
                    "__v": 2,
                    "citationCount": 1184,
                    "result": 5.35979755012013
                },
                "dda32e99-40c9-4d5f-8982-51e4b1dca885": {
                    "authors": [
                        "Mayur Datar",
                        "Nicole Immorlica",
                        "Piotr Indyk",
                        "Vahab S. Mirrokni"
                    ],
                    "references": [
                        "0f094852-0668-4dfe-92cc-ae5659ffc1d9",
                        "15ea05e5-6f54-4572-973b-a7ec37f5bd26",
                        "1cd8a7cf-6612-4ad0-991b-f5850aa76755",
                        "2cde7156-9b73-4ffd-804b-2089b7b98d51",
                        "2e0c0709-138c-461c-af4f-64037b7feee4",
                        "7a5b23b4-b171-4c19-8925-167583868f93",
                        "833da8cb-e068-44eb-955c-48b52adabfae",
                        "89022b09-5732-4493-9e2d-2046059dd2e5",
                        "a03d2ca2-f919-42b5-9de0-1d6d7d22d396",
                        "a54c454c-87ab-4b2b-a004-b3061edc468c",
                        "aae946fb-32ef-4c5c-9845-0c08e44ae132",
                        "adf6fdf9-01a0-4051-9d99-965f4a5baa4d",
                        "dfb5be8d-536e-49f5-9b3e-4be49eb371ed",
                        "e4fdce29-a285-48c5-a1bb-589194276c70",
                        "e9683341-c49f-4f44-8df2-970b9c17b501",
                        "f51965b2-5fc0-4269-a02d-c62f3b79a77a",
                        "f6272ea9-0360-47ed-90a5-651ea958143f"
                    ],
                    "keyword": [
                        "time",
                        "scheme",
                        "data",
                        "norm",
                        "earlier",
                        "case",
                        "bounded",
                        "approximate",
                        "algorithm"
                    ],
                    "group": [],
                    "_id": "dda32e99-40c9-4d5f-8982-51e4b1dca885",
                    "abstract": "We present a novel Locality-Sensitive Hashing scheme for the Approximate Nearest Neighbor Problem under  l  p  norm, based on  p -stable distributions.Our scheme improves the running time of the earlier algorithm for the case of the  l  p  norm. It also yields the first known provably efficient approximate NN algorithm for the case  p  O (log  n ) time for data satisfying certain \"bounded growth\" condition.Unlike earlier schemes, our LSH scheme works directly on points in the Euclidean space without embeddings. Consequently, the resulting query time bound is free of large factors and is simple and easy to implement. Our experiments (on synthetic data sets) show that the our data structure is up to 40 times faster than  kd -tree.",
                    "title": "Locality-sensitive hashing scheme based on p-stable distributions",
                    "venue": "symposium on computational geometry",
                    "year": 2004,
                    "__v": 2,
                    "citationCount": 975,
                    "result": 3.2833171730230553
                },
                "e649a9fd-f6d9-4aac-b428-29b82c20a484": {
                    "authors": [
                        "Paul A. Viola",
                        "Michael J. Jones"
                    ],
                    "references": [
                        "13cd743f-beb9-43a1-8e08-2ef08f0d8b3f",
                        "17f811d8-8607-4270-bbec-1cc7883edd68",
                        "310cbba4-d88d-4bf4-a4f2-738f91b5f8c8",
                        "36800655-b2ff-4eb7-9070-c6be304c4baa",
                        "43530fe4-10a9-4ddf-b61d-8844f0ff3f04",
                        "5ffac6f9-2456-42cf-830c-9049ce37c899",
                        "6d121e97-e351-4cf9-8c44-d7ab3ce9d9fe",
                        "9fa55b0f-eaa6-4c59-b6e5-77e5f1a406f0",
                        "c7f93552-c1ef-4ae4-b1f5-2317e1c9d904",
                        "d5e5a24d-f80e-4f1a-b48b-22403b653276",
                        "d6e37fb1-5f7e-448e-847b-7d1f1271c574",
                        "db26488d-78be-44b1-a343-e896f43c5d29",
                        "f1bd37c4-d033-4cd1-af44-4df9f11c71e4",
                        "f4642ffc-3571-4d02-8b94-142f2448023a"
                    ],
                    "keyword": [
                        "images",
                        "detection",
                        "regions",
                        "object",
                        "yields",
                        "visual",
                        "system",
                        "rates",
                        "quickly",
                        "previous"
                    ],
                    "group": [
                        null
                    ],
                    "_id": "e649a9fd-f6d9-4aac-b428-29b82c20a484",
                    "abstract": "This paper describes a machine learning approach for visual object detection which is capable of processing images extremely rapidly and achieving high detection rates. This work is distinguished by three key contributions. The first is the introduction of a new image representation called the \"integral image\" which allows the features used by our detector to be computed very quickly. The second is a learning algorithm, based on AdaBoost, which selects a small number of critical visual features from a larger set and yields extremely efficient classifiers. The third contribution is a method for combining increasingly more complex classifiers in a \"cascade\" which allows background regions of the image to be quickly discarded while spending more computation on promising object-like regions. The cascade can be viewed as an object specific focus-of-attention mechanism which unlike previous approaches provides statistical guarantees that discarded regions are unlikely to contain the object of interest. In the domain of face detection the system yields detection rates comparable to the best previous systems. Used in real-time applications, the detector runs at 15 frames per second without resorting to image differencing or skin color detection.",
                    "title": "Rapid object detection using a boosted cascade of simple features",
                    "venue": "computer vision and pattern recognition",
                    "year": 2001,
                    "__v": 3,
                    "citationCount": 5200,
                    "result": 6.003928708862296
                },
                "f225f439-4389-4312-a503-f8c1b0aa02de": {
                    "authors": [
                        "Herbert Bay",
                        "Tinne Tuytelaars",
                        "Luc J. Van Gool"
                    ],
                    "references": [
                        "0b86c956-29dc-4979-b046-f2ec971d8ac8",
                        "21c67dad-f0eb-4479-afe7-fdf4a71eef01",
                        "2d6c9f60-ea78-44a8-b5f9-6964575dd196",
                        "2fa58737-dfec-48e8-a1d5-dc96c510d44f",
                        "34758e0a-3def-447b-9c5e-e82a206426b5",
                        "36800655-b2ff-4eb7-9070-c6be304c4baa",
                        "3c1e64c0-8e48-45d3-96e8-f2c3252b4b83",
                        "472cc3e6-8149-41ef-b4c4-fa9e6a60b66f",
                        "473cf1a4-9f42-4e6d-b34f-77787f329079",
                        "509e1ae2-768b-4417-bebe-d90cf1e0fdae",
                        "5f84f09f-7644-447c-89e1-8dc9ee334197",
                        "6018a516-8149-4bce-bc33-5449d86e58c2",
                        "60285266-7da2-474e-b05a-b380c836f665",
                        "6fe37c18-8dc5-4baa-b6e0-5546353907bb",
                        "774c108a-4002-4123-861f-edd3b7ccb0e7",
                        "7ab7b36d-baae-4b21-89fc-69389fcabc44",
                        "8d8e7d51-3223-4776-bf6a-40306774b8a1",
                        "9f5f1500-0df7-4675-8290-b47979bcad38",
                        "a5254ae0-1ce1-4390-b9f8-8d5a3dcb1e62",
                        "b944f77f-113b-4a02-ae5e-d4a124b8fd5b",
                        "e649a9fd-f6d9-4aac-b428-29b82c20a484",
                        "ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d",
                        "ffa029cf-7240-4723-8339-51fac57f9f28"
                    ],
                    "keyword": [],
                    "group": [],
                    "_id": "f225f439-4389-4312-a503-f8c1b0aa02de",
                    "abstract": "In this paper, we present a novel scale- and rotation-invariant interest point detector and descriptor, coined SURF (Speeded Up Robust Features). It approximates or even outperforms previously proposed schemes with respect to repeatability, distinctiveness, and robustness, yet can be computed and compared much faster.#R##N##R##N#This is achieved by relying on integral images for image convolutions; by building on the strengths of the leading existing detectors and descriptors (in casu, using a Hessian matrix-based measure for the detector, and a distribution-based descriptor); and by simplifying these methods to the essential. This leads to a combination of novel detection, description, and matching steps. The paper presents experimental results on a standard evaluation set, as well as on imagery obtained in the context of a real-life object recognition application. Both show SURF's strong performance.",
                    "title": "SURF: speeded up robust features",
                    "venue": "european conference on computer vision",
                    "year": 2006,
                    "__v": 0,
                    "citationCount": 3617,
                    "result": 6.774193548387096
                },
                "ffa029cf-7240-4723-8339-51fac57f9f28": {
                    "authors": [
                        "Krystian Mikolajczyk",
                        "Cordelia Schmid"
                    ],
                    "references": [
                        "0d287faa-99bb-42df-98a7-24fcd601b9a4",
                        "1c016f4a-20fb-44b5-84ad-96c10cb8e61b",
                        "2beaa150-6293-4f05-ba04-8e001993e766",
                        "2d6c9f60-ea78-44a8-b5f9-6964575dd196",
                        "33711daf-2a44-4f42-8466-c7801f29959b",
                        "34758e0a-3def-447b-9c5e-e82a206426b5",
                        "36800655-b2ff-4eb7-9070-c6be304c4baa",
                        "457f15ab-c8e1-461d-b768-e044d88f1917",
                        "473cf1a4-9f42-4e6d-b34f-77787f329079",
                        "509e1ae2-768b-4417-bebe-d90cf1e0fdae",
                        "5149d3c0-5ac9-47ba-9fb0-3d2ef757b0e8",
                        "58d0cc4d-9deb-4188-98d2-7ca475ca7221",
                        "5f1992df-975f-49e7-bd88-aee0740317cf",
                        "5f84f09f-7644-447c-89e1-8dc9ee334197",
                        "6018a516-8149-4bce-bc33-5449d86e58c2",
                        "60285266-7da2-474e-b05a-b380c836f665",
                        "643913d9-b72a-4ee3-9c3f-63c1249e9a3c",
                        "64ea9dde-3bd8-4868-9c0b-f15556e67ad5",
                        "7283fa2b-1f6a-4138-a3da-4bf69809a1a9",
                        "79050acb-3012-4d4b-af60-66040a28043d",
                        "7a9f04e3-2883-4204-8fb3-7db1ce5ddc09",
                        "7ab7b36d-baae-4b21-89fc-69389fcabc44",
                        "899de8c7-9cd9-4dd5-82f1-ad9acb801f8e",
                        "8ab773a4-49b4-4755-a070-4ab1b1710690",
                        "a00704dc-a2fa-4267-b7a6-427167d99521",
                        "a0be9da4-c423-4f87-a387-822fe304aa03",
                        "a72802aa-e1ab-4f52-bae8-703d68f9b220",
                        "b3e60214-b54c-4e8f-9315-a6975c760f4c",
                        "c591c440-b19b-4d7b-b067-cd8c366b7d6d",
                        "cc6caca8-1564-4cf8-88a3-f0733c46e0dd",
                        "d4e9734a-a4e7-4c19-be20-c32f55d4d26f",
                        "e86ce68d-0d77-4f44-a212-518e7d8f394b",
                        "eeb31134-612a-42bf-a6c2-8b7d7c17e694",
                        "ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d"
                    ],
                    "keyword": [
                        "scale",
                        "points",
                        "invariant",
                        "affine",
                        "detectors",
                        "neighborhood",
                        "transformations",
                        "shape",
                        "results",
                        "region"
                    ],
                    "group": [],
                    "_id": "ffa029cf-7240-4723-8339-51fac57f9f28",
                    "abstract": "In this paper we propose a novel approach for detecting interest points invariant to scale and affine transformations. Our scale and affine invariant detectors are based on the following recent results: (1) Interest points extracted with the Harris detector can be adapted to affine transformations and give repeatable results (geometrically stable). (2) The characteristic scale of a local structure is indicated by a local extremum over scale of normalized derivatives (the Laplacian). (3) The affine shape of a point neighborhood is estimated based on the second moment matrix.#R##N##R##N#Our scale invariant detector computes a multi-scale representation for the Harris interest point detector and then selects points at which a local measure (the Laplacian) is maximal over scales. This provides a set of distinctive points which are invariant to scale, rotation and translation as well as robust to illumination changes and limited changes of viewpoint. The characteristic scale determines a scale invariant region for each point. We extend the scale invariant detector to affine invariance by estimating the affine shape of a point neighborhood. An iterative algorithm modifies location, scale and neighborhood of each point and converges to affine invariant points. This method can deal with significant affine transformations including large scale changes. The characteristic scale and the affine shape of neighborhood determine an affine invariant region for each point.#R##N##R##N#We present a comparative evaluation of different detectors and show that our approach provides better results than existing methods. The performance of our detector is also confirmed by excellent matching resultss the image is described by a set of scale/affine invariant descriptors computed on the regions associated with our points.",
                    "title": "Scale & Affine Invariant Interest Point Detectors",
                    "venue": "International Journal of Computer Vision",
                    "year": 2004,
                    "__v": 2,
                    "citationCount": 1525,
                    "result": 7.786366166712043
                }
            }
        ],
        "_id": "50252efa-a843-4cc6-a591-22f527ee3d6c",
        "abstract": "This article presents a novel scale- and rotation-invariant detector and descriptor, coined SURF (Speeded-Up Robust Features). SURF approximates or even outperforms previously proposed schemes with respect to repeatability, distinctiveness, and robustness, yet can be computed and compared much faster. This is achieved by relying on integral images for image convolutions; by building on the strengths of the leading existing detectors and descriptors (specifically, using a Hessian matrix-based measure for the detector, and a distribution-based descriptor); and by simplifying these methods to the essential. This leads to a combination of novel detection, description, and matching steps. The paper encompasses a detailed description of the detector and descriptor and then explores the effects of the most important parameters. We conclude the article with SURF's application to two challenging, yet converse goals: camera calibration as a special case of image registration, and object recognition. Our experiments underline SURF's usefulness in a broad range of topics in computer vision.",
        "title": "Speeded-Up Robust Features (SURF)",
        "venue": "Computer Vision and Image Understanding",
        "year": 2008,
        "__v": 3,
        "citationCount": 3151
    },
    {
        "authors": [
            "Carsten Rother",
            "Vladimir Kolmogorov",
            "Andrew Blake"
        ],
        "references": [
            "1317365d-c46d-4c09-8261-9d07404e4908",
            "19d9d23c-339d-4026-aff7-c81ee3daa0d7",
            "1bcbede9-dcb1-4f5d-a88f-85d9176c5e27",
            "1c63e1d5-b963-455b-829d-e4f3eb63a36a",
            "789f15ca-dd46-4b74-8526-a73b9d6c3e14",
            "82eb55e6-39a8-4968-8be6-e2bfbb439a40",
            "88a1d409-c3f4-4252-b831-56518e6a179a",
            "dd8087bb-bde1-4b8e-8ef0-3f8d0aabce9b",
            "e8247450-abbc-48fe-a022-5f6579f9de14",
            "f3d57b86-0677-4dd8-bbf5-52efaeed9a82"
        ],
        "keyword": [
            "information",
            "images",
            "developed",
            "tools",
            "segmentation",
            "powerful",
            "iterative",
            "interactive",
            "graphcut",
            "colour"
        ],
        "group": [
            {
                "789f15ca-dd46-4b74-8526-a73b9d6c3e14": {
                    "authors": [
                        "Eric N. Mortensen",
                        "William A. Barrett"
                    ],
                    "references": [
                        "1c63e1d5-b963-455b-829d-e4f3eb63a36a",
                        "2f7bbeb2-25d1-4dfa-bc2d-754792ec2613",
                        "54d3b99b-17e0-443f-bd4c-23db90ce9c26",
                        "5fadd790-4d5c-4a63-9d0c-39661713cf69",
                        "6d5985ab-a8a9-4473-842b-0956ba1beded",
                        "76dea053-0a8b-4cbc-88c2-f6057e4d08b8",
                        "784b6b67-b84b-48d5-942c-fb4960289de0",
                        "79359cb0-3770-480a-943b-fabb0f8da236",
                        "7ecd6949-c92d-410d-a204-41b50bba15f1",
                        "893791c5-4414-4db6-a307-472768e36e3b",
                        "e8247450-abbc-48fe-a022-5f6579f9de14"
                    ],
                    "keyword": [
                        "graph",
                        "user",
                        "tobogganing",
                        "segmentation",
                        "resulting",
                        "optimal",
                        "interactive",
                        "image",
                        "faster",
                        "edge"
                    ],
                    "group": [],
                    "_id": "789f15ca-dd46-4b74-8526-a73b9d6c3e14",
                    "abstract": "Intelligent Scissors is an interactive image segmentation tool that allows a user to select piece-wise globally optimal contour segments that correspond to a desired object boundary. We present a new and faster method of computing the optimal path by over-segmenting the image using tobogganing and then imposing a weighted planar graph on top of the resulting region boundaries. The resulting region-based graph is many times smaller than the previous pixel-based graph, thus providing faster graph searches and immediate user interaction. Further tobogganing provides an new systematic and predictable framework for computing edge model parameters, allowing subpixel localization as well as a measure of edge blur.",
                    "title": "Toboggan-based intelligent scissors with a four-parameter edge model",
                    "venue": "computer vision and pattern recognition",
                    "year": 1999,
                    "__v": 2,
                    "citationCount": 55,
                    "result": 12.55215278357693
                },
                "82eb55e6-39a8-4968-8be6-e2bfbb439a40": {
                    "authors": [
                        "Vicent Caselles",
                        "Ron Kimmel",
                        "Guillermo Sapiro"
                    ],
                    "references": [
                        "050ca16f-ca2a-4614-b2a1-6f56154238c0",
                        "1aab9f45-5ddc-407d-813d-ef41f63e6208",
                        "1c63e1d5-b963-455b-829d-e4f3eb63a36a",
                        "270de21e-f73e-44bb-a424-43441369f827",
                        "2ccb01b5-e59c-4ff4-b627-a76a72c9738c",
                        "3620aa43-c845-4b25-9da5-61a5d4f85609",
                        "36800655-b2ff-4eb7-9070-c6be304c4baa",
                        "36dd023a-14a7-479a-89c6-26d731dc5ae3",
                        "3f4cc95c-5f47-4031-8671-e23ff4fe2ed2",
                        "5b255d3a-5639-41cf-886b-8377bea8193f",
                        "61aa50fc-f75b-4246-9235-5e8e1b2846bc",
                        "85a39731-9a54-4d2c-9b92-d8ba04b28763",
                        "893791c5-4414-4db6-a307-472768e36e3b",
                        "8c80ee9a-3e0f-40a6-965c-d0a0fc3aa9d9",
                        "a32162d0-5f52-44b4-8bb1-be62d003f5d0",
                        "b1d5effd-27a3-417f-8ac3-8988e00c4558",
                        "b2de99a5-01d1-4359-be11-10c2ce130a05",
                        "b3c68e31-fa5b-49c8-9fac-bf19a78e41b6",
                        "c5e1a14b-3106-4195-820a-3d57b17a590b",
                        "e500049d-e42e-43a5-8e0c-4f57cdf91fa7",
                        "e89b3a55-ab36-4ed2-ae8f-cf297b58efa8",
                        "ef330947-bc34-4f55-834b-40469ee33769",
                        "f18355d4-bc52-48c8-bae0-309cb9d4307a",
                        "f4353d3d-9909-40cb-be04-9fc4d5ef8635",
                        "fc33562a-70e0-4279-887a-de8bc085d565"
                    ],
                    "keyword": [
                        "contours",
                        "based",
                        "active",
                        "object",
                        "minimal",
                        "geometric",
                        "curves",
                        "presented",
                        "image",
                        "geodesics"
                    ],
                    "group": [],
                    "_id": "82eb55e6-39a8-4968-8be6-e2bfbb439a40",
                    "abstract": "A novel scheme for the detection of object boundaries is presented. The technique is based on active contours deforming according to intrinsic geometric measures of the image. The evolving contours naturally split and merge, allowing the simultaneous detection of several objects and both interior and exterior boundaries. The proposed approach is based on the relation between active contours and the computation of geodesics or minimal distance curves. The minimal distance curve lays in a Riemannian space whose metric as defined by the image content. This geodesic approach for object segmentation allows to connect classical \"snakes\" based on energy minimization and geometric active contours based on the theory of curve evolution. Previous models of geometric active contours are improved as showed by a number of examples. Formal results concerning existence, uniqueness, stability, and correctness of the evolution are presented as well. >",
                    "title": "Geodesic active contours",
                    "venue": "international conference on computer vision",
                    "year": 1995,
                    "__v": 2,
                    "citationCount": 2129,
                    "result": 8.524786642665902
                },
                "88a1d409-c3f4-4252-b831-56518e6a179a": {
                    "authors": [
                        "Andrew Blake",
                        "Carsten Rother",
                        "Matthew A. Brown",
                        "Patrick Pérez",
                        "Philip H. S. Torr"
                    ],
                    "references": [
                        "1317365d-c46d-4c09-8261-9d07404e4908",
                        "19d9d23c-339d-4026-aff7-c81ee3daa0d7",
                        "1bcbede9-dcb1-4f5d-a88f-85d9176c5e27",
                        "5f70f18c-5f9c-442e-ae2c-ee6aadecab95",
                        "98cfeac3-9abb-4f5b-9705-158c3b7b9d3a"
                    ],
                    "keyword": [],
                    "group": [],
                    "_id": "88a1d409-c3f4-4252-b831-56518e6a179a",
                    "abstract": "The problem of interactive foreground/background segmentation in still images is of great practical importance in image editing. The state of the art in interactive segmentation is probably represented by the graph cut algorithm of Boykov and Jolly (ICCV 2001). Its underlying model uses both colour and contrast information, together with a strong prior for region coherence. Estimation is performed by solving a graph cut problem for which very efficient algorithms have recently been developed. However the model depends on parameters which must be set by hand and the aim of this work is for those constants to be learned from image data. First, a generative, probabilistic formulation of the model is set out in terms of a \"Gaussian Mixture Markov Random Field\" (GMMRF). Secondly, a pseudolike- lihood algorithm is derived which jointly learns the colour mixture and coherence parameters for foreground and background respectively. Error rates for GMMRF segmentation are calculated throughout using a new image database, available on the web, with ground truth provided by a human segmenter. The graph cut al- gorithm, using the learned parameters, generates good object-segmentations with little interaction. However, pseudolikelihood learning proves to be frail, which limits the complexity of usable models, and hence also the achievable error rate.",
                    "title": "Interactive Image Segmentation Using an Adaptive GMMRF Model",
                    "venue": "european conference on computer vision",
                    "year": 2004,
                    "__v": 0,
                    "citationCount": 295,
                    "result": 3
                }
            }
        ],
        "_id": "5ffadf36-4496-4be6-b8a8-828fa37f7757",
        "abstract": "The problem of efficient, interactive foreground/background segmentation in still images is of great practical importance in image editing. Classical image segmentation tools use either texture (colour) information, e.g. Magic Wand, or edge (contrast) information, e.g. Intelligent Scissors. Recently, an approach based on optimization by graph-cut has been developed which successfully combines both types of information. In this paper we extend the graph-cut approach in three respects. First, we have developed a more powerful, iterative version of the optimisation. Secondly, the power of the iterative algorithm is used to simplify substantially the user interaction needed for a given quality of result. Thirdly, a robust algorithm for \"border matting\" has been developed to estimate simultaneously the alpha-matte around an object boundary and the colours of foreground pixels. We show that for moderately difficult examples the proposed method outperforms competitive tools.",
        "title": "\"GrabCut\": interactive foreground extraction using iterated graph cuts",
        "venue": "international conference on computer graphics and interactive techniques",
        "year": 2004,
        "__v": 2,
        "citationCount": 2085
    },
    {
        "authors": [
            "Réka Albert",
            "Albert-László Barabási"
        ],
        "references": [],
        "keyword": [
            "networks",
            "nodes",
            "degree",
            "systems",
            "real",
            "distribution",
            "topology",
            "random",
            "modeling"
        ],
        "group": [
            null
        ],
        "_id": "60ef3852-fa16-44bf-9434-9909268ba5d8",
        "abstract": "The emergence of order in natural systems is a constant source of inspiration for both physical and biological sciences. While the spatial order characterizing for example the crystals has been the basis of many advances in contemporary physics, most complex systems in nature do not offer such high degree of order. Many of these systems form complex networks whose nodes are the elements of the system and edges represent the interactions between them. #R##N#Traditionally complex networks have been described by the random graph theory founded in 1959 by Paul Erdohs and Alfred Renyi. One of the defining features of random graphs is that they are statistically homogeneous, and their degree distribution (characterizing the spread in the number of edges starting from a node) is a Poisson distribution. In contrast, recent empirical studies, including the work of our group, indicate that the topology of real networks is much richer than that of random graphs. In particular, the degree distribution of real networks is a power-law, indicating a heterogeneous topology in which the majority of the nodes have a small degree, but there is a significant fraction of highly connected nodes that play an important role in the connectivity of the network. #R##N#The scale-free topology of real networks has very important consequences on their functioning. For example, we have discovered that scale-free networks are extremely resilient to the random disruption of their nodes. On the other hand, the selective removal of the nodes with highest degree induces a rapid breakdown of the network to isolated subparts that cannot communicate with each other. #R##N#The non-trivial scaling of the degree distribution of real networks is also an indication of their assembly and evolution. Indeed, our modeling studies have shown us that there are general principles governing the evolution of networks. Most networks start from a small seed and grow by the addition of new nodes which attach to the nodes already in the system. This process obeys preferential attachment: the new nodes are more likely to connect to nodes with already high degree. We have proposed a simple model based on these two principles wich was able to reproduce the power-law degree distribution of real networks. Perhaps even more importantly, this model paved the way to a new paradigm of network modeling, trying to capture the evolution of networks, not just their static topology.",
        "title": "Statistical mechanics of complex networks",
        "venue": "Reviews of Modern Physics",
        "year": 2001,
        "__v": 3,
        "citationCount": 3029
    },
    {
        "authors": [
            "Kalyanmoy Deb",
            "Amrit Pratap",
            "Sameer Agarwal",
            "T. Meyarivan"
        ],
        "references": [
            "0cc8a4bb-8bb1-4526-ab1e-ae8ff4eccc6d",
            "1f5b4b74-9c6f-43c8-b490-447ae33d6157",
            "32db0b6b-7326-4bd6-9404-fa88ce9e0746",
            "8666d3c4-737c-48ef-b1bd-a65206527ba9",
            "96954e25-e35d-405a-a01a-cb017ddae552",
            "9cf177c9-48f2-4743-823d-950b096f0008",
            "b8be5256-00f7-4d83-bd1b-f13bfcdf0673",
            "be180e3d-b6df-41ad-a123-521a925a2f06",
            "c6553383-a300-4d96-b68a-398ea1b4389a",
            "da763e77-162f-4d3f-a172-10ec6f7bb599",
            "fbbddfd2-5b7c-4f54-8718-5fe1f58ebf33"
        ],
        "keyword": [
            "problems",
            "nsgaii",
            "nondominated",
            "sorting",
            "multiobjective",
            "moeas",
            "constrained",
            "algorithms"
        ],
        "group": [
            {
                "8666d3c4-737c-48ef-b1bd-a65206527ba9": {
                    "authors": [
                        "Carlos M. Fonseca",
                        "Peter J. Fleming"
                    ],
                    "references": [
                        "6a6b9aa6-683f-4c7c-b06e-9c3018d10fd3",
                        "7f903659-26c5-4f3a-827e-237913b2fdaa",
                        "858a4272-c06a-4689-82e8-ac71be713972",
                        "957d98db-ad29-41a6-bc3a-f8d4e704228f",
                        "b0970783-382f-4109-93a2-3b5dc8b4f97f",
                        "b8be5256-00f7-4d83-bd1b-f13bfcdf0673",
                        "c061069f-29d1-46d4-9974-dede8d5461f9",
                        "c6553383-a300-4d96-b68a-398ea1b4389a",
                        "f81dfe60-7ce5-4a65-b43e-4b3de9f5ca54"
                    ],
                    "keyword": [
                        "optimization",
                        "design",
                        "algorithm",
                        "study",
                        "set",
                        "preference",
                        "practical",
                        "part",
                        "paper",
                        "objective"
                    ],
                    "group": [],
                    "_id": "8666d3c4-737c-48ef-b1bd-a65206527ba9",
                    "abstract": "For part I see ibid., 26-37. The evolutionary approach to multiple function optimization formulated in the first part of the paper is applied to the optimization of the low-pressure spool speed governor of a Pegasus gas turbine engine. This study illustrates how a technique such as the multiobjective genetic algorithm can be applied, and exemplifies how design requirements can be refined as the algorithm runs. Several objective functions and associated goals express design concerns in direct form, i.e., as the designer would state them. While such a designer-oriented formulation is very attractive, its practical usefulness depends heavily on the ability to search and optimize cost surfaces in a class much broader than usual, as already provided to a large extent by the genetic algorithm (GA). The two instances of the problem studied demonstrate the need for preference articulation in cases where many and highly competing objectives lead to a nondominated set too large for a finite population to sample effectively. It is shown that only a very small portion of the nondominated set is of practical relevance, which further substantiates the need to supply preference information to the GA. The paper concludes with a discussion of the results.",
                    "title": "Multiobjective optimization and multiple constraint handling with evolutionary algorithms. II. Application example",
                    "venue": "systems man and cybernetics",
                    "year": 1998,
                    "__v": 2,
                    "citationCount": 129,
                    "result": 5.8614272981920035
                },
                "be180e3d-b6df-41ad-a123-521a925a2f06": {
                    "authors": [
                        "Kalyanmoy Deb"
                    ],
                    "references": [
                        "0bae2284-926b-48ed-a9c1-74c3f4c08f88",
                        "0cc8a4bb-8bb1-4526-ab1e-ae8ff4eccc6d",
                        "0fa84405-e743-4119-af98-d7b5173dcb86",
                        "27681688-e444-4ce4-a802-a12cd89bb132",
                        "32db0b6b-7326-4bd6-9404-fa88ce9e0746",
                        "441667da-4d23-4862-b80d-36664fec7240",
                        "4e490ea3-7655-4bf9-a857-5e73a0295f51",
                        "54502992-c2e8-4780-8c09-b3dc3452b9a7",
                        "5c4cb3fc-9a25-4aa7-92ff-8044f9662c7d",
                        "6a6b9aa6-683f-4c7c-b06e-9c3018d10fd3",
                        "8666d3c4-737c-48ef-b1bd-a65206527ba9",
                        "8f6bea7e-2956-4d17-927d-968cd850d153",
                        "9cf177c9-48f2-4743-823d-950b096f0008",
                        "9f9332c3-e3f4-4b52-9786-2866c291f65f",
                        "a26620c4-e573-4dca-9144-cf2d203fe559",
                        "a4ba09d4-8c4e-4f36-b9d9-2c6b519de69a",
                        "b8be5256-00f7-4d83-bd1b-f13bfcdf0673",
                        "c73b926a-0c5a-4d32-b1b1-2b572f739965",
                        "d05c6688-882c-414f-8fcc-5ebe34a8b8f9",
                        "d9a65bd2-f9d9-41e2-a270-677c07d14931",
                        "da763e77-162f-4d3f-a172-10ec6f7bb599",
                        "e184cb56-a353-42dc-a4d3-8fc7648e63bd",
                        "f24c6cd0-7061-4952-8faa-e24922a37ba8",
                        "fbbddfd2-5b7c-4f54-8718-5fe1f58ebf33"
                    ],
                    "keyword": [
                        "problem",
                        "multiobjective",
                        "test",
                        "optimization",
                        "features",
                        "difficult",
                        "specific",
                        "singleobjective",
                        "constructed",
                        "algorithm"
                    ],
                    "group": [],
                    "_id": "be180e3d-b6df-41ad-a123-521a925a2f06",
                    "abstract": "In this paper, we study the problem features that may cause a multi-objective genetic algorithm (GA) difficulty in converging to the true Pareto-optimal front. Identification of such features helps us develop difficult test problems for multi-objective optimization. Multi-objective test problems are constructed from single-objective optimization problems, thereby allowing known difficult features of single-objective problems (such as multi-modality, isolation, or deception) to be directly transferred to the corresponding multi-objective problem. In addition, test problems having features specific to multi-objective optimization are also constructed. More importantly, these difficult test problems will enable researchers to test their algorithms for specific aspects of multi-objective optimization.",
                    "title": "Multi-objective genetic algorithms: Problem difficulties and construction of test problems",
                    "venue": "electronic commerce",
                    "year": 1999,
                    "__v": 2,
                    "citationCount": 329,
                    "result": 13.649400680034681
                },
                "c6553383-a300-4d96-b68a-398ea1b4389a": {
                    "authors": [
                        "Carlos M. Fonseca",
                        "Peter J. Fleming"
                    ],
                    "references": [
                        "0cc8a4bb-8bb1-4526-ab1e-ae8ff4eccc6d",
                        "32db0b6b-7326-4bd6-9404-fa88ce9e0746",
                        "6a6b9aa6-683f-4c7c-b06e-9c3018d10fd3",
                        "6c7024e9-1b71-4d52-b22e-9c9d759df4c6",
                        "6d882eb9-28bb-48ea-8156-213cca215014",
                        "7306abeb-0a3e-4373-b2c7-b88d616ca94c",
                        "858a4272-c06a-4689-82e8-ac71be713972",
                        "8666d3c4-737c-48ef-b1bd-a65206527ba9",
                        "957d98db-ad29-41a6-bc3a-f8d4e704228f",
                        "ae6768ce-3cf1-415b-a489-7d344bdbec5e",
                        "b50241aa-a437-4f1d-a5c2-3058f175787c",
                        "b8be5256-00f7-4d83-bd1b-f13bfcdf0673",
                        "c061069f-29d1-46d4-9974-dede8d5461f9",
                        "c6fed450-131c-49e9-bf77-321ff0ea38bf",
                        "d05c6688-882c-414f-8fcc-5ebe34a8b8f9"
                    ],
                    "keyword": [
                        "optimization",
                        "decision",
                        "cost",
                        "candidate",
                        "solutions",
                        "requirements",
                        "preference",
                        "multiobjective",
                        "eas",
                        "algorithms"
                    ],
                    "group": [],
                    "_id": "c6553383-a300-4d96-b68a-398ea1b4389a",
                    "abstract": "In optimization, multiple objectives and constraints cannot be handled independently of the underlying optimizer. Requirements such as continuity and differentiability of the cost surface add yet another conflicting element to the decision process. While \"better\" solutions should be rated higher than \"worse\" ones, the resulting cost landscape must also comply with such requirements. Evolutionary algorithms (EAs), which have found application in many areas not amenable to optimization by other methods, possess many characteristics desirable in a multiobjective optimizer, most notably the concerted handling of multiple candidate solutions. However, EAs are essentially unconstrained search techniques which require the assignment of a scalar measure of quality, or fitness, to such candidate solutions. After reviewing current revolutionary approaches to multiobjective and constrained optimization, the paper proposes that fitness assignment be interpreted as, or at least related to, a multicriterion decision process. A suitable decision making framework based on goals and priorities is subsequently formulated in terms of a relational operator, characterized, and shown to encompass a number of simpler decision strategies. Finally, the ranking of an arbitrary number of candidates is considered. The effect of preference changes on the cost surface seen by an EA is illustrated graphically for a simple problem. The paper concludes with the formulation of a multiobjective genetic algorithm based on the proposed decision strategy. Niche formation techniques are used to promote diversity among preferable candidates, and progressive articulation of preferences is shown to be possible as long as the genetic algorithm can recover from abrupt changes in the cost landscape.",
                    "title": "Multiobjective optimization and multiple constraint handling with evolutionary algorithms. I. A unified formulation",
                    "venue": "systems man and cybernetics",
                    "year": 1998,
                    "__v": 2,
                    "citationCount": 360,
                    "result": 9.74811229362313
                },
                "da763e77-162f-4d3f-a172-10ec6f7bb599": {
                    "authors": [
                        "Carlos M. Fonseca",
                        "Peter J. Fleming"
                    ],
                    "references": [
                        "d05c6688-882c-414f-8fcc-5ebe34a8b8f9"
                    ],
                    "keyword": [
                        "performance",
                        "statistical",
                        "shown",
                        "optimizers",
                        "nonparametric",
                        "multiobjective",
                        "analogous",
                        "work",
                        "typical",
                        "test"
                    ],
                    "group": [],
                    "_id": "da763e77-162f-4d3f-a172-10ec6f7bb599",
                    "abstract": "This work proposes a quantitative, non-parametric interpre- tation of statistical performance of stochastic multiobjective optimizers, including, but not limited to, genetic algorithms. It is shown that, accord- ing to this interpretation, typical performance can be defined in terms analogous to the notion of median for ordinal data, as can other measures analogous to other quantiles. Non-parametric statistical test procedures are then shown to be useful in deciding the relative performance of different multiobjective optimizers on a given problem. Illustrative experimental results are provided to support the discussion.",
                    "title": "On the Performance Assessment and Comparison of Stochastic Multiobjective Optimizers",
                    "venue": "parallel problem solving from nature",
                    "year": 1996,
                    "__v": 2,
                    "citationCount": 182,
                    "result": 4.0605442425539335
                }
            }
        ],
        "_id": "65d5ccdc-7022-45b0-adf9-0385273b1283",
        "abstract": "Multi-objective evolutionary algorithms (MOEAs) that use non-dominated sorting and sharing have been criticized mainly for: (1) their O(MN/sup 3/) computational complexity (where M is the number of objectives and N is the population size); (2) their non-elitism approach; and (3) the need to specify a sharing parameter. In this paper, we suggest a non-dominated sorting-based MOEA, called NSGA-II (Non-dominated Sorting Genetic Algorithm II), which alleviates all of the above three difficulties. Specifically, a fast non-dominated sorting approach with O(MN/sup 2/) computational complexity is presented. Also, a selection operator is presented that creates a mating pool by combining the parent and offspring populations and selecting the best N solutions (with respect to fitness and spread). Simulation results on difficult test problems show that NSGA-II is able, for most problems, to find a much better spread of solutions and better convergence near the true Pareto-optimal front compared to the Pareto-archived evolution strategy and the strength-Pareto evolutionary algorithm - two other elitist MOEAs that pay special attention to creating a diverse Pareto-optimal front. Moreover, we modify the definition of dominance in order to solve constrained multi-objective problems efficiently. Simulation results of the constrained NSGA-II on a number of test problems, including a five-objective, seven-constraint nonlinear problem, are compared with another constrained multi-objective optimizer, and the much better performance of NSGA-II is observed.",
        "title": "A fast and elitist multiobjective genetic algorithm: NSGA-II",
        "venue": "IEEE Transactions on Evolutionary Computation",
        "year": 2002,
        "__v": 3,
        "citationCount": 6696
    },
    {
        "authors": [
            "Santo Fortunato"
        ],
        "references": [
            "043346ea-c1fe-4719-b86e-57d2adaae648",
            "0ad2acb7-43ee-424d-b4d2-472e167a9c84",
            "0c120a60-a306-4618-96ba-b1aec7a7314e",
            "0c60f247-abf1-4fbf-92fc-39407c5ed556",
            "0cdb081e-f2db-49d9-8c65-45cbcc948265",
            "0d6a426e-79ad-4747-b0c6-537078ba6e70",
            "1035fd34-a47d-4c70-93f7-a7b3b20e5b60",
            "106ac945-1fd6-4abd-b059-1b56ca491d0a",
            "10d125fa-b98d-4942-8270-6c63ce1c5890",
            "1431d9db-19ca-45f8-9ee7-e8e23ca316a0",
            "15c30ca5-6af6-4acf-b8c5-f2c0e18e6ad8",
            "15ec420c-7fb8-4950-8ba5-5149c8c78749",
            "1721b1de-cf3d-4ebd-8229-80a79ab29747",
            "18819165-7f73-4da1-9bf2-792c258be677",
            "1b41d9a0-3857-4fb6-b7ba-d39da73c04dd",
            "1d383765-fe50-4493-9714-3df0c5e05057",
            "207c393f-ae4c-4426-bdf5-195458a41abd",
            "24065196-bfc0-44b2-998c-4f3c4b5027b4",
            "26cd1d0d-331d-499a-8d35-a501e6af9200",
            "26e47743-414d-424d-bfa3-d51e253df655",
            "287df3fe-6f46-4071-8ab5-99274b9887b1",
            "2ae42d91-fc91-472f-bd7f-426f09e6f912",
            "2b3f5e5a-36cf-41ab-b9e0-a69f792866f2",
            "2f082a6f-9356-45f8-b4ff-4409c48ba0ec",
            "3044fef1-b4aa-46ca-a1e2-7079b4583362",
            "32d9efda-7b21-4106-bc1a-47b09e81a27c",
            "33716924-a3c8-407b-8448-0398eaf90bc1",
            "35cad820-9f36-41ac-86e7-b14bf90e75ba",
            "3f442f61-f9e7-4ed3-aee5-7bf67f1f3b7b",
            "3f4cc95c-5f47-4031-8671-e23ff4fe2ed2",
            "3fe346d3-5a15-4d14-9363-24f402d474a3",
            "414b741a-a47c-40f0-b37a-6b102f442e8c",
            "42fa459d-f2db-47d3-9855-bc6fcfd7204b",
            "440ab2d5-3af6-4a67-9ddb-d1a7b6693063",
            "48d388af-7e23-4b8f-b245-c92c1f262f42",
            "4cedadea-4628-455a-8824-17eab0dc790c",
            "516632de-65d2-4342-b358-3c154de44776",
            "5215ff24-af48-4682-8c59-fe9db5fd4515",
            "53649a4b-3941-4221-ae31-c0334a1cfac4",
            "56aacaea-4377-41f7-9e73-0dcdd25984fc",
            "597ecf84-4084-4057-a40d-30988ef74121",
            "5e3020bb-324a-4926-963c-36f66eda1b27",
            "5f1a52f2-faca-45ab-bb82-8d459d1c77ce",
            "608ab163-0fbf-4c6e-bf21-29b3145bae2a",
            "60ef3852-fa16-44bf-9434-9909268ba5d8",
            "63ec4f55-8f3b-431e-88e5-87c04caa7e9f",
            "646fd5f1-1f89-40a7-b605-8402513ae682",
            "68f5a094-18a6-4250-85de-214f7840bc6b",
            "6e49eac6-161b-4254-9529-b792395ba1fb",
            "748bce90-b5d8-4759-b733-c75b4e57bfea",
            "756e5f32-dade-48dc-9271-5ca96ce73d0f",
            "75830a91-6bd3-47b9-a517-5e1e0b68bf04",
            "76395316-a3bc-43c9-9113-cf11eff1ccbf",
            "764a3426-aaea-4b4a-a692-a6cc215fe34e",
            "772e015f-5e9e-4b55-9b08-394ff78f3529",
            "79433674-7ae3-4613-9914-2db2b16fd01f",
            "7a1a3bf9-8c23-4c13-8c8e-85b79ad6143e",
            "7c90045b-63b9-4f29-82a0-bf7c914a6ef6",
            "7d4be6a0-afa0-4c75-a3dd-e04b3cd0b874",
            "86b69247-af69-4276-a105-b5e821559946",
            "881ffdab-0f89-4a72-8655-8bc3a3fc6577",
            "8e245630-549b-4b1c-afe7-cdf466295f32",
            "90916b32-f4d4-44a6-a6f2-c6e6398703a2",
            "9167c2df-4b86-4b47-98c9-3807261c343a",
            "940e7ab9-c036-4e6a-8942-b90dc6b9c339",
            "9438a773-c15c-4ef2-a97c-54f643ce6082",
            "993143bf-fe78-4033-b59b-cba01cc3861e",
            "9ce54ae7-19f5-423e-bf83-5e0eb187d460",
            "9dbdc129-b8f3-4712-9c95-406bc8911bee",
            "9df2aa63-11f9-4a64-b6c4-1fef1f8cde91",
            "a2fa78b2-9eb2-4d93-b2f5-f33579e4cbdf",
            "a86e0c46-2085-4d1f-a712-a03be726ae4e",
            "aa35f1f9-396c-4909-b303-493b5cb44b89",
            "ab7366d4-1ed3-4673-a39c-ac67c54f735e",
            "b09f2059-32bd-444f-9919-49ef62b99691",
            "b0afa6ff-6528-4701-800b-5dc0b5411b0c",
            "b0ef6e4d-4c86-4b10-9e0a-7b630ca8d7f7",
            "b6af7a3b-1d82-44df-94e9-1297c7c6c542",
            "b6c8bcad-70a8-4d76-82f7-109c0439a645",
            "b7fb5dc9-9016-436d-a365-55c52e3c3e62",
            "b80d9c8a-c008-495f-a1e3-01da69ec54d9",
            "b92f5495-64f2-4712-80ae-ceaf751618d0",
            "baeb6078-a7bb-4f89-9807-c67791def7a5",
            "c5ec6a5c-ff8d-494d-b093-66383861fe51",
            "c6765391-ea04-40cc-ac43-a37261c94cc1",
            "c7e4e04b-45da-4bae-8c8a-d17ca0087361",
            "c8678358-846c-457d-a775-b74aa2f56b8d",
            "ca25acbc-7ec2-453c-911f-077a06d76ebf",
            "cc248270-c3d6-4613-8b30-df4a066a5cb9",
            "d9a1466a-0e41-4eb7-b751-d7c282b53460",
            "dc88af6e-158d-4a2e-badd-2afaf5c95648",
            "dd90433d-a428-4ff1-833d-050702f7699c",
            "e2a97ffb-90b0-4f1a-b01d-b15a77a820de",
            "e6d5b127-aa36-4add-971a-aa4dc2689baa",
            "e75d428e-9877-4d52-8660-1bb3bf0b9f5e",
            "e96828f8-70d7-4df8-a75a-5cf81e168601",
            "ea8cd3d8-17ae-4a1e-8f83-1609469087af",
            "eb141c7c-b6d9-48d4-8e96-150d4f59bac5",
            "ecd9f620-88b9-4f98-95a5-cca95d2722ff",
            "ee86124f-174f-47ad-944a-52ba1a637d22",
            "ef2e097d-9060-4e66-ab5a-ba742240f5e2",
            "f0b1c421-218b-484a-85d2-162058a63b60",
            "f15b19f2-4b37-454c-851e-a71cccf3e53a",
            "f246f6f3-f5c6-4cb8-a08f-1ca8d0d63cf8",
            "f48eee6b-7421-48bc-92ea-b571bef6af20",
            "f5ab3435-0ea9-4db2-82db-f42f12df9aa6",
            "f5de6b41-0df8-4270-8211-a67a081dad45",
            "f6326c6d-6313-43fb-a028-5bfe5cf3505c",
            "f6a607ee-8043-4137-a6e6-070108fff1dd",
            "f780dea5-4a66-4de2-8288-f6a1e9ae0d23",
            "f972e14c-debe-452d-a9ba-aa7156923a76",
            "fa0e3a65-c218-4eff-bf8b-cf284855bb32",
            "fb244d98-60f6-40f8-8c42-a233dfa5843f",
            "fbdbd8f0-1b0d-4eff-bb82-cdb6fee483e9",
            "fc93dd72-b331-4f0c-8b54-4b52deaf6764",
            "feddae21-3c05-4743-80fa-b8e101f1b93f"
        ],
        "keyword": [
            "clustering",
            "community",
            "vertices",
            "systems",
            "graphs",
            "significant",
            "science",
            "representing",
            "real",
            "problem"
        ],
        "group": [
            {
                "0ad2acb7-43ee-424d-b4d2-472e167a9c84": {
                    "authors": [
                        "David Liben-Nowell",
                        "Jon M. Kleinberg"
                    ],
                    "references": [
                        "12e1573f-0ae1-4924-a0b7-a77d46bd3bb4",
                        "4a39c97f-9d81-4cf7-ac75-5b9c76df88fe",
                        "51bd8299-2450-4387-aa6f-bfff35b61db2",
                        "5f5f1d00-4b9a-483b-b54a-ae746885401b",
                        "69f988d0-f5e7-455f-a9fc-ee9d9a1c97ce",
                        "7c6a970a-0d6f-4e4b-b50e-6c6fbd23a9ab",
                        "9578a7de-c4c5-404b-9348-69a64c2fb839",
                        "ac14afe6-de4d-4056-b2ac-0f6e36f369a2",
                        "b0ef6e4d-4c86-4b10-9e0a-7b630ca8d7f7",
                        "c4716aad-c8bc-431b-8173-0300064a77b0",
                        "c66d83cd-0fd9-4d4b-a42e-cd9754bf5aca",
                        "c7e4e04b-45da-4bae-8c8a-d17ca0087361",
                        "ccc5cb4e-4af9-44b4-b510-d87bea1e4500",
                        "d71f089c-0658-478a-b58e-bb8e6f131c21",
                        "e75d8e62-a86d-4241-953f-1b315005d920"
                    ],
                    "keyword": [
                        "network",
                        "measures",
                        "proximity",
                        "prediction",
                        "nodes",
                        "link",
                        "interactions",
                        "future",
                        "topology",
                        "suggest"
                    ],
                    "group": [],
                    "_id": "0ad2acb7-43ee-424d-b4d2-472e167a9c84",
                    "abstract": "Given a snapshot of a social network, can we infer which new interactions among its members are likely to occur in the near future? We formalize this question as the  link prediction problem , and develop approaches to link prediction based on measures the \"proximity\" of nodes in a network. Experiments on large co-authorship networks suggest that information about future interactions can be extracted from network topology alone, and that fairly subtle measures for detecting node proximity can outperform more direct measures.",
                    "title": "The link prediction problem for social networks",
                    "venue": "conference on information and knowledge management",
                    "year": 2003,
                    "__v": 1,
                    "citationCount": 855,
                    "result": 5.2377369460427
                },
                "26cd1d0d-331d-499a-8d35-a501e6af9200": {
                    "authors": [
                        "Deepayan Chakrabarti",
                        "Ravi Kumar",
                        "Andrew Tomkins"
                    ],
                    "references": [
                        "298701cf-cf9e-4cdf-a918-1d28885469b1",
                        "38135245-8eff-4078-af6a-ea559ffa660b",
                        "43507af7-3e99-48fa-9ae3-8bb7e641c3e3",
                        "6fbc39eb-3034-4243-9c53-d9cec53225fc",
                        "7c460e8e-5c9e-45f5-9d18-461f27fcef43",
                        "7c6e7aea-f51f-4811-9846-529a7c01dfe6",
                        "9556b193-e64a-4e67-a2d0-1dce95b63461",
                        "9b4e6c65-da64-4ffe-8f2b-810d7f1efb54",
                        "a7ea9ff6-393e-4d43-ad54-7a5cc6053155",
                        "b69d05a9-a463-47a9-89c1-a3b6af57b6d7",
                        "c9a7fa76-fef3-465e-bec8-6f4eaef60316",
                        "d4d4286f-609d-42cb-a3a5-47f057ff4a7e",
                        "fb739bf0-40a7-48c9-a30d-c3ac421819de"
                    ],
                    "keyword": [
                        "clustering",
                        "data",
                        "algorithms",
                        "time",
                        "simultaneously",
                        "problem",
                        "high",
                        "framework",
                        "evolutionary"
                    ],
                    "group": [],
                    "_id": "26cd1d0d-331d-499a-8d35-a501e6af9200",
                    "abstract": "We consider the problem of clustering data over time. An  evolutionary clustering  should simultaneously optimize two potentially conflicting criteria: first, the clustering at any point in time should remain faithful to the current data as much as possible; and second, the clustering should not shift dramatically from one timestep to the next. We present a generic framework for this problem, and discuss evolutionary versions of two widely-used clustering algorithms within this framework:  k -means and agglomerative hierarchical clustering. We extensively evaluate these algorithms on real data sets and show that our algorithms can simultaneously attain both high accuracy in capturing today's data, and high fidelity in reflecting yesterday's clustering.",
                    "title": "Evolutionary clustering",
                    "venue": "knowledge discovery and data mining",
                    "year": 2006,
                    "__v": 2,
                    "citationCount": 243,
                    "result": 4.717368444286603
                },
                "5215ff24-af48-4682-8c59-fe9db5fd4515": {
                    "authors": [
                        "Bo Yang",
                        "Jiming Liu"
                    ],
                    "references": [
                        "056cf1d0-647b-4a33-8668-484321486e51",
                        "1474446b-580c-4a5d-bb69-4c228264f66e",
                        "18819165-7f73-4da1-9bf2-792c258be677",
                        "4c90c75e-cebe-4dd8-bfa3-87bf768cdbdc",
                        "8f6cafa9-28c3-424e-87bd-c28c8e57a44f",
                        "8f9e92cf-f266-4e51-807f-c098a260a0dc",
                        "9167c2df-4b86-4b47-98c9-3807261c343a",
                        "92a82b3c-5c2d-4331-9e28-eb023f429f2b",
                        "940e7ab9-c036-4e6a-8942-b90dc6b9c339",
                        "94b095a5-74ad-47ec-a39d-8dc877b2ef1e",
                        "9a3e62d9-2d53-41de-8db3-b896dce42ac3",
                        "bb02f0c6-3f59-4545-b72b-95dfdacea506"
                    ],
                    "keyword": [
                        "networks",
                        "central",
                        "studying",
                        "problems",
                        "methods",
                        "communities",
                        "topological",
                        "structures",
                        "property",
                        "nodes"
                    ],
                    "group": [],
                    "_id": "5215ff24-af48-4682-8c59-fe9db5fd4515",
                    "abstract": "One of the central problems in studying and understanding complex networks, such as online social networks or World Wide Web, is to discover hidden, either physically (e.g., interactions or hyperlinks) or logically (e.g., profiles or semantics) well-defined topological structures. From a practical point of view, a good example of such structures would be so-called network communities. Earlier studies have introduced various formulations as well as methods for the problem of identifying or extracting communities. While each of them has pros and cons as far as the effectiveness and efficiency are concerned, almost none of them has explicitly dealt with the potential relationship between the global topological property of a network and the local property of individual nodes. In order to study this problem, this paper presents a new algorithm, called ICS, which aims to discover natural network communities by inferring from the local information of nodes inherently hidden in networks based on a new centrality, that is, clustering centrality, which is a generalization of eigenvector centrality. As compared with existing methods, our method runs efficiently with a good clustering performance. Additionally, it is insensitive to its built-in parameters and prior knowledge.",
                    "title": "Discovering global network communities based on local centralities",
                    "venue": "ACM Transactions on The Web",
                    "year": 2008,
                    "__v": 1,
                    "citationCount": 12,
                    "result": 7.5172383791552155
                },
                "56aacaea-4377-41f7-9e73-0dcdd25984fc": {
                    "authors": [
                        "Renaud Lambiotte",
                        "Jean-Charles Delvenne",
                        "Mauricio Barahona"
                    ],
                    "references": [
                        "0285051d-2ed6-4965-8498-30c4abf6a406",
                        "0cdb081e-f2db-49d9-8c65-45cbcc948265",
                        "0d6a426e-79ad-4747-b0c6-537078ba6e70",
                        "1dbcac1a-7b93-4d45-9576-ae0bff19b7e7",
                        "2ae42d91-fc91-472f-bd7f-426f09e6f912",
                        "3e1c7e71-b0ee-4ddd-8fb9-09a6bf51181f",
                        "3e5fd33f-1fd0-4815-a47a-3c41a26a538a",
                        "4aa004c0-0833-4ba2-a6ee-6c9af9696851",
                        "68faab18-b537-4f62-85cf-ddc9ef352362",
                        "6b7f76d4-3816-4baf-ab4a-7bab66ec68d3",
                        "75338da2-345d-46f9-a85e-364219264773",
                        "756e5f32-dade-48dc-9271-5ca96ce73d0f",
                        "87d8ffaa-9e66-4e1f-88fd-cdfdab02fb29",
                        "9167c2df-4b86-4b47-98c9-3807261c343a",
                        "9ce54ae7-19f5-423e-bf83-5e0eb187d460",
                        "9df2aa63-11f9-4a64-b6c4-1fef1f8cde91",
                        "ab35dc68-62bd-4c54-81d3-9a8406827489",
                        "ad947bd3-2510-40b0-be63-4c2643d05fba",
                        "ae52879e-54a8-4fb2-ae54-ac64891f7a27",
                        "b0ef6e4d-4c86-4b10-9e0a-7b630ca8d7f7",
                        "b6c8bcad-70a8-4d76-82f7-109c0439a645",
                        "d7ad566c-4a36-49b8-9a55-8421d3285176",
                        "d9162547-fd7f-4605-855d-0a3173c4b08e",
                        "ea1d5c21-fba6-4fae-9fdc-ee7679ee46c9",
                        "ee6d8660-320d-4705-a19a-25562b96523a",
                        "f6d4b5b4-6217-419f-997d-2472db60abe5"
                    ],
                    "keyword": [
                        "communities",
                        "graph",
                        "markov",
                        "dynamical",
                        "quality",
                        "optimized",
                        "function",
                        "framework",
                        "detection"
                    ],
                    "group": [],
                    "_id": "56aacaea-4377-41f7-9e73-0dcdd25984fc",
                    "abstract": "Most methods proposed to uncover communities in complex networks rely on combinatorial graph properties. Usually an edge-counting quality function, such as modularity, is optimized over all partitions of the graph compared against a null random graph model. Here we introduce a systematic dynamical framework to design and analyze a wide variety of quality functions for community detection. The quality of a partition is measured by its Markov Stability, a time-parametrized function defined in terms of the statistical properties of a Markov process taking place on the graph. The Markov process provides a dynamical sweeping across all scales in the graph, and the time scale is an intrinsic parameter that uncovers communities at different resolutions. This dynamic-based community detection leads to a compound optimization, which favours communities of comparable centrality (as defined by the stationary distribution), and provides a unifying framework for spectral algorithms, as well as different heuristics for community detection, including versions of modularity and Potts model. Our dynamic framework creates a systematic link between different stochastic dynamics and their corresponding notions of optimal communities under distinct (node and edge) centralities. We show that the Markov Stability can be computed efficiently to find multi-scale community structure in large networks.",
                    "title": "Random Walks, Markov Processes and the Multiscale Modular Organization of Complex Networks",
                    "venue": "IEEE Transactions on Network Science and Engineering",
                    "year": 2014,
                    "__v": 1,
                    "citationCount": 68,
                    "result": 5.571300368196386
                },
                "597ecf84-4084-4057-a40d-30988ef74121": {
                    "authors": [
                        "Petter Holme",
                        "Mikael Huss",
                        "Hawoong Jeong"
                    ],
                    "references": [
                        "a6a89259-271d-43af-afb6-b6d6e9318e4e",
                        "cf8e8e5f-67b3-48d6-b6ba-df301b76b7e2",
                        "d536f87d-bbda-42a1-b55f-63f83bfd85da",
                        "ee10a31e-7efd-4a19-8c15-4b5a0ac0907d"
                    ],
                    "keyword": [
                        "networks",
                        "vastness",
                        "subnetworks",
                        "nonlocal",
                        "motivation",
                        "modern",
                        "mapped",
                        "inherent",
                        "genomics",
                        "decomposition"
                    ],
                    "group": [],
                    "_id": "597ecf84-4084-4057-a40d-30988ef74121",
                    "abstract": "Motivation: The vastness and complexity of the biochemical networks that have been mapped out by modern genomics calls for decomposition into subnetworks. Such networks can have inherent non-local  ...",
                    "title": "Subnetwork hierarchies of biochemical pathways",
                    "venue": "Bioinformatics",
                    "year": 2003,
                    "__v": 2,
                    "citationCount": 79,
                    "result": 4.135703646647246
                },
                "5e3020bb-324a-4926-963c-36f66eda1b27": {
                    "authors": [
                        "Vladimir Gudkov",
                        "Vladimir Montealegre"
                    ],
                    "references": [],
                    "keyword": [
                        "networks",
                        "method",
                        "dse",
                        "detect",
                        "complex",
                        "communities",
                        "welldefined",
                        "substructures",
                        "simplex",
                        "random"
                    ],
                    "group": [],
                    "_id": "5e3020bb-324a-4926-963c-36f66eda1b27",
                    "abstract": "We benchmark the dynamical simplex evolution (DSE) method with several of the currently available algorithms to detect communities in complex networks by comparing correctly identified nodes for different levels of \"fuzziness\" of random networks composed of well-defined communities. The potential benefits of the DSE method to detect hierarchical substructures in complex networks are discussed.",
                    "title": "Community Detection in Complex Networks by Dynamical Simplex Evolution",
                    "venue": "Physical Review E",
                    "year": 2008,
                    "__v": 1,
                    "citationCount": 7,
                    "result": 4.057656664837981
                },
                "5f1a52f2-faca-45ab-bb82-8d459d1c77ce": {
                    "authors": [
                        "Balachander Krishnamurthy",
                        "Jia Wang"
                    ],
                    "references": [
                        "10619753-15e6-4fe3-9f51-49680504e3b2",
                        "36f0f3cb-6b32-4284-8e08-0972ee67074f",
                        "6c30c592-28a5-4a03-80ee-92e759fbea3a",
                        "e80c59fb-2f00-48b1-845a-a46e18afca99"
                    ],
                    "keyword": [
                        "clients",
                        "web",
                        "groups",
                        "site's",
                        "responsible",
                        "requests",
                        "identify",
                        "clusters",
                        "topologically",
                        "table"
                    ],
                    "group": [],
                    "_id": "5f1a52f2-faca-45ab-bb82-8d459d1c77ce",
                    "abstract": "Being able to identify the groups of clients that are responsible for a significant portion of a Web site's requests can be helpful to both the Web site and the clients. In a Web application, it is beneficial to move content closer to groups of clients that are responsible for large subsets of requests to an origin server. We introduce  clusters ---a grouping of clients that are close together topologically and likely to be under common administrative control. We identify clusters using a ``network-aware\" method, based on information available from BGP routing table snapshots.",
                    "title": "On network-aware clustering of Web clients",
                    "venue": "acm special interest group on data communication",
                    "year": 2000,
                    "__v": 2,
                    "citationCount": 186,
                    "result": 6.362823571337504
                },
                "608ab163-0fbf-4c6e-bf21-29b3145bae2a": {
                    "authors": [
                        "Pablo M. Gleiser",
                        "Leon Danon"
                    ],
                    "references": [
                        "60ef3852-fa16-44bf-9434-9909268ba5d8",
                        "b0ef6e4d-4c86-4b10-9e0a-7b630ca8d7f7",
                        "f15b19f2-4b37-454c-851e-a71cccf3e53a"
                    ],
                    "keyword": [
                        "network",
                        "musicians",
                        "study",
                        "jazz",
                        "community",
                        "collaboration",
                        "band",
                        "structure",
                        "social",
                        "reveals"
                    ],
                    "group": [],
                    "_id": "608ab163-0fbf-4c6e-bf21-29b3145bae2a",
                    "abstract": "Using a database of jazz recordings we study the collaboration network of jazz musicians. We define the network at two different levels. First we study the collaboration network between individuals, where two musicians are connected if they have played in the same band. Then we consider the collaboration between bands, where two bands are connected if they have a musician in common. The community structure analysis reveals that these constructions capture essential ingredients of the social interactions between jazz musicians. We observe correlations between recording locations, racial segregation and the community structure. A quantitative analysis of the community size distribution reveals a surprising similarity with an e-mail based social network recently studied.",
                    "title": "COMMUNITY STRUCTURE IN JAZZ",
                    "venue": "Advances in Complex Systems",
                    "year": 2003,
                    "__v": 1,
                    "citationCount": 166,
                    "result": 5.0570253178114495
                },
                "60ef3852-fa16-44bf-9434-9909268ba5d8": {
                    "authors": [
                        "Réka Albert",
                        "Albert-László Barabási"
                    ],
                    "references": [],
                    "keyword": [
                        "networks",
                        "nodes",
                        "degree",
                        "systems",
                        "real",
                        "distribution",
                        "topology",
                        "random",
                        "modeling"
                    ],
                    "group": [
                        null
                    ],
                    "_id": "60ef3852-fa16-44bf-9434-9909268ba5d8",
                    "abstract": "The emergence of order in natural systems is a constant source of inspiration for both physical and biological sciences. While the spatial order characterizing for example the crystals has been the basis of many advances in contemporary physics, most complex systems in nature do not offer such high degree of order. Many of these systems form complex networks whose nodes are the elements of the system and edges represent the interactions between them. #R##N#Traditionally complex networks have been described by the random graph theory founded in 1959 by Paul Erdohs and Alfred Renyi. One of the defining features of random graphs is that they are statistically homogeneous, and their degree distribution (characterizing the spread in the number of edges starting from a node) is a Poisson distribution. In contrast, recent empirical studies, including the work of our group, indicate that the topology of real networks is much richer than that of random graphs. In particular, the degree distribution of real networks is a power-law, indicating a heterogeneous topology in which the majority of the nodes have a small degree, but there is a significant fraction of highly connected nodes that play an important role in the connectivity of the network. #R##N#The scale-free topology of real networks has very important consequences on their functioning. For example, we have discovered that scale-free networks are extremely resilient to the random disruption of their nodes. On the other hand, the selective removal of the nodes with highest degree induces a rapid breakdown of the network to isolated subparts that cannot communicate with each other. #R##N#The non-trivial scaling of the degree distribution of real networks is also an indication of their assembly and evolution. Indeed, our modeling studies have shown us that there are general principles governing the evolution of networks. Most networks start from a small seed and grow by the addition of new nodes which attach to the nodes already in the system. This process obeys preferential attachment: the new nodes are more likely to connect to nodes with already high degree. We have proposed a simple model based on these two principles wich was able to reproduce the power-law degree distribution of real networks. Perhaps even more importantly, this model paved the way to a new paradigm of network modeling, trying to capture the evolution of networks, not just their static topology.",
                    "title": "Statistical mechanics of complex networks",
                    "venue": "Reviews of Modern Physics",
                    "year": 2001,
                    "__v": 3,
                    "citationCount": 3029,
                    "result": 4.945410961587433
                },
                "63ec4f55-8f3b-431e-88e5-87c04caa7e9f": {
                    "authors": [
                        "Lars W. Hagen",
                        "Andrew B. Kahng"
                    ],
                    "references": [
                        "1214493c-3497-4eab-87dc-53ff98882bad",
                        "1722ff88-e788-4e0c-86cd-6551b75eabca",
                        "614c4a46-08bb-48fa-94a4-8c05d65a24f7",
                        "63139dcf-11e2-4b8e-bcbd-ebd1f0511389",
                        "679f537b-1aa2-4977-9255-8f1a3d021246",
                        "6f7517aa-b3dd-4289-a44e-42cec8ef0370",
                        "8b7e9a42-ef7f-41f1-970b-6d05d65c8b40",
                        "cab30a53-0314-48f3-9ff9-e4438cc109f8",
                        "dc88af6e-158d-4a2e-badd-2afaf5c95648",
                        "e30d86fe-546b-45ed-9463-d6305c08a006",
                        "ea90d7c2-28ad-48c1-8e34-a29d0e4f1419",
                        "eea2da24-467e-4179-acb9-ae3c24591119",
                        "f078efcf-4e45-49cb-a9d1-0886eedfcfc6",
                        "ff1609ce-c9ab-41e5-b7cb-481d5a51693e"
                    ],
                    "keyword": [
                        "partitioning",
                        "netlists",
                        "ratio",
                        "heuristic",
                        "eigenvalue",
                        "cut",
                        "proposed",
                        "methods",
                        "intersection",
                        "graph"
                    ],
                    "group": [],
                    "_id": "63ec4f55-8f3b-431e-88e5-87c04caa7e9f",
                    "abstract": "Partitioning of circuit netlists in VLSI design is considered. It is shown that the second smallest eigenvalue of a matrix derived from the netlist gives a provably good approximation of the optimal ratio cut partition cost. It is also demonstrated that fast Lanczos-type methods for the sparse symmetric eigenvalue problem are a robust basis for computing heuristic ratio cuts based on the eigenvector of this second eigenvalue. Effective clustering methods are an immediate by-product of the second eigenvector computation and are very successful on the difficult input classes proposed in the CAD literature. The intersection graph representation of the circuit netlist is considered, as a basis for partitioning, a heuristic based on spectral ratio cut partitioning of the netlist intersection graph is proposed. The partitioning heuristics were tested on industry benchmark suites, and the results were good in terms of both solution quality and runtime. Several types of algorithmic speedups and directions for future work are discussed. >",
                    "title": "Fast spectral methods for ratio cut partitioning and clustering",
                    "venue": "international conference on computer aided design",
                    "year": 1991,
                    "__v": 2,
                    "citationCount": 383,
                    "result": 5.898254317654873
                },
                "646fd5f1-1f89-40a7-b605-8402513ae682": {
                    "authors": [
                        "Nikhil Bansal",
                        "Avrim Blum",
                        "Shuchi Chawla"
                    ],
                    "references": [
                        "0ddbeed7-f2e3-41ac-a429-54a44be76f53",
                        "2f1292f0-289a-45e8-87ac-ea4a35c99649",
                        "3ea42300-0191-4c77-92dc-eb9626b43e82",
                        "3fea26ac-637a-4916-aa27-2e633ba0cfbd",
                        "53ea71d5-ce12-4ca6-8f3e-c07b0a8505cb",
                        "628ac4a5-9092-4c9c-ae5f-879c5f93d669",
                        "63032127-4928-4ee3-b874-399b7fcadb2d",
                        "691e7002-cce5-49f3-9ae1-029b2037b555",
                        "75830a91-6bd3-47b9-a517-5e1e0b68bf04",
                        "7bd576b4-5791-4756-b00d-76bfadb5c78f",
                        "93b14f9a-884c-441a-b91d-66a659248c0d",
                        "9c17488a-82f6-46cc-95e1-e0016fd8bf03",
                        "a0695446-05d0-4499-92d5-f44bb4ce94e6",
                        "c58d05c1-ef5e-4c04-9cc4-8e6198685861",
                        "c5f76d69-6616-49aa-8130-8cdc32c48124",
                        "e4e5c3a5-2473-4cea-8e0f-13bc369e4d6a",
                        "f1169046-1125-4633-bd90-bd9e217e91ed",
                        "f99a6b3a-0980-4a9e-bbce-f9397c45106f"
                    ],
                    "keyword": [
                        "clustering",
                        "edge",
                        "number",
                        "labeled",
                        "problem",
                        "minimizes",
                        "maximizes",
                        "give",
                        "formulation",
                        "disagreements"
                    ],
                    "group": [],
                    "_id": "646fd5f1-1f89-40a7-b605-8402513ae682",
                    "abstract": "We consider the following clustering problem: we have a complete graph on n vertices (items), where each edge (u, v) is labeled either + or − depending on whether u and v have been deemed to be similar or different. The goal is to produce a partition of the vertices (a clustering) that agrees as much as possible with the edge labels. That is, we want a clustering that maximizes the number of + edges within clusters, plus the number of − edges between clusters (equivalently, minimizes the number of disagreements: the number of − edges inside clusters plus the number of + edges between clusters). This formulation is motivated from a document clustering problem in which one has a pairwise similarity function f learned from past data, and the goal is to partition the current set of documents in a way that correlates with f as much as possibles it can also be viewed as a kind of “agnostic learning” problem.#R##N##R##N#An interesting feature of this clustering formulation is that one does not need to specify the number of clusters k as a separate parameter, as in measures such as k-median or min-sum or min-max clustering. Instead, in our formulation, the optimal number of clusters could be any value between 1 and n, depending on the edge labels. We look at approximation algorithms for both minimizing disagreements and for maximizing agreements. For minimizing disagreements, we give a constant factor approximation. For maximizing agreements we give a PTAS, building on ideas of Goldreich, Goldwasser, and Ron (1998) and de la Veg (1996). We also show how to extend some of these results to graphs with edge labels in [−1, +1], and give some results for the case of random noise.",
                    "title": "Correlation Clustering",
                    "venue": "",
                    "year": 2004,
                    "__v": 2,
                    "citationCount": 381,
                    "result": 5.834680721973996
                },
                "68f5a094-18a6-4250-85de-214f7840bc6b": {
                    "authors": [
                        "Marina Meila",
                        "David Heckerman"
                    ],
                    "references": [
                        "1017d9d4-9a4c-423d-ad40-6d9bebbd6b31",
                        "19f7014f-6507-4097-95e9-085442ab13cc",
                        "592e8a18-27bf-4561-89d2-01afb204534d",
                        "75688d20-068c-4c13-ae88-dde5f3b4abaa",
                        "779eeee0-44fa-410f-ad0a-092cad0917b2",
                        "85168cf8-e1cc-4d32-91e3-11817038f489",
                        "e6cbd7a8-7b5d-4b0e-b3ae-4f541bfea6d8",
                        "fb30cc06-7551-4da0-b5e2-7648a2457b12"
                    ],
                    "keyword": [
                        "algorithms",
                        "model",
                        "em",
                        "methods",
                        "clustering",
                        "parameters",
                        "modelbased",
                        "learn",
                        "initialization",
                        "agglomerative"
                    ],
                    "group": [],
                    "_id": "68f5a094-18a6-4250-85de-214f7840bc6b",
                    "abstract": "We compare the three basic algorithms for model-based clustering on high-dimensional discrete-variable datasets. All three algorithms use the same underlying model: a naive-Bayes model with a hidden root node, also known as a multinomial-mixture model. In the first part of the paper, we perform an experimental comparison between three batch algorithms that learn the parameters of this model: the Expectation–Maximization (EM) algorithm, a “winner take all” version of the EM algorithm reminiscent of the K-means algorithm, and model-based agglomerative clustering. We find that the EM algorithm significantly outperforms the other methods, and proceed to investigate the effect of various initialization methods on the final solution produced by the EM algorithm. The initializations that we consider are (1) parameters sampled from an uninformative prior, (2) random perturbations of the marginal distribution of the data, and (3) the output of agglomerative clustering. Although the methods are substantially different, they lead to learned models that are similar in quality.",
                    "title": "An Experimental Comparison of Model-Based Clustering Methods",
                    "venue": "Machine Learning",
                    "year": 2001,
                    "__v": 2,
                    "citationCount": 76,
                    "result": 5.376620011432908
                },
                "756e5f32-dade-48dc-9271-5ca96ce73d0f": {
                    "authors": [
                        "Alex Arenas",
                        "Jordi Duch",
                        "Alberto Fernandez",
                        "Sergio Gómez"
                    ],
                    "references": [
                        "608ab163-0fbf-4c6e-bf21-29b3145bae2a"
                    ],
                    "keyword": [
                        "modular",
                        "size",
                        "optimization",
                        "networks",
                        "reduction",
                        "complex",
                        "structure",
                        "propose",
                        "obtained",
                        "functionality"
                    ],
                    "group": [],
                    "_id": "756e5f32-dade-48dc-9271-5ca96ce73d0f",
                    "abstract": "The ubiquity of modular structure in real-world complex networks is being the focus of attention in many trials to understand the interplay between network topology and functionality. The best approaches to the identification of modular structure are based on the optimization of a quality function known as modularity. However this optimization is a hard task provided that the computational complexity of the problem is in the NP-hard class. Here we propose an exact method for reducing the size of weighted (directed and undirected) complex networks while maintaining invariant its modularity. This size reduction allows the heuristic algorithms that optimize modularity for a better exploration of the modularity landscape. We compare the modularity obtained in several real complex-networks by using the Extremal Optimization algorithm, before and after the size reduction, showing the improvement obtained. We speculate that the proposed analytical size reduction could be extended to an exact coarse graining of the network in the scope of real-space renormalization.",
                    "title": "Size reduction of complex networks preserving modularity",
                    "venue": "New Journal of Physics",
                    "year": 2007,
                    "__v": 2,
                    "citationCount": 78,
                    "result": 3.6629664171495806
                },
                "75830a91-6bd3-47b9-a517-5e1e0b68bf04": {
                    "authors": [
                        "Anne Condon",
                        "Richard M. Karp"
                    ],
                    "references": [
                        "67438f8b-1a4f-4cfb-af74-2911ff03db6f",
                        "679f537b-1aa2-4977-9255-8f1a3d021246",
                        "6ccec23e-d1ac-4f52-b87f-65ad55d09778",
                        "75ceda8c-9668-44bf-be09-482c3709d523",
                        "7b2b02cc-b743-474a-968a-f1f5fbe025a6",
                        "8110182e-b1fc-455d-83ff-4d51a55d02a5",
                        "caec8c02-0227-48f6-82ad-2f31e5bd6605",
                        "f724a9b0-e839-4590-9c73-3a42e436c0c7",
                        "ff1609ce-c9ab-41e5-b7cb-481d5a51693e"
                    ],
                    "keyword": [
                        "groups",
                        "graph",
                        "partition",
                        "nodes",
                        "edges",
                        "problem",
                        "probability",
                        "lpartition",
                        "undirected",
                        "random"
                    ],
                    "group": [],
                    "_id": "75830a91-6bd3-47b9-a517-5e1e0b68bf04",
                    "abstract": "Abstract#R##N##R##N#The NP-hard graph bisection problem is to partition the nodes of an undirected graph into two equal-sized groups so as to minimize the number of edges that cross the partition. The more general graph l-partition problem is to partition the nodes of an undirected graph into l equal-sized groups so as to minimize the total number of edges that cross between groups. We present a simple, linear-time algorithm for the graph l-partition problem and we analyze it on a random “planted l-partition” model. In this model, the n nodes of a graph are partitioned into l groups, each of size n/l; two nodes in the same group are connected by an edge with some probability p, and two nodes in different groups are connected by an edge with some probability r<p. We show that if p−r≥n−1/2+ϵ for some constant ϵ, then the algorithm finds the optimal partition with probability 1− exp(−nΘ(e)). © 2001 John Wiley & Sons, Inc. Random Struct. Alg., 18: 116–140, 2001",
                    "title": "Algorithms for graph partitioning on the planted partition model",
                    "venue": "Random Structures and Algorithms",
                    "year": 2001,
                    "__v": 1,
                    "citationCount": 158,
                    "result": 5.958298684459675
                },
                "76395316-a3bc-43c9-9113-cf11eff1ccbf": {
                    "authors": [
                        "Yudong Sun",
                        "Bogdan Danila",
                        "Krešimir Josić",
                        "Kevin E. Bassler"
                    ],
                    "references": [],
                    "keyword": [
                        "algorithms",
                        "step",
                        "results",
                        "network",
                        "finding",
                        "show",
                        "proposed",
                        "partitioning",
                        "effectiveness",
                        "complex"
                    ],
                    "group": [],
                    "_id": "76395316-a3bc-43c9-9113-cf11eff1ccbf",
                    "abstract": "The community structure of a complex network can be determined by finding the partitioning of its nodes that maximizes modularity. Many of the proposed algorithms for doing this work by recursively bisecting the network. We show that this unduely constrains their results, leading to a bias in the size of the communities they find and limiting their effectiveness. To solve this problem, we propose adding a step, which is a modification of the Kernighan-Lin algorithm, to the existing algorithms. This additional step does not increase the order of their computational complexity. We show that, if this step is combined with a commonly used method, the identified constraint and resulting bias are removed, and its ability to find the optimal partitioning is improved. The effectiveness of this combined algorithm is also demonstrated by using it on real-world example networks. For a number of these examples, it achieves the best results of any known algorithm.",
                    "title": "Improved community structure detection using a modified fine tuning strategy",
                    "venue": "EPL",
                    "year": 2009,
                    "__v": 1,
                    "citationCount": 19,
                    "result": 5.358495906883982
                },
                "764a3426-aaea-4b4a-a692-a6cc215fe34e": {
                    "authors": [
                        "Ernesto Estrada",
                        "Naomichi Hatano"
                    ],
                    "references": [
                        "b0ef6e4d-4c86-4b10-9e0a-7b630ca8d7f7",
                        "b6c8bcad-70a8-4d76-82f7-109c0439a645",
                        "c6831026-e260-46f3-8472-846856fd4e24",
                        "d85fb16f-9e7d-409f-9133-bffc8a57508a",
                        "e43d7ff9-a981-4a45-85f6-6be4568d4e29",
                        "e6d5b127-aa36-4add-971a-aa4dc2689baa"
                    ],
                    "keyword": [
                        "network",
                        "communities",
                        "communicability",
                        "complex",
                        "airport",
                        "concept",
                        "algorithm",
                        "problem",
                        "nodes",
                        "detection"
                    ],
                    "group": [],
                    "_id": "764a3426-aaea-4b4a-a692-a6cc215fe34e",
                    "abstract": "We use the concept of the network communicability [E. Estrada, N. Hatano, Communicability in complex networks, Phys. Rev. E 77 (2008) 036111] to define communities in a complex network. The communities are defined as the cliques of a ''communicability graph'', which has the same set of nodes as the complex network and links determined by the communicability function. Then, the problem of finding the network communities is transformed to an all-clique problem of the communicability graph. We discuss the efficiency of this algorithm of community detection. In addition, we extend here the concept of the communicability to account for the strength of the interactions between the nodes by using the concept of inverse temperature of the network. Finally, we develop an algorithm to manage the different degrees of overlapping between the communities in a complex network. We then analyze the USA airport network, for which we successfully detect two big communities of the eastern airports and of the western/central airports as well as two bridging central communities. In striking contrast, a well-known algorithm groups all but two of the continental airports into one community.",
                    "title": "Communicability graph and community structures in complex networks",
                    "venue": "Applied Mathematics and Computation",
                    "year": 2009,
                    "__v": 1,
                    "citationCount": 19,
                    "result": 6.636621567346452
                },
                "79433674-7ae3-4613-9914-2db2b16fd01f": {
                    "authors": [
                        "William Y. C. Chen",
                        "Andreas W. M. Dress",
                        "Winking Q. Yu"
                    ],
                    "references": [
                        "090a55a8-73b0-4f07-9467-fadeac63cc44",
                        "18819165-7f73-4da1-9bf2-792c258be677",
                        "9167c2df-4b86-4b47-98c9-3807261c343a",
                        "940e7ab9-c036-4e6a-8942-b90dc6b9c339",
                        "a3941c59-604d-4593-b4a2-881484a3d3b0",
                        "a78f446d-50ea-4445-aa89-b5da9ff22358",
                        "b2ccdd1f-c7fe-436b-9be4-6cf02e5436ba",
                        "cede414d-501e-4247-a650-42240f00a401",
                        "f15b19f2-4b37-454c-851e-a71cccf3e53a",
                        "fedf9041-1533-4660-9a5a-887cf3c9e6f3"
                    ],
                    "keyword": [
                        "networks",
                        "edges",
                        "structures",
                        "nodes",
                        "cost",
                        "community",
                        "collection",
                        "approach",
                        "union",
                        "terms"
                    ],
                    "group": [],
                    "_id": "79433674-7ae3-4613-9914-2db2b16fd01f",
                    "abstract": "We present an approach to studying the community structures of networks by using linear programming (LP). Starting with a network in terms of (a) a collection of nodes and (b) a collection of edges connecting some of these nodes, we use a new LP-based method for simultaneously (i) finding, at minimal cost, a second edge set by deleting existing and inserting additional edges so that the network becomes a disjoint union of cliques and (ii) appropriately calibrating the costs for doing so. We provide examples that suggest that, in practice, this approach provides a surprisingly good strategy for detecting community structures in given networks.",
                    "title": "Community Structures of Networks",
                    "venue": "Mathematics in Computer Science",
                    "year": 2008,
                    "__v": 2,
                    "citationCount": 7,
                    "result": 5.820211352767134
                },
                "7c90045b-63b9-4f29-82a0-bf7c914a6ef6": {
                    "authors": [
                        "Ulrike von Luxburg"
                    ],
                    "references": [
                        "05bbaec3-7980-4941-8638-2bbfa4ac8be0",
                        "05c81472-37d6-460f-9343-675d70402c7e",
                        "089053a7-cf4b-43fa-9c17-e1e13cdc9278",
                        "0a3876f3-df2f-4dd8-b2a1-53bfe7714348",
                        "0cdb081e-f2db-49d9-8c65-45cbcc948265",
                        "158f4525-404a-4ffc-be57-51f02a53445c",
                        "1b806dc6-7d06-48c4-b8a9-16111d135559",
                        "213ccf22-1ea7-42a3-8369-644a47a5fbe2",
                        "2cd6f789-de0b-4d5d-b3d0-60962bd31d41",
                        "31d1a3f9-73ab-4dd3-8977-6b322e5ecc1d",
                        "3549c862-c615-4f80-ac53-f562d3e2b846",
                        "3b64a259-80c2-4b82-9c04-34a0ee4a20aa",
                        "3e1c7e71-b0ee-4ddd-8fb9-09a6bf51181f",
                        "44d7e2c1-7a65-4fb8-86e5-ea0bfdad98e9",
                        "4d4df750-7647-42f4-b1bb-120d91bc0352",
                        "5d3ddeee-5a39-49b8-8fa3-28099a31f7aa",
                        "63ec4f55-8f3b-431e-88e5-87c04caa7e9f",
                        "7a1a3bf9-8c23-4c13-8c8e-85b79ad6143e",
                        "7ec5f06e-2fe3-495a-84a0-94fcfe08bb7b",
                        "82a4ef1a-c503-49bd-a2f4-34d13537a5f1",
                        "89492dcb-ea5d-4dda-a5fb-687818cbe384",
                        "98da593f-2756-4d08-b67b-f8c610f41354",
                        "991b5edd-202d-4194-ac57-e2edb1fb0201",
                        "9fa127d1-10cf-4a8b-b938-bcb079cbc96c",
                        "a64c03c2-ba6c-4cc5-afc1-16b4108ea29d",
                        "a7da3014-5be5-49a0-a77c-4271633b941c",
                        "b6208d93-998c-4593-b2d9-1d3ff936750f",
                        "bd55a32a-8dab-4551-806c-bce9e4a32c67",
                        "d33a7b23-08c6-4de6-95c8-e3b6bf8c16bb",
                        "dd90433d-a428-4ff1-833d-050702f7699c",
                        "ea8cd3d8-17ae-4a1e-8f83-1609469087af",
                        "f3b1b423-aa89-4484-b985-666ee01b06c4",
                        "f99a6b3a-0980-4a9e-bbce-f9397c45106f"
                    ],
                    "keyword": [
                        "clustering",
                        "algorithms",
                        "spectral"
                    ],
                    "group": [],
                    "_id": "7c90045b-63b9-4f29-82a0-bf7c914a6ef6",
                    "abstract": "In recent years, spectral clustering has become one of the most popular modern clustering algorithms. It is simple to implement, can be solved efficiently by standard linear algebra software, and very often outperforms traditional clustering algorithms such as the k-means algorithm. On the first glance spectral clustering appears slightly mysterious, and it is not obvious to see why it works at all and what it really does. The goal of this tutorial is to give some intuition on those questions. We describe different graph Laplacians and their basic properties, present the most common spectral clustering algorithms, and derive those algorithms from scratch by several different approaches. Advantages and disadvantages of the different spectral clustering algorithms are discussed.",
                    "title": "A tutorial on spectral clustering",
                    "venue": "Statistics and Computing",
                    "year": 2007,
                    "__v": 1,
                    "citationCount": 2009,
                    "result": 2.9181259860265945
                },
                "7d4be6a0-afa0-4c75-a3dd-e04b3cd0b874": {
                    "authors": [
                        "Nan Du",
                        "Bai Wang",
                        "Bin Wu",
                        "Yi Wang"
                    ],
                    "references": [],
                    "keyword": [
                        "networks",
                        "community",
                        "structures",
                        "overlapping",
                        "bitector",
                        "bipartite",
                        "algorithm",
                        "sparse",
                        "society",
                        "showing"
                    ],
                    "group": [],
                    "_id": "7d4be6a0-afa0-4c75-a3dd-e04b3cd0b874",
                    "abstract": "Recent researches have discovered that rich interactions among entities in nature and human society bring about complex networks with community structures. In this paper, we propose a novel algorithm BiTector (Bi-community DeTector) to mine the overlapping communities in large-scale sparse bipartite networks. We apply the algorithm to various real-world datasets, showing that BiTector can identify the overlapping community structures in the bipartite networks efficiently and effectively.",
                    "title": "Overlapping Community Detection in Bipartite Networks",
                    "venue": "web intelligence",
                    "year": 2008,
                    "__v": 2,
                    "citationCount": 18,
                    "result": 5.419345351930492
                },
                "86b69247-af69-4276-a105-b5e821559946": {
                    "authors": [
                        "Inderjit S. Dhillon",
                        "Yuqiang Guan",
                        "Brian Kulis"
                    ],
                    "references": [
                        "243298e6-89e2-4291-a354-9764bd40a1a4",
                        "2ba8193c-58e1-46fb-9f4c-5c3e393cf5c0",
                        "4df853eb-d37f-4cff-96d0-4bba374e4a01",
                        "4ee20287-bd56-400a-9164-10b007c2a387",
                        "57a4c414-6c90-4977-abab-ccf563e92c6b",
                        "5c89ee50-d7f5-4cd6-8eed-19a08efd6f90",
                        "64707a64-e9f8-4117-b828-e1905366b06c",
                        "65838144-9870-49a5-aa9a-4d2e408292a2",
                        "93b8f6ed-865d-4698-8556-d7a8713afbf8",
                        "94898e1d-1e50-41ab-9dcc-2c2e030cddd0",
                        "991b5edd-202d-4194-ac57-e2edb1fb0201",
                        "b1e63971-42d0-43f0-8d71-be74deadc4ed",
                        "c8c88c99-84c5-4988-bfa4-72f03bd8a74f",
                        "cede414d-501e-4247-a650-42240f00a401",
                        "ea8cd3d8-17ae-4a1e-8f83-1609469087af"
                    ],
                    "keyword": [
                        "clustering",
                        "graph",
                        "algorithms",
                        "weighted",
                        "objective",
                        "multilevel",
                        "methods",
                        "kmeans",
                        "kernel",
                        "equivalence"
                    ],
                    "group": [],
                    "_id": "86b69247-af69-4276-a105-b5e821559946",
                    "abstract": "A variety of clustering algorithms have recently been proposed to handle data that is not linearly separable; spectral clustering and kernel k-means are two of the main methods. In this paper, we discuss an equivalence between the objective functions used in these seemingly different methods - in particular, a general weighted kernel k-means objective is  mathematically equivalent  to a weighted graph clustering objective. We exploit this equivalence to develop a fast high-quality multilevel algorithm that directly optimizes various weighted graph clustering objectives, such as the popular ratio cut, normalized cut, and ratio association criteria. This eliminates the need for any eigenvector computation for graph clustering problems, which can be prohibitive for very large graphs. Previous multilevel graph partitioning methods such as Metis have suffered from the restriction of equal-sized clusters; our multilevel algorithm removes this restriction by using kernel k-means to optimize weighted graph cuts. Experimental results show that our multilevel algorithm outperforms a state-of-the-art spectral clustering algorithm in terms of speed, memory usage, and quality. We demonstrate that our algorithm is applicable to large-scale clustering tasks such as image segmentation, social network analysis, and gene network analysis.",
                    "title": "Weighted Graph Cuts without Eigenvectors A Multilevel Approach",
                    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "year": 2007,
                    "__v": 2,
                    "citationCount": 298,
                    "result": 6.167369645051935
                },
                "881ffdab-0f89-4a72-8655-8bc3a3fc6577": {
                    "authors": [
                        "Lars Backstrom",
                        "Daniel P. Huttenlocher",
                        "Jon M. Kleinberg",
                        "Xiangyang Lan"
                    ],
                    "references": [
                        "0f115eea-2272-431f-9f21-6d6789b2bbc9",
                        "18819165-7f73-4da1-9bf2-792c258be677",
                        "2131b26d-48b9-4414-83a1-506e48eacadd",
                        "6f456564-1b70-4002-93d3-6ce341df9129",
                        "79b938b2-023d-44ae-9a9d-9ee73a3ac028",
                        "824bc599-cc29-4c79-9c43-e0ee0237f245",
                        "8f8dba5c-b91d-468d-9b92-8359843a2900",
                        "9863baf6-d69f-495a-8d5a-71442adea84e",
                        "a9dca587-4658-4504-ba1b-805a4c6f8439",
                        "ac14afe6-de4d-4056-b2ac-0f6e36f369a2",
                        "b2a5773c-be4b-4d8c-bbd9-1f1d0a09c5b5",
                        "b4795aa3-5d49-4e23-92ed-d20c81c750c7",
                        "b49c1e2b-0cd0-4950-a724-00c698e5b49d",
                        "c48b62a8-0c5b-4393-a4e1-a7719ddfece9",
                        "fcce3147-a07f-4066-8fb8-9e85a129af59"
                    ],
                    "keyword": [
                        "communities",
                        "structural",
                        "social",
                        "individuals",
                        "networking",
                        "movements",
                        "join",
                        "groups"
                    ],
                    "group": [],
                    "_id": "881ffdab-0f89-4a72-8655-8bc3a3fc6577",
                    "abstract": "The processes by which communities come together, attract new members, and develop over time is a central research issue in the social sciences - political movements, professional organizations, and religious denominations all provide fundamental examples of such communities. In the digital domain, on-line groups are becoming increasingly prominent due to the growth of community and social networking sites such as MySpace and LiveJournal. However, the challenge of collecting and analyzing large-scale time-resolved data on social groups and communities has left most basic questions about the evolution of such groups largely unresolved: what are the structural features that influence whether individuals will join communities, which communities will grow rapidly, and how do the overlaps among pairs of communities change over time.Here we address these questions using two large sources of data: friendship links and community membership on LiveJournal, and co-authorship and conference publications in DBLP. Both of these datasets provide explicit user-defined communities, where conferences serve as proxies for communities in DBLP. We study how the evolution of these communities relates to properties such as the structure of the underlying social networks. We find that the propensity of individuals to join communities, and of communities to grow rapidly, depends in subtle ways on the underlying network structure. For example, the tendency of an individual to join a community is influenced not just by the number of friends he or she has within the community, but also crucially by how those friends are connected to one another. We use decision-tree techniques to identify the most significant structural determinants of these properties. We also develop a novel methodology for measuring movement of individuals between communities, and show how such movements are closely aligned with changes in the topics of interest within the communities.",
                    "title": "Group formation in large social networks: membership, growth, and evolution",
                    "venue": "knowledge discovery and data mining",
                    "year": 2006,
                    "__v": 1,
                    "citationCount": 738,
                    "result": 4.851995227587734
                },
                "8e245630-549b-4b1c-afe7-cdf466295f32": {
                    "authors": [
                        "Uriel Feige",
                        "Guy Kortsarz",
                        "David Peleg"
                    ],
                    "references": [
                        "045f874b-4343-4334-ad73-3e4d49989577",
                        "34905a89-c798-49f7-b618-667834d4f175",
                        "60dafc55-cd3f-4c0c-a233-3a257f2d012b",
                        "63139dcf-11e2-4b8e-bcbd-ebd1f0511389",
                        "7b2b02cc-b743-474a-968a-f1f5fbe025a6",
                        "b29f89dc-71c5-4d7b-a138-9bb12685d206",
                        "b720b943-8232-487c-b2da-fa60049c0dd7"
                    ],
                    "keyword": [
                        "subgraph",
                        "problem",
                        "approximation",
                        "vertex",
                        "ratio",
                        "paper",
                        "graph",
                        "edges",
                        "developed",
                        "dense"
                    ],
                    "group": [],
                    "_id": "8e245630-549b-4b1c-afe7-cdf466295f32",
                    "abstract": "This paper considers the problem of computing the dense k -vertex subgraph of a given graph, namely, the subgraph with the most edges. An approximation algorithm is developed for the problem, with approximation ratio O(nδ) , for some δ < 1/3 .",
                    "title": "The dense k-subgraph problem",
                    "venue": "Algorithmica",
                    "year": 2001,
                    "__v": 1,
                    "citationCount": 245,
                    "result": 6.43685904140878
                },
                "9167c2df-4b86-4b47-98c9-3807261c343a": {
                    "authors": [
                        "Fang Wu",
                        "Bernardo A. Huberman"
                    ],
                    "references": [
                        "ff1609ce-c9ab-41e5-b7cb-481d5a51693e"
                    ],
                    "keyword": [
                        "graphs",
                        "communities",
                        "size",
                        "method",
                        "discovery",
                        "voltage",
                        "times",
                        "swift",
                        "surrounding",
                        "solve"
                    ],
                    "group": [],
                    "_id": "9167c2df-4b86-4b47-98c9-3807261c343a",
                    "abstract": "We present a method that allows for the discovery of communities within graphs of arbitrary size in times that scale linearly with their size. This method avoids edge cutting and is based on notions of voltage drops across networks that are both intuitive and easy to solve regardless of the complexity of the graph involved. We additionally show how this algorithm allows for the swift discovery of the community surrounding a given node without having to extract all the communities out of a graph.",
                    "title": "Finding communities in linear time: a physics approach",
                    "venue": "European Physical Journal B",
                    "year": 2004,
                    "__v": 1,
                    "citationCount": 132,
                    "result": 4.8266570804496505
                },
                "940e7ab9-c036-4e6a-8942-b90dc6b9c339": {
                    "authors": [
                        "Joshua R. Tyler",
                        "Dennis M. Wilkinson",
                        "Bernardo A. Huberman"
                    ],
                    "references": [
                        "05332f60-3d2e-45bb-9ecd-a7c7aa7774dc",
                        "270c2f13-926f-4ab5-8097-9eb5d719d113",
                        "8d2d62eb-e79f-45d6-b782-6c6792622512",
                        "b0ef6e4d-4c86-4b10-9e0a-7b630ca8d7f7",
                        "c4716aad-c8bc-431b-8173-0300064a77b0",
                        "efea2966-0b4d-4041-8dd7-467f45e949b9"
                    ],
                    "keyword": [
                        "communities",
                        "method",
                        "information",
                        "identification",
                        "graph",
                        "email",
                        "algorithm",
                        "true",
                        "studies",
                        "span"
                    ],
                    "group": [],
                    "_id": "940e7ab9-c036-4e6a-8942-b90dc6b9c339",
                    "abstract": "We describe a method for the automatic identification of communities of practice from e-mail logs within an organization. We use a betweenness centrality algorithm that can rapidly find communities within a graph representing information flows. We apply this algorithm to an initial e-mail corpus of nearly 1 million messages collected over a 2-month span, and show that the method is effective at identifying true communities, both formal and informal, within these scale-free graphs. This approach also enables the identification of leadership roles within the communities. These studies are complemented by a qualitative evaluation of the results in the field.",
                    "title": "E-Mail as Spectroscopy: Automated Discovery of Community Structure within Organizations",
                    "venue": "The Information Society",
                    "year": 2005,
                    "__v": 2,
                    "citationCount": 206,
                    "result": 5.523547318950702
                },
                "9438a773-c15c-4ef2-a97c-54f643ce6082": {
                    "authors": [
                        "Jianbo Shi",
                        "Jitendra Malik"
                    ],
                    "references": [
                        "1017d9d4-9a4c-423d-ad40-6d9bebbd6b31",
                        "3f4cc95c-5f47-4031-8671-e23ff4fe2ed2",
                        "52a537ee-57dc-45c7-a59a-03209eb997e2",
                        "7b8583e6-dbd3-4d2f-859a-f1de071886f2",
                        "8742180d-2a83-478a-b5d2-43a52423d1fe",
                        "c4aab071-cda5-414c-ad19-a0df22ffe0d7",
                        "d285cffc-b94d-4f81-bb6a-51ca70d95f75",
                        "ee51b885-3527-4a95-92b1-78432c2d0dca"
                    ],
                    "keyword": [
                        "image",
                        "segmentation",
                        "problem",
                        "grouping",
                        "criterion",
                        "approach",
                        "total",
                        "propose",
                        "normalized",
                        "graph"
                    ],
                    "group": [],
                    "_id": "9438a773-c15c-4ef2-a97c-54f643ce6082",
                    "abstract": "We propose a novel approach for solving the perceptual grouping problem in vision. Rather than focusing on local features and their consistencies in the image data, our approach aims at extracting the global impression of an image. We treat image segmentation as a graph partitioning problem and propose a novel global criterion, the normalized cut, for segmenting the graph. The normalized cut criterion measures both the total dissimilarity between the different groups as well as the total similarity within the groups. We show that an efficient computational technique based on a generalized eigenvalue problem can be used to optimize this criterion. We have applied this approach to segmenting static images and found results very encouraging.",
                    "title": "Normalized cuts and image segmentation",
                    "venue": "computer vision and pattern recognition",
                    "year": 1997,
                    "__v": 2,
                    "citationCount": 1195,
                    "result": 6.100387323967447
                },
                "993143bf-fe78-4033-b59b-cba01cc3861e": {
                    "authors": [
                        "Páll Jónsson",
                        "Tamara Cavanna",
                        "Daniel Zicha",
                        "Paul A. Bates"
                    ],
                    "references": [
                        "2236ab5d-b633-42b5-8958-43cf8c3b015c",
                        "397894a7-5671-441b-8d0e-453dc0f2928e",
                        "652a56d6-af99-40b8-8aca-7f0dbc6fd9fc",
                        "88b0ab38-3d4c-4b01-aca3-f372f66ed102",
                        "b9100dc3-f693-474e-a495-a6b8a0651baa",
                        "c62fa221-166b-41af-bdc6-654a418a8de2",
                        "cd87c89c-615b-4a8b-b6df-59349a497771"
                    ],
                    "keyword": [
                        "studied",
                        "methods",
                        "extensive",
                        "biochemical",
                        "approaches",
                        "utilised",
                        "twohybrid",
                        "traditionally",
                        "timeconsuming",
                        "survey"
                    ],
                    "group": [],
                    "_id": "993143bf-fe78-4033-b59b-cba01cc3861e",
                    "abstract": "Background#R##N#Protein-protein interactions have traditionally been studied on a small scale, using classical biochemical methods to investigate the proteins of interest. More recently large-scale methods, such as two-hybrid screens, have been utilised to survey extensive portions of genomes. Current high-throughput approaches have a relatively high rate of errors, whereas in-depth biochemical studies are too expensive and time-consuming to be practical for extensive studies. As a result, there are gaps in our knowledge of many key biological networks, for which computational approaches are particularly suitable.",
                    "title": "Cluster analysis of networks generated through homology: automatic identification of important protein communities involved in cancer metastasis",
                    "venue": "BMC Bioinformatics",
                    "year": 2006,
                    "__v": 2,
                    "citationCount": 43,
                    "result": 4.524954711685766
                },
                "9ce54ae7-19f5-423e-bf83-5e0eb187d460": {
                    "authors": [
                        "Luh Yen",
                        "François Fouss",
                        "Christine Decaestecker",
                        "Pascal Francq",
                        "Marco Saerens"
                    ],
                    "references": [
                        "058fb9ea-3e34-48f3-9d12-1d5793d51582",
                        "05bbaec3-7980-4941-8638-2bbfa4ac8be0",
                        "060303eb-f10b-4ff0-92e8-f04a6f2705b6",
                        "0895c22d-37c5-4c8f-9202-a32ebd2cb0c0",
                        "0a32020b-d21d-4fcc-b920-00324362cd4b",
                        "0cdb081e-f2db-49d9-8c65-45cbcc948265",
                        "1017d9d4-9a4c-423d-ad40-6d9bebbd6b31",
                        "106ac945-1fd6-4abd-b059-1b56ca491d0a",
                        "1721b1de-cf3d-4ebd-8229-80a79ab29747",
                        "173afdcd-45fa-461f-8ad1-2eab98dd739a",
                        "1c6fd3df-7e0e-4f63-af60-d0f2f4337f2b",
                        "1d383765-fe50-4493-9714-3df0c5e05057",
                        "1ddb34c4-84cf-469d-b0cb-6b4d25e1ee27",
                        "220df5f8-cf66-41f0-a25a-be08c4b29d72",
                        "22527ddd-8d68-4a78-864b-9a9cd04ba426",
                        "233249a7-0793-4c50-967b-14099d6a1d21",
                        "29c109cc-a95e-4d8a-b765-9fa0f247f23a",
                        "3445bf5e-0bee-43ca-98d8-f6cda100c10d",
                        "3b535520-eac9-4021-8071-2251654f62cc",
                        "3c383c6f-3503-458d-bdd7-a34cb8f4515f",
                        "3e5fd33f-1fd0-4815-a47a-3c41a26a538a",
                        "3edb85bc-ea71-4871-a460-25d7aec6ffe0",
                        "493ba21c-5ffe-4f14-8162-c5134aedf2b8",
                        "4c0cd9bb-5b3b-4fa3-aefa-eccd4a8f5b33",
                        "500bb8d0-4f34-4e4e-8334-86b3420f083c",
                        "50d9a0e1-00a5-4445-b8b2-9f1405cbe6e1",
                        "5203a51a-949f-46d0-81ae-108dffa35951",
                        "56bdc7bc-62de-4362-8a35-085f126562d8",
                        "5c7e505c-48fd-4740-a74e-2282cdccdfa6",
                        "5fc7c376-5895-490a-8ea2-989442940c7b",
                        "63ec4f55-8f3b-431e-88e5-87c04caa7e9f",
                        "6445f129-25df-4d9f-9bd5-1ed88bf244a4",
                        "64707a64-e9f8-4117-b828-e1905366b06c",
                        "68453f24-4276-4d0c-b37e-19d23af549be",
                        "6d3b87c1-0ca0-4b21-b8e7-74942e311018",
                        "72796539-ec1c-46c9-ba98-c431c1b8c640",
                        "73869616-a8ee-4147-af16-33cd010d7e01",
                        "7468b7d2-c442-4a2b-babd-0d510fbd9325",
                        "7a1a3bf9-8c23-4c13-8c8e-85b79ad6143e",
                        "7b4cf790-4a87-4a53-9cbb-c1816e2ac057",
                        "7c90045b-63b9-4f29-82a0-bf7c914a6ef6",
                        "824bc599-cc29-4c79-9c43-e0ee0237f245",
                        "82a4ef1a-c503-49bd-a2f4-34d13537a5f1",
                        "87d8ffaa-9e66-4e1f-88fd-cdfdab02fb29",
                        "8887411b-f589-42f2-a71b-5cc43712c813",
                        "89492dcb-ea5d-4dda-a5fb-687818cbe384",
                        "8b0bdc97-6a88-4301-9483-730a4edf35bd",
                        "8c0ec27c-e654-4e0e-8c49-9b427117a98e",
                        "8c443f3c-af9d-499b-9ce6-85e502da573f",
                        "8f9e92cf-f266-4e51-807f-c098a260a0dc",
                        "9167c2df-4b86-4b47-98c9-3807261c343a",
                        "933318ba-9f92-4a98-9b9a-6200ac57f4f9",
                        "93b8f6ed-865d-4698-8556-d7a8713afbf8",
                        "9b4e6c65-da64-4ffe-8f2b-810d7f1efb54",
                        "9b4e79ae-6d0c-4ee7-a879-d13ef777b83f",
                        "9db5c445-2caa-4129-a277-368dc375689b",
                        "a074ebda-9cbb-409e-8d6e-62005941bedb",
                        "ac14afe6-de4d-4056-b2ac-0f6e36f369a2",
                        "ad8dd722-3f65-4cd0-b002-e8b6f789cfff",
                        "af25c75f-5bd3-48ee-a6f1-051d7b30ea54",
                        "b0223a0f-89c3-475b-9fd2-0598e5831e50",
                        "b1bde621-17dc-4511-9878-9efa329a7ee4",
                        "b8f031ee-d823-4f80-ac3c-38b521b9aa90",
                        "beb99a69-15c8-4fcb-9148-51acd93cd54d",
                        "c0f1cb2b-e1ad-4ae2-abc0-c63b3389fef4",
                        "c6831026-e260-46f3-8472-846856fd4e24",
                        "c6ce5286-9b3b-419e-acd4-b4267eac25ba",
                        "c7586a6b-9453-4daa-b3a0-0f5b915cd6f0",
                        "c7e4e04b-45da-4bae-8c8a-d17ca0087361",
                        "cdf47515-1a77-4e27-8b78-42f282dd9eba",
                        "ce1b2bb2-6b8c-44b6-818f-d965a4a9fea3",
                        "d78003db-ad8a-48d2-be57-1c50e95cef72",
                        "dd90433d-a428-4ff1-833d-050702f7699c",
                        "dfb8a5e6-8046-4dcf-b6f3-be079bd26a8b",
                        "e45c2f8a-f919-4b39-80a9-8f128ae67280",
                        "e75d428e-9877-4d52-8660-1bb3bf0b9f5e",
                        "ea8cd3d8-17ae-4a1e-8f83-1609469087af",
                        "eab63a89-1016-4045-b3ff-2c9c365af2bf",
                        "ec5536e1-2323-4530-a7e3-28f8867b9be7",
                        "fe85c60c-9d9a-4a0a-a5c5-35923645ca60"
                    ],
                    "keyword": [
                        "kernel",
                        "clusters",
                        "graph",
                        "similarity",
                        "matrix",
                        "nodes",
                        "proposed",
                        "measure",
                        "kmeans",
                        "hierarchical"
                    ],
                    "group": [],
                    "_id": "9ce54ae7-19f5-423e-bf83-5e0eb187d460",
                    "abstract": "This work addresses the problem of detecting clusters in a weighted, undirected, graph by using kernel-based clustering methods, directly partitioning the graph according to a well-defined similarity measure between the nodes (a kernel on a graph). The proposed algorithms are based on a two-step procedure. First, a kernel or similarity matrix, providing a meaningful similarity measure between any couple of nodes, is computed from the adjacency matrix of the graph. Then, the nodes of the graph are clustered by performing a kernel clustering on this similarity matrix. Besides the introduction of a prototype-based kernel version of the gaussian mixtures model and Ward's hierarchical clustering, in addition to the already known kernel k-means and fuzzy k-means, a new kernel, called the sigmoid commute-time kernel (K\"C\"T^S) is presented. The joint use of the K\"C\"T^S kernel matrix and kernel clustering appears to be quite effective. Indeed, this methodology provides the best results on a systematic comparison with a selection of graph clustering and communities detection algorithms on three real-world databases. Finally, some links between the proposed hierarchical kernel clustering and spectral clustering are examined.",
                    "title": "Graph nodes clustering with the sigmoid commute-time kernel: A comparative study",
                    "venue": "data and knowledge engineering",
                    "year": 2009,
                    "__v": 1,
                    "citationCount": 30,
                    "result": 6.716663933139325
                },
                "9dbdc129-b8f3-4712-9c95-406bc8911bee": {
                    "authors": [
                        "Michael Molloy",
                        "Bruce A. Reed"
                    ],
                    "references": [
                        "05ba6f70-dca3-4b74-922f-a4c64c287db8",
                        "0ee9606b-8e5d-45f1-a0d1-ff9a430163ed",
                        "424bab1d-a362-4bd2-a878-eb81372b689d",
                        "5bde5552-01ff-4b99-a3ff-e7651d3e3478",
                        "9517ab8e-096d-4b18-89b2-92bed157f94b",
                        "f1b33f3a-82a7-43d5-9542-bef5dd81712d"
                    ],
                    "keyword": [
                        "graphs",
                        "random",
                        "numbers",
                        "ii",
                        "gn",
                        "component",
                        "wiley",
                        "wellknown",
                        "vertices",
                        "sum"
                    ],
                    "group": [],
                    "_id": "9dbdc129-b8f3-4712-9c95-406bc8911bee",
                    "abstract": "Given a sequence of nonnegative real numbers λ0, λ1… which sum to 1, we consider random graphs having approximately λi n vertices of degree i. Essentially, we show that if Σ i(i - 2)λi > 0, then such graphs almost surely have a giant component, while if Σ i(i -2)λ. < 0, then almost surely all components in such graphs are small. We can apply these results to Gn,p,Gn.M, and other well-known models of random graphs. There are also applications related to the chromatic number of sparse random graphs. © 1995 Wiley Periodicals, Inc.",
                    "title": "A critical point for random graphs with a given degree sequence",
                    "venue": "Random Structures and Algorithms",
                    "year": 1995,
                    "__v": 1,
                    "citationCount": 395,
                    "result": 4.48938716082679
                },
                "9df2aa63-11f9-4a64-b6c4-1fef1f8cde91": {
                    "authors": [
                        "Jean-Charles Delvenne",
                        "Sophia N. Yaliraki",
                        "Mauricio Barahona"
                    ],
                    "references": [
                        "0d6a426e-79ad-4747-b0c6-537078ba6e70",
                        "2f2dc23e-b1f1-425e-a6af-91f121e41d07",
                        "56aacaea-4377-41f7-9e73-0dcdd25984fc",
                        "649320e9-6975-461c-b44d-913cfde3eb5b",
                        "75d0cdfa-44cd-4fc3-ae56-72e982cb383b",
                        "87d8ffaa-9e66-4e1f-88fd-cdfdab02fb29",
                        "b0ef6e4d-4c86-4b10-9e0a-7b630ca8d7f7",
                        "dd90433d-a428-4ff1-833d-050702f7699c",
                        "fa3a2e13-70d5-4fa3-929a-126dd14d5c62"
                    ],
                    "keyword": [
                        "time",
                        "partitions",
                        "networks",
                        "communities",
                        "structure",
                        "measure",
                        "clusters"
                    ],
                    "group": [],
                    "_id": "9df2aa63-11f9-4a64-b6c4-1fef1f8cde91",
                    "abstract": "The complexity of biological, social, and engineering networks makes it desirable to find natural partitions into clusters (or communities) that can provide insight into the structure of the overall system and even act as simplified functional descriptions. Although methods for community detection abound, there is a lack of consensus on how to quantify and rank the quality of partitions. We introduce here the stability of a partition, a measure of its quality as a community structure based on the clustered autocovariance of a dynamic Markov process taking place on the network. Because the stability has an intrinsic dependence on time scales of the graph, it allows us to compare and rank partitions at each time and also to establish the time spans over which partitions are optimal. Hence the Markov time acts effectively as an intrinsic resolution parameter that establishes a hierarchy of increasingly coarser communities. Our dynamical definition provides a unifying framework for several standard partitioning measures: modularity and normalized cut size can be interpreted as one-step time measures, whereas Fiedler’s spectral clustering emerges at long times. We apply our method to characterize the relevance of partitions over time for constructive and real networks, including hierarchical graphs and social networks, and use it to obtain reduced descriptions for atomic-level protein structures over different time scales.",
                    "title": "Stability of graph communities across time scales",
                    "venue": "Proceedings of the National Academy of Sciences of the United States of America",
                    "year": 2010,
                    "__v": 1,
                    "citationCount": 70,
                    "result": 4.894106368999611
                },
                "a2fa78b2-9eb2-4d93-b2f5-f33579e4cbdf": {
                    "authors": [
                        "Andreas Noack"
                    ],
                    "references": [
                        "179ce328-3b8a-4ed5-b0bb-f674e7d74da5"
                    ],
                    "keyword": [
                        "layouts",
                        "clusterings",
                        "representations",
                        "quality",
                        "optimal",
                        "modularity",
                        "energy",
                        "widely",
                        "vertices",
                        "vertex"
                    ],
                    "group": [],
                    "_id": "a2fa78b2-9eb2-4d93-b2f5-f33579e4cbdf",
                    "abstract": "Two natural and widely used representations for the community structure of networks are clusterings, which partition the vertex set into disjoint subsets, and layouts, which assign the vertices to positions in a metric space. This paper unifies prominent characterizations of layout quality and clustering quality, by showing that energy models of pairwise attraction and repulsion subsume Newman and Girvan's modularity measure. Layouts with optimal energy are relaxations of, and are thus consistent with, clusterings with optimal modularity, which is of practical relevance because the two representations are complementary and often used together.",
                    "title": "Modularity clustering is force-directed layout",
                    "venue": "Physical Review E",
                    "year": 2009,
                    "__v": 1,
                    "citationCount": 58,
                    "result": 7.36759531833835
                },
                "a86e0c46-2085-4d1f-a712-a03be726ae4e": {
                    "authors": [
                        "Jirí Síma",
                        "Satu Elisa Schaeffer"
                    ],
                    "references": [
                        "14450392-6a7b-4d0f-ba07-ca8c1f0695ca",
                        "172f9f68-8417-43bb-8fe5-b377d569f6b6",
                        "26d3b385-bcba-48f0-91ee-67c9a8a14793",
                        "2f082a6f-9356-45f8-b4ff-4409c48ba0ec",
                        "38135245-8eff-4078-af6a-ea559ffa660b",
                        "3f610d75-809b-4a12-858f-95e346c17e8c",
                        "444ab669-1554-47b0-92fa-76e89ab7727e",
                        "5ec51989-7ee3-4137-a688-16c143eeb591",
                        "646fd5f1-1f89-40a7-b605-8402513ae682",
                        "679f537b-1aa2-4977-9255-8f1a3d021246",
                        "75d0cdfa-44cd-4fc3-ae56-72e982cb383b",
                        "89492dcb-ea5d-4dda-a5fb-687818cbe384",
                        "9e05a68a-35e4-4c9f-8c1a-49619ba25066",
                        "9f3aec67-ab4d-4c86-9d52-7aaad6c2c78b",
                        "b613fdc9-9f3c-484c-aac3-2d55eadf7cbb",
                        "e6cfd4ec-6676-4cf6-a645-27078fcd7509"
                    ],
                    "keyword": [
                        "clustering",
                        "optimizing",
                        "measures",
                        "graph",
                        "problem",
                        "identifying",
                        "fitness",
                        "tasks",
                        "subgraphs",
                        "sparsely"
                    ],
                    "group": [],
                    "_id": "a86e0c46-2085-4d1f-a712-a03be726ae4e",
                    "abstract": "Graph clustering is the problem of identifying sparsely connected dense subgraphs (clusters) in a given graph. Identifying clusters can be achieved by optimizing a fitness function that measures the quality of a cluster within the graph. Examples of such cluster measures include the conductance, the local and relative densities, and single cluster editing. We prove that the decision problems associated with the optimization tasks of finding clusters that are optimal with respect to these fitness measures are NP-complete.",
                    "title": "On the NP-Completeness of some graph cluster measures",
                    "venue": "conference on current trends in theory and practice of informatics",
                    "year": 2006,
                    "__v": 2,
                    "citationCount": 29,
                    "result": 7.898640748122972
                },
                "aa35f1f9-396c-4909-b303-493b5cb44b89": {
                    "authors": [
                        "Jure Leskovec",
                        "Kevin J. Lang",
                        "Anirban Dasgupta",
                        "Michael W. Mahoney"
                    ],
                    "references": [
                        "05332f60-3d2e-45bb-9ecd-a7c7aa7774dc",
                        "05fadb61-949a-4984-8559-d12a51202c8d",
                        "0a32020b-d21d-4fcc-b920-00324362cd4b",
                        "0b26e3b6-97c5-4a17-b462-4df399b59eb7",
                        "0bb130dc-8e44-4bd2-a8e8-73bcd6603770",
                        "0d60bb94-f0d2-4033-a825-e5698d615f3d",
                        "1165a045-794b-42dc-a3dd-979b743857c6",
                        "126446a1-730e-44dc-858b-e5c768bd81ac",
                        "18819165-7f73-4da1-9bf2-792c258be677",
                        "1a24e9c7-d0ce-4be4-8e3a-c849b4630851",
                        "24902bc1-0b86-4959-93f3-6c62a56b69ed",
                        "278d81bc-8359-4169-b1e7-48021c57d3eb",
                        "287df3fe-6f46-4071-8ab5-99274b9887b1",
                        "2b78227d-7cc3-4e64-bedd-195272ba6348",
                        "2e0a1db4-4ae1-478a-9f4f-719adfc7b75f",
                        "3370037d-1335-4ef3-98e1-90dc8dbc9192",
                        "353eae75-c04b-45cf-89d8-5c4d474d3821",
                        "35cad820-9f36-41ac-86e7-b14bf90e75ba",
                        "367d6866-9451-47b1-8872-766cf71c6d88",
                        "38135245-8eff-4078-af6a-ea559ffa660b",
                        "3909d566-d059-4c26-b537-77bbd78e72a1",
                        "3935c71a-826a-443c-8b11-8fb059a677ba",
                        "3c0c7536-7f11-4e63-bf6d-32d67050d8ef",
                        "3f610d75-809b-4a12-858f-95e346c17e8c",
                        "444ab669-1554-47b0-92fa-76e89ab7727e",
                        "46d6eece-0327-44a6-8862-7fa4ba5dad1a",
                        "4df853eb-d37f-4cff-96d0-4bba374e4a01",
                        "5670fab7-1d9a-49d1-af96-95bea64cf950",
                        "5d80fcf9-9cf0-402d-b001-f1e2eb22b7b3",
                        "60dafc55-cd3f-4c0c-a233-3a257f2d012b",
                        "60ef3852-fa16-44bf-9434-9909268ba5d8",
                        "63139dcf-11e2-4b8e-bcbd-ebd1f0511389",
                        "68faab18-b537-4f62-85cf-ddc9ef352362",
                        "6e551a7c-6769-49c1-93c5-037a06f4aaef",
                        "6fbc185a-1319-46e0-9f4f-662fce6108f2",
                        "6fc238bb-1b47-4c96-ac79-0259b19a4691",
                        "7291c68d-db95-48a0-b856-6545ef18b503",
                        "764a3426-aaea-4b4a-a692-a6cc215fe34e",
                        "76c5d4b1-d58a-4aca-831c-bed358d4bc38",
                        "7890fda1-bebe-4252-b667-cd5871113748",
                        "7c90045b-63b9-4f29-82a0-bf7c914a6ef6",
                        "824bc599-cc29-4c79-9c43-e0ee0237f245",
                        "86b69247-af69-4276-a105-b5e821559946",
                        "881ffdab-0f89-4a72-8655-8bc3a3fc6577",
                        "89492dcb-ea5d-4dda-a5fb-687818cbe384",
                        "8fba2fca-e15b-4a6a-a7d2-469ab8b9466c",
                        "90202eff-1598-4356-b7f5-0cc8aa9f220a",
                        "9167c2df-4b86-4b47-98c9-3807261c343a",
                        "94238b5d-654e-47df-a3c2-35d3c7a15a69",
                        "9b013225-8651-4f50-a0ae-ffc362862207",
                        "9d2359f9-aa7e-4dcf-91af-08f59196caa6",
                        "9dbdc129-b8f3-4712-9c95-406bc8911bee",
                        "9e2da831-0b8e-46af-a13a-034915cfcd15",
                        "9e79e32e-e99f-4ad8-9351-4e901fdabe2a",
                        "9f9c74c4-8573-48b7-bc6c-208f83057563",
                        "a0181d7d-c725-4bc4-8371-2510c70c96a4",
                        "a4196738-8874-4196-b395-355f718979b3",
                        "ab249818-6f8b-4266-87a3-33f9f1db52c9",
                        "ae27d9dc-0dfd-4ebc-a703-7b0f3dcf3dc8",
                        "b0ef6e4d-4c86-4b10-9e0a-7b630ca8d7f7",
                        "b2a5773c-be4b-4d8c-bbd9-1f1d0a09c5b5",
                        "b421d4e4-1c9b-4394-b7dd-c778d41400a9",
                        "b613fdc9-9f3c-484c-aac3-2d55eadf7cbb",
                        "bafb2fda-239d-4ccd-a158-e66d485954a2",
                        "bb02f0c6-3f59-4545-b72b-95dfdacea506",
                        "bcfb1417-4781-4c66-a6a0-ca2c8e1261a6",
                        "c6765391-ea04-40cc-ac43-a37261c94cc1",
                        "c7fb024d-ce71-4b1e-a8c0-4572e4a97f68",
                        "c913f9df-75b6-4b5d-9ca1-85ad141bb61b",
                        "cc4938ae-0ef7-4028-82ba-74693b0916b4",
                        "ccc5eeaa-bbb5-4224-b7a7-6583f6b6ae01",
                        "cede414d-501e-4247-a650-42240f00a401",
                        "d3a07676-c9bf-4b84-989a-7acebb79c48c",
                        "d9e71400-57ec-443b-8e71-9eb5c3c40632",
                        "ea24ad7a-7839-4e1c-a5b3-ccedefc6f961",
                        "ecf4c786-08a3-4f00-a8e1-20c3465c37d7",
                        "ede95d3e-4a79-4560-8698-94b72cb498df",
                        "f138717e-c64e-409d-b888-dc9f26e7e3a4",
                        "f15b19f2-4b37-454c-851e-a71cccf3e53a",
                        "f5de6b41-0df8-4270-8211-a67a081dad45",
                        "f9ff1d5c-ce5c-4dd0-be95-be53a81a4f94",
                        "fa2e520b-75fc-40a5-8e6d-45cdc807d854",
                        "ff1609ce-c9ab-41e5-b7cb-481d5a51693e",
                        "ff392d57-903f-40c7-84a9-c36a816d6b58"
                    ],
                    "keyword": [
                        "nodes",
                        "communities",
                        "social",
                        "set",
                        "networks",
                        "graphs",
                        "represent",
                        "large",
                        "information",
                        "identifying"
                    ],
                    "group": [],
                    "_id": "aa35f1f9-396c-4909-b303-493b5cb44b89",
                    "abstract": "A large body of work has been devoted to defining and identifying clusters or communities in social and information networks, i.e., in graphs in which the nodes represent underlying social entities and the edges represent some sort of interaction between pairs of nodes. Most such research begins with the premise that a community or a cluster should be thought of as a set of nodes that has more and/or better connections between its members than to the remainder of the network. In this paper, we explore from a novel perspective several questions related to identifying meaningful communities in large social and information networks, and we come to several striking conclusions. Rather than defining a procedure to extract sets of nodes from a graph and then attempting to interpret these sets as \"real\" communities, we employ approximation algorithms for the graph-partitioning problem to characterize as a function of size the statistical and structural properties of partitions of graphs that could plausibly be i...",
                    "title": "Community Structure in Large Networks: Natural Cluster Sizes and the Absence of Large Well-Defined Clusters",
                    "venue": "Internet Mathematics",
                    "year": 2009,
                    "__v": 2,
                    "citationCount": 513,
                    "result": 7.63309292157376
                },
                "b09f2059-32bd-444f-9919-49ef62b99691": {
                    "authors": [
                        "Hideo Matsuda",
                        "Takayuki Ishihara",
                        "Akihiro Hashimoto"
                    ],
                    "references": [
                        "172f9f68-8417-43bb-8fe5-b377d569f6b6",
                        "241f2c03-4a0e-4269-9287-dc47a28c05b4",
                        "47835067-de0f-48e9-894f-0643085995aa",
                        "93a848f8-348a-49f5-9425-eb30879687d7",
                        "be9698e8-ef21-4479-ad11-e9854ea96b66"
                    ],
                    "keyword": [
                        "sequences",
                        "similarity",
                        "complete",
                        "method",
                        "graph",
                        "pquasi",
                        "classifying"
                    ],
                    "group": [],
                    "_id": "b09f2059-32bd-444f-9919-49ef62b99691",
                    "abstract": "This paper presents a method for classifying a large and mixed set of uncharacterized sequences provided by genome projects. As the measure of sequence similarity, we use similarity score computed by a method based on the dynamic programming (DP), such as the Smith{Waterman local alignment algorithm. Although comparison by DP based method is very sensitive, when given sequences include a family of sequences that are much diverged in evolutionary process, similarity among some of them may be hidden behind spurious similarity of some unrelated sequences. Also the distance derived from the similarity score may not be metric (i.e., triangle inequality may not hold) when some sequences have multi-domain structure. To cope with these problems, we introduce a new graph structure called p-quasi complete graph for describing a family of sequences with a condence measure. We prove that a restricted version of the pquasi complete graph problem (given a positive integer k, whether a graph contains a 0.5-quasi complete subgraph of which size >k or not) is NP-complete. Thus we present an approximation algorithm for classifying a set of sequences using p-quasi complete subgraphs. The eectiveness of our method is demonstrated by the result of classifying over 4000 protein sequences on the Escherichia coli genome that was completely determined recently. c 1999|Elsevier Science B.V. All rights reserved",
                    "title": "Classifying molecular sequences using a linkage graph with their pairwise similarities",
                    "venue": "Theoretical Computer Science",
                    "year": 1999,
                    "__v": 2,
                    "citationCount": 36,
                    "result": 3.89054281631681
                },
                "b0afa6ff-6528-4701-800b-5dc0b5411b0c": {
                    "authors": [
                        "Jorma Rissanen"
                    ],
                    "references": [
                        "a0b958fe-cc21-4635-952f-0d74a0db91ff"
                    ],
                    "keyword": [
                        "parameters",
                        "observed",
                        "model",
                        "write",
                        "time",
                        "system",
                        "structure",
                        "series",
                        "sequence",
                        "realvalued"
                    ],
                    "group": [],
                    "_id": "b0afa6ff-6528-4701-800b-5dc0b5411b0c",
                    "abstract": "The number of digits it takes to write down an observed sequence x\"1, ..., x\"N of a time series depends on the model with its parameters that one assumes to have generated the observed data. Accordingly, by finding the model which minimizes the description length one obtains estimates of both the integer-valued structure parameters and the real-valued system parameters.",
                    "title": "Paper: Modeling by shortest data description",
                    "venue": "Automatica",
                    "year": 1978,
                    "__v": 1,
                    "citationCount": 1833,
                    "result": 6.829104022912074
                },
                "b0ef6e4d-4c86-4b10-9e0a-7b630ca8d7f7": {
                    "authors": [
                        "M. E. J. Newman"
                    ],
                    "references": [
                        "008d95fd-26f0-47f3-8774-6a896446baea",
                        "05332f60-3d2e-45bb-9ecd-a7c7aa7774dc",
                        "05f5fba9-e7ca-4c46-be79-df57944a8b41",
                        "0718dc34-4b49-4b24-8a2e-b5cd0d9d82c6",
                        "0d8eb1a3-5b89-419b-9eea-8fffd03c78a1",
                        "16e3c2f7-37fb-4192-bf76-20fe7838958a",
                        "18819165-7f73-4da1-9bf2-792c258be677",
                        "19f41085-f8c3-4087-a48a-27205b43bdb8",
                        "1a24e9c7-d0ce-4be4-8e3a-c849b4630851",
                        "1b41d9a0-3857-4fb6-b7ba-d39da73c04dd",
                        "27e4ec4d-0ce3-437b-9511-db610b7ba805",
                        "2a2fd168-2bcf-4527-afcd-5c99e75ad511",
                        "38135245-8eff-4078-af6a-ea559ffa660b",
                        "3bbad1d7-7c16-4c85-ae98-4cfd6913794f",
                        "3f610d75-809b-4a12-858f-95e346c17e8c",
                        "424bab1d-a362-4bd2-a878-eb81372b689d",
                        "4c343995-619f-4859-bd00-321c87adcd3c",
                        "597ecf84-4084-4057-a40d-30988ef74121",
                        "5ea35ec7-ab9f-4d0e-9a85-ef4add482ec7",
                        "606e4423-5a84-4c3b-bfb1-0cf549bf21e9",
                        "60c814e2-c4d1-47d7-9a5a-68f4141505ae",
                        "60ef3852-fa16-44bf-9434-9909268ba5d8",
                        "63245010-95d3-4eb1-a0d0-62894531d092",
                        "686c5563-3f13-4744-ac6d-1020e39953bf",
                        "6e6cac85-1ca8-4d49-8e16-aa3d353fc20a",
                        "71414cbd-e8f3-43ce-b536-029959d08b14",
                        "7192626f-12df-45f7-889d-c78e4da08773",
                        "7291c68d-db95-48a0-b856-6545ef18b503",
                        "8a4d517a-da96-4f80-879d-dda81e69d9c9",
                        "8f12317e-0ea6-455c-a973-7c7440af5f37",
                        "8f9e92cf-f266-4e51-807f-c098a260a0dc",
                        "98c4a2e2-f046-4e49-9173-91779f961cc0",
                        "9dbdc129-b8f3-4712-9c95-406bc8911bee",
                        "a0181d7d-c725-4bc4-8371-2510c70c96a4",
                        "a08549f5-fa6a-4adb-b643-714867228a0c",
                        "a0c94b9b-d64e-40d5-ba44-4208dec791d0",
                        "a22c015f-fa44-4b73-b906-ef030405d9c9",
                        "a4a93e4a-68f2-4509-bf87-5b33122ff614",
                        "a78ddf3f-d0ac-4262-bd99-ca8d5bd8309e",
                        "af8a7a02-c5f2-4367-9a67-7593d92f6003",
                        "b2f1d79b-d47a-4f2a-b810-ac3c837d7ee4",
                        "b407837a-0eae-4882-9a2c-2c185d5c16e0",
                        "baad4ab4-a3f2-45fc-b87d-954f608e8db7",
                        "bd34626f-94ae-46a2-8037-8c367831fa78",
                        "c2165f5b-d07b-4cd2-9d2b-e6f3002c80db",
                        "c4716aad-c8bc-431b-8173-0300064a77b0",
                        "c7e4e04b-45da-4bae-8c8a-d17ca0087361",
                        "ce115523-6b89-47ad-8cf3-1cb3e2a865d3",
                        "d71f089c-0658-478a-b58e-bb8e6f131c21",
                        "dd38911a-f68b-4bb5-a817-fd7153f0ff2f",
                        "df4b8e90-b404-47f8-a384-c93aa1313694",
                        "e2a97ffb-90b0-4f1a-b01d-b15a77a820de",
                        "e4f056cc-ab1e-4ca0-8754-fc81b133a47d",
                        "f15b19f2-4b37-454c-851e-a71cccf3e53a",
                        "f8088d69-04af-49f3-84b9-daf7682cc5f5"
                    ],
                    "keyword": [
                        "networked",
                        "models",
                        "systems",
                        "developed",
                        "years",
                        "variety",
                        "understand",
                        "techniques",
                        "studies",
                        "social"
                    ],
                    "group": [
                        null
                    ],
                    "_id": "b0ef6e4d-4c86-4b10-9e0a-7b630ca8d7f7",
                    "abstract": "Inspired by empirical studies of networked systems such as the Internet, social networks, and biological networks, researchers have in recent years developed a variety of techniques and models to help us understand or predict the behavior of these systems. Here we review developments in this field, including such concepts as the small-world effect, degree distributions, clustering, network correlations, random graph models, models of network growth and preferential attachment, and dynamical processes taking place on networks.",
                    "title": "The Structure and Function of Complex Networks",
                    "venue": "Siam Review",
                    "year": 2003,
                    "__v": 3,
                    "citationCount": 3109,
                    "result": 5.550691762242952
                },
                "b6af7a3b-1d82-44df-94e9-1297c7c6c542": {
                    "authors": [
                        "Marco Gaertler",
                        "Robert Görke",
                        "Dorothea Wagner"
                    ],
                    "references": [
                        "03648d82-c68e-43e1-956a-79c5bfaca10f",
                        "0a32020b-d21d-4fcc-b920-00324362cd4b",
                        "1cae18e6-a24a-4135-9f81-2858a448ebc3",
                        "2f082a6f-9356-45f8-b4ff-4409c48ba0ec",
                        "662659fd-3aaa-4537-af74-212929a96d44",
                        "bfc8eb8e-f365-459b-b995-154a55c10d2d"
                    ],
                    "keyword": [
                        "quality",
                        "paradigm",
                        "modularity",
                        "systematically",
                        "resulting",
                        "realizations",
                        "clusterings"
                    ],
                    "group": [],
                    "_id": "b6af7a3b-1d82-44df-94e9-1297c7c6c542",
                    "abstract": "Modularity, the recently defined quality measure for clusterings, has attained instant popularity in the fields of social and natural sciences. We revisit the rationale behind the definition of modularity and explore the founding paradigm. This paradigm is based on the trade-off between the achieved quality and the expected quality of a clustering with respect to networks with similar intrinsic structure. We experimentally evaluate realizations of this paradigm systematically, including modularity, and describe efficient algorithms for their optimization. We confirm the feasibility of the resulting generality by a first systematic analysis of the behavior of these realizations on both artificial and on real-world data, arriving at remarkably good results of community detection.",
                    "title": "Significance-Driven Graph Clustering",
                    "venue": "algorithmic applications in management",
                    "year": 2007,
                    "__v": 2,
                    "citationCount": 12,
                    "result": 6.057593012193459
                },
                "b7fb5dc9-9016-436d-a365-55c52e3c3e62": {
                    "authors": [
                        "René Peeters"
                    ],
                    "references": [
                        "9e05a68a-35e4-4c9f-8c1a-49619ba25066",
                        "a99d24b3-2f1f-4918-8434-43ebd960d396",
                        "af0e7b77-e5c3-4d64-adc2-cc43a4b0976e",
                        "de7a10aa-051f-42cf-a9a6-2ba3853371d9",
                        "f4fcc2b5-370c-4349-a309-04b41b85c8a6"
                    ],
                    "keyword": [
                        "biclique",
                        "maximum",
                        "problem",
                        "number",
                        "graphs",
                        "finding",
                        "edge",
                        "bipartite",
                        "vertices",
                        "vertex"
                    ],
                    "group": [],
                    "_id": "b7fb5dc9-9016-436d-a365-55c52e3c3e62",
                    "abstract": "We prove that the maximum edge biclique problem in bipartite graphs is NP-complete.A biclique in a bipartite graph is a vertex induced subgraph which is complete.The problem of finding a biclique with a maximum number of vertices is known to be solvable in polynomial time but the complexity of finding a biclique with a maximum number of edges was still undecided.",
                    "title": "The maximum edge biclique problem is NP-complete",
                    "venue": "Discrete Applied Mathematics",
                    "year": 2003,
                    "__v": 2,
                    "citationCount": 159,
                    "result": 7.092841592531994
                },
                "b80d9c8a-c008-495f-a1e3-01da69ec54d9": {
                    "authors": [
                        "Ravi Kumar",
                        "Jasmine Novak",
                        "Prabhakar Raghavan",
                        "Andrew Tomkins"
                    ],
                    "references": [
                        "0bcdf44c-c747-4e1f-8778-ade3decdbc37",
                        "287df3fe-6f46-4071-8ab5-99274b9887b1",
                        "34b7e270-80d7-46d5-a6f1-e50087a8d045",
                        "3d11074d-a91c-4dba-bbca-2797badbc00a",
                        "700fe5e3-36d0-47a5-b35f-8b0419086576",
                        "79b938b2-023d-44ae-9a9d-9ee73a3ac028",
                        "8098554b-a355-425c-8300-4dcfe672c56d",
                        "8e245630-549b-4b1c-afe7-cdf466295f32",
                        "8f9e92cf-f266-4e51-807f-c098a260a0dc",
                        "946cb26d-542c-4331-8d1b-a6c7399de655",
                        "a4d85314-8e53-41a9-bb1d-6467eac4fb88",
                        "bb02f0c6-3f59-4545-b72b-95dfdacea506"
                    ],
                    "keyword": [
                        "time",
                        "community",
                        "structure",
                        "link",
                        "graphs",
                        "evolution",
                        "blogspace",
                        "blogs"
                    ],
                    "group": [],
                    "_id": "b80d9c8a-c008-495f-a1e3-01da69ec54d9",
                    "abstract": "We propose two new tools to address the evolution of hyperlinked corpora. First, we define  time graphs  to extend the traditional notion of an evolving directed graph, capturing link creation as a point phenomenon in time. Second, we develop definitions and algorithms for  time-dense community tracking , to crystallize the notion of community evolution. We develop these tools in the context of  Blogspace  , the space of weblogs (or  blogs ). Our study involves approximately 750K links among 25K blogs. We create a time graph on these blogs by an automatic analysis of their internal time stamps. We then study the evolution of connected component structure and microscopic community structure in this time graph. We show that Blogspace underwent a transition behavior around the end of 2001, and has been rapidly expanding over the past year, not just in metrics of scale, but also in metrics of community structure and connectedness. This expansion shows no sign of abating, although measures of connectedness must plateau within two years. By randomizing link destinations in Blogspace, but retaining sources and timestamps, we introduce a concept of  randomized Blogspace  . Herein, we observe similar evolution of a giant component, but no corresponding increase in community structure. Having demonstrated the formation of micro-communities over time, we then turn to the ongoing activity within active communities. We extend recent work of Kleinberg [11] to discover dense periods of \"bursty\" intra-community link creation.",
                    "title": "On the bursty evolution of blogspace",
                    "venue": "international world wide web conferences",
                    "year": 2003,
                    "__v": 2,
                    "citationCount": 333,
                    "result": 4.458782567088321
                },
                "c5ec6a5c-ff8d-494d-b093-66383861fe51": {
                    "authors": [
                        "M. E. J. Newman"
                    ],
                    "references": [
                        "1b41d9a0-3857-4fb6-b7ba-d39da73c04dd",
                        "263c4b91-8c62-4e92-87e7-e64b94b6588a"
                    ],
                    "keyword": [
                        "node",
                        "paths",
                        "measure",
                        "shortest",
                        "network",
                        "walks",
                        "spread",
                        "random",
                        "information",
                        "counting"
                    ],
                    "group": [],
                    "_id": "c5ec6a5c-ff8d-494d-b093-66383861fe51",
                    "abstract": "Betweenness is a measure of the centrality of a node in a network, and is normally calculated as the fraction of shortest paths between node pairs that pass through the node of interest. Betweenness is, in some sense, a measure of the influence a node has over the spread of information through the network. By counting only shortest paths, however, the conventional definition implicitly assumes that information spreads only along those shortest paths. Here we propose a betweenness measure that relaxes this assumption, including contributions from essentially all paths between nodes, not just the shortest, although it still gives more weight to short paths. The measure is based on random walks, counting how often a node is traversed by a random walk between two other nodes. We show how our measure can be calculated using matrix methods, and give some examples of its application to particular networks.",
                    "title": "A measure of betweenness centrality based on random walks",
                    "venue": "Social Networks",
                    "year": 2005,
                    "__v": 2,
                    "citationCount": 399,
                    "result": 5.16475200125782
                },
                "c6765391-ea04-40cc-ac43-a37261c94cc1": {
                    "authors": [
                        "Aaron Clauset",
                        "Cristopher Moore",
                        "M. E. J. Newman"
                    ],
                    "references": [
                        "60ef3852-fa16-44bf-9434-9909268ba5d8",
                        "646fd5f1-1f89-40a7-b605-8402513ae682",
                        "6e6cac85-1ca8-4d49-8e16-aa3d353fc20a",
                        "b0ef6e4d-4c86-4b10-9e0a-7b630ca8d7f7",
                        "b55b3100-5054-4d25-860d-d3e32fc56d14"
                    ],
                    "keyword": [
                        "networks",
                        "property",
                        "hierarchical",
                        "groups",
                        "structure",
                        "model",
                        "graph",
                        "give",
                        "generic",
                        "generating"
                    ],
                    "group": [],
                    "_id": "c6765391-ea04-40cc-ac43-a37261c94cc1",
                    "abstract": "One property of networks that has received comparatively little attention is hierarchy, i.e., the property of having vertices that cluster together in groups, which then join to form groups of groups, and so forth, up through all levels of organization in the network. Here, we give a precise definition of hierarchical structure, give a generic model for generating arbitrary hierarchical structure in a random graph, and describe a statistically principled way to learn the set of hierarchical features that most plausibly explain a particular real-world network. By applying this approach to two example networks, we demonstrate its advantages for the interpretation of network data, the annotation of graphs with edge, vertex and community properties, and the generation of generic null models for further hypothesis testing.",
                    "title": "Structural inference of hierarchies in networks",
                    "venue": "international conference on machine learning",
                    "year": 2006,
                    "__v": 2,
                    "citationCount": 43,
                    "result": 6.381163463358937
                },
                "c8678358-846c-457d-a775-b74aa2f56b8d": {
                    "authors": [
                        "Jimeng Sun",
                        "Christos Faloutsos",
                        "Spiros Papadimitriou",
                        "Philip S. Yu"
                    ],
                    "references": [
                        "1a24e9c7-d0ce-4be4-8e3a-c849b4630851",
                        "35cad820-9f36-41ac-86e7-b14bf90e75ba",
                        "423f82b0-7075-4b88-8b25-bd58ce3638c8",
                        "67c2f5c4-a49e-47ef-8caf-d5e5821154f6",
                        "748bce90-b5d8-4759-b733-c75b4e57bfea",
                        "8098554b-a355-425c-8300-4dcfe672c56d",
                        "854fac6a-4f3a-4145-b91d-53bb8829dc3c",
                        "881ffdab-0f89-4a72-8655-8bc3a3fc6577",
                        "8f28b0bc-d359-448c-9eb8-6331ee9c28bb",
                        "94b095a5-74ad-47ec-a39d-8dc877b2ef1e",
                        "9a3e62d9-2d53-41de-8db3-b896dce42ac3",
                        "d0c2d5cf-b631-4e98-b7fb-4330367fc453",
                        "ea8cd3d8-17ae-4a1e-8f83-1609469087af",
                        "eb2f8d56-66b8-442e-a1a0-580cde910e91",
                        "f4fbff9b-2c32-40c8-8d18-b49cb5113374"
                    ],
                    "keyword": [
                        "streams",
                        "graphscope",
                        "graphs",
                        "fashion",
                        "userdefined",
                        "timepoints",
                        "timeevolving",
                        "theoretic",
                        "spot",
                        "socialinteractions"
                    ],
                    "group": [],
                    "_id": "c8678358-846c-457d-a775-b74aa2f56b8d",
                    "abstract": "How can we find communities in dynamic networks of socialinteractions, such as who calls whom, who emails whom, or who sells to whom? How can we spot discontinuity time-points in such streams of graphs, in an on-line, any-time fashion? We propose GraphScope, that addresses both problems, using information theoretic principles. Contrary to the majority of earlier methods, it needs no user-defined parameters. Moreover, it is designed to operate on large graphs, in a streaming fashion. We demonstrate the efficiency and effectiveness of our GraphScope on real datasets from several diverse domains. In all cases it produces meaningful time-evolving patterns that agree with human intuition.",
                    "title": "GraphScope: parameter-free mining of large time-evolving graphs",
                    "venue": "knowledge discovery and data mining",
                    "year": 2007,
                    "__v": 2,
                    "citationCount": 242,
                    "result": 7.208717333980748
                },
                "cc248270-c3d6-4613-8b30-df4a066a5cb9": {
                    "authors": [
                        "Alexei Vazquez"
                    ],
                    "references": [
                        "1b15743e-ed7b-47c3-980b-e103c821d4ff",
                        "9a91df50-24ec-4b74-87b8-737c6d576ea0"
                    ],
                    "keyword": [
                        "population",
                        "stratification",
                        "element",
                        "structure",
                        "problem",
                        "natural",
                        "hypergraph",
                        "concept",
                        "attributes"
                    ],
                    "group": [],
                    "_id": "cc248270-c3d6-4613-8b30-df4a066a5cb9",
                    "abstract": "Population stratification is a problem encountered in several areas of natural science, engineering, and public health. We tackle this problem by mapping a population and its element attributes onto a hypergraph, a natural extension of the concept of graph or network to encode associations among any number of elements. On this hypergraph, we construct a statistical model reflecting our intuition about how the element attributes can emerge from a postulated population structure. Finally, we introduce the concept of stratification representativeness as a mean to identify the simplest stratification already containing most of the information about the population structure. We demonstrate the power of this framework stratifying an animal and a human population based on phenotypic and genotypic properties, respectively.",
                    "title": "Population stratification using a statistical model on hypergraphs",
                    "venue": "Physical Review E",
                    "year": 2008,
                    "__v": 2,
                    "citationCount": 6,
                    "result": 6.562122162398106
                },
                "dc88af6e-158d-4a2e-badd-2afaf5c95648": {
                    "authors": [
                        "Yen-Chuen A. Wei",
                        "Chung-Kuan Cheng"
                    ],
                    "references": [
                        "67bb1c02-7d64-4d95-935e-45c2ae49c07d",
                        "8b7e9a42-ef7f-41f1-970b-6d05d65c8b40",
                        "d42e2fd0-0bc2-4ff9-8569-f7d9dc67c80e",
                        "ea90d7c2-28ad-48c1-8e34-a29d0e4f1419",
                        "eea2da24-467e-4179-acb9-ae3c24591119",
                        "ff1609ce-c9ab-41e5-b7cb-481d5a51693e"
                    ],
                    "keyword": [
                        "ratio",
                        "cut",
                        "proposed",
                        "algorithm",
                        "linear",
                        "circuit",
                        "cases"
                    ],
                    "group": [],
                    "_id": "dc88af6e-158d-4a2e-badd-2afaf5c95648",
                    "abstract": "A partitioning approach called ratio cut is proposed. The authors demonstrate that the ratio cut algorithm can locate the clustering structures in the circuit. Finding the optimal ratio cut is NP-complete. However, in certain cases the ratio cut can be solved by linear programming techniques via the multicommodity flow problem. They also propose a fast heuristic algorithm running in linear time with respect to the number of pins in the circuit. Experiments show good results in all tested cases, and as much as 70% improvement over the Kernighan-Lin algorithm in terms of the proposed ratio metric. >",
                    "title": "Towards efficient hierarchical designs by ratio cut partitioning",
                    "venue": "international conference on computer aided design",
                    "year": 1989,
                    "__v": 2,
                    "citationCount": 88,
                    "result": 2.9104764516529222
                },
                "dd90433d-a428-4ff1-833d-050702f7699c": {
                    "authors": [
                        "François Fouss",
                        "Alain Pirotte",
                        "Jean-Michel Renders",
                        "Marco Saerens"
                    ],
                    "references": [
                        "05bbaec3-7980-4941-8638-2bbfa4ac8be0",
                        "0ea745c7-58b2-48e8-9115-42e9b0d20f2a",
                        "106ac945-1fd6-4abd-b059-1b56ca491d0a",
                        "1d383765-fe50-4493-9714-3df0c5e05057",
                        "1ddb34c4-84cf-469d-b0cb-6b4d25e1ee27",
                        "213ccf22-1ea7-42a3-8369-644a47a5fbe2",
                        "2ebf75c1-1630-45cc-90de-ee5db9190d89",
                        "34d4e37b-e575-4316-847b-d8a661b51473",
                        "3945dce8-e585-4e9c-98e7-9c4d4218f724",
                        "3c383c6f-3503-458d-bdd7-a34cb8f4515f",
                        "3e5fd33f-1fd0-4815-a47a-3c41a26a538a",
                        "4c0cd9bb-5b3b-4fa3-aefa-eccd4a8f5b33",
                        "5558ea9c-380f-4d58-8088-2e3712248bd2",
                        "5fc7c376-5895-490a-8ea2-989442940c7b",
                        "619f8b07-bb28-404b-8e53-91dbf0109770",
                        "6e425bce-a497-4c63-9eb0-b038e660a54f",
                        "6fff0e62-9812-4ea8-8f28-a2f94d571b90",
                        "7a1a3bf9-8c23-4c13-8c8e-85b79ad6143e",
                        "8c443f3c-af9d-499b-9ce6-85e502da573f",
                        "8f9e92cf-f266-4e51-807f-c098a260a0dc",
                        "99d18eba-2586-46fd-984d-3c471927bb51",
                        "a23effc2-0dad-40ee-b1d0-0375bf76fc8e",
                        "ad467380-4465-4b1a-b8ff-7f90bf4868e4",
                        "bd741812-afb5-4b2c-a807-1d6c93fde3ac",
                        "c5ec6a5c-ff8d-494d-b093-66383861fe51",
                        "cbff2ff2-6b8f-425d-a5ef-aff0de9be3e5",
                        "ddedcf0e-043f-4362-a33d-ae8ba33d07fe",
                        "e75d428e-9877-4d52-8660-1bb3bf0b9f5e",
                        "eab63a89-1016-4045-b3ff-2c9c365af2bf",
                        "f2014a2b-0a8a-42b9-9ff7-61e4fe71bf39",
                        "f782a72e-eeca-4757-ace9-670012f961a8"
                    ],
                    "keyword": [
                        "graph",
                        "time",
                        "similarity",
                        "nodes",
                        "matrix",
                        "elements",
                        "database",
                        "commute"
                    ],
                    "group": [],
                    "_id": "dd90433d-a428-4ff1-833d-050702f7699c",
                    "abstract": "This work presents a new perspective on characterizing the similarity between elements of a database or, more generally, nodes of a weighted and undirected graph. It is based on a Markov-chain model of random walk through the database. More precisely, we compute quantities (the average commute time, the pseudoinverse of the Laplacian matrix of the graph, etc.) that provide similarities between any pair of nodes, having the nice property of increasing when the number of paths connecting those elements increases and when the \"length\" of paths decreases. It turns out that the square root of the average commute time is a Euclidean distance and that the pseudoinverse of the Laplacian matrix is a kernel matrix (its elements are inner products closely related to commute times). A principal component analysis (PCA) of the graph is introduced for computing the subspace projection of the node vectors in a manner that preserves as much variance as possible in terms of the Euclidean commute-time distance. This graph PCA provides a nice interpretation to the \"Fiedler vector,\" widely used for graph partitioning. The model is evaluated on a collaborative-recommendation task where suggestions are made about which movies people should watch based upon what they watched in the past. Experimental results on the MovieLens database show that the Laplacian-based similarities perform well in comparison with other methods. The model, which nicely fits into the so-called \"statistical relational learning\" framework, could also be used to compute document or word similarities, and, more generally, it could be applied to machine-learning and pattern-recognition tasks involving a relational database",
                    "title": "Random-Walk Computation of Similarities between Nodes of a Graph with Application to Collaborative Recommendation",
                    "venue": "IEEE Transactions on Knowledge and Data Engineering",
                    "year": 2007,
                    "__v": 2,
                    "citationCount": 349,
                    "result": 4.510251138136267
                },
                "e96828f8-70d7-4df8-a75a-5cf81e168601": {
                    "authors": [
                        "Balázs Adamcsek",
                        "Gergely Palla",
                        "Illés J. Farkas",
                        "Imre Derényi",
                        "Tamás Vicsek"
                    ],
                    "references": [
                        "4301fad3-c6e0-4cf2-8e6f-86aa2366d078",
                        "5d23ee63-af72-4425-93b2-46c9858c0600",
                        "89b2e0e5-38c9-4386-920a-44ceb0c33b07",
                        "ece3a6da-5a36-4dae-a67d-6b7952a3da1f"
                    ],
                    "keyword": [
                        "proteins",
                        "modules",
                        "groups",
                        "cfinder",
                        "overlap",
                        "nodes",
                        "network",
                        "graphs",
                        "locating",
                        "interconnected"
                    ],
                    "group": [],
                    "_id": "e96828f8-70d7-4df8-a75a-5cf81e168601",
                    "abstract": "Summary: Most cellular tasks are performed not by individual proteins, but by groups of functionally associated proteins, often referred to as modules. In a protein assocation network modules appear as groups of densely interconnected nodes, also called communities or clusters. These modules often overlap with each other and form a network of their own, in which nodes (links) represent the modules (overlaps). We introduce CFinder, a fast program locating and visualizing overlapping, densely interconnected groups of nodes in undirected graphs, and allowing the user to easily navigate between the original graph and the web of these groups. We show that in gene (protein) association networks CFinder can be used to predict the function(s) of a single protein and to discover novel modules. CFinder is also very efficient for locating the cliques of large sparse graphs.#R##N##R##N#Availability: CFinder (for Windows, Linux and Macintosh) and its manual can be downloaded from http://angel.elte.hu/clustering.#R##N##R##N#Supplementary information: Supplementary data are available on Bioinformatics online.#R##N##R##N#Contact: cfinder@angel.elte.hu",
                    "title": "CFinder: locating cliques and overlapping modules in biological networks",
                    "venue": "Bioinformatics",
                    "year": 2006,
                    "__v": 2,
                    "citationCount": 234,
                    "result": 6.0255832115268095
                },
                "ea8cd3d8-17ae-4a1e-8f83-1609469087af": {
                    "authors": [
                        "Andrew Y. Ng",
                        "Michael I. Jordan",
                        "Yair Weiss"
                    ],
                    "references": [
                        "52b8747c-6eef-43bc-8e11-aa3c4aae1111",
                        "5c89ee50-d7f5-4cd6-8eed-19a08efd6f90",
                        "75d0cdfa-44cd-4fc3-ae56-72e982cb383b",
                        "94898e1d-1e50-41ab-9dcc-2c2e030cddd0",
                        "98cfeac3-9abb-4f5b-9705-158c3b7b9d3a",
                        "d78003db-ad8a-48d2-be57-1c50e95cef72",
                        "fbb1d0f0-290f-490d-baab-63d29bc5f794"
                    ],
                    "keyword": [
                        "clustering",
                        "algorithms",
                        "spectral",
                        "eigenvectors",
                        "wide",
                        "variety",
                        "unresolved",
                        "tools",
                        "theory",
                        "surprisingly"
                    ],
                    "group": [],
                    "_id": "ea8cd3d8-17ae-4a1e-8f83-1609469087af",
                    "abstract": "Despite many empirical successes of spectral clustering methods— algorithms that cluster points using eigenvectors of matrices derived from the data—there are several unresolved issues. First. there are a wide variety of algorithms that use the eigenvectors in slightly different ways. Second, many of these algorithms have no proof that they will actually compute a reasonable clustering. In this paper, we present a simple spectral clustering algorithm that can be implemented using a few lines of Matlab. Using tools from matrix perturbation theory, we analyze the algorithm, and give conditions under which it can be expected to do well. We also show surprisingly good experimental results on a number of challenging clustering problems.",
                    "title": "On Spectral Clustering: Analysis and an algorithm",
                    "venue": "neural information processing systems",
                    "year": 2002,
                    "__v": 2,
                    "citationCount": 2537,
                    "result": 4.864780154486038
                },
                "ecd9f620-88b9-4f98-95a5-cca95d2722ff": {
                    "authors": [
                        "Yu-Ru Lin",
                        "Yun Chi",
                        "Shenghuo Zhu",
                        "Hari Sundaram",
                        "Belle L. Tseng"
                    ],
                    "references": [
                        "0a32020b-d21d-4fcc-b920-00324362cd4b",
                        "20da9656-3beb-4ffb-beed-423dac7efb0c",
                        "2256cad0-cf03-42da-bcf3-4a89be0ebf8e",
                        "26cd1d0d-331d-499a-8d35-a501e6af9200",
                        "287df3fe-6f46-4071-8ab5-99274b9887b1",
                        "2b3f5e5a-36cf-41ab-b9e0-a69f792866f2",
                        "2ba8193c-58e1-46fb-9f4c-5c3e393cf5c0",
                        "2f8e4ab5-8b2f-4fba-81e9-cbb7c09cd697",
                        "35cad820-9f36-41ac-86e7-b14bf90e75ba",
                        "72ec3684-a3ef-4061-8fc6-390ddfaf65d2",
                        "8f9e92cf-f266-4e51-807f-c098a260a0dc",
                        "93b8f6ed-865d-4698-8556-d7a8713afbf8",
                        "952ed52e-68a0-49d9-9ff6-21a849ea6af3",
                        "a86fabcd-83b9-441d-8b24-285e06700113",
                        "b80d9c8a-c008-495f-a1e3-01da69ec54d9",
                        "c8678358-846c-457d-a775-b74aa2f56b8d",
                        "db4206fb-0398-44f5-9b08-6b70ce170bf0",
                        "f972e14c-debe-452d-a9ba-aa7156923a76"
                    ],
                    "keyword": [
                        "communities",
                        "evolution",
                        "network",
                        "approach",
                        "traditional",
                        "time",
                        "social",
                        "discover",
                        "data",
                        "analyze"
                    ],
                    "group": [],
                    "_id": "ecd9f620-88b9-4f98-95a5-cca95d2722ff",
                    "abstract": "We discover communities from social network data, and analyze the community evolution. These communities are inherent characteristics of human interaction in online social networks, as well as paper citation networks. Also, communities may evolve over time, due to changes to individuals' roles and social status in the network as well as changes to individuals' research interests. We present an innovative algorithm that deviates from the traditional two-step approach to analyze community evolutions. In the traditional approach, communities are first detected for each time slice, and then compared to determine correspondences. We argue that this approach is inappropriate in applications with noisy data. In this paper, we propose FacetNet for analyzing communities and their evolutions through a robust unified process. In this novel framework, communities not only generate evolutions, they also are regularized by the temporal smoothness of evolutions. As a result, this framework will discover communities that jointly maximize the fit to the observed data and the temporal evolution. Our approach relies on formulating the problem in terms of non-negative matrix factorization, where communities and their evolutions are factorized in a unified way. Then we develop an iterative algorithm, with proven low time complexity, which is guaranteed to converge to an optimal solution. We perform extensive experimental studies, on both synthetic datasets and real datasets, to demonstrate that our method discovers meaningful communities and provides additional insights not directly obtainable from traditional methods.",
                    "title": "Facetnet: a framework for analyzing communities and their evolutions in dynamic networks",
                    "venue": "international world wide web conferences",
                    "year": 2008,
                    "__v": 2,
                    "citationCount": 142,
                    "result": 5.404677069428324
                },
                "ee86124f-174f-47ad-944a-52ba1a637d22": {
                    "authors": [
                        "Roger Guimerà",
                        "Marta Sales-Pardo",
                        "Luís A. Nunes Amaral"
                    ],
                    "references": [
                        "2c49234a-e2c0-4dc2-9c42-d46f7802b02d",
                        "362f16f0-4494-4f18-a9b8-f64fe83a50d8",
                        "597ecf84-4084-4057-a40d-30988ef74121",
                        "89afa754-f19c-4539-b71e-699bc7b46b1f",
                        "b0ef6e4d-4c86-4b10-9e0a-7b630ca8d7f7",
                        "d536f87d-bbda-42a1-b55f-63f83bfd85da",
                        "d7348c3f-f4df-4bec-acbc-ca5087ea7845",
                        "e9e15b3c-6dde-478b-b44e-e7501b67ba62",
                        "ee6e73fa-cc6d-4355-b6ac-736b1c48183d",
                        "f3481090-ad0e-4869-95c3-4a06b2b0adb1",
                        "fd1c9541-f4e7-42dc-9172-017e45160c94"
                    ],
                    "keyword": [
                        "networks",
                        "enzymes",
                        "targets",
                        "specifically",
                        "represent",
                        "promises",
                        "nodes",
                        "metabolites",
                        "links",
                        "essential"
                    ],
                    "group": [],
                    "_id": "ee86124f-174f-47ad-944a-52ba1a637d22",
                    "abstract": "Motivation: The lack of new antimicrobials, combined with increasing microbial resistance to old ones, poses a serious threat to public health. With hundreds of genomes sequenced, systems biology promises to help in solving this problem by uncovering new drug targets.#R##N##R##N#Results: Here, we propose an approach that is based on the mapping of the interactions between biochemical agents, such as proteins and metabolites, onto complex networks. We report that nodes and links in complex biochemical networks can be grouped into a small number of classes, based on their role in connecting different functional modules. Specifically, for metabolic networks, in which nodes represent metabolites and links represent enzymes, we demonstrate that some enzyme classes are more likely to be essential, some are more likely to be species-specific and some are likely to be both essential and specific. Our network-based enzyme classification scheme is thus a promising tool for the identification of drug targets.#R##N##R##N#Contact: rguimera@northwestern.edu#R##N##R##N#Supplementary information: Supplementary data are available at Bioinformatics online.",
                    "title": "A network-based method for target selection in metabolic networks",
                    "venue": "Bioinformatics",
                    "year": 2007,
                    "__v": 2,
                    "citationCount": 16,
                    "result": 6.337446034683678
                },
                "ef2e097d-9060-4e66-ab5a-ba742240f5e2": {
                    "authors": [
                        "Matthew J. Rattigan",
                        "Marc E. Maier",
                        "David D. Jensen"
                    ],
                    "references": [
                        "15a69f2f-1009-42ab-b7e0-7da508adda6a",
                        "1f81c292-6ddf-4d05-9c35-baf635fffe26",
                        "218fcf99-2ce4-426e-8561-e1dd8562c5d1",
                        "35cad820-9f36-41ac-86e7-b14bf90e75ba",
                        "4a72719e-6d47-4b91-a6ef-56446f8b9f3b",
                        "556effa9-58de-41f6-8943-e078a5a17929",
                        "5ea35ec7-ab9f-4d0e-9a85-ef4add482ec7",
                        "6207b5c7-b09d-4b5b-8a41-9695f4cc9195",
                        "639bbe84-4bda-4ede-9221-94af9e65dbd0",
                        "6619abc7-aea3-4448-a4a2-73934582925a",
                        "6e6cac85-1ca8-4d49-8e16-aa3d353fc20a",
                        "89022b09-5732-4493-9e2d-2046059dd2e5",
                        "94c11abe-49cf-4960-9f2e-89fb7b97786f",
                        "9578a7de-c4c5-404b-9348-69a64c2fb839",
                        "9aabd55f-5712-41f4-a0e3-ad190389a48b",
                        "a23effc2-0dad-40ee-b1d0-0375bf76fc8e",
                        "c0a97389-451d-48ad-be97-b7d94b3aa02a",
                        "c5b5edcb-39b0-476b-ba4e-79dfcc79b03e"
                    ],
                    "keyword": [
                        "networks",
                        "varieties",
                        "statistics",
                        "short",
                        "set",
                        "paths",
                        "nsi",
                        "node",
                        "graph",
                        "estimate"
                    ],
                    "group": [],
                    "_id": "ef2e097d-9060-4e66-ab5a-ba742240f5e2",
                    "abstract": "Statistics on networks have become vital to the study of relational data drawn from areas such as bibliometrics, fraud detection, bioinformatics, and the Internet. Calculating many of the most important measures - such as betweenness centrality, closeness centrality, and graph diameter-requires identifying short paths in these networks. However, finding these short paths can be intractable for even moderate-size networks. We introduce the concept of a network structure index (NSI), a composition of (1) a set of annotations on every node in the network and (2) a function that uses the annotations to estimate graph distance between pairs of nodes. We present several varieties of NSIs, examine their time and space complexity, and analyze their performance on synthetic and real data sets. We show that creating an NSI for a given network enables extremely efficient and accurate estimation of a wide variety of network statistics on that network.",
                    "title": "Using structure indices for efficient approximation of network properties",
                    "venue": "knowledge discovery and data mining",
                    "year": 2006,
                    "__v": 2,
                    "citationCount": 27,
                    "result": 4.202682612098647
                },
                "f246f6f3-f5c6-4cb8-a08f-1ca8d0d63cf8": {
                    "authors": [
                        "C. Lee Giles",
                        "Kurt D. Bollacker",
                        "Steve Lawrence"
                    ],
                    "references": [
                        "07c804bf-b60d-4b5d-b004-8f4652e7d81b",
                        "0895c22d-37c5-4c8f-9202-a32ebd2cb0c0",
                        "1ce7a9a3-91c4-45d6-984a-e1d240fd81aa",
                        "62ed9996-7de2-4fff-84a8-8b2f702d517b",
                        "f7eda5e5-6c14-4f52-8665-fc52b5e48f64"
                    ],
                    "keyword": [
                        "citation",
                        "paper",
                        "citeseer",
                        "indexing",
                        "context",
                        "publication",
                        "literature",
                        "journals"
                    ],
                    "group": [],
                    "_id": "f246f6f3-f5c6-4cb8-a08f-1ca8d0d63cf8",
                    "abstract": "We present CiteSeer: an autonomous citation indexing system which indexes academic literature in electronic format (e.g. Postscript files on the Web). CiteSeer understands how to parse citations, identify citations to the same paper in different formats, and identify the context of citations in the body of articles. CiteSeer provides most of the advantages of traditional (manually constructed) citation indexes (e.g. the ISI citation indexes), including: literature retrieval by following citation links (e.g. by providing a list of papers that cite a given paper), the evaluation and ranking of papers, authors, journals, etc. based on the number of citations, and the identification of research trends. CiteSeer has many advantages over traditional citation indexes, including the ability to create more up-to-date databases which are not limited to a preselected set of journals or restricted by journal publication delays, completely autonomous operation with a corresponding reduction in cost, and powerful interactive browsing of the literature using the context of citations. Given a particular paper of interest, CiteSeer can display the context of how the paper is cited in subsequent publications. This context may contain a brief summary of the paper, another author’s response to the paper, or subsequent work which builds upon the original article. CiteSeer allows the location of papers by keyword search or by citation links. Papers related to a given paper can be located using common citation information or word vector similarity. CiteSeer will soon be available for public use.",
                    "title": "CiteSeer: an automatic citation indexing system",
                    "venue": "",
                    "year": 1998,
                    "__v": 2,
                    "citationCount": 315,
                    "result": 5.31898150868739
                },
                "f5ab3435-0ea9-4db2-82db-f42f12df9aa6": {
                    "authors": [
                        "Yon Dourisboure",
                        "Filippo Geraci",
                        "Marco Pellegrini"
                    ],
                    "references": [
                        "18819165-7f73-4da1-9bf2-792c258be677",
                        "1a34d746-d1b6-42b6-9e77-19e2569d9627",
                        "1f09f092-b295-4941-bddf-0771eb569ef2",
                        "287df3fe-6f46-4071-8ab5-99274b9887b1",
                        "3c8a10d2-062f-4875-9b60-257bc801dba1",
                        "3deadb30-bc01-432f-a3bf-bf903162493e",
                        "3f610d75-809b-4a12-858f-95e346c17e8c",
                        "47499a73-446b-4766-aa65-dd78a136ecd8",
                        "52d1e58e-13cc-4910-9760-6a8f79994846",
                        "5584cb98-993c-4fc2-8975-4c06861f140b",
                        "6e551a7c-6769-49c1-93c5-037a06f4aaef",
                        "8098554b-a355-425c-8300-4dcfe672c56d",
                        "89b26cab-631a-4b87-a9aa-6c2d9d8af720",
                        "8e245630-549b-4b1c-afe7-cdf466295f32",
                        "8fdfe964-054e-4ae6-a3fd-fbc61a145a4f",
                        "91607150-f585-48ce-9475-737d58280e8a",
                        "a1f72d22-270a-4b1a-9d9f-668fef81d735",
                        "b0ef6e4d-4c86-4b10-9e0a-7b630ca8d7f7",
                        "bb02f0c6-3f59-4545-b72b-95dfdacea506",
                        "be23df9d-eee9-4db4-8e88-55c3b9dd0481",
                        "c66d83cd-0fd9-4d4b-a42e-cd9754bf5aca",
                        "d2e6738d-9ae8-4151-b118-ce69e6f2e52e",
                        "d3a8beb7-5ba1-4da6-ad8c-a2386683fd21",
                        "d3d86ca1-5de1-451e-8be0-c6055df46d9e",
                        "e31917d8-c25b-4511-8aa4-33e1cbb2f531",
                        "e4195865-096f-42ce-9d05-502eddea54b3",
                        "f39ed2ef-c643-4fd5-ab79-01a5f1da3635",
                        "f5e25042-8017-42b9-9c39-f38689d3e1cd",
                        "f829405f-d94b-4a3e-867e-8ffd39941651",
                        "fcfb8132-1170-4fe7-a9c1-6de2e9a7f2ac"
                    ],
                    "keyword": [
                        "communities",
                        "webgraph",
                        "nodes",
                        "web",
                        "dense",
                        "algorithm",
                        "subgraph",
                        "group",
                        "density",
                        "arcs"
                    ],
                    "group": [],
                    "_id": "f5ab3435-0ea9-4db2-82db-f42f12df9aa6",
                    "abstract": "The World Wide Web (WWW) is rapidly becoming important for society as a medium for sharing data, information and services, and there is a growing interest in tools for understanding collective behaviors and emerging phenomena in the WWW. In this paper we focus on the problem of searching and classifying communities in the web. Loosely speaking a community is a group of pages related to a common interest. More formally communities have been associated in the computer science literature with the existence of a locally dense sub-graph of the web-graph (where web pages are nodes and hyper-links are arcs of the web-graph). The core of our contribution is a new scalable algorithm for finding relatively dense subgraphs in massive graphs. We apply our algorithm on web-graphs built on three publicly available large crawls of the web (with raw sizes up to 120M nodes and 1G arcs). The effectiveness of our algorithm in finding dense subgraphs is demonstrated experimentally by embedding artificial communities in the web-graph and counting how many of these are blindly found. Effectiveness increases with the size and density of the communities: it is close to 100% for communities of a thirty nodes or more (even at low density). It is still about 80% even for communities of twenty nodes with density over 50% of the arcs present. At the lower extremes the algorithm catches 35% of dense communities made of ten nodes. We complete our Community Watch system by clustering the communities found in the web-graph into homogeneous groups by topic and labelling each group by representative keywords.",
                    "title": "Extraction and classification of dense communities in the web",
                    "venue": "international world wide web conferences",
                    "year": 2007,
                    "__v": 2,
                    "citationCount": 64,
                    "result": 5.4302426613278545
                },
                "f6326c6d-6313-43fb-a028-5bfe5cf3505c": {
                    "authors": [
                        "Andrew Y. Wu",
                        "Michael Garland",
                        "Jiawei Han"
                    ],
                    "references": [
                        "010793c8-fedb-49ee-88bc-1e20f8bae870",
                        "0500a560-277f-4868-a3e8-353e87aeb6eb",
                        "1d383765-fe50-4493-9714-3df0c5e05057",
                        "7442998c-f646-4c83-b5f7-081e60208c1f",
                        "8f9e92cf-f266-4e51-807f-c098a260a0dc",
                        "9863baf6-d69f-495a-8d5a-71442adea84e",
                        "b0ef6e4d-4c86-4b10-9e0a-7b630ca8d7f7",
                        "b4795aa3-5d49-4e23-92ed-d20c81c750c7",
                        "c7e4e04b-45da-4bae-8c8a-d17ca0087361",
                        "fabf6595-1331-4f1a-a6e0-24e1001a1fe7"
                    ],
                    "keyword": [
                        "graphs",
                        "networks",
                        "structure",
                        "multilevel",
                        "data",
                        "social",
                        "shortest",
                        "scalefree",
                        "realworld",
                        "paths"
                    ],
                    "group": [],
                    "_id": "f6326c6d-6313-43fb-a028-5bfe5cf3505c",
                    "abstract": "Many real-world graphs have been shown to be scale-free---vertex degrees follow power law distributions, vertices tend to cluster, and the average length of all shortest paths is small. We present a new model for understanding scale-free networks based on multilevel geodesic approximation, using a new data structure called a  multilevel mesh .Using this multilevel framework, we propose a new kind of graph clustering for data reduction of very large graph systems such as social, biological, or electronic networks. Finally, we apply our algorithms to real-world social networks and protein interaction graphs to show that they can reveal knowledge embedded in underlying graph structures. We also demonstrate how our data structures can be used to quickly answer approximate distance and shortest path queries on scale-free networks.",
                    "title": "Mining scale-free networks using geodesic clustering",
                    "venue": "knowledge discovery and data mining",
                    "year": 2004,
                    "__v": 2,
                    "citationCount": 34,
                    "result": 5.532187353469514
                },
                "f6a607ee-8043-4137-a6e6-070108fff1dd": {
                    "authors": [
                        "Jianhua Ruan",
                        "Weixiong Zhang"
                    ],
                    "references": [
                        "0a32020b-d21d-4fcc-b920-00324362cd4b",
                        "1a24e9c7-d0ce-4be4-8e3a-c849b4630851",
                        "608ab163-0fbf-4c6e-bf21-29b3145bae2a",
                        "60ef3852-fa16-44bf-9434-9909268ba5d8",
                        "9438a773-c15c-4ef2-a97c-54f643ce6082",
                        "a9bb2246-1ffd-4802-a236-db1c4083c57e",
                        "b0ef6e4d-4c86-4b10-9e0a-7b630ca8d7f7",
                        "bba5b861-70a6-47d8-96aa-e2722d016253",
                        "dd4ba9ca-8824-4921-b16b-3d6998f438ab",
                        "ea8cd3d8-17ae-4a1e-8f83-1609469087af",
                        "fe81612e-f699-467b-97ff-9e86560a7d78"
                    ],
                    "keyword": [
                        "algorithms",
                        "community",
                        "structures",
                        "optimization",
                        "networks",
                        "social",
                        "science",
                        "realworld",
                        "present",
                        "paper"
                    ],
                    "group": [],
                    "_id": "f6a607ee-8043-4137-a6e6-070108fff1dd",
                    "abstract": "Automatic discovery of community structures in complex networks is a fundamental task in many disciplines, including social science, engineering, and biology. A quantitative measure called modularity (Q) has been proposed to effectively assess the quality of community structures. Several community discovery algorithms have since been developed based on the optimization of Q. However, this optimization problem is NP-hard, and the existing algorithms have a low accuracy or are computationally expensive. In this paper, we present an efficient spectral algorithm for modularity optimization. When tested on a large number of synthetic or real-world networks, and compared to the existing algorithms, our method is efficient and and has a high accuracy. In addition, we have successfully applied our algorithm to detect interesting and meaningful community structures from real-world networks in different domains, including biology, medicine and social science. Due to space limitation, results of these applications are presented in a complete version of the paper available on our Website (http://cse .wustl.edu/  ~ jruan/).",
                    "title": "An Efficient Spectral Algorithm for Network Community Discovery and Its Applications to Biological and Social Networks",
                    "venue": "international conference on data mining",
                    "year": 2007,
                    "__v": 2,
                    "citationCount": 57,
                    "result": 7.461234795002278
                },
                "f972e14c-debe-452d-a9ba-aa7156923a76": {
                    "authors": [
                        "Yun Chi",
                        "Xiaodan Song",
                        "Dengyong Zhou",
                        "Koji Hino",
                        "Belle L. Tseng"
                    ],
                    "references": [
                        "0c3129f4-4662-4b1d-b5af-4de82cf93967",
                        "26cd1d0d-331d-499a-8d35-a501e6af9200",
                        "2ba8193c-58e1-46fb-9f4c-5c3e393cf5c0",
                        "61b70ef3-3bf9-4479-b811-433a50c1cb45",
                        "6fe3741c-1871-4c87-a255-c60bb4d456e9",
                        "7ec5f06e-2fe3-495a-84a0-94fcfe08bb7b",
                        "807b8ea8-a82a-46ae-87d4-387ea795fa7a",
                        "8aa8c8c0-54cb-4bfd-b31d-bc5c784380d5",
                        "8cf07005-c54f-44e6-a152-daf4a67edc06",
                        "93b8f6ed-865d-4698-8556-d7a8713afbf8",
                        "d78003db-ad8a-48d2-be57-1c50e95cef72",
                        "db4206fb-0398-44f5-9b08-6b70ce170bf0",
                        "e1ebee81-dfa4-4fe0-b0e1-c00df9ada4d4",
                        "ea8cd3d8-17ae-4a1e-8f83-1609469087af",
                        "eab9650b-4693-4dff-bfc4-372950024ec3",
                        "fb0fe732-1fad-4c66-b917-46318a0550fe",
                        "fb739bf0-40a7-48c9-a30d-c3ac421819de"
                    ],
                    "keyword": [
                        "clustering",
                        "evolutionary",
                        "spectral",
                        "problem",
                        "data",
                        "result",
                        "provide"
                    ],
                    "group": [],
                    "_id": "f972e14c-debe-452d-a9ba-aa7156923a76",
                    "abstract": "Evolutionary clustering is an emerging research area essential to important applications such as clustering dynamic Web and blog contents and clustering data streams. In evolutionary clustering, a good clustering result should fit the current data well, while simultaneously not deviate too dramatically from the recent history. To fulfill this dual purpose, a measure of  temporal smoothness  is integrated in the overall measure of clustering quality. In this paper, we propose two frameworks that incorporate temporal smoothness in evolutionary spectral clustering. For both frameworks, we start with intuitions gained from the well-known  k -means clustering problem, and then propose and solve corresponding cost functions for the evolutionary spectral clustering problems. Our solutions to the evolutionary spectral clustering problems provide more stable and consistent clustering results that are less sensitive to short-term noises while at the same time are adaptive to long-term cluster drifts. Furthermore, we demonstrate that our methods provide the optimal solutions to the relaxed versions of the corresponding evolutionary  k -means clustering problems. Performance experiments over a number of real and synthetic data sets illustrate our evolutionary spectral clustering methods provide more robust clustering results that are not sensitive to noise and can adapt to data drifts.",
                    "title": "Evolutionary spectral clustering by incorporating temporal smoothness",
                    "venue": "knowledge discovery and data mining",
                    "year": 2007,
                    "__v": 2,
                    "citationCount": 159,
                    "result": 4.834728112770709
                },
                "fb244d98-60f6-40f8-8c42-a233dfa5843f": {
                    "authors": [
                        "Michael I. Jordan",
                        "Zoubin Ghahramani",
                        "Tommi S. Jaakkola",
                        "Lawrence K. Saul"
                    ],
                    "references": [
                        "11f6604f-52c2-4426-914d-80e2710f4ae5",
                        "1c9e0295-e59f-41a2-b7ea-821efd4e65e9",
                        "2199c5a8-b004-4bcb-81c6-bb1568112077",
                        "2430ab7c-cec5-4cee-a05c-d34bc9eef826",
                        "2f61da3e-df6f-4404-aeec-f01a9a55f6fa",
                        "396dfb85-1ae7-4678-9f17-e63510d0b6e3",
                        "3cac4b23-ec43-4b4d-a234-ac3a35bf58b7",
                        "45a83c74-42cf-4193-b8fc-17c1853f26e4",
                        "50c2b314-1596-4444-ae9a-606df9899372",
                        "5fd00f57-47b6-4775-8d34-069344c2ca60",
                        "653388d4-5b08-490f-82ae-fc9317ce3faa",
                        "6f9aeb94-bd72-4ac6-8ec4-4c3f98dcb993",
                        "7d9f8158-d147-419b-b71d-d87d1d55d6f2",
                        "98f32ce5-a223-4ea0-ae5c-eafae780adaf",
                        "a24b04bd-66bc-496c-80b0-11e596a50034",
                        "a59c58cf-12b7-4424-b7bf-4b8d7ae9da3c",
                        "a6be1203-c21a-4cbd-b589-60fc782f2eaf",
                        "ad3a4ba4-5b88-4d61-9ba5-263cda996e9c",
                        "c4140a7e-f036-4816-a82f-9035ca99ed97",
                        "d3e00e7e-1c64-4d7a-b2b2-1ad98ba4c706",
                        "d68203bb-77bb-45fa-9ea8-8e014c3e26d8",
                        "df9e7880-4829-44db-8fc0-90c53657bbed",
                        "e8571238-943e-46d2-920b-63013e5dd5cd",
                        "f0f524d0-5e31-4dfe-9f6e-49b706d0d284",
                        "f5df4e93-55a5-4827-9eba-f22535baba96"
                    ],
                    "keyword": [
                        "models",
                        "variational",
                        "inference",
                        "graphical",
                        "transform",
                        "presents",
                        "original",
                        "number",
                        "networks",
                        "methods"
                    ],
                    "group": [],
                    "_id": "fb244d98-60f6-40f8-8c42-a233dfa5843f",
                    "abstract": "This paper presents a tutorial introduction to the use of variational methods for inference and learning in graphical models (Bayesian networks and Markov random fields). We present a number of examples of graphical models, including the QMR-DT database, the sigmoid belief network, the Boltzmann machine, and several variants of hidden Markov models, in which it is infeasible to run exact inference algorithms. We then introduce variational methods, which exploit laws of large numbers to transform the original graphical model into a simplified graphical model in which inference is efficient. Inference in the simpified model provides bounds on probabilities of interest in the original model. We describe a general framework for generating variational transformations based on convex duality. Finally we return to the examples and demonstrate how variational algorithms can be formulated in each case.",
                    "title": "An Introduction to Variational Methods for Graphical Models",
                    "venue": "Machine Learning",
                    "year": 1999,
                    "__v": 2,
                    "citationCount": 695,
                    "result": 5.740995107403776
                },
                "fbdbd8f0-1b0d-4eff-bb82-cdb6fee483e9": {
                    "authors": [
                        "Mason A. Porter",
                        "Peter J. Mucha",
                        "M. E. J. Newman",
                        "A. J. Friend"
                    ],
                    "references": [
                        "374aeac2-d5e8-41d2-8477-290fc13f74b0",
                        "4cb90d70-fd37-4256-a485-026c71f3ac92",
                        "60ef3852-fa16-44bf-9434-9909268ba5d8",
                        "aef245f5-c3bf-4734-990b-10dc44041a20",
                        "b0ef6e4d-4c86-4b10-9e0a-7b630ca8d7f7",
                        "b9523dd7-14e1-4cbf-a1c3-13fd5c81c3e8",
                        "b9c8d390-017c-43db-adaf-2afd565bca9f",
                        "c5ec6a5c-ff8d-494d-b093-66383861fe51",
                        "e4b8967e-454f-4cc8-8a65-d25e60c9c5d6"
                    ],
                    "keyword": [
                        "structure",
                        "house",
                        "committee",
                        "networks",
                        "hierarchical"
                    ],
                    "group": [],
                    "_id": "fbdbd8f0-1b0d-4eff-bb82-cdb6fee483e9",
                    "abstract": "We investigate the networks of committee and subcommittee assignments in the United States House of Representatives from the 101st–108th Congresses, with the committees connected by “interlocks” or common membership. We examine the community structure in these networks using several methods, revealing strong links between certain committees as well as an intrinsic hierarchical structure in the House as a whole. We identify structural changes, including additional hierarchical levels and higher modularity, resulting from the 1994 election, in which the Republican party earned majority status in the House for the first time in more than 40 years. We also combine our network approach with the analysis of roll call votes using singular value decomposition to uncover correlations between the political and organizational structure of House committees.",
                    "title": "Community Structure in the United States House of Representatives",
                    "venue": "Physica A-statistical Mechanics and Its Applications",
                    "year": 2007,
                    "__v": 1,
                    "citationCount": 23,
                    "result": 2.752092534288008
                },
                "feddae21-3c05-4743-80fa-b8e101f1b93f": {
                    "authors": [
                        "Gediminas Adomavicius",
                        "Alexander Tuzhilin"
                    ],
                    "references": [
                        "05234ed3-29a1-4a96-970c-44ebdf1a2fe6",
                        "05f5fba9-e7ca-4c46-be79-df57944a8b41",
                        "06f4b95e-9242-4408-b9cc-114357d88fe7",
                        "09880ee2-8770-4f53-96d0-90eaa4d3133d",
                        "0ad38f3e-8131-4287-9e62-2b2ae77f47f7",
                        "0e00f9b2-a002-465a-baa8-e167aa0fbeac",
                        "0ea745c7-58b2-48e8-9115-42e9b0d20f2a",
                        "1406f119-82cd-4cbb-9231-f885212a724e",
                        "1a9d8939-2919-4d50-8f2b-12b4aeb25aa1",
                        "1b7418af-1aba-4090-bad4-0dd0e900f5aa",
                        "238bfbbc-91cc-407b-8f37-b7942b09410a",
                        "23f66d97-4abf-479f-8af5-ec833d850a24",
                        "290e0375-d2ad-4bec-a94f-f05e1580125b",
                        "2d741908-7f21-4984-89b3-53e34ebbd3e7",
                        "2e34c4e7-7c2a-4172-af48-f32834865655",
                        "312e54ca-e7e9-4129-99f4-36f3aeff827e",
                        "3730ca24-81f0-456e-a7f3-5c0987e05147",
                        "38332469-d318-4976-a49e-9613695cac08",
                        "3cf667e4-b285-48e6-9816-085ce9c56f8c",
                        "44e91111-b413-4143-85a9-81872a97fa9d",
                        "47197c38-6c68-4fb5-9dd3-5b083262bd22",
                        "48632bf4-3e9f-4e98-b8f6-c08aaf7f2b58",
                        "48a1dbbd-b496-4b37-b3ba-db144c654d23",
                        "57bd2d58-8b2c-4783-9bd0-445de23e5e76",
                        "5d134b15-3e3f-402e-a4cd-d5022aef1305",
                        "5ee83a3b-d5f8-4532-97dd-c0579bed0d17",
                        "60c814e2-c4d1-47d7-9a5a-68f4141505ae",
                        "67fa583a-da81-4338-8349-e9a7f19f6fe2",
                        "694f475e-f6c4-4105-b645-84c7d592db30",
                        "6a6d14f3-83d4-4df4-bd27-94455c216c4f",
                        "6acfaeb4-5d94-4245-9a0a-dd0e8de54c6c",
                        "6b700ee7-1b54-4aa7-8cdb-d6a9a08592aa",
                        "7b960c31-7b3c-456f-9352-80380e2be085",
                        "7f2e92f7-6a67-491c-9546-cfd9b8a3b348",
                        "7f2f7b7d-3e6c-4196-9056-a943b3e96c2f",
                        "812c314c-9742-46fa-b1e8-5c7d640f1322",
                        "822235e6-6abe-442b-b761-b51795df418a",
                        "8735c7ea-f5c6-4310-b250-bc0d1bf5e834",
                        "8afd1b1d-7e34-43ac-8f93-654be568e61c",
                        "8c3149bc-5c9e-44bc-a58a-1ce8d92208d5",
                        "8ca1fc15-957a-4b80-9988-3c8cae85a4f6",
                        "8de6e50f-dde3-40ad-99fa-83fcbce40b76",
                        "92bd56e3-08b9-4c30-8539-5a8b8c042933",
                        "962a941e-d2b0-4ba7-8698-0257b7ebe695",
                        "98b23182-8f51-428a-a4af-a91d280471ca",
                        "9a7e4c43-690d-432d-b9a5-b519bf377646",
                        "9ad74e9b-de27-4f5a-8108-08043eb6d544",
                        "9ae0142d-b12f-42b1-ac48-d655fdec233f",
                        "9b602954-f960-46fe-87ae-41f06c486efc",
                        "a214c450-50cc-4210-acd9-480a2a7e8eb4",
                        "a3d4a2d1-d9dd-4f4d-9d8e-bcc056135d21",
                        "a69adad1-7efb-4204-93de-97aaeed2424a",
                        "b3321db8-4600-4969-ae23-336c36669dae",
                        "b9009e04-394c-4bcb-ab04-adc4365e0fe1",
                        "b919b53b-591a-4046-bda3-fe16340939d5",
                        "bc288dd8-9104-456a-9edf-f0526b0f8633",
                        "c12af7c5-ea9e-41b8-8d0a-eab301f8d270",
                        "c69ef004-087e-486c-97c9-9b4587d0b10a",
                        "c7ce0fc7-4d38-4355-aa19-ab35527d2519",
                        "cb512b89-7b86-4565-92c7-81599f1b1ca2",
                        "d1fcfcd1-faa8-4ba3-a0d2-50fb53a9f47f",
                        "d3c5fc62-2f5b-4ab2-a321-564ef9232643",
                        "d3ec5b39-7147-440d-82b0-4c4d05e671c9",
                        "d4e20fdf-beec-410c-a9b4-1ded047b320b",
                        "e09ac4da-c7fb-4a9d-9c77-cc41c6f74621",
                        "e5e1e41c-774c-4bb4-a087-bcd02fd37b0f",
                        "ed4c0d5d-5152-4915-b9bd-d0bd25f82674",
                        "f782a72e-eeca-4757-ace9-670012f961a8",
                        "f9571f5e-7bf7-427f-a512-b6979338ff31",
                        "fada1cc8-d343-45fb-9040-22795f1ca833",
                        "fe7f2770-ddca-4716-a7d9-545e68f691fe"
                    ],
                    "keyword": [
                        "recommender",
                        "systems",
                        "paper",
                        "methods",
                        "improve",
                        "extensions",
                        "describes",
                        "current",
                        "applicable"
                    ],
                    "group": [
                        null
                    ],
                    "_id": "feddae21-3c05-4743-80fa-b8e101f1b93f",
                    "abstract": "This paper presents an overview of the field of recommender systems and describes the current generation of recommendation methods that are usually classified into the following three main categories: content-based, collaborative, and hybrid recommendation approaches. This paper also describes various limitations of current recommendation methods and discusses possible extensions that can improve recommendation capabilities and make recommender systems applicable to an even broader range of applications. These extensions include, among others, an improvement of understanding of users and items, incorporation of the contextual information into the recommendation process, support for multicriteria ratings, and a provision of more flexible and less intrusive types of recommendations.",
                    "title": "Toward the next generation of recommender systems: a survey of the state-of-the-art and possible extensions",
                    "venue": "IEEE Transactions on Knowledge and Data Engineering",
                    "year": 2005,
                    "__v": 3,
                    "citationCount": 3038,
                    "result": 6.315634150850869
                }
            }
        ],
        "_id": "68faab18-b537-4f62-85cf-ddc9ef352362",
        "abstract": "The modern science of networks has brought significant advances to our understanding of complex systems. One of the most relevant features of graphs representing real systems is community structure, or clustering, i.e. the organization of vertices in clusters, with many edges joining vertices of the same cluster and comparatively few edges joining vertices of different clusters. Such clusters, or communities, can be considered as fairly independent compartments of a graph, playing a similar role like, e.g., the tissues or the organs in the human body. Detecting communities is of great importance in sociology, biology and computer science, disciplines where systems are often represented as graphs. This problem is very hard and not yet satisfactorily solved, despite the huge effort of a large interdisciplinary community of scientists working on it over the past few years. We will attempt a thorough exposition of the topic, from the definition of the main elements of the problem, to the presentation of most methods developed, with a special focus on techniques designed by statistical physicists, from the discussion of crucial issues like the significance of clustering and how methods should be tested and compared against each other, to the description of applications to real networks.",
        "title": "Community detection in graphs",
        "venue": "Physics Reports",
        "year": 2010,
        "__v": 2,
        "citationCount": 2124
    },
    {
        "authors": [
            "Joel A. Tropp",
            "Anna C. Gilbert"
        ],
        "references": [
            "0bb77e7f-bfc4-4d0d-873a-3d6d3c28b316",
            "0cd544e3-4888-4707-8a20-4a6780a71925",
            "15e40102-1512-4446-9850-c8102506cbd4",
            "449bfdfc-f916-422c-ac0d-ebfdd2ab773a",
            "6ea0a74d-1f54-4187-a299-7f6706432563",
            "6ff01654-66d1-49c7-b526-1c8ed7fa893a",
            "71a18de9-e543-4337-ab7a-3db31d9f8c00",
            "8fed7067-5f57-4f15-88cc-c948bcdd83f4",
            "9ec51dea-b1bb-49cc-9e36-9a13dfcadd52",
            "a53a3dda-b003-4d5c-96b1-e9afd8e35692",
            "bb3c38fa-c2b0-4d4f-8c9d-ca1884343474",
            "c380b798-6583-4821-9613-0a9731b1ced1",
            "de4fea1d-2739-4e0f-b5a3-08f0df58d787",
            "e43d02bf-6474-4b51-b481-fe1b09b29406",
            "eacf08f1-1e8b-44ee-90b5-234724ae8355",
            "f56b877b-4060-4754-b303-e8140968544c",
            "fd7205d5-656f-4fda-a9dc-3851a2c1da6f"
        ],
        "keyword": [
            "signal",
            "results",
            "omp",
            "pursuit",
            "measurements",
            "called",
            "bp",
            "algorithm",
            "theoretically",
            "settings"
        ],
        "group": [
            {
                "0bb77e7f-bfc4-4d0d-873a-3d6d3c28b316": {
                    "authors": [
                        "Deanna Needell",
                        "Roman Vershynin"
                    ],
                    "references": [
                        "000b6195-a08b-4775-86fc-e6787547bd3e",
                        "05c85ace-c998-47cd-a285-f6ecfd72004d",
                        "154ba112-2438-4621-a4ae-0110895207c0",
                        "5da96caa-c879-4877-8d55-771137f6643b",
                        "69b9ef96-11d5-49b0-9ae3-492763e02ca8",
                        "6ff01654-66d1-49c7-b526-1c8ed7fa893a",
                        "71a18de9-e543-4337-ab7a-3db31d9f8c00",
                        "88bf340b-5d4a-4446-9758-73e0c6e4ce86",
                        "941f432f-1ea2-477e-86c4-4f7bebd8cb70",
                        "a53a3dda-b003-4d5c-96b1-e9afd8e35692",
                        "dbb8606e-3419-45c0-84ee-8872c86fdcd8",
                        "e27ac60c-b7e6-4bcd-bf8c-5edcddf5d6b7",
                        "eacf08f1-1e8b-44ee-90b5-234724ae8355",
                        "f56b877b-4060-4754-b303-e8140968544c"
                    ],
                    "keyword": [],
                    "group": [],
                    "_id": "0bb77e7f-bfc4-4d0d-873a-3d6d3c28b316",
                    "abstract": "This paper seeks to bridge the two major algorithmic approaches to sparse signal recovery from an incomplete set of linear measurements—L1-minimization methods and iterative methods (Matching Pursuits). We find a simple regularized version of Orthogonal Matching Pursuit (ROMP) which has advantages of both approaches: the speed and transparency of OMP and the strong uniform guarantees of L1-minimization. Our algorithm, ROMP, reconstructs a sparse signal in a number of iterations linear in the sparsity, and the reconstruction is exact provided the linear measurements satisfy the uniform uncertainty principle.",
                    "title": "Uniform Uncertainty Principle and Signal Recovery via Regularized Orthogonal Matching Pursuit",
                    "venue": "Foundations of Computational Mathematics",
                    "year": 2009,
                    "__v": 0,
                    "citationCount": 260,
                    "result": 2.9411764705882355
                },
                "6ea0a74d-1f54-4187-a299-7f6706432563": {
                    "authors": [
                        "Holger Rauhut"
                    ],
                    "references": [
                        "014cfe85-5aef-4543-abba-772b0ff3c87f",
                        "05c85ace-c998-47cd-a285-f6ecfd72004d",
                        "0bb77e7f-bfc4-4d0d-873a-3d6d3c28b316",
                        "38c8c7a7-e6f4-4f59-91de-76d74e801418",
                        "449bfdfc-f916-422c-ac0d-ebfdd2ab773a",
                        "692d603d-a504-4899-928e-5cb5643b66b7",
                        "69b9ef96-11d5-49b0-9ae3-492763e02ca8",
                        "71a18de9-e543-4337-ab7a-3db31d9f8c00",
                        "a53a3dda-b003-4d5c-96b1-e9afd8e35692",
                        "bb3c38fa-c2b0-4d4f-8c9d-ca1884343474",
                        "e43d02bf-6474-4b51-b481-fe1b09b29406",
                        "f56b877b-4060-4754-b303-e8140968544c"
                    ],
                    "keyword": [
                        "bp",
                        "trigonometric",
                        "sparse",
                        "small",
                        "samples",
                        "result",
                        "pursuit",
                        "polynomial",
                        "omp",
                        "number"
                    ],
                    "group": [],
                    "_id": "6ea0a74d-1f54-4187-a299-7f6706432563",
                    "abstract": "Recently, it has been observed that a sparse trigonometric polynomial, i.e., having only a small number of nonzero coefficients, can be reconstructed exactly from a small number of random samples using basis pursuit (BP) or orthogonal matching pursuit (OMP). In this paper, it is shown that recovery by a BP variant is stable under perturbation of the samples values by noise. A similar partial result for OMP is provided. For BP, in addition, the stability result is extended to (nonsparse) trigonometric polynomials that can be well approximated by sparse ones. The theoretical findings are illustrated by numerical experiments.",
                    "title": "Stability Results for Random Sampling of Sparse Trigonometric Polynomials",
                    "venue": "IEEE Transactions on Information Theory",
                    "year": 2008,
                    "__v": 2,
                    "citationCount": 44,
                    "result": 12.74637043084344
                },
                "6ff01654-66d1-49c7-b526-1c8ed7fa893a": {
                    "authors": [
                        "Emmanuel J. Candès",
                        "Terence Tao"
                    ],
                    "references": [
                        "0e654e87-bc20-4fed-bcf8-cb2b99cbd39c",
                        "449bfdfc-f916-422c-ac0d-ebfdd2ab773a",
                        "71a18de9-e543-4337-ab7a-3db31d9f8c00",
                        "87a4faed-c1a5-45c8-81eb-3bf19ae19011",
                        "87c3242f-f4a5-4ef1-8ec3-e52c4402b8c0",
                        "a53a3dda-b003-4d5c-96b1-e9afd8e35692",
                        "d84405a3-88f2-4f71-8575-d16f3c8d4ca1",
                        "f11bfae2-e272-4acc-b231-a9619f1e4d6c",
                        "f56b877b-4060-4754-b303-e8140968544c",
                        "f56dbdc3-f2ee-4a66-a3fb-df142f830dc5"
                    ],
                    "keyword": [
                        "spl",
                        "recover",
                        "problem",
                        "works",
                        "vector",
                        "parsub",
                        "error"
                    ],
                    "group": [],
                    "_id": "6ff01654-66d1-49c7-b526-1c8ed7fa893a",
                    "abstract": "This paper considers a natural error correcting problem with real valued input/output. We wish to recover an input vector f/spl isin/R/sup n/ from corrupted measurements y=Af+e. Here, A is an m by n (coding) matrix and e is an arbitrary and unknown vector of errors. Is it possible to recover f exactly from the data y? We prove that under suitable conditions on the coding matrix A, the input f is the unique solution to the /spl lscr//sub 1/-minimization problem (/spl par/x/spl par//sub /spl lscr/1/:=/spl Sigma//sub i/|x/sub i/|) min(g/spl isin/R/sup n/) /spl par/y - Ag/spl par//sub /spl lscr/1/ provided that the support of the vector of errors is not too large, /spl par/e/spl par//sub /spl lscr/0/:=|{i:e/sub i/ /spl ne/ 0}|/spl les//spl rho//spl middot/m for some /spl rho/>0. In short, f can be recovered exactly by solving a simple convex optimization problem (which one can recast as a linear program). In addition, numerical experiments suggest that this recovery procedure works unreasonably well; f is recovered exactly even in situations where a significant fraction of the output is corrupted. This work is related to the problem of finding sparse solutions to vastly underdetermined systems of linear equations. There are also significant connections with the problem of recovering signals from highly incomplete measurements. In fact, the results introduced in this paper improve on our earlier work. Finally, underlying the success of /spl lscr//sub 1/ is a crucial property we call the uniform uncertainty principle that we shall describe in detail.",
                    "title": "Decoding by linear programming",
                    "venue": "IEEE Transactions on Information Theory",
                    "year": 2005,
                    "__v": 2,
                    "citationCount": 1991,
                    "result": 4.573112345171169
                },
                "71a18de9-e543-4337-ab7a-3db31d9f8c00": {
                    "authors": [
                        "Emmanuel J. Candès",
                        "Terence Tao"
                    ],
                    "references": [
                        "036a19f8-fdca-4e84-a237-e54f2108dcb4",
                        "2d75f21b-8617-4c21-a1bf-467a82458459",
                        "5eb8608d-d0a1-4f14-af98-8a26bab51fae",
                        "6ff01654-66d1-49c7-b526-1c8ed7fa893a",
                        "87a4faed-c1a5-45c8-81eb-3bf19ae19011",
                        "9b021b12-2e59-42bc-9e29-86e480e652b7",
                        "a53a3dda-b003-4d5c-96b1-e9afd8e35692",
                        "c385db5b-803b-4d88-b756-f7cc417bbfb0",
                        "d84405a3-88f2-4f71-8575-d16f3c8d4ca1",
                        "e33adb02-12d9-47b9-af5e-b9a79070a920",
                        "f56b877b-4060-4754-b303-e8140968544c"
                    ],
                    "keyword": [
                        "measurements",
                        "vector",
                        "suppose",
                        "random",
                        "obeys"
                    ],
                    "group": [],
                    "_id": "71a18de9-e543-4337-ab7a-3db31d9f8c00",
                    "abstract": "Suppose we are given a vector f in a class FsubeRopf N  , e.g., a class of digital signals or digital images. How many linear measurements do we need to make about f to be able to recover f to within precision epsi in the Euclidean (lscr 2 ) metric? This paper shows that if the objects of interest are sparse in a fixed basis or compressible, then it is possible to reconstruct f to within very high accuracy from a small number of random measurements by solving a simple linear program. More precisely, suppose that the nth largest entry of the vector |f| (or of its coefficients in a fixed basis) obeys |f| (n) lesRmiddotn -1 p/, where R>0 and p>0. Suppose that we take measurements y k =langf #  ,X k rang,k=1,...,K, where the X k  are N-dimensional Gaussian vectors with independent standard normal entries. Then for each f obeying the decay estimate above for some 0 t , defined as the solution to the constraints y k =langf #  ,X k rang with minimal lscr 1  norm, obeys parf-f # par lscr2 lesC p  middotRmiddot(K/logN) -r , r=1/p-1/2. There is a sense in which this result is optimal; it is generally impossible to obtain a higher accuracy from any set of K measurements whatsoever. The methodology extends to various other random measurement ensembles; for example, we show that similar results hold if one observes a few randomly sampled Fourier coefficients of f. In fact, the results are quite general and require only two hypotheses on the measurement ensemble which are detailed",
                    "title": "Near-Optimal Signal Recovery From Random Projections: Universal Encoding Strategies?",
                    "venue": "IEEE Transactions on Information Theory",
                    "year": 2006,
                    "__v": 1,
                    "citationCount": 1928,
                    "result": 4.601931742596705
                },
                "8fed7067-5f57-4f15-88cc-c948bcdd83f4": {
                    "authors": [
                        "Dimitris Achlioptas"
                    ],
                    "references": [
                        "0abac7af-48d0-4858-85ee-02431aa7219f",
                        "0f094852-0668-4dfe-92cc-ae5659ffc1d9",
                        "2fd9e662-2a85-49ce-97af-9ae76df4ca5f",
                        "49636ac5-e7f1-4d06-8460-114d23de9a66",
                        "6665ab85-61a8-4997-9a9e-77e0353f06a8",
                        "75fdce7f-366a-427a-a0ba-0400c26feabf",
                        "9a33ddde-c275-4997-b037-0b48648bb1f7",
                        "a06138e8-6351-4d1f-aead-6418990b2918",
                        "adcd100c-2ef5-409e-8d80-06cfc83fad9e",
                        "adf6fdf9-01a0-4051-9d99-965f4a5baa4d",
                        "bf132fef-c091-4f7e-a850-22b83ff7a9e2",
                        "c19c233b-6b1d-40a9-b553-a6efbe11932c",
                        "dd7b260e-5911-40a5-95fe-1beabd611348",
                        "e4e5c3a5-2473-4cea-8e0f-13bc369e4d6a",
                        "e7ad5317-8580-47c8-82f3-9dff19d3e5f8",
                        "f17cee87-b96c-4891-b510-c165727b4d4a"
                    ],
                    "keyword": [
                        "embedded",
                        "constructions",
                        "random",
                        "projecting",
                        "points",
                        "kdimensional",
                        "euclidean"
                    ],
                    "group": [],
                    "_id": "8fed7067-5f57-4f15-88cc-c948bcdd83f4",
                    "abstract": "A classic result of Johnson and Lindenstrauss asserts that any set of n points in d-dimensional Euclidean space can be embedded into k-dimensional Euclidean space---where k is logarithmic in n and independent of d--so that all pairwise distances are maintained within an arbitrarily small factor. All known constructions of such embeddings involve projecting the n points onto a spherically random k-dimensional hyperplane through the origin. We give two constructions of such embeddings with the property that all elements of the projection matrix belong in {-1, 0, +1 }. Such constructions are particularly well suited for database environments, as the computation of the embedding reduces to evaluating a single aggregate over k random partitions of the attributes.",
                    "title": "Database-friendly random projections: Johnson-Lindenstrauss with binary coins",
                    "venue": "Journal of Computer and System Sciences",
                    "year": 2003,
                    "__v": 1,
                    "citationCount": 387,
                    "result": 2.800112517789863
                },
                "9ec51dea-b1bb-49cc-9e36-9a13dfcadd52": {
                    "authors": [
                        "Bhaskar D. Rao",
                        "Kenneth Kreutz-Delgado"
                    ],
                    "references": [
                        "404775ac-d2d2-4a0b-8195-9458da97105b",
                        "428e2706-08da-47e6-ac8f-cb01d456df67",
                        "592f4278-aa82-4c43-9026-c4e180500dcb",
                        "b886fa0c-5409-4030-99ac-805440552eff",
                        "bb3c38fa-c2b0-4d4f-8c9d-ca1884343474",
                        "bd91c3d4-f7db-498f-b5ea-0dd2f9e55038",
                        "c0fba0f5-76d1-402f-909a-868291247426",
                        "cb17c20e-e335-43dc-b2ae-350e43b74faa",
                        "e664c24c-6222-47c5-aa3a-b3936dcdd18e",
                        "f4bd6520-1046-48b5-993a-98a38c25172c",
                        "f7d16f47-63d0-47d9-ae1c-e90e9ef0e804"
                    ],
                    "keyword": [
                        "algorithms",
                        "measures",
                        "entropies",
                        "convergence",
                        "solutions",
                        "optimal",
                        "minimizing",
                        "methodology",
                        "gaussian",
                        "diversity"
                    ],
                    "group": [],
                    "_id": "9ec51dea-b1bb-49cc-9e36-9a13dfcadd52",
                    "abstract": "A methodology is developed to derive algorithms for optimal basis selection by minimizing diversity measures proposed by Wickerhauser (1994) and Donoho (1994). These measures include the p-norm-like (l/sub (p/spl les/1)/) diversity measures and the Gaussian and Shannon entropies. The algorithm development methodology uses a factored representation for the gradient and involves successive relaxation of the Lagrangian necessary condition. This yields algorithms that are intimately related to the affine scaling transformation (AST) based methods commonly employed by the interior point approach to nonlinear optimization. The algorithms minimizing the (l/sub (p/spl les/1)/) diversity measures are equivalent to a previously developed class of algorithms called focal underdetermined system solver (FOCUSS). The general nature of the methodology provides a systematic approach for deriving this class of algorithms and a natural mechanism for extending them. It also facilitates a better understanding of the convergence behavior and a strengthening of the convergence results. The Gaussian entropy minimization algorithm is shown to be equivalent to a well-behaved p=0 norm-like optimization algorithm. Computer experiments demonstrate that the p-norm-like and the Gaussian entropy algorithms perform well, converging to sparse solutions. The Shannon entropy algorithm produces solutions that are concentrated but are shown to not converge to a fully sparse solution.",
                    "title": "An affine scaling methodology for best basis selection",
                    "venue": "IEEE Transactions on Signal Processing",
                    "year": 1999,
                    "__v": 2,
                    "citationCount": 152,
                    "result": 6.826892586257911
                },
                "a53a3dda-b003-4d5c-96b1-e9afd8e35692": {
                    "authors": [
                        "Emmanuel J. Candès",
                        "Justin K. Romberg",
                        "Terence Tao"
                    ],
                    "references": [
                        "2d75f21b-8617-4c21-a1bf-467a82458459",
                        "4114181f-6f48-4cb6-b6d3-b337515d57f8",
                        "449bfdfc-f916-422c-ac0d-ebfdd2ab773a",
                        "53c1d13a-863d-4db2-bc77-bbc7f8a45fa8",
                        "5eb8608d-d0a1-4f14-af98-8a26bab51fae",
                        "7291a02d-1d94-48b7-a4e2-35406c0e52ad",
                        "87a4faed-c1a5-45c8-81eb-3bf19ae19011",
                        "d2104367-6389-4b06-8dbe-bab7e05b903b",
                        "f11bfae2-e272-4acc-b231-a9619f1e4d6c"
                    ],
                    "keyword": [
                        "spl",
                        "frequency",
                        "samples",
                        "reconstructing",
                        "spikes",
                        "set",
                        "problem",
                        "probability",
                        "omega",
                        "convex"
                    ],
                    "group": [
                        null
                    ],
                    "_id": "a53a3dda-b003-4d5c-96b1-e9afd8e35692",
                    "abstract": "This paper considers the model problem of reconstructing an object from incomplete frequency samples. Consider a discrete-time signal f/spl isin/C/sup N/ and a randomly chosen set of frequencies /spl Omega/. Is it possible to reconstruct f from the partial knowledge of its Fourier coefficients on the set /spl Omega/? A typical result of this paper is as follows. Suppose that f is a superposition of |T| spikes f(t)=/spl sigma//sub /spl tau//spl isin/T/f(/spl tau/)/spl delta/(t-/spl tau/) obeying |T|/spl les/C/sub M//spl middot/(log N)/sup -1/ /spl middot/ |/spl Omega/| for some constant C/sub M/>0. We do not know the locations of the spikes nor their amplitudes. Then with probability at least 1-O(N/sup -M/), f can be reconstructed exactly as the solution to the /spl lscr//sub 1/ minimization problem. In short, exact recovery may be obtained by solving a convex optimization problem. We give numerical values for C/sub M/ which depend on the desired probability of success. Our result may be interpreted as a novel kind of nonlinear sampling theorem. In effect, it says that any signal made out of |T| spikes may be recovered by convex programming from almost every set of frequencies of size O(|T|/spl middot/logN). Moreover, this is nearly optimal in the sense that any method succeeding with probability 1-O(N/sup -M/) would in general require a number of frequency samples at least proportional to |T|/spl middot/logN. The methodology extends to a variety of other situations and higher dimensions. For example, we show how one can reconstruct a piecewise constant (one- or two-dimensional) object from incomplete frequency samples - provided that the number of jumps (discontinuities) obeys the condition above - by minimizing other convex functionals such as the total variation of f.",
                    "title": "Robust uncertainty principles: exact signal reconstruction from highly incomplete frequency information",
                    "venue": "IEEE Transactions on Information Theory",
                    "year": 2006,
                    "__v": 3,
                    "citationCount": 3800,
                    "result": 4.06006288001644
                },
                "bb3c38fa-c2b0-4d4f-8c9d-ca1884343474": {
                    "authors": [
                        "S. Mallat",
                        "Zhifeng Zhang"
                    ],
                    "references": [
                        "3f0bc2c9-a5c2-4e4c-a4e9-7631e36bc6a3",
                        "cb17c20e-e335-43dc-b2ae-350e43b74faa"
                    ],
                    "keyword": [
                        "signal",
                        "matching",
                        "pursuit",
                        "dictionary",
                        "waveforms",
                        "timefrequency",
                        "structures",
                        "selected",
                        "functions",
                        "expansion"
                    ],
                    "group": [],
                    "_id": "bb3c38fa-c2b0-4d4f-8c9d-ca1884343474",
                    "abstract": "The authors introduce an algorithm, called matching pursuit, that decomposes any signal into a linear expansion of waveforms that are selected from a redundant dictionary of functions. These waveforms are chosen in order to best match the signal structures. Matching pursuits are general procedures to compute adaptive signal representations. With a dictionary of Gabor functions a matching pursuit defines an adaptive time-frequency transform. They derive a signal energy distribution in the time-frequency plane, which does not include interference terms, unlike Wigner and Cohen class distributions. A matching pursuit isolates the signal structures that are coherent with respect to a given dictionary. An application to pattern extraction from noisy signals is described. They compare a matching pursuit decomposition with a signal expansion over an optimized wavepacket orthonormal basis, selected with the algorithm of Coifman and Wickerhauser see (IEEE Trans. Informat. Theory, vol. 38, Mar. 1992). >",
                    "title": "Matching pursuits with time-frequency dictionaries",
                    "venue": "IEEE Transactions on Signal Processing",
                    "year": 1993,
                    "__v": 2,
                    "citationCount": 2385,
                    "result": 6.1878773183861355
                },
                "c380b798-6583-4821-9613-0a9731b1ced1": {
                    "authors": [
                        "Ronald A. DeVore",
                        "Vladimir N. Temlyakov"
                    ],
                    "references": [
                        "3cc2c3e4-c2c1-4593-a006-814c26fa3857",
                        "eb5bfcb8-7dd1-4fef-93de-7351e27dfade"
                    ],
                    "keyword": [
                        "greedy",
                        "algorithms",
                        "function",
                        "estimates",
                        "approximation",
                        "relaxed",
                        "rate",
                        "pure",
                        "orthogonal",
                        "discussed"
                    ],
                    "group": [],
                    "_id": "c380b798-6583-4821-9613-0a9731b1ced1",
                    "abstract": "Estimates are given for the rate of approximation of a function by means of greedy algorithms. The estimates apply to approximation from an arbitrary dictionary of functions. Three greedy algorithms are discussed: the Pure Greedy Algorithm, an Orthogonal Greedy Algorithm, and a Relaxed Greedy Algorithm.",
                    "title": "Some remarks on greedy algorithms",
                    "venue": "Advances in Computational Mathematics",
                    "year": 1996,
                    "__v": 2,
                    "citationCount": 93,
                    "result": 6.2183216250553714
                },
                "e43d02bf-6474-4b51-b481-fe1b09b29406": {
                    "authors": [
                        "Stefan Kunis",
                        "Holger Rauhut"
                    ],
                    "references": [
                        "07b31ae6-8ce6-4acf-97ab-1cd9d45246ca",
                        "1ab0f330-2dca-496c-8992-111e9e80fc0e",
                        "38c8c7a7-e6f4-4f59-91de-76d74e801418",
                        "3ab1d996-976c-43ff-adbc-15ec54f31af9",
                        "449bfdfc-f916-422c-ac0d-ebfdd2ab773a",
                        "5eb8608d-d0a1-4f14-af98-8a26bab51fae",
                        "69b9ef96-11d5-49b0-9ae3-492763e02ca8",
                        "6ea0a74d-1f54-4187-a299-7f6706432563",
                        "6ff01654-66d1-49c7-b526-1c8ed7fa893a",
                        "71a18de9-e543-4337-ab7a-3db31d9f8c00",
                        "a53a3dda-b003-4d5c-96b1-e9afd8e35692",
                        "bb3c38fa-c2b0-4d4f-8c9d-ca1884343474",
                        "bef09d21-c47a-4966-8e6d-644bcab384dc",
                        "d84405a3-88f2-4f71-8575-d16f3c8d4ca1",
                        "e35e172e-0856-4aaf-bdbc-f23711f40232",
                        "f56b877b-4060-4754-b303-e8140968544c"
                    ],
                    "keyword": [
                        "pursuit",
                        "basis",
                        "thresholding",
                        "samples",
                        "recovery",
                        "reconstructing",
                        "probability",
                        "omp",
                        "greedy",
                        "algorithms"
                    ],
                    "group": [],
                    "_id": "e43d02bf-6474-4b51-b481-fe1b09b29406",
                    "abstract": "We investigate the problem of reconstructing sparse multivariate trigonometric polynomials from few randomly taken samples by Basis Pursuit and greedy algorithms such as Orthogonal Matching Pursuit (OMP) and Thresholding. While recovery by Basis Pursuit has recently been studied by several authors, we provide theoretical results on the success probability of reconstruction via Thresholding and OMP for both a continuous and a discrete probability model for the sampling points. We present numerical experiments, which indicate that usually Basis Pursuit is significantly slower than greedy algorithms, while the recovery rates are very similar.",
                    "title": "Random Sampling of Sparse Trigonometric Polynomials, II. Orthogonal Matching Pursuit versus Basis Pursuit",
                    "venue": "Foundations of Computational Mathematics",
                    "year": 2008,
                    "__v": 2,
                    "citationCount": 52,
                    "result": 11.969438663369205
                },
                "f56b877b-4060-4754-b303-e8140968544c": {
                    "authors": [
                        "David L. Donoho"
                    ],
                    "references": [
                        "036a19f8-fdca-4e84-a237-e54f2108dcb4",
                        "05c85ace-c998-47cd-a285-f6ecfd72004d",
                        "0bb77e7f-bfc4-4d0d-873a-3d6d3c28b316",
                        "0ed39048-dd26-467a-bcd5-7017fcccddb5",
                        "225591b8-1c1a-4854-81d4-5b5f364c20a9",
                        "2862ec34-58f4-41c0-8790-1740130f1814",
                        "2a15f947-2402-4979-94b8-53de9ceef26e",
                        "3d414a5e-b97a-498e-8a75-920997235c6b",
                        "3dd913b8-e22d-434e-9015-bf68fbbb7bef",
                        "3ddea798-1e4f-408a-86db-a611c7bbcdcf",
                        "449bfdfc-f916-422c-ac0d-ebfdd2ab773a",
                        "4c9f2bac-2f23-4170-a0f1-a3001f63a7b9",
                        "5eb8608d-d0a1-4f14-af98-8a26bab51fae",
                        "71a18de9-e543-4337-ab7a-3db31d9f8c00",
                        "7291a02d-1d94-48b7-a4e2-35406c0e52ad",
                        "834863b2-34f0-40dc-b4d2-f4189eaa262a",
                        "87a4faed-c1a5-45c8-81eb-3bf19ae19011",
                        "8dd4158a-bbc4-40cf-a4d5-14e0fe630387",
                        "9b021b12-2e59-42bc-9e29-86e480e652b7",
                        "9e65914c-bfef-45e7-9fd7-85c39ed13ac4",
                        "a53a3dda-b003-4d5c-96b1-e9afd8e35692",
                        "adc31a96-1f8e-4793-8ee9-ecef04a16ac6",
                        "ae4ab999-5078-4348-9a3d-94c019952bcc",
                        "aecf8a08-eff7-4182-8bbb-a7b29de2f281",
                        "bb3c38fa-c2b0-4d4f-8c9d-ca1884343474",
                        "c380b798-6583-4821-9613-0a9731b1ced1",
                        "c9bf7235-7aad-4e6d-a9a6-e4a6bbddc327",
                        "ca546a51-ffda-46b1-b783-ff512ec9c4bd",
                        "cd9bd50b-d672-43a9-b0c2-0b332cf0b88e",
                        "d2104367-6389-4b06-8dbe-bab7e05b903b",
                        "d6457de8-9f03-4671-91da-f557a0ec20e0",
                        "defc112d-f91d-4b34-9d44-bd7f702c2391",
                        "f11bfae2-e272-4acc-b231-a9619f1e4d6c",
                        "ff44599f-5e74-4d9b-94d3-286592973471"
                    ],
                    "keyword": [
                        "measure",
                        "reconstruct",
                        "nwidths",
                        "nonadaptive",
                        "linear",
                        "coefficients"
                    ],
                    "group": [
                        null
                    ],
                    "_id": "f56b877b-4060-4754-b303-e8140968544c",
                    "abstract": "Suppose x is an unknown vector in Ropf m  (a digital image or signal); we plan to measure n general linear functionals of x and then reconstruct. If x is known to be compressible by transform coding with a known transform, and we reconstruct via the nonlinear procedure defined here, the number of measurements n can be dramatically smaller than the size m. Thus, certain natural classes of images with m pixels need only n=O(m 1/4 log 5/2 (m)) nonadaptive nonpixel samples for faithful recovery, as opposed to the usual m pixel samples. More specifically, suppose x has a sparse representation in some orthonormal basis (e.g., wavelet, Fourier) or tight frame (e.g., curvelet, Gabor)-so the coefficients belong to an lscr p  ball for 0 2  error O(N 1/2-1 p/). It is possible to design n=O(Nlog(m)) nonadaptive measurements allowing reconstruction with accuracy comparable to that attainable with direct knowledge of the N most important coefficients. Moreover, a good approximation to those N important coefficients is extracted from the n measurements by solving a linear program-Basis Pursuit in signal processing. The nonadaptive measurements have the character of \"random\" linear combinations of basis/frame elements. Our results use the notions of optimal recovery, of n-widths, and information-based complexity. We estimate the Gel'fand n-widths of lscr p  balls in high-dimensional Euclidean space in the case 0<ples1, and give a criterion identifying near- optimal subspaces for Gel'fand n-widths. We show that \"most\" subspaces are near-optimal, and show that convex optimization (Basis Pursuit) is a near-optimal way to extract information derived from these near-optimal subspaces",
                    "title": "Compressed sensing",
                    "venue": "IEEE Transactions on Information Theory",
                    "year": 2006,
                    "__v": 3,
                    "citationCount": 6079,
                    "result": 6.689074338562829
                },
                "fd7205d5-656f-4fda-a9dc-3851a2c1da6f": {
                    "authors": [
                        "Dmitry M. Malioutov",
                        "Müjdat Çetin",
                        "Alan S. Willsky"
                    ],
                    "references": [
                        "1a77aa56-c4f8-466f-a1e6-e6b538199858",
                        "449bfdfc-f916-422c-ac0d-ebfdd2ab773a",
                        "58df00c0-c4df-44bd-8bec-810164b323d3",
                        "87a4faed-c1a5-45c8-81eb-3bf19ae19011",
                        "de4fea1d-2739-4e0f-b5a3-08f0df58d787"
                    ],
                    "keyword": [
                        "regularization",
                        "pursuit",
                        "parameter",
                        "basis",
                        "solutions",
                        "problem",
                        "algorithm"
                    ],
                    "group": [],
                    "_id": "fd7205d5-656f-4fda-a9dc-3851a2c1da6f",
                    "abstract": "We explore the application of a homotopy continuation-based method for sparse signal representation in overcomplete dictionaries. Our problem setup is based on the basis pursuit framework, which involves a convex optimization problem consisting of terms enforcing data fidelity and sparsity, balanced by a regularization parameter. Choosing a good regularization parameter in this framework is a challenging task. We describe a homotopy continuation-based algorithm to find and trace efficiently all solutions of basis pursuit as a function of the regularization parameter. In addition to providing an attractive alternative to existing optimization methods for solving the basis pursuit problem, this algorithm can also be used to provide an automatic choice for the regularization parameter, based on prior information about the desired number of non-zero components in the sparse representation. Our numerical examples demonstrate the effectiveness of this algorithm in accurately and efficiently generating entire solution paths for basis pursuit, as well as producing reasonable regularization parameter choices. Furthermore, exploring the resulting solution paths in various operating conditions reveals insights about the nature of basis pursuit solutions.",
                    "title": "Homotopy continuation for sparse signal representation",
                    "venue": "international conference on acoustics, speech, and signal processing",
                    "year": 2005,
                    "__v": 2,
                    "citationCount": 90,
                    "result": 6.347886331075185
                }
            }
        ],
        "_id": "69b9ef96-11d5-49b0-9ae3-492763e02ca8",
        "abstract": "This paper demonstrates theoretically and empirically that a greedy algorithm called orthogonal matching pursuit (OMP) can reliably recover a signal with m nonzero entries in dimension d given O(m ln d) random linear measurements of that signal. This is a massive improvement over previous results, which require  O (m 2 ) measurements. The new results for OMP are comparable with recent results for another approach called basis pursuit (BP). In some settings, the OMP algorithm is faster and easier to implement, so it is an attractive alternative to BP for signal recovery problems.",
        "title": "Signal Recovery From Random Measurements Via Orthogonal Matching Pursuit",
        "venue": "IEEE Transactions on Information Theory",
        "year": 2007,
        "__v": 2,
        "citationCount": 2067
    },
    {
        "authors": [
            "John Wright",
            "Allen Y. Yang",
            "Arvind Ganesh",
            "Shankar Sastry",
            "Yi Ma"
        ],
        "references": [
            "00909251-9935-44f3-94a1-629023b5015b",
            "0ddbfee1-8cc2-49f6-be79-59276f496884",
            "0fa84c94-ae45-44d3-bd37-aa3d48158977",
            "225591b8-1c1a-4854-81d4-5b5f364c20a9",
            "25e9d8cf-7f9d-4b60-834f-b162c6fb922b",
            "27505f5b-d81f-4b85-b85e-bd357aaa8468",
            "2d11c1d7-cd1a-41d8-8468-67ae0bdd3198",
            "32d158dc-6f9f-426a-973b-8edc5e4c5dad",
            "494b497b-836b-445a-8bcb-095600835d89",
            "56f4b72a-ec39-47ac-8220-899296e7fb18",
            "5da29eee-8cfd-4916-8b9e-01f58f218f9e",
            "5e8b0e8a-d687-4333-bfe9-73b4c1bebde5",
            "649fc07a-8aa2-48d1-97ac-520b6526a3bd",
            "65106f7a-8bce-4521-ac08-a545f9fd59fa",
            "71a18de9-e543-4337-ab7a-3db31d9f8c00",
            "7dd65996-11c9-427d-83f6-917895da8a28",
            "876d9f73-86e8-4af2-87cc-adaf94b2912f",
            "89bbd7d2-749b-4ec1-8f30-fc1d7c3a39e8",
            "a0fd543e-bbb5-4e10-ba43-8dc54ad9f4fc",
            "a1f6fc9b-b718-4c9f-93ee-ca53dcd46468",
            "a2c00050-3078-4ed8-a52d-070859e42c5e",
            "a866200f-b4ed-4f38-86d5-bd55ba2d0591",
            "ac8bcd1e-4510-498c-b51b-d85e5d827614",
            "adcd100c-2ef5-409e-8d80-06cfc83fad9e",
            "b0afa6ff-6528-4701-800b-5dc0b5411b0c",
            "b8b938f5-cc7f-40ae-b34b-6b592a487a10",
            "cc2d6b33-8c70-4f7f-be72-897ccde5c95e",
            "d99d5225-5b3d-406d-9da1-96223bd50daa",
            "db3572c6-2a7e-47d7-9aec-1f57291c55d5",
            "de4fea1d-2739-4e0f-b5a3-08f0df58d787",
            "e3a5cec9-7e82-4c14-86ab-0d95a92712a7",
            "e6a1607a-88cf-4964-afb5-41f97f7fe2e2",
            "f43261e9-b984-4746-97b2-613e071f6357"
        ],
        "keyword": [
            "feature",
            "sparse",
            "representation",
            "recognition",
            "occlusion",
            "problem",
            "theory",
            "algorithm"
        ],
        "group": [
            {
                "5da29eee-8cfd-4916-8b9e-01f58f218f9e": {
                    "authors": [
                        "Aapo Hyvärinen",
                        "Erkki Oja"
                    ],
                    "references": [
                        "0400f185-d501-4eac-86cc-fff1ff9b5ba0",
                        "0ddbfee1-8cc2-49f6-be79-59276f496884",
                        "1a559436-838a-4358-a97f-d260dba7783e",
                        "4f36c937-7def-406b-8ac6-4529f6f43b7d",
                        "6549b337-541c-400a-8f44-3ea444db7ed6",
                        "6c8cffb5-1552-434d-8941-d5fa38cfdfec",
                        "7ccbdf09-a84e-4ad2-ab20-cb28b6c41155",
                        "7d150afa-0bd6-495e-8755-47bea06395bc",
                        "7f3844c2-2dd6-4047-941f-6146e1d5b72c",
                        "984e6f85-be9b-4965-b8c0-ae5887007504",
                        "99a16eb9-6c41-4a72-a300-73f48c7eb158",
                        "9fa21f34-e706-4f0b-a750-3d676d93c461",
                        "a0b2cd2a-786d-450d-89a4-c32df53b63d8",
                        "a8db8191-75fe-4f32-9104-6a82575a92f1",
                        "ada27ede-4400-4e7d-aee5-1b5e62fe1800",
                        "cf7de934-cbeb-4ae0-8009-942e24c8d6b2",
                        "e6da6a29-1fbc-417f-b1a4-b8d78799d41d",
                        "f9de8a43-0312-48c7-9d91-4564c5558ffd"
                    ],
                    "keyword": [
                        "representation",
                        "linear",
                        "data",
                        "component",
                        "independent",
                        "analysis",
                        "transformation",
                        "original",
                        "methods",
                        "include"
                    ],
                    "group": [],
                    "_id": "5da29eee-8cfd-4916-8b9e-01f58f218f9e",
                    "abstract": "A fundamental problem in neural network research, as well as in many other disciplines, is finding a suitable representation of multivariate data, i.e. random vectors. For reasons of computational and conceptual simplicity, the representation is often sought as a linear transformation of the original data. In other words, each component of the representation is a linear combination of the original variables. Well-known linear transformation methods include principal component analysis, factor analysis, and projection pursuit. Independent component analysis (ICA) is a recently developed method in which the goal is to find a linear representation of non-Gaussian data so that the components are statistically independent, or as independent as possible. Such a representation seems to capture the essential structure of the data in many applications, including feature extraction and signal separation. In this paper, we present the basic theory and applications of ICA, and our recent work on the subject.",
                    "title": "Independent component analysis: algorithms and applications",
                    "venue": "Neural Networks",
                    "year": 2000,
                    "__v": 2,
                    "citationCount": 1367,
                    "result": 6.530453013805417
                },
                "5e8b0e8a-d687-4333-bfe9-73b4c1bebde5": {
                    "authors": [
                        "Athinodoros S. Georghiades",
                        "Peter N. Belhumeur",
                        "David J. Kriegman"
                    ],
                    "references": [
                        "04c0fda2-3699-4f61-98d2-3d621931c1f9",
                        "0702de7d-688c-460b-bb27-197eaa123a07",
                        "0838d523-ab76-4dcb-8516-b1432251add2",
                        "0d2d1d04-272d-4968-b52e-5f9f44709f9e",
                        "0fa84c94-ae45-44d3-bd37-aa3d48158977",
                        "123dbd0e-74f1-428b-9f16-00d04583f937",
                        "17ee8c1c-3d4e-4402-8a19-d06ece63b281",
                        "1a364b81-4662-4c79-ae11-67429e67ca25",
                        "33d74862-6527-4c30-be0c-95226a3f8a3a",
                        "342dd278-5caa-499c-89ed-9c644150ff6e",
                        "3b3d7569-08b1-4017-9910-2a017a00e43e",
                        "40f728c0-55b3-423b-aff5-a9b3ff27b7d5",
                        "424b58a8-4f48-4fed-b532-4fba374e3c0c",
                        "4a30b000-b1c6-4281-892b-3b60e83d0c05",
                        "4c857862-1cb7-4ad4-907f-f9f694fe6245",
                        "54a5822c-e405-44ad-84e3-cea51e7349c2",
                        "56f4b72a-ec39-47ac-8220-899296e7fb18",
                        "5b146739-a8f7-4b19-acb7-0370d72ff561",
                        "5de25331-b39f-4667-a074-b30c99f9a720",
                        "5ebbd1f5-dfe5-4eec-9883-b8b5efea366c",
                        "5f9f2346-d1e3-4716-a8af-8c14f1490e00",
                        "6e8cc926-79a1-4676-a2bd-f9d49f3144cf",
                        "700061b6-54a5-4f50-a1ef-1d8de3015c43",
                        "7099aef8-6ac6-4351-9615-1a6c6ae53487",
                        "7cdb6afa-db51-43a2-a1a6-5939051412a2",
                        "8428f986-6dce-46fc-b5f5-5e22df139f80",
                        "8c987526-6d8e-46ff-9e5a-403e804623ff",
                        "8df7292c-b52e-4888-80ab-776f5fba5810",
                        "905461e4-643b-4da0-a669-f52318b9e126",
                        "94a0b002-578e-4581-ad1d-8fc52a7052ea",
                        "9aeac8e2-4fce-4b5c-a566-3318041472b6",
                        "aa4f1c11-6860-46ed-9188-ce3c10bcb4f3",
                        "b1295c0c-9c1c-41d7-8cd2-74ed1557481c",
                        "b71b91cc-0ede-49c8-b528-cca5345bbb45",
                        "b85ac095-a9f2-4954-b2bf-f53fde98958c",
                        "bdd75c60-ad86-483b-9d5f-99039ef800a2",
                        "bf03f268-de9d-4a80-aee1-200990056503",
                        "c42f42f8-d1b5-4965-b7c2-33a0e2d9c8a9",
                        "c94373fe-6625-4763-99e6-003e611c2aee",
                        "cacef546-cc48-4fb9-814f-9c12141662d8",
                        "d3962f4e-82aa-47cf-92fa-47d90881f5cc",
                        "d42f853d-12d7-416d-8b27-c314ef563eed",
                        "d5e5a24d-f80e-4f1a-b48b-22403b653276",
                        "d6e37fb1-5f7e-448e-847b-7d1f1271c574",
                        "d9fd463e-26cb-40be-9885-e5c3bc6922d4",
                        "de9218ee-1982-455b-96c4-f28718f76a2f",
                        "eb63b82d-5108-4abf-8ee7-2d11bc1998a0",
                        "ef50568a-329a-42d8-bb6b-3e10f34ca75a",
                        "fdf8a6b9-89bc-42cd-9407-27021d31333d"
                    ],
                    "keyword": [
                        "images",
                        "pose",
                        "illumination",
                        "faces",
                        "method",
                        "lighting",
                        "generative",
                        "cone",
                        "test",
                        "space"
                    ],
                    "group": [],
                    "_id": "5e8b0e8a-d687-4333-bfe9-73b4c1bebde5",
                    "abstract": "We present a generative appearance-based method for recognizing human faces under variation in lighting and viewpoint. Our method exploits the fact that the set of images of an object in fixed pose, but under all possible illumination conditions, is a convex cone in the space of images. Using a small number of training images of each face taken with different lighting directions, the shape and albedo of the face can be reconstructed. In turn, this reconstruction serves as a generative model that can be used to render (or synthesize) images of the face under novel poses and illumination conditions. The pose space is then sampled and, for each pose, the corresponding illumination cone is approximated by a low-dimensional linear subspace whose basis vectors are estimated using the generative model. Our recognition algorithm assigns to a test image the identity of the closest approximated illumination cone. Test results show that the method performs almost without error, except on the most extreme lighting directions.",
                    "title": "From few to many: illumination cone models for face recognition under variable lighting and pose",
                    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "year": 2001,
                    "__v": 2,
                    "citationCount": 1860,
                    "result": 4.529074838130565
                },
                "649fc07a-8aa2-48d1-97ac-520b6526a3bd": {
                    "authors": [
                        "Jeffrey Ho",
                        "Ming-Hsuan Yang",
                        "Jongwoo Lim",
                        "Kuang-Chih Lee",
                        "David J. Kriegman"
                    ],
                    "references": [
                        "00133edb-9a26-4010-9d79-3aa2b5610518",
                        "01329570-deab-438a-8fde-9240e3e5bb4b",
                        "0cfa872d-f140-4f47-bf09-2bc7bc923480",
                        "0efb7bac-1ce1-4b9a-bcfd-004619e6c640",
                        "17ee8c1c-3d4e-4402-8a19-d06ece63b281",
                        "342dd278-5caa-499c-89ed-9c644150ff6e",
                        "37032748-43bb-410a-8349-d2808bb6f7fa",
                        "38135245-8eff-4078-af6a-ea559ffa660b",
                        "5e8b0e8a-d687-4333-bfe9-73b4c1bebde5",
                        "5ebbd1f5-dfe5-4eec-9883-b8b5efea366c",
                        "6610452d-4154-4f59-af0d-8ded28c9f52c",
                        "894c5634-efa9-4c2b-8360-d559fa002748",
                        "a149919e-1c00-4ef2-8535-60634a5532a4",
                        "c8cc88b8-d971-49e9-8810-e784c856872f",
                        "ce9c0c07-83af-4fb7-9491-38255660025c",
                        "d78003db-ad8a-48d2-be57-1c50e95cef72",
                        "e48ae9b9-f7d1-4bf9-8de1-495f4d71807f",
                        "ea8cd3d8-17ae-4a1e-8f83-1609469087af",
                        "ece4f56c-b724-40cf-b23c-d4ec101cf4de",
                        "fdf8a6b9-89bc-42cd-9407-27021d31333d"
                    ],
                    "keyword": [
                        "images",
                        "methods",
                        "introduce",
                        "illumination",
                        "gradient",
                        "cones",
                        "clustering",
                        "algorithm",
                        "varying",
                        "set"
                    ],
                    "group": [],
                    "_id": "649fc07a-8aa2-48d1-97ac-520b6526a3bd",
                    "abstract": "We introduce two appearance-based methods for clustering a set of images of 3D (three-dimensional) objects, acquired under varying illumination conditions, into disjoint subsets corresponding to individual objects. The first algorithm is based on the concept of illumination cones. According to the theory, the clustering problem is equivalent to finding convex polyhedral cones in the high-dimensional image space. To efficiently determine the conic structures hidden in the image data, we introduce the concept of conic affinity, which measures the likelihood of a pair of images belonging to the same underlying polyhedral cone. For the second method, we introduce another affinity measure based on image gradient comparisons. The algorithm operates directly on the image gradients by comparing the magnitudes and orientations of the image gradient at each pixel. Both methods have clear geometric motivations, and they operate directly on the images without the need for feature extraction or computation of pixel statistics. We demonstrate experimentally that both algorithms are surprisingly effective in clustering images acquired under varying illumination conditions with two large, well-known image data sets.",
                    "title": "Clustering appearances of objects under varying illumination conditions",
                    "venue": "computer vision and pattern recognition",
                    "year": 2003,
                    "__v": 2,
                    "citationCount": 224,
                    "result": 5.589146835276866
                },
                "65106f7a-8bce-4521-ac08-a545f9fd59fa": {
                    "authors": [
                        "Kuang-Chih Lee",
                        "Jeffrey Ho",
                        "David J. Kriegman"
                    ],
                    "references": [
                        "0cfa872d-f140-4f47-bf09-2bc7bc923480",
                        "17ee8c1c-3d4e-4402-8a19-d06ece63b281",
                        "21921f30-d090-43f4-9e1e-f538967c6385",
                        "342dd278-5caa-499c-89ed-9c644150ff6e",
                        "348e218b-7058-451c-b808-5c25010add03",
                        "4efb085b-65e4-4fec-906d-5cd8b6009fdc",
                        "5e8b0e8a-d687-4333-bfe9-73b4c1bebde5",
                        "831a0211-1a23-4f1e-86bb-bd9496ad765d",
                        "894c5634-efa9-4c2b-8360-d559fa002748",
                        "a149919e-1c00-4ef2-8535-60634a5532a4",
                        "b1295c0c-9c1c-41d7-8cd2-74ed1557481c",
                        "c8cc88b8-d971-49e9-8810-e784c856872f",
                        "e585b0ee-e9e8-4799-8f47-8657ad67f73c",
                        "e6c69797-bf47-4a3a-af4a-8b016c6d5fad",
                        "fdf8a6b9-89bc-42cd-9407-27021d31333d"
                    ],
                    "keyword": [
                        "image",
                        "lighting",
                        "subspace",
                        "sources",
                        "objects",
                        "acquired",
                        "spaces",
                        "modeled",
                        "basis",
                        "3d"
                    ],
                    "group": [],
                    "_id": "65106f7a-8bce-4521-ac08-a545f9fd59fa",
                    "abstract": "Previous work has demonstrated that the image variation of many objects (human faces in particular) under variable lighting can be effectively modeled by low-dimensional linear spaces, even when there are multiple light sources and shadowing. Basis images spanning this space are usually obtained in one of three ways: a large set of images of the object under different lighting conditions is acquired, and principal component analysis (PCA) is used to estimate a subspace. Alternatively, synthetic images are rendered from a 3D model (perhaps reconstructed from images) under point sources and, again, PCA is used to estimate a subspace. Finally, images rendered from a 3D model under diffuse lighting based on spherical harmonics are directly used as basis images. In this paper, we show how to arrange physical lighting so that the acquired images of each object can be directly used as the basis vectors of a low-dimensional linear space and that this subspace is close to those acquired by the other methods. More specifically, there exist configurations of k point light source directions, with k typically ranging from 5 to 9, such that, by taking k images of an object under these single sources, the resulting subspace is an effective representation for recognition under a wide range of lighting conditions. Since the subspace is generated directly from real images, potentially complex and/or brittle intermediate steps such as 3D reconstruction can be completely avoided; nor is it necessary to acquire large numbers of training images or to physically construct complex diffuse (harmonic) light fields. We validate the use of subspaces constructed in this fashion within the context of face recognition.",
                    "title": "Acquiring linear subspaces for face recognition under variable lighting",
                    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "year": 2005,
                    "__v": 2,
                    "citationCount": 892,
                    "result": 2.633544843529364
                },
                "7dd65996-11c9-427d-83f6-917895da8a28": {
                    "authors": [
                        "P.J. Phillips",
                        "W.T. Scruggs",
                        "Alice J. O'Toole",
                        "Patrick J. Flynn",
                        "Kevin W. Bowyer",
                        "C.L. Schott",
                        "M. Sharpe"
                    ],
                    "references": [
                        "11a0fdf5-50f4-48b2-898c-2711e41e4720",
                        "32d158dc-6f9f-426a-973b-8edc5e4c5dad",
                        "40f728c0-55b3-423b-aff5-a9b3ff27b7d5",
                        "54a5822c-e405-44ad-84e3-cea51e7349c2",
                        "708eed41-b806-4354-9715-b6fdcb7e1b6a",
                        "784216e5-56e4-44ac-a1aa-90080d267c3b",
                        "803af597-6e09-41c7-be51-e9eb7007ec20",
                        "8c66b643-8085-4fd3-acaa-41b228484394",
                        "971a895a-1c02-4631-8b0d-2b2f12b8083a",
                        "973f4aac-2b66-4b54-b815-2407979b59ab",
                        "bdb36af0-8cca-41c0-a193-d6139197beb5",
                        "db4e7aa7-0645-44f6-8e08-d3e1f1b26b15",
                        "f300828d-6eb7-4162-8f0c-fc5f3eb8047c"
                    ],
                    "keyword": [
                        "images",
                        "face",
                        "2006",
                        "performance",
                        "ice",
                        "frvt",
                        "recognition",
                        "frontal",
                        "3d",
                        "highresolution"
                    ],
                    "group": [],
                    "_id": "7dd65996-11c9-427d-83f6-917895da8a28",
                    "abstract": "This paper describes the large-scale experimental results from the Face Recognition Vendor Test (FRVT) 2006 and the Iris Challenge Evaluation (ICE) 2006. The FRVT 2006 looked at recognition from high-resolution still frontal face images and 3D face images, and measured performance for still frontal face images taken under controlled and uncontrolled illumination. The ICE 2006 evaluation reported verification performance for both left and right irises. The images in the ICE 2006 intentionally represent a broader range of quality than the ICE 2006 sensor would normally acquire. This includes images that did not pass the quality control software embedded in the sensor. The FRVT 2006 results from controlled still and 3D images document at least an order-of-magnitude improvement in recognition performance over the FRVT 2002. The FRVT 2006 and the ICE 2006 compared recognition performance from high-resolution still frontal face images, 3D face images, and the single-iris images. On the FRVT 2006 and the ICE 2006 data sets, recognition performance was comparable for high-resolution frontal face, 3D face, and the iris images. In an experiment comparing human and algorithms on matching face identity across changes in illumination on frontal face images, the best performing algorithms were more accurate than humans on unfamiliar faces.",
                    "title": "FRVT 2006 and ICE 2006 Large-Scale Experimental Results",
                    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "year": 2010,
                    "__v": 2,
                    "citationCount": 151,
                    "result": 4.481334620121805
                },
                "876d9f73-86e8-4af2-87cc-adaf94b2912f": {
                    "authors": [
                        "S.Z. Li",
                        "Xin Wen Hou",
                        "Hong Jiang Zhang",
                        "Qian Sheng Cheng"
                    ],
                    "references": [
                        "0ddbfee1-8cc2-49f6-be79-59276f496884",
                        "5ebbd1f5-dfe5-4eec-9883-b8b5efea366c",
                        "839e59b8-b356-4329-ba79-97f981cf6768",
                        "85114f9d-70a8-4940-83aa-af504b75acf8"
                    ],
                    "keyword": [
                        "local",
                        "representation",
                        "lnmf",
                        "presented",
                        "nonnegative",
                        "nmf",
                        "method",
                        "learning",
                        "constraint"
                    ],
                    "group": [],
                    "_id": "876d9f73-86e8-4af2-87cc-adaf94b2912f",
                    "abstract": "In this paper, we propose a novel method, called local non-negative matrix factorization (LNMF), for learning spatially localized, parts-based subspace representation of visual patterns. An objective function is defined to impose a localization constraint, in addition to the non-negativity constraint in the standard NMF. This gives a set of bases which not only allows a non-subtractive (part-based) representation of images but also manifests localized features. An algorithm is presented for the learning of such basic components. Experimental results are presented to compare LNMF with the NMF and PCA methods for face representation and recognition, which demonstrates advantages of LNMF.",
                    "title": "Learning spatially localized, parts-based representation",
                    "venue": "computer vision and pattern recognition",
                    "year": 2001,
                    "__v": 2,
                    "citationCount": 364,
                    "result": 5.876491040480138
                },
                "89bbd7d2-749b-4ec1-8f30-fc1d7c3a39e8": {
                    "authors": [
                        "Sanja Fidler",
                        "Danijel Skocaj",
                        "Ales Leonardis"
                    ],
                    "references": [
                        "04b889e8-73c8-42cb-a806-99198080ff63",
                        "0ddbfee1-8cc2-49f6-be79-59276f496884",
                        "1a9ab3c5-2870-42ab-bc6b-82b3aa1451b4",
                        "31694e30-f279-4014-8a46-cf76272cd058",
                        "36d35d5a-7c1d-4468-8e5c-b08b2458bd76",
                        "420acfbb-a503-4d34-915d-354a3048b83e",
                        "4c2e0a92-13bf-4815-8c27-ac11c42ec16c",
                        "56f4b72a-ec39-47ac-8220-899296e7fb18",
                        "5eb1916a-bbf2-4413-b5ba-589c62877ac0",
                        "64319b0a-71ae-43d9-b01e-0966dfaa63b0",
                        "810f7115-00c6-42b2-bf8c-142b2a35ed57",
                        "839e59b8-b356-4329-ba79-97f981cf6768",
                        "e1f0c7a5-f9a0-4bc8-b103-01e2326d58d7",
                        "e4cbec05-c21a-4df3-a482-2336a311351c",
                        "eb4aa79c-c7d0-44b2-9494-1cb3c51ddc55",
                        "f8849dde-b6fa-4848-8de7-7eef1a13a8e4"
                    ],
                    "keyword": [
                        "methods",
                        "discriminative",
                        "tasks",
                        "reconstruction",
                        "pixels",
                        "outliers",
                        "data",
                        "approach",
                        "theoretical",
                        "subspace"
                    ],
                    "group": [],
                    "_id": "89bbd7d2-749b-4ec1-8f30-fc1d7c3a39e8",
                    "abstract": "Linear subspace methods that provide sufficient reconstruction of the data, such as PCA, offer an efficient way of dealing with missing pixels, outliers, and occlusions that often appear in the visual data. Discriminative methods, such as LDA, which, on the other hand, are better suited for classification tasks, are highly sensitive to corrupted data. We present a theoretical framework for achieving the best of both types of methods: an approach that combines the discrimination power of discriminative methods with the reconstruction property of reconstructive methods which enables one to work on subsets of pixels in images to efficiently detect and reject the outliers. The proposed approach is therefore capable of robust classification with a high-breakdown point. We also show that subspace methods, such as CCA, which are used for solving regression tasks, can be treated in a similar manner. The theoretical results are demonstrated on several computer vision tasks showing that the proposed approach significantly outperforms the standard discriminative methods in the case of missing pixels and images containing occlusions and outliers.",
                    "title": "Combining reconstructive and discriminative subspace methods for robust classification and regression by subsampling",
                    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "year": 2006,
                    "__v": 2,
                    "citationCount": 82,
                    "result": 5.360351944835052
                },
                "a0fd543e-bbb5-4e10-ba43-8dc54ad9f4fc": {
                    "authors": [
                        "Davi Geiger",
                        "Tyng Luh Liu",
                        "Michael J. Donahue"
                    ],
                    "references": [
                        "092ee78a-f488-464b-bfb5-55d884be38ed",
                        "60a23a5f-cac1-4e83-9df5-7922e8e59257",
                        "657dc877-eda1-4b98-8ec4-3e575c615ed3",
                        "85114f9d-70a8-4940-83aa-af504b75acf8",
                        "9dee56d9-8fd5-414c-83ae-31551b20ae88",
                        "ab28357b-19c1-42d4-9479-6da360aad22c",
                        "b0afa6ff-6528-4701-800b-5dc0b5411b0c",
                        "b2f30765-3243-48f6-82c2-0e337c86e993",
                        "b8a86432-fff7-474e-9d72-046c5189e6dc",
                        "bb3c38fa-c2b0-4d4f-8c9d-ca1884343474",
                        "bc44be22-a9f0-4b80-a555-b72a97104a9c",
                        "cadbc693-2f8d-4468-b1e4-622081afa465",
                        "cb17c20e-e335-43dc-b2ae-350e43b74faa",
                        "d9752a5a-1603-45cc-9a21-7997750d429f"
                    ],
                    "keyword": [
                        "templates",
                        "cal",
                        "representation",
                        "local",
                        "image",
                        "weighted",
                        "study",
                        "select",
                        "norm",
                        "minima"
                    ],
                    "group": [],
                    "_id": "a0fd543e-bbb5-4e10-ba43-8dc54ad9f4fc",
                    "abstract": "We are given an image I and a library of templates {\\cal L} , such that {\\cal L} is an overcomplete basis for I. The templates can represent objects, faces, features, analytical functions, or be single pixel templates (canonical templates). There are infinitely many ways to decompose I as a linear combination of the library templates. Each decomposition defines a representation for the image I, given {\\cal L} .#R##N##R##N#What is an optimal representation for I given {\\cal L} and how to select it? We are motivated to select a sparse/compact representation for I, and to account for occlusions and noise in the image. We present a concave cost function criterion on the linear decomposition coefficients that satisfies our requirements. More specifically, we study a “weighted L norm” with 0 < p < 1. We prove a result that allows us to generate all local minima for the L norm, and the global minimum is obtained by searching through the local ones. Due to the computational complexity, i.e., the large number of local minima, we also study a greedy and iterative “weighted L Matching Pursuit” strategy.",
                    "title": "Sparse Representations for Image Decompositions",
                    "venue": "International Journal of Computer Vision",
                    "year": 1999,
                    "__v": 2,
                    "citationCount": 10,
                    "result": 4.669171116196287
                },
                "a1f6fc9b-b718-4c9f-93ee-ca53dcd46468": {
                    "authors": [
                        "Chengjun Liu"
                    ],
                    "references": [
                        "00909251-9935-44f3-94a1-629023b5015b",
                        "018498c0-b975-4f7e-9b04-cd61a0f018c1",
                        "03fc3b81-7792-4343-b7d7-cd9ed329d021",
                        "04159164-700d-4aa5-91f5-f8a17bebfc1a",
                        "068538e8-3804-4e84-a102-89d9514cd93d",
                        "32d122fa-ca24-404f-bc21-ad0109e67afb",
                        "32d158dc-6f9f-426a-973b-8edc5e4c5dad",
                        "3a4a8846-ccb1-4751-beb8-b571a1cbfac9",
                        "40f728c0-55b3-423b-aff5-a9b3ff27b7d5",
                        "54a5822c-e405-44ad-84e3-cea51e7349c2",
                        "56f4b72a-ec39-47ac-8220-899296e7fb18",
                        "5e8b0e8a-d687-4333-bfe9-73b4c1bebde5",
                        "5eb1916a-bbf2-4413-b5ba-589c62877ac0",
                        "6f79bf94-39e6-47df-b0c7-ffca294e5053",
                        "74b6f195-dae1-4c60-b61d-856f77bb1843",
                        "7c931981-f219-486b-b6f8-719ccef22e5f",
                        "7d738632-dc5d-4ec9-a4cd-1d1a74d33166",
                        "7fb8700d-8569-406a-9e53-ed991bda3764",
                        "85114f9d-70a8-4940-83aa-af504b75acf8",
                        "8835551e-08fe-468f-8523-3bc1752f41f3",
                        "8c66b643-8085-4fd3-acaa-41b228484394",
                        "977d5066-11f7-473e-befe-b140db86c3ce",
                        "9792abba-296e-4de0-ae6e-c55651a7fdaf",
                        "9c08dfaf-cb9d-4bf3-ac35-647b95cb806e",
                        "a083a1b9-8dfb-45d6-99a9-fa30c4a6e9f5",
                        "aaf9e7d6-6b1c-432e-84c5-81a4322b5097",
                        "c5e0a533-2805-4b6a-842c-a8d979e7a7be",
                        "e48694de-c53b-4588-9638-5affe99cb5b6",
                        "ea12798a-feaf-4f04-b494-7834146f613a",
                        "fec9c952-e99e-40b8-b75f-dcd8f1f2b622"
                    ],
                    "keyword": [
                        "method",
                        "recognition",
                        "performance",
                        "kfa",
                        "space",
                        "pattern",
                        "improving",
                        "framework",
                        "power",
                        "gda"
                    ],
                    "group": [],
                    "_id": "a1f6fc9b-b718-4c9f-93ee-ca53dcd46468",
                    "abstract": "This paper presents a novel pattern recognition framework by capitalizing on dimensionality increasing techniques. In particular, the framework integrates Gabor image representation, a novel multiclass kernel Fisher analysis (KFA) method, and fractional power polynomial models for improving pattern recognition performance. Gabor image representation, which increases dimensionality by incorporating Gabor filters with different scales and orientations, is characterized by spatial frequency, spatial locality, and orientational selectivity for coping with image variabilities such as illumination variations. The KFA method first performs nonlinear mapping from the input space to a high-dimensional feature space, and then implements the multiclass Fisher discriminant analysis in the feature space. The significance of the nonlinear mapping is that it increases the discriminating power of the KFA method, which is linear in the feature space but nonlinear in the input space. The novelty of the KFA method comes from the fact that 1) it extends the two-class kernel Fisher methods by addressing multiclass pattern classification problems and 2) it improves upon the traditional generalized discriminant analysis (GDA) method by deriving a unique solution (compared to the GDA solution, which is not unique). The fractional power polynomial models further improve performance of the proposed pattern recognition framework. Experiments on face recognition using both the FERET database and the FRGC (face recognition grand challenge) databases show the feasibility of the proposed framework. In particular, experimental results using the FERET database show that the KFA method performs better than the GDA method and the fractional power polynomial models help both the KFA method and the GDA method improve their face recognition performance. Experimental results using the FRGC databases show that the proposed pattern recognition framework improves face recognition performance upon the BEE baseline algorithm and the LDA-based baseline algorithm by large margins.",
                    "title": "Capitalize on dimensionality increasing techniques for improving face recognition grand challenge performance",
                    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "year": 2006,
                    "__v": 2,
                    "citationCount": 151,
                    "result": 5.17456221632423
                },
                "a2c00050-3078-4ed8-a52d-070859e42c5e": {
                    "authors": [
                        "Ron Zass",
                        "Amnon Shashua"
                    ],
                    "references": [
                        "05b7b300-610a-4c07-89db-afdb355fef65",
                        "2f01bffb-be3e-4264-baa1-e49121ab65d7",
                        "44d58f7c-09df-4fb5-a8a8-8331547892a7",
                        "4d2eade0-7917-485d-842d-ed0c336e4e4d",
                        "876d9f73-86e8-4af2-87cc-adaf94b2912f",
                        "e644f2cb-aa7b-45f7-aa12-bf1b0f8d1eca"
                    ],
                    "keyword": [
                        "sparse",
                        "original",
                        "nonnegative",
                        "coordinates",
                        "representation",
                        "projected",
                        "problem",
                        "points",
                        "pca",
                        "describe"
                    ],
                    "group": [],
                    "_id": "a2c00050-3078-4ed8-a52d-070859e42c5e",
                    "abstract": "We describe a nonnegative variant of the \"Sparse PCA\" problem. The goal is to create a low dimensional representation from a collection of points which on the one hand maximizes the variance of the projected points and on the other uses only parts of the original coordinates, and thereby creating a sparse representation. What distinguishes our problem from other Sparse PCA formulations is that the projection involves only nonnegative weights of the original coordinates — a desired quality in various fields, including economics, bioinformatics and computer vision. Adding nonnegativity contributes to sparseness, where it enforces a partitioning of the original coordinates among the new axes. We describe a simple yet efficient iterative coordinate-descent type of scheme which converges to a local optimum of our optimization criteria, giving good results on large real world datasets.",
                    "title": "Nonnegative Sparse PCA",
                    "venue": "neural information processing systems",
                    "year": 2007,
                    "__v": 2,
                    "citationCount": 59,
                    "result": 7.228120201689997
                },
                "a866200f-b4ed-4f38-86d5-bd55ba2d0591": {
                    "authors": [
                        "Ke Huang",
                        "Selin Aviyente"
                    ],
                    "references": [
                        "157a2881-c6cb-4d05-8f15-d9225e5751f5",
                        "15e40102-1512-4446-9850-c8102506cbd4",
                        "20ebfc17-0fd5-462a-8e7d-363bb12caf77",
                        "327febd7-dabd-4a4b-b8ec-ef8de879e4de",
                        "4b00142e-0e50-4245-9094-8d0108a68582",
                        "56f4b72a-ec39-47ac-8220-899296e7fb18",
                        "810f7115-00c6-42b2-bf8c-142b2a35ed57",
                        "89bbd7d2-749b-4ec1-8f30-fc1d7c3a39e8",
                        "8bb47288-c305-4131-9a23-3635d1bc15ad",
                        "af6d91d3-3a39-400c-8130-ca744d2b1fe3",
                        "bb3c38fa-c2b0-4d4f-8c9d-ca1884343474",
                        "c6417c11-878b-4492-8d25-6f5af6a53741",
                        "d6457de8-9f03-4671-91da-f557a0ec20e0",
                        "e672c4ab-76b2-4d6c-9dbe-69cb2b2ef937",
                        "fcb41378-32f7-4aab-8458-fc5a99d74f92"
                    ],
                    "keyword": [
                        "signals",
                        "sparse",
                        "representation",
                        "discriminative",
                        "classification",
                        "reconstruction",
                        "methods",
                        "corruption",
                        "approach"
                    ],
                    "group": [],
                    "_id": "a866200f-b4ed-4f38-86d5-bd55ba2d0591",
                    "abstract": "In this paper, application of sparse representation (factorization) of signals over an overcomplete basis (dictionary) for signal classification is discussed. Searching for the sparse representation of a signal over an overcomplete dictionary is achieved by optimizing an objective function that includes two terms: one that measures the signal reconstruction error and another that measures the sparsity. This objective function works well in applications where signals need to be reconstructed, like coding and denoising. On the other hand, discriminative methods, such as linear discriminative analysis (LDA), are better suited for classification tasks. However, discriminative methods are usually sensitive to corruption in signals due to lacking crucial properties for signal reconstruction. In this paper, we present a theoretical framework for signal classification with sparse representation. The approach combines the discrimination power of the discriminative methods with the reconstruction property and the sparsity of the sparse representation that enables one to deal with signal corruptions: noise, missing data and outliers. The proposed approach is therefore capable of robust classification with a sparse representation of signals. The theoretical results are demonstrated with signal classification tasks, showing that the proposed approach outperforms the standard discriminative methods and the standard sparse representation in the case of corrupted signals.",
                    "title": "Sparse Representation for Signal Classification",
                    "venue": "neural information processing systems",
                    "year": 2007,
                    "__v": 2,
                    "citationCount": 255,
                    "result": 8.636286848088572
                },
                "ac8bcd1e-4510-498c-b51b-d85e5d827614": {
                    "authors": [
                        "Bo Gun Park",
                        "Kyoung Mu Lee",
                        "Sang Uk Lee"
                    ],
                    "references": [
                        "015e2c36-b014-4eca-97fb-73aa7e8bee1a",
                        "0cc61139-15c4-49d9-a41d-7d7be4878121",
                        "27505f5b-d81f-4b85-b85e-bd357aaa8468",
                        "32d158dc-6f9f-426a-973b-8edc5e4c5dad",
                        "342dd278-5caa-499c-89ed-9c644150ff6e",
                        "56f4b72a-ec39-47ac-8220-899296e7fb18",
                        "5e8b0e8a-d687-4333-bfe9-73b4c1bebde5",
                        "61e615e7-f78f-4f1e-b604-343ecf4b2ec9",
                        "6300a64b-4e61-472d-8e92-4daaf85c2163",
                        "82777392-2c1a-4594-b6e0-6f541283ba86",
                        "876d9f73-86e8-4af2-87cc-adaf94b2912f",
                        "8c84a055-7b38-41db-85fc-1b1f00e40168",
                        "98bacf51-6a05-4e2c-9a20-7f42ac4cbc20",
                        "a341ae67-d809-4a44-a91e-a944748d44aa",
                        "c23df197-74d6-4d07-b1e5-2492bd49ae2a",
                        "d07392f2-ffeb-406f-88a7-06162620a18a"
                    ],
                    "keyword": [
                        "structural",
                        "propose",
                        "matching",
                        "facearg",
                        "face",
                        "arg",
                        "algorithm",
                        "varying",
                        "single",
                        "sample"
                    ],
                    "group": [],
                    "_id": "ac8bcd1e-4510-498c-b51b-d85e5d827614",
                    "abstract": "In this paper, we propose a novel line feature-based face recognition algorithm. A face is represented by the face-ARG model, where all the geometric quantities and the structural information are encoded in an attributed relational graph (ARG) structure, then the partial ARG matching is done for matching face-ARG's. Experimental results demonstrate that the proposed algorithm is quite robust to various facial expression changes, varying illumination conditions and occlusion, even when a single sample per person is given.",
                    "title": "Face recognition using face-ARG matching",
                    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "year": 2005,
                    "__v": 2,
                    "citationCount": 41,
                    "result": 5.813110659550288
                },
                "adcd100c-2ef5-409e-8d80-06cfc83fad9e": {
                    "authors": [
                        "Dimitris Achlioptas"
                    ],
                    "references": [
                        "0abac7af-48d0-4858-85ee-02431aa7219f",
                        "0f094852-0668-4dfe-92cc-ae5659ffc1d9",
                        "2fd9e662-2a85-49ce-97af-9ae76df4ca5f",
                        "49636ac5-e7f1-4d06-8460-114d23de9a66",
                        "9a33ddde-c275-4997-b037-0b48648bb1f7",
                        "a06138e8-6351-4d1f-aead-6418990b2918",
                        "adf6fdf9-01a0-4051-9d99-965f4a5baa4d",
                        "bf132fef-c091-4f7e-a850-22b83ff7a9e2",
                        "c19c233b-6b1d-40a9-b553-a6efbe11932c",
                        "dd7b260e-5911-40a5-95fe-1beabd611348",
                        "e4e5c3a5-2473-4cea-8e0f-13bc369e4d6a",
                        "e7ad5317-8580-47c8-82f3-9dff19d3e5f8"
                    ],
                    "keyword": [
                        "embedded",
                        "dimensional",
                        "space",
                        "random",
                        "points",
                        "euclidean",
                        "constructions",
                        "suitable",
                        "small",
                        "simple"
                    ],
                    "group": [],
                    "_id": "adcd100c-2ef5-409e-8d80-06cfc83fad9e",
                    "abstract": "A classic result of Johnson and Lindenstrauss asserts that any set of  n  points in  d -dimensional Euclidean space can be embedded into  k -dimensional Euclidean space where  k  is logarithmic in  n  and independent of  d  so that all pairwise distances are maintained within an arbitrarily small factor. All known constructions of such embeddings involve projecting the  n  points onto a random  k -dimensional hyperplane. We give a novel construction of the embedding, suitable for database applications, which amounts to computing a simple aggregate over  k  random attribute partitions.",
                    "title": "Database-friendly random projections",
                    "venue": "symposium on principles of database systems",
                    "year": 2001,
                    "__v": 1,
                    "citationCount": 305,
                    "result": 3.8472129277372242
                },
                "b0afa6ff-6528-4701-800b-5dc0b5411b0c": {
                    "authors": [
                        "Jorma Rissanen"
                    ],
                    "references": [
                        "a0b958fe-cc21-4635-952f-0d74a0db91ff"
                    ],
                    "keyword": [
                        "parameters",
                        "observed",
                        "model",
                        "write",
                        "time",
                        "system",
                        "structure",
                        "series",
                        "sequence",
                        "realvalued"
                    ],
                    "group": [],
                    "_id": "b0afa6ff-6528-4701-800b-5dc0b5411b0c",
                    "abstract": "The number of digits it takes to write down an observed sequence x\"1, ..., x\"N of a time series depends on the model with its parameters that one assumes to have generated the observed data. Accordingly, by finding the model which minimizes the description length one obtains estimates of both the integer-valued structure parameters and the real-valued system parameters.",
                    "title": "Paper: Modeling by shortest data description",
                    "venue": "Automatica",
                    "year": 1978,
                    "__v": 1,
                    "citationCount": 1833,
                    "result": 4.061727771712292
                },
                "b8b938f5-cc7f-40ae-b34b-6b592a487a10": {
                    "authors": [
                        "Peng Zhao",
                        "Bin Yu"
                    ],
                    "references": [
                        "05c85ace-c998-47cd-a285-f6ecfd72004d",
                        "a1e762ba-4019-4722-b9e1-b7ed9a7644a9"
                    ],
                    "keyword": [
                        "models",
                        "selection",
                        "lasso",
                        "true",
                        "condition",
                        "predictor",
                        "irrepresentable",
                        "sufficient",
                        "setting",
                        "sciences"
                    ],
                    "group": [],
                    "_id": "b8b938f5-cc7f-40ae-b34b-6b592a487a10",
                    "abstract": "Sparsity or parsimony of statistical models is crucial for their proper interpretations, as in sciences and social sciences. Model selection is a commonly used method to find such models, but usually involves a computationally heavy combinatorial search. Lasso (Tibshirani, 1996) is now being used as a computationally feasible alternative to model selection. Therefore it is important to study Lasso for model selection purposes.#R##N##R##N#In this paper, we prove that a single condition, which we call the Irrepresentable Condition, is almost necessary and sufficient for Lasso to select the true model both in the classical fixed p setting and in the large p setting as the sample size n gets large. Based on these results, sufficient conditions that are verifiable in practice are given to relate to previous works and help applications of Lasso for feature selection and sparse representation.#R##N##R##N#This Irrepresentable Condition, which depends mainly on the covariance of the predictor variables, states that Lasso selects the true model consistently if and (almost) only if the predictors that are not in the true model are \"irrepresentable\" (in a sense to be clarified) by predictors that are in the true model. Furthermore, simulations are carried out to provide insights and understanding of this result.",
                    "title": "On Model Selection Consistency of Lasso",
                    "venue": "Journal of Machine Learning Research",
                    "year": 2006,
                    "__v": 2,
                    "citationCount": 396,
                    "result": 5.60894354183828
                },
                "cc2d6b33-8c70-4f7f-be72-897ccde5c95e": {
                    "authors": [
                        "Haitao Wang",
                        "Stan Z. Li",
                        "Yangsheng Wang"
                    ],
                    "references": [
                        "04c0fda2-3699-4f61-98d2-3d621931c1f9",
                        "21921f30-d090-43f4-9e1e-f538967c6385",
                        "2f4464a5-a7b6-4689-8685-b0e3302a25a9",
                        "57cc976f-ea69-4fec-927d-5d749b7c743b",
                        "5e8b0e8a-d687-4333-bfe9-73b4c1bebde5",
                        "831a0211-1a23-4f1e-86bb-bd9496ad765d",
                        "87f38871-bfdd-4285-a155-1e96ab64035f",
                        "a149919e-1c00-4ef2-8535-60634a5532a4",
                        "b1295c0c-9c1c-41d7-8cd2-74ed1557481c",
                        "b7fdfb26-0f3b-49c4-9d49-538c58d8620a",
                        "c23df197-74d6-4d07-b1e5-2492bd49ae2a",
                        "c8cc88b8-d971-49e9-8810-e784c856872f",
                        "ca43753e-cb52-4fa4-ac7e-bacc58e2d591",
                        "ce9c0c07-83af-4fb7-9491-38255660025c",
                        "ece4f56c-b724-40cf-b23c-d4ec101cf4de"
                    ],
                    "keyword": [
                        "images",
                        "qi",
                        "nonpoint",
                        "light",
                        "works",
                        "spherical",
                        "recognition",
                        "quotient",
                        "perform",
                        "modeling"
                    ],
                    "group": [],
                    "_id": "cc2d6b33-8c70-4f7f-be72-897ccde5c95e",
                    "abstract": "We present a unified framework for modeling intrinsic properties of face images for recognition. It is based on the quotient image (QI) concept, in particular on the existing works of QI, spherical harmonic, image ratio and retinex. Under this framework, we generalize these previous works into two new algorithms: (1) non-point light quotient image (NPL-QI) extends QI to deal with non-point light sources by modeling non-point light directions using spherical harmonic bases; (2) self-quotient image (S-QI) extends QI to perform illumination subtraction without the need for alignment and no shadow assumption. Experimental results show that our algorithms can significantly improve the performance of face recognition under varying illumination conditions.",
                    "title": "Generalized quotient image",
                    "venue": "computer vision and pattern recognition",
                    "year": 2004,
                    "__v": 2,
                    "citationCount": 75,
                    "result": 4.360184806668182
                },
                "db3572c6-2a7e-47d7-9aec-1f57291c55d5": {
                    "authors": [
                        "Thomas M. Cover"
                    ],
                    "references": [
                        "c8a92b83-0d39-498c-883c-481cc1b2691d",
                        "d9b4ddfd-5ba2-44b2-a972-579dd34b1962"
                    ],
                    "keyword": [
                        "separating",
                        "pattern",
                        "surfaces",
                        "set",
                        "capacities",
                        "vectors",
                        "general",
                        "shown",
                        "points",
                        "number"
                    ],
                    "group": [],
                    "_id": "db3572c6-2a7e-47d7-9aec-1f57291c55d5",
                    "abstract": "This paper develops the separating capacities of families of nonlinear decision surfaces by a direct application of a theorem in classical combinatorial geometry. It is shown that a family of surfaces having d degrees of freedom has a natural separating capacity of 2d pattern vectors, thus extending and unifying results of Winder and others on the pattern-separating capacity of hyperplanes. Applying these ideas to the vertices of a binary n-cube yields bounds on the number of spherically, quadratically, and, in general, nonlinearly separable Boolean functions of n variables. It is shown that the set of all surfaces which separate a dichotomy of an infinite, random, separable set of pattern vectors can be characterized, on the average, by a subset of only 2d extreme pattern vectors. In addition, the problem of generalizing the classifications on a labeled set of pattern points to the classification of a new point is defined, and it is found that the probability of ambiguous generalization is large unless the number of training patterns exceeds the capacity of the set of separating surfaces.",
                    "title": "Geometrical and Statistical Properties of Systems of Linear Inequalities with Applications in Pattern Recognition",
                    "venue": "IEEE Transactions on Electronic Computers",
                    "year": 1965,
                    "__v": 2,
                    "citationCount": 438,
                    "result": 3.801019680354045
                },
                "e3a5cec9-7e82-4c14-86ab-0d95a92712a7": {
                    "authors": [
                        "Timo Ahonen",
                        "Abdenour Hadid",
                        "Matti Pietikäinen"
                    ],
                    "references": [
                        "17373dba-934f-4ae0-bb50-8cc00dd7c19f",
                        "1a461d15-582e-4b71-b98c-1b85902ee011",
                        "29cd43e2-b893-40a5-883e-bbddf5b60a66",
                        "2e71fa79-72e8-41ac-9b84-ea04720d7255",
                        "32d158dc-6f9f-426a-973b-8edc5e4c5dad",
                        "3dadbfa5-c6e3-4f19-899b-2294bc6660da",
                        "3f28cca1-f895-4b34-9eb2-2afba6dad338",
                        "40ea9b15-e3ff-4e65-b8b7-dd8b8e564931",
                        "40f728c0-55b3-423b-aff5-a9b3ff27b7d5",
                        "47b09a19-0c16-452b-8459-4348cde02256",
                        "4bd3fdd6-d3df-4ee7-9bfa-92e2293d484d",
                        "54a5822c-e405-44ad-84e3-cea51e7349c2",
                        "72c27d5a-23c5-4d1b-a000-280b87b368ee",
                        "853b9534-32ab-4bf8-a328-1f4c18cf3a1b",
                        "8d8e7d51-3223-4776-bf6a-40306774b8a1",
                        "9270a9b5-940a-4394-814f-433c6440f286",
                        "971a895a-1c02-4631-8b0d-2b2f12b8083a",
                        "9b7139da-fbd5-42d0-ade2-8cfdb4fa4cf1",
                        "bd18a75e-3c40-4f53-b0e2-b4a9c6d49fae",
                        "e2204e92-e6dc-4884-9bbc-200029491fc7",
                        "ea8b1ce5-aad8-4502-8ef9-f4f314cd2b80"
                    ],
                    "keyword": [
                        "features",
                        "face",
                        "lbp",
                        "image",
                        "vector",
                        "texture",
                        "representation",
                        "regions",
                        "recognition",
                        "proposed"
                    ],
                    "group": [],
                    "_id": "e3a5cec9-7e82-4c14-86ab-0d95a92712a7",
                    "abstract": "This paper presents a novel and efficient facial image representation based on local binary pattern (LBP) texture features. The face image is divided into several regions from which the LBP feature distributions are extracted and concatenated into an enhanced feature vector to be used as a face descriptor. The performance of the proposed method is assessed in the face recognition problem under different challenges. Other applications and several extensions are also discussed",
                    "title": "Face Description with Local Binary Patterns: Application to Face Recognition",
                    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "year": 2006,
                    "__v": 2,
                    "citationCount": 1744,
                    "result": 8.450088612947004
                }
            }
        ],
        "_id": "7236dbb7-f0b2-4e28-bb7c-6de187c32d64",
        "abstract": "We consider the problem of automatically recognizing human faces from frontal views with varying expression and illumination, as well as occlusion and disguise. We cast the recognition problem as one of classifying among multiple linear regression models and argue that new theory from sparse signal representation offers the key to addressing this problem. Based on a sparse representation computed by C 1 -minimization, we propose a general classification algorithm for (image-based) object recognition. This new framework provides new insights into two crucial issues in face recognition: feature extraction and robustness to occlusion. For feature extraction, we show that if sparsity in the recognition problem is properly harnessed, the choice of features is no longer critical. What is critical, however, is whether the number of features is sufficiently large and whether the sparse representation is correctly computed. Unconventional features such as downsampled images and random projections perform just as well as conventional features such as eigenfaces and Laplacianfaces, as long as the dimension of the feature space surpasses certain threshold, predicted by the theory of sparse representation. This framework can handle errors due to occlusion and corruption uniformly by exploiting the fact that these errors are often sparse with respect to the standard (pixel) basis. The theory of sparse representation helps predict how much occlusion the recognition algorithm can handle and how to choose the training images to maximize robustness to occlusion. We conduct extensive experiments on publicly available databases to verify the efficacy of the proposed algorithm and corroborate the above claims.",
        "title": "Robust Face Recognition via Sparse Representation",
        "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
        "year": 2009,
        "__v": 3,
        "citationCount": 3393
    },
    {
        "authors": [
            "Paul Barham",
            "Boris Dragovic",
            "Keir Fraser",
            "Steven Hand",
            "Timothy L. Harris",
            "Alex Ho",
            "Rolf Neugebauer",
            "Ian Pratt",
            "Andrew Warfield"
        ],
        "references": [
            "115ce5c8-8c08-46b1-a100-f6aaa68f20d5",
            "17d502ec-9d95-412a-b1d4-004fc5d8ab04",
            "207aecbb-81f9-48c2-b8be-21119bcceafc",
            "2c9ebc3d-713f-42d8-a867-0ff2d24644d3",
            "37c3f144-3bb2-4df7-a05d-d482dbca0398",
            "53f82d8c-22d7-43e4-be03-fe0cdd7b8abc",
            "553db688-bb98-4ed0-a2a4-42f1e5678559",
            "569b777f-eb40-4fa8-9567-c5844c8c3522",
            "6993119b-feb4-4f91-b2d8-5fe12bcdfa84",
            "70177cf6-e1e7-4624-b371-75b49a1b837f",
            "79df819e-bae3-4d67-bee8-baa3fc148d82",
            "84cdb716-319a-430a-b8e1-90e4848aa187",
            "9dddf29d-dcfe-4a5c-85cc-6a7b6b2d91b4",
            "b5b9d83b-c85b-4418-8d01-4d00ef8a091f",
            "b5ba979f-ba02-4ba4-975d-8687812f4b70",
            "c7bf74ee-739c-45c6-9713-6a0eeb08e76d",
            "d693ff4a-02ea-43a1-bc66-c64970f275a9",
            "da8e4122-1d7b-449c-b52d-0a43c32fc6e7",
            "dfcd55ef-26c0-41c9-8681-9af2a2afd43b",
            "e49e1d41-99eb-41f7-971b-d9c2544198ed",
            "e883ae1e-0c54-4fcb-9c38-4165bb0fcc7a",
            "e96dc7d8-19a8-4495-861e-bfc3963361a7",
            "f483eabe-4858-4d94-88bc-82df43f32a81",
            "f4d35f6d-e961-4f7e-bd18-fda32093cfd0",
            "f67bf40c-fdad-4215-942b-b23b2a017115",
            "fd5b4339-0328-41fc-90b7-12d5f093072c"
        ],
        "keyword": [
            "virtualization",
            "systems",
            "performance",
            "operating",
            "resources",
            "machine"
        ],
        "group": [
            {
                "53f82d8c-22d7-43e4-be03-fe0cdd7b8abc": {
                    "authors": [
                        "Edouard Bugnion",
                        "Scott Devine",
                        "Kinshuk Govil",
                        "Mendel Rosenblum"
                    ],
                    "references": [
                        "0ce74249-8be4-45f5-96de-c5fb2c69c2e9",
                        "111f2584-8c19-4c7e-a2b1-d8d251d5ec83",
                        "5b568078-c342-461d-8a19-44ad105e74fa",
                        "5dff73b0-a0d7-4104-b7a4-1a58644cd651",
                        "65225cd7-9916-41fe-8ef0-633d688a4ede",
                        "6d48d624-d9f7-4f9c-a819-21c6d482f3a5",
                        "7065b53e-5ef1-4109-a3ab-d4feba34efe4",
                        "806ffeb4-b86a-4839-8aa4-9c45620df81b",
                        "81cd5e19-7d92-4996-8917-5058220c7304",
                        "8e9a7151-65d3-4403-86ae-cfc950094610",
                        "95bca9f8-5bb2-45d0-9b54-a6b6b4de1577",
                        "9866e6c4-9757-421d-8cf4-3bf03d3899cf",
                        "a4f95e3a-17b0-46ed-a588-341d2bc53a33",
                        "a6e04f75-7b4f-4a13-bba1-3366c36ce2ed",
                        "b6bf9b19-6b77-42fa-882d-a95defdc965b",
                        "bc7220f4-e7b6-403c-bedb-2977c11e360f",
                        "c373e17d-9dea-46da-a488-7185819a2f3f",
                        "d693ff4a-02ea-43a1-bc66-c64970f275a9",
                        "ec452cf7-daa7-468a-81b3-5f69af655cb3",
                        "f2ea8c07-5e89-412d-b061-29a10d931ce3",
                        "fef5d56d-9674-4e27-b463-5ceef02d3f2a"
                    ],
                    "keyword": [
                        "systems",
                        "operating",
                        "run",
                        "multiprocessors",
                        "machine",
                        "virtual",
                        "scalable",
                        "multiple",
                        "approach"
                    ],
                    "group": [],
                    "_id": "53f82d8c-22d7-43e4-be03-fe0cdd7b8abc",
                    "abstract": "In this article we examine the problem of extending modern operating systems to run efficiently on large-scale shared-memory multiprocessors without a large implementation effort. Our approach brings back an idea popular in the 1970s: virtual machine monitors. We use virtual machines to run multiple commodity operating systems on a scalable multiprocessor. This solution addresses many of the challenges facing the system software for these machines. We demonstrate our approach with a prototype called Disco that runs multiple copies of Silicon Graphics' IRIX operating system on a multiprocessor. Our experience shows that the overheads of the monitor are small and that the approach provides scalability as well as the ability to deal with the nonuniform memory access time of these  systems. To reduce the memory overheads associated with running multiple operating systems, virtual machines transparently share major data structures such as the program code and the file system buffer cache. We use the distributed-system support of modern operating systems to export a partial single system image to the users. The overall solution achieves most of the benefits of operating systems customized for scalable multiprocessors, yet it can be achieved with a significantly smaller implementation effort.",
                    "title": "Disco: running commodity operating systems on scalable multiprocessors",
                    "venue": "ACM Transactions on Computer Systems",
                    "year": 1997,
                    "__v": 1,
                    "citationCount": 204,
                    "result": 6.08500977579925
                },
                "553db688-bb98-4ed0-a2a4-42f1e5678559": {
                    "authors": [
                        "Ajay V. Bakre",
                        "B. R. Badrinath"
                    ],
                    "references": [
                        "02df8f8c-ddff-4412-b212-7d41e9af7a2e",
                        "0b648474-ee09-4bfe-9eb8-62018d7595ad",
                        "0ce74249-8be4-45f5-96de-c5fb2c69c2e9",
                        "17f9698e-02de-4248-b2b8-9bc3c2ccfaff",
                        "22cf117e-17a7-44ab-b502-11389ffbbaa8",
                        "2eb01c13-2c0c-4ae5-83e8-3b2033848374",
                        "6a9c2062-e8eb-4584-8d40-35f8ed4e40d2",
                        "9ed8e875-ca35-4c39-b6e1-35e9802f3933",
                        "ee4aae5e-a7fe-4521-b3f9-280d3abeb745",
                        "f1bfc5c7-e5bb-4958-828d-c523c5e075aa",
                        "fd85eee7-2f63-476b-917a-d7087733f922"
                    ],
                    "keyword": [
                        "mobile",
                        "hosts",
                        "wireless",
                        "itcp",
                        "fixed",
                        "transport",
                        "network",
                        "link",
                        "layer",
                        "unreliable"
                    ],
                    "group": [],
                    "_id": "553db688-bb98-4ed0-a2a4-42f1e5678559",
                    "abstract": "IP based solutions to accommodate mobile hosts within existing internetworks do not address the distinctive features of wireless mobile computing. IP-based transport protocols thus suffer from poor performance when a mobile host communicates with a host on the fixed network. This is caused by frequent disruptions in network layer connectivity due to i) mobility and ii) unreliable nature of the wireless link. We describe I-TCP, which is an indirect transport layer protocol for mobile hosts. I-TCP utilizes the resources of Mobility Support Routers (MSRs) to provide transport layer communication between mobile hosts and hosts on the fixed network. With I-TCP, the problems related to mobility and unreliability of wireless link are handled entirely within the wireless link; the TCP/IP software on the fixed hosts is not modified. Using I-TCP on our testbed, the throughput between a fixed host and a mobile host improved substantially in comparison to regular TCP.",
                    "title": "I-TCP: indirect TCP for mobile hosts",
                    "venue": "international conference on distributed computing systems",
                    "year": 1995,
                    "__v": 2,
                    "citationCount": 518,
                    "result": 2.347914014090485
                },
                "569b777f-eb40-4fa8-9567-c5844c8c3522": {
                    "authors": [
                        "Carl A. Waldspurger"
                    ],
                    "references": [
                        "02c3cd9b-1b52-425b-8746-3bff04d2059f",
                        "1c2688fa-75db-4c48-9a40-10ba11aada5b",
                        "1cfe75c4-a58d-459c-a1bc-81f70a0d1e73",
                        "25cb1196-7b25-48da-8f69-ecbf66842636",
                        "33b89c99-821c-450a-9580-948e7bbde37e",
                        "4109d08d-e457-4c9c-b2f2-0d455a570371",
                        "53f82d8c-22d7-43e4-be03-fe0cdd7b8abc",
                        "6087e97e-61fc-4baf-8708-343b88389f8f",
                        "6412aeff-d7b8-4b57-af8f-eea75e8d8946",
                        "65225cd7-9916-41fe-8ef0-633d688a4ede",
                        "7e219fae-4077-40ed-aaad-218c9eb93009",
                        "9866e6c4-9757-421d-8cf4-3bf03d3899cf",
                        "d17c6230-b25b-4b7b-9112-f0a7fa827152",
                        "da8e4122-1d7b-449c-b52d-0a43c32fc6e7",
                        "dfcd55ef-26c0-41c9-8681-9af2a2afd43b",
                        "ef464df7-4382-4fd3-85c2-e026fac04d9a",
                        "f2ea8c07-5e89-412d-b061-29a10d931ce3",
                        "f499e252-d8e3-4ba3-a1d5-b7ed53fbee21",
                        "f4d35f6d-e961-4f7e-bd18-fda32093cfd0",
                        "fa16b6c0-a2ab-47dd-a394-b2de1ac87077"
                    ],
                    "keyword": [
                        "pages",
                        "memory",
                        "virtual",
                        "machines",
                        "efficiently",
                        "technique",
                        "systems",
                        "server",
                        "running",
                        "remapping"
                    ],
                    "group": [],
                    "_id": "569b777f-eb40-4fa8-9567-c5844c8c3522",
                    "abstract": "VMware ESX Server is a thin software layer designed to multiplex hardware resources efficiently among virtual machines running unmodified commodity operating systems. This paper introduces several novel ESX Server mechanisms and policies for managing memory. A  ballooning  technique reclaims the pages considered least valuable by the operating system running in a virtual machine. An  idle memory tax  achieves efficient memory utilization while maintaining performance isolation guarantees.  Content-based page sharing  and  hot I/O page remapping  exploit transparent page remapping to eliminate redundancy and reduce copying overheads. These techniques are combined to efficiently support virtual machine workloads that overcommit memory.",
                    "title": "Memory resource management in VMware ESX server",
                    "venue": "operating systems design and implementation",
                    "year": 2002,
                    "__v": 2,
                    "citationCount": 566,
                    "result": 6.899206581172526
                },
                "6993119b-feb4-4f91-b2d8-5fe12bcdfa84": {
                    "authors": [
                        "Dawson R. Engler",
                        "S. Gupta",
                        "M.F. Kaashoek"
                    ],
                    "references": [
                        "022d0740-e121-4c5e-8a75-d3e9c878e127",
                        "02c3cd9b-1b52-425b-8746-3bff04d2059f",
                        "0f21c4db-5abf-4e7a-9290-bcb1f4fef798",
                        "11079e33-fdbe-469e-947d-1c7290815c5b",
                        "139f0f7c-ad2f-4961-9fea-c5af8b717201",
                        "4a57f93d-844e-4de8-9352-0a727e06c6a5",
                        "4f33a9e2-46f7-43eb-9c99-4947b37f994d",
                        "4f4498ee-ed1e-4e3a-ad12-ea64f27a5068",
                        "5893b3c3-c5ed-4247-8583-04a60452a7c9",
                        "6087e97e-61fc-4baf-8708-343b88389f8f",
                        "733e7f54-7319-4c7a-8a4f-8fe8af31e1d8",
                        "94c4beaa-b16c-4ae9-aeab-0676d31cdbb0",
                        "a43738d7-f3e6-4943-ad86-70c796fd3ff2",
                        "ba1c271b-c5a2-45ae-baf8-c1d2c6c226a6",
                        "c327095d-8bd1-42aa-954a-fa46c0f6f44e",
                        "d1ea4096-d7f2-4568-8256-db2d0cdfcf7d",
                        "d5a1ce74-b4bc-48c6-93ef-174ae2d95935",
                        "dfe956b4-b304-497f-8db3-40b2b990282e"
                    ],
                    "keyword": [
                        "application",
                        "vm",
                        "system",
                        "memory",
                        "avm",
                        "abstraction",
                        "kernel",
                        "implement",
                        "virtual",
                        "specialize"
                    ],
                    "group": [],
                    "_id": "6993119b-feb4-4f91-b2d8-5fe12bcdfa84",
                    "abstract": "Virtual memory (VM) is a notoriously complicated abstraction to implement, and is hard to change, specialize, or replace. Although a certain degree of flexibility is achieved by user-level pagers, the control they provide is limited: they leave much of the VM system fixed in the kernel, unreachable by the application. As applications become more diverse and the opportunity cost of bad memory policies grows, it is essential for applications to have more control over the VM abstraction. We motivate and describe a VM system that is implemented completely at the application level. To the best of our knowledge this system is the first complete example of application-level virtual memory (AVM). AVM allows applications to easily specialize, modify, or even replace the VM abstractions offered. For example, on architectures with software TLB management, applications can even select their own page-table structures. In addition, AVM simplifies the OS kernel, since the kernel only multiplexes and does not abstract physical memory. A prototype AVM system is implemented for Aegis, an experimental exokernel.",
                    "title": "AVM: application-level virtual memory",
                    "venue": "ieee international conference on requirements engineering",
                    "year": 1995,
                    "__v": 2,
                    "citationCount": 20,
                    "result": 4.353410291268683
                },
                "79df819e-bae3-4d67-bee8-baa3fc148d82": {
                    "authors": [
                        "Ian Pratt",
                        "Keir Fraser"
                    ],
                    "references": [
                        "022d0740-e121-4c5e-8a75-d3e9c878e127",
                        "3fde9cbc-651b-4d22-9262-782c3f2bc4a6",
                        "4c661e26-84ea-4d42-bf14-c9f0842f236b",
                        "5a286502-3870-48c4-b55e-5d0d16a75586",
                        "5b568078-c342-461d-8a19-44ad105e74fa",
                        "933b0197-7587-4594-aadb-fc1427bcf9ab",
                        "9e9fa3f6-039d-47cd-ba7a-e9ec125b3133",
                        "af4b047e-d931-4885-8c78-c48dc5d121de",
                        "b758088b-6e92-44fd-9dd6-ca59586d1756",
                        "c39eace1-d09f-4415-8e51-e2bdf9824d67",
                        "d4147d25-c3a2-4604-aab1-be9c7df581a8"
                    ],
                    "keyword": [
                        "system",
                        "operating",
                        "packets",
                        "applications",
                        "interface",
                        "arsenic",
                        "receive",
                        "performed",
                        "implements",
                        "functions"
                    ],
                    "group": [],
                    "_id": "79df819e-bae3-4d67-bee8-baa3fc148d82",
                    "abstract": "Arsenic is a gigabit Ethernet NIC which exports an extended interface to the operating system and user applications. Unlike conventional adaptors, it implements some of the protection and multiplexing functions traditionally performed by the operating system. This enables applications to be given direct access to their own 'virtual interface', allowing them to send and receive packets without operating system interaction. Packet filters uploaded to the interface card by the operating system are used to demultiplex received packets to their destination application, and to validate packets before transmission. Transmit traffic shaping and scheduling mechanisms enable the bandwidth used by applications to be controlled. These features allow protocol processing to be moved into user-space shared libraries without sacrificing the security and resource management functionality that the operating system normally provides. The paper describes Arsenic's design and implementation, and outlines how it is integrated into the Linux 2.3 operating system. Performance measurements are presented that show Arsenic supports low latency, high bandwidth communication while offering greater CPU efficiency and better quality of service than conventional devices.",
                    "title": "Arsenic: a user-accessible gigabit Ethernet interface",
                    "venue": "international conference on computer communications",
                    "year": 2001,
                    "__v": 2,
                    "citationCount": 37,
                    "result": 6.377950558213716
                },
                "84cdb716-319a-430a-b8e1-90e4848aa187": {
                    "authors": [
                        "Juan Antonio Navarro",
                        "Sitaram Iyer",
                        "Peter Druschel",
                        "Alan L. Cox"
                    ],
                    "references": [
                        "019a5ad3-5d2f-4514-92a8-d5a0280d5ac9",
                        "11079e33-fdbe-469e-947d-1c7290815c5b",
                        "183c8b34-1580-4157-916e-da210323ec36",
                        "22e8a825-056c-42af-8ce8-ef9e7e189604",
                        "28ff28a1-2b20-48dc-ba44-cc694932df41",
                        "33e556d6-c610-42a3-919c-89ef831480b0",
                        "37c3f144-3bb2-4df7-a05d-d482dbca0398",
                        "3ee96aae-7b9b-40c1-9eea-fb8448c04c9c",
                        "4f33a9e2-46f7-43eb-9c99-4947b37f994d",
                        "588a76d0-092e-417c-b480-1b55d7b9f1db",
                        "7065b53e-5ef1-4109-a3ab-d4feba34efe4",
                        "8eaeb13b-5458-44fd-be05-0579b3182cf4",
                        "a0bdc3de-d70f-41f7-b51a-1a73f2b1ec1c",
                        "a678349c-47d3-4993-a493-3ba4d48378ab",
                        "d040f77c-fcc3-40ae-85f7-b2d880e5f70d"
                    ],
                    "keyword": [
                        "superpages",
                        "tlb",
                        "workloads",
                        "system",
                        "support",
                        "performance",
                        "memory",
                        "large",
                        "benefits"
                    ],
                    "group": [],
                    "_id": "84cdb716-319a-430a-b8e1-90e4848aa187",
                    "abstract": "Most general-purpose processors provide support for memory pages of large sizes, called superpages. Superpages enable each entry in the translation lookaside buffer (TLB) to map a large physical memory region into a virtual address space. This dramatically increases TLB coverage, reduces TLB misses, and promises performance improvements for many applications. However, supporting superpages poses several challenges to the operating system, in terms of superpage allocation and promotion tradeoffs, fragmentation control, etc. We analyze these issues, and propose the design of an effective superpage management system. We implement it in FreeBSD on the Alpha CPU, and evaluate it on real workloads and benchmarks. We obtain substantial performance benefits, often exceeding 30%; these benefits are sustained even under stressful workload scenarios.",
                    "title": "Practical, transparent operating system support for superpages",
                    "venue": "operating systems design and implementation",
                    "year": 2002,
                    "__v": 2,
                    "citationCount": 66,
                    "result": 4.125879057303206
                },
                "9dddf29d-dcfe-4a5c-85cc-6a7b6b2d91b4": {
                    "authors": [
                        "George W. Dunlap",
                        "Samuel T. King",
                        "Sukru Cinar",
                        "Murtaza A. Basrai",
                        "Peter M. Chen"
                    ],
                    "references": [
                        "094c6468-7f80-46cb-986b-d34d12b3b091",
                        "11f52fe3-4eca-4818-9bcf-9e24cdc76fb5",
                        "2333a723-ccd8-44d4-ac30-e4735594474b",
                        "240a4209-d0f7-4417-9f4c-6ed14ef00631",
                        "25cb1196-7b25-48da-8f69-ecbf66842636",
                        "58f68055-36b0-41cc-bf97-958c5de5c849",
                        "65225cd7-9916-41fe-8ef0-633d688a4ede",
                        "735dedeb-a935-4e6e-b071-4f7e3edfebb8",
                        "7c813997-94bd-42aa-a46d-41c39c947fd5",
                        "8f877f63-55b7-4408-9cf0-cb5fffe27ac6",
                        "94fbc0ff-4485-4899-a1ea-e317bbdc07e3",
                        "98b2c542-5f0a-4789-a4f4-15f7542df419",
                        "f0333553-8971-4b32-a2f2-c120e50fd101"
                    ],
                    "keyword": [
                        "system",
                        "logged",
                        "virtual",
                        "revirt",
                        "workloads",
                        "replay",
                        "overhead",
                        "operating",
                        "machine",
                        "execution"
                    ],
                    "group": [],
                    "_id": "9dddf29d-dcfe-4a5c-85cc-6a7b6b2d91b4",
                    "abstract": "Current system loggers have two problems: they depend on the integrity of the operating system being logged, and they do not save sufficient information to replay and analyze attacks that include any non-deterministic events. ReVirt removes the dependency on the target operating system by moving it into a virtual machine and logging below the virtual machine. This allows ReVirt to replay the system's execution before, during, and after an intruder compromises the system, even if the intruder replaces the target operating system. ReVirt logs enough information to replay a long-term execution of the virtual machine instruction-by-instruction. This enables it to provide arbitrarily detailed observations about what transpired on the system, even in the presence of non-deterministic attacks and executions. ReVirt adds reasonable time and space overhead. Overheads due to virtualization are imperceptible for interactive use and CPU-bound workloads, and 13--58% for kernel-intensive workloads. Logging adds 0--8% overhead, and logging traffic for our workloads can be stored on a single disk for several months.",
                    "title": "ReVirt: enabling intrusion analysis through virtual-machine logging and replay",
                    "venue": "operating systems design and implementation",
                    "year": 2002,
                    "__v": 2,
                    "citationCount": 427,
                    "result": 5.77791398487993
                },
                "b5b9d83b-c85b-4418-8d01-4d00ef8a091f": {
                    "authors": [
                        "Samuel T. King",
                        "George W. Dunlap",
                        "Peter M. Chen"
                    ],
                    "references": [
                        "094c6468-7f80-46cb-986b-d34d12b3b091",
                        "207aecbb-81f9-48c2-b8be-21119bcceafc",
                        "2333a723-ccd8-44d4-ac30-e4735594474b",
                        "240a4209-d0f7-4417-9f4c-6ed14ef00631",
                        "25cb1196-7b25-48da-8f69-ecbf66842636",
                        "38814a1c-d529-43d5-ae7c-b4edd888f1b8",
                        "53f82d8c-22d7-43e4-be03-fe0cdd7b8abc",
                        "569b777f-eb40-4fa8-9567-c5844c8c3522",
                        "65225cd7-9916-41fe-8ef0-633d688a4ede",
                        "8f877f63-55b7-4408-9cf0-cb5fffe27ac6",
                        "98b2c542-5f0a-4789-a4f4-15f7542df419",
                        "9dddf29d-dcfe-4a5c-85cc-6a7b6b2d91b4",
                        "a0af2962-d4dc-456c-9369-482ce62c4944",
                        "a4d42fcb-07bd-4069-bf66-4c1a07110534",
                        "e75d2b2d-3d6c-4091-b4ec-32734caefe4a",
                        "f483eabe-4858-4d94-88bc-82df43f32a81",
                        "f67bf40c-fdad-4215-942b-b23b2a017115"
                    ],
                    "keyword": [
                        "vmms",
                        "type",
                        "system",
                        "ii",
                        "vmm",
                        "virtual",
                        "overhead",
                        "operating",
                        "running",
                        "machine"
                    ],
                    "group": [],
                    "_id": "b5b9d83b-c85b-4418-8d01-4d00ef8a091f",
                    "abstract": "A virtual-machine monitor (VMM) is a useful technique for adding functionality below existing operating system and application software. One class of VMMs (called Type II VMMs) builds on the abstractions provided by a host operating system. Type II VMMs are elegant and convenient, but their performance is currently an order of magnitude slower than that achieved when running outside a virtual machine (a standalone system). In this paper, we examine the reasons for this large overhead for Type II VMMs. We find that a few simple extensions to a host operating system can make it a much faster platform for running a VMM. Taking advantage of these extensions reduces virtualization overhead for a Type II VMM to 14-35% overhead, even for workloads that exercise the virtual machine intensively.",
                    "title": "Operating system support for virtual machines",
                    "venue": "usenix technical conference",
                    "year": 2003,
                    "__v": 2,
                    "citationCount": 50,
                    "result": 7.93302276498871
                },
                "c7bf74ee-739c-45c6-9713-6a0eeb08e76d": {
                    "authors": [
                        "Larry L. Peterson",
                        "Thomas E. Anderson",
                        "David E. Culler",
                        "Timothy Roscoe"
                    ],
                    "references": [
                        "0ba640e8-a0ab-4d39-b13b-c85572a5c57d",
                        "0e015120-cce1-4cb7-bbe3-f0ea3679c5c3",
                        "1cc64868-4f72-4939-aed4-fc8fb0b45118",
                        "36c05ec1-7f89-44d4-a180-49820c36e4a0",
                        "4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4",
                        "5e354aca-2d93-43f7-8e80-6bc4eb96e7d9",
                        "8df0f1e0-c75c-4c63-81d9-b8ab58daa4fd",
                        "a369afee-a619-4e9a-9250-5fd2b06e8a05",
                        "a5a4cf29-7161-4648-a1f4-8cc95aa725b7",
                        "b7d7ec53-f079-4bd7-a795-8b6fe77f2db6",
                        "cbc01e36-33c2-4709-a00d-22e6d0727560",
                        "f14df1ed-e3e9-4348-9040-fc06e3411b95",
                        "f483eabe-4858-4d94-88bc-82df43f32a81"
                    ],
                    "keyword": [
                        "services",
                        "design",
                        "testbed",
                        "network",
                        "supports",
                        "principles",
                        "overlay's",
                        "slice",
                        "run",
                        "resources"
                    ],
                    "group": [],
                    "_id": "c7bf74ee-739c-45c6-9713-6a0eeb08e76d",
                    "abstract": "This paper argues that a new class of geographically distributed network services is emerging, and that the most effective way to design, evaluate, and deploy these services is by using an overlay-based testbed. Unlike conventional network testbeds, however, we advocate an approach that supports both researchers that want to develop new services, and clients that want to use them. This dual use, in turn, suggests four design principles that are not widely supported in existing testbeds: services should be able to run continuously and access a slice of the overlay's resources, control over resources should be distributed, overlay management services should be unbundled and run in their own slices, and APIs should be designed to promote application development. We believe a testbed that supports these design principles will facilitate the emergence of a new  service-oriented network architecture . Towards this end, the paper also briefly describes PlanetLab, an overlay network being designed with these four principles in mind.",
                    "title": "A blueprint for introducing disruptive technology into the Internet",
                    "venue": "acm special interest group on data communication",
                    "year": 2003,
                    "__v": 2,
                    "citationCount": 440,
                    "result": 4.5075435572339595
                },
                "d693ff4a-02ea-43a1-bc66-c64970f275a9": {
                    "authors": [
                        "M. Frans Kaashoek",
                        "Dawson R. Engler",
                        "Gregory R. Ganger",
                        "Héctor M. Briceño",
                        "Russell Hunt",
                        "David Mazières",
                        "Thomas Pinckney",
                        "Robert Grimm",
                        "John Jannotti",
                        "Kenneth Mackenzie"
                    ],
                    "references": [
                        "0a62cd6c-394c-481b-95e8-47e7b4b9280f",
                        "0d8c3dd5-e271-480f-98ad-284c76f3aee9",
                        "31928b23-12ba-43f4-8ed8-f067a05835e6",
                        "33b89c99-821c-450a-9580-948e7bbde37e",
                        "35556f73-dafc-4f68-abcc-62642784184c",
                        "3b44e784-c356-45a8-af90-64e926577870",
                        "3e67ce64-43ca-41c4-a2ef-d70140b7d92b",
                        "4c67ed1d-37b6-44cb-a837-608e606da85e",
                        "53f82d8c-22d7-43e4-be03-fe0cdd7b8abc",
                        "5a3f0783-1f29-4624-b67e-8948aac3c8ab",
                        "5b568078-c342-461d-8a19-44ad105e74fa",
                        "5fa0709f-7330-417f-8da7-3ab31d91da5b",
                        "6087e97e-61fc-4baf-8708-343b88389f8f",
                        "628b5474-440d-42c5-b6bf-aed522765eef",
                        "65225cd7-9916-41fe-8ef0-633d688a4ede",
                        "721b9572-74f3-4077-b8b8-442d259f706b",
                        "733e7f54-7319-4c7a-8a4f-8fe8af31e1d8",
                        "76f932f2-b6ff-4b18-819d-ce1120afd5a5",
                        "93e617b9-2640-4741-ae41-b0811edd4748",
                        "9866e6c4-9757-421d-8cf4-3bf03d3899cf",
                        "a0af2962-d4dc-456c-9369-482ce62c4944",
                        "afecdb92-5d3f-4a72-92c5-2c4495696d67",
                        "b87860ce-71bf-4dea-a751-180eb22a8ff4",
                        "b9442fce-3e06-4c6a-8818-e41ec6ec591e",
                        "c39eace1-d09f-4415-8e51-e2bdf9824d67",
                        "d280422d-76a8-448e-bf7d-6b362fc7d6cf",
                        "d4147d25-c3a2-4604-aab1-be9c7df581a8",
                        "d532d0cc-1f0a-444a-a457-ab15e09645aa",
                        "dfe956b4-b304-497f-8db3-40b2b990282e",
                        "e883ae1e-0c54-4fcb-9c38-4165bb0fcc7a",
                        "fa16b6c0-a2ab-47dd-a394-b2de1ac87077",
                        "fcd5e8a7-818a-4c8f-a537-d81143c1ee8b"
                    ],
                    "keyword": [
                        "performance",
                        "exokernel",
                        "applications",
                        "unix",
                        "system",
                        "xok",
                        "software",
                        "show",
                        "results",
                        "resources"
                    ],
                    "group": [],
                    "_id": "d693ff4a-02ea-43a1-bc66-c64970f275a9",
                    "abstract": "The exokernel operating system architecture safely gives untrusted software efficient control over hardware and software resou rces by separating management from protection. This paper describes an exokernel system that allows specialized applications to achieve high performance without sacrificing the performance of unm odified UNIX programs. It evaluates the exokernel architectur e by measuring end-to-end application performance on Xok, an exokernel for Intel x86-based computers, and by comparing Xok’s performance to the performance of two widely-used 4.4BSD UNIX systems (FreeBSD and OpenBSD). The results show that common unmodified UNIX applications can enjoy the benefits of exoker nels: applications either perform comparably on Xok/ExOS and the BSD UNIXes, or perform significantly better. In addition , the results show that customized applications can benefit subst antially from control over their resources (e.g., a factor of eight fo r a Web server). This paper also describes insights about the exokernel approach gained through building three different exokernel systems, and presents novel approaches to resource multiplexing.",
                    "title": "Application performance and flexibility on exokernel systems",
                    "venue": "symposium on operating systems principles",
                    "year": 1997,
                    "__v": 2,
                    "citationCount": 142,
                    "result": 5.80630831157147
                },
                "dfcd55ef-26c0-41c9-8681-9af2a2afd43b": {
                    "authors": [
                        "Love H. Seawright",
                        "Richard A. MacKinnon"
                    ],
                    "references": [
                        "4c97a730-c2a4-433d-b091-155161872d9a",
                        "65225cd7-9916-41fe-8ef0-633d688a4ede",
                        "872a888b-ead7-4c92-832a-60661f53b985",
                        "886eccb7-7b4d-48fc-be5d-08cf0b388ed1",
                        "ac92f464-7e8f-4c1d-b33a-1f0650d67ed7",
                        "b0c5b1e4-27c1-43a7-9c25-88adf86772f5"
                    ],
                    "keyword": [
                        "vm370",
                        "virtual",
                        "system",
                        "paper",
                        "machine",
                        "rest",
                        "program",
                        "overview",
                        "networking",
                        "multiple"
                    ],
                    "group": [],
                    "_id": "dfcd55ef-26c0-41c9-8681-9af2a2afd43b",
                    "abstract": "This paper is an overview of IBM'S Virtual Machine Facility/370. It describes the virtual machine concept and its capabilities and implementation in VM/370. Two components of VM/370 are discussed-the control program and the Conversational Monitor System. The usefulness of VM/370 in multiple and diverse environments is covered. New developments in VM/370 from hardware assists to system extensions, networking, and handshaking are briefly described as an introduction to the rest of the papers in this issue.",
                    "title": "VM/370: a study of multiplicity and usefulness",
                    "venue": "Ibm Systems Journal",
                    "year": 1979,
                    "__v": 2,
                    "citationCount": 48,
                    "result": 5.347828014778479
                }
            }
        ],
        "_id": "78991392-db9c-45a4-86a2-b4ce93ab0ec0",
        "abstract": "Numerous systems have been designed which use virtualization to subdivide the ample resources of a modern computer. Some require specialized hardware, or cannot support commodity operating systems. Some target 100% binary compatibility at the expense of performance. Others sacrifice security or functionality for speed. Few offer resource isolation or performance guarantees; most provide only best-effort provisioning, risking denial of service.This paper presents Xen, an x86 virtual machine monitor which allows multiple commodity operating systems to share conventional hardware in a safe and resource managed fashion, but without sacrificing either performance or functionality. This is achieved by providing an idealized virtual machine abstraction to which operating systems such as Linux, BSD and Windows XP, can be  ported  with minimal effort.Our design is targeted at hosting up to 100 virtual machine instances simultaneously on a modern server. The virtualization approach taken by Xen is extremely efficient: we allow operating systems such as Linux and Windows XP to be hosted simultaneously for a negligible performance overhead --- at most a few percent compared with the unvirtualized case. We considerably outperform competing commercial and freely available solutions in a range of microbenchmarks and system-wide tests.",
        "title": "Xen and the art of virtualization",
        "venue": "symposium on operating systems principles",
        "year": 2003,
        "__v": 2,
        "citationCount": 2835
    },
    {
        "authors": [
            "Ulrike von Luxburg"
        ],
        "references": [
            "05bbaec3-7980-4941-8638-2bbfa4ac8be0",
            "05c81472-37d6-460f-9343-675d70402c7e",
            "089053a7-cf4b-43fa-9c17-e1e13cdc9278",
            "0a3876f3-df2f-4dd8-b2a1-53bfe7714348",
            "0cdb081e-f2db-49d9-8c65-45cbcc948265",
            "158f4525-404a-4ffc-be57-51f02a53445c",
            "1b806dc6-7d06-48c4-b8a9-16111d135559",
            "213ccf22-1ea7-42a3-8369-644a47a5fbe2",
            "2cd6f789-de0b-4d5d-b3d0-60962bd31d41",
            "31d1a3f9-73ab-4dd3-8977-6b322e5ecc1d",
            "3549c862-c615-4f80-ac53-f562d3e2b846",
            "3b64a259-80c2-4b82-9c04-34a0ee4a20aa",
            "3e1c7e71-b0ee-4ddd-8fb9-09a6bf51181f",
            "44d7e2c1-7a65-4fb8-86e5-ea0bfdad98e9",
            "4d4df750-7647-42f4-b1bb-120d91bc0352",
            "5d3ddeee-5a39-49b8-8fa3-28099a31f7aa",
            "63ec4f55-8f3b-431e-88e5-87c04caa7e9f",
            "7a1a3bf9-8c23-4c13-8c8e-85b79ad6143e",
            "7ec5f06e-2fe3-495a-84a0-94fcfe08bb7b",
            "82a4ef1a-c503-49bd-a2f4-34d13537a5f1",
            "89492dcb-ea5d-4dda-a5fb-687818cbe384",
            "98da593f-2756-4d08-b67b-f8c610f41354",
            "991b5edd-202d-4194-ac57-e2edb1fb0201",
            "9fa127d1-10cf-4a8b-b938-bcb079cbc96c",
            "a64c03c2-ba6c-4cc5-afc1-16b4108ea29d",
            "a7da3014-5be5-49a0-a77c-4271633b941c",
            "b6208d93-998c-4593-b2d9-1d3ff936750f",
            "bd55a32a-8dab-4551-806c-bce9e4a32c67",
            "d33a7b23-08c6-4de6-95c8-e3b6bf8c16bb",
            "dd90433d-a428-4ff1-833d-050702f7699c",
            "ea8cd3d8-17ae-4a1e-8f83-1609469087af",
            "f3b1b423-aa89-4484-b985-666ee01b06c4",
            "f99a6b3a-0980-4a9e-bbce-f9397c45106f"
        ],
        "keyword": [
            "clustering",
            "algorithms",
            "spectral"
        ],
        "group": [
            {
                "213ccf22-1ea7-42a3-8369-644a47a5fbe2": {
                    "authors": [
                        "Boaz Nadler",
                        "Stephane Lafon",
                        "Ioannis G. Kevrekidis",
                        "Ronald R. Coifman"
                    ],
                    "references": [
                        "05bbaec3-7980-4941-8638-2bbfa4ac8be0",
                        "0cdb081e-f2db-49d9-8c65-45cbcc948265",
                        "1b806dc6-7d06-48c4-b8a9-16111d135559",
                        "220df5f8-cf66-41f0-a25a-be08c4b29d72",
                        "2cd6f789-de0b-4d5d-b3d0-60962bd31d41",
                        "691b653a-fb64-4c8d-88b5-fc51354f4a9b",
                        "7a1a3bf9-8c23-4c13-8c8e-85b79ad6143e",
                        "93a14c23-d227-41fd-ad18-7de38817cb52",
                        "94898e1d-1e50-41ab-9dcc-2c2e030cddd0",
                        "98da593f-2756-4d08-b67b-f8c610f41354",
                        "a7da3014-5be5-49a0-a77c-4271633b941c",
                        "bd55a32a-8dab-4551-806c-bce9e4a32c67",
                        "c472bfe1-9ef6-43c6-89b5-a86b22c9f5df",
                        "cbff2ff2-6b8f-425d-a5ef-aff0de9be3e5",
                        "d78003db-ad8a-48d2-be57-1c50e95cef72",
                        "ea8cd3d8-17ae-4a1e-8f83-1609469087af",
                        "f346663a-7df3-4474-97e4-4923cef60cdb"
                    ],
                    "keyword": [],
                    "group": [],
                    "_id": "213ccf22-1ea7-42a3-8369-644a47a5fbe2",
                    "abstract": "This paper presents a diffusion based probabilistic interpretation of spectral clustering and dimensionality reduction algorithms that use the eigenvectors of the normalized graph Laplacian. Given the pairwise adjacency matrix of all points, we define a diffusion distance between any two data points and show that the low dimensional representation of the data by the first few eigenvectors of the corresponding Markov matrix is optimal under a certain mean squared error criterion. Furthermore, assuming that data points are random samples from a density p(x) = e-U(x) we identify these eigenvectors as discrete approximations of eigenfunctions of a Fokker-Planck operator in a potential 2U(x) with reflecting boundary conditions. Finally, applying known results regarding the eigenvalues and eigenfunctions of the continuous Fokker-Planck operator, we provide a mathematical justification for the success of spectral clustering and dimensional reduction algorithms based on these first few eigenvectors. This analysis elucidates, in terms of the characteristics of diffusion processes, many empirical findings regarding spectral clustering algorithms.",
                    "title": "Diffusion Maps, Spectral Clustering and Eigenfunctions of Fokker-Planck Operators",
                    "venue": "neural information processing systems",
                    "year": 2006,
                    "__v": 0,
                    "citationCount": 121,
                    "result": 2.727272727272727
                },
                "4d4df750-7647-42f4-b1bb-120d91bc0352": {
                    "authors": [
                        "Arik Azran",
                        "Zoubin Ghahramani"
                    ],
                    "references": [
                        "0cdb081e-f2db-49d9-8c65-45cbcc948265",
                        "38135245-8eff-4078-af6a-ea559ffa660b",
                        "691b653a-fb64-4c8d-88b5-fc51354f4a9b",
                        "75d0cdfa-44cd-4fc3-ae56-72e982cb383b",
                        "9e2da831-0b8e-46af-a13a-034915cfcd15",
                        "ea8cd3d8-17ae-4a1e-8f83-1609469087af"
                    ],
                    "keyword": [
                        "clustering",
                        "number",
                        "walk",
                        "steps",
                        "points",
                        "data",
                        "reveals",
                        "random",
                        "distributions",
                        "algorithm"
                    ],
                    "group": [],
                    "_id": "4d4df750-7647-42f4-b1bb-120d91bc0352",
                    "abstract": "We consider the problem of clustering in its most basic form where only a local metric on the data space is given. No parametric statistical model is assumed, and the number of clusters is learned from the data. We introduce, analyze and demonstrate a novel approach to clustering where data points are viewed as nodes of a graph, and pairwise similarities are used to derive a transition probability matrix  P  for a Markov random walk between them. The algorithm automatically reveals structure at increasing scales by varying the number of steps taken by this random walk. Points are represented as rows of  P   t  , which are the  t -step distributions of the walk starting at that point; these distributions are then clustered using a KL-minimizing iterative algorithm. Both the number of clusters, and the number of steps that 'best reveal' it, are found by optimizing spectral properties of  P .",
                    "title": "A new approach to data driven clustering",
                    "venue": "international conference on machine learning",
                    "year": 2006,
                    "__v": 1,
                    "citationCount": 10,
                    "result": 4.7142254374452515
                },
                "63ec4f55-8f3b-431e-88e5-87c04caa7e9f": {
                    "authors": [
                        "Lars W. Hagen",
                        "Andrew B. Kahng"
                    ],
                    "references": [
                        "1214493c-3497-4eab-87dc-53ff98882bad",
                        "1722ff88-e788-4e0c-86cd-6551b75eabca",
                        "614c4a46-08bb-48fa-94a4-8c05d65a24f7",
                        "63139dcf-11e2-4b8e-bcbd-ebd1f0511389",
                        "679f537b-1aa2-4977-9255-8f1a3d021246",
                        "6f7517aa-b3dd-4289-a44e-42cec8ef0370",
                        "8b7e9a42-ef7f-41f1-970b-6d05d65c8b40",
                        "cab30a53-0314-48f3-9ff9-e4438cc109f8",
                        "dc88af6e-158d-4a2e-badd-2afaf5c95648",
                        "e30d86fe-546b-45ed-9463-d6305c08a006",
                        "ea90d7c2-28ad-48c1-8e34-a29d0e4f1419",
                        "eea2da24-467e-4179-acb9-ae3c24591119",
                        "f078efcf-4e45-49cb-a9d1-0886eedfcfc6",
                        "ff1609ce-c9ab-41e5-b7cb-481d5a51693e"
                    ],
                    "keyword": [
                        "partitioning",
                        "netlists",
                        "ratio",
                        "heuristic",
                        "eigenvalue",
                        "cut",
                        "proposed",
                        "methods",
                        "intersection",
                        "graph"
                    ],
                    "group": [],
                    "_id": "63ec4f55-8f3b-431e-88e5-87c04caa7e9f",
                    "abstract": "Partitioning of circuit netlists in VLSI design is considered. It is shown that the second smallest eigenvalue of a matrix derived from the netlist gives a provably good approximation of the optimal ratio cut partition cost. It is also demonstrated that fast Lanczos-type methods for the sparse symmetric eigenvalue problem are a robust basis for computing heuristic ratio cuts based on the eigenvector of this second eigenvalue. Effective clustering methods are an immediate by-product of the second eigenvector computation and are very successful on the difficult input classes proposed in the CAD literature. The intersection graph representation of the circuit netlist is considered, as a basis for partitioning, a heuristic based on spectral ratio cut partitioning of the netlist intersection graph is proposed. The partitioning heuristics were tested on industry benchmark suites, and the results were good in terms of both solution quality and runtime. Several types of algorithmic speedups and directions for future work are discussed. >",
                    "title": "Fast spectral methods for ratio cut partitioning and clustering",
                    "venue": "international conference on computer aided design",
                    "year": 1991,
                    "__v": 2,
                    "citationCount": 383,
                    "result": 2.1443553178847297
                },
                "7ec5f06e-2fe3-495a-84a0-94fcfe08bb7b": {
                    "authors": [
                        "Inderjit S. Dhillon"
                    ],
                    "references": [
                        "407ceb18-464f-4ab3-b731-68f7681fb26d",
                        "63ec4f55-8f3b-431e-88e5-87c04caa7e9f",
                        "9463c44f-b075-4704-bdfe-f099b4d0a252",
                        "9b4e6c65-da64-4ffe-8f2b-810d7f1efb54",
                        "a9ce5107-6998-4ce8-a2f9-368b8d21219b",
                        "c3e99ff5-57f9-4012-8b92-48c8d26bf232",
                        "e75d8e62-a86d-4241-953f-1b315005d920",
                        "ff1609ce-c9ab-41e5-b7cb-481d5a51693e"
                    ],
                    "keyword": [
                        "problems",
                        "document",
                        "clustering",
                        "bipartite",
                        "algorithms",
                        "word",
                        "graph",
                        "vectors",
                        "spectral",
                        "solve"
                    ],
                    "group": [],
                    "_id": "7ec5f06e-2fe3-495a-84a0-94fcfe08bb7b",
                    "abstract": "Both document clustering and word clustering are well studied problems. Most existing algorithms cluster documents and words separately but not simultaneously. In this paper we present the novel idea of modeling the document collection as a bipartite graph between documents and words, using which the simultaneous clustering problem can be posed as a bipartite graph partitioning problem. To solve the partitioning problem, we use a new spectral co-clustering algorithm that uses the second left and right singular vectors of an appropriately scaled word-document matrix to yield good bipartitionings. The spectral algorithm enjoys some optimality properties; it can be shown that the singular vectors solve a real relaxation to the NP-complete graph bipartitioning problem. We present experimental results to verify that the resulting co-clustering algorithm works well in practice.",
                    "title": "Co-clustering documents and words using bipartite spectral graph partitioning",
                    "venue": "knowledge discovery and data mining",
                    "year": 2001,
                    "__v": 2,
                    "citationCount": 672,
                    "result": 4.925057132410073
                },
                "82a4ef1a-c503-49bd-a2f4-34d13537a5f1": {
                    "authors": [
                        "Chris H. Q. Ding",
                        "Xiaofeng He",
                        "Hongyuan Zha",
                        "Ming Gu",
                        "Horst D. Simon"
                    ],
                    "references": [
                        "05060319-a945-4855-a927-9140612881c9",
                        "1914b556-6d34-4071-b9b4-9fa3ce61662e",
                        "409cba78-cd24-46da-bd19-fa4517d59604",
                        "42f4a7d0-df25-49e1-9c24-ad0a07c40d56",
                        "63ec4f55-8f3b-431e-88e5-87c04caa7e9f",
                        "c4d758e3-eadb-4d0f-828f-323ff3a1dd8c"
                    ],
                    "keyword": [
                        "partitioning",
                        "graph",
                        "minmax",
                        "clustering",
                        "objects",
                        "data",
                        "cut",
                        "algorithm",
                        "vector",
                        "methods"
                    ],
                    "group": [],
                    "_id": "82a4ef1a-c503-49bd-a2f4-34d13537a5f1",
                    "abstract": "An important application of graph partitioning is data clustering using a graph model - the pairwise similarities between all data objects form a weighted graph adjacency matrix that contains all necessary information for clustering. In this paper, we propose a new algorithm for graph partitioning with an objective function that follows the min-max clustering principle. The relaxed version of the optimization of the min-max cut objective function leads to the Fiedler vector in spectral graph partitioning. Theoretical analyses of min-max cut indicate that it leads to balanced partitions, and lower bounds are derived. The min-max cut algorithm is tested on newsgroup data sets and is found to out-perform other current popular partitioning/clustering methods. The linkage-based refinements to the algorithm further improve the quality of clustering substantially. We also demonstrate that a linearized search order based on linkage differential is better than that based on the Fiedler vector, providing another effective partitioning method.",
                    "title": "A min-max cut algorithm for graph partitioning and data clustering",
                    "venue": "international conference on data mining",
                    "year": 2001,
                    "__v": 2,
                    "citationCount": 347,
                    "result": 4.148189718777954
                },
                "89492dcb-ea5d-4dda-a5fb-687818cbe384": {
                    "authors": [
                        "Ravi Kannan",
                        "Santosh Vempala",
                        "Adrian Vetta"
                    ],
                    "references": [
                        "22527ddd-8d68-4a78-864b-9a9cd04ba426",
                        "52b8747c-6eef-43bc-8e11-aa3c4aae1111",
                        "6c4b0829-01d8-407a-8cab-53cd38080c2f",
                        "70c53433-0357-4957-9089-6e59a06282c3",
                        "74d13b4a-b2ab-49e1-8066-d00fe9f07d0f",
                        "7ec5f06e-2fe3-495a-84a0-94fcfe08bb7b",
                        "93b14f9a-884c-441a-b91d-66a659248c0d",
                        "aaa548b1-1c83-4325-8218-ee1efbf9a484",
                        "b613fdc9-9f3c-484c-aac3-2d55eadf7cbb",
                        "c19c233b-6b1d-40a9-b553-a6efbe11932c",
                        "c4d758e3-eadb-4d0f-828f-323ff3a1dd8c",
                        "d78003db-ad8a-48d2-be57-1c50e95cef72",
                        "e1ebee81-dfa4-4fe0-b0e1-c00df9ada4d4"
                    ],
                    "keyword": [
                        "measure",
                        "clustering",
                        "worstcase",
                        "spectral",
                        "guarantees",
                        "existing",
                        "variant",
                        "turns",
                        "simple",
                        "shown"
                    ],
                    "group": [],
                    "_id": "89492dcb-ea5d-4dda-a5fb-687818cbe384",
                    "abstract": "We motivate and develop a natural bicriteria measure for assessing the quality of a clustering that avoids the drawbacks of existing measures. A simple recursive heuristic is shown to have poly-logarithmic worst-case guarantees under the new measure. The main result of the article is the analysis of a popular  spectral  algorithm. One variant of spectral clustering turns out to have effective worst-case guarantees; another finds a \"good\" clustering, if one exists.",
                    "title": "On clusterings: Good, bad and spectral",
                    "venue": "Journal of the ACM",
                    "year": 2004,
                    "__v": 1,
                    "citationCount": 337,
                    "result": 3.652213309566251
                },
                "991b5edd-202d-4194-ac57-e2edb1fb0201": {
                    "authors": [
                        "Francis R. Bach",
                        "Michael I. Jordan"
                    ],
                    "references": [
                        "06df372e-5e18-44e1-81b5-84f65aea2816",
                        "0bc83749-8225-4f84-975c-5674e021dcf8",
                        "47f728b9-85b0-44c4-ab88-b46eb3b88d4d",
                        "57e35e32-f009-4b9b-bfb2-3747eac40b72",
                        "5c89ee50-d7f5-4cd6-8eed-19a08efd6f90",
                        "807b8ea8-a82a-46ae-87d4-387ea795fa7a",
                        "8c0ec27c-e654-4e0e-8c49-9b427117a98e",
                        "93b8f6ed-865d-4698-8556-d7a8713afbf8",
                        "b2107f09-3d6d-43de-90e7-787175c82499",
                        "c8c88c99-84c5-4988-bfa4-72f03bd8a74f",
                        "ea8cd3d8-17ae-4a1e-8f83-1609469087af",
                        "fbb1d0f0-290f-490d-baab-63d29bc5f794"
                    ],
                    "keyword": [
                        "clustering",
                        "similarity",
                        "spectral",
                        "points",
                        "partition",
                        "matrix",
                        "function",
                        "cost",
                        "respect",
                        "minimizing"
                    ],
                    "group": [],
                    "_id": "991b5edd-202d-4194-ac57-e2edb1fb0201",
                    "abstract": "Spectral clustering refers to a class of techniques which rely on the eigen-structure of a similarity matrix to partition points into disjoint clusters with points in the same cluster having high similarity and points in different clusters having low similarity. In this paper, we derive a new cost function for spectral clustering based on a measure of error between a given partition and a solution of the spectral relaxation of a minimum normalized cut problem. Minimizing this cost function with respect to the partition leads to a new spectral clustering algorithm. Minimizing with respect to the similarity matrix leads to an algorithm for learning the similarity matrix. We develop a tractable approximation of our cost function that is based on the power method of computing eigenvectors.",
                    "title": "Learning Spectral Clustering",
                    "venue": "neural information processing systems",
                    "year": 2004,
                    "__v": 2,
                    "citationCount": 175,
                    "result": 4.732490548667019
                },
                "b6208d93-998c-4593-b2d9-1d3ff936750f": {
                    "authors": [
                        "Mechthild Stoer",
                        "Frank R. Wagner"
                    ],
                    "references": [
                        "1c8392a4-4d32-4e49-9903-5bdb7bd0a786",
                        "693b872d-d5d6-4a95-a5b0-ea4bc599c007",
                        "8b06e94d-9d43-4160-ba76-3f65bc761eb4",
                        "9ffe7be9-e522-41be-a442-e813e01d3b56",
                        "b4d7f1ca-e2e9-48d3-bb72-8502af3abac3",
                        "ca1d3032-e288-42f1-9228-f95da0535c0c",
                        "f5de6b41-0df8-4270-8211-a67a081dad45",
                        "ff68e871-65e0-4aa3-8edf-7fc2be480dcf"
                    ],
                    "keyword": [
                        "algorithm",
                        "simple",
                        "runtime",
                        "undirected",
                        "techniques",
                        "surprisingly",
                        "straightforward",
                        "speaking",
                        "short",
                        "search"
                    ],
                    "group": [],
                    "_id": "b6208d93-998c-4593-b2d9-1d3ff936750f",
                    "abstract": "We present an algorithm for finding the minimum cut of an undirected edge-weighted graph. It is simple in every respect. It has a short and compact description, is easy to implement, and has a surprisingly simple proof of correctness. Its runtime matches that of the fastest algorithm known. The runtime analysis is straightforward. In contrast to nearly all approaches so far, the algorithm uses no flow techniques. Roughly speaking, the algorithm consists of about | V | nearly identical phases each of which is a  maximum adjacency search .",
                    "title": "A simple min-cut algorithm",
                    "venue": "Journal of the ACM",
                    "year": 1997,
                    "__v": 1,
                    "citationCount": 247,
                    "result": 3.2433287584822104
                },
                "bd55a32a-8dab-4551-806c-bce9e4a32c67": {
                    "authors": [
                        "Lihi Zelnik-Manor",
                        "Pietro Perona"
                    ],
                    "references": [
                        "0efb7bac-1ce1-4b9a-bcfd-004619e6c640",
                        "6e184d1b-925b-4918-b354-a2647e8fd945",
                        "75d0cdfa-44cd-4fc3-ae56-72e982cb383b",
                        "d78003db-ad8a-48d2-be57-1c50e95cef72",
                        "ea8cd3d8-17ae-4a1e-8f83-1609469087af",
                        "fbb1d0f0-290f-490d-baab-63d29bc5f794"
                    ],
                    "keyword": [
                        "scale",
                        "clustering",
                        "number",
                        "'local'",
                        "leads",
                        "groups",
                        "data",
                        "clutter",
                        "background",
                        "automatically"
                    ],
                    "group": [],
                    "_id": "bd55a32a-8dab-4551-806c-bce9e4a32c67",
                    "abstract": "We study a number of open issues in spectral clustering: (i) Selecting the appropriate scale of analysis, (ii) Handling multi-scale data, (iii) Clustering with irregular background clutter, and, (iv) Finding automatically the number of groups. We first propose that a 'local' scale should be used to compute the affinity between each pair of points. This local scaling leads to better clustering especially when the data includes multiple scales and when the clusters are placed within a cluttered background. We further suggest exploiting the structure of the eigenvectors to infer automatically the number of groups. This leads to a new algorithm in which the final randomly initialized k-means stage is eliminated.",
                    "title": "Self-Tuning Spectral Clustering",
                    "venue": "neural information processing systems",
                    "year": 2005,
                    "__v": 2,
                    "citationCount": 757,
                    "result": 2.913676966308545
                },
                "dd90433d-a428-4ff1-833d-050702f7699c": {
                    "authors": [
                        "François Fouss",
                        "Alain Pirotte",
                        "Jean-Michel Renders",
                        "Marco Saerens"
                    ],
                    "references": [
                        "05bbaec3-7980-4941-8638-2bbfa4ac8be0",
                        "0ea745c7-58b2-48e8-9115-42e9b0d20f2a",
                        "106ac945-1fd6-4abd-b059-1b56ca491d0a",
                        "1d383765-fe50-4493-9714-3df0c5e05057",
                        "1ddb34c4-84cf-469d-b0cb-6b4d25e1ee27",
                        "213ccf22-1ea7-42a3-8369-644a47a5fbe2",
                        "2ebf75c1-1630-45cc-90de-ee5db9190d89",
                        "34d4e37b-e575-4316-847b-d8a661b51473",
                        "3945dce8-e585-4e9c-98e7-9c4d4218f724",
                        "3c383c6f-3503-458d-bdd7-a34cb8f4515f",
                        "3e5fd33f-1fd0-4815-a47a-3c41a26a538a",
                        "4c0cd9bb-5b3b-4fa3-aefa-eccd4a8f5b33",
                        "5558ea9c-380f-4d58-8088-2e3712248bd2",
                        "5fc7c376-5895-490a-8ea2-989442940c7b",
                        "619f8b07-bb28-404b-8e53-91dbf0109770",
                        "6e425bce-a497-4c63-9eb0-b038e660a54f",
                        "6fff0e62-9812-4ea8-8f28-a2f94d571b90",
                        "7a1a3bf9-8c23-4c13-8c8e-85b79ad6143e",
                        "8c443f3c-af9d-499b-9ce6-85e502da573f",
                        "8f9e92cf-f266-4e51-807f-c098a260a0dc",
                        "99d18eba-2586-46fd-984d-3c471927bb51",
                        "a23effc2-0dad-40ee-b1d0-0375bf76fc8e",
                        "ad467380-4465-4b1a-b8ff-7f90bf4868e4",
                        "bd741812-afb5-4b2c-a807-1d6c93fde3ac",
                        "c5ec6a5c-ff8d-494d-b093-66383861fe51",
                        "cbff2ff2-6b8f-425d-a5ef-aff0de9be3e5",
                        "ddedcf0e-043f-4362-a33d-ae8ba33d07fe",
                        "e75d428e-9877-4d52-8660-1bb3bf0b9f5e",
                        "eab63a89-1016-4045-b3ff-2c9c365af2bf",
                        "f2014a2b-0a8a-42b9-9ff7-61e4fe71bf39",
                        "f782a72e-eeca-4757-ace9-670012f961a8"
                    ],
                    "keyword": [
                        "graph",
                        "time",
                        "similarity",
                        "nodes",
                        "matrix",
                        "elements",
                        "database",
                        "commute"
                    ],
                    "group": [],
                    "_id": "dd90433d-a428-4ff1-833d-050702f7699c",
                    "abstract": "This work presents a new perspective on characterizing the similarity between elements of a database or, more generally, nodes of a weighted and undirected graph. It is based on a Markov-chain model of random walk through the database. More precisely, we compute quantities (the average commute time, the pseudoinverse of the Laplacian matrix of the graph, etc.) that provide similarities between any pair of nodes, having the nice property of increasing when the number of paths connecting those elements increases and when the \"length\" of paths decreases. It turns out that the square root of the average commute time is a Euclidean distance and that the pseudoinverse of the Laplacian matrix is a kernel matrix (its elements are inner products closely related to commute times). A principal component analysis (PCA) of the graph is introduced for computing the subspace projection of the node vectors in a manner that preserves as much variance as possible in terms of the Euclidean commute-time distance. This graph PCA provides a nice interpretation to the \"Fiedler vector,\" widely used for graph partitioning. The model is evaluated on a collaborative-recommendation task where suggestions are made about which movies people should watch based upon what they watched in the past. Experimental results on the MovieLens database show that the Laplacian-based similarities perform well in comparison with other methods. The model, which nicely fits into the so-called \"statistical relational learning\" framework, could also be used to compute document or word similarities, and, more generally, it could be applied to machine-learning and pattern-recognition tasks involving a relational database",
                    "title": "Random-Walk Computation of Similarities between Nodes of a Graph with Application to Collaborative Recommendation",
                    "venue": "IEEE Transactions on Knowledge and Data Engineering",
                    "year": 2007,
                    "__v": 2,
                    "citationCount": 349,
                    "result": 2.00995670995671
                },
                "ea8cd3d8-17ae-4a1e-8f83-1609469087af": {
                    "authors": [
                        "Andrew Y. Ng",
                        "Michael I. Jordan",
                        "Yair Weiss"
                    ],
                    "references": [
                        "52b8747c-6eef-43bc-8e11-aa3c4aae1111",
                        "5c89ee50-d7f5-4cd6-8eed-19a08efd6f90",
                        "75d0cdfa-44cd-4fc3-ae56-72e982cb383b",
                        "94898e1d-1e50-41ab-9dcc-2c2e030cddd0",
                        "98cfeac3-9abb-4f5b-9705-158c3b7b9d3a",
                        "d78003db-ad8a-48d2-be57-1c50e95cef72",
                        "fbb1d0f0-290f-490d-baab-63d29bc5f794"
                    ],
                    "keyword": [
                        "clustering",
                        "algorithms",
                        "spectral",
                        "eigenvectors",
                        "wide",
                        "variety",
                        "unresolved",
                        "tools",
                        "theory",
                        "surprisingly"
                    ],
                    "group": [],
                    "_id": "ea8cd3d8-17ae-4a1e-8f83-1609469087af",
                    "abstract": "Despite many empirical successes of spectral clustering methods— algorithms that cluster points using eigenvectors of matrices derived from the data—there are several unresolved issues. First. there are a wide variety of algorithms that use the eigenvectors in slightly different ways. Second, many of these algorithms have no proof that they will actually compute a reasonable clustering. In this paper, we present a simple spectral clustering algorithm that can be implemented using a few lines of Matlab. Using tools from matrix perturbation theory, we analyze the algorithm, and give conditions under which it can be expected to do well. We also show surprisingly good experimental results on a number of challenging clustering problems.",
                    "title": "On Spectral Clustering: Analysis and an algorithm",
                    "venue": "neural information processing systems",
                    "year": 2002,
                    "__v": 2,
                    "citationCount": 2537,
                    "result": 4.746825396825398
                },
                "f3b1b423-aa89-4484-b985-666ee01b06c4": {
                    "authors": [
                        "Susanne Still",
                        "William Bialek"
                    ],
                    "references": [
                        "15c30ca5-6af6-4acf-b8c5-f2c0e18e6ad8",
                        "43789c79-4510-4bea-9c74-5a15673789cf",
                        "44d7e2c1-7a65-4fb8-86e5-ea0bfdad98e9",
                        "56a80b9a-8712-4e47-b883-f0381aa9fb88",
                        "60f2a508-6947-4452-b875-eb2c057a9d32",
                        "70463312-9eca-4686-8e1d-34cd903b9cce"
                    ],
                    "keyword": [
                        "clustering",
                        "data",
                        "temperature",
                        "criterion",
                        "sets",
                        "optimal",
                        "number",
                        "determines"
                    ],
                    "group": [],
                    "_id": "f3b1b423-aa89-4484-b985-666ee01b06c4",
                    "abstract": "Clustering provides a common means of identifying structure in complex data, and there is renewed interest in clustering as a tool for the analysis of large data sets in many fields. A natural question is how many clusters are appropriate for the description of a given system. Traditional approaches to this problem are based on either a framework in which clusters of a particular shape are assumed as a model of the system or on a two-step procedure in which a clustering criterion determines the optimal assignments for a given number of clusters and a separate criterion measures the goodness of the classification to determine the number of clusters. In a statistical mechanics approach, clustering can be seen as a trade-off between energy- and entropy-like terms, with lower temperature driving the proliferation of clusters to provide a more detailed description of the data. For finite data sets, we expect that there is a limit to the meaningful structure that can be resolved and therefore a minimum temperature beyond which we will capture sampling noise. This suggests that correcting the clustering criterion for the bias that arises due to sampling errors will allow us to find a clustering solution at a temperature that is optimal in the sense that we capture maximal meaningful structure—without having to define an external criterion for the goodness or stability of the clustering. We show that in a general information-theoretic framework, the finite size of a data set determines an optimal temperature, and we introduce a method for finding the maximal number of clusters that can be resolved from the data in the hard clustering limit.",
                    "title": "How Many Clusters? An Information-Theoretic Perspective",
                    "venue": "Neural Computation",
                    "year": 2004,
                    "__v": 2,
                    "citationCount": 33,
                    "result": 3.211567105065557
                }
            }
        ],
        "_id": "7c90045b-63b9-4f29-82a0-bf7c914a6ef6",
        "abstract": "In recent years, spectral clustering has become one of the most popular modern clustering algorithms. It is simple to implement, can be solved efficiently by standard linear algebra software, and very often outperforms traditional clustering algorithms such as the k-means algorithm. On the first glance spectral clustering appears slightly mysterious, and it is not obvious to see why it works at all and what it really does. The goal of this tutorial is to give some intuition on those questions. We describe different graph Laplacians and their basic properties, present the most common spectral clustering algorithms, and derive those algorithms from scratch by several different approaches. Advantages and disadvantages of the different spectral clustering algorithms are discussed.",
        "title": "A tutorial on spectral clustering",
        "venue": "Statistics and Computing",
        "year": 2007,
        "__v": 1,
        "citationCount": 2009
    },
    {
        "authors": [
            "Zhou Wang",
            "Alan C. Bovik",
            "Hamid Rahim Sheikh",
            "Eero P. Simoncelli"
        ],
        "references": [
            "016e3dfb-350a-40c1-872f-ed1b8be4108a",
            "037d3257-c6f1-4ca7-8afe-7d788b23d2da",
            "0566c6b1-834f-44cb-900f-a2fd8f47f8cc",
            "1982b7ad-363d-4a4d-9673-3c431cd22b4d",
            "28b8d07b-a802-4e3a-9dfb-2735d0ef7dfb",
            "2b9cbced-5342-477e-b082-cf15a3be2934",
            "4392923d-3552-451b-8c14-663fa12d79dd",
            "58915db1-cde0-456c-9271-4e43b7efe153",
            "613fab48-0df5-4599-9fe5-48b481f98548",
            "65a38557-50dc-4f3c-bc41-f7bc45b63b54",
            "6bfa4f30-2a89-4ae2-bf1a-41ad952df5d8",
            "91d3815e-d707-4951-ba99-122f7e3b4fd5",
            "9489a56e-051b-4da3-8664-5c021debcc06",
            "9524aeae-f790-443a-a543-9fa47205b54e",
            "9b030b43-281f-42ca-aa9b-c625af825185",
            "9bd00024-b302-407e-92af-5d62759757bd",
            "9cd86bc3-7187-49e5-ab11-9dcd4c70b423",
            "9f542713-2bb2-4d2a-987f-5d3735422bdc",
            "a78c096f-3835-428e-9bbb-c8688f652e16",
            "ab99a18a-b0c2-4f86-91c4-d53f6ed4ebb1",
            "aecf8a08-eff7-4182-8bbb-a7b29de2f281",
            "b74101d6-0cfc-4298-a58d-71ff5d92ea9a",
            "d2275b1f-5443-4243-a1ed-c840ba187d87",
            "e09dd998-1039-4df0-9fe6-10cc77a41c77",
            "e30b7c7e-cbaa-48ce-9ee5-7a4c29b2a4ef",
            "f0563415-aadf-4013-b007-a75ce8db7714",
            "f1e7c5a5-779e-4899-8d9e-62d5127a1939",
            "f286c7c9-8d20-4f20-a0e0-341e76570ea0"
        ],
        "keyword": [
            "image",
            "structural",
            "visual",
            "quality",
            "objective",
            "methods",
            "information",
            "human",
            "assessing"
        ],
        "group": [
            {
                "016e3dfb-350a-40c1-872f-ed1b8be4108a": {
                    "authors": [
                        "Michael P. Eckert",
                        "Andrew P. Bradley"
                    ],
                    "references": [
                        "037d3257-c6f1-4ca7-8afe-7d788b23d2da",
                        "139cf2f3-19e0-489f-85b7-4881dcfff165",
                        "1982b7ad-363d-4a4d-9673-3c431cd22b4d",
                        "1d3cdad2-0c96-4693-a08c-f0f4d38647ea",
                        "1ef6b375-068c-4691-8a61-4d30dc39808d",
                        "23d0131f-4822-41e3-aed7-9701516c2e0a",
                        "28b8d07b-a802-4e3a-9dfb-2735d0ef7dfb",
                        "36800655-b2ff-4eb7-9070-c6be304c4baa",
                        "480a2c09-fdc6-4348-9b03-7a5170df834b",
                        "929213d2-97f1-4ef6-8c1b-253f67ad0b77",
                        "9bd00024-b302-407e-92af-5d62759757bd",
                        "a78c096f-3835-428e-9bbb-c8688f652e16",
                        "ab99a18a-b0c2-4f86-91c4-d53f6ed4ebb1",
                        "b0e448de-f181-4a33-ac19-ddd0e1eeeaba",
                        "b2b23a63-ad26-4cc6-bcd5-d5dc9104ce77",
                        "b74101d6-0cfc-4298-a58d-71ff5d92ea9a",
                        "d63564a1-6c85-4f2d-bb1f-45d17cec4bed",
                        "dfb9bc26-b116-4a6d-8acd-46aed7e02592",
                        "eb42fb1b-ebb9-4b7f-abd2-6ef09becd655",
                        "f1e7c5a5-779e-4899-8d9e-62d5127a1939",
                        "f42aad97-6be2-4c58-8e3b-2b6b4ded606c",
                        "f758f489-1bd9-405f-bb6b-9c6dc087e335",
                        "fad0058a-cf91-4f4e-859a-12d817db5d53"
                    ],
                    "keyword": [],
                    "group": [],
                    "_id": "016e3dfb-350a-40c1-872f-ed1b8be4108a",
                    "abstract": "We present a review of perceptual image quality metrics and their application to still image compression. The review describes how image quality metrics can be used to guide an image compression scheme and outlines the advantages, disadvantages and limitations of a number of quality metrics. We examine a broad range of metrics ranging from simple mathematical measures to those which incorporate full perceptual models. We highlight some variation in the models for luminance adaptation and the contrast sensitivity function and discuss what appears to be a lack of a general consensus regarding the models which best describe contrast masking and error summation. We identify how the various perceptual components have been incorporated in quality metrics, and identify a number of psychophysical testing techniques that can be used to validate the metrics. We conclude by illustrating some of the issues discussed throughout the paper with a simple demonstration. (C) 1998 Elsevier Science B.V. All rights reserved.",
                    "title": "Perceptual quality metrics applied to still image compression",
                    "venue": "Signal Processing",
                    "year": 1998,
                    "__v": 0,
                    "citationCount": 110,
                    "result": 2.8571428571428568
                },
                "58915db1-cde0-456c-9271-4e43b7efe153": {
                    "authors": [
                        "Wilfried M. Osberger",
                        "Neil W. Bergmann",
                        "Anthony J. Maeder"
                    ],
                    "references": [
                        "360ac50d-e048-4903-8cfb-720385a6bbc6",
                        "929213d2-97f1-4ef6-8c1b-253f67ad0b77",
                        "9fe09fc7-b007-477d-af0a-9f477e5bd25f",
                        "a2ca9333-af8b-4b08-bfef-6c553c24d31e",
                        "a55e6055-b73d-4083-baf8-42f34d77939a"
                    ],
                    "keyword": [
                        "technique",
                        "image",
                        "visual",
                        "regions",
                        "quality",
                        "model",
                        "importance"
                    ],
                    "group": [],
                    "_id": "58915db1-cde0-456c-9271-4e43b7efe153",
                    "abstract": "We present an objective image quality assessment technique which is based on the properties of the human visual system (HVS). It consists of two major components: an early vision model (multi-channel and designed specifically for complex natural images), and a visual attention model which indicates regions of interest in a scene through the use of importance maps. Visible errors are then weighted, depending on the perceptual importance of the region in which they occur. We show that this technique produces a high correlation with subjective test data (0.93), compared to only 0.65 for PSNR. This technique is particularly useful for images coded with spatially varying quality.",
                    "title": "An automatic image quality assessment technique incorporating higher level perceptual factors",
                    "venue": "international conference on image processing",
                    "year": 1998,
                    "__v": 2,
                    "citationCount": 30,
                    "result": 5.527132954764535
                },
                "613fab48-0df5-4599-9fe5-48b481f98548": {
                    "authors": [
                        "Robert W. Buccigrossi",
                        "Eero P. Simoncelli"
                    ],
                    "references": [
                        "011ac5b7-efca-4771-aca8-c16af5f31143",
                        "15b97643-1763-4c9b-bfd5-873f62e1ad88",
                        "28b8d07b-a802-4e3a-9dfb-2735d0ef7dfb",
                        "3d1f5985-fe85-4e7f-92bc-fae84c785cab",
                        "48ffef7f-9d41-47b6-9b00-6cdc419ad207",
                        "4dad08c6-fd3b-4615-9250-f62429ee65f8",
                        "59135305-4445-4506-8aad-52b0de9ca850",
                        "7ccbdf09-a84e-4ad2-ab20-cb28b6c41155",
                        "8304794c-3498-4d7d-9489-6fcd38678858",
                        "84752e4d-c2ad-478e-bb90-dfcf83889638",
                        "8a1ad048-c712-4f21-9dac-6fd6ffa545a9",
                        "8fcb253b-fbb7-46b5-8a8e-5a9b3d996d60",
                        "938b98e9-7c7e-4d9e-9d26-53f5f9c44c25",
                        "96efae45-7c42-4929-9212-6a61bc1d3d3e",
                        "a1c82a72-a282-44c4-baa8-d83d6da5af0b",
                        "aecf8a08-eff7-4182-8bbb-a7b29de2f281",
                        "b0e448de-f181-4a33-ac19-ddd0e1eeeaba",
                        "b55670f3-3025-457e-9bd8-06930a1b3e74",
                        "b8a86432-fff7-474e-9d72-046c5189e6dc",
                        "bb3c38fa-c2b0-4d4f-8c9d-ca1884343474",
                        "cb17c20e-e335-43dc-b2ae-350e43b74faa",
                        "d044e483-e074-443e-b437-ef8c5e167f5e"
                    ],
                    "keyword": [
                        "images",
                        "model",
                        "statistics",
                        "coder",
                        "wavelet",
                        "encoded",
                        "coefficients"
                    ],
                    "group": [],
                    "_id": "613fab48-0df5-4599-9fe5-48b481f98548",
                    "abstract": "We develop a probability model for natural images, based on empirical observation of their statistics in the wavelet transform domain. Pairs of wavelet coefficients, corresponding to basis functions at adjacent spatial locations, orientations, and scales, are found to be non-Gaussian in both their marginal and joint statistical properties. Specifically, their marginals are heavy-tailed, and although they are typically decorrelated, their magnitudes are highly correlated. We propose a Markov model that explains these dependencies using a linear predictor for magnitude coupled with both multiplicative and additive uncertainties, and show that it accounts for the statistics of a wide variety of images including photographic images, graphical images, and medical images. In order to directly demonstrate the power of the model, we construct an image coder called EPWIC (embedded predictive wavelet image coder), in which subband coefficients are encoded one bitplane at a time using a nonadaptive arithmetic encoder that utilizes conditional probabilities calculated from the model. Bitplanes are ordered using a greedy algorithm that considers the MSE reduction per encoded bit. The decoder uses the statistical model to predict coefficient values based on the bits it has received. Despite the simplicity of the model, the rate-distortion performance of the coder is roughly comparable to the best image coders in the literature.",
                    "title": "Image compression via joint statistical characterization in the wavelet domain",
                    "venue": "IEEE Transactions on Image Processing",
                    "year": 1999,
                    "__v": 2,
                    "citationCount": 220,
                    "result": 3.570908417348045
                },
                "65a38557-50dc-4f3c-bc41-f7bc45b63b54": {
                    "authors": [
                        "Andrew B. Watson",
                        "James Hu",
                        "John F. McGowan"
                    ],
                    "references": [
                        "0344d79c-293e-4057-a6d7-add77cf867e8",
                        "15cbca1c-c139-4f62-8eab-587173dc4a3c",
                        "4c6d35b2-d342-4d8b-ad0f-4fbb00e120c5",
                        "a78c096f-3835-428e-9bbb-c8688f652e16"
                    ],
                    "keyword": [
                        "digital",
                        "video",
                        "quality",
                        "metric",
                        "visual"
                    ],
                    "group": [],
                    "_id": "65a38557-50dc-4f3c-bc41-f7bc45b63b54",
                    "abstract": "The growth of digital video has given rise to a need for computational methods for evaluating the visual quality of digital video. We have developed a new digital video quality metric, which we call DVQ (digital video quality) (A. B. Watson, in Human Vision, Visual Processing, and Digital Display VIII, Proc. SPIE 3299, 139- 147 (1998)). Here, we provide a brief description of the metric, and give a preliminary report on its performance. DVQ accepts a pair of digital video sequences, and computes a measure of the magnitude of the visible difference between them. The metric is based on the discrete cosine transform. It incorporates aspects of early visual pro- cessing, including light adaptation, luminance, and chromatic chan- nels; spatial and temporal filtering; spatial frequency channels; con- trast masking; and probability summation. It also includes primitive dynamics of light adaptation and contrast masking. We have applied the metric to digital video sequences corrupted by various typical compression artifacts, and compared the results to quality ratings made by human observers. © 2001 SPIE and IS&T. (DOI: 10.1117/1.1329896)",
                    "title": "Digital video quality metric based on human vision",
                    "venue": "Journal of Electronic Imaging",
                    "year": 2001,
                    "__v": 1,
                    "citationCount": 149,
                    "result": 4.737806637806638
                },
                "6bfa4f30-2a89-4ae2-bf1a-41ad952df5d8": {
                    "authors": [
                        "Stefan Winkler"
                    ],
                    "references": [
                        "0344d79c-293e-4057-a6d7-add77cf867e8",
                        "08d5c9dc-f83c-4052-9da2-0078c7c78693",
                        "0d8c8167-71b9-4698-906c-4db64a2bea5f",
                        "157e9481-2933-451d-aeb0-55861dd9d2cf",
                        "1982b7ad-363d-4a4d-9673-3c431cd22b4d",
                        "282bc861-04b0-461f-ba09-5bc0d4f26b0f",
                        "28b8d07b-a802-4e3a-9dfb-2735d0ef7dfb",
                        "2f76d037-8da2-42e3-a17e-7ed7bb08971c",
                        "4c6d35b2-d342-4d8b-ad0f-4fbb00e120c5",
                        "51778ef2-b1be-4980-98cd-475cf7b923bf",
                        "5cc4d85a-0fac-4899-89e4-9a4b54dd4ebe",
                        "64c6d531-1b6d-4b23-851a-b5f5249c6130",
                        "73ec2ba4-ee66-45bf-9b57-9ed3cdf10896",
                        "828b1b47-de4d-4d98-ad96-c699df5b28ca",
                        "83d0bb55-8a45-4321-be3a-7d3014349c7f",
                        "8c18452c-5351-45ad-85ee-1109df55812c",
                        "929213d2-97f1-4ef6-8c1b-253f67ad0b77",
                        "9cd86bc3-7187-49e5-ab11-9dcd4c70b423",
                        "a55e6055-b73d-4083-baf8-42f34d77939a",
                        "cc6e40f7-236a-4a72-a107-0be5bcd2158e",
                        "d52c796e-3dcf-4d40-baf4-77bf5367de71",
                        "e6f0aa1f-2eff-42fb-bee8-4a56a4ea0eff",
                        "eeded0fa-fbb8-4ee1-a8a7-1d2dcc7c04b2",
                        "f1e7c5a5-779e-4899-8d9e-62d5127a1939"
                    ],
                    "keyword": [
                        "systems",
                        "modeling",
                        "vision",
                        "video",
                        "quality",
                        "pvqa",
                        "important",
                        "characteristics",
                        "assessment"
                    ],
                    "group": [],
                    "_id": "6bfa4f30-2a89-4ae2-bf1a-41ad952df5d8",
                    "abstract": "Lossy compression algorithms used in digital video systems produce artifacts whose visibility strongly depends on the actual image content. Simple error measures such as RMSE or PSNR, albeit popular, ignore this important fact and are only a mediocre predictor of perceived quality. Many applications require more reliable assessment methods. This paper discusses issues in vision modeling for perceptual video quality assessment (PVQA). Its purpose is not to describe a particular model or system, but rather to summarize and to provide pointers to up-to-date knowledge of important characteristics of the human visual system, to explain how these characteristics may be incorporated in vision models for PVQA, to give a brief overview of the state-of-the-art and current efforts in this field, and to outline directions for future research. Verlustbehaftete Kompressionsalgorithmen, wie sie in digitalen Video-Systemen verwendet werden, erzeugen Artefakte, deren Sichtbarkeit stark vom Bildinhalt ab",
                    "title": "Issues in vision modeling for perceptual video quality assessment",
                    "venue": "Signal Processing",
                    "year": 1999,
                    "__v": 1,
                    "citationCount": 85,
                    "result": 6.590912844951074
                },
                "91d3815e-d707-4951-ba99-122f7e3b4fd5": {
                    "authors": [
                        "Juan Liu",
                        "Pierre Moulin"
                    ],
                    "references": [
                        "1e9dc3ef-4c20-47b9-8277-efd5b895183d",
                        "236a47f2-fa62-410d-bc68-d821d67f060a",
                        "333679c2-26ec-4914-9b1c-deec7da8a90f",
                        "3d1f5985-fe85-4e7f-92bc-fae84c785cab",
                        "4f335df3-3e1c-4509-8d1f-37150da1cbca",
                        "5140e52c-4efc-496c-8607-ec6a1b5b1c2a",
                        "613fab48-0df5-4599-9fe5-48b481f98548",
                        "6999cd75-fd74-491e-997b-b76dc1006f46",
                        "834863b2-34f0-40dc-b4d2-f4189eaa262a",
                        "97571808-28e5-400a-8793-5ca824c4fc6e",
                        "97e7a68e-3d23-4fe8-a44f-b599128715b6",
                        "9bd00024-b302-407e-92af-5d62759757bd",
                        "9dcad8a1-64d8-4718-8234-0b99d8fddab8",
                        "ad8cac50-5df3-4c77-8f94-9a6de5a8aef8",
                        "aecf8a08-eff7-4182-8bbb-a7b29de2f281",
                        "b55670f3-3025-457e-9bd8-06930a1b3e74",
                        "baf3fa1c-8f80-45cb-940b-1e3653b7f806",
                        "bd327c12-eb08-4536-a68b-1d8bbcd7b146",
                        "c57b917f-17cf-41b0-8267-07d2bb18697d",
                        "ca40fe4e-f587-49df-b456-c16cf6d14f83",
                        "d044e483-e074-443e-b437-ef8c5e167f5e",
                        "dc5ed054-0c63-473e-9996-3c91daeca369",
                        "eddcd955-643f-43d2-93f1-54e6ba91f568",
                        "edeef22a-7bcd-4a2d-8dc2-8fffdbcb5903",
                        "f570315c-f69c-4406-862e-56f80fc9aa9f",
                        "f70cfd7a-c3d6-4438-acef-662081c1b333"
                    ],
                    "keyword": [
                        "image",
                        "dependencies",
                        "statistical",
                        "performance",
                        "mutual",
                        "information",
                        "wavelet",
                        "observations",
                        "models",
                        "estimation"
                    ],
                    "group": [],
                    "_id": "91d3815e-d707-4951-ba99-122f7e3b4fd5",
                    "abstract": "This paper presents an information-theoretic analysis of statistical dependencies between image wavelet coefficients. The dependencies are measured using mutual information, which has a fundamental relationship to data compression, estimation, and classification performance. Mutual information is computed analytically for several statistical image models, and depends strongly on the choice of wavelet filters. In the absence of an explicit statistical model, a method is studied for reliably estimating mutual information from image data. The validity of the model-based and data-driven approaches is assessed on representative real-world photographic images. Our results are consistent with empirical observations that coding schemes exploiting inter- and intrascale dependencies alone perform very well, whereas taking both into account does not significantly improve coding performance. A similar observation applies to other image processing applications.",
                    "title": "Information-theoretic analysis of interscale and intrascale dependencies between image wavelet coefficients",
                    "venue": "IEEE Transactions on Image Processing",
                    "year": 2001,
                    "__v": 2,
                    "citationCount": 128,
                    "result": 9.391054877355188
                },
                "9524aeae-f790-443a-a543-9fa47205b54e": {
                    "authors": [
                        "Claudio M. Privitera",
                        "Lawrence Stark"
                    ],
                    "references": [
                        "04f6cbb5-4324-4f96-9e20-ab8a960dfc59",
                        "406b9bdc-19b0-4755-8781-b92cb7a1b7f3",
                        "49bd4101-61ea-4005-9522-17c237a8baf7",
                        "61f782a0-293a-4e9c-8b56-9cb74b3b3893",
                        "64c0face-e620-4ea2-917a-2dff6e6d850d",
                        "6d121e97-e351-4cf9-8c44-d7ab3ce9d9fe",
                        "9123f881-f505-468c-8673-d0c5450d5dc3",
                        "929ace7d-dbf0-4278-83f9-e3b0a34e1a46",
                        "c9a04aad-4a2e-429f-b541-b7ba865d416f",
                        "ff787607-78be-4d58-84d8-04033b0ca54f"
                    ],
                    "keyword": [
                        "sequences",
                        "rois",
                        "image",
                        "algorithmically",
                        "subset",
                        "methodology",
                        "identify",
                        "human",
                        "hrois",
                        "arois"
                    ],
                    "group": [],
                    "_id": "9524aeae-f790-443a-a543-9fa47205b54e",
                    "abstract": "Many machine vision applications, such as compression, pictorial database querying, and image understanding, often need to analyze in detail only a representative subset of the image, which may be arranged into sequences of loci called regions-of-interest (ROIs). We have investigated and developed a methodology that serves to automatically identify such a subset of aROIs (algorithmically detected ROIs) using different image processing algorithms (IPAs), and appropriate clustering procedures. In human perception, an internal representation directs top-down, context-dependent sequences of eye movements to fixate on similar sequences of hROIs (human identified ROIs). In the paper, we introduce our methodology and we compare aROIs with hROIs as a criterion for evaluating and selecting bottom-up, context-free algorithms. An application is finally discussed.",
                    "title": "Algorithms for defining visual regions-of-interest: comparison with eye fixations",
                    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "year": 2000,
                    "__v": 2,
                    "citationCount": 244,
                    "result": 5.860213613804272
                },
                "9b030b43-281f-42ca-aa9b-c625af825185": {
                    "authors": [
                        "Zhou Wang",
                        "Alan C. Bovik"
                    ],
                    "references": [
                        "02ad2ee4-f101-4df0-b2cf-9e9a4cc29904",
                        "0d3ab957-2162-40cc-ad73-433b081a8099",
                        "26df4bb5-0596-4725-96e0-5cae9e3a9de9",
                        "380ee98a-c203-4017-93be-facc127989f5",
                        "4729a1b8-b9bf-496e-a642-d9f0ef4bcae5",
                        "9524aeae-f790-443a-a543-9fa47205b54e",
                        "9bd00024-b302-407e-92af-5d62759757bd",
                        "a2ca9333-af8b-4b08-bfef-6c553c24d31e",
                        "a6702d98-8961-4aef-a09c-9a8bf23bb7ab",
                        "a78c096f-3835-428e-9bbb-c8688f652e16",
                        "a980d215-6c62-4c1e-8f1c-ea78ad66b83e",
                        "aecf8a08-eff7-4182-8bbb-a7b29de2f281",
                        "b0e448de-f181-4a33-ac19-ddd0e1eeeaba",
                        "b74101d6-0cfc-4298-a58d-71ff5d92ea9a",
                        "bd21a55f-7854-4e67-889d-61e3c7b9842e",
                        "c0be4d67-bf26-45a0-a056-483b4c3dc82f",
                        "d0059d86-9e2d-48cb-b116-cfec0b24d5fb",
                        "ee3fa7f4-a88d-4b58-8ee8-843370ed51be",
                        "f1b87c3e-d079-41bb-b788-6af5f1af2eb2",
                        "f286c7c9-8d20-4f20-a0e0-341e76570ea0",
                        "f9966ac4-728f-4864-8644-9d4aa0d6c311"
                    ],
                    "keyword": [
                        "image",
                        "foveation",
                        "coding",
                        "quality",
                        "wavelet",
                        "good",
                        "embedded",
                        "algorithms",
                        "point",
                        "efic"
                    ],
                    "group": [],
                    "_id": "9b030b43-281f-42ca-aa9b-c625af825185",
                    "abstract": "The human visual system (HVS) is highly space-variant in sampling, coding, processing, and understanding. The spatial resolution of the HVS is highest around the point of fixation (foveation point) and decreases rapidly with increasing eccentricity. By taking advantage of this fact, it is possible to remove considerable high-frequency information redundancy from the peripheral regions and still reconstruct a perceptually good quality image. Great success has been obtained previously by a class of embedded wavelet image coding algorithms, such as the embedded zerotree wavelet (EZW) and the set partitioning in hierarchical trees (SPIHT) algorithms. Embedded wavelet coding not only provides very good compression performance, but also has the property that the bitstream can be truncated at any point and still be decoded to recreate a reasonably good quality image. In this paper, we propose an embedded foveation image coding (EFIC) algorithm, which orders the encoded bitstream to optimize foveated visual quality at arbitrary bit-rates. A foveation-based image quality metric, namely, foveated wavelet image quality index (FWQI), plays an important role in the EFIC system. We also developed a modified SPIHT algorithm to improve the coding efficiency. Experiments show that EFIC integrates foveation filtering with foveated image coding and demonstrates very good coding performance and scalability in terms of foveated image quality measurement.",
                    "title": "Embedded foveation image coding",
                    "venue": "IEEE Transactions on Image Processing",
                    "year": 2001,
                    "__v": 2,
                    "citationCount": 91,
                    "result": 8.061584614216194
                },
                "9bd00024-b302-407e-92af-5d62759757bd": {
                    "authors": [
                        "Amir Said",
                        "William A. Pearlman"
                    ],
                    "references": [
                        "010951bc-22ff-4d96-811f-d64d20435465",
                        "48ffef7f-9d41-47b6-9b00-6cdc419ad207",
                        "49b0508a-feaf-4799-bc92-1b63f67bfeff",
                        "678f1bf9-947c-4a8c-8fe2-4b81e22edeb5",
                        "8eaaee11-fdcc-479e-adcf-9ef720a18cbf",
                        "8fef809b-f2e7-4828-91f4-e9ceb6b71e8b",
                        "aecf8a08-eff7-4182-8bbb-a7b29de2f281",
                        "b0e448de-f181-4a33-ac19-ddd0e1eeeaba",
                        "eb42fb1b-ebb9-4b7f-abd2-6ef09becd655",
                        "fd9761a2-c929-4912-b36c-6954ac9cb60b"
                    ],
                    "keyword": [
                        "coding",
                        "performance",
                        "image",
                        "ezw"
                    ],
                    "group": [],
                    "_id": "9bd00024-b302-407e-92af-5d62759757bd",
                    "abstract": "Embedded zerotree wavelet (EZW) coding, introduced by Shapiro (see IEEE Trans. Signal Processing, vol.41, no.12, p.3445, 1993), is a very effective and computationally simple technique for image compression. We offer an alternative explanation of the principles of its operation, so that the reasons for its excellent performance can be better understood. These principles are partial ordering by magnitude with a set partitioning sorting algorithm, ordered bit plane transmission, and exploitation of self-similarity across different scales of an image wavelet transform. Moreover, we present a new and different implementation based on set partitioning in hierarchical trees (SPIHT), which provides even better performance than our previously reported extension of EZW that surpassed the performance of the original EZW. The image coding results, calculated from actual file sizes and images reconstructed by the decoding algorithm, are either comparable to or surpass previous results obtained through much more sophisticated and computationally complex methods. In addition, the new coding and decoding procedures are extremely fast, and they can be made even faster, with only small loss in performance, by omitting entropy coding of the bit stream by the arithmetic code.",
                    "title": "A new, fast, and efficient image codec based on set partitioning in hierarchical trees",
                    "venue": "IEEE Transactions on Circuits and Systems for Video Technology",
                    "year": 1996,
                    "__v": 1,
                    "citationCount": 2084,
                    "result": 3.2014152514152516
                },
                "9f542713-2bb2-4d2a-987f-5d3735422bdc": {
                    "authors": [
                        "Andrew B. Watson"
                    ],
                    "references": [],
                    "keyword": [
                        "tailored",
                        "solutions",
                        "selectability",
                        "quantization",
                        "quality",
                        "problems",
                        "pooling",
                        "perceptual",
                        "method",
                        "matrix"
                    ],
                    "group": [],
                    "_id": "9f542713-2bb2-4d2a-987f-5d3735422bdc",
                    "abstract": "A custom quantization matrix tailored to a particular image is designed by an image-dependent perceptual method incorporating solutions to the problems of luminance and contrast masking, error pooling and quality selectability. >",
                    "title": "Visually optimal DCT quantization matrices for individual images",
                    "venue": "data compression conference",
                    "year": 1993,
                    "__v": 2,
                    "citationCount": 121,
                    "result": 7.029741130902121
                },
                "a78c096f-3835-428e-9bbb-c8688f652e16": {
                    "authors": [
                        "Andrew B. Watson",
                        "Gloria Y. Yang",
                        "Joshua A. Solomon",
                        "John D. Villasenor"
                    ],
                    "references": [
                        "15cbca1c-c139-4f62-8eab-587173dc4a3c",
                        "938b98e9-7c7e-4d9e-9d26-53f5f9c44c25",
                        "9f542713-2bb2-4d2a-987f-5d3735422bdc",
                        "a980d215-6c62-4c1e-8f1c-ea78ad66b83e",
                        "ad176fe8-d0db-4c2c-8bf6-7d56de7f45f4",
                        "b0e448de-f181-4a33-ac19-ddd0e1eeeaba",
                        "b27e99cb-56f1-48ba-86c4-aa88037ab730",
                        "d63564a1-6c85-4f2d-bb1f-45d17cec4bed",
                        "ee3fa7f4-a88d-4b58-8ee8-843370ed51be",
                        "fad0058a-cf91-4f4e-859a-12d817db5d53"
                    ],
                    "keyword": [
                        "quantization",
                        "dwt",
                        "thresholds",
                        "wavelet",
                        "visual",
                        "uniform",
                        "spatial",
                        "orientation",
                        "noise",
                        "frequency"
                    ],
                    "group": [],
                    "_id": "a78c096f-3835-428e-9bbb-c8688f652e16",
                    "abstract": "The discrete wavelet transform (DWT) decomposes an image into bands that vary in spatial frequency and orientation. It is widely used for image compression, measures of the visibility of DWT quantization errors are required to achieve optimal compression. Uniform quantization of a single band of coefficients results in an artifact that we call DWT uniform quantization noise; it is the sum of a lattice of random amplitude basis functions of the corresponding DWT synthesis filter. We measured visual detection thresholds for samples of DWT uniform quantization noise in Y, Cb, and Cr color channels. The spatial frequency of a wavelet is r2/sup -/spl lambda//, where r is the display visual resolution in pixels/degree, and /spl lambda/ is the wavelet level. Thresholds increase rapidly with wavelet spatial frequency. Thresholds also increase from Y to Cr to Cb, and with orientation from lowpass to horizontal/vertical to diagonal. We construct a mathematical model for DWT noise detection thresholds that is a function of level, orientation, and display visual resolution. This allows calculation of a \"perceptually lossless\" quantization matrix for which all errors are in theory below the visual threshold. The model may also be used as the basis for adaptive quantization schemes.",
                    "title": "Visibility of wavelet quantization noise",
                    "venue": "IEEE Transactions on Image Processing",
                    "year": 1997,
                    "__v": 2,
                    "citationCount": 255,
                    "result": 6.063182689343679
                },
                "aecf8a08-eff7-4182-8bbb-a7b29de2f281": {
                    "authors": [
                        "Jerome M. Shapiro"
                    ],
                    "references": [
                        "011ac5b7-efca-4771-aca8-c16af5f31143",
                        "3f0bc2c9-a5c2-4e4c-a4e9-7631e36bc6a3",
                        "7ccbdf09-a84e-4ad2-ab20-cb28b6c41155",
                        "87624da4-289a-4c42-92a0-c239a103b029",
                        "8d611b4b-5120-494f-b5bd-d234be570072",
                        "8eaaee11-fdcc-479e-adcf-9ef720a18cbf",
                        "a6656b9e-ac90-42eb-8b65-9bd78b66f1f2",
                        "b9c3ab48-c632-4ec2-9e03-72c00b2d21ed",
                        "cb17c20e-e335-43dc-b2ae-350e43b74faa",
                        "d846cbd5-1ce3-40c0-b528-3669185e3c6c",
                        "eb42fb1b-ebb9-4b7f-abd2-6ef09becd655",
                        "ee3fa7f4-a88d-4b58-8ee8-843370ed51be",
                        "fd9761a2-c929-4912-b36c-6954ac9cb60b",
                        "ffe19a00-434e-4208-b764-27ce16f1b83e"
                    ],
                    "keyword": [
                        "image",
                        "bits",
                        "stream",
                        "embedded",
                        "algorithm",
                        "compression",
                        "code",
                        "produce",
                        "ezw",
                        "encoder"
                    ],
                    "group": [],
                    "_id": "aecf8a08-eff7-4182-8bbb-a7b29de2f281",
                    "abstract": "The embedded zerotree wavelet algorithm (EZW) is a simple, yet remarkably effective, image compression algorithm, having the property that the bits in the bit stream are generated in order of importance, yielding a fully embedded code. The embedded code represents a sequence of binary decisions that distinguish an image from the \"null\" image. Using an embedded coding algorithm, an encoder can terminate the encoding at any point thereby allowing a target rate or target distortion metric to be met exactly. Also, given a bit stream, the decoder can cease decoding at any point in the bit stream and still produce exactly the same image that would have been encoded at the bit rate corresponding to the truncated bit stream. In addition to producing a fully embedded bit stream, the EZW consistently produces compression results that are competitive with virtually all known compression algorithms on standard test images. Yet this performance is achieved with a technique that requires absolutely no training, no pre-stored tables or codebooks, and requires no prior knowledge of the image source. The EZW algorithm is based on four key concepts: (1) a discrete wavelet transform or hierarchical subband decomposition, (2) prediction of the absence of significant information across scales by exploiting the self-similarity inherent in images, (3) entropy-coded successive-approximation quantization, and (4) universal lossless data compression which is achieved via adaptive arithmetic coding. >",
                    "title": "Embedded image coding using zerotrees of wavelet coefficients",
                    "venue": "IEEE Transactions on Signal Processing",
                    "year": 1993,
                    "__v": 1,
                    "citationCount": 1846,
                    "result": 3.9341916253680957
                },
                "b74101d6-0cfc-4298-a58d-71ff5d92ea9a": {
                    "authors": [
                        "Andrew P. Bradley"
                    ],
                    "references": [
                        "0d7a4be0-8cb4-42be-972d-3f072f288449",
                        "23d0131f-4822-41e3-aed7-9701516c2e0a",
                        "28b8d07b-a802-4e3a-9dfb-2735d0ef7dfb",
                        "68d7e284-ada9-4660-a137-cd79d21ca486",
                        "7c803f70-1b85-491e-b621-93a832a1c15c",
                        "929213d2-97f1-4ef6-8c1b-253f67ad0b77",
                        "9bd00024-b302-407e-92af-5d62759757bd",
                        "9f542713-2bb2-4d2a-987f-5d3735422bdc",
                        "a78c096f-3835-428e-9bbb-c8688f652e16",
                        "aecf8a08-eff7-4182-8bbb-a7b29de2f281",
                        "b0e448de-f181-4a33-ac19-ddd0e1eeeaba",
                        "b2b23a63-ad26-4cc6-bcd5-d5dc9104ce77",
                        "d63564a1-6c85-4f2d-bb1f-45d17cec4bed",
                        "dfb9bc26-b116-4a6d-8acd-46aed7e02592",
                        "eb42fb1b-ebb9-4b7f-abd2-6ef09becd655",
                        "f1e7c5a5-779e-4899-8d9e-62d5127a1939",
                        "fad0058a-cf91-4f4e-859a-12d817db5d53"
                    ],
                    "keyword": [
                        "wavelet",
                        "transform",
                        "model",
                        "wvdp",
                        "image",
                        "based",
                        "visibility",
                        "sensitivity",
                        "hvs"
                    ],
                    "group": [],
                    "_id": "b74101d6-0cfc-4298-a58d-71ff5d92ea9a",
                    "abstract": "We describe a model of the human visual system (HVS) based on the wavelet transform. This model is largely based on a previously proposed model, but has a number of modifications that make it more amenable to potential integration into a wavelet based image compression scheme. These modifications include the use of a separable wavelet transform instead of the cortex transform, the application of a wavelet contrast sensitivity function (CSF), and a simplified definition of subband contrast that allows one to predict the noise visibility directly from the wavelet coefficients. Initially, we outline the luminance, frequency, and masking sensitivities of the HVS and discuss how these can be incorporated into the wavelet transform. We then outline a number of limitations of the wavelet transform as a model of the HVS, namely the lack of translational invariance and poor orientation sensitivity. In order to investigate the efficacy of this wavelet based model, a wavelet visible difference predictor (WVDP) is described. The WVDP is then used to predict visible differences between an original and compressed (or noisy) image. Results are presented to emphasize the limitations of commonly used measures of image quality and to demonstrate the performance of the WVDP. The paper concludes with suggestions on how the WVDP can be used to determine a visually optimal quantization strategy for wavelet coefficients and produce a quantitative measure of image quality.",
                    "title": "A wavelet visible difference predictor",
                    "venue": "IEEE Transactions on Image Processing",
                    "year": 1999,
                    "__v": 2,
                    "citationCount": 77,
                    "result": 6.845004668534079
                },
                "d2275b1f-5443-4243-a1ed-c840ba187d87": {
                    "authors": [
                        "Zhou Wang",
                        "Alan C. Bovik",
                        "Ligang Lu"
                    ],
                    "references": [
                        "65a38557-50dc-4f3c-bc41-f7bc45b63b54",
                        "a78c096f-3835-428e-9bbb-c8688f652e16"
                    ],
                    "keyword": [
                        "image",
                        "quality",
                        "assessment",
                        "structural",
                        "philosophy",
                        "perceived",
                        "metrics",
                        "measurement",
                        "human",
                        "distortion"
                    ],
                    "group": [],
                    "_id": "d2275b1f-5443-4243-a1ed-c840ba187d87",
                    "abstract": "Image quality assessment plays an important role in various image processing applications. A great deal of effort has been made in recent years to develop objective image quality metrics that correlate with perceived quality measurement. Unfortunately, only limited success has been achieved. In this paper, we provide some insights on why image quality assessment is so difficult by pointing out the weaknesses of the error sensitivity based framework, which has been used by most image quality assessment approaches in the literature. Furthermore, we propose a new philosophy in designing image quality metrics: The main function of the human eyes is to extract structural information from the viewing field, and the human visual system is highly adapted for this purpose. Therefore, a measurement of structural distortion should be a good approximation of perceived image distortion. Based on the new philosophy, we implemented a simple but effective image quality indexing algorithm, which is very promising as shown by our current results.",
                    "title": "Why is image quality assessment so difficult",
                    "venue": "international conference on acoustics, speech, and signal processing",
                    "year": 2002,
                    "__v": 2,
                    "citationCount": 187,
                    "result": 9.096418072811261
                },
                "e09dd998-1039-4df0-9fe6-10cc77a41c77": {
                    "authors": [
                        "Andrew Watson",
                        "Lindsay Kreslake"
                    ],
                    "references": [
                        "30e2ec0f-0306-4a0a-9a23-d2f67e5f0cf9",
                        "65a38557-50dc-4f3c-bc41-f7bc45b63b54",
                        "fc66ed84-6be2-4ebf-8fde-a2859c14888d"
                    ],
                    "keyword": [
                        "measurement",
                        "video",
                        "scale",
                        "method",
                        "impairment",
                        "quality",
                        "jnd",
                        "artifact"
                    ],
                    "group": [],
                    "_id": "e09dd998-1039-4df0-9fe6-10cc77a41c77",
                    "abstract": "The study of subjective visual quality, and the development of computed quality metrics, require accurate and meaningful measurement of visual impairment. A natural unit for impairment is the JND (just-noticeable-difference). In many cases, what is required is a measure of an impairment scale, that is, the growth of the subjective impairment, in JNDs, as some physical parameter (such as amount of artifact) is increased. Measurement of sensory scales is a classical problem in psychophysics. In the method of pair comparison, each trial consists of a pair of samples and the observer selects the one perceived to be greater on the relevant scale. This may be regarded as an extension of the method of forced-choice: from measurement of threshold (one JND), to measurement of the larger sensory scale (multiple JNDs). While simple for the observer, pair comparison is inefficient because if all samples are compared, many comparisons will be uninformative. In general, samples separated by about 1 JND are most informative. We have developed an efficient adaptive method for selection of sample pairs. As with the QUEST adaptive threshold procedure[1], the method is based on Bayesian estimation of the sensory scale after each trial. We call the method Efficient Adaptive Scale Estimation, or EASE (\"to make less painful\"). We have used the EASE method to measure impairment scales for digital video. Each video was derived from an original source (SRC) by the addition of a particular artifact, produced by a particular codec at a specific bit rate, called a hypothetical reference circuit (HRC). Different amounts of artifact were produced by linear combination of the source and compressed videos. On each pair-comparison trial the observer selected which of two sequences, containing different amounts of artifact, appeared more impaired. The scale is estimated from the pair comparison data using a maximum likelihood method. At the top of the scale, when all of the artifact is present, the scale value is the total number of JNDs corresponding to that SRC/HRC condition. We have measured impairment scales for 25 video sequences, derived from five SRCs combined with each of five HRCs. We find that EASE is a reliable method for measuring impairment scales and JNDs for processed video sequences. We have compared our JND measurements with mean opinion scores for the same sequences obtained at one viewing distance using the DSCQS method by the Video Quality Experts Group (VQEG), and we find that the two measures are highly correlated. The advantages of the JND measurements are that they are in absolute and meaningful units and are unlikely to be subject to context effects. We note that JND measurements offer a means of creating calibrated artifact samples, and of testing and calibrating video quality models. 1. BACKGROUND 1.1. Need for accurate subjective measures of video quality The design and use of digital video systems entail difficult tradeoffs amongst various quantities, of which the two most important are cost and visual quality. While there is no difficulty in measuring cost, beauty remains locked in the eye of the beholder. However in recent years a number of computational metrics have been developed which purport to measure video quality or video impairment. Metrics of this sort would be very valuable in providing a means for automatically specifying, monitoring, and optimizing the visual quality of digital video.",
                    "title": "Measurement of visual impairment scales for digital video",
                    "venue": "Proceedings of SPIE",
                    "year": 2001,
                    "__v": 2,
                    "citationCount": 1,
                    "result": 4.937958034397663
                },
                "f1e7c5a5-779e-4899-8d9e-62d5127a1939": {
                    "authors": [
                        "James L. Mannos",
                        "David J. Sakrison"
                    ],
                    "references": [
                        "7198e37b-5f59-413d-b810-9516b77224d9",
                        "a8a782b1-28be-43b0-99b4-8d5f471d74a7",
                        "d6d1ea99-7f44-4d93-a9fc-49302653ccb8"
                    ],
                    "keyword": [
                        "measure",
                        "distortion",
                        "rate",
                        "images",
                        "subjective",
                        "simulate",
                        "ratedistortion",
                        "performance",
                        "observer",
                        "investigate"
                    ],
                    "group": [],
                    "_id": "f1e7c5a5-779e-4899-8d9e-62d5127a1939",
                    "abstract": "Shannon's rate-distortion function provides a potentially useful lower bound against which to compare the rate-versus-distortion performance of practical encoding-transmission systems. However, this bound is not applicable unless one can arrive at a numerically-valued measure of distortion which is in reasonable correspondence with the subjective evaluation of the observer or interpreter. We have attempted to investigate this choice of distortion measure for monochrome still images. This investigation has considered a class of distortion measures for which it is possible to simulate the optimum (in a rate-distortion sense) encoding. Such simulation was performed at a fixed rate for various measures in the class and the results compared subjectively by observers. For several choices of transmission rate and original images, one distortion measure was fairly consistently rated as yielding the most satisfactory appearing encoded images.",
                    "title": "The effects of a visual fidelity criterion of the encoding of images",
                    "venue": "IEEE Transactions on Information Theory",
                    "year": 1974,
                    "__v": 2,
                    "citationCount": 362,
                    "result": 7.652935113225868
                },
                "f286c7c9-8d20-4f20-a0e0-341e76570ea0": {
                    "authors": [
                        "Yung-Kai Lai",
                        "C.-C. Jay Kuo"
                    ],
                    "references": [
                        "08d5c9dc-f83c-4052-9da2-0078c7c78693",
                        "3289d5cc-3430-4211-9c70-652c4d94706a",
                        "84752e4d-c2ad-478e-bb90-dfcf83889638",
                        "9e4c57e0-a064-49f1-8595-d188b60c28ca",
                        "d52c796e-3dcf-4d40-baf4-77bf5367de71",
                        "f42aad97-6be2-4c58-8e3b-2b6b4ded606c"
                    ],
                    "keyword": [
                        "human",
                        "wavelet",
                        "visual",
                        "subjective",
                        "model",
                        "measures",
                        "hvs",
                        "haar"
                    ],
                    "group": [],
                    "_id": "f286c7c9-8d20-4f20-a0e0-341e76570ea0",
                    "abstract": "The traditional mean-squared-error and peak-signal-to-noise-ratio error measures are mainly focused on the pixel-by-pixel difference between the original and compressed images. Such metrics are improper for subjective quality assessment, since human perception is very sensitive to specific correlations between adjacent pixels. In this work, we explore the Haar wavelet to model the space?frequency localization property of human visual system (HVS) responses. It is shown that the physical contrast in different resolutions can be easily represented in terms of wavelet coefficients. By analyzing and modeling several visual mechanisms of the HVS with the Haar transform, we develop a new subjective fidelity measure which is more consistent with human observation experience.",
                    "title": "A Haar Wavelet Approach to Compressed Image Quality Measurement",
                    "venue": "Journal of Visual Communication and Image Representation",
                    "year": 2000,
                    "__v": 2,
                    "citationCount": 31,
                    "result": 5.303814769681642
                }
            }
        ],
        "_id": "7f1214b2-e070-4ff2-a5d3-647e7c16c2d7",
        "abstract": "Objective methods for assessing perceptual image quality traditionally attempted to quantify the visibility of errors (differences) between a distorted image and a reference image using a variety of known properties of the human visual system. Under the assumption that human visual perception is highly adapted for extracting structural information from a scene, we introduce an alternative complementary framework for quality assessment based on the degradation of structural information. As a specific example of this concept, we develop a structural similarity index and demonstrate its promise through a set of intuitive examples, as well as comparison to both subjective ratings and state-of-the-art objective methods on a database of images compressed with JPEG and JPEG2000. A MATLAB implementation of the proposed algorithm is available online at http://www.cns.nyu.edu//spl sim/lcv/ssim/.",
        "title": "Image quality assessment: from error visibility to structural similarity",
        "venue": "IEEE Transactions on Image Processing",
        "year": 2004,
        "__v": 3,
        "citationCount": 5713
    },
    {
        "authors": [
            "Mark A. Hall",
            "Eibe Frank",
            "Geoffrey Holmes",
            "Bernhard Pfahringer",
            "Peter Reutemann",
            "Ian H. Witten"
        ],
        "references": [
            "2f3397df-feb5-48bf-b120-74f8643cf85f",
            "307db816-5b31-4902-b554-29597320719d",
            "3b247c61-c539-4f54-9295-8d6b379316e6",
            "3e0ad93f-aa9f-402a-b2a6-bcd008aa5eb4",
            "4cbd7765-c47a-4004-a5f8-c2da7c7d1c7b",
            "5113d676-dde0-4807-86e1-460567719413",
            "55fff3f7-2df2-4ff1-833a-f040099a0958",
            "57a3a136-170f-4557-90ec-b46bc4095260",
            "5af5a87e-9360-4dd6-bde1-0aae7d9d1ab0",
            "5daf2270-cd5c-4833-a0c8-50a584d59c63",
            "76d74d72-d6eb-4240-9677-2760b375b75d",
            "78a8e7be-0693-414f-a88d-3525d294c94f",
            "853c9c28-f8e8-49ff-9a53-7e2472d4a670",
            "863f58c4-462b-41ba-a018-79371353d959",
            "8ed6c561-0706-4724-b0f3-bbce686ec3c6",
            "99a154b1-f489-4d8d-8c46-44ade2a250f1",
            "a5f043bb-8503-4578-998e-0298edabcb83",
            "b17ce4d9-37c3-4568-b9c4-a00bb44ec0fd",
            "b7e95219-3a35-4515-9559-66e58a01a9c9",
            "b81cf038-b064-473b-8178-086b21b92788",
            "bc889676-4be9-4288-a05e-580080038bac",
            "c1b6b493-01ef-420f-be44-7bacfe34e846",
            "cab6ead4-35d5-4cf6-80ba-1b9a14bf2fd5",
            "eb957b6d-4f22-4f13-94cc-847210fad714",
            "f7b1307a-d793-4f56-8a72-215db0f593a3"
        ],
        "keyword": [
            "weka",
            "release",
            "time",
            "stable",
            "years",
            "workbench",
            "widespread",
            "version",
            "twelve",
            "text"
        ],
        "group": [
            {
                "4cbd7765-c47a-4004-a5f8-c2da7c7d1c7b": {
                    "authors": [
                        "Rong-En Fan",
                        "Kai-Wei Chang",
                        "Cho-Jui Hsieh",
                        "Xiang-Rui Wang",
                        "Chih-Jen Lin"
                    ],
                    "references": [
                        "8bfb1563-5f31-4127-a98c-8d36c630fce8",
                        "c1b6b493-01ef-420f-be44-7bacfe34e846",
                        "eadb0f66-1fb0-4b1c-9b8b-76cf5edbfad1",
                        "eef64a27-8e9a-40b2-865f-0cca306fdc31",
                        "f006e236-59ad-4647-a59f-4f46dc2c85be"
                    ],
                    "keyword": [
                        "users",
                        "supports",
                        "linear",
                        "library",
                        "liblinear",
                        "vector",
                        "tools",
                        "sparse",
                        "source",
                        "sets"
                    ],
                    "group": [],
                    "_id": "4cbd7765-c47a-4004-a5f8-c2da7c7d1c7b",
                    "abstract": "LIBLINEAR is an open source library for large-scale linear classification. It supports logistic regression and linear support vector machines. We provide easy-to-use command-line tools and library calls for users and developers. Comprehensive documents are available for both beginners and advanced users. Experiments demonstrate that LIBLINEAR is very efficient on large sparse data sets.",
                    "title": "LIBLINEAR: A Library for Large Linear Classification",
                    "venue": "Journal of Machine Learning Research",
                    "year": 2008,
                    "__v": 2,
                    "citationCount": 2507,
                    "result": 4.808961300137771
                },
                "55fff3f7-2df2-4ff1-833a-f040099a0958": {
                    "authors": [
                        "Jiang Su",
                        "Harry Zhang",
                        "Charles X. Ling",
                        "Stan Matwin"
                    ],
                    "references": [
                        "3704f939-09a2-4e9f-b851-1261bcd310df",
                        "8c289402-3834-4167-a32f-2deb827d8cc5",
                        "97e55485-2ec4-4167-92bd-fec145e593f4",
                        "c9e19b93-2126-42df-b586-c90c68599921",
                        "d3e00e7e-1c64-4d7a-b2b2-1ad98ba4c706",
                        "e30006aa-a666-4d31-a6e5-9464797811a6",
                        "f8b2045f-195e-420f-9516-df72eeb7df74",
                        "fa70488d-1d06-4967-8c8e-c678cf1052c8"
                    ],
                    "keyword": [
                        "learning",
                        "discriminative",
                        "parameters",
                        "generative",
                        "efficient",
                        "network",
                        "method",
                        "frequency",
                        "effective",
                        "dfe"
                    ],
                    "group": [],
                    "_id": "55fff3f7-2df2-4ff1-833a-f040099a0958",
                    "abstract": "Bayesian network classifiers have been widely used for classification problems. Given a fixed Bayesian network structure, parameters learning can take two different approaches: generative and discriminative learning. While generative parameter learning is more efficient, discriminative parameter learning is more effective. In this paper, we propose a simple, efficient, and effective discriminative parameter learning method, called  Discriminative Frequency Estimate  (DFE), which learns parameters by discriminatively computing frequencies from data. Empirical studies show that the DFE algorithm integrates the advantages of both generative and discriminative learning: it performs as well as the state-of-the-art discriminative parameter learning method ELR in accuracy, but is significantly more efficient.",
                    "title": "Discriminative parameter learning for Bayesian networks",
                    "venue": "international conference on machine learning",
                    "year": 2008,
                    "__v": 2,
                    "citationCount": 49,
                    "result": 5.005314740299261
                },
                "57a3a136-170f-4557-90ec-b46bc4095260": {
                    "authors": [
                        "Jan E. Gewehr",
                        "Martin Szugat",
                        "Ralf Zimmer"
                    ],
                    "references": [
                        "303ad4fe-3630-4e41-b6a0-8db052ccb866",
                        "721919b7-22d5-4f0a-aafe-d2dcc701b9b7",
                        "867f7b0f-20eb-4b30-80aa-f8c45e88b891"
                    ],
                    "keyword": [
                        "data",
                        "weka",
                        "formats",
                        "bioweka",
                        "bioinformatics",
                        "users",
                        "project",
                        "methods"
                    ],
                    "group": [],
                    "_id": "57a3a136-170f-4557-90ec-b46bc4095260",
                    "abstract": "Summary: Given the growing amount of biological data, data mining methods have become an integral part of bioinformatics research. Unfortunately, standard data mining tools are often not sufficiently equipped for handling raw data such as e.g. amino acid sequences. One popular and freely available framework that contains many well-known data mining algorithms is the Waikato Environment for Knowledge Analysis (Weka). In the BioWeka project, we introduce various input formats for bioinformatics data and bioinformatics methods like alignments to Weka. This allows users to easily combine them with Weka's classification, clustering, validation and visualization facilities on a single platform and therefore reduces the overhead of converting data between different data formats as well as the need to write custom evaluation procedures that can deal with many different programs. We encourage users to participate in this project by adding their own components and data formats to BioWeka.#R##N##R##N#Availability: The software, documentation and tutorial are available at http://www.bioweka.org.#R##N##R##N#Contact: support@bioweka.org",
                    "title": "BioWeka---extending the Weka framework for bioinformatics",
                    "venue": "Bioinformatics",
                    "year": 2007,
                    "__v": 2,
                    "citationCount": 17,
                    "result": 4.189065466697045
                },
                "5af5a87e-9360-4dd6-bde1-0aae7d9d1ab0": {
                    "authors": [
                        "Noam Slonim",
                        "Nir Friedman",
                        "Naftali Tishby"
                    ],
                    "references": [
                        "11ea6b73-e0bd-4f20-914b-1c6cdcc20437",
                        "15c30ca5-6af6-4acf-b8c5-f2c0e18e6ad8",
                        "1b258de4-2daa-494c-942a-925608edeb05",
                        "4880e88e-c3c0-48a3-a240-318311335502",
                        "5537c95b-1650-4243-8b1a-c9fa3520799e",
                        "69df0789-a06f-4166-9c34-93047de2673d",
                        "ab68780d-3419-4b9f-be4a-354c01e6ca6c",
                        "bba5b861-70a6-47d8-96aa-e2722d016253",
                        "bc5c976a-7b0b-4c26-a882-b2839f905d31",
                        "d709ad53-fd9b-4a1f-bb18-6c1377e18a52",
                        "ede9c372-c77f-414c-969a-6032ecf57f02"
                    ],
                    "keyword": [
                        "clustering",
                        "sib",
                        "information",
                        "ib",
                        "algorithm",
                        "typically",
                        "time",
                        "space",
                        "size",
                        "significantly"
                    ],
                    "group": [],
                    "_id": "5af5a87e-9360-4dd6-bde1-0aae7d9d1ab0",
                    "abstract": "We present a novel sequential clustering algorithm which is motivated by the  Information Bottleneck (IB)  method. In contrast to the agglomerative  IB  algorithm, the new sequential ( sIB ) approach is guaranteed to converge to a local maximum of the information with time and space complexity typically linear in the data size. information, as required by the original IB principle. Moreover, the time and space complexity are significantly improved. We apply this algorithm to unsupervised document classification. In our evaluation, on small and medium size corpora, the  sIB  is found to be consistently superior to all the other clustering methods we examine, typically by a significant margin. Moreover, the  sIB  results are comparable to those obtained by a  supervised  Naive Bayes classifier. Finally, we propose a simple procedure for trading cluster's recall to gain higher precision, and show how this approach can extract clusters which match the existing topics of the corpus almost perfectly.",
                    "title": "Unsupervised document classification using sequential information maximization",
                    "venue": "international acm sigir conference on research and development in information retrieval",
                    "year": 2002,
                    "__v": 1,
                    "citationCount": 135,
                    "result": 2.8199938949938947
                },
                "5daf2270-cd5c-4833-a0c8-50a584d59c63": {
                    "authors": [
                        "Ilkay Altintas",
                        "Chad Berkley",
                        "Efrat Jaeger",
                        "Matthew B. Jones",
                        "Bertram Ludäscher",
                        "Steve Mock"
                    ],
                    "references": [
                        "5d64d66f-9f7b-4fe1-8864-924e85006c25"
                    ],
                    "keyword": [
                        "workflow",
                        "data",
                        "swfs",
                        "system",
                        "scientists",
                        "business",
                        "process",
                        "kepler",
                        "execution"
                    ],
                    "group": [],
                    "_id": "5daf2270-cd5c-4833-a0c8-50a584d59c63",
                    "abstract": "Most scientists conduct analyses and run models in several different software and hardware environments, mentally coordinating the export and import of data from one environment to another. The Kepler scientific workflow system provides domain scientists with an easy-to-use yet powerful system for capturing scientific workflows (SWFs). SWFs are a formalization of the ad-hoc process that a scientist may go through to get from raw data to publishable results. Kepler attempts to streamline the workflow creation and execution process so that scientists can design, execute, monitor, re-run, and communicate analytical procedures repeatedly with minimal effort. Kepler is unique in that it seamlessly combines high-level workflow design with execution and runtime interaction, access to local and remote data, and local and remote service invocation. SWFs are superficially similar to business process workflows but have several challenges not present in the business workflow scenario. For example, they often operate on large, complex and heterogeneous data, can be computationally intensive and produce complex derived data products that may be archived for use in reparameterized runs or other workflows. Moreover, unlike business workflows, SWFs are often dataflow-oriented as witnessed by a number of recent academic systems (e.g., DiscoveryNet, Taverna and Triana) and commercial systems (Scitegic/Pipeline-Pilot, Inforsense). In a sense, SWFs are often closer to signal-processing and data streaming applications than they are to control-oriented business workflow applications.",
                    "title": "Kepler: an extensible system for design and execution of scientific workflows",
                    "venue": "statistical and scientific database management",
                    "year": 2004,
                    "__v": 2,
                    "citationCount": 353,
                    "result": 3.2856707018471716
                },
                "76d74d72-d6eb-4240-9677-2760b375b75d": {
                    "authors": [
                        "Janko Dietzsch",
                        "Nils Gehlenborg",
                        "Kay Nieselt"
                    ],
                    "references": [
                        "c3d2009f-c7e9-4804-913d-73573e6703c4",
                        "ef830c0b-f000-4d68-a76a-b44750ea40b3",
                        "fa36b6f0-90b1-4118-b8ef-399acef58a22"
                    ],
                    "keyword": [
                        "data",
                        "methods",
                        "mayday",
                        "information",
                        "visualization",
                        "user",
                        "unituebingen",
                        "public",
                        "plugins",
                        "microarray"
                    ],
                    "group": [],
                    "_id": "76d74d72-d6eb-4240-9677-2760b375b75d",
                    "abstract": "Mayday is a workbench for visualization, analysis and storage of microarray data. It features a graphical user interface and supports the development and integration of existing and new analysis methods. Besides the infrastructural core functionality, Mayday offers a variety of plug-ins, such as various interactive viewers, a connection to the R statistical environment, a connection to SQL-based databases and different data mining methods, including WEKA-library based methods for classification and various clustering methods. In addition, so-called meta information objects are provided for annotation of the microarray data allowing integration of data from different sources, which is a feature that, for instance, is employed in the enhanced heatmap visualization.#R##N##R##N#Contact: nieselt@informatik.uni-tuebingen.de#R##N##R##N#Supplementary information: The software and more detailed information including screenshots and a user guide as well as test data can be found on the Mayday home page http://www.zbit.uni-tuebingen.de/pas/mayday. The core is published under the GPL (GNU Public License) and the associated plug-ins under the LGPL (Lesser GNU Public License).",
                    "title": "Mayday-a microarray data analysis workbench",
                    "venue": "Bioinformatics",
                    "year": 2006,
                    "__v": 2,
                    "citationCount": 14,
                    "result": 2.246288798920378
                },
                "853c9c28-f8e8-49ff-9a53-7e2472d4a670": {
                    "authors": [
                        "Ingo Mierswa",
                        "Michael Wurst",
                        "Ralf Klinkenberg",
                        "Martin Scholz",
                        "Timm Euler"
                    ],
                    "references": [
                        "1ce7a9a3-91c4-45d6-984a-e1d240fd81aa",
                        "38500fe9-7c31-4a6a-aa20-fc96325f2946",
                        "3fca58b2-76fc-402f-b7f4-31383e7c39c7",
                        "567a964a-7589-4950-b0c0-fb2054584c9e",
                        "adc5d61f-31e0-4315-a504-9b3280a77a62",
                        "b45b32ff-8bd1-4616-aa3b-cd35092a8847",
                        "e2a7eed7-948a-4a8c-ba04-7e1c2346d6bb",
                        "e9abffef-c6bf-44da-a673-be480773dbbb",
                        "ff75fc41-ebf3-49da-8f3c-01913bfd7b96"
                    ],
                    "keyword": [
                        "prototyping",
                        "rapid",
                        "methods",
                        "ale",
                        "task",
                        "processing",
                        "kdd",
                        "development",
                        "design",
                        "data"
                    ],
                    "group": [],
                    "_id": "853c9c28-f8e8-49ff-9a53-7e2472d4a670",
                    "abstract": "KDD is a complex and demanding task. While a large number of methods has been established for numerous problems, many challenges remain to be solved. New tasks emerge requiring the development of new methods or processing schemes. Like in software development, the development of such solutions demands for careful analysis, specification, implementation, and testing. Rapid prototyping is an approach which allows crucial design decisions as early as possible. A rapid prototyping system should support maximal re-use and innovative combinations of existing methods, as well as simple and quick integration of new ones.This paper describes Y ale , a free open-source environment forKDD and machine learning. Y ale  provides a rich variety of methods whichallows rapid prototyping for new applications and makes costlyre-implementations unnecessary. Additionally, Y ale  offers extensive functionality for process evaluation and optimization which is a crucial property for any KDD rapid prototyping tool. Following the paradigm of visual programming eases the design of processing schemes. While the graphical user interface supports interactive design, the underlying XML representation enables automated applications after the prototyping phase.After a discussion of the key concepts of Y ale , we illustrate the advantages of rapid prototyping for KDD on case studies ranging from data pre-processing to result visualization. These case studies cover tasks like feature engineering, text mining, data stream mining and tracking drifting concepts, ensemble methods and distributed data mining. This variety of applications is also reflected in a broad user base, we counted more than 40,000 downloads during the last twelve months.",
                    "title": "YALE: rapid prototyping for complex data mining tasks",
                    "venue": "knowledge discovery and data mining",
                    "year": 2006,
                    "__v": 2,
                    "citationCount": 427,
                    "result": 3.449243154506312
                },
                "8ed6c561-0706-4724-b0f3-bbce686ec3c6": {
                    "authors": [
                        "João Gama"
                    ],
                    "references": [
                        "01cf82c6-1ffc-4ab6-acbd-32168856bcb8",
                        "03c65362-4803-46af-b539-1d2e3519e000",
                        "2ed02b36-2c89-43e4-a0d7-b5e01a16d8ae",
                        "473308a4-a098-4eae-8bbf-8c30bc7701a4",
                        "4bd85613-9015-4603-a9b2-3ae9bd153780",
                        "9d391f89-9fbd-438a-bbba-57f8fe085e0c",
                        "bd1f5543-addf-4db6-b6f1-9fb3edeeb1d4",
                        "c3addfce-21af-41b6-af69-d4423095e921"
                    ],
                    "keyword": [
                        "trees",
                        "algorithms",
                        "multivariate",
                        "regression",
                        "nodes",
                        "decision",
                        "classification",
                        "problems",
                        "linear",
                        "function"
                    ],
                    "group": [],
                    "_id": "8ed6c561-0706-4724-b0f3-bbce686ec3c6",
                    "abstract": "The design of algorithms that explore multiple representation languages and explore different search spaces has an intuitive appeal. In the context of classification problems, algorithms that generate multivariate trees are able to explore multiple representation languages by using decision tests based on a combination of attributes. The same applies to model trees algorithms, in regression domains, but using linear models at leaf nodes. In this paper we study where to use combinations of attributes in regression and classification tree learning. We present an algorithm for multivariate tree learning that combines a univariate decision tree with a linear function by means of constructive induction. This algorithm is able to use decision nodes with multivariate tests, and leaf nodes that make predictions using linear functions. Multivariate decision nodes are built when growing the tree, while functional leaves are built when pruning the tree. The algorithm has been implemented both for classification problems and regression problems. The experimental evaluation shows that our algorithm has clear advantages with respect to the generalization ability when compared against its components, two simplified versions, and competes well against the state-of-the-art in multivariate regression and classification trees.",
                    "title": "Functional Trees",
                    "venue": "discovery science",
                    "year": 2001,
                    "__v": 1,
                    "citationCount": 56,
                    "result": 5.262550839253626
                },
                "a5f043bb-8503-4578-998e-0298edabcb83": {
                    "authors": [
                        "Mark A. Hall",
                        "Eibe Frank"
                    ],
                    "references": [
                        "d20df5c3-667b-42d4-a128-d5f0b649cc32"
                    ],
                    "keyword": [
                        "seminaive",
                        "naive",
                        "bayes",
                        "technique",
                        "tables",
                        "significantly",
                        "decision",
                        "combines",
                        "variant",
                        "true"
                    ],
                    "group": [],
                    "_id": "a5f043bb-8503-4578-998e-0298edabcb83",
                    "abstract": "We investigate a simple semi-naive Bayesian ranking method that combines naive Bayes with induction of decision tables. Naive Bayes and decision tables can both be trained efficiently, and the same holds true for the combined semi-naive model. We show that the resulting ranker, compared to either component technique, frequently significantly increases AUC. For some datasets it significantly improves on both techniques. This is also the case when attribute selection is performed in naive Bayes and its semi-naive variant.",
                    "title": "Combining Naive Bayes and Decision Tables",
                    "venue": "the florida ai research society",
                    "year": 2008,
                    "__v": 2,
                    "citationCount": 36,
                    "result": 3.719771894771895
                },
                "b17ce4d9-37c3-4568-b9c4-a00bb44ec0fd": {
                    "authors": [
                        "Eibe Frank",
                        "Stefan Kramer"
                    ],
                    "references": [
                        "111a25a1-44ca-44fb-bca8-51e8157463d3",
                        "12fa9885-b0a9-4ea3-a0de-e020c333c3f0",
                        "1aa20da0-7b11-4639-b33d-bdb367348f77",
                        "7fbbef81-7c36-4a5d-9e92-e7c59e7b82b7",
                        "97c41b73-f4eb-4e1f-8f9f-a3daa571353d",
                        "ca756b69-343b-4363-a9b7-7046fe3fe7d7",
                        "cdbd2ef9-d4b1-4dff-9037-3ea84627424d",
                        "cf6e901a-6336-4644-a41f-91334e39df66",
                        "f00fc370-0854-4967-bc6a-83b6c49da8bf",
                        "f33acc76-f25e-446f-a834-9d898907b326"
                    ],
                    "keyword": [
                        "problems",
                        "regression",
                        "multiclass",
                        "logistic",
                        "dichotomies",
                        "classification",
                        "trees",
                        "nested",
                        "comparable",
                        "classifier"
                    ],
                    "group": [],
                    "_id": "b17ce4d9-37c3-4568-b9c4-a00bb44ec0fd",
                    "abstract": "Nested dichotomies are a standard statistical technique for tackling certain polytomous classification problems with logistic regression. They can be represented as binary trees that recursively split a multi-class classification task into a system of dichotomies and provide a statistically sound way of applying two-class learning algorithms to multi-class problems (assuming these algorithms generate class probability estimates). However, there are usually many candidate trees for a given problem and in the standard approach the choice of a particular tree is based on domain knowledge that may not be available in practice. An alternative is to treat every system of nested dichotomies as equally likely and to form an ensemble classifier based on this assumption. We show that this approach produces more accurate classifications than applying C4.5 and logistic regression directly to multi-class problems. Our results also show that ensembles of nested dichotomies produce more accurate classifiers than pairwise classification if both techniques are used with C4.5, and comparable results for logistic regression. Compared to error-correcting output codes, they are preferable if logistic regression is used, and comparable in the case of C4.5. An additional benefit is that they generate class probability estimates. Consequently they appear to be a good general-purpose method for applying binary classifiers to multi-class problems.",
                    "title": "Ensembles of nested dichotomies for multi-class problems",
                    "venue": "international conference on machine learning",
                    "year": 2004,
                    "__v": 2,
                    "citationCount": 36,
                    "result": 5.013128976286871
                },
                "b7e95219-3a35-4515-9559-66e58a01a9c9": {
                    "authors": [
                        "João Gama"
                    ],
                    "references": [
                        "01cf82c6-1ffc-4ab6-acbd-32168856bcb8",
                        "03c65362-4803-46af-b539-1d2e3519e000",
                        "0c77e85f-0bd2-4eeb-b97e-4d59887daf8e",
                        "0f115eea-2272-431f-9f21-6d6789b2bbc9",
                        "2ed02b36-2c89-43e4-a0d7-b5e01a16d8ae",
                        "473308a4-a098-4eae-8bbf-8c30bc7701a4",
                        "485598b2-ed73-4670-a44d-b0844f923fa4",
                        "4bd85613-9015-4603-a9b2-3ae9bd153780",
                        "5fed1e5a-cf4c-45d3-8be7-b8daa5a558c8",
                        "7c585fb9-63ee-462d-b50c-e9d0ba0c0dda",
                        "9d391f89-9fbd-438a-bbba-57f8fe085e0c",
                        "bd1f5543-addf-4db6-b6f1-9fb3edeeb1d4",
                        "c3addfce-21af-41b6-af69-d4423095e921",
                        "d68ec58f-29f2-49fd-8dd1-4f76578e7dab",
                        "d89dd3fc-962f-40de-bc39-e32039ee5398",
                        "da4534a6-897c-4431-89ef-cd326bfaf9a8",
                        "e28939c6-e43e-489b-8877-d09a758503a6",
                        "eafe3cda-d060-41e9-9029-2129818177ec"
                    ],
                    "keyword": [
                        "nodes",
                        "trees",
                        "decision",
                        "multivariate",
                        "functional",
                        "study",
                        "linear",
                        "leaves",
                        "combination",
                        "model"
                    ],
                    "group": [],
                    "_id": "b7e95219-3a35-4515-9559-66e58a01a9c9",
                    "abstract": "In the context of classification problems, algorithms that generate multivariate trees are able to explore multiple representation languages by using decision tests based on a combination of attributes. In the regression setting, model trees algorithms explore multiple representation languages but using linear models at leaf nodes. In this work we study the effects of using combinations of attributes at decision nodes, leaf nodes, or both nodes and leaves in regression and classification tree learning. In order to study the use of functional nodes at different places and for different types of modeling, we introduce a simple unifying framework for multivariate tree learning. This framework combines a univariate decision tree with a linear function by means of constructive induction. Decision trees derived from the framework are able to use decision nodes with multivariate tests, and leaf nodes that make predictions using linear functions. Multivariate decision nodes are built when growing the tree, while functional leaves are built when pruning the tree. We experimentally evaluate a univariate tree, a multivariate tree using linear combinations at inner and leaf nodes, and two simplified versions restricting linear combinations to inner nodes and leaves. The experimental evaluation shows that all functional trees variants exhibit similar performance, with advantages in different datasets. In this study there is a marginal advantage of the full model. These results lead us to study the role of functional leaves and nodes. We use the bias-variance decomposition of the error, cluster analysis, and learning curves as tools for analysis. We observe that in the datasets under study and for classification and regression, the use of multivariate decision nodes has more impact in the bias component of the error, while the use of multivariate decision leaves has more impact in the variance component.",
                    "title": "Functional Trees",
                    "venue": "Machine Learning",
                    "year": 2004,
                    "__v": 1,
                    "citationCount": 73,
                    "result": 5.796598662775134
                },
                "b81cf038-b064-473b-8178-086b21b92788": {
                    "authors": [
                        "Juan José Rodríguez",
                        "Ludmila I. Kuncheva",
                        "Carlos J. Alonso"
                    ],
                    "references": [
                        "059d662d-7c78-4744-9487-3ce298861300",
                        "0f115eea-2272-431f-9f21-6d6789b2bbc9",
                        "12fa9885-b0a9-4ea3-a0de-e020c333c3f0",
                        "168f05e4-d428-4184-bfd5-e53bfd6644c4",
                        "17f811d8-8607-4270-bbec-1cc7883edd68",
                        "2c962c64-02d3-4f07-a5a8-62ba4ebc9b72",
                        "310cbba4-d88d-4bf4-a4f2-738f91b5f8c8",
                        "3ae9664a-bf6f-45d2-852f-bba9b47e2b8a",
                        "42e0cffb-e875-439f-a8b2-8434fbbda827",
                        "5711769b-da84-47c6-9402-c293ec1fcec5",
                        "6c871065-76b8-44f3-97d5-ac3bce951421",
                        "7c8e4760-a1d9-4d17-b005-8c77cd77f95a",
                        "7d004384-46d8-48a4-a133-f1cdc5eeb8af",
                        "82a0321a-e450-45db-ab12-395fe0efe06a",
                        "84806dbe-fa0e-47c0-b1f2-00fb2eed25a7",
                        "852d4703-36db-4c8c-814c-6cd2273b536b",
                        "9e460e04-9280-4bad-9486-6cda157e62d8",
                        "a36e20a3-b513-49b0-b65d-7926ab51eead",
                        "b11d7f27-90e2-4c44-b94c-ce3f95bc0ac6",
                        "becc43bc-a7b6-46e1-817e-553c84a4a6dd",
                        "c3fe4b8f-c3a3-43ea-b569-6273b1a0cbb3",
                        "db26488d-78be-44b1-a343-e896f43c5d29",
                        "e9663ac0-4c6e-4269-b906-3883c1343a69",
                        "f6791823-2f7b-4752-8c4f-c97db8eeabd3",
                        "f6bd8b64-684d-429a-aab5-8ff3a2c23cd6",
                        "f730901c-ee82-4fdf-bae6-10a7b954df34"
                    ],
                    "keyword": [
                        "rotations",
                        "feature",
                        "classifier",
                        "based",
                        "forest",
                        "ensembles",
                        "data",
                        "set",
                        "randomly",
                        "principal"
                    ],
                    "group": [],
                    "_id": "b81cf038-b064-473b-8178-086b21b92788",
                    "abstract": "We propose a method for generating classifier ensembles based on feature extraction. To create the training data for a base classifier, the feature set is randomly split into K subsets (K is a parameter of the algorithm) and principal component analysis (PCA) is applied to each subset. All principal components are retained in order to preserve the variability information in the data. Thus, K axis rotations take place to form the new features for a base classifier. The idea of the rotation approach is to encourage simultaneously individual accuracy and diversity within the ensemble. Diversity is promoted through the feature extraction for each base classifier. Decision trees were chosen here because they are sensitive to rotation of the feature axes, hence the name \"forest\". Accuracy is sought by keeping all principal components and also using the whole data set to train each base classifier. Using WEKA, we examined the rotation forest ensemble on a random selection of 33 benchmark data sets from the UCI repository and compared it with bagging, AdaBoost, and random forest. The results were favorable to rotation forest and prompted an investigation into diversity-accuracy landscape of the ensemble models. Diversity-error diagrams revealed that rotation forest ensembles construct individual classifiers which are more accurate than these in AdaBoost and random forest, and more diverse than these in bagging, sometimes more accurate as well",
                    "title": "Rotation Forest: A New Classifier Ensemble Method",
                    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "year": 2006,
                    "__v": 2,
                    "citationCount": 416,
                    "result": 4.621457953810895
                },
                "bc889676-4be9-4288-a05e-580080038bac": {
                    "authors": [
                        "Ian H. Witten",
                        "Gordon W. Paynter",
                        "Eibe Frank",
                        "Carl Gutwin",
                        "Craig G. Nevill-Manning"
                    ],
                    "references": [
                        "135c7d8b-578a-462d-98d0-0288eec3a9fc",
                        "39058eb5-778f-41eb-85aa-fc630f5c2d92",
                        "72609944-bd7e-45cd-ad07-80bdb806ff21",
                        "73586b0a-467c-4dd5-9148-60bef0017bce",
                        "96d6d9b9-6d69-4c9a-b3f5-c8083966d55c",
                        "a5f3e8ff-ea04-4863-ac09-df3e5727855d",
                        "a7761d31-5e2a-45a3-ae7b-d95694a8ab0f",
                        "d13e1fd6-83b6-45c3-a473-ebd53e5b85e8",
                        "d20df5c3-667b-42d4-a128-d5f0b649cc32",
                        "f6fe76df-543e-456f-999f-44628a4b14a5",
                        "fa81a051-0f8e-4f10-a172-acd5a8923e23"
                    ],
                    "keyword": [
                        "keyphrases",
                        "kea",
                        "documents",
                        "candidate",
                        "predict",
                        "model",
                        "identifies",
                        "algorithm"
                    ],
                    "group": [],
                    "_id": "bc889676-4be9-4288-a05e-580080038bac",
                    "abstract": "Keyphrases provide semantic metadata that summarize and characterize documents. This paper describes Kea, an algorithm for automatically extracting keyphrases from text. Kea identifies candidate keyphrases using lexical methods, calculates feature values for each candidate, and uses a machine-learning algorithm to predict which candidates are good keyphrases. The machine learning scheme first builds a prediction model using training documents with known keyphrases, and then uses the model to find keyphrases in new documents. We use a large test corpus to evaluate Kea's effectiveness in terms of how many author-assigned keyphrases are correctly identified. The system is simple, robust, and publicly available.",
                    "title": "KEA: practical automatic keyphrase extraction",
                    "venue": "arXiv: Digital Libraries",
                    "year": 1999,
                    "__v": 1,
                    "citationCount": 340,
                    "result": 3.5012614836144245
                },
                "c1b6b493-01ef-420f-be44-7bacfe34e846": {
                    "authors": [
                        "Chih-Chung Chang",
                        "Chih-Jen Lin"
                    ],
                    "references": [
                        "036a2a1b-8729-431d-b260-3d6b33c6c6a4",
                        "078b095c-7687-43f2-a0bf-30ea78f787db",
                        "11f27d27-6bd9-4691-834e-9864871a65f4",
                        "1f556c88-b553-4c75-b243-92d8200f8149",
                        "2d768672-0070-4a38-87c8-f0cce1dd2f44",
                        "33184e74-4574-4856-a969-e497fdc2fec8",
                        "41087d29-5163-4a9f-b55a-3f407b8a040d",
                        "4317334f-595f-45be-a095-efe8f258b558",
                        "50dd56db-151d-4d62-8576-65f0ef6f381b",
                        "5ffac6f9-2456-42cf-830c-9049ce37c899",
                        "633e2247-d487-4ae7-b6ab-a17a075b83aa",
                        "7c6a970a-0d6f-4e4b-b50e-6c6fbd23a9ab",
                        "7f03746d-ba06-4b34-828e-683192e9ee42",
                        "8b26f4a9-380f-432d-aea1-66a86ce407e8",
                        "8c0ec27c-e654-4e0e-8c49-9b427117a98e",
                        "90925435-d33a-4abd-892d-abbe52e547c4",
                        "92a420a1-f54b-4cdd-b5a4-2669ac2e7c5d",
                        "962d4022-ff67-4067-a544-828604d8db52",
                        "9764de87-e34e-4ea1-8de3-12d9bffc4f55",
                        "97bfd03c-335a-4f39-89d3-cf0a22769383",
                        "a2e5c222-c380-42d7-8846-cbc232f46a69",
                        "a5d347a7-9984-45f4-821e-df7356477185",
                        "b532d930-ad51-4a05-9c5c-9a75d6b021a2",
                        "b90f9310-726f-4116-9322-6fc01ab598fd",
                        "bb693c93-e418-46ea-8b38-9c53df27bdf2",
                        "cdbd2ef9-d4b1-4dff-9037-3ea84627424d",
                        "dd5a3ef5-9d44-4dde-bcdb-dc4d17c69073",
                        "f006e236-59ad-4647-a59f-4f46dc2c85be",
                        "feff8862-f47d-4591-a7cb-b62d7efc81a2"
                    ],
                    "keyword": [
                        "libsvm",
                        "svm",
                        "machines",
                        "details",
                        "year",
                        "wide",
                        "vector",
                        "users",
                        "theoretical",
                        "svms"
                    ],
                    "group": [
                        null
                    ],
                    "_id": "c1b6b493-01ef-420f-be44-7bacfe34e846",
                    "abstract": "LIBSVM is a library for Support Vector Machines (SVMs). We have been actively developing this package since the year 2000. The goal is to help users to easily apply SVM to their applications. LIBSVM has gained wide popularity in machine learning and many other areas. In this article, we present all implementation details of LIBSVM. Issues such as solving SVM optimization problems theoretical convergence multiclass classification probability estimates and parameter selection are discussed in detail.",
                    "title": "LIBSVM: A library for support vector machines",
                    "venue": "ACM Transactions on Intelligent Systems and Technology",
                    "year": 2011,
                    "__v": 3,
                    "citationCount": 13475,
                    "result": 4.200401353032932
                },
                "eb957b6d-4f22-4f13-94cc-847210fad714": {
                    "authors": [
                        "Alexander Genkin",
                        "David D. Lewis",
                        "David Madigan"
                    ],
                    "references": [
                        "0895c22d-37c5-4c8f-9202-a32ebd2cb0c0",
                        "179fd669-6c22-4cdb-999b-a18e1062a8d0",
                        "19d8e565-399d-47a8-bd30-8ff4fe857892",
                        "1ce7a9a3-91c4-45d6-984a-e1d240fd81aa",
                        "3a715cc4-ecf7-4986-868f-c41f4efdd4d5",
                        "4adb467d-dacf-4019-b0d5-28ce1f323cf4",
                        "58913a76-a718-4493-a5e9-2fa8aa3ef52b",
                        "5925fee7-b33e-4b62-b1cd-546b5e59c828",
                        "5b2842ed-e697-4c6c-9e3b-845c4c3ba0dc",
                        "64c13c1b-5147-4d15-8ef7-3b765eee1d99",
                        "75ec0b95-65c5-48c9-ae1b-a44c6c378bec",
                        "77dc5843-fb8b-4dd6-a230-63b67f1aff18",
                        "8bb47288-c305-4131-9a23-3635d1bc15ad",
                        "9e57898a-eb7f-4166-a3c2-ce32473abee3",
                        "9f4995af-e704-48ab-8717-6972a3d4455b",
                        "a1e762ba-4019-4722-b9e1-b7ed9a7644a9",
                        "aa24e310-630a-4a59-81cc-f25421aa7fc0",
                        "b0d60993-d0e5-4f52-8b3d-dceb67154a58",
                        "b5ed7586-8f67-4e79-ac6b-f8cd6422650a",
                        "b7850d71-2cee-4c3b-9d53-216d63ca0515",
                        "b8b938f5-cc7f-40ae-b34b-6b592a487a10",
                        "bb74ee29-c9bd-4ed8-978c-295045e24594",
                        "bc95970b-34c5-4860-a832-41bc04a50889",
                        "beb4fbeb-f38a-4796-b768-851ef7d8af6a",
                        "c2cce1cf-b653-430b-b5e4-b5141484f09c",
                        "cb4fbf1c-02e4-4ca9-995d-29f5282fdb4a",
                        "d1a51572-839b-4ae1-97c3-ad045ea6425a"
                    ],
                    "keyword": [
                        "regression",
                        "produces",
                        "models",
                        "logistic",
                        "text",
                        "predictive",
                        "data",
                        "approach"
                    ],
                    "group": [],
                    "_id": "eb957b6d-4f22-4f13-94cc-847210fad714",
                    "abstract": "Logistic regression analysis of high-dimensional data, such as natural language text, poses computational and statistical challenges. Maximum likelihood estimation often fails in these applications. We present a simple Bayesian logistic regression approach that uses a Laplace prior to avoid overfitting and produces sparse predictive models for text data. We apply this approach to a range of document classification problems and show that it produces compact predictive models at least as effective as those produced by support vector machine classifiers or ridge logistic regression combined with feature selection. We describe our model fitting algorithm, our open source implementations (BBR and BMR), and experimental results.",
                    "title": "Large-Scale Bayesian Logistic Regression for Text Categorization",
                    "venue": "Technometrics",
                    "year": 2007,
                    "__v": 2,
                    "citationCount": 168,
                    "result": 4.203643578643579
                }
            }
        ],
        "_id": "8026f56a-a93e-4933-8ead-c9aa9e3f0498",
        "abstract": "More than twelve years have elapsed since the first public release of WEKA. In that time, the software has been rewritten entirely from scratch, evolved substantially and now accompanies a text on data mining [35]. These days, WEKA enjoys widespread acceptance in both academia and business, has an active community, and has been downloaded more than 1.4 million times since being placed on Source-Forge in April 2000. This paper provides an introduction to the WEKA workbench, reviews the history of the project, and, in light of the recent 3.6 stable release, briefly discusses what has been added since the last stable version (Weka 3.4) released in 2003.",
        "title": "The WEKA data mining software: an update",
        "venue": "knowledge discovery and data mining",
        "year": 2009,
        "__v": 3,
        "citationCount": 5847
    },
    {
        "authors": [
            "Daniel D. Lee",
            "H. Sebastian Seung"
        ],
        "references": [
            "328aafa9-db5d-4ac4-9338-fe918ea60f42",
            "5cd74e0b-f25c-4aaf-8327-7ec949c7d098",
            "9707d672-9d01-4f8e-bfa0-028ed63f0837",
            "b0217d71-3709-4ada-a5de-a78af1de2e02",
            "cd17473b-9aec-4099-bf27-b116490b43ea"
        ],
        "keyword": [
            "algorithms",
            "factorization",
            "convergence",
            "shown",
            "rescaled",
            "nmf",
            "multiplicative",
            "minimize"
        ],
        "group": [
            {
                "b0217d71-3709-4ada-a5de-a78af1de2e02": {
                    "authors": [
                        "Daniel D. Lee",
                        "H. Sebastian Seung"
                    ],
                    "references": [
                        "102ec2cf-9844-43e5-81c9-de319d68ce8d",
                        "16c37100-0533-42e1-aebd-a3805a7c3dde",
                        "363d7090-ebd7-4635-b7cd-09b3907967bf",
                        "87969fc2-8332-4ee5-b6b0-e1b26d01ebd4",
                        "8b2c0aff-4589-4e0f-aae4-4f84a4413406",
                        "ae3e7593-586f-495f-9416-4b50ed1fcd10",
                        "ba3a624a-9a10-4e40-9d1d-2db068775a14",
                        "db65ecfc-898a-47b4-89e3-53f185390f61"
                    ],
                    "keyword": [
                        "algorithms",
                        "vectors",
                        "input",
                        "encoders",
                        "convex",
                        "conic",
                        "reconstruction",
                        "models",
                        "learning",
                        "basis"
                    ],
                    "group": [],
                    "_id": "b0217d71-3709-4ada-a5de-a78af1de2e02",
                    "abstract": "Unsupervised learning algorithms based on convex and conic encoders are proposed. The encoders find the closest convex or conic combination of basis vectors to the input. The learning algorithms produce basis vectors that minimize the reconstruction error of the encoders. The convex algorithm develops locally linear models of the input, while the conic algorithm discovers features. Both algorithms are used to model handwritten digits and compared with vector quantization and principal component analysis. The neural network implementations involve feedback connections that project a reconstruction back to the input layer.",
                    "title": "Unsupervised Learning by Convex and Conic Coding",
                    "venue": "neural information processing systems",
                    "year": 1997,
                    "__v": 2,
                    "citationCount": 28,
                    "result": 5.236491010746629
                }
            }
        ],
        "_id": "839e59b8-b356-4329-ba79-97f981cf6768",
        "abstract": "Non-negative matrix factorization (NMF) has previously been shown to be a useful decomposition for multivariate data. Two different multiplicative algorithms for NMF are analyzed. They differ only slightly in the multiplicative factor used in the update rules. One algorithm can be shown to minimize the conventional least squares error while the other minimizes the generalized Kullback-Leibler divergence. The monotonic convergence of both algorithms can be proven using an auxiliary function analogous to that used for proving convergence of the Expectation-Maximization algorithm. The algorithms can also be interpreted as diagonally rescaled gradient descent, where the rescaling factor is optimally chosen to ensure convergence.",
        "title": "Algorithms for Non-negative Matrix Factorization",
        "venue": "neural information processing systems",
        "year": 2001,
        "__v": 2,
        "citationCount": 2397
    },
    {
        "authors": [
            "Wei Ye",
            "John S. Heidemann",
            "Deborah Estrin"
        ],
        "references": [
            "0b93552e-74e8-483f-82cb-5c04e1cd9232",
            "1dd8c68d-3b20-4171-9245-3a12c64c2838",
            "2088d2fd-d0ed-477f-b350-5d342624e91e",
            "23dd7fc0-1ebd-43ce-ab3e-43896512c209",
            "330841ef-6d92-4fe7-aebe-c8e7abaf9cd2",
            "4f60dbc7-9647-4b91-b96f-9f77d07fea7c",
            "55a6413a-4a9c-4e8d-957b-8c1a4e5d5f0b",
            "6858fa05-89cf-48b9-ab78-507b868de4bd",
            "73574f5f-bf4f-44fb-b13f-d5eaa8c96619",
            "afc06b7c-7fb3-4f88-942b-3076ed77920e"
        ],
        "keyword": [
            "smac",
            "nodes",
            "networks",
            "sensor",
            "mac",
            "energy",
            "wireless",
            "sleep",
            "reduce",
            "application"
        ],
        "group": [
            {
                "2088d2fd-d0ed-477f-b350-5d342624e91e": {
                    "authors": [
                        "John S. Heidemann",
                        "Fabio Silva",
                        "Chalermek Intanagonwiwat",
                        "Ramesh Govindan",
                        "Deborah Estrin",
                        "Deepak Ganesan"
                    ],
                    "references": [
                        "05fb3436-276f-43ca-979b-0a3323240c19",
                        "094c330a-2a29-4c7f-b1da-21f35dd85560",
                        "23dd7fc0-1ebd-43ce-ab3e-43896512c209",
                        "31c5e39a-3f24-4d20-bf8c-3d00036baf95",
                        "4ce4d734-c29c-4097-9ca9-314feaccc642",
                        "4f60dbc7-9647-4b91-b96f-9f77d07fea7c",
                        "5520148d-133b-4512-91d3-bf4379992ac8",
                        "55a6413a-4a9c-4e8d-957b-8c1a4e5d5f0b",
                        "6500989e-b1e1-4b02-a921-21ec25685b73",
                        "6858fa05-89cf-48b9-ab78-507b868de4bd",
                        "7c9f8cd8-d0ef-4954-b4db-4a6c803459c2",
                        "83cff325-43e0-4161-aedd-01bd59463cc7",
                        "8448e4d9-0abd-4733-a786-f808673ea8b4",
                        "84dc5aaa-7b2c-4f15-97f4-aa867b4328e2",
                        "8887b1ca-a0eb-40a0-ae8e-52c935dcafec",
                        "9b2403f1-010a-490b-bff6-d607b24c4009",
                        "9eac8f56-e6ce-4d57-89ba-6f1119209b9a",
                        "afc06b7c-7fb3-4f88-942b-3076ed77920e",
                        "afe332fa-d8bd-425f-b861-f32a53e2a1f1",
                        "c2ae33d8-85e5-4d1d-8f17-b71a210b4546",
                        "cabe73d6-d410-47fc-8604-02ec6d37b57c",
                        "cae1e692-9d2c-48ca-80da-956c63397390",
                        "cc24b268-96b4-4a06-83af-eee9be5c7ac9",
                        "f8ece2c5-c8b1-4a1e-8528-c09357ec23a4"
                    ],
                    "keyword": [],
                    "group": [],
                    "_id": "2088d2fd-d0ed-477f-b350-5d342624e91e",
                    "abstract": "In most distributed systems, naming of nodes for low-level communication leverages topological location (such as node addresses) and is independent of any application. In this paper, we investigate an emerging class of distributed systems where low-level communication does not rely on network topological location. Rather, low-level communication is based on attributes that are  external  to the network topology and  relevant  to the application. When combined with dense deployment of nodes, this kind of named data enables  in-network processing  for data aggregation, collaborative signal processing, and similar problems. These approaches are essential for emerging applications such as sensor networks where resources such as bandwidth and energy are limited. This paper is the first description of the software architecture that supports named data and in-network processing in an operational, multi-application sensor-network. We show that approaches such as in-network aggregation and nested queries can significantly affect network traffic. In one experiment aggregation reduces traffic by up to 42% and nested queries reduce loss rates by 30%. Although aggregation has been previously studied in simulation, this paper demonstrates nested queries as another form of in-network processing, and it presents the first evaluation of these approaches over an operational testbed.",
                    "title": "Building efficient wireless sensor networks with low-level naming",
                    "venue": "symposium on operating systems principles",
                    "year": 2001,
                    "__v": 0,
                    "citationCount": 289,
                    "result": 5
                },
                "4f60dbc7-9647-4b91-b96f-9f77d07fea7c": {
                    "authors": [
                        "Frazer Bennett",
                        "David Clarke",
                        "Joseph B. Evans",
                        "Andrew Hopper",
                        "Alan Jones",
                        "David Leask"
                    ],
                    "references": [
                        "0b93552e-74e8-483f-82cb-5c04e1cd9232",
                        "8b374059-8866-461b-b1f9-2f6a3dcb6f04",
                        "cbdef30c-2065-420b-97ab-bbc912575763",
                        "d7825e13-b803-413c-924c-7aea5e2a1159"
                    ],
                    "keyword": [
                        "system",
                        "piconet",
                        "network",
                        "embedded",
                        "connectivity",
                        "article"
                    ],
                    "group": [],
                    "_id": "4f60dbc7-9647-4b91-b96f-9f77d07fea7c",
                    "abstract": "Piconet is a general-purpose, low-power ad hoc radio network. It provides a base level of connectivity to even the simplest of sensing and computing objects. It is our intention that a full range of portable and embedded devices may make use of this connectivity. This article outlines the Piconet system, under development at the Olivetti and Oracle Research Laboratory (ORL). The authors discuss the motivation for providing this low-level \"embedded networking\", and describe their experiences of building such a system. The article concludes with a commentary on some of the implications that power saving, and other considerations central to Piconet, have on the design of the system.",
                    "title": "Piconet: embedded mobile networking",
                    "venue": "IEEE Personal Communications",
                    "year": 1997,
                    "__v": 1,
                    "citationCount": 98,
                    "result": 4.40514208014208
                },
                "6858fa05-89cf-48b9-ab78-507b868de4bd": {
                    "authors": [
                        "Suresh Singh",
                        "Cauligi S. Raghavendra"
                    ],
                    "references": [
                        "0b93552e-74e8-483f-82cb-5c04e1cd9232",
                        "13556eea-051f-487b-8c52-476314eedaa5",
                        "1aaee431-d884-4764-b1ab-fa15594bf745",
                        "41d377e3-9d04-43f9-9705-13b39d68ab0b",
                        "53f1c69e-3fbf-45b6-a5c0-18fb7eb87f2f",
                        "795ac717-1d24-4688-84c5-984d615cfcc6",
                        "9ada4e4d-dfeb-4ed6-b7b7-1e9464a771b3",
                        "ad460af7-e50d-4c66-8bdf-ef01f0255989",
                        "c65a2601-11ba-43f8-9b60-8a7709a21f68",
                        "da931260-00e6-400b-ba90-d1fb00690031",
                        "e2baa34c-eba8-45fc-ac64-693761c9680b",
                        "ef4e6127-1de5-4998-a80c-571c606860a9"
                    ],
                    "keyword": [
                        "protocol",
                        "power",
                        "nodes",
                        "networks",
                        "multiaccess",
                        "hoc",
                        "conserves",
                        "ad"
                    ],
                    "group": [],
                    "_id": "6858fa05-89cf-48b9-ab78-507b868de4bd",
                    "abstract": "In this paper we develop a new multiaccess protocol for ad hoc radio networks. The protocol is based on the original MACA protocol with the adition of a separate signalling channel. The unique feature of our protocol is that it conserves battery power at nodes by intelligently powering off nodes that are not actively transmitting or receiving packets. The manner in which nodes power themselves off does not influence the delay or throughput characteristics of our protocol. We illustrate the power conserving behavior of PAMAS via extensive simulations performed over ad hoc networks containing 10-20 nodes. Our results indicate that power savings of between 10% and 70% are attainable in most systems. Finally, we discuss how the idea of power awareness can be built into other multiaccess protocols as well.",
                    "title": "PAMAS—power aware multi-access protocol with signalling for ad hoc networks",
                    "venue": "acm special interest group on data communication",
                    "year": 1998,
                    "__v": 1,
                    "citationCount": 517,
                    "result": 5.542020724373665
                },
                "73574f5f-bf4f-44fb-b13f-d5eaa8c96619": {
                    "authors": [
                        "Alec Woo",
                        "David E. Culler"
                    ],
                    "references": [
                        "0b93552e-74e8-483f-82cb-5c04e1cd9232",
                        "10f58ff9-c14e-4bf5-9c44-0a3f14626d3f",
                        "1dd8c68d-3b20-4171-9245-3a12c64c2838",
                        "3804c050-c207-4072-8077-f61297d009aa",
                        "38f54b84-5272-43df-8cde-a3e755b17dee",
                        "6858fa05-89cf-48b9-ab78-507b868de4bd",
                        "686b1f97-3cb7-47a6-bbd2-e8ba891dc1b5"
                    ],
                    "keyword": [
                        "networks",
                        "energy",
                        "control",
                        "sensor",
                        "regime",
                        "media",
                        "goals",
                        "fair",
                        "efficient",
                        "computation"
                    ],
                    "group": [],
                    "_id": "73574f5f-bf4f-44fb-b13f-d5eaa8c96619",
                    "abstract": "We study the problem of media access control in the novel regime of sensor networks, where unique application behavior and tight constraints in computation power, storage, energy resources, and radio technology have shaped this design space to be very different from that found in traditional mobile computing regime. Media access control in sensor networks must not only be energy efficient but should also allow fair bandwidth allocation to the infrastructure for all nodes in a multihop network. We propose an adaptive rate control mechanism aiming to support these two goals and find that such a scheme is most effective in achieving our fairness goal while being energy efficient for both low and high duty cycle of network traffic.",
                    "title": "A transmission control scheme for media access in sensor networks",
                    "venue": "acm ieee international conference on mobile computing and networking",
                    "year": 2001,
                    "__v": 1,
                    "citationCount": 445,
                    "result": 8.799358974358976
                },
                "afc06b7c-7fb3-4f88-942b-3076ed77920e": {
                    "authors": [
                        "Chalermek Intanagonwiwat",
                        "Ramesh Govindan",
                        "Deborah Estrin"
                    ],
                    "references": [
                        "027291a7-a3fd-4ab0-a81c-6e350f989cc5",
                        "19bb3151-ecc6-47d3-a639-476590858f2b",
                        "4f60dbc7-9647-4b91-b96f-9f77d07fea7c",
                        "55a6413a-4a9c-4e8d-957b-8c1a4e5d5f0b",
                        "6500989e-b1e1-4b02-a921-21ec25685b73",
                        "7c9f8cd8-d0ef-4954-b4db-4a6c803459c2",
                        "83a2eb55-b330-4e0c-8dc9-05e9466d5028",
                        "b46af373-5147-4193-9c1d-70adb1f5a527",
                        "cae1e692-9d2c-48ca-80da-956c63397390",
                        "d563bff2-b63b-470e-a53f-567f8927dbf4",
                        "dc0c4146-bf52-4584-85d9-1ea648aecc14",
                        "f8ece2c5-c8b1-4a1e-8528-c09357ec23a4"
                    ],
                    "keyword": [
                        "directed",
                        "diffusion",
                        "nodes",
                        "networks",
                        "sensing",
                        "explore",
                        "enable",
                        "data",
                        "coordinate",
                        "communication"
                    ],
                    "group": [],
                    "_id": "afc06b7c-7fb3-4f88-942b-3076ed77920e",
                    "abstract": "Advances in processor, memory and radio technology will enable small and cheap nodes capable of sensing, communication and computation. Networks of such nodes can coordinate to perform distributed sensing of environmental phenomena. In this paper, we explore the  directed diffusion  paradigm for such coordination. Directed diffusion is datacentric in that all communication is for named data. All nodes in a directed diffusion-based network are application-aware. This enables diffusion to achieve energy savings by selecting empirically good paths and by caching and processing data in-network. We explore and evaluate the use of directed diffusion for a simple remote-surveillance sensor network.",
                    "title": "Directed diffusion: a scalable and robust communication paradigm for sensor networks",
                    "venue": "acm ieee international conference on mobile computing and networking",
                    "year": 2000,
                    "__v": 2,
                    "citationCount": 2463,
                    "result": 8.741332643964222
                }
            }
        ],
        "_id": "85352dec-58be-43db-a428-f3f574ff96ec",
        "abstract": "This paper proposes S-MAC, a medium-access control (MAC) protocol designed for wireless sensor networks. Wireless sensor networks use battery-operated computing and sensing devices. A network of these devices will collaborate for a common application such as environmental monitoring. We expect sensor networks to be deployed in an ad hoc fashion, with individual nodes remaining largely inactive for long periods of time, but then becoming suddenly active when something is detected. These characteristics of sensor networks and applications motivate a MAC that is different from traditional wireless MACs such as IEEE 802.11 in almost every way: energy conservation and self-configuration are primary goals, while per-node fairness and latency are less important. S-MAC uses three novel techniques to reduce energy consumption and support self-configuration. To reduce energy consumption in listening to an idle channel, nodes periodically sleep. Neighboring nodes form virtual clusters to auto-synchronize on sleep schedules. Inspired by PAMAS, S-MAC also sets the radio to sleep during transmissions of other nodes. Unlike PAMAS, it only uses in-channel signaling. Finally, S-MAC applies message passing to reduce contention latency for sensor-network applications that require store-and-forward processing as data move through the network. We evaluate our implementation of S-MAC over a sample sensor node, the Mote, developed at University of California, Berkeley. The experiment results show that, on a source node, an 802.11-like MAC consumes 2-6 times more energy than S-MAC for traffic load with messages sent every 1-10 s.",
        "title": "An energy-efficient MAC protocol for wireless sensor networks",
        "venue": "international conference on computer communications",
        "year": 2002,
        "__v": 2,
        "citationCount": 2377
    },
    {
        "authors": [
            "Alan R. Hevner",
            "Salvatore T. March",
            "Jinsoo Park",
            "Sudha Ram"
        ],
        "references": [
            "1a0748e8-7784-4443-85ce-24b0bb7b10dc",
            "1aadbbb6-93df-48fb-92dc-5bac61391316",
            "1c95d184-179f-44d1-88a8-5fab9e567e69",
            "207b6ea8-acd9-4479-8543-f46f9c73cbec",
            "2819d0c5-ecb8-47bf-a039-6ae12e308990",
            "2d629e02-11eb-472f-880f-e66813d1f8d0",
            "33d6dabd-c086-4a6e-939a-c322b6ada724",
            "349b1a29-5e0f-421e-b4f7-5290441be737",
            "34e244ae-84ef-4c21-a09d-b0e8384d976c",
            "3b15b0a1-c6a2-4660-8b7a-e44a74c6783d",
            "41de53c6-ae14-4507-80df-56c80dbaca18",
            "42adc492-2606-43c9-af6d-43bd4264d939",
            "42cf5b6d-b65f-4ae1-b9bd-81165896db95",
            "44d2324a-d9dc-472e-a4fc-e0644b5609e1",
            "50468a24-0fa9-45a8-a341-3a61c91af35a",
            "55571c5a-e9c9-40b8-a4b4-0b706f7e82ec",
            "5d7a48c5-605f-45df-856c-7053120194fc",
            "6583dbde-1c44-439f-a6ca-a8e2df87bf82",
            "7b05662e-0286-4000-bab6-ff33c5bb148b",
            "7e88ab32-1149-48e7-a1be-ef76f9a6acbd",
            "7ee0fa98-5997-45fd-8be9-590cac338cc2",
            "7ef21340-0ea9-4835-a1e1-e2b2c9890a5e",
            "818d5415-3f96-4533-86ce-8439aadedc72",
            "8323156f-9f08-4bb2-9c3a-9a0642beb2a5",
            "86a5e25c-9baf-4e34-add5-b9dc543e54fc",
            "8b8804d5-a240-4134-bc87-01c6ac4b68c3",
            "91d002d5-e891-4cf3-ac94-d2aca279fe03",
            "91dc1d1f-6803-44ec-8d93-073db4ba289f",
            "9685b232-5492-4c1b-a76a-c087e105c1ab",
            "9b19a579-dc25-4dc8-8139-fd9f264983ac",
            "9f6dfbd6-c3cf-40c2-9187-ac2460ca2b19",
            "afd63c47-1b9b-4ca0-8693-e8f3efd61b64",
            "b0d91fa2-50f4-4380-8cf5-558fb08e3644",
            "b4f3c77c-33dd-46a6-8745-342bdb72546a",
            "b541380f-8e36-4fd8-91b3-04cf1f8d2736",
            "b9282b89-c224-453b-bb4a-40254b6cf8a9",
            "ba76c3e1-dbba-479f-8b50-e27299668d51",
            "bf22519c-7596-44b7-8102-7256ab462fbb",
            "c4311469-79c7-4253-bf67-1eab02723305",
            "c86c217e-0e21-44cb-82a9-ddb68399d34d",
            "c8a77118-2518-4b98-85cc-f6024215f2de",
            "d169eecc-adbe-4278-b9e6-106aa543b0f7",
            "d2762077-af8d-406e-9a01-51b8747f7ea7",
            "d2f8e7b6-6290-486c-981b-44db12bce30e",
            "db3f8780-9cce-4d22-81f7-84aef42bcedb",
            "df4bbccc-151a-4e2e-a62a-c25e6db9e6ee",
            "e186ea05-4dac-48cc-8710-6290edc2a3d1",
            "e56598ba-3d5a-4413-ba28-e92afd3a7b49",
            "e5767879-f411-46ae-9e47-be1dc2b893ec",
            "e84f8f3a-e60f-4f6e-82a3-1d0bf40f9922",
            "e986651a-4554-4c1e-a86b-97d89d56020d",
            "eadb780b-eac5-4cc7-ada6-eadd74cfe027",
            "eafe9070-ec42-4439-96db-5e2cf7d3a0f7",
            "eba77fc3-7b23-427b-b01d-48aac84e364a",
            "ee3f66e5-6921-4320-9125-944eb33a04f1",
            "f1501991-4872-4fd8-bc0e-3e16e4cfa7e0",
            "f578c7a8-aceb-4bdf-ac64-70b5a815463b",
            "f686ddf0-8e02-4edf-9f36-1c266a88b098",
            "fe2918f3-a823-44cc-ae45-5ae902336497"
        ],
        "keyword": [
            "research",
            "paradigms",
            "designscience",
            "understanding",
            "systems",
            "seeks",
            "science",
            "performance",
            "organizational",
            "information"
        ],
        "group": [
            {
                "55571c5a-e9c9-40b8-a4b4-0b706f7e82ec": {
                    "authors": [
                        "Veda C. Storey",
                        "Roger H. L. Chiang",
                        "Debabrata Dey",
                        "Robert C. Goldstein",
                        "Shankar Sudaresan"
                    ],
                    "references": [
                        "000d9c65-b685-4908-b5ae-885a4e0acc6e",
                        "0ef09ac5-089a-40c3-806f-1282eb8cd9f5",
                        "18cb0a40-9026-42c2-be9b-4e54fca6251a",
                        "1932a180-172a-4031-ae93-9296abf8ca32",
                        "30991cbc-af1e-4a29-b5ff-d5de5568f6e4",
                        "32c1945c-8865-482a-9849-b9048c634e4c",
                        "3c58fab2-684b-41dd-ac58-d94b6a3e8b8e",
                        "42f84c77-f1b0-48f3-ab11-07ab7f12b557",
                        "505db261-0585-409e-8264-18b7dbe7d890",
                        "598262fa-aa3d-4b51-a653-d1d46ea9a992",
                        "649d4741-dacc-4f72-9791-3b9280d8c6fe",
                        "67748140-c7e0-4ed0-abb6-42c6659ba4f6",
                        "86f29f55-be4b-4952-aff0-4cd1d0e3d133",
                        "94584b62-bbde-42f3-9472-e7f1ac37fe50",
                        "a9a43aae-965f-4adb-8720-aa5cc0f9baad",
                        "b82a831d-20af-4088-86c3-443752add44b",
                        "b9796f86-4c36-410f-9c41-c45eccd0e7b7",
                        "d1c02eba-6883-455c-a3df-91fae59c7d2e",
                        "e298ffe9-16b8-465a-92ef-ff427472a8a2",
                        "f47687ef-397f-4414-96e1-97d0b5cd43b0",
                        "f9298ed7-645e-4d82-afe5-e1e8dc43754c"
                    ],
                    "keyword": [
                        "knowledge",
                        "design",
                        "database",
                        "systems",
                        "reasoner",
                        "facts",
                        "domains",
                        "developed",
                        "business",
                        "base"
                    ],
                    "group": [],
                    "_id": "55571c5a-e9c9-40b8-a4b4-0b706f7e82ec",
                    "abstract": "Automated database design systems embody knowledge about the database design process. However, their lack of knowledge about the domains for which databases are being developed significantly limits their usefulness. A methodology for acquiring and using general world knowledge about business for database design has been developed and implemented in a system called the Common Sense Business Reasoner, which acquires facts about application domains and organizes them into a a hierarchical, context-dependent knowledge base. This knowledge is used to make intelligent suggestions to a user about the entities, attributes, and relationships to include in a database design. A distance function approach is employed for integrating specific facts, obtained from individual design sessions, into  the knowledge base (learning) and for applying the knowledge to subsequent design problems (reasoning).",
                    "title": "Database design with common sense business reasoning and learning",
                    "venue": "ACM Transactions on Database Systems",
                    "year": 1997,
                    "__v": 1,
                    "citationCount": 24,
                    "result": 5.624561824484423
                },
                "5d7a48c5-605f-45df-856c-7053120194fc": {
                    "authors": [
                        "Wanda J. Orlikowski",
                        "C. Suzanne Iacono"
                    ],
                    "references": [
                        "1014c457-be27-4c1b-b460-f83e82bff2fb",
                        "190faa88-5e48-4bc1-9676-78535905e7e1",
                        "1d43ecb6-6cca-40d5-968c-fb51dd83e6cf",
                        "2852b223-0cb8-44a0-9213-72126a1de04a",
                        "58e82047-ff87-4984-b337-f5dfaf3daa6f",
                        "6f793a28-8968-4d29-a5bf-8c5a0fbd302e",
                        "7e88ab32-1149-48e7-a1be-ef76f9a6acbd",
                        "c74f65fd-c7b0-4b06-baf0-2e31803fa71c",
                        "e0d06b4d-9064-4f7c-9b20-d8811d62beb5",
                        "fe2918f3-a823-44cc-ae45-5ae902336497"
                    ],
                    "keyword": [
                        "technology",
                        "research",
                        "information",
                        "artifact",
                        "field",
                        "context",
                        "systems",
                        "significance",
                        "propose",
                        "find"
                    ],
                    "group": [],
                    "_id": "5d7a48c5-605f-45df-856c-7053120194fc",
                    "abstract": "The field of information systems is premised on the centrality of information technology in everyday socio-economic life. Yet, drawing on a review of the full set of articles published inInformation Systems Research ( ISR) over the past ten years, we argue that the field has not deeply engaged its core subject matter--the information technology (IT) artifact. Instead, we find that IS researchers tend to give central theoretical significance to the context (within which some usually unspecified technology is seen to operate), the discrete processing capabilities of the artifact (as separable from its context or use), or the dependent variable (that which is posited to be affected or changed as technology is developed, implemented, and used). The IT artifact itself tends to disappear from view, be taken for granted, or is presumed to be unproblematic once it is built and installed. After discussing the implications of our findings, we propose a research direction for the IS field that begins to take technology as seriously as its effects, context, and capabilities. In particular, we propose that IS researchers begin to theorize specifically about IT artifacts, and then incorporate these theories explicitly into their studies. We believe that such a research direction is critical if IS research is to make a significant contribution to the understanding of a world increasingly suffused with ubiquitous, interdependent, and emergent information technologies.",
                    "title": "Research Commentary: Desperately Seeking the IT in IT Research--A Call to Theorizing the IT Artifact",
                    "venue": "Information Systems Research",
                    "year": 2001,
                    "__v": 2,
                    "citationCount": 751,
                    "result": 8.502194703091952
                },
                "6583dbde-1c44-439f-a6ca-a8e2df87bf82": {
                    "authors": [
                        "Jesper M. Johansson",
                        "Salvatore T. March",
                        "J. David Naumann"
                    ],
                    "references": [
                        "31c0684d-f4a4-4115-832a-c40f7d1ee84c",
                        "42ba38eb-a833-49a8-8bca-fe04edaa2bdf",
                        "4396144a-f148-4ab1-bbbc-1a48ccacad35",
                        "50468a24-0fa9-45a8-a341-3a61c91af35a",
                        "93e189b3-a7a5-4d65-92bb-8b7d24dfa174",
                        "9685b232-5492-4c1b-a76a-c087e105c1ab",
                        "ad35e37d-feaf-4731-bf63-70f1e9e8d537",
                        "c136cb92-e037-4027-a8e9-7d5bc6c0220c",
                        "c3d3ec6b-e7f0-484a-8707-a3c47b809306",
                        "d1705bb3-741d-4aaf-809f-e3152dff7ac9",
                        "d2eab5e1-444e-47b6-9d8e-7b815ce1aea6",
                        "eee77e27-de4a-435a-83e5-45ec522b562b",
                        "fc1d9a98-5313-4e6f-bffd-63f6ac0aaaa5"
                    ],
                    "keyword": [
                        "design",
                        "processing",
                        "parallel",
                        "distributed",
                        "database",
                        "time",
                        "query",
                        "latency",
                        "effects",
                        "data"
                    ],
                    "group": [],
                    "_id": "6583dbde-1c44-439f-a6ca-a8e2df87bf82",
                    "abstract": "ABSTRACT#R##N##R##N#The design of responsive distributed database systems is a key concern for information systems managers. In high bandwidth networks latency and local processing are the most significant factors in query and update response time. Parallel processing can be used to minimize their effects, particularly if it is considered at design time. It is the judicious replication and placement of data within a network that enable parallelism to be effectively used. However, latency and parallel processing have largely been ignored in previous distributed database design approaches. We present a comprehensive approach to distributed database design that develops efficient combinations of data allocation and query processing strategies that take full advantage of parallelism. We use a genetic algorithm to enable the simultaneous optimization of data allocation and query processing strategies. We demonstrate that ignoring the effects of latency and parallelism at design time can result in the selection of unresponsive distributed database designs.",
                    "title": "Modeling Network Latency and Parallel Processing in Distributed Database Design",
                    "venue": "Decision Sciences",
                    "year": 2003,
                    "__v": 2,
                    "citationCount": 6,
                    "result": 6.180168490794507
                },
                "7e88ab32-1149-48e7-a1be-ef76f9a6acbd": {
                    "authors": [
                        "Andrew W. Trice",
                        "Randall Davis"
                    ],
                    "references": [
                        "084ac30d-401f-4e85-a121-aeedcd6877c8",
                        "1e2e692e-998d-41d8-b02e-436a68497ecf",
                        "1f45e4d9-2a66-406a-9305-7bf923c6d0dc",
                        "3324919c-b79e-401c-8b3b-3b7bc02e4f30",
                        "36cac293-ee33-4c1a-a9c7-0787a7c37bb0",
                        "530650e3-8b38-40d7-b775-9c977344e078",
                        "54f73b80-bd14-46e1-8435-9082cc7a82f5",
                        "5c8ceaa7-e743-456d-a4c4-9ed521cc8006",
                        "67e9b68e-553f-4218-96c0-5cae50683e56",
                        "884127f2-2585-44d6-8ad4-10e332c93db5",
                        "8e305f9f-f897-4856-97f1-64ba71764893",
                        "9027b908-a1fe-4126-bf1f-9c56e827af71",
                        "94944b18-fbdc-4c3c-b58d-bc23107a72a2",
                        "95053160-8923-43f4-9fd7-812a84463811",
                        "b75c0b61-7d06-4587-be47-10ca339751c8",
                        "bbf8f4c2-1d0d-4a4b-b92a-becade783c1f",
                        "d55b22d6-2cf2-48c2-ba9c-ae3cf440c3ad",
                        "d8292b19-e10f-4d4d-879a-6a397a1e9ef9"
                    ],
                    "keyword": [
                        "knowledge",
                        "bases",
                        "discrepancies",
                        "technique",
                        "heuristics",
                        "reconciling",
                        "problems",
                        "independent",
                        "developed",
                        "acquisition"
                    ],
                    "group": [],
                    "_id": "7e88ab32-1149-48e7-a1be-ef76f9a6acbd",
                    "abstract": "One of the major unsolved problems in knowledge acquisition is reconciling knowledge originating from different sources. This paper proposes a technique for reconciling knowledge in two independent knowledge bases, describes a working program built to implement that technique, and discusses an exploratory study for validating the technique. The technique is based on the use of heuristics for identifying and resolving discrepancies between the knowledge bases. Each heuristic developed provides detection and resolution procedures for a distinct variety of discrepancy in the knowledge bases. Sample discrepancies include using synonyms for the same term, conflicting rules, and extra reasoning steps. Discrepancies are detected and resolved through the use of circumstantial evidence available from the knowledge bases themselves and by asking sharply focussed questions to the experts responsible for the knowledge bases. The technique was tested on two independently developed knowledge bases designed to aid novice statisticians in diagnosing problems in linear regression models. The heuristics located a significant number of the discrepancies between the knowledge bases and assisted the experts in creating a consensus knowledge base for diagnosing multicollinearity problems. We argue that the task of identifying discrepancies between independent bodies of knowledge is an inevitable part of any large knowledge acquisition effort. Hence the heuristics developed in this work are applicable even when knowledge acquisition is not done by reconciling two complete knowledge bases. We also suggest that our approach can be extended to other knowledge representations such as frames and database schemas, and speculate about its potential application to other domains involving the reconciliation of knowledge, such as requirements determination, negotiation, and design.",
                    "title": "Heuristics for Reconciling Independent Knowledge Bases",
                    "venue": "Information Systems Research",
                    "year": 1993,
                    "__v": 2,
                    "citationCount": 5,
                    "result": 6.627540785742427
                },
                "818d5415-3f96-4533-86ce-8439aadedc72": {
                    "authors": [
                        "Akhil Kumar",
                        "J. Leon Zhao"
                    ],
                    "references": [
                        "01e1fae4-75e0-466c-bcb4-c94f317b6de2",
                        "17b5e0c3-26e6-4294-90f1-31e742264460",
                        "64472c04-d171-4b64-aef2-b21e9078d287",
                        "7afaa2af-a99d-4a9f-b81b-dc6e33790c93",
                        "849ed648-7648-4817-9201-f36cbc2bba96",
                        "a15c29fd-1835-4d47-909b-98b3897fdae8",
                        "d39138a4-c330-472e-a3a8-8027480f7efc",
                        "eadb780b-eac5-4cc7-ada6-eadd74cfe027",
                        "ed0341b0-66f2-4c68-a2bc-e2fa5acd828b",
                        "ff122013-7a95-4577-aa46-2c0fd3400523"
                    ],
                    "keyword": [
                        "routing",
                        "language",
                        "document",
                        "support",
                        "internet",
                        "electronic",
                        "commerce",
                        "extensible",
                        "commercial"
                    ],
                    "group": [],
                    "_id": "818d5415-3f96-4533-86ce-8439aadedc72",
                    "abstract": "Internet-based electronic commerce is becoming the next frontier of new business opportunities. However, commerce on the Internet is seriously hindered by the lack of a common language for collaborative commercial activities. Although Extensible Markup Language (XML) allows trading partners to exchange semantic information electronically, it does not provide support for document routing. In this paper, we describe various inter-organizational electronic commerce applications and discuss their needs for workflow support. Then, we propose a blueprint for XRL, an Extensible Routing Language that enables routing of commercial documents over the Internet and helps in creating truly intelligent documents. This routing language is simple, yet powerful enough to support flexible routing of documents in the Internet environment.",
                    "title": "Workflow support for electronic commerce applications",
                    "venue": "decision support systems",
                    "year": 2002,
                    "__v": 2,
                    "citationCount": 27,
                    "result": 4.616157131919056
                },
                "8323156f-9f08-4bb2-9c3a-9a0642beb2a5": {
                    "authors": [
                        "Sandeep Purao",
                        "Veda C. Storey",
                        "Taedong Han"
                    ],
                    "references": [
                        "000d9c65-b685-4908-b5ae-885a4e0acc6e",
                        "21fc80b2-bf4c-4000-8a7e-465e2432141f",
                        "244a27f0-e11d-46dd-b094-2d1a58f9381d",
                        "288106a6-f48d-44c2-98fb-bd4c257d6ff5",
                        "2ab8a117-e8a3-4886-a63d-bbc680efa523",
                        "2f53b167-06ed-4217-b520-7ac21ed02964",
                        "2fc313c9-b78e-4818-a9d4-5fe31f7fdaf8",
                        "41f23592-7546-4143-87df-a15bcd98ae1c",
                        "4b8e42cf-9795-40a8-bbfa-fe3b84f066ec",
                        "50189eb4-52fc-4a6a-86ee-6a7b279e1e4e",
                        "5690960f-ca5d-4ef2-8ffa-ffa1072a23a4",
                        "58776de1-b258-43c5-8210-5587fd5df7be",
                        "593bb176-2e01-43fb-90fe-930b9b4d4b89",
                        "797343b9-4eea-4172-98e7-62a6c3537032",
                        "79c7f24e-361c-4259-ba08-b78930a59709",
                        "7f4872b0-d490-4ea5-9a08-514a1f7ee324",
                        "a908c540-e64a-4e39-a213-a6d7aec3ebad",
                        "dc82fd5a-e36c-4ab2-8c39-3fd4fbb59a80",
                        "e14273da-8a8e-4dd9-ac19-0596459e3a73",
                        "e6926e5f-2bcf-4fa3-b9e7-3a6a0f055be3",
                        "eff9adf0-c70b-42cc-9d6d-47ec62958c23",
                        "f6347ba2-8fee-4ee6-a2ef-2aedc9c2d2d3"
                    ],
                    "keyword": [
                        "design",
                        "conceptual",
                        "learning",
                        "reuse",
                        "patterns",
                        "methodology",
                        "development",
                        "benefit",
                        "analysis",
                        "tasks"
                    ],
                    "group": [],
                    "_id": "8323156f-9f08-4bb2-9c3a-9a0642beb2a5",
                    "abstract": "Conceptual design is an important, but difficult, phase of systems development. Analysis patterns can greatly benefit this phase because they capture abstractions of situations that occur frequently in conceptual modeling. NaA¯ve approaches to automate conceptual design with reuse of analysis patterns have had limited success because they do not emulate the learning that occurs over time. This research develops learning mechanisms for improving analysis pattern reuse in conceptual design. The learning mechanisms employ supervised learning techniques to support the generic reuse tasks of retrieval, adaptation, and integration, and emulate expert behaviors of analogy making and designing by assembly. They are added to a naA¯ve approach and the augmented methodology implemented as an intelligent assistant to a designer for generating an initial conceptual design that a developer may refine. To assess the potential of the methodology to benefit practice, empirical testing is carried out on multiple domains and tasks of different sizes. The results suggest that the methodology has the potential to benefit practice.",
                    "title": "Improving Analysis Pattern Reuse in Conceptual Design: Augmenting Automated Processes with Supervised Learning",
                    "venue": "Information Systems Research",
                    "year": 2003,
                    "__v": 2,
                    "citationCount": 44,
                    "result": 6.107527542976456
                },
                "86a5e25c-9baf-4e34-add5-b9dc543e54fc": {
                    "authors": [
                        "Amit Basu",
                        "Robert W. Blanning"
                    ],
                    "references": [
                        "0a859a3d-323d-42b7-a501-41d9a19d0759",
                        "0d261b6a-c94a-4d5e-b44e-eb6ae46581fc",
                        "35570a69-ca0c-4c6e-a809-86bafacaddba",
                        "42904222-e2f8-4a17-b7d9-067917cc2eb9",
                        "42ea6086-62ba-4bfa-b59c-4e454c848818",
                        "4301e0d9-b3fe-4e15-a6f1-2d801b46b01e",
                        "5607ae79-0e2e-4b5b-8b96-f20063dc2e6f",
                        "56a32270-caed-4a98-a874-55b1cc94b969",
                        "5bde98b7-c3e0-47f9-8b94-b0152b0ae4f3",
                        "5e40d0b0-f596-4042-b856-d5b91c0d0e28",
                        "631574d8-94a0-4ce5-81af-c39fe0ebd66a",
                        "64472c04-d171-4b64-aef2-b21e9078d287",
                        "6f5d242d-238c-4a80-b80e-c053d91aae85",
                        "a1981834-8d32-4f46-b1f2-9b2597b297d4",
                        "ad66922a-94dd-444c-985e-102f668180be",
                        "c27c5287-c8a0-4a16-b0e6-f80f82e3a15a",
                        "cb83fb41-2c57-4933-aaee-5b4110423077"
                    ],
                    "keyword": [
                        "workflows",
                        "processes",
                        "systems",
                        "information",
                        "tasks",
                        "organization",
                        "rise",
                        "organizational",
                        "managers",
                        "elements"
                    ],
                    "group": [],
                    "_id": "86a5e25c-9baf-4e34-add5-b9dc543e54fc",
                    "abstract": "Agile manufacturing, fast-response micromarketing, and the rise of the virtual organization have led managers to focus on cross-functional business processes that link various divisions and organizations. These processes may be realized as one or more workflows, each of which is an instantiation of a process under certain conditions. Because an ability to adapt processes to workflow conditions is essential for organizational responsiveness, identifying and analyzing significant workflows is an important activity for managers, organization designers, and information systems specialists. A variety of software systems have been developed to aid in the structuring and implementation of workflow systems, but they are mostly visualization tools with few analytical capabilities. For example, they do not allow their users to easily determine which information elements are needed to compute other information elements, whether certain tasks depend on other tasks, and how resource availability affects information and tasks. Analyses of this type can be performed by inspection, but this gives rise to the possibility of error, especially in large systems. In this paper, we show how a mathematical construct called a metagraph can be used to represent workflows, so that such questions can be addressed through formal operations, leading to more effective design of organizational processes.",
                    "title": "A Formal Approach to Workflow Analysis",
                    "venue": "Information Systems Research",
                    "year": 2000,
                    "__v": 2,
                    "citationCount": 57,
                    "result": 10.003454825860937
                },
                "8b8804d5-a240-4134-bc87-01c6ac4b68c3": {
                    "authors": [
                        "Dinesh Batra",
                        "J. A. Hoffler",
                        "Robert P. Bostrom"
                    ],
                    "references": [
                        "3654034f-cfd9-4261-99f4-2782e8130e9b",
                        "3cdc4189-d6fb-402b-af37-f2e049b528a1",
                        "42ef7bbd-7370-4e33-bfef-776b94137618",
                        "4e9c347b-0852-495a-8fc4-59c0c5dd0a55",
                        "5c51aca5-e5e2-45b5-8d0f-075065b0fab3",
                        "7d1e260d-f029-45e1-b3ae-7be84d7f4420",
                        "7fbd753d-0eb3-46b7-af75-7506a743410e",
                        "93812939-66d9-4b0b-9137-d08f62dea283",
                        "9967cd2b-0616-49e6-85f9-21b972d2580d",
                        "a2d095fb-cb2c-4658-9156-85a7e5953082",
                        "bcaeffd8-2b75-4d94-b5a6-9c268df866f9",
                        "c5ec7fe8-adea-47ec-95fe-b05344b47fc6",
                        "cdc52fea-7bea-4795-8f56-60ae8ac38364",
                        "e930195e-baa4-4d42-9d5f-e042fcaf5a9e",
                        "f28260d0-1e07-4187-b900-c852ee1955b0",
                        "f5a9c9bf-824a-4290-b5d8-69dac9dc63bb"
                    ],
                    "keyword": [
                        "systems",
                        "users",
                        "technology",
                        "raises",
                        "quality",
                        "issues",
                        "information",
                        "efficiency",
                        "diffusion",
                        "develop"
                    ],
                    "group": [],
                    "_id": "8b8804d5-a240-4134-bc87-01c6ac4b68c3",
                    "abstract": "The diffusion of technology to end users who can now develop their own information systems raises issues concerning the cost, quality, efficiency, and accuracy of such systems.",
                    "title": "Comparing representations with relational and EER models",
                    "venue": "Communications of The ACM",
                    "year": 1990,
                    "__v": 1,
                    "citationCount": 113,
                    "result": 7.458763770292915
                },
                "91d002d5-e891-4cf3-ac94-d2aca279fe03": {
                    "authors": [
                        "Hemant K. Bhargava",
                        "Ramayya Krishnan",
                        "Peter Piela"
                    ],
                    "references": [
                        "00ec2a93-ebec-4fe1-b564-0b004e56ffc1",
                        "09512e32-2003-40b3-b2d1-7c2dfc56c7c6",
                        "199560bb-cd8d-4297-89b1-9f975643b7c3",
                        "21f83041-72f5-4e21-bff3-b9e4742194e5",
                        "3269610c-fecb-47f0-b15c-03a536cbb7d6",
                        "4cdc38d4-b8ea-40b9-b2e5-4f9d99b9a453",
                        "50689679-8346-48f2-8d70-4dfd29f8b470",
                        "525418be-4b9b-458e-8e70-21ba0bf7c8ab",
                        "5945a181-08d6-4081-bb74-184f8e91c492",
                        "6ff9d8c9-c44c-472e-a9d6-1d0905a34efe",
                        "7659d5cc-9c55-4410-a177-2abf20188d1b",
                        "7c59931e-f1e7-4ca4-8262-1303b45e7c97",
                        "9aa032c9-f07b-4be3-98b1-09f59c43e5e4",
                        "a662a4e7-415e-417e-8a8f-fe085d7e487f",
                        "bacb73ba-17d6-4033-87a1-622d9fcafe67",
                        "c005e7a9-2c99-4340-abe3-aa5d5e2d7071",
                        "ccf8c835-3516-46f5-9d7b-c7992ee58678",
                        "e2011786-f659-4cce-8a97-3a61e8c4f9c0",
                        "e99d274c-a5ce-4395-9955-cd7f3d8122bc"
                    ],
                    "keyword": [
                        "modeling",
                        "typing",
                        "language",
                        "mathematical",
                        "strong",
                        "ascend",
                        "system",
                        "properties",
                        "operators",
                        "develop"
                    ],
                    "group": [],
                    "_id": "91d002d5-e891-4cf3-ac94-d2aca279fe03",
                    "abstract": "The use of strong typing, exemplified in the Ascend modeling language, is a recent phenomenon in executable modeling languages for mathematical modeling. It is also one that has significant potential for improving the functionality of computer-based modeling environments. Besides being a strongly typed language, Ascend is unique in providing operators that allow dynamic type inference, a feature that has been shown to be useful in assisting model evolution and reuse. We develop formal semantics for the type system in Ascend-focusing on these operators-and analyze its mathematical and computational properties. We show that despite the strong interactions between various statements involving the operators, the language does possess certain desirable mathematical and computational properties. Further, our analysis identifies general issues in the design and implementation of type systems in mathematical modeling languages. The methods used in the article are applicable beyond Ascend to a class of typed modeling languages that may be developed in the future.",
                    "title": "On Formal Semantics and Analysis of Typed Modeling Languages: An Analysis of Ascend",
                    "venue": "Informs Journal on Computing",
                    "year": 1998,
                    "__v": 1,
                    "citationCount": 2,
                    "result": 7.165770933572791
                },
                "91dc1d1f-6803-44ec-8d93-073db4ba289f": {
                    "authors": [
                        "Marvin V. Zelkowitz",
                        "Dolores R. Wallace"
                    ],
                    "references": [
                        "4c1c86de-d732-42fa-a7e1-e801ff97daba",
                        "5a9dd9da-27d9-44be-b5c3-329f8c3ee1c0",
                        "83d54f51-723b-4ab2-9ef7-b844797dacc1",
                        "a0832e58-0b98-4cb0-bdc9-d806deda8b9f"
                    ],
                    "keyword": [
                        "experimentation",
                        "methods",
                        "developed",
                        "validity",
                        "theories",
                        "taxonomy",
                        "software",
                        "effectiveness",
                        "determine",
                        "twelve"
                    ],
                    "group": [],
                    "_id": "91dc1d1f-6803-44ec-8d93-073db4ba289f",
                    "abstract": "Experimentation helps determine the effectiveness of proposed theories and methods. However, computer science has not developed a concise taxonomy of methods for demonstrating the validity of new techniques. Experimentation is a crucial part of attribute evaluation and can help determine whether methods used in accordance with some theory during product development will result in software being as effective as necessary. By looking at multiple examples of technology validation, the authors develop a taxonomy for software engineering experimentation that describes twelve different experimental approaches.",
                    "title": "Experimental models for validating technology",
                    "venue": "IEEE Computer",
                    "year": 1998,
                    "__v": 1,
                    "citationCount": 192,
                    "result": 4.9025063091936145
                },
                "9685b232-5492-4c1b-a76a-c087e105c1ab": {
                    "authors": [
                        "Salvatore T. March",
                        "Alan R. Hevner",
                        "Sudha Ram"
                    ],
                    "references": [
                        "132b85cf-7fb8-4f4d-8819-d79eba4c1d4a",
                        "20753f95-f8b8-4b61-a9b1-eb4a8edd3842",
                        "21e8be89-d52c-4b1a-b0b2-675e2bea0f94",
                        "2a5ec054-7c04-44ea-b0f1-b46c9a569b8d",
                        "2e4e507b-bf78-45ae-889f-27a3d7296ae4",
                        "34aa6228-4531-40c1-950d-bfdcbbe97e6e",
                        "4bed09ab-4449-4003-8af6-c8dd8aac1471",
                        "54d57e60-b80b-43f0-bd23-3acb5517ac16",
                        "55571c5a-e9c9-40b8-a4b4-0b706f7e82ec",
                        "5f8c58ce-c657-47fc-96f1-baac917fea5a",
                        "61749bfb-5291-4e89-87fa-b7b03b595f83",
                        "620150d0-8acf-467e-b69d-dd831c5b59c9",
                        "6598199d-6009-4036-bd07-0800eaa6117f",
                        "65eea2ae-34c0-46f9-8078-6cffc820781c",
                        "77086361-1614-442a-a07d-d8a924b6f357",
                        "7a5d7de4-3fd7-4dc4-a67c-cce499cda760",
                        "7c0e4a87-d78c-41ea-8822-4c75d3b826b8",
                        "8de391d6-0d44-4558-a9d8-4ced86e55181",
                        "908d6d8e-4e77-4b8c-acdb-ac3aab11b048",
                        "953127b5-2333-4980-99c8-597de0750fa6",
                        "a01a3be3-ea48-4e41-a223-960f6b893938",
                        "acd39e2e-4fc5-4276-a792-e74f7de3eed2",
                        "adea5377-3a51-4831-add5-80ebf31685e1",
                        "b02c3681-31e5-462e-bdfd-ba6dba31b389",
                        "b553aa12-2811-417c-9849-cd0e3fa5b558",
                        "b6a2d407-f19d-49ea-a7cc-3fc955db1ccc",
                        "bdd7ef6f-d4c3-4078-a143-805667dc71a0",
                        "c8a77118-2518-4b98-85cc-f6024215f2de",
                        "d1097be3-d6dd-4d3e-ab11-d2cf843569d2",
                        "d3c5fc62-2f5b-4ab2-a321-564ef9232643",
                        "daef850c-4981-4eb3-8ec3-f50ae45fff46",
                        "e520ee12-4e7a-423b-a131-d07608947f73",
                        "f38a52f7-849d-4890-90a0-2328227857ba",
                        "f47687ef-397f-4414-96e1-97d0b5cd43b0",
                        "fa02ed32-f986-4f85-904b-ce78d6b0f278",
                        "fe8230ef-0a66-4be8-8807-1d0c9cce994a",
                        "ff2867cd-26aa-4a73-b474-452c8ae14bd2"
                    ],
                    "keyword": [
                        "research",
                        "science",
                        "organizations",
                        "computer",
                        "systems",
                        "environments",
                        "challenges",
                        "addressing"
                    ],
                    "group": [],
                    "_id": "9685b232-5492-4c1b-a76a-c087e105c1ab",
                    "abstract": "Application-driven, technology-intensive research is critically needed to meet the challenges of globalization, interactivity, high productivity, and rapid adaptation faced by business organizations. Information systems researchers are uniquely positioned to conduct such research, combining computer science, mathematical modeling, systems thinking, management science, cognitive science, and knowledge of organizations and their functions. We present an agenda for addressing these challenges as they affect organizations in heterogeneous and distributed environments. We focus on three major capabilities enabled by such environments: Mobile Computing, Intelligent Agents, and Net-Centric Computing. We identify and define important unresolved problems in each of these areas and propose research strategies to address them.",
                    "title": "Research Commentary: An Agenda for Information Technology Research in Heterogeneous and Distributed Environments",
                    "venue": "Information Systems Research",
                    "year": 2000,
                    "__v": 2,
                    "citationCount": 66,
                    "result": 8.986813634884797
                },
                "9f6dfbd6-c3cf-40c2-9187-ac2460ca2b19": {
                    "authors": [
                        "Victor R. Basili"
                    ],
                    "references": [
                        "428adab0-e700-410c-ab1f-07face240174",
                        "4c1c86de-d732-42fa-a7e1-e801ff97daba",
                        "5e6ba10f-32c8-45c5-8e2d-52f5fc53c5f5",
                        "68734730-8262-47e2-a8a1-6d67cbdf32f8",
                        "83d54f51-723b-4ab2-9ef7-b844797dacc1",
                        "8d3d2fbb-64a3-49bb-96b2-fd349669457f",
                        "fd6f8b28-b44d-4b03-80f8-9a5f38811528"
                    ],
                    "keyword": [
                        "paradigm",
                        "experimental",
                        "develop",
                        "paper",
                        "improvement",
                        "approach",
                        "software",
                        "sciences",
                        "scheme",
                        "role"
                    ],
                    "group": [],
                    "_id": "9f6dfbd6-c3cf-40c2-9187-ac2460ca2b19",
                    "abstract": "Software engineering needs to follow the model of other physical sciences and develop an experimental paradigm for the field. This paper proposes the approach towards developing an experimental component of such a paradigm. The approach is based upon a quality improvement paradigm that addresses the role of experimentation and process improvement in the content of industrial development. The paper outlines a classification scheme for characterizing such experiments.",
                    "title": "The role of experimentation in software engineering: past, current, and future",
                    "venue": "international conference on software engineering",
                    "year": 1996,
                    "__v": 2,
                    "citationCount": 116,
                    "result": 6.327480345218263
                },
                "afd63c47-1b9b-4ca0-8693-e8f3efd61b64": {
                    "authors": [
                        "Heinz K. Klein",
                        "Michael D. Myers"
                    ],
                    "references": [
                        "0ef31fea-209f-4e05-960c-706930439441",
                        "0f2797aa-3a4e-4d8b-99ca-2d0a93863034",
                        "10b22a78-c007-42ee-8884-497a2d016c5a",
                        "5ae09a19-ab9e-4525-9ede-3c8dae340dbc",
                        "5e6ba10f-32c8-45c5-8e2d-52f5fc53c5f5",
                        "6f793a28-8968-4d29-a5bf-8c5a0fbd302e",
                        "756a7555-f85d-4746-a649-83df25cef8ff",
                        "8529a0cd-9bb0-4f4e-a8b9-4de3881c9fde",
                        "879d076a-c53e-46a3-94f9-16c3d76ca945",
                        "a1669534-7f2a-4a12-90ee-a7b3e1f2258e",
                        "b97c62a1-8d95-4ada-a438-a1a9b78f7c68",
                        "c23d9b8a-2537-4d63-a928-247c7e7f621a",
                        "ce24db8b-6855-42b6-b78a-576d4bc85473",
                        "d5e061a5-185d-49b4-9cc1-013feb6c6c9d"
                    ],
                    "keyword": [
                        "interpretive",
                        "research",
                        "systems",
                        "studies",
                        "information",
                        "field",
                        "evaluating",
                        "conduct",
                        "science",
                        "principles"
                    ],
                    "group": [],
                    "_id": "afd63c47-1b9b-4ca0-8693-e8f3efd61b64",
                    "abstract": "This article discusses the conduct and evaluatoin of interpretive research in information systems. While the conventions for evaluating information systems case studies conducted according to the natural science model of social science are now widely accepted, this is not the case for interpretive field studies. A set of principles for the conduct and evaluation of interpretive field research in information systems is proposed, along with their philosophical rationale. The usefulness of the principles is illustrated by evaluating three published interpretive field studies drawn from the IS research literature. The intention of the paper is to further reflect and debate on the important subject of grounding interpretive research methodology.",
                    "title": "A set of principles for conducting and evaluating interpretive field studies in information systems",
                    "venue": "Management Information Systems Quarterly",
                    "year": 1999,
                    "__v": 2,
                    "citationCount": 1313,
                    "result": 10.791453769529552
                },
                "b4f3c77c-33dd-46a6-8745-342bdb72546a": {
                    "authors": [
                        "Gary W. Dickson",
                        "Joo-Eng Lee Partridge",
                        "Lora Robinson"
                    ],
                    "references": [
                        "187ebf8e-b27c-495e-bb41-93044886ee8c",
                        "3b60724c-4fe7-4bed-9c6a-88bc9b8bf6fe",
                        "42cf5b6d-b65f-4ae1-b9bd-81165896db95",
                        "489664b9-2155-4758-9ede-356c822ef8e5",
                        "58e82047-ff87-4984-b337-f5dfaf3daa6f",
                        "77cd8a11-82b6-4575-907a-2f79db93da4d",
                        "8a79ddbd-1ca4-4eb7-94f3-f702d4999715",
                        "9faeeb6f-56c6-411b-99d7-6d6f6dd7f135",
                        "b679f16b-1efd-4f77-889f-b6339d721014",
                        "c4311469-79c7-4253-bf67-1eab02723305",
                        "c4fe01fe-2ff8-4be1-90a7-c62cc486d0a9",
                        "d62dabf7-895f-41db-9240-459ad35f4a46"
                    ],
                    "keyword": [
                        "support",
                        "facilitative",
                        "group",
                        "gdss",
                        "effectiveness",
                        "technology",
                        "research",
                        "users",
                        "task",
                        "systems"
                    ],
                    "group": [],
                    "_id": "b4f3c77c-33dd-46a6-8745-342bdb72546a",
                    "abstract": "The use of group decision support systems (GDSS) is rapidly growing. One key factor in the effectiveness of these systems may be the manner in which users are supported in their use of this technology. This paper explores two types of GDSS facilitative support: chauffeur-riven and facilitator-driven. In the former case, a person is used to reduce the mystique of the GDSS technology for users. In the latter case, a person assists the group with its group process in addition to reducing the mystique of the technology. The work unfolds a research story in which the original thinking of the research tem to the effect that facilitator-driven GDSS facilitative support is superior is proven incorrect. The results of a pilot study caused the research team to reverse its thinking and hypothesize that, given the nature of the facilitation used and the task faced by the group, chauffeur-driven facilitation would have an advantage. The results of the experiment reported in this paper support this hypothesis. Arguments are presented to the effect that, to be effective in a judgment task environment, facilitation must be open and adaptive rather than restrictive.",
                    "title": "Exploring modes of facilitative support for GDSS technology",
                    "venue": "Management Information Systems Quarterly",
                    "year": 1993,
                    "__v": 2,
                    "citationCount": 57,
                    "result": 5.787624113124945
                },
                "b541380f-8e36-4fd8-91b3-04cf1f8d2736": {
                    "authors": [
                        "William H. DeLone",
                        "Ephraim R. McLean"
                    ],
                    "references": [],
                    "keyword": [
                        "success",
                        "researchers",
                        "taxonomy",
                        "dimensions",
                        "studies",
                        "quality",
                        "organize",
                        "information",
                        "impact",
                        "elusive"
                    ],
                    "group": [],
                    "_id": "b541380f-8e36-4fd8-91b3-04cf1f8d2736",
                    "abstract": "A large number of studies have been conducted during the last decade and a half attempting to identify those factors that contribute to information systems success. However, the dependent variable in these studies-I/S success-has been an elusive one to define. Different researchers have addressed different aspects of success, making comparisons difficult and the prospect of building a cumulative tradition for I/S research similarly elusive. To organize this diverse research, as well as to present a more integrated view of the concept of I/S success, a comprehensive taxonomy is introduced. This taxonomy posits six major dimensions or categories of I/S success-SYSTEM QUALITY, INFORMATION QUALITY, USE, USER SATISFACTION, INDIVIDUAL IMPACT, and ORGANIZATIONAL IMPACT. Using these dimensions, both conceptual and empirical studies are then reviewed a total of 180 articles are cited and organized according to the dimensions of the taxonomy. Finally, the many aspects of I/S success are drawn together into a descriptive model and its implications for future I/S research are discussed.",
                    "title": "Information Systems Success: The Quest for the Dependent Variable",
                    "venue": "Information Systems Research",
                    "year": 1992,
                    "__v": 1,
                    "citationCount": 2141,
                    "result": 7.893744999933583
                },
                "ba76c3e1-dbba-479f-8b50-e27299668d51": {
                    "authors": [
                        "Salvatore T. March",
                        "Gerald F. Smith"
                    ],
                    "references": [
                        "3372fbfc-c6ed-40bf-94d2-82a1b1876589",
                        "42ba38eb-a833-49a8-8bca-fe04edaa2bdf",
                        "44d2324a-d9dc-472e-a4fc-e0644b5609e1",
                        "58e82047-ff87-4984-b337-f5dfaf3daa6f",
                        "5e6ba10f-32c8-45c5-8e2d-52f5fc53c5f5",
                        "648b7f48-23d3-42a5-97fd-8ffad352fec8",
                        "6f63269d-272e-4ad1-a551-8734dca7e62d",
                        "7d1e260d-f029-45e1-b3ae-7be84d7f4420",
                        "7e1eeb34-62a7-41b7-8c1d-9cce0b528102",
                        "8a93d770-1fff-48cd-a87d-32e519fe7daa",
                        "8b8804d5-a240-4134-bc87-01c6ac4b68c3",
                        "8eff2edb-63b9-462e-81e3-df4bf72a3bb0",
                        "a4468d5f-9680-469e-bad0-adc5b984fe16",
                        "ad3b42a6-f3ef-4b8b-867c-76df8738ad31",
                        "b5dd8da7-a605-4aab-b849-544763107038",
                        "b8c248c8-14dd-482d-9ad8-3b3506bc3a03",
                        "bacd65d3-a4e3-499b-9b30-81dbe60ea12b",
                        "bcaeffd8-2b75-4d94-b5a6-9c268df866f9",
                        "c5ec7fe8-adea-47ec-95fe-b05344b47fc6",
                        "ca42ec07-7069-40f9-a14a-73b220d53295",
                        "d1705bb3-741d-4aaf-809f-e3152dff7ac9",
                        "e52738ed-9702-4117-b7db-9052e88eceb6",
                        "e930195e-baa4-4d42-9d5f-e042fcaf5a9e",
                        "ff536a1a-8781-4d08-8d11-435e5ecf3712"
                    ],
                    "keyword": [
                        "research",
                        "natural",
                        "design",
                        "science",
                        "work",
                        "understanding",
                        "types",
                        "systems",
                        "solution",
                        "laws"
                    ],
                    "group": [],
                    "_id": "ba76c3e1-dbba-479f-8b50-e27299668d51",
                    "abstract": "Research in IT must address the design tasks faced by practitioners. Real problems must be properly conceptualized and represented, appropriate techniques for their solution must be constructed, and solutions must be implemented and evaluated using appropriate criteria. If significant progress is to be made, IT research must also develop an understanding of how and why IT systems work or do not work. Such an understanding must tie together natural laws governing IT systems with natural laws governing the environments in which they operate. This paper presents a two dimensional framework for research in information technology. The first dimension is based on broad types of design and natural science research activities: build, evaluate, theorize, and justify. The second dimension is based on broad types of outputs produced by design research: representational constructs, models, methods, and instantiations. We argue that both design science and natural science activities are needed to insure that IT research is both relevant and effective.",
                    "title": "Design and natural science research on information technology",
                    "venue": "decision support systems",
                    "year": 1995,
                    "__v": 2,
                    "citationCount": 876,
                    "result": 9.72255496053392
                },
                "d169eecc-adbe-4278-b9e6-106aa543b0f7": {
                    "authors": [
                        "Jay F. Nunamaker",
                        "Michael C. Chen"
                    ],
                    "references": [
                        "010efcae-5cb5-4790-85fe-3fa89554bdf8",
                        "0465cfac-c5d8-4e0d-b926-75171ff59bb5",
                        "26db4152-3ccf-4b7a-9b23-fc69cb5d220b",
                        "276a17eb-83c3-4da9-af4c-72101bd22408",
                        "2a933244-84bb-4d24-a79f-75ad659cae01",
                        "3c85cb2d-e921-4b22-bd64-9eaea427879b",
                        "53e16979-de42-4e10-9ccd-f8935f4457ac",
                        "5f97ba4a-f5f3-4822-9e08-6092fad2e2bb",
                        "636d33db-9a68-42d0-bdef-d7faede5d09a",
                        "9f141f8a-d30b-4151-964b-c29aa5fefb0a",
                        "a104b046-b056-4ab9-ad35-c9734d1c8d69",
                        "a3e4896d-df39-43fd-b75f-17d5f6e4dbf3",
                        "c4311469-79c7-4253-bf67-1eab02723305",
                        "e6934542-5c47-4a30-ab2e-d97842c0624a",
                        "f264e727-b5a8-4da7-8943-15feb4e4795d",
                        "fc6c10d8-5a3b-41da-bbda-b0016af969fb",
                        "fc760346-b345-40ec-a309-b9ac60777be4"
                    ],
                    "keyword": [
                        "research",
                        "systems",
                        "development",
                        "methodology",
                        "review",
                        "proposed",
                        "presented",
                        "framework",
                        "engineering",
                        "domain"
                    ],
                    "group": [],
                    "_id": "d169eecc-adbe-4278-b9e6-106aa543b0f7",
                    "abstract": "The authors critically review systems development in information systems (IS) research. Several classification schemes of research are described and systems development is identified as a developmental, engineering, and formulative type of research. A framework of research is proposed to explain the dual nature of systems development as a research methodology and a research domain in IS research. Progress in several disciplinary areas is reviewed to provide a basis to argue that systems development is a valid research methodology. A systems development research process is presented from a methodological perspective. Software engineering, the basic method is applying the systems development research methodology, is then discussed. A framework to classify IS research domain and various research methodologies in studying systems development is presented. It is suggested that systems development and empirical research methodologies are complementary to each other. It is further proposed that an integrated multidimensional and multimethodological approach will generate fruitful research results in IS research. >",
                    "title": "Systems development in information systems research",
                    "venue": "hawaii international conference on system sciences",
                    "year": 1990,
                    "__v": 2,
                    "citationCount": 295,
                    "result": 6.8763907923075145
                },
                "d2f8e7b6-6290-486c-981b-44db12bce30e": {
                    "authors": [
                        "Peter B. Seddon"
                    ],
                    "references": [
                        "1d2f5c2a-19fa-458e-affb-6e7961ae9b8d",
                        "2df731d1-37e4-4afb-a9b0-60a5361a79ff",
                        "6a5737b2-6b6e-4b6b-a536-7d2f71857606",
                        "81ed6312-e38a-469c-a757-685b2714df56",
                        "9d912297-e52f-4ab6-add4-633e0f263933",
                        "9da2f3bb-2b7f-48e1-86af-7e45c808bc49",
                        "b541380f-8e36-4fd8-91b3-04cf1f8d2736",
                        "d9430896-2615-4ed8-b9c5-be111fbac9ba"
                    ],
                    "keyword": [
                        "model",
                        "systems",
                        "success",
                        "mclean's",
                        "information",
                        "delone",
                        "confusing"
                    ],
                    "group": [],
                    "_id": "d2f8e7b6-6290-486c-981b-44db12bce30e",
                    "abstract": "DeLone and McLean's DeLone, W. H., E. R. McLean. 1992. Information systems success: The quest for the dependent variable. Inform. Systems Res.31 60--95. comprehensive review of different information system success measures concludes with a model of “temporal and causal” interdependencies between their six categories of IS Success. After working with this model for some years, it has become apparent that the inclusion of both variance and process interpretations in their model leads to so many potentially confusing meanings that the value of the model is diminished. Because of the confusion that this overloading of meanings can cause, this paper presents and justifies a respecified and slightly extended version of DeLone and McLean's model.",
                    "title": "A Respecification and Extension of the DeLone and McLean Model of IS Success",
                    "venue": "Information Systems Research",
                    "year": 1997,
                    "__v": 2,
                    "citationCount": 552,
                    "result": 5.940963871970109
                },
                "e186ea05-4dac-48cc-8710-6290edc2a3d1": {
                    "authors": [
                        "Milam W. Aiken",
                        "Olivia R. Liu Sheng",
                        "Douglas R. Vogel"
                    ],
                    "references": [
                        "18e7205b-b90d-4fff-bdc7-55abf66d2bbd",
                        "227bcc91-a10f-4d0e-92e1-e4ee79ae87d8",
                        "259600d4-c2ca-4876-90b7-fc0360275209",
                        "25daaa08-14bb-47fe-8027-29d805e2e4be",
                        "40e82bf1-aeeb-465d-aefc-1d0d2b3f8abb",
                        "58e82047-ff87-4984-b337-f5dfaf3daa6f",
                        "59827436-eb4d-47ec-a1dd-ca51d04e6d6e",
                        "5f97ba4a-f5f3-4822-9e08-6092fad2e2bb",
                        "68bdf75e-3747-469c-a5e4-ee9c38724402",
                        "6cb3a448-8ffe-4ed9-b8f5-dbf1c529eb70",
                        "8fd9aa19-5b11-48a2-a8dc-4cc75c36d8eb",
                        "95053160-8923-43f4-9fd7-812a84463811",
                        "a4a81e66-3930-43d2-bb45-2b0467624761",
                        "aa89be80-b100-469f-b60d-b47d0d317540",
                        "ad3b42a6-f3ef-4b8b-867c-76df8738ad31",
                        "b8d3bee2-5723-47c7-89a1-01c151fa1306",
                        "c4311469-79c7-4253-bf67-1eab02723305",
                        "cf678916-b823-47fe-82af-7b36ac5192b6",
                        "d62dabf7-895f-41db-9240-459ad35f4a46",
                        "dc7d31a4-7973-4229-84fe-e231e9ee8f08",
                        "f264e727-b5a8-4da7-8943-15feb4e4795d"
                    ],
                    "keyword": [
                        "systems",
                        "wide",
                        "group",
                        "expert",
                        "decision",
                        "work",
                        "variety",
                        "tools",
                        "technologies",
                        "synergies"
                    ],
                    "group": [],
                    "_id": "e186ea05-4dac-48cc-8710-6290edc2a3d1",
                    "abstract": "Expert systems are powerful tools that serve as adjuncts to decision making and have found wide applicability in a wide variety of areas. Integrating expert systems with group decision support systems has the potential to enhance the quality and effeciency of group communication, negotiation, and collaborative work. This paper examines possible synergies between the two technologies and provides a survey of current partially-integrated systems. Finally, a prototype design of a highly-integrated system is described with directions for further research.",
                    "title": "Integrating expert systems with group decision support systems",
                    "venue": "ACM Transactions on Information Systems",
                    "year": 1991,
                    "__v": 2,
                    "citationCount": 18,
                    "result": 5.648632665538754
                },
                "e5767879-f411-46ae-9e47-be1dc2b893ec": {
                    "authors": [
                        "M. Lynne Markus",
                        "Ann Majchrzak",
                        "Les Gasser"
                    ],
                    "references": [
                        "1d282693-16b8-4cd4-a230-7d1753b1f8a4",
                        "226a77aa-dbe1-4f60-b5fa-adc3c6806604",
                        "29f08f1d-565b-47dc-90d7-b1bef4e72a4f",
                        "2a992ee3-d2b8-40bd-82f2-d33459728fc9",
                        "405801cc-7dd8-47e5-bdbf-c722cdf02bfa",
                        "47f3271e-a9f1-4482-bee5-c2e997b698f2",
                        "4ceba8b8-3c48-4e28-8fe9-12b0b019da4f",
                        "5fb2451e-1897-4714-96b6-8b9b1fb7f05b",
                        "625a5543-62ef-418f-8b8d-9193cc2ee8e4",
                        "7a930898-68b5-4584-8d13-fb089e548f3f",
                        "af03585d-1de6-4196-adec-8e45d7d470d3",
                        "bf22519c-7596-44b7-8102-7256ab462fbb",
                        "ed5721c9-f096-4189-99d3-7a225e3e1545",
                        "eef093e5-6c82-427e-b85a-a87f5d075496",
                        "f43fae7f-9aaa-4328-960b-1ad57d558784",
                        "f61cb89f-729f-402a-8c3a-75277468e666",
                        "f8647e4d-8b60-440b-a7e3-3cdcbc785848",
                        "f99fe55e-4fb0-472f-ad97-06c18a5c6e65",
                        "fd56a094-0e11-46ea-9971-b270a3057973"
                    ],
                    "keyword": [
                        "systems",
                        "ekps",
                        "design",
                        "development",
                        "theory",
                        "support",
                        "processes",
                        "set"
                    ],
                    "group": [],
                    "_id": "e5767879-f411-46ae-9e47-be1dc2b893ec",
                    "abstract": "This paper addresses the design problem of providing IT support for emerging knowledge processes (EKPs). EKPs are organizational activity patterns that exhibit three characteristics in combination: an emergent process of deliberations with no best structure or sequence; requirements for knowledge that are complex (both general and situational), distributed across people, and evolving dynamically; and an actor set that is unpredictable in terms of job roles or prior knowledge. Examples of EKPs include basic research, new product development, strategic business planning, and organization design. EKPs differ qualitatively from semi-structured decision making processes; therefore, they have unique requirements that are not all thoroughly supported by familiar classes of systems, such as executive information systems, expert systems, electronic communication systems, organizational memory systems, or repositories. Further, the development literature on familiar classes of systems does not provide adequate guidance on how to build systems that support EKPs. Consequently, EKPs require a new IS design theory, as explicated by Walls et al. (1992).#R##N##R##N#We created such a theory while designing and deploying a system for the EKP of organization design. The system was demonstrated through subsequent empirical analysis to be successful in supporting the process. Abstracting from the experience of building this system, we developed an IS design theory for EKP support systems. This new IS design theory is an important theoretical contribution, because it both provides guidance to developers and sets an agenda for academic research. EKP design theory makes the development process more tractable for developers by restricting the range of effective features (or rules for selecting features) and the range of effective development practices to a more manageable set. EKP design theory also sets an agenda for academic research by articulating theory-based principles that are subject to empirical, as well as practical, validation.",
                    "title": "A design theory for systems that support emergent knowledge processes",
                    "venue": "Management Information Systems Quarterly",
                    "year": 2002,
                    "__v": 2,
                    "citationCount": 380,
                    "result": 5.309194589817196
                },
                "eadb780b-eac5-4cc7-ada6-eadd74cfe027": {
                    "authors": [
                        "van der Wmp Wil Aalst",
                        "Akhil Kumar"
                    ],
                    "references": [
                        "01705046-aa54-4f08-a1bd-d97e5ee8c690",
                        "01e1fae4-75e0-466c-bcb4-c94f317b6de2",
                        "17b5e0c3-26e6-4294-90f1-31e742264460",
                        "5bf62d6e-5777-4c9b-95f9-76ba9df4fa07",
                        "640b2ff5-c940-4eeb-b908-696eb93f38f4",
                        "64472c04-d171-4b64-aef2-b21e9078d287",
                        "6503615e-03b6-49e1-90e1-cdec07f75615",
                        "7afaa2af-a99d-4a9f-b81b-dc6e33790c93",
                        "83b30cd4-491b-4937-9735-67d84d31fd08",
                        "8d2ab0cb-9e94-43e4-97d3-65264fab644a",
                        "a11ce7f1-f247-42a0-bcec-803ff42407a4",
                        "a15c29fd-1835-4d47-909b-98b3897fdae8",
                        "a6e155ef-540f-47f5-806a-0c49e8737379",
                        "b03dcacb-276b-4184-b045-06aa4f128b18",
                        "b0dd02fe-a95a-40f4-8166-b1660699dead",
                        "bc95bc2a-f8df-406e-b19e-a62d14b17a3b",
                        "cec1c96f-74a2-49df-a101-9adc3d455f43",
                        "d09d5c1c-ce2d-42e3-ad7d-0bc8378c4849",
                        "d39138a4-c330-472e-a3a8-8027480f7efc",
                        "ed0341b0-66f2-4c68-a2bc-e2fa5acd828b",
                        "f4072fcc-c815-4861-8291-555fc0b9d857",
                        "f9a8290c-2f79-4ecf-a538-1928439367f9",
                        "ff122013-7a95-4577-aa46-2c0fd3400523"
                    ],
                    "keyword": [
                        "xrl",
                        "xml",
                        "workflow",
                        "route",
                        "partners",
                        "electronic",
                        "commerce",
                        "business",
                        "processes",
                        "language"
                    ],
                    "group": [],
                    "_id": "eadb780b-eac5-4cc7-ada6-eadd74cfe027",
                    "abstract": "The full potential of the Web as a medium for electronic commerce can be realized only when multiple partners in a supply chain can route information among themselves in a seamless way. Commerce on the Internet is still far from being \"friction free,\" because business partners cannot exchange information about their business processes in an automated manner. In this paper, we propose the design for aneXchangeable Routing Language (XRL) using eXtensible Markup Language (XML) syntax. XML is a means for trading partners to exchange business data electronically. The novel contribution of our work is to show how XML can also be used to describe workflow process schemas to support flexible routing of documents in the Internet environment. The design of XRL is grounded in Petri nets, which is a well-known formalism. By using this formalism, it is possible to analyze correctness and performance of workflows described in XRL. Architectures to facilitate interoperation through loose and tight integration are also discussed. Examples illustrate how this approach can be used for implementing interorganizational electronic commerce applications. As a proof of concept, we have also developedXRL/flower, a prototype implementation of a workflow management system based on XRL.",
                    "title": "XML-Based Schema Definition for Support of Interorganizational Workflow",
                    "venue": "Information Systems Research",
                    "year": 2003,
                    "__v": 2,
                    "citationCount": 106,
                    "result": 4.194365008916092
                },
                "ee3f66e5-6921-4320-9125-944eb33a04f1": {
                    "authors": [
                        "Viswanath Venkatesh"
                    ],
                    "references": [
                        "017d7159-547c-4627-9a45-d98331ed2892",
                        "05057282-4831-4793-adda-7abb31e3f0f1",
                        "0a5567c5-7a18-4e16-9f53-a79c9f21e32d",
                        "1014c457-be27-4c1b-b460-f83e82bff2fb",
                        "123c0f7a-4341-4a95-bb80-824a969eda20",
                        "22c866d0-81fe-4011-8149-676ac1fa02b8",
                        "2df731d1-37e4-4afb-a9b0-60a5361a79ff",
                        "35db08aa-da18-443d-a17f-bbfdefd6097a",
                        "3bac5d08-74d8-4776-b976-c80acffe44d7",
                        "42d8e3d9-b3ce-430d-8361-a8a5225311eb",
                        "46c466a0-4c5f-4184-808a-4a28bebb3504",
                        "571de123-77aa-4b08-a25e-7f80cf5a2e5b",
                        "662db3d8-b707-420c-9727-42e9f12a5479",
                        "67316eeb-77f8-43f4-b0bd-d604387e80f1",
                        "7583b6d0-44bd-444e-a311-4c537015a77d",
                        "767eacbf-fb87-44f8-bd87-9a4440413602",
                        "9d912297-e52f-4ab6-add4-633e0f263933",
                        "a536637e-ef3d-4dab-aa8c-fd86e575c002",
                        "a6489c44-f0a4-474a-97c0-eba9c62bcd67",
                        "b1ba90ca-3599-4363-8703-5acce9f7f3f5",
                        "c5b280d6-5047-4296-99f2-724efbd7808c",
                        "c6c47e96-4768-473b-853a-e33dd56a9688",
                        "cf6802fe-c0b2-45c7-92cd-d1187f8986b1",
                        "e05b1c8c-557d-498a-a425-40a99c2c9146",
                        "e2a46555-6ca9-4cd4-a815-f4715ae04253",
                        "f98cc304-5a77-49f4-9bd6-3af076bc83d9"
                    ],
                    "keyword": [
                        "perceived",
                        "ease",
                        "computer",
                        "systemspecific",
                        "model",
                        "proposes",
                        "perception",
                        "anchoring"
                    ],
                    "group": [],
                    "_id": "ee3f66e5-6921-4320-9125-944eb33a04f1",
                    "abstract": "Much previous research has established that perceived ease of use is an important factor influencing user acceptance and usage behavior of information technologies. However, very little research has been conducted to understand how that perception forms and changes over time. The current work presents and tests an anchoring and adjustment-based theoretical model of the determinants of system-specific perceived ease of use. The model proposes control (internal and external--conceptualized as computer self-efficacy and facilitating conditions, respectively), intrinsic motivation (conceptualized as computer playfulness), and emotion (conceptualized as computer anxiety) as anchors that determine early perceptions about the ease of use of a new system. With increasing experience, it is expected that system-specific perceived ease of use, while still anchored to the general beliefs regarding computers and computer use, will adjust to reflect objective usability, perceptions of external control specific to the new system environment, and system-specific perceived enjoyment. The proposed model was tested in three different organizations among 246 employees using three measurements taken over a three-month period. The proposed model was strongly supported at all points of measurement, and explained up to 60% of the variance in system-specific perceived ease of use, which is twice as much as our current understanding. Important theoretical and practical implications of these findings are discussed.",
                    "title": "Determinants of Perceived Ease of Use: Integrating Control, Intrinsic Motivation, and Emotion into the Technology Acceptance Model",
                    "venue": "Information Systems Research",
                    "year": 2000,
                    "__v": 2,
                    "citationCount": 1029,
                    "result": 6.549164779597543
                },
                "fe2918f3-a823-44cc-ae45-5ae902336497": {
                    "authors": [
                        "Wanda J. Orlikowski",
                        "Stephen R. Barley"
                    ],
                    "references": [
                        "004050d0-c5b4-4721-bd2c-f13b8ca8dcb5",
                        "012b87db-a68a-43bf-a60d-ddfa4334d4e0",
                        "1b6d7728-b8b2-4b48-8abc-f4db6125f25d",
                        "1d13bb3f-b6b6-43c6-a3c9-442e780af17c",
                        "2819d0c5-ecb8-47bf-a039-6ae12e308990",
                        "360579c4-6f88-4a73-ae63-04a2dfad3ecd",
                        "5408bafe-7744-4aef-897b-3a59be4920f6",
                        "5a1d74c0-4da5-496b-8319-1d55a7cb5040",
                        "5ad3df4f-f303-45a1-967b-7a388f11be28",
                        "5dcfc51a-2540-4365-8fd8-956ef8add878",
                        "5e12fc72-c1c9-4719-81e5-08ade8276682",
                        "624c99eb-6d0b-449c-9122-db5659f9cd32",
                        "6a1a06fa-b652-4c56-8668-3842c6b56761",
                        "6a5737b2-6b6e-4b6b-a536-7d2f71857606",
                        "75aa36b5-c66d-4269-adf6-efae9ad1da44",
                        "81ba306e-9224-494c-9afe-6b61cea1e236",
                        "8c650936-63ad-4763-9df2-750e154e4668",
                        "9d912297-e52f-4ab6-add4-633e0f263933",
                        "9f89ed42-da2e-423a-b4b4-0802c91db225",
                        "ae60913a-c417-463a-a46b-429dfd160eac",
                        "b2e77172-14e8-4e22-8aaa-051ee33c1e55",
                        "c9bc6870-0da5-4a69-8c8c-a6f85223461b",
                        "dc31f5b7-0343-47f8-a260-1745b3f05834",
                        "e0d06b4d-9064-4f7c-9b20-d8811d62beb5",
                        "f74a6d6c-c91e-46dc-afb7-cc7aa492383e",
                        "f8f39d98-fb54-4ced-a890-2ca79605c4a0",
                        "fdda59a1-3b4a-4bd2-a9fa-cc2728dd4bfd"
                    ],
                    "keyword": [
                        "technology",
                        "organization",
                        "studies",
                        "information",
                        "fields",
                        "research",
                        "nature",
                        "interaction",
                        "institutional",
                        "important"
                    ],
                    "group": [],
                    "_id": "fe2918f3-a823-44cc-ae45-5ae902336497",
                    "abstract": "We argue that because of important epistemological differences between the fields of information technology and organization studies, much can be gained from greater interaction between them. In particular, we argue that information technology research can benefit from incorporating institutional analysis from organization studies, while organization studies can benefit even more by following the lead of information technology research in taking the material properties of technologies into account. We further suggest that the transformations currently occurring in the nature of work and organizing cannot be understood without considering both the technological changes and the institutional contexts that are reshaping economic and organizational activity. Thus, greater interaction between the fields of information technology and organization studies should be viewed as more than a matter of enrichment. In the intellectual engagement of these two fields lies the potential for an important fusion of perspectives, a fusion more carefully attuned to explaining the nature and consequences of the techno-social phenomena that increasingly pervade our lives.",
                    "title": "Technology and institutions: what can research on information technology and research on organizations learn from each other?",
                    "venue": "Management Information Systems Quarterly",
                    "year": 2001,
                    "__v": 2,
                    "citationCount": 237,
                    "result": 10.367745480529212
                }
            }
        ],
        "_id": "885cfaf9-43e5-4101-9554-40962d09fe53",
        "abstract": "Two paradigms characterize much of the research in the Information Systems discipline: behavioral science and design science. The behavioral-science paradigm seeks to develop and verify theories that explain or predict human or organizational behavior. The design-science paradigm seeks to extend the boundaries of human and organizational capabilities by creating new and innovative artifacts. Both paradigms are foundational to the IS discipline, positioned as it is at the confluence of people, organizations, and technology. Our objective is to describe the performance of design-science research in Information Systems via a concise conceptual framework and clear guidelines for understanding, executing, and evaluating the research. In the design-science paradigm, knowledge and understanding of a problem domain and its solution are achieved in the building and application of the designed artifact. Three recent exemplars in the research literature are used to demonstrate the application of these guidelines. We conclude with an analysis of the challenges of performing high-quality design-science research in the context of the broader IS community.",
        "title": "Design science in information systems research",
        "venue": "Management Information Systems Quarterly",
        "year": 2004,
        "__v": 2,
        "citationCount": 2732
    },
    {
        "authors": [
            "Geoffrey E. Hinton",
            "Simon Osindero",
            "Yee Whye Teh"
        ],
        "references": [
            "061d43fb-e3af-4700-bdc2-2e34dfbace26",
            "13439034-6d0a-4842-a6a1-dac976b6c120",
            "146aac22-d446-44ec-9e85-ca24284d7371",
            "3df2f42c-eb57-4a76-99c1-311c20ed6d8e",
            "4453fa3b-308f-472a-be61-65d1ce5c3de2",
            "5055413d-4850-4d6a-b4d4-4343550be9ec",
            "61dcad2b-ef68-4240-95e2-79c12c6bfda9",
            "7745e216-83f5-4a17-8452-d8fb2969c937",
            "7876d86f-e782-4ca6-9504-5f347d1c388f",
            "873b967f-3823-4587-b177-36317e57ee68",
            "8f0a7a93-0b28-4dd1-801b-fdbab29c5283",
            "b592576f-ff29-4a68-9b2f-8a8ad02e9c70",
            "c414c2ad-81f0-4af9-b63a-9e40c8233cdb",
            "ca250ca4-70fd-411f-8cc7-fb17be31cd9e",
            "cf740e2c-f5bf-4e0c-8375-2948d6dff2c7",
            "d2de642b-7044-4d04-85ea-1e05eea964c6",
            "d6104d9a-faaa-4db4-8c4e-748176157ef2",
            "e8571238-943e-46d2-920b-63013e5dd5cd"
        ],
        "keyword": [
            "layers",
            "algorithm",
            "model",
            "memory",
            "learn",
            "digit",
            "associative",
            "ravines",
            "priors",
            "networks"
        ],
        "group": [
            {
                "5055413d-4850-4d6a-b4d4-4343550be9ec": {
                    "authors": [
                        "Joseph F. Murray",
                        "Kenneth Kreutz-Delgado"
                    ],
                    "references": [
                        "02ab1c1c-0b15-46eb-8a0d-300fb4164c24",
                        "2942ecfc-4dee-401e-ab79-ac7fa39c3209",
                        "2b47bbb0-4b04-494a-999a-c4bce4331f8e",
                        "3df2f42c-eb57-4a76-99c1-311c20ed6d8e",
                        "475b0a93-ba0b-4a83-bf1d-0756b5edda30",
                        "6db72d62-cfdf-4c56-b15b-1c3604009d0e",
                        "8614b1c7-03c0-4bd4-9318-ec8dd70ee092",
                        "89f10062-acf1-4171-b882-f3222c3a357e",
                        "95e314d8-096a-4130-b34e-0454dcdf9147",
                        "991bb85a-f14e-418e-9155-305684f02c77",
                        "9e062d9c-20d8-4fe5-af2e-c7edd65d67db",
                        "ad4f81d3-cba5-4db2-9044-93962e883865",
                        "b19405c0-94ad-44c7-8a1d-bb0215318a3b",
                        "b67e937c-3186-4df1-ad0a-34437288602e",
                        "b751c61e-4d40-475b-ad9c-5ded31a7e4e5",
                        "c414c2ad-81f0-4af9-b63a-9e40c8233cdb",
                        "ddbe4bd6-32c2-42bd-b1cf-eb931a29cdbe",
                        "e05a6676-6e91-466e-b705-19e19b66e5a2",
                        "e8fe573a-2572-49f3-b7d3-ea167b6ffa9d"
                    ],
                    "keyword": [
                        "learning",
                        "visual",
                        "overcomplete",
                        "tasks",
                        "algorithm"
                    ],
                    "group": [],
                    "_id": "5055413d-4850-4d6a-b4d4-4343550be9ec",
                    "abstract": "We present a hierarchical architecture and learning algorithm for visual recognition and other visual inference tasks such as imagination, reconstruction of occluded images, and expectation-driven segmentation. Using properties of biological vision for guidance, we posit a stochastic generative world model and from it develop a simplified world model (SWM) based on a tractable variational approximation that is designed to enforce sparse coding. Recent developments in computational methods for learning overcomplete representations (Lewicki & Sejnowski, 2000; Teh, Welling, Osindero, & Hinton, 2003) suggest that overcompleteness can be useful for visual tasks, and we use an overcomplete dictionary learning algorithm (Kreutz-Delgado, et al., 2003) as a preprocessing stage to produce accurate, sparse codings of images.#R##N##R##N#Inference is performed by constructing a dynamic multilayer network with feedforward, feedback, and lateral connections, which is trained to approximate the SWM. Learning is done with a variant of the back-propagation-through-time algorithm, which encourages convergence to desired states within a fixed number of iterations. Vision tasks require large networks, and to make learning efficient, we take advantage of the sparsity of each layer to update only a small subset of elements in a large weight matrix at each iteration. Experiments on a set of rotated objects demonstrate various types of visual inference and show that increasing the degree of overcompleteness improves recognition performance in difficult scenes with occluded objects in clutter.",
                    "title": "Visual Recognition and Inference Using Dynamic Overcomplete Sparse Learning",
                    "venue": "Neural Computation",
                    "year": 2007,
                    "__v": 1,
                    "citationCount": 19,
                    "result": 4.878790653790654
                },
                "61dcad2b-ef68-4240-95e2-79c12c6bfda9": {
                    "authors": [
                        "Max Welling",
                        "Michal Rosen-Zvi",
                        "Geoffrey E. Hinton"
                    ],
                    "references": [
                        "0ad38f3e-8131-4287-9e62-2b2ae77f47f7",
                        "2097211d-d686-4c8a-b681-1ecffc62a42a",
                        "2f28839a-8819-4194-a43d-1423e2a29f6b",
                        "4453fa3b-308f-472a-be61-65d1ce5c3de2",
                        "7a274fcf-8bb9-45ad-ae20-3f345d724dce",
                        "8f0a7a93-0b28-4dd1-801b-fdbab29c5283",
                        "94a26b29-62ba-47f0-9aa6-957e8a4c9d9c",
                        "97233a1c-326d-45da-abdf-06c8fb366ed2",
                        "ac14afe6-de4d-4056-b2ac-0f6e36f369a2",
                        "bb893038-baa5-4a2f-97d2-c82b0293de83"
                    ],
                    "keyword": [
                        "models",
                        "variables",
                        "semantics",
                        "family",
                        "random",
                        "performed",
                        "layer",
                        "infer",
                        "hidden",
                        "exponential"
                    ],
                    "group": [],
                    "_id": "61dcad2b-ef68-4240-95e2-79c12c6bfda9",
                    "abstract": "Directed graphical models with one layer of observed random variables and one or more layers of hidden random variables have been the dominant modelling paradigm in many research fields. Although this approach has met with considerable success, the causal semantics of these models can make it difficult to infer the posterior distribution over the hidden variables. In this paper we propose an alternative two-layer model based on exponential family distributions and the semantics of undirected models. Inference in these \"exponential family harmoniums\" is fast while learning is performed by minimizing contrastive divergence. A member of this family is then studied as an alternative probabilistic model for latent semantic indexing. In experiments it is shown that they perform well on document retrieval tasks and provide an elegant solution to searching with keywords.",
                    "title": "Exponential Family Harmoniums with an Application to Information Retrieval",
                    "venue": "neural information processing systems",
                    "year": 2005,
                    "__v": 2,
                    "citationCount": 190,
                    "result": 6.473732639909112
                },
                "7745e216-83f5-4a17-8452-d8fb2969c937": {
                    "authors": [
                        "Terence D. Sanger"
                    ],
                    "references": [
                        "09b6e04e-ca5e-40ce-bd92-73502563e488",
                        "1a040e34-192c-48da-89c4-a89f05cc6f9b",
                        "3e1074e9-eadd-44ef-9195-1a3a531dc381",
                        "43ff9bc9-8e2e-40d9-acdd-049247b698ac",
                        "5b38ce2f-9c78-4d6e-850e-c398a8813b67",
                        "7396853d-1470-4bf8-9e40-334d0c4eff11",
                        "82556b82-e0a1-461a-ad39-cd9e9f284e14",
                        "9c7afac9-4cd2-4a61-b988-df5adc0397cf",
                        "d2b4d30a-4bcd-4fb6-bef9-8345fc11f3fd",
                        "d9215ef1-ba4b-4a59-bd6f-b6900dbf8ae3",
                        "df20dd57-943e-4ac6-9d4e-c5a0ced37a01"
                    ],
                    "keyword": [
                        "network",
                        "algorithm",
                        "neural",
                        "learning",
                        "visual",
                        "unsupervised",
                        "statistics",
                        "shown",
                        "rule",
                        "problem"
                    ],
                    "group": [],
                    "_id": "7745e216-83f5-4a17-8452-d8fb2969c937",
                    "abstract": "Abstraet--A new approach to unsupervised learning in a single-layer linear feedforward neural network is discussed. An optimality principle is proposed which is based upon preserving maximal information in the output units. An algorithm for unsupervised learning based upon a Hebbian learning rule, which achieves the desired optimality is presented, The algorithm finds the eigenvectors of the input correlation matrix, and it is proven to converge with probability one. An implementation which can train neural networks using only local \"synaptic\" modification rules is described. It is shown that the algorithm is closely related to algorithms in statistics (Factor Analysis and Principal Components Analysis) and neural networks (Self-supervised Backpropagation, or the \"encoder\" problem). It thus provides an explanation of certain neural network behavior in terms of\" classical statistical techniques. Examples of the use of a linear network for solving image coding and texture segmentation problems are presented. Also, it is shown that the algorithm can be used to find \"visual receptive fields'\" which are qualitatively similar to those found in primate retina and visual cortex.",
                    "title": "Optimal Unsupervised Learning in a Single-Layer Linear Feedforward Neural Network",
                    "venue": "Neural Networks",
                    "year": 1989,
                    "__v": 2,
                    "citationCount": 475,
                    "result": 6.561231982671611
                },
                "7876d86f-e782-4ca6-9504-5f347d1c388f": {
                    "authors": [
                        "Stefan Roth",
                        "Michael J. Black"
                    ],
                    "references": [
                        "0e2bd188-d294-43b9-917f-a42d97183634",
                        "1ddcd105-153a-4613-9e4f-d1891c8dab3b",
                        "27bbf878-cd23-43b4-8232-2b0706aec3ca",
                        "3d414a5e-b97a-498e-8a75-920997235c6b",
                        "442895c4-93e2-4dea-afb7-4be44eaded41",
                        "4453fa3b-308f-472a-be61-65d1ce5c3de2",
                        "48b2f9f3-f780-4f6b-95b9-b650bb93ef65",
                        "57e35e32-f009-4b9b-bfb2-3747eac40b72",
                        "6ff0fc03-066b-4aa0-bdbd-e25aede63c47",
                        "7f1214b2-e070-4ff2-a5d3-647e7c16c2d7",
                        "8f0a7a93-0b28-4dd1-801b-fdbab29c5283",
                        "9308c3cb-9b84-4ea4-8e6c-bbb6fb466640",
                        "b39299a5-6c2f-4be9-842d-0433262505ad",
                        "b76ab2bb-c56c-4fa3-8188-f16c8e581559",
                        "b8a86432-fff7-474e-9d72-046c5189e6dc",
                        "c79fa5f7-bd43-4fb6-97cc-e1c56e044062",
                        "e33abe71-07fd-4486-8df0-b98614d7df4f",
                        "ef3569d3-7b9e-4696-9cc9-647c64767b40"
                    ],
                    "keyword": [
                        "models",
                        "image",
                        "learning",
                        "field",
                        "training",
                        "potential",
                        "mrf",
                        "linear",
                        "generic",
                        "functions"
                    ],
                    "group": [],
                    "_id": "7876d86f-e782-4ca6-9504-5f347d1c388f",
                    "abstract": "We develop a framework for learning generic, expressive image priors that capture the statistics of natural scenes and can be used for a variety of machine vision tasks. The approach extends traditional Markov random field (MRF) models by learning potential functions over extended pixel neighborhoods. Field potentials are modeled using a Products-of-Experts framework that exploits nonlinear functions of many linear filter responses. In contrast to previous MRF approaches all parameters, including the linear filters themselves, are learned from training data. We demonstrate the capabilities of this Field of Experts model with two example applications, image denoising and image inpainting, which are implemented using a simple, approximate inference scheme. While the model is trained on a generic image database and is not tuned toward a specific application, we obtain results that compete with and even outperform specialized techniques.",
                    "title": "Fields of Experts: a framework for learning image priors",
                    "venue": "computer vision and pattern recognition",
                    "year": 2005,
                    "__v": 2,
                    "citationCount": 381,
                    "result": 6.052744477744479
                },
                "873b967f-3823-4587-b177-36317e57ee68": {
                    "authors": [
                        "Ilya Sutskever",
                        "Geoffrey E. Hinton"
                    ],
                    "references": [
                        "32c1bdf2-cea7-4d60-8289-2207eaa41a77",
                        "3b83c815-532d-4122-811f-2b57e8b80c5d",
                        "4453fa3b-308f-472a-be61-65d1ce5c3de2",
                        "4c5ed508-b6e5-4db5-a59f-00e1d88dc221",
                        "89f10062-acf1-4171-b882-f3222c3a357e",
                        "8d7bb750-adbb-4a71-813f-09fdfab8f7d0",
                        "c4024860-8d55-47c1-bab0-6c53f90831ee",
                        "e00917f7-1629-48db-baa5-7cc0d179de17"
                    ],
                    "keyword": [
                        "show",
                        "networks",
                        "width",
                        "vectors",
                        "note",
                        "limited",
                        "learned",
                        "layer",
                        "impractical",
                        "greedily"
                    ],
                    "group": [],
                    "_id": "873b967f-3823-4587-b177-36317e57ee68",
                    "abstract": "In this note, we show that exponentially deep belief networks can approximate any distribution over binary vectors to arbitrary accuracy, even when the width of each layer is limited to the dimensionality of the data. We further show that such networks can be greedily learned in an easy yet impractical way.",
                    "title": "Deep, narrow sigmoid belief networks are universal approximators",
                    "venue": "Neural Computation",
                    "year": 2008,
                    "__v": 1,
                    "citationCount": 31,
                    "result": 6.495232545232546
                },
                "8f0a7a93-0b28-4dd1-801b-fdbab29c5283": {
                    "authors": [
                        "Max Welling",
                        "Simon Osindero",
                        "Geoffrey E. Hinton"
                    ],
                    "references": [
                        "4453fa3b-308f-472a-be61-65d1ce5c3de2",
                        "5140e52c-4efc-496c-8607-ec6a1b5b1c2a",
                        "6610284f-1f5a-4460-95d6-b0ad690e171d",
                        "9fa21f34-e706-4f0b-a750-3d676d93c461",
                        "aa7b7a12-94a7-4fc1-85cf-6df7a2eab7fa"
                    ],
                    "keyword": [
                        "filter",
                        "model",
                        "learns",
                        "outputs",
                        "images",
                        "system",
                        "sets",
                        "product",
                        "probability",
                        "map"
                    ],
                    "group": [],
                    "_id": "8f0a7a93-0b28-4dd1-801b-fdbab29c5283",
                    "abstract": "We propose a model for natural images in which the probability of an image is proportional to the product of the probabilities of some filter outputs. We encourage the system to find sparse features by using a Student-t distribution to model each filter output. If the t-distribution is used to model the combined outputs of sets of neurally adjacent filters, the system learns a topographic map in which the orientation, spatial frequency and location of the filters change smoothly across the map. Even though maximum likelihood learning is intractable in our model, the product form allows a relatively efficient learning procedure that works well even for highly overcomplete sets of filters. Once the model has been learned it can be used as a prior to derive the \"iterated Wiener filter\" for the purpose of denoising images.",
                    "title": "Learning Sparse Topographic Representations with Products of Student-t Distributions",
                    "venue": "neural information processing systems",
                    "year": 2003,
                    "__v": 2,
                    "citationCount": 79,
                    "result": 4.217604617604617
                },
                "b592576f-ff29-4a68-9b2f-8a8ad02e9c70": {
                    "authors": [
                        "Serge J. Belongie",
                        "Jitendra Malik",
                        "Jan Puzicha"
                    ],
                    "references": [
                        "00909251-9935-44f3-94a1-629023b5015b",
                        "042d18d1-aed3-4a9d-ba8b-fb7f3e14f568",
                        "0fc7a847-923c-4742-9b05-2b46eda24b2e",
                        "110d4ac1-9abd-4678-882c-56933790933c",
                        "13cd743f-beb9-43a1-8e08-2ef08f0d8b3f",
                        "1e4f4b5c-55e0-4d5b-b7cc-9e7fada3e341",
                        "1ef607fe-5348-4658-8964-25a57fc49270",
                        "23c61d04-333b-42c1-b8f8-a93cc33f4411",
                        "24187b9b-fe6b-484d-9a0e-0b849362fa18",
                        "25b0c9f9-0c8a-4f2a-b075-90d339b6faa3",
                        "2a082569-b03f-474a-8e45-dfd713557277",
                        "2ae7a9b5-6231-45ca-9813-afc3a6b5f5ff",
                        "31d3bf4a-4175-414e-84c4-0eb8e42fc66e",
                        "37032748-43bb-410a-8349-d2808bb6f7fa",
                        "4a29b56b-b74e-4945-9017-61a7ab844fd9",
                        "50dd56db-151d-4d62-8576-65f0ef6f381b",
                        "59ade036-678c-42ad-bce8-7aa9301103e1",
                        "5ae4ef7f-b13a-4e78-8afd-1e2d22259b87",
                        "5ebbd1f5-dfe5-4eec-9883-b8b5efea366c",
                        "5f1992df-975f-49e7-bd88-aee0740317cf",
                        "6018a516-8149-4bce-bc33-5449d86e58c2",
                        "6d86ad90-fe62-40e5-b917-7e3f31350523",
                        "772654a7-a951-4327-aca5-ba5da8dfec7c",
                        "88f85c71-d474-4d12-9c74-43ac3b7c7ee6",
                        "8fc9506c-3603-4af2-b0c8-02b368863fcb",
                        "923f5d0a-23a3-4fb1-bee7-ec72122709a4",
                        "932ef745-7197-4b00-bcd4-781bd048938f",
                        "9f84e529-87a3-42f1-9d63-9af710f40925",
                        "a8c6ead3-d61a-4f6a-a702-08743f19eec9",
                        "bf1d8c69-aefb-4a7a-8b02-f815b754833c",
                        "d5f8e154-e8c9-45e8-a3a0-fd705f00ced4",
                        "d6104d9a-faaa-4db4-8c4e-748176157ef2",
                        "d9752a5a-1603-45cc-9a21-7997750d429f",
                        "f1268507-d7ad-40be-a33a-083131f0ca8c",
                        "f3959783-a9aa-48a2-9fcc-978879de365e"
                    ],
                    "keyword": [
                        "shapes",
                        "points",
                        "similarity",
                        "correspondences",
                        "transform",
                        "solving",
                        "problem",
                        "measuring",
                        "context",
                        "aligning"
                    ],
                    "group": [],
                    "_id": "b592576f-ff29-4a68-9b2f-8a8ad02e9c70",
                    "abstract": "We present a novel approach to measuring similarity between shapes and exploit it for object recognition. In our framework, the measurement of similarity is preceded by: (1) solving for correspondences between points on the two shapes; (2) using the correspondences to estimate an aligning transform. In order to solve the correspondence problem, we attach a descriptor, the shape context, to each point. The shape context at a reference point captures the distribution of the remaining points relative to it, thus offering a globally discriminative characterization. Corresponding points on two similar shapes will have similar shape contexts, enabling us to solve for correspondences as an optimal assignment problem. Given the point correspondences, we estimate the transformation that best aligns the two shapes; regularized thin-plate splines provide a flexible class of transformation maps for this purpose. The dissimilarity between the two shapes is computed as a sum of matching errors between corresponding points, together with a term measuring the magnitude of the aligning transform. We treat recognition in a nearest-neighbor classification framework as the problem of finding the stored prototype shape that is maximally similar to that in the image. Results are presented for silhouettes, trademarks, handwritten digits, and the COIL data set.",
                    "title": "Shape matching and object recognition using shape contexts",
                    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "year": 2002,
                    "__v": 1,
                    "citationCount": 2839,
                    "result": 5.408854621470721
                },
                "ca250ca4-70fd-411f-8cc7-fb17be31cd9e": {
                    "authors": [
                        "Patrice Y. Simard",
                        "David W. Steinkraus",
                        "John Platt"
                    ],
                    "references": [
                        "7b75127a-9fc0-4fa3-85dd-1e9744d3addb",
                        "d6104d9a-faaa-4db4-8c4e-748176157ef2",
                        "ec892eb8-6815-4ea3-b309-026f9202c256"
                    ],
                    "keyword": [
                        "networks",
                        "documents",
                        "set",
                        "neural",
                        "architecture",
                        "visual",
                        "training",
                        "simple",
                        "results",
                        "analysis"
                    ],
                    "group": [],
                    "_id": "ca250ca4-70fd-411f-8cc7-fb17be31cd9e",
                    "abstract": "Neural networks are a powerful technology forclassification of visual inputs arising from documents.However, there is a confusing plethora of different neuralnetwork methods that are used in the literature and inindustry. This paper describes a set of concrete bestpractices that document analysis researchers can use toget good results with neural networks. The mostimportant practice is getting a training set as large aspossible: we expand the training set by adding a newform of distorted data. The next most important practiceis that convolutional neural networks are better suited forvisual document tasks than fully connected networks. Wepropose that a simple \"do-it-yourself\" implementation ofconvolution with a flexible architecture is suitable formany visual document problems. This simpleconvolutional neural network does not require complexmethods, such as momentum, weight decay, structure-dependentlearning rates, averaging layers, tangent prop,or even finely-tuning the architecture. The end result is avery simple yet general architecture which can yieldstate-of-the-art performance for document analysis. Weillustrate our claims on the MNIST set of English digitimages.",
                    "title": "Best practices for convolutional neural networks applied to visual document analysis",
                    "venue": "international conference on document analysis and recognition",
                    "year": 2003,
                    "__v": 2,
                    "citationCount": 387,
                    "result": 4.884905737537316
                },
                "d2de642b-7044-4d04-85ea-1e05eea964c6": {
                    "authors": [
                        "Feng Ning",
                        "Damien Delhomme",
                        "Yann LeCun",
                        "Fabio Piano",
                        "Léon Bottou",
                        "Paolo Emilio Barbano"
                    ],
                    "references": [
                        "019bc913-6270-451a-96c1-639c2ec6d7e8",
                        "06db35ce-e924-4f3d-9eae-136b008b1800",
                        "0c59decd-cb41-4d27-bffa-85a600bc0bf8",
                        "1c63e1d5-b963-455b-829d-e4f3eb63a36a",
                        "2348054d-64ba-4368-8843-516baee03da0",
                        "28baa713-3f4f-421b-b140-e1e46b0e7012",
                        "3630ebbb-a82a-435e-a5eb-b33d9fad26c9",
                        "50deb9e0-e10b-40bd-a73f-c544285457e3",
                        "526860a6-aea8-4f8d-b7f9-e01d3629a6a9",
                        "57e35e32-f009-4b9b-bfb2-3747eac40b72",
                        "7051106a-e8cd-4bed-a312-30e32ac9600d",
                        "820b9eee-e009-4dc1-b464-f5fd4485d6b3",
                        "8d7477d3-f3cf-4db0-83eb-e2f5e22b0dc8",
                        "a2c0b7ee-74df-44b9-a22a-111d84bcc8ee",
                        "ae829318-5d10-461d-9c99-34a95a3f8732",
                        "c1569952-27a7-42dc-8e4c-f396d061ac31",
                        "c414c2ad-81f0-4af9-b63a-9e40c8233cdb",
                        "ce27fac2-00d6-4589-82fd-ef2b415f75f1",
                        "dee57284-55cf-4236-ba5c-98ef533453de",
                        "e649a9fd-f6d9-4aac-b428-29b82c20a484",
                        "f484f56b-640f-4f4a-a9cf-05f9adcafe8d",
                        "fb1e85b8-5ae8-4074-88cf-4e9270d625ff"
                    ],
                    "keyword": [
                        "system",
                        "images",
                        "nucleus",
                        "network",
                        "model",
                        "label",
                        "embryos",
                        "developing",
                        "convolutional",
                        "cells"
                    ],
                    "group": [],
                    "_id": "d2de642b-7044-4d04-85ea-1e05eea964c6",
                    "abstract": "We describe a trainable system for analyzing videos of developing C. elegans embryos. The system automatically detects, segments, and locates cells and nuclei in microscopic images. The system was designed as the central component of a fully automated phenotyping system. The system contains three modules 1) a convolutional network trained to classify each pixel into five categories: cell wall, cytoplasm, nucleus membrane, nucleus, outside medium; 2) an energy-based model, which cleans up the output of the convolutional network by learning local consistency constraints that must be satisfied by label images; 3) a set of elastic models of the embryo at various stages of development that are matched to the label images.",
                    "title": "Toward automatic phenotyping of developing embryos from videos",
                    "venue": "IEEE Transactions on Image Processing",
                    "year": 2005,
                    "__v": 2,
                    "citationCount": 50,
                    "result": 5.896536590344639
                },
                "d6104d9a-faaa-4db4-8c4e-748176157ef2": {
                    "authors": [
                        "Dennis DeCoste",
                        "Bernhard Schölkopf"
                    ],
                    "references": [
                        "186ea3a7-0ce3-41a1-8380-c3d10543f451",
                        "1ef607fe-5348-4658-8964-25a57fc49270",
                        "3514c54b-4a5a-4807-9d10-174915c9202b",
                        "3e60e095-4c4b-46ca-9b6b-97ae0ea9eebb",
                        "50dd56db-151d-4d62-8576-65f0ef6f381b",
                        "549f0527-0f13-4447-9dc0-ca699e2dc219",
                        "56f68d8b-36ca-422e-b721-c1f17ac7a78d",
                        "87969fc2-8332-4ee5-b6b0-e1b26d01ebd4",
                        "8b2c0aff-4589-4e0f-aae4-4f84a4413406",
                        "92af8bc1-80b2-40aa-9c0c-f40dbebee3a0",
                        "94898e1d-1e50-41ab-9dcc-2c2e030cddd0",
                        "ae3e7593-586f-495f-9416-4b50ed1fcd10",
                        "b4c5a572-c0a9-41e3-8782-9d4ee8105d81",
                        "b90f9310-726f-4116-9322-6fc01ab598fd",
                        "c1d82182-8cfa-4d6e-92b7-2b7e430c4f60",
                        "cabaf8b7-46f2-4eed-af57-120fd206f760",
                        "cb4fbf1c-02e4-4ca9-995d-29f5282fdb4a",
                        "ec8c9e00-d026-4d33-b102-ffd5389234cd",
                        "eca46fc4-e594-461f-83b8-aa5247e440ca",
                        "f006e236-59ad-4647-a59f-4f46dc2c85be",
                        "f6c418d7-c420-492f-8d24-de3827674b93"
                    ],
                    "keyword": [
                        "training",
                        "svm",
                        "significant",
                        "results",
                        "reported",
                        "methods",
                        "work",
                        "wellknown",
                        "vector",
                        "times"
                    ],
                    "group": [],
                    "_id": "d6104d9a-faaa-4db4-8c4e-748176157ef2",
                    "abstract": "Practical experience has shown that in order to obtain the best possible performance, prior knowledge about invariances of a classification problem at hand ought to be incorporated into the training procedure. We describe and review all known methods for doing so in support vector machines, provide experimental results, and discuss their respective merits. One of the significant new results reported in this work is our recent achievement of the lowest reported test error on the well-known MNIST digit recognition benchmark task, with SVM training times that are also significantly faster than previous SVM methods.",
                    "title": "Training Invariant Support Vector Machines",
                    "venue": "Machine Learning",
                    "year": 2002,
                    "__v": 2,
                    "citationCount": 226,
                    "result": 4.772671772671773
                }
            }
        ],
        "_id": "89f10062-acf1-4171-b882-f3222c3a357e",
        "abstract": "We show how to use \"complementary priors\" to eliminate the explaining-away effects that make inference difficult in densely connected belief nets that have many hidden layers. Using complementary priors, we derive a fast, greedy algorithm that can learn deep, directed belief networks one layer at a time, provided the top two layers form an undirected associative memory. The fast, greedy algorithm is used to initialize a slower learning procedure that fine-tunes the weights using a contrastive version of the wake-sleep algorithm. After fine-tuning, a network with three hidden layers forms a very good generative model of the joint distribution of handwritten digit images and their labels. This generative model gives better digit classification than the best discriminative learning algorithms. The low-dimensional manifolds on which the digits lie are modeled by long ravines in the free-energy landscape of the top-level associative memory, and it is easy to explore these ravines by using the directed connections to display what the associative memory has in mind.",
        "title": "A fast learning algorithm for deep belief nets",
        "venue": "Neural Computation",
        "year": 2006,
        "__v": 2,
        "citationCount": 2595
    },
    {
        "authors": [
            "Paul A. Viola",
            "Michael J. Jones"
        ],
        "references": [
            "13cd743f-beb9-43a1-8e08-2ef08f0d8b3f",
            "17f811d8-8607-4270-bbec-1cc7883edd68",
            "245e4043-ccdb-457a-9be1-e120c7a94753",
            "310cbba4-d88d-4bf4-a4f2-738f91b5f8c8",
            "36800655-b2ff-4eb7-9070-c6be304c4baa",
            "43530fe4-10a9-4ddf-b61d-8844f0ff3f04",
            "55fa440a-2b98-4e8e-bb45-fa09598b4eca",
            "5ffac6f9-2456-42cf-830c-9049ce37c899",
            "613841ae-c925-4aee-9c2e-8675213e4bbf",
            "62d0a064-3808-4bc0-99bd-f007359ce651",
            "6d121e97-e351-4cf9-8c44-d7ab3ce9d9fe",
            "8f6a657e-e387-4572-bb88-91aee042e8da",
            "9fa55b0f-eaa6-4c59-b6e5-77e5f1a406f0",
            "b49c1e2b-0cd0-4950-a724-00c698e5b49d",
            "c7f93552-c1ef-4ae4-b1f5-2317e1c9d904",
            "d5e5a24d-f80e-4f1a-b48b-22403b653276",
            "d6e37fb1-5f7e-448e-847b-7d1f1271c574",
            "db26488d-78be-44b1-a343-e896f43c5d29",
            "f1bd37c4-d033-4cd1-af44-4df9f11c71e4",
            "f4642ffc-3571-4d02-8b94-142f2448023a"
        ],
        "keyword": [
            "detection",
            "images",
            "face",
            "features",
            "system",
            "set",
            "regions",
            "quickly",
            "contributions",
            "computed"
        ],
        "group": [
            {
                "55fa440a-2b98-4e8e-bb45-fa09598b4eca": {
                    "authors": [
                        "Henry A. Rowley",
                        "Shumeet Baluja",
                        "Takeo Kanade"
                    ],
                    "references": [
                        "0150e8cd-09bc-4991-92b4-454fe4b0bfac",
                        "0b4c0d6f-58fd-4704-98af-8c12de196ede",
                        "1863ec2a-4485-4bf6-80c4-6dfce4a8d627",
                        "49b0495d-2caa-4dbf-b1ab-6f9695b8bd72",
                        "5ffac6f9-2456-42cf-830c-9049ce37c899",
                        "9499c3b8-c1f9-4d80-9cfb-c0b9b26b2511",
                        "ae3e7593-586f-495f-9416-4b50ed1fcd10",
                        "d42f853d-12d7-416d-8b27-c314ef563eed",
                        "d5e5a24d-f80e-4f1a-b48b-22403b653276",
                        "e9f4315c-139f-400c-b6e5-1e5cb369191d",
                        "eb2dc957-4aae-4d39-a99d-8adab1effb39",
                        "eca46fc4-e594-461f-83b8-aa5247e440ca",
                        "fe966e48-ad81-4d33-af4f-b9e2509b64ed"
                    ],
                    "keyword": [
                        "training",
                        "system",
                        "network",
                        "detection",
                        "face",
                        "windows",
                        "present",
                        "performance",
                        "nonface",
                        "neural"
                    ],
                    "group": [],
                    "_id": "55fa440a-2b98-4e8e-bb45-fa09598b4eca",
                    "abstract": "We present a neural network-based face detection system. A retinally connected neural network examines small windows of an image and decides whether each window contains a face. The system arbitrates between multiple networks to improve performance over a single network. We use a bootstrap algorithm for training the networks, which adds false detections into the training set as training progresses. This eliminates the difficult task of manually selecting non-face training examples, which must be chosen to span the entire space of non-face images. Comparisons with other state-of-the-art face detection systems are presented; our system has better performance in terms of detection and false-positive rates.",
                    "title": "Neural network-based face detection",
                    "venue": "computer vision and pattern recognition",
                    "year": 1996,
                    "__v": 1,
                    "citationCount": 325,
                    "result": 8.449962902594482
                },
                "5ffac6f9-2456-42cf-830c-9049ce37c899": {
                    "authors": [
                        "Edgar Osuna",
                        "Robert M. Freund",
                        "Federico Girosit"
                    ],
                    "references": [
                        "0150e8cd-09bc-4991-92b4-454fe4b0bfac",
                        "50dd56db-151d-4d62-8576-65f0ef6f381b",
                        "648675c6-6ea7-4fa5-a91d-9d3156d09692",
                        "a689c833-ccce-475c-87af-526da83ebb29",
                        "d42f853d-12d7-416d-8b27-c314ef563eed",
                        "d46e68dc-dbb7-4296-8f40-f3c513b432bc",
                        "d5e5a24d-f80e-4f1a-b48b-22403b653276",
                        "eb2dc957-4aae-4d39-a99d-8adab1effb39",
                        "f006e236-59ad-4647-a59f-4f46dc2c85be"
                    ],
                    "keyword": [
                        "data",
                        "svm",
                        "problem",
                        "optimization",
                        "training",
                        "sets",
                        "quadratic",
                        "present",
                        "points",
                        "iterative"
                    ],
                    "group": [],
                    "_id": "5ffac6f9-2456-42cf-830c-9049ce37c899",
                    "abstract": "We investigate the application of Support Vector Machines (SVMs) in computer vision. SVM is a learning technique developed by V. Vapnik and his team (AT&T Bell Labs., 1985) that can be seen as a new method for training polynomial, neural network, or Radial Basis Functions classifiers. The decision surfaces are found by solving a linearly constrained quadratic programming problem. This optimization problem is challenging because the quadratic form is completely dense and the memory requirements grow with the square of the number of data points. We present a decomposition algorithm that guarantees global optimality, and can be used to train SVM's over very large data sets. The main idea behind the decomposition is the iterative solution of sub-problems and the evaluation of optimality conditions which are used both to generate improved iterative values, and also establish the stopping criteria for the algorithm. We present experimental results of our implementation of SVM, and demonstrate the feasibility of our approach on a face detection problem that involves a data set of 50,000 data points.",
                    "title": "Training support vector machines: an application to face detection",
                    "venue": "computer vision and pattern recognition",
                    "year": 1997,
                    "__v": 2,
                    "citationCount": 975,
                    "result": 5.566459554863108
                },
                "613841ae-c925-4aee-9c2e-8675213e4bbf": {
                    "authors": [
                        "Yali Amit",
                        "Donald Geman"
                    ],
                    "references": [
                        "2958fc5c-15e8-45e7-8da8-d2e0fa46f0c7",
                        "5057898e-bc25-4969-a4b4-881ba80d6783",
                        "5242f101-1511-4660-9a4c-4eb597aaa3c6",
                        "762c9918-e579-42ef-80e5-4e464870a017",
                        "cd9494ab-fbd2-401d-8afe-376c0bd24c80",
                        "d5e5a24d-f80e-4f1a-b48b-22403b653276",
                        "d6e37fb1-5f7e-448e-847b-7d1f1271c574",
                        "f4dcf3a2-512e-4218-a762-62c4323df249"
                    ],
                    "keyword": [
                        "localizing",
                        "groupings",
                        "detecting",
                        "selection",
                        "regions",
                        "processing",
                        "object",
                        "model",
                        "geometrical",
                        "functions"
                    ],
                    "group": [],
                    "_id": "613841ae-c925-4aee-9c2e-8675213e4bbf",
                    "abstract": "We propose a computational model for detecting and localizing instances from an object class in static gray-level images. We divide detection into visual selection and final classification, concentrating on the former: drastically reducing the number of candidate regions that require further, usually more intensive, processing, but with a minimum of computation and missed detections. Bottom-up processing is based on local groupings of edge fragments constrained by loose geometrical relationships. They have no a priori semantic or geometric interpretation. The role of training is to select special groupings that are moderately likely at certain places on the object but rare in the background. We show that the statistics in both populations are stable. The candidate regions are those that contain global arrangements of several local groupings. Whereas our model was not conceived to explain brain functions, it does cohere with evidence about the functions of neurons in V1 and V2, such as responses to coarse ...",
                    "title": "A computational model for visual selection",
                    "venue": "Neural Computation",
                    "year": 1999,
                    "__v": 2,
                    "citationCount": 88,
                    "result": 8.59381810999458
                },
                "62d0a064-3808-4bc0-99bd-f007359ce651": {
                    "authors": [
                        "Patrice Y. Simard",
                        "Léon Bottou",
                        "Patrick Haffner",
                        "Yann LeCun"
                    ],
                    "references": [
                        "3baa1754-b5f7-41cc-a23e-91850cd97f8f"
                    ],
                    "keyword": [
                        "convolution",
                        "signal",
                        "feature",
                        "extraction",
                        "speed",
                        "resulting",
                        "order",
                        "impulse",
                        "functions",
                        "computational"
                    ],
                    "group": [],
                    "_id": "62d0a064-3808-4bc0-99bd-f007359ce651",
                    "abstract": "Signal processing and pattern recognition algorithms make extensive use of convolution. In many cases, computational accuracy is not as important as computational speed. In feature extraction, for instance, the features of interest in a signal are usually quite distorted. This form of noise justifies some level of quantization in order to achieve faster feature extraction. Our approach consists of approximating regions of the signal with low degree polynomials, and then differentiating the resulting signals in order to obtain impulse functions (or derivatives of impulse functions). With this representation, convolution becomes extremely simple and can be implemented quite effectively. The true convolution can be recovered by integrating the result of the convolution. This method yields substantial speed up in feature extraction and is applicable to convolutional neural networks.",
                    "title": "Boxlets: A Fast Convolution Algorithm for Signal Processing and Neural Networks",
                    "venue": "neural information processing systems",
                    "year": 1999,
                    "__v": 2,
                    "citationCount": 40,
                    "result": 8.5141041019524
                },
                "6d121e97-e351-4cf9-8c44-d7ab3ce9d9fe": {
                    "authors": [
                        "Laurent Itti",
                        "Christof Koch",
                        "Ernst Niebur"
                    ],
                    "references": [
                        "f0d33a06-24c8-42c5-a8e9-839ea9891157",
                        "f4642ffc-3571-4d02-8b94-142f2448023a"
                    ],
                    "keyword": [
                        "system",
                        "visual",
                        "selects",
                        "saliency",
                        "locations",
                        "understanding",
                        "topographical",
                        "single",
                        "scene",
                        "rapidly"
                    ],
                    "group": [],
                    "_id": "6d121e97-e351-4cf9-8c44-d7ab3ce9d9fe",
                    "abstract": "A visual attention system, inspired by the behavior and the neuronal architecture of the early primate visual system, is presented. Multiscale image features are combined into a single topographical saliency map. A dynamical neural network then selects attended locations in order of decreasing saliency. The system breaks down the complex problem of scene understanding by rapidly selecting, in a computationally efficient manner, conspicuous locations to be analyzed in detail.",
                    "title": "A model of saliency-based visual attention for rapid scene analysis",
                    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "year": 1998,
                    "__v": 2,
                    "citationCount": 3535,
                    "result": 4.474270990447461
                },
                "8f6a657e-e387-4572-bb88-91aee042e8da": {
                    "authors": [
                        "Ming-Hsuan Yang",
                        "Dan Roth",
                        "Narendra Ahuja"
                    ],
                    "references": [
                        "18517405-939f-49c6-ba79-3aa563e8998f",
                        "1a364b81-4662-4c79-ae11-67429e67ca25",
                        "308bbc62-e490-4c86-b054-647ab74fab02",
                        "4e1c8814-d64a-45b5-88cb-6581dd336cf3",
                        "540ef6bb-631e-4cf0-a146-3adea6e19944",
                        "56f4b72a-ec39-47ac-8220-899296e7fb18",
                        "5ffac6f9-2456-42cf-830c-9049ce37c899",
                        "642a2775-3e20-49fb-8516-d49af3118a06",
                        "6e8cc926-79a1-4676-a2bd-f9d49f3144cf",
                        "7e07a82b-4d78-4de4-84bd-67083c040e7f",
                        "ba44ae01-0d02-4831-b637-48885d606c37",
                        "c42f42f8-d1b5-4965-b7c2-33a0e2d9c8a9",
                        "cad79de9-968c-4c48-bcbf-5255712ac4ae",
                        "d5e5a24d-f80e-4f1a-b48b-22403b653276",
                        "d6e37fb1-5f7e-448e-847b-7d1f1271c574",
                        "e8aa5e4f-d877-46c5-b3c8-6facecb5d959",
                        "e91a0a81-da9c-4009-9007-18ba9b8595b2",
                        "e9f4315c-139f-400c-b6e5-1e5cb369191d",
                        "ed59a2e5-7330-4e07-9edf-cc80872135d0"
                    ],
                    "keyword": [
                        "learning",
                        "methods",
                        "face",
                        "network",
                        "wide",
                        "snowbased",
                        "set",
                        "range",
                        "linear",
                        "images"
                    ],
                    "group": [],
                    "_id": "8f6a657e-e387-4572-bb88-91aee042e8da",
                    "abstract": "A novel learning approach for human face detection using a network of linear units is presented. The SNoW learning architecture is a sparse network of linear functions over a pre-defined or incrementally learned feature space and is specifically tailored for learning in the presence of a very large number of features. A wide range of face images in different poses, with different expressions and under different lighting conditions are used as a training set to capture the variations of human faces. Experimental results on commonly used benchmark data sets of a wide range of face images show that the SNoW-based approach outperforms methods that use neural networks, Bayesian methods, support vector machines and others. Furthermore, learning and evaluation using the SNoW-based method are significantly more efficient than with other methods.",
                    "title": "A SNoW-Based Face Detector",
                    "venue": "neural information processing systems",
                    "year": 2000,
                    "__v": 2,
                    "citationCount": 148,
                    "result": 6.699278499278499
                },
                "9fa55b0f-eaa6-4c59-b6e5-77e5f1a406f0": {
                    "authors": [
                        "Franklin C. Crow"
                    ],
                    "references": [
                        "023ba930-7460-4044-98b9-f49a14423f8d",
                        "24170cb6-386a-4beb-bdbd-633643045a04",
                        "47cadce1-29d8-4a65-8d19-5d7acd50d366",
                        "6038a4bb-7978-4fac-9751-c929871d2fe4",
                        "9ecac0ea-d548-4b3d-b77d-bed14dc8c030"
                    ],
                    "keyword": [
                        "technique",
                        "texture",
                        "tables",
                        "function",
                        "costs",
                        "computations",
                        "yield",
                        "values",
                        "tractable",
                        "texturemap"
                    ],
                    "group": [],
                    "_id": "9fa55b0f-eaa6-4c59-b6e5-77e5f1a406f0",
                    "abstract": "Texture-map computations can be made tractable through use of precalculated tables which allow computational costs independent of the texture density. The first example of this technique, the “mip” map, uses a set of tables containing successively lower-resolution representations filtered down from the discrete texture function. An alternative method using a single table of values representing the integral over the texture function rather than the function itself may yield superior results at similar cost. The necessary algorithms to support the new technique are explained. Finally, the cost and performance of the new technique is compared to previous techniques.",
                    "title": "Summed-area tables for texture mapping",
                    "venue": "international conference on computer graphics and interactive techniques",
                    "year": 1984,
                    "__v": 2,
                    "citationCount": 488,
                    "result": 7.649458538649546
                },
                "b49c1e2b-0cd0-4950-a724-00c698e5b49d": {
                    "authors": [
                        "John Ross Quinlan"
                    ],
                    "references": [
                        "14bf22f7-7122-4a3d-8273-47ac434d75ad",
                        "8683b169-fa91-44f5-b164-5f00310c7e23",
                        "9413fafa-9972-49c2-993f-dae7613abde5",
                        "c2c4f5fa-9f73-4e82-abd9-5c4ca93e8e1c",
                        "c9d7e50e-26d6-41f1-aa09-f49fc546af36",
                        "d4b23547-44a0-457d-a4cc-79051c27cb72"
                    ],
                    "keyword": [
                        "systems",
                        "paper",
                        "variety",
                        "trees",
                        "technology",
                        "synthesizing",
                        "summarizes",
                        "successfully",
                        "studies",
                        "show"
                    ],
                    "group": [],
                    "_id": "b49c1e2b-0cd0-4950-a724-00c698e5b49d",
                    "abstract": "The technology for building knowledge-based systems by inductive inference from examples has been demonstrated successfully in several practical applications. This paper summarizes an approach to synthesizing decision trees that has been used in a variety of systems, and it describes one such system, ID3, in detail. Results from recent studies show ways in which the methodology can be modified to deal with information that is noisy and/or incomplete. A reported shortcoming of the basic algorithm is discussed and two means of overcoming it are compared. The paper concludes with illustrations of current research directions.",
                    "title": "Induction of Decision Trees",
                    "venue": "Machine Learning",
                    "year": 1986,
                    "__v": 2,
                    "citationCount": 4703,
                    "result": 5.245736304048323
                },
                "c7f93552-c1ef-4ae4-b1f5-2317e1c9d904": {
                    "authors": [
                        "Henry Schneiderman",
                        "Takeo Kanade"
                    ],
                    "references": [
                        "310cbba4-d88d-4bf4-a4f2-738f91b5f8c8",
                        "4a29b56b-b74e-4945-9017-61a7ab844fd9",
                        "8f6a657e-e387-4572-bb88-91aee042e8da",
                        "96d6d9b9-6d69-4c9a-b3f5-c8083966d55c",
                        "bb83383f-0de9-408b-9ba2-aa902c63f14a",
                        "d5e5a24d-f80e-4f1a-b48b-22403b653276",
                        "d6e37fb1-5f7e-448e-847b-7d1f1271c574",
                        "db26488d-78be-44b1-a343-e896f43c5d29",
                        "ed59a2e5-7330-4e07-9edf-cc80872135d0"
                    ],
                    "keyword": [
                        "statistical",
                        "represent",
                        "object",
                        "histograms",
                        "detection",
                        "wide",
                        "reliably",
                        "method",
                        "algorithm",
                        "wavelet"
                    ],
                    "group": [],
                    "_id": "c7f93552-c1ef-4ae4-b1f5-2317e1c9d904",
                    "abstract": "In this paper, we describe a statistical method for 3D object detection. We represent the statistics of both object appearance and \"non-object\" appearance using a product of histograms. Each histogram represents the joint statistics of a subset of wavelet coefficients and their position on the object. Our approach is to use many such histograms representing a wide variety of visual attributes. Using this method, we have developed the first algorithm that can reliably detect human faces with out-of-plane rotation and the first algorithm that can reliably detect passenger cars over a wide range of viewpoints.",
                    "title": "A statistical method for 3D object detection applied to faces and cars",
                    "venue": "computer vision and pattern recognition",
                    "year": 2000,
                    "__v": 2,
                    "citationCount": 525,
                    "result": 8.029598995775466
                },
                "d5e5a24d-f80e-4f1a-b48b-22403b653276": {
                    "authors": [
                        "Kah Kay Sung",
                        "Tomaso Poggio"
                    ],
                    "references": [
                        "17bb9954-1e92-4f77-b952-8f99153aba0c",
                        "1e4f4b5c-55e0-4d5b-b7cc-9e7fada3e341",
                        "3b3d7569-08b1-4017-9910-2a017a00e43e",
                        "3e7823cd-cff6-43b3-8df8-990f5525eb50",
                        "64fa74e8-db02-4190-87d7-bf23e9859a7c",
                        "85114f9d-70a8-4940-83aa-af504b75acf8",
                        "9499c3b8-c1f9-4d80-9cfb-c0b9b26b2511"
                    ],
                    "keyword": [
                        "models",
                        "faces",
                        "vector",
                        "locating",
                        "image",
                        "human",
                        "feature",
                        "difference",
                        "patterns",
                        "nonface"
                    ],
                    "group": [],
                    "_id": "d5e5a24d-f80e-4f1a-b48b-22403b653276",
                    "abstract": "We present an example-based learning approach for locating vertical frontal views of human faces in complex scenes. The technique models the distribution of human face patterns by means of a few view-based \"face\" and \"nonface\" model clusters. At each image location, a difference feature vector is computed between the local image pattern and the distribution-based model. A trained classifier determines, based on the difference feature vector measurements, whether or not a human face exists at the current image location. We show empirically that the distance metric we adopt for computing difference feature vectors, and the \"nonface\" clusters we include in our distribution-based model, are both critical for the success of our system.",
                    "title": "Example-based learning for view-based human face detection",
                    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "year": 1998,
                    "__v": 2,
                    "citationCount": 802,
                    "result": 6.787155242418404
                },
                "d6e37fb1-5f7e-448e-847b-7d1f1271c574": {
                    "authors": [
                        "Henry A. Rowley",
                        "Shumeet Baluja",
                        "Takeo Kanade"
                    ],
                    "references": [
                        "0150e8cd-09bc-4991-92b4-454fe4b0bfac",
                        "0b4c0d6f-58fd-4704-98af-8c12de196ede",
                        "168d7a6e-46b3-41b6-8776-3890b23b6b1c",
                        "1863ec2a-4485-4bf6-80c4-6dfce4a8d627",
                        "1c940510-5473-4e01-9c7c-bce8e006134a",
                        "1d1fe6e4-bf7f-4785-893a-04156d3cfa6a",
                        "2a08b967-f90e-43d5-860e-d07ef09431c2",
                        "40f728c0-55b3-423b-aff5-a9b3ff27b7d5",
                        "47e8badc-7db1-4e43-99e7-6fea4a6d65e3",
                        "49b0495d-2caa-4dbf-b1ab-6f9695b8bd72",
                        "59242d60-5827-412a-ab6c-69ba14fa3b6a",
                        "5ffac6f9-2456-42cf-830c-9049ce37c899",
                        "6ca64ec6-3080-42c1-8970-33677cb1e3f1",
                        "772654a7-a951-4327-aca5-ba5da8dfec7c",
                        "79bd9613-8976-41a1-b0b7-133b80b8477e",
                        "88b9bcca-fb07-4eb3-8dba-d5a06741c360",
                        "91979159-37d8-410f-a245-a33ef80a092b",
                        "9499c3b8-c1f9-4d80-9cfb-c0b9b26b2511",
                        "98df207d-2dfc-4365-846a-c875a2a3a59e",
                        "ac0fee21-9f70-4e21-8536-5c9b5d3dc420",
                        "ae3e7593-586f-495f-9416-4b50ed1fcd10",
                        "cdbb7784-a0c2-4b40-bd6d-d14fc14651a7",
                        "ce9c0c07-83af-4fb7-9491-38255660025c",
                        "d42f853d-12d7-416d-8b27-c314ef563eed",
                        "e29cd2ee-bb3e-4c90-a085-ebd358cd4757",
                        "e41b2fd1-c576-453e-9a22-9b0eeafe308c",
                        "e9f4315c-139f-400c-b6e5-1e5cb369191d",
                        "eb2dc957-4aae-4d39-a99d-8adab1effb39",
                        "eca46fc4-e594-461f-83b8-aa5247e440ca",
                        "f3eb4ac3-9302-42aa-be89-7cf746f286fd",
                        "fe966e48-ad81-4d33-af4f-b9e2509b64ed"
                    ],
                    "keyword": [
                        "face",
                        "training",
                        "system",
                        "detection",
                        "present",
                        "network",
                        "image",
                        "examples",
                        "windows",
                        "performance"
                    ],
                    "group": [],
                    "_id": "d6e37fb1-5f7e-448e-847b-7d1f1271c574",
                    "abstract": "We present a neural network-based upright frontal face detection system. A retinally connected neural network examines small windows of an image and decides whether each window contains a face. The system arbitrates between multiple networks to improve performance over a single network. We present a straightforward procedure for aligning positive face examples for training. To collect negative examples, we use a bootstrap algorithm, which adds false detections into the training set as training progresses. This eliminates the difficult task of manually selecting nonface training examples, which must be chosen to span the entire space of nonface images. Simple heuristics, such as using the fact that faces rarely overlap in images, can further improve the accuracy. Comparisons with several other state-of-the-art face detection systems are presented, showing that our system has comparable performance in terms of detection and false-positive rates.",
                    "title": "Neural network-based face detection",
                    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "year": 1998,
                    "__v": 2,
                    "citationCount": 1384,
                    "result": 8.03726448989607
                },
                "f1bd37c4-d033-4cd1-af44-4df9f11c71e4": {
                    "authors": [
                        "F. Fleuret",
                        "Donald Geman"
                    ],
                    "references": [
                        "2958fc5c-15e8-45e7-8da8-d2e0fa46f0c7",
                        "5242f101-1511-4660-9a4c-4eb597aaa3c6",
                        "55fa440a-2b98-4e8e-bb45-fa09598b4eca",
                        "5ffac6f9-2456-42cf-830c-9049ce37c899",
                        "613841ae-c925-4aee-9c2e-8675213e4bbf",
                        "64fa74e8-db02-4190-87d7-bf23e9859a7c",
                        "6610284f-1f5a-4460-95d6-b0ad690e171d",
                        "6da113cb-3257-4014-990b-2ebbb7d998f2",
                        "757078f8-0e20-4c8b-a907-5d068db66fc4",
                        "762c9918-e579-42ef-80e5-4e464870a017",
                        "b85ac095-a9f2-4954-b2bf-f53fde98958c",
                        "bcc5343a-dee5-4e42-bd84-6700cbab125e",
                        "bec76d54-02fb-4e7e-8a9c-c058f780194d",
                        "cd9494ab-fbd2-401d-8afe-376c0bd24c80",
                        "d5e5a24d-f80e-4f1a-b48b-22403b653276",
                        "d6e37fb1-5f7e-448e-847b-7d1f1271c574",
                        "ea294286-3cc2-4979-a22b-2fbb78c2ef18"
                    ],
                    "keyword": [],
                    "group": [],
                    "_id": "f1bd37c4-d033-4cd1-af44-4df9f11c71e4",
                    "abstract": "We study visual selection: Detect and roughly localize all instances of a generic object class, such as a face, in a greyscale scene, measuring performance in terms of computation and false alarms. Our approach is sequential testing which is coarse-to-fine in both in the exploration of poses and the representation of objects. All the tests are binary and indicate the presence or absence of loose spatial arrangements of oriented edge fragments. Starting from training examples, we recursively find larger and larger arrangements which are “decomposable,” which implies the probability of an arrangement appearing on an object decays slowly with its size. Detection means finding a sufficient number of arrangements of each size along a decreasing sequence of pose cells. At the beginning, the tests are simple and universal, accommodating many poses simultaneously, but the false alarm rate is relatively high. Eventually, the tests are more discriminating, but also more complex and dedicated to specific poses. As a result, the spatial distribution of processing is highly skewed and detection is rapid, but at the expense of (isolated) false alarms which, presumably, could be eliminated with localized, more intensive, processing.",
                    "title": "Coarse-to-Fine Face Detection",
                    "venue": "International Journal of Computer Vision",
                    "year": 2001,
                    "__v": 0,
                    "citationCount": 131,
                    "result": 2.5
                }
            }
        ],
        "_id": "8b8a2247-bd77-4736-b493-449734f56b9a",
        "abstract": "This paper describes a face detection framework that is capable of processing images extremely rapidly while achieving high detection rates. There are three key contributions. The first is the introduction of a new image representation called the “Integral Image” which allows the features used by our detector to be computed very quickly. The second is a simple and efficient classifier which is built using the AdaBoost learning algorithm (Freund and Schapire, 1995) to select a small number of critical visual features from a very large set of potential features. The third contribution is a method for combining classifiers in a “cascade” which allows background regions of the image to be quickly discarded while spending more computation on promising face-like regions. A set of experiments in the domain of face detection is presented. The system yields face detection performance comparable to the best previous systems (Sung and Poggio, 1998; Rowley et al., 1998; Schneiderman and Kanade, 2000; Roth et al., 2000). Implemented on a conventional desktop, face detection proceeds at 15 frames per second.",
        "title": "Robust real-time face detection",
        "venue": "international conference on computer vision",
        "year": 2001,
        "__v": 3,
        "citationCount": 4436
    },
    {
        "authors": [
            "Frank R. Kschischang",
            "Brendan J. Frey",
            "Hans-Andrea Loeliger"
        ],
        "references": [
            "6f9aeb94-bd72-4ac6-8ec4-4c3f98dcb993",
            "7963ab0f-472d-47ec-a2d9-d21d72e390b2",
            "7d13dc57-6231-4275-bbd6-ecc7a2935795",
            "8285b7c1-a2cd-4916-ad56-afc0eceeb815",
            "8611c7fe-134c-47dd-8ae2-0bf04fe8f224",
            "9ec287ca-9bbf-4b96-96e3-fdb78a808228",
            "b897fabf-4e80-4491-87db-3e5bb81a8bd3",
            "c5a3d783-7e53-43b0-9ef5-a333af312ced"
        ],
        "keyword": [
            "algorithms",
            "functions",
            "factor",
            "sumproduct",
            "graph",
            "variables",
            "global",
            "derived"
        ],
        "group": [
            {
                "6f9aeb94-bd72-4ac6-8ec4-4c3f98dcb993": {
                    "authors": [
                        "Robert J. McEliece",
                        "David J. C. MacKay",
                        "Jung-Fu Cheng"
                    ],
                    "references": [
                        "20e2f5a8-deb4-4216-8f9e-69ed379bd66a",
                        "2b65cf67-1c71-4509-9f2c-52e48ac183f8",
                        "333fea0a-edb1-48d6-8efe-d4425b3d4396",
                        "3595fa71-68db-476e-9cb7-ad6ece6f446e",
                        "3e7689e9-49da-4607-b1e8-034f3359f47c",
                        "45a83c74-42cf-4193-b8fc-17c1853f26e4",
                        "610c0014-3812-4ade-9c60-746a9acf3f73",
                        "62febf9b-1438-4218-a965-93b136fb428f",
                        "736eee36-d6fd-4d8d-86bc-ed3047007cad",
                        "7d13dc57-6231-4275-bbd6-ecc7a2935795",
                        "8192d2df-8e42-4366-9d0a-efba8b748cef",
                        "8285b7c1-a2cd-4916-ad56-afc0eceeb815",
                        "84d51516-9812-4d83-b9e3-337a078a8100",
                        "8611c7fe-134c-47dd-8ae2-0bf04fe8f224",
                        "9ec287ca-9bbf-4b96-96e3-fdb78a808228",
                        "a74969a9-0bd6-4cfd-a520-f57088deaed0",
                        "aa8df09d-259d-490d-b1b6-d3775a02ab07",
                        "ad3a4ba4-5b88-4d61-9ba5-263cda996e9c",
                        "b897fabf-4e80-4491-87db-3e5bb81a8bd3",
                        "c9ea1ab7-b2db-4c0f-9696-80e3310cec6c",
                        "d92b0700-ed07-40b9-b3e2-0273fea711dd",
                        "db6588f7-45b8-4083-8845-d99f1d8f2b2d"
                    ],
                    "keyword": [
                        "algorithm",
                        "decoding",
                        "codes",
                        "pearl's",
                        "belief",
                        "turbo",
                        "iterative",
                        "systems",
                        "propagation",
                        "loops"
                    ],
                    "group": [],
                    "_id": "6f9aeb94-bd72-4ac6-8ec4-4c3f98dcb993",
                    "abstract": "We describe the close connection between the now celebrated iterative turbo decoding algorithm of Berrou et al. (1993) and an algorithm that has been well known in the artificial intelligence community for a decade, but which is relatively unknown to information theorists: Pearl's (1982) belief propagation algorithm. We see that if Pearl's algorithm is applied to the \"belief network\" of a parallel concatenation of two or more codes, the turbo decoding algorithm immediately results. Unfortunately, however, this belief diagram has loops, and Pearl only proved that his algorithm works when there are no loops, so an explanation of the experimental performance of turbo decoding is still lacking. However, we also show that Pearl's algorithm can be used to routinely derive previously known iterative, but suboptimal, decoding algorithms for a number of other error-control systems, including Gallager's (1962) low-density parity-check codes, serially concatenated codes, and product codes. Thus, belief propagation provides a very attractive general methodology for devising low-complexity iterative decoding algorithms for hybrid coded systems.",
                    "title": "Turbo decoding as an instance of Pearl's \"belief propagation\" algorithm",
                    "venue": "IEEE Journal on Selected Areas in Communications",
                    "year": 1998,
                    "__v": 2,
                    "citationCount": 340,
                    "result": 10.44624239709379
                },
                "7963ab0f-472d-47ec-a2d9-d21d72e390b2": {
                    "authors": [
                        "Srinivas M. Aji",
                        "Robert J. McEliece"
                    ],
                    "references": [
                        "248875d2-e08a-4566-bc6f-650bf1734313",
                        "3595fa71-68db-476e-9cb7-ad6ece6f446e",
                        "51657f5d-8e60-4a5f-9797-d7bd64609284",
                        "527187d3-e96a-4e67-b947-a5911f51804f",
                        "6f9aeb94-bd72-4ac6-8ec4-4c3f98dcb993",
                        "7d13dc57-6231-4275-bbd6-ecc7a2935795",
                        "8285b7c1-a2cd-4916-ad56-afc0eceeb815",
                        "8cea470a-9c6d-4137-8f4c-acda7e0d1904",
                        "9ec287ca-9bbf-4b96-96e3-fdb78a808228",
                        "b897fabf-4e80-4491-87db-3e5bb81a8bd3",
                        "c37d3e37-e57b-44c4-bcde-888112e7695c",
                        "d68203bb-77bb-45fa-9ea8-8e014c3e26d8"
                    ],
                    "keyword": [
                        "algorithm",
                        "decoding",
                        "cases",
                        "work",
                        "turbo",
                        "propagation",
                        "includes",
                        "general",
                        "gdl"
                    ],
                    "group": [],
                    "_id": "7963ab0f-472d-47ec-a2d9-d21d72e390b2",
                    "abstract": "We discuss a general message passing algorithm, which we call the generalized distributive law (GDL). The GDL is a synthesis of the work of many authors in information theory, digital communications, signal processing, statistics, and artificial intelligence. It includes as special cases the Baum-Welch algorithm, the fast Fourier transform (FFT) on any finite Abelian group, the Gallager-Tanner-Wiberg decoding algorithm, Viterbi's algorithm, the BCJR algorithm, Pearl's \"belief propagation\" algorithm, the Shafer-Shenoy probability propagation algorithm, and the turbo decoding algorithm. Although this algorithm is guaranteed to give exact answers only in certain cases (the \"junction tree\" condition), unfortunately not including the cases of GTW with cycles or turbo decoding, there is much experimental evidence, and a few theorems, suggesting that it often works approximately even when it is not supposed to.",
                    "title": "The generalized distributive law",
                    "venue": "IEEE Transactions on Information Theory",
                    "year": 2000,
                    "__v": 1,
                    "citationCount": 301,
                    "result": 10.275096059770982
                },
                "7d13dc57-6231-4275-bbd6-ecc7a2935795": {
                    "authors": [
                        "Robert Michael Tanner"
                    ],
                    "references": [
                        "2241936c-1eaa-408c-b72c-8d66021f7b70",
                        "3ba9d82f-1fc3-48fb-b037-780b03dfd68d",
                        "7736630d-4dcf-44f5-9812-2394318d97c8",
                        "a0d69c45-6eba-498f-b8be-8e49615e5da2",
                        "a662a4e7-415e-417e-8a8f-fe085d7e487f",
                        "d5af3e68-0370-4713-b40f-d0d7f2dd94af"
                    ],
                    "keyword": [
                        "codes",
                        "decoders",
                        "subcodes",
                        "graph",
                        "shown",
                        "shorter",
                        "proposed",
                        "information",
                        "errorcorrecting",
                        "digits"
                    ],
                    "group": [],
                    "_id": "7d13dc57-6231-4275-bbd6-ecc7a2935795",
                    "abstract": "A method is described for constructing long error-correcting codes from one or more shorter error-correcting codes, referred to as subcodes, and a bipartite graph. A graph is shown which specifies carefully chosen subsets of the digits of the new codes that must be codewords in one of the shorter subcodes. Lower bounds to the rate and the minimum distance of the new code are derived in terms of the parameters of the graph and the subeodes. Both the encoders and decoders proposed are shown to take advantage of the code's explicit decomposition into subcodes to decompose and simplify the associated computational processes. Bounds on the performance of two specific decoding algorithms are established, and the asymptotic growth of the complexity of decoding for two types of codes and decoders is analyzed. The proposed decoders are able to make effective use of probabilistic information supplied by the channel receiver, e.g., reliability information, without greatly increasing the number of computations required. It is shown that choosing a transmission order for the digits that is appropriate for the graph and the subcodes can give the code excellent burst-error correction abilities. The construction principles",
                    "title": "A recursive approach to low complexity codes",
                    "venue": "IEEE Transactions on Information Theory",
                    "year": 1981,
                    "__v": 2,
                    "citationCount": 1026,
                    "result": 4.844049981292545
                },
                "8285b7c1-a2cd-4916-ad56-afc0eceeb815": {
                    "authors": [
                        "Frank R. Kschischang",
                        "Brendan J. Frey"
                    ],
                    "references": [
                        "6f9aeb94-bd72-4ac6-8ec4-4c3f98dcb993",
                        "7d13dc57-6231-4275-bbd6-ecc7a2935795",
                        "8611c7fe-134c-47dd-8ae2-0bf04fe8f224",
                        "9ec287ca-9bbf-4b96-96e3-fdb78a808228",
                        "aa8df09d-259d-490d-b1b6-d3775a02ab07",
                        "b897fabf-4e80-4491-87db-3e5bb81a8bd3",
                        "d3e00e7e-1c64-4d7a-b2b2-1ad98ba4c706",
                        "e3053caa-aafc-45a5-9e84-929dd3d997f4"
                    ],
                    "keyword": [
                        "codes",
                        "algorithms",
                        "decoding",
                        "model",
                        "iterative",
                        "graphical",
                        "deriving",
                        "propagation",
                        "networks",
                        "graphs"
                    ],
                    "group": [],
                    "_id": "8285b7c1-a2cd-4916-ad56-afc0eceeb815",
                    "abstract": "We present a unified graphical model framework for describing compound codes and deriving iterative decoding algorithms. After reviewing a variety of graphical models (Markov random fields, Tanner graphs, and Bayesian networks), we derive a general distributed marginalization algorithm for functions described by factor graphs. From this general algorithm, Pearl's (1986) belief propagation algorithm is easily derived as a special case. We point out that iterative decoding algorithms for various codes, including \"turbo decoding\" of parallel-concatenated convolutional codes, may be viewed as probability propagation in a graphical model of the code. We focus on Bayesian network descriptions of codes, which give a natural input/state/output/channel description of a code and channel, and we indicate how iterative decoders can be developed for parallel-and serially concatenated coding systems, product codes, and low-density parity-check codes.",
                    "title": "Iterative decoding of compound codes by probability propagation in graphical models",
                    "venue": "IEEE Journal on Selected Areas in Communications",
                    "year": 1998,
                    "__v": 2,
                    "citationCount": 157,
                    "result": 13.314077992870564
                },
                "8611c7fe-134c-47dd-8ae2-0bf04fe8f224": {
                    "authors": [
                        "David J. C. MacKay"
                    ],
                    "references": [
                        "04fc518d-bcb8-46ae-aae0-e762a4bd6b45",
                        "0a857f96-7979-4cfe-be07-b38556c11379",
                        "163c33dd-5a9c-44c4-98ab-5b045734e6a8",
                        "190fd656-b653-42b4-b77b-c6ae42488a1c",
                        "2a071733-dc94-441a-ac07-521913dfc736",
                        "347d0792-c17f-413c-8ec4-b82ab726f2c0",
                        "3595fa71-68db-476e-9cb7-ad6ece6f446e",
                        "5c89a51d-ec74-4587-b06c-60bbfd28c75f",
                        "62febf9b-1438-4218-a965-93b136fb428f",
                        "6bdc98d8-224c-4d2a-b7ef-12ee06ae6400",
                        "6f9aeb94-bd72-4ac6-8ec4-4c3f98dcb993",
                        "786e1963-5f8e-40dc-90fe-a770fffbea18",
                        "7ca4edce-5361-461e-b158-6b44218acc59",
                        "7d13dc57-6231-4275-bbd6-ecc7a2935795",
                        "84d51516-9812-4d83-b9e3-337a078a8100",
                        "8c6298f3-6edb-4fbd-832a-11c8cb03d009",
                        "8ff0a138-f1a0-4419-8b3a-e2542fb11e03",
                        "9ec287ca-9bbf-4b96-96e3-fdb78a808228",
                        "a78c0f40-ccf7-44ab-af61-a3433b168795",
                        "accd62a4-3a66-4fbe-b9d5-0c9128321aee",
                        "ad743da8-f0fc-4f28-9c25-1981b5667c93",
                        "adfe0dda-5d6c-46cd-9e45-a5f1c671151c",
                        "b897fabf-4e80-4491-87db-3e5bb81a8bd3",
                        "b8b308ec-022c-4baf-9d7c-3a1dbc487cb1",
                        "bff11fa3-5279-4b9a-8522-c580c3960db2",
                        "d3e00e7e-1c64-4d7a-b2b2-1ad98ba4c706",
                        "e33d89f1-291f-4ceb-9b6f-ecc166412650",
                        "e6b0a4fb-9126-4766-9d53-348789ad27ec"
                    ],
                    "keyword": [
                        "codes",
                        "channel",
                        "shannon",
                        "result",
                        "practical",
                        "performance",
                        "limit",
                        "gallager",
                        "decoding",
                        "binarysymmetric"
                    ],
                    "group": [],
                    "_id": "8611c7fe-134c-47dd-8ae2-0bf04fe8f224",
                    "abstract": "We study two families of error-correcting codes defined in terms of very sparse matrices. \"MN\" (MacKay-Neal (1995)) codes are recently invented, and \"Gallager codes\" were first investigated in 1962, but appear to have been largely forgotten, in spite of their excellent properties. The decoding of both codes can be tackled with a practical sum-product algorithm. We prove that these codes are \"very good\", in that sequences of codes exist which, when optimally decoded, achieve information rates up to the Shannon limit. This result holds not only for the binary-symmetric channel but also for any channel with symmetric stationary ergodic noise. We give experimental results for binary-symmetric channels and Gaussian channels demonstrating that practical performance substantially better than that of standard convolutional and concatenated codes can be achieved; indeed, the performance of Gallager codes is almost as close to the Shannon limit as that of turbo codes.",
                    "title": "Good error-correcting codes based on very sparse matrices",
                    "venue": "international symposium on information theory",
                    "year": 1997,
                    "__v": 2,
                    "citationCount": 1265,
                    "result": 8.912906998850598
                },
                "9ec287ca-9bbf-4b96-96e3-fdb78a808228": {
                    "authors": [
                        "Lalit R. Bahl",
                        "John Cocke",
                        "Frederick Jelinek",
                        "Josef Raviv"
                    ],
                    "references": [
                        "3595fa71-68db-476e-9cb7-ad6ece6f446e",
                        "73999b4c-db4a-4f80-a56a-4a1a4ea93f7f"
                    ],
                    "keyword": [
                        "problem",
                        "probabilities",
                        "decoding",
                        "transitions",
                        "symbol",
                        "states",
                        "special",
                        "source",
                        "shown",
                        "posteriori"
                    ],
                    "group": [],
                    "_id": "9ec287ca-9bbf-4b96-96e3-fdb78a808228",
                    "abstract": "The general problem of estimating the a posteriori probabilities of the states and transitions of a Markov source observed through a discrete memoryless channel is considered. The decoding of linear block and convolutional codes to minimize symbol error probability is shown to be a special case of this problem. An optimal decoding algorithm is derived.",
                    "title": "Optimal decoding of linear codes for minimizing symbol error rate (Corresp.)",
                    "venue": "IEEE Transactions on Information Theory",
                    "year": 1974,
                    "__v": 1,
                    "citationCount": 2103,
                    "result": 4.005513397850859
                },
                "c5a3d783-7e53-43b0-9ef5-a333af312ced": {
                    "authors": [
                        "Roberto Garello",
                        "Guido Montorsi",
                        "Sergio Benedetto",
                        "Giovanni Cancellieri"
                    ],
                    "references": [
                        "014cbc77-cd11-4280-bce9-9b0d8b6d1729",
                        "06ef3afa-4330-4ab2-a0f2-acdfc36a8568",
                        "0fe3888a-668a-42aa-a6a8-3a2e8a020e07",
                        "126fd2b4-cdb2-44c7-98b2-ab80c036992f",
                        "1810ce66-6e8c-44fb-a7bb-14fd170c7cdb",
                        "31c891bc-d8ac-4832-890e-d919a4d34fd9",
                        "347e9a97-ee5f-4317-9e2b-2fe673eacaa0",
                        "5a87ff21-176c-4905-b9ec-3a50e5b34b60",
                        "6524c88c-aded-4742-8f2d-a29975d94b85",
                        "714b7aaa-d0e8-49ac-8620-0bc6841816af",
                        "9dfb08b1-82ac-4aa9-8105-2a5a2f0f732b",
                        "9ec287ca-9bbf-4b96-96e3-fdb78a808228",
                        "aa6d1b41-0ca4-4a1b-91a1-cc767bd109b8",
                        "c77b2d54-fc77-422c-b64d-35e58c9cc97a",
                        "d35d1e54-6b07-4f04-880f-7d13d424368b",
                        "d92b0700-ed07-40b9-b3e2-0273fea711dd",
                        "e3053caa-aafc-45a5-9e84-929dd3d997f4",
                        "e3ab7120-5193-47cb-802f-47b3098b9387",
                        "e85e8b03-abdd-4ef0-aa7c-47b365654f1b"
                    ],
                    "keyword": [
                        "interleavers",
                        "complexity",
                        "parameters",
                        "code"
                    ],
                    "group": [],
                    "_id": "c5a3d783-7e53-43b0-9ef5-a333af312ced",
                    "abstract": "In this paper, the basic theory of interleavers is revisited in a semi-tutorial manner, and extended to encompass noncausal interleavers. The parameters that characterize the interleaver behavior (like delay, latency, and period) are clearly defined. The input-output interleaver code is introduced and its complexity studied. Connections among various interleaver parameters are explored. The classes of convolutional and block interleavers are considered, and their practical implementation discussed. The trellis complexity of turbo codes is tied to the complexity of the constituent interleaver. A procedure of complexity reduction by coordinate permutation is also presented, together with some examples of its application.",
                    "title": "Interleaver properties and their applications to the trellis complexity analysis of turbo codes",
                    "venue": "IEEE Transactions on Communications",
                    "year": 2001,
                    "__v": 1,
                    "citationCount": 20,
                    "result": 2.7241419914794527
                }
            }
        ],
        "_id": "8cea470a-9c6d-4137-8f4c-acda7e0d1904",
        "abstract": "Algorithms that must deal with complicated global functions of many variables often exploit the manner in which the given functions factor as a product of \"local\" functions, each of which depends on a subset of the variables. Such a factorization can be visualized with a bipartite graph that we call a factor graph, In this tutorial paper, we present a generic message-passing algorithm, the sum-product algorithm, that operates in a factor graph. Following a single, simple computational rule, the sum-product algorithm computes-either exactly or approximately-various marginal functions derived from the global function. A wide variety of algorithms developed in artificial intelligence, signal processing, and digital communications can be derived as specific instances of the sum-product algorithm, including the forward/backward algorithm, the Viterbi algorithm, the iterative \"turbo\" decoding algorithm, Pearl's (1988) belief propagation algorithm for Bayesian networks, the Kalman filter, and certain fast Fourier transform (FFT) algorithms.",
        "title": "Factor graphs and the sum-product algorithm",
        "venue": "IEEE Transactions on Information Theory",
        "year": 2001,
        "__v": 2,
        "citationCount": 2388
    },
    {
        "authors": [
            "Thomas Wiegand",
            "Gary J. Sullivan",
            "Gisle Bjontegaard",
            "Ajay Luthra"
        ],
        "references": [
            "1ea5125c-2c09-47c7-ba82-913bda694a3f",
            "237a87ca-d393-4173-a89d-fd2c5c1f3d37",
            "260a8eb0-9e62-4156-b89b-bb8c9a48e962",
            "32e67a88-4535-4734-8e1b-b79d04ce064d",
            "4aa6d2f8-2633-4e06-849f-f81badaac3d6",
            "55ac55cc-c6ea-4f37-ad4a-e8d8322202d1",
            "586b90e7-e84c-4129-8d7b-8c14cdf2ce78",
            "696bf9e4-eb9d-4d3a-96b3-b41e18d4ac6f",
            "7210fb5d-2d76-4639-9365-e3fe830307b4",
            "7b88373c-de8f-420b-ab8f-94c4da5753f8",
            "7ddd1b00-19c3-4b04-b002-6156433b9af0",
            "d5327892-4102-4cd1-b8e2-87e3d0a3d279"
        ],
        "keyword": [
            "standard",
            "video",
            "264avc",
            "group",
            "experts",
            "coding",
            "applications"
        ],
        "group": [
            {
                "237a87ca-d393-4173-a89d-fd2c5c1f3d37": {
                    "authors": [
                        "Thomas Wiegand",
                        "Heiko Schwarz",
                        "Joch A",
                        "Faouzi Kossentini",
                        "Gary J. Sullivan"
                    ],
                    "references": [
                        "21528d31-71fa-4244-a272-1df8a0492107",
                        "260a8eb0-9e62-4156-b89b-bb8c9a48e962",
                        "32e67a88-4535-4734-8e1b-b79d04ce064d",
                        "37708b6d-80cd-4d60-bc32-9255c830032a",
                        "40004921-c73a-4c14-b261-7581f3628da2",
                        "7210fb5d-2d76-4639-9365-e3fe830307b4",
                        "7b88373c-de8f-420b-ab8f-94c4da5753f8",
                        "94e25efe-d596-4767-99f0-d87f8c950f0c",
                        "bc5b0e19-28da-4859-922a-38c9735fea87",
                        "d5327892-4102-4cd1-b8e2-87e3d0a3d279"
                    ],
                    "keyword": [],
                    "group": [],
                    "_id": "237a87ca-d393-4173-a89d-fd2c5c1f3d37",
                    "abstract": "A unified approach to the coder control of video coding standards such as MPEG-2, H.263, MPEG-4, and the draft video coding standard H.264/AVC (advanced video coding) is presented. The performance of the various standards is compared by means of PSNR and subjective testing results. The results indicate that H.264/AVC compliant encoders typically achieve essentially the same reproduction quality as encoders that are compliant with the previous standards while typically requiring 60% or less of the bit rate.",
                    "title": "Rate-constrained coder control and comparison of video coding standards",
                    "venue": "IEEE Transactions on Circuits and Systems for Video Technology",
                    "year": 2003,
                    "__v": 0,
                    "citationCount": 1998,
                    "result": 4.166666666666667
                },
                "32e67a88-4535-4734-8e1b-b79d04ce064d": {
                    "authors": [
                        "Thomas Stockhammer",
                        "Miska M. Hannuksela",
                        "Thomas Wiegand"
                    ],
                    "references": [
                        "1c556d44-b168-4491-a6ea-8b84f7d69971",
                        "21528d31-71fa-4244-a272-1df8a0492107",
                        "237a87ca-d393-4173-a89d-fd2c5c1f3d37",
                        "2eb82ba0-d2dd-46a8-8fbd-6872c3abe1a5",
                        "3df4d827-20a8-4e4f-b454-5f8261080a4d",
                        "4aa6d2f8-2633-4e06-849f-f81badaac3d6",
                        "68b10ecd-f306-4e04-af8d-b040a1d5b67b",
                        "7ddd1b00-19c3-4b04-b002-6156433b9af0",
                        "93e2599f-e6b0-4df4-949c-7840cb02794a",
                        "94e25efe-d596-4767-99f0-d87f8c950f0c",
                        "9bafdb60-ae87-47be-92f3-14ad87f489d6",
                        "9f2086af-047d-4b6a-80e4-7b52d3aa3eeb",
                        "a0582c2f-2516-4a51-b227-8f2f8b41b5e0",
                        "b884a36e-0c4d-49d7-a815-9fd9b5e4a8b5",
                        "b88ad275-e83f-4751-9e2f-16cbecbcaacc",
                        "cb43e76e-caeb-403d-b1d5-96503a362e3d",
                        "cb6b6e17-ad50-4984-807e-5b33a9b28c02",
                        "cede2f70-f1f1-4484-b5d3-d3c2d0adf8cb",
                        "dbfb0dd3-5bea-4064-98e8-03c977f40873",
                        "ed063f6e-7a7d-4215-b391-d2d10da5e9b7",
                        "fa72ee30-f4e1-4173-b2fa-8723df31a7cd"
                    ],
                    "keyword": [],
                    "group": [],
                    "_id": "32e67a88-4535-4734-8e1b-b79d04ce064d",
                    "abstract": "Video transmission in wireless environments is a challenging task calling for high-compression efficiency as well as a network friendly design. Both have been major goals of the H.264/AVC standardization effort addressing \"conversational\" (i.e., video telephony) and \"nonconversational\" (i.e., storage, broadcast, or streaming) applications. The video compression performance of the H.264/AVC video coding layer typically provides a significant improvement. The network-friendly design goal of H.264/AVC is addressed via the network abstraction layer that has been developed to transport the coded video data over any existing and future networks including wireless systems. The main objective of this paper is to provide an overview over the tools which are likely to be used in wireless environments and discusses the most challenging application, wireless conversational services in greater detail. Appropriate justifications for the application of different tools based on experimental results are presented.",
                    "title": "H.264/AVC in wireless environments",
                    "venue": "IEEE Transactions on Circuits and Systems for Video Technology",
                    "year": 2003,
                    "__v": 0,
                    "citationCount": 233,
                    "result": 2.5
                },
                "55ac55cc-c6ea-4f37-ad4a-e8d8322202d1": {
                    "authors": [
                        "Henrique S. Malvar",
                        "Antti Hallapuro",
                        "Marta Karczewicz",
                        "Louis Kerofsky"
                    ],
                    "references": [],
                    "keyword": [
                        "transform",
                        "computed",
                        "quantization",
                        "multiplications",
                        "avoiding",
                        "arithmetic",
                        "264",
                        "times8",
                        "times4",
                        "tables"
                    ],
                    "group": [],
                    "_id": "55ac55cc-c6ea-4f37-ad4a-e8d8322202d1",
                    "abstract": "This paper presents an overview of the transform and quantization designs in H.264. Unlike the popular 8/spl times/8 discrete cosine transform used in previous standards, the 4/spl times/4 transforms in H.264 can be computed exactly in integer arithmetic, thus avoiding inverse transform mismatch problems. The new transforms can also be computed without multiplications, just additions and shifts, in 16-bit arithmetic, thus minimizing computational complexity, especially for low-end processors. By using short tables, the new quantization formulas use multiplications but avoid divisions.",
                    "title": "Low-complexity transform and quantization in H.264/AVC",
                    "venue": "IEEE Transactions on Circuits and Systems for Video Technology",
                    "year": 2003,
                    "__v": 2,
                    "citationCount": 303,
                    "result": 3.7615907192222977
                },
                "586b90e7-e84c-4129-8d7b-8c14cdf2ce78": {
                    "authors": [
                        "Peter List",
                        "Joch A",
                        "Jani Lainema",
                        "Gisle Bjontegaard",
                        "Marta Karczewicz"
                    ],
                    "references": [
                        "538f18c2-2b14-45fd-82e4-5a71c66d6994",
                        "5f6f177e-db91-429a-9144-5937e4276cef",
                        "ae450d93-393d-4175-b248-84f964839fbe"
                    ],
                    "keyword": [
                        "filter",
                        "coding",
                        "video",
                        "standard",
                        "simple",
                        "selected",
                        "performs",
                        "paper",
                        "operations",
                        "detect"
                    ],
                    "group": [],
                    "_id": "586b90e7-e84c-4129-8d7b-8c14cdf2ce78",
                    "abstract": "This paper describes the adaptive deblocking filter used in the H.264/MPEG-4 AVC video coding standard. The filter performs simple operations to detect and analyze artifacts on coded block boundaries and attenuates those by applying a selected filter.",
                    "title": "Adaptive deblocking filter",
                    "venue": "IEEE Transactions on Circuits and Systems for Video Technology",
                    "year": 2003,
                    "__v": 2,
                    "citationCount": 284,
                    "result": 5.136732711732711
                },
                "696bf9e4-eb9d-4d3a-96b3-b41e18d4ac6f": {
                    "authors": [
                        "Thomas Wedi",
                        "Hans Georg Musmann"
                    ],
                    "references": [
                        "237a87ca-d393-4173-a89d-fd2c5c1f3d37",
                        "7b88373c-de8f-420b-ab8f-94c4da5753f8",
                        "7ec5bf8c-ef1d-4561-a2a4-2b96dc4b95b7",
                        "818a3e74-f654-4a75-b0b9-f7f8346d9160",
                        "94e25efe-d596-4767-99f0-d87f8c950f0c",
                        "bad538ec-41a8-4fb0-81b3-83a87cdd1c32",
                        "d5327892-4102-4cd1-b8e2-87e3d0a3d279"
                    ],
                    "keyword": [
                        "vector",
                        "resolution",
                        "displacement",
                        "coding",
                        "prediction",
                        "interpolation",
                        "filters",
                        "14pel",
                        "wiener",
                        "order"
                    ],
                    "group": [],
                    "_id": "696bf9e4-eb9d-4d3a-96b3-b41e18d4ac6f",
                    "abstract": "In order to reduce the bit rate of video signals, the standardized coding techniques apply motion-compensated prediction in combination with transform coding of the prediction error. By mathematical analysis, it is shown that aliasing components are deteriorating the prediction efficiency. In order to compensate the aliasing, two-dimensional (2-D) and three-dimensional interpolation filters are developed. As a result, motion- and aliasing-compensated prediction with 1/4-pel displacement vector resolution and a separable 2-D Wiener interpolation filter provide a coding gain of up to 2 dB when compared to 1/2-pel displacement vector resolution as it is used in H.263 or MPEG-2. An additional coding gain of 1 dB can be obtained with 1/8-pel displacement vector resolution when compared to 1/4-pel displacement vector resolution. In consequence of the significantly improved coding efficiency, a Wiener interpolation filter and 1/4-pel displacement vector resolution is applied in H.264/AVC and in MPEG-4 (advanced simple profile).",
                    "title": "Motion- and aliasing-compensated prediction for hybrid video coding",
                    "venue": "IEEE Transactions on Circuits and Systems for Video Technology",
                    "year": 2003,
                    "__v": 2,
                    "citationCount": 83,
                    "result": 6.315653520960426
                },
                "7210fb5d-2d76-4639-9365-e3fe830307b4": {
                    "authors": [
                        "Detlev Marpe",
                        "Heiko Schwarz",
                        "Thomas Wiegand"
                    ],
                    "references": [
                        "14793abe-f83c-4126-b77d-cd535d374885",
                        "237a87ca-d393-4173-a89d-fd2c5c1f3d37",
                        "239071eb-5253-452a-bf53-de04aa83c5a1",
                        "4e47828d-4c0b-4a27-a911-015692119af7",
                        "67b2b3cd-7c5d-4b5f-b301-d6e1bd857ec1",
                        "6d7602e6-0b75-44ca-a0ad-e63dc9a4e52f",
                        "7aab600d-6664-44fe-a1c8-733324555235",
                        "81c04700-d059-4c15-a49e-e019a41117d1",
                        "8d48e23f-7977-4518-b1ee-9fd091b68e81",
                        "94e25efe-d596-4767-99f0-d87f8c950f0c",
                        "9bd00024-b302-407e-92af-5d62759757bd",
                        "aec18dd9-31ea-4d47-856c-b88c108eb625",
                        "b9583494-0b9f-43e6-a5b8-d654b9e6fbf1",
                        "d4cd99a4-620d-4150-b5c8-243c3bae7bf9"
                    ],
                    "keyword": [
                        "coding",
                        "cabac",
                        "binary",
                        "arithmetic",
                        "adaptive",
                        "video",
                        "typical",
                        "method",
                        "applications",
                        "achieved"
                    ],
                    "group": [],
                    "_id": "7210fb5d-2d76-4639-9365-e3fe830307b4",
                    "abstract": "Context-based adaptive binary arithmetic coding (CABAC) as a normative part of the new ITU-T/ISO/IEC standard H.264/AVC for video compression is presented. By combining an adaptive binary arithmetic coding technique with context modeling, a high degree of adaptation and redundancy reduction is achieved. The CABAC framework also includes a novel low-complexity method for binary arithmetic coding and probability estimation that is well suited for efficient hardware and software implementations. CABAC significantly outperforms the baseline entropy coding method of H.264/AVC for the typical area of envisaged target applications. For a set of test sequences representing typical material used in broadcast applications and for a range of acceptable video quality of about 30 to 38 dB, average bit-rate savings of 9%-14% are achieved.",
                    "title": "Context-based adaptive binary arithmetic coding in the H.264/AVC video compression standard",
                    "venue": "IEEE Transactions on Circuits and Systems for Video Technology",
                    "year": 2003,
                    "__v": 2,
                    "citationCount": 429,
                    "result": 5.458706816059757
                },
                "7b88373c-de8f-420b-ab8f-94c4da5753f8": {
                    "authors": [
                        "Markus Flierl",
                        "Bernd Girod"
                    ],
                    "references": [
                        "237a87ca-d393-4173-a89d-fd2c5c1f3d37",
                        "239d0c17-d44e-43ce-b0f3-18ebc8823de3",
                        "2eef0cb1-cc0c-48ee-9eea-2034711aa345",
                        "31907507-643d-4bf0-a6f2-8cec94d9d779",
                        "40004921-c73a-4c14-b261-7581f3628da2",
                        "59b905dd-c832-4d30-8e29-5062a0d6d8c9",
                        "7210fb5d-2d76-4639-9365-e3fe830307b4",
                        "8af0e559-c8c4-4960-a883-f6a23c840215",
                        "d5327892-4102-4cd1-b8e2-87e3d0a3d279"
                    ],
                    "keyword": [
                        "prediction",
                        "pictures",
                        "signals",
                        "show",
                        "multihypothesis",
                        "combined",
                        "264avc",
                        "reference",
                        "ratedistortion",
                        "layer"
                    ],
                    "group": [],
                    "_id": "7b88373c-de8f-420b-ab8f-94c4da5753f8",
                    "abstract": "This paper reviews recent advances in using B pictures in the context of the draft H.264/AVC video-compression standard. We focus on reference picture selection and linearly combined motion-compensated prediction signals. We show that bidirectional prediction exploits partially the efficiency of combined prediction signals whereas multihypothesis prediction allows a more general form of B pictures. The general concept of linearly combined prediction signals chosen from an arbitrary set of reference pictures improves the H.264/AVC test model TML-9 which is used in the following. We outline H.264/AVC macroblock prediction modes for B pictures, classify them into four groups and compare their efficiency in terms of rate-distortion performance. When investigating multihypothesis prediction, we show that bidirectional prediction is a special case of this concept. Multihypothesis prediction allows also two combined forward prediction signals. Experimental results show that this case is also advantageous in terms of compression efficiency. The draft H.264/AVC video-compression standard offers improved entropy coding by context-based adaptive binary arithmetic coding. Simulations show that the gains by multihypothesis prediction and arithmetic coding are additive. B pictures establish an enhancement layer and are predicted from reference pictures that are provided by the base layer. The quality of the base layer influences the rate-distortion trade-off for B pictures. We demonstrate how the quality of the B pictures should be reduced to improve the overall rate-distortion performance of the scalable representation.",
                    "title": "Generalized B pictures and the draft H.264/AVC video-compression standard",
                    "venue": "IEEE Transactions on Circuits and Systems for Video Technology",
                    "year": 2003,
                    "__v": 2,
                    "citationCount": 79,
                    "result": 5.559866332497911
                },
                "7ddd1b00-19c3-4b04-b002-6156433b9af0": {
                    "authors": [
                        "Stephan Wenger"
                    ],
                    "references": [
                        "237a87ca-d393-4173-a89d-fd2c5c1f3d37",
                        "2e0e474a-0156-45f2-b50d-5c5f105b5b52",
                        "32e67a88-4535-4734-8e1b-b79d04ce064d",
                        "3df4d827-20a8-4e4f-b454-5f8261080a4d",
                        "6f1bb20f-25f0-4d0b-a7a5-f31e3fa66bdd",
                        "8fe1bab5-92eb-42fc-8132-f7bd24e83494",
                        "94e25efe-d596-4767-99f0-d87f8c950f0c"
                    ],
                    "keyword": [
                        "video",
                        "264",
                        "network",
                        "coding",
                        "vcl",
                        "tools",
                        "strings",
                        "rtp",
                        "performs",
                        "layer"
                    ],
                    "group": [],
                    "_id": "7ddd1b00-19c3-4b04-b002-6156433b9af0",
                    "abstract": "H.264 is the ITU-T's new, nonbackward compatible video compression Recommendation that significantly outperforms all previous video compression standards. It consists of a video coding layer (VCL) which performs all the classic signal processing tasks and generates bit strings containing coded macroblocks, and a network adaptation layer (NAL) which adapts those bit strings in a network friendly way. The paper describes the use of H.264 coded video over best-effort IP networks, using RTP as the real-time transport protocol. After a description of the environment, the error-resilience tools of H.264 and the draft specification of the RTP payload format are introduced. Next the performance of several possible VCL- and NAL-based error-resilience tools of H.264 are verified in simulations.",
                    "title": "H.264/AVC over IP",
                    "venue": "IEEE Transactions on Circuits and Systems for Video Technology",
                    "year": 2003,
                    "__v": 1,
                    "citationCount": 278,
                    "result": 5.798984348984348
                },
                "d5327892-4102-4cd1-b8e2-87e3d0a3d279": {
                    "authors": [
                        "Thomas Wiegand",
                        "Xiaozheng Zhang",
                        "Bernd Girod"
                    ],
                    "references": [
                        "10ee658a-64c0-432e-b2bb-759d7ce333fc",
                        "21528d31-71fa-4244-a272-1df8a0492107",
                        "31907507-643d-4bf0-a6f2-8cec94d9d779",
                        "346962dd-8989-4875-b724-1869688fec35",
                        "37708b6d-80cd-4d60-bc32-9255c830032a",
                        "41f2d24d-a212-4e8c-9ef9-8bb847435d4f",
                        "445e0ccc-70c9-4f59-9b34-1800a8f75f5a",
                        "74b8bee0-ab67-4543-ab57-260b9ff301e6",
                        "781a6016-9ed4-4ebf-95c6-dc3c72f4457e",
                        "91f88443-327f-4844-8fa4-2875908e3add",
                        "9dee56d9-8fd5-414c-83ae-31551b20ae88",
                        "a2ece6c0-bde5-4bb4-99d1-4cce80b89118",
                        "a72238b8-8ea8-4759-85dd-4f592fe6ef89",
                        "ab8cfea7-61ac-4071-b13b-da7ad6c9c439",
                        "b0599f00-217d-4bd8-b02b-04d22238d3b1",
                        "b8d8d081-fa66-42db-adf8-6bd769026575",
                        "c7ec7611-23ef-44b9-86ae-10902648bb30",
                        "fbb3df8d-35ed-462f-a0e8-da4a9fd5ea3c"
                    ],
                    "keyword": [
                        "prediction",
                        "motion",
                        "memory",
                        "longterm",
                        "rate",
                        "improved",
                        "frames",
                        "decoded"
                    ],
                    "group": [],
                    "_id": "d5327892-4102-4cd1-b8e2-87e3d0a3d279",
                    "abstract": "Long-term memory motion-compensated prediction extends the spatial displacement vector utilized in block-based hybrid video coding by a variable time delay permitting the use of more frames than the previously decoded one for motion compensated prediction. The long-term memory covers several seconds of decoded frames at the encoder and decoder. The use of multiple frames for motion compensation in most cases provides significantly improved prediction gain. The variable time delay has to be transmitted as side information requiring an additional bit rate which may be prohibitive when the size of the long-term memory becomes too large. Therefore, me control the bit rate of the motion information by employing rate constrained motion estimation. Simulation results are obtained by integrating long-term memory prediction into an H.263 codec. Reconstruction PSNR improvements up to 2 dB for the Foreman sequence and 1.5 dB for the Mother-Daughter sequence are demonstrated in comparison to the TMN-2.0 H.263 coder. The PSNR improvements correspond to bit-rate savings up to 34 and 30%, respectively. Mathematical inequalities are used to speed up motion estimation while achieving full prediction gain.",
                    "title": "Long-term memory motion-compensated prediction",
                    "venue": "IEEE Transactions on Circuits and Systems for Video Technology",
                    "year": 1999,
                    "__v": 2,
                    "citationCount": 153,
                    "result": 2.237792762792763
                }
            }
        ],
        "_id": "94e25efe-d596-4767-99f0-d87f8c950f0c",
        "abstract": "H.264/AVC is newest video coding standard of the ITU-T Video Coding Experts Group and the ISO/IEC Moving Picture Experts Group. The main goals of the H.264/AVC standardization effort have been enhanced compression performance and provision of a \"network-friendly\" video representation addressing \"conversational\" (video telephony) and \"nonconversational\" (storage, broadcast, or streaming) applications. H.264/AVC has achieved a significant improvement in rate-distortion efficiency relative to existing standards. This article provides an overview of the technical features of H.264/AVC, describes profiles and applications for the standard, and outlines the history of the standardization process.",
        "title": "Overview of the H.264/AVC video coding standard",
        "venue": "IEEE Transactions on Circuits and Systems for Video Technology",
        "year": 2003,
        "__v": 2,
        "citationCount": 2925
    },
    {
        "authors": [
            "Isabelle Guyon",
            "Jason Weston",
            "Stephen D. Barnhill",
            "Vladimir Vapnik"
        ],
        "references": [
            "07398a91-b607-4d52-ad00-586caceb0ac9",
            "0781e713-d8ca-4f62-89e8-3047b77dd6e6",
            "08dcb9a2-1d9e-4094-a9ed-144d4343167e",
            "1e37aa02-2911-45db-867f-bc2043492c08",
            "2bd9968a-1e0b-4a11-85a2-19edcf0ee77d",
            "404775ac-d2d2-4a0b-8195-9458da97105b",
            "4c3fd4d5-c23d-4a24-84cd-21d45208941e",
            "50d6ceff-8829-44e3-a8a0-96b69b1805b4",
            "50dd56db-151d-4d62-8576-65f0ef6f381b",
            "685b313d-8a77-481e-9456-e405a1d29549",
            "94898e1d-1e50-41ab-9dcc-2c2e030cddd0",
            "95fdc823-57bc-4e49-8e5b-8fac0c4cfb7f",
            "dc92e76f-e502-44a0-898b-a3e12d7fabe9",
            "e85a4f52-0e1c-447b-98b4-33ec8b9ee6f3",
            "ec039631-17e8-4794-bc48-2840c96ba044",
            "f006e236-59ad-4647-a59f-4f46dc2c85be"
        ],
        "keyword": [
            "genes",
            "methods",
            "cancerous",
            "tissue",
            "selection",
            "yield",
            "normal",
            "microarrays",
            "baseline"
        ],
        "group": [
            {
                "0781e713-d8ca-4f62-89e8-3047b77dd6e6": {
                    "authors": [
                        "Jason Weston",
                        "Sayan Mukherjee",
                        "Olivier Chapelle",
                        "Massimiliano Pontil",
                        "Tomaso Poggio",
                        "Vladimir Vapnik"
                    ],
                    "references": [
                        "08dcb9a2-1d9e-4094-a9ed-144d4343167e",
                        "1e4f4b5c-55e0-4d5b-b7cc-9e7fada3e341",
                        "43530fe4-10a9-4ddf-b61d-8844f0ff3f04",
                        "4c3fd4d5-c23d-4a24-84cd-21d45208941e",
                        "685b313d-8a77-481e-9456-e405a1d29549",
                        "95fdc823-57bc-4e49-8e5b-8fac0c4cfb7f",
                        "9fa61eb1-0984-4492-955a-4f7aedbdc368",
                        "d04682be-3715-4727-b177-709d7eab30d7"
                    ],
                    "keyword": [],
                    "group": [],
                    "_id": "0781e713-d8ca-4f62-89e8-3047b77dd6e6",
                    "abstract": "We introduce a method of feature selection for Support Vector Machines. The method is based upon finding those features which minimize bounds on the leave-one-out error. This search can be efficiently performed via gradient descent. The resulting algorithms are shown to be superior to some standard feature selection algorithms on both toy data and real-life problems of face recognition, pedestrian detection and analyzing DNA microarray data.",
                    "title": "Feature Selection for SVMs",
                    "venue": "neural information processing systems",
                    "year": 2001,
                    "__v": 0,
                    "citationCount": 374,
                    "result": 2.5
                },
                "50d6ceff-8829-44e3-a8a0-96b69b1805b4": {
                    "authors": [
                        "Michael J. Kearns",
                        "Yishay Mansour",
                        "Andrew Y. Ng",
                        "Dana Ron"
                    ],
                    "references": [
                        "007cf08c-7de6-437c-ae53-8b41e276a9a6",
                        "24a041e4-be7e-45d4-95e0-80d44a5bc725",
                        "271c13a3-16b3-404c-8c59-4363010e8dc6",
                        "28e70562-4760-4398-bbf3-04ecbcb2aca3",
                        "479d1e45-2bdb-4b94-858f-76c4fdc743e9",
                        "69f00f82-45eb-4e2b-b239-5526d80f11ea",
                        "9128639a-b411-49bc-9c12-b4ba96515d3e",
                        "9a3d89a3-cf57-4db1-8cab-d3d7fef4d065",
                        "b0afa6ff-6528-4701-800b-5dc0b5411b0c"
                    ],
                    "keyword": [
                        "methods",
                        "selection",
                        "generalization",
                        "model",
                        "error",
                        "terms",
                        "problem",
                        "penaltybased",
                        "complexity"
                    ],
                    "group": [],
                    "_id": "50d6ceff-8829-44e3-a8a0-96b69b1805b4",
                    "abstract": "We investigate the problem of {\\it model\\ selection} in the setting of supervised learning of boolean functions from independent random examples. More precisely, we compare methods for finding a balance between the complexity of the hypothesis chosen and its observed error on a random training sample of limited size, when the goal is that of minimizing the resulting generalization error. We undertake a detailed comparison of three well-known model selection methods — a variation of Vapnik‘s {\\it Guaranteed\\ Risk\\ Minimization} (GRM), an instance of Rissanen‘s {\\it Minimum\\ Description\\ Length\\ Principle} (MDL), and (hold-out) cross validation (CV). We introduce a general class of model selection methods (called {\\it penalty-based} methods) that includes both GRM and MDL, and provide general methods for analyzing such rules. We provide both controlled experimental evidence and formal theorems to support the following conclusions:#R##N##R##N#\\bulletEven on simple model selection problems, the behavior of the methods examined can be both complex and incomparable. Furthermore, no amount of “tuning” of the rules investigated (such as introducing constant multipliers on the complexity penalty terms, or a distribution-specific “effective dimension”) can eliminate this incomparability.#R##N##R##N#\\bulletIt is possible to give rather general bounds on the generalization error, as a function of sample size, for penalty-based methods. The quality of such bounds depends in a precise way on the extent to which the method considered automatically limits the complexity of the hypothesis selected.#R##N##R##N#\\bulletFor {\\it any} model selection problem, the additional error of cross validation compared to {\\it any} other method can be bounded above by the sum of two terms. The first term is large only if the learning curve of the underlying function classes experiences a phase transition” between (1-\\gamma)m andm examples (where \\gamma is the fraction saved for testing in CV). The second and competing term can be made arbitrarily small by increasing\\gamma .#R##N##R##N#\\bulletThe class of penalty-based methods is fundamentally handicapped in the sense that there exist two types of model selection problems for which every penalty-based method must incur large generalization error on at least one, while CV enjoys small generalization error on both.",
                    "title": "An experimental and theoretical comparison of model selection methods",
                    "venue": "computational learning theory",
                    "year": 1995,
                    "__v": 1,
                    "citationCount": 64,
                    "result": 7.084186536306606
                },
                "50dd56db-151d-4d62-8576-65f0ef6f381b": {
                    "authors": [
                        "Corinna Cortes",
                        "Vladimir Vapnik"
                    ],
                    "references": [
                        "c4dc7b46-01d3-44f5-91ca-0cc063d38c8c",
                        "f006e236-59ad-4647-a59f-4f46dc2c85be"
                    ],
                    "keyword": [
                        "supportvector",
                        "network",
                        "machine",
                        "learning",
                        "training",
                        "surface",
                        "space",
                        "input",
                        "implements",
                        "idea"
                    ],
                    "group": [],
                    "_id": "50dd56db-151d-4d62-8576-65f0ef6f381b",
                    "abstract": "The support-vector network is a new learning machine for two-group classification problems. The machine conceptually implements the following idea: input vectors are non-linearly mapped to a very high-dimension feature space. In this feature space a linear decision surface is constructed. Special properties of the decision surface ensures high generalization ability of the learning machine. The idea behind the support-vector network was previously implemented for the restricted case where the training data can be separated without errors. We here extend this result to non-separable training data.#R##N##R##N#High generalization ability of support-vector networks utilizing polynomial input transformations is demonstrated. We also compare the performance of the support-vector network to various classical learning algorithms that all took part in a benchmark study of Optical Character Recognition.",
                    "title": "Support-Vector Networks",
                    "venue": "Machine Learning",
                    "year": 1995,
                    "__v": 2,
                    "citationCount": 6683,
                    "result": 4.184464065346417
                },
                "685b313d-8a77-481e-9456-e405a1d29549": {
                    "authors": [
                        "Ron Kohavi",
                        "George H. John"
                    ],
                    "references": [
                        "0587052d-9988-4c3f-8f82-3ffcf8da7c86",
                        "0cc7f81d-3960-4e11-ab65-5406091a49d8",
                        "0f115eea-2272-431f-9f21-6d6789b2bbc9",
                        "0f240e79-dd13-4510-a19a-64586438f8d5",
                        "119792fb-54c1-49f5-8648-13d24b19ecf5",
                        "1570e0c2-bcf6-4f5a-92db-d1b0936d68d3",
                        "245e4043-ccdb-457a-9be1-e120c7a94753",
                        "34ea7fc5-8b5a-46d6-aa41-155442792ab0",
                        "36313bb8-e0c2-4900-a399-3e772f9f51dc",
                        "36338d50-6305-4d9f-9065-cde919913bfb",
                        "3a90b5d2-3377-4ffa-9545-9ef332679370",
                        "3b85426c-08c7-4299-af41-3d0140325e56",
                        "43e502f4-87f2-4672-9217-823cf6c56e56",
                        "485598b2-ed73-4670-a44d-b0844f923fa4",
                        "4b0df874-c029-4993-9c36-50e795192cfb",
                        "4de0dbe7-3582-4125-94be-d0c36ea097fc",
                        "522e1bb9-8ec7-448b-a6ea-7e08b3b6b205",
                        "60ac157b-ad14-49c3-a901-6673c71cdb9d",
                        "62549bc2-e0b3-46e8-8d32-390dded105d5",
                        "6a6b9aa6-683f-4c7c-b06e-9c3018d10fd3",
                        "6aae8997-db46-40ef-a668-78ba5736c756",
                        "6b991684-bcc5-42ea-b160-fe79470d112b",
                        "6c68311c-2745-446f-9c09-df4632392a78",
                        "755fce0d-fa7f-438e-b0b7-aa21f0a74458",
                        "7a4f827a-aced-46e7-987d-5ad7f3016c32",
                        "7e4a176e-5c7c-475a-b9fa-c1a5c5635a27",
                        "7ef53f8d-34c3-4e75-ac28-d3b86ae8fa3a",
                        "80bcd4d1-c1cd-43a7-bc4d-42e274324933",
                        "91b55919-de45-4ecb-8de2-7405faea114e",
                        "9263339a-c88a-4151-baff-0e3a562420ff",
                        "936187f8-f6c2-412c-bdd2-0b4f5d60f8df",
                        "9c01a502-04f3-4adb-9bde-f06253818cb9",
                        "9eee3b9a-cd39-4db4-8b35-151667483add",
                        "9f1396bc-5579-40ca-abcd-17771eaba7b6",
                        "a4589cfe-15e7-4c34-9349-d002d1d2c9df",
                        "a9a79a49-3063-4d7f-a353-34df2a8175a1",
                        "ac237969-3fd5-4303-83b7-a67e02afe976",
                        "adab43f8-fd25-46c6-960d-54bd988c5aaa",
                        "b2159ee7-ace1-4e4d-982e-e6c9eb554a3e",
                        "b49c1e2b-0cd0-4950-a724-00c698e5b49d",
                        "b4fb7dd0-46d6-4db0-825d-0c01fa3e44ba",
                        "b9214a76-78e7-484b-83ae-939f30e58583",
                        "bdba5fe6-dc9e-4e25-b49a-1bff29f3f0c8",
                        "c8ca0fbb-6cf7-4678-bdbc-d52a93446d31",
                        "ca3e323a-57d3-4d3d-835f-c5d9c0c1001a",
                        "ce028c76-6040-4f87-b8e7-d6741ce9d1c4",
                        "cf740e2c-f5bf-4e0c-8375-2948d6dff2c7",
                        "d584301a-e949-47a8-ae15-232ec53aa62b",
                        "d7c2d469-53c2-4216-9af3-22dc6b4ccb1c",
                        "da4534a6-897c-4431-89ef-cd326bfaf9a8",
                        "da9219cb-fa1c-4241-a9eb-108c6699a80f",
                        "db26488d-78be-44b1-a343-e896f43c5d29",
                        "e1662082-8ddd-4df1-90a9-c1f30382b3d0",
                        "e899cb89-58db-44be-99d7-1d318183ffc1",
                        "ead81f2f-a99d-4e65-a0aa-735699199454",
                        "ed748247-965b-4857-a004-7531209fa975",
                        "eef1ec6d-1aed-47a3-831d-b0feb5432851",
                        "f17bdf85-6dc4-48ec-8946-c2613678abfb",
                        "f6ea2106-9ff3-4a2b-a195-6f81979f942d",
                        "f76331c6-7be5-4f61-bbb1-25ea462536e6",
                        "fc603eb6-d237-4584-842c-c80805f31370",
                        "fcb41378-32f7-4aab-8458-fc5a99d74f92"
                    ],
                    "keyword": [
                        "subset",
                        "feature",
                        "selection",
                        "algorithm",
                        "wrapper",
                        "approach",
                        "training",
                        "set",
                        "relevant",
                        "problem"
                    ],
                    "group": [],
                    "_id": "685b313d-8a77-481e-9456-e405a1d29549",
                    "abstract": "Copyright (c) 1997 Elsevier Science B.V. All rights reserved. In the feature subset selection problem, a learning algorithm is faced with the problem of selecting a relevant subset of features upon which to focus its attention, while ignoring the rest. To achieve the best possible performance with a particular learning algorithm on a particular training set, a feature subset selection method should consider how the algorithm and the training set interact. We explore the relation between optimal feature subset selection and relevance. Our wrapper method searches for an optimal feature subset tailored to a particular algorithm and a domain. We study the strengths and weaknesses of the wrapper approach and show a series of improved designs. We compare the wrapper approach to induction without feature subset selection and to Relief, a filter approach to feature subset selection. Significant improvement in accuracy is achieved for some datasets for the two families of induction algorithms used: decision trees and Naive-Bayes.",
                    "title": "Wrappers for feature subset selection",
                    "venue": "Artificial Intelligence",
                    "year": 1997,
                    "__v": 1,
                    "citationCount": 2579,
                    "result": 5.44466056818998
                },
                "94898e1d-1e50-41ab-9dcc-2c2e030cddd0": {
                    "authors": [
                        "Bernhard Schölkopf",
                        "Alexander J. Smola",
                        "Klaus-Robert Müller"
                    ],
                    "references": [
                        "29e06cb4-0ae3-4c7b-863a-d63ced9b1fa2",
                        "50dd56db-151d-4d62-8576-65f0ef6f381b",
                        "7b57db11-7c4d-4d1e-aa62-3a5d7d1f7987",
                        "7c016469-519e-4f34-9655-cf37f116942b",
                        "7d575c42-b8c4-43fe-bf75-842cfe0a3fe3",
                        "85114f9d-70a8-4940-83aa-af504b75acf8",
                        "87969fc2-8332-4ee5-b6b0-e1b26d01ebd4",
                        "a8693e98-1ed1-457b-a9fa-0f03395ce3fe",
                        "ae3e7593-586f-495f-9416-4b50ed1fcd10",
                        "aec3237b-b440-4d97-91a7-f57c249f82d6",
                        "b33eea94-414c-4232-a1b8-1ffc687c1d61",
                        "d46e68dc-dbb7-4296-8f40-f3c513b432bc",
                        "db84fccc-eb21-4b65-9ea5-7be175c6fc24",
                        "f006e236-59ad-4647-a59f-4f46dc2c85be",
                        "f15b056f-a577-4391-9724-a5be885e2bd2"
                    ],
                    "keyword": [
                        "spaces",
                        "principal",
                        "nonlinear",
                        "method",
                        "feature",
                        "component",
                        "16",
                        "results",
                        "related",
                        "recognition"
                    ],
                    "group": [],
                    "_id": "94898e1d-1e50-41ab-9dcc-2c2e030cddd0",
                    "abstract": "A new method for performing a nonlinear form of principal component analysis is proposed. By the use of integral operator kernel functions, one can efficiently compute principal components in high-dimensional feature spaces, related to input space by some nonlinear map—for instance, the space of all possible five-pixel products in 16 × 16 images. We give the derivation of the method and present experimental results on polynomial feature extraction for pattern recognition.",
                    "title": "Nonlinear component analysis as a kernel eigenvalue problem",
                    "venue": "Neural Computation",
                    "year": 1998,
                    "__v": 2,
                    "citationCount": 2527,
                    "result": 5.951928626928628
                },
                "95fdc823-57bc-4e49-8e5b-8fac0c4cfb7f": {
                    "authors": [
                        "Avrim Blum",
                        "Pat Langley"
                    ],
                    "references": [
                        "0cff5d73-afc6-47e3-9906-7f21e4cab620",
                        "0ddbfee1-8cc2-49f6-be79-59276f496884",
                        "17964919-da15-4d08-9f7d-1731a39f1f5e",
                        "1defeff4-5a9b-491d-84b0-30b990d6c121",
                        "245e4043-ccdb-457a-9be1-e120c7a94753",
                        "2fb1b055-2eb3-4016-92e5-41e882d8bf57",
                        "2fff0bf2-3304-4057-be74-8c6235116e21",
                        "32518a4c-fbc3-470f-8024-cb7a65f1fe3f",
                        "3374e2de-0a88-49f4-a5a3-56ceb7dfb823",
                        "340c101a-7317-4ba9-b642-a91eb2e456a7",
                        "36c3e386-cc87-4d6d-a8b6-fd8343b23c8b",
                        "3c35d94a-ddb2-460e-a66d-6010ecd1d331",
                        "4de0dbe7-3582-4125-94be-d0c36ea097fc",
                        "4e80450b-37ed-440c-87cc-d17d27e0d892",
                        "502704c9-2881-41c2-95f6-132d5b8939d5",
                        "505f493b-e09d-444d-9ee2-5e5db6a5b8ac",
                        "5880d47f-8b99-416d-a743-28d6b49f7ba9",
                        "5899eb6c-2e22-4d79-a2be-15fe67911177",
                        "5bb08be4-365a-4e4a-8cc2-92d399ad4bb1",
                        "5cd74e0b-f25c-4aaf-8327-7ec949c7d098",
                        "5da28397-677c-4d92-9ac9-a1f2bf061016",
                        "5fce2337-58b4-433e-9bc5-1ae1c4a5467f",
                        "62549bc2-e0b3-46e8-8d32-390dded105d5",
                        "66e1bf85-a2cc-4c97-847c-e803243f4c66",
                        "685b313d-8a77-481e-9456-e405a1d29549",
                        "6aae8997-db46-40ef-a668-78ba5736c756",
                        "6c2fee35-a596-416a-bd8a-a7966324f71e",
                        "6ca7ce19-1c90-4641-a8b1-6556d4b5d0cc",
                        "6fe13464-786c-4668-8c16-5b0461042e78",
                        "7a10be82-6113-4f60-9e37-f35f2d9423c5",
                        "86dafb65-1d2e-42d9-8982-4d520b6da774",
                        "8735c7ea-f5c6-4310-b250-bc0d1bf5e834",
                        "91b55919-de45-4ecb-8de2-7405faea114e",
                        "996c7ee1-b8de-4dc7-8ec4-6f403f00d3bc",
                        "9eee3b9a-cd39-4db4-8b35-151667483add",
                        "a5f31bf3-3f2c-430a-b68f-0c2521c130c6",
                        "a8f17d49-3bef-4ccb-8e4c-6fc27d99a8db",
                        "ac28de8d-4445-4d2d-a134-7f0e835ebca9",
                        "b2159ee7-ace1-4e4d-982e-e6c9eb554a3e",
                        "b4fb7dd0-46d6-4db0-825d-0c01fa3e44ba",
                        "ba44ae01-0d02-4831-b637-48885d606c37",
                        "c41aed07-fe73-431b-8a8c-700731db9088",
                        "c61bad33-aa9f-4a6e-ab8b-8e7eaa835492",
                        "c9d7e50e-26d6-41f1-aa09-f49fc546af36",
                        "cda06ad5-1cad-4bb7-834f-cd5693ad277a",
                        "ce028c76-6040-4f87-b8e7-d6741ce9d1c4",
                        "d0c44a36-4572-4101-815d-150d53d8a057",
                        "d6f92f3a-fff7-4312-be70-72f61e92913d",
                        "da9219cb-fa1c-4241-a9eb-108c6699a80f",
                        "e0cbdcfd-80c2-4ec2-9c0b-0bcb85843511",
                        "e1d4d2dc-35dc-46d9-9773-a3964a3d831c",
                        "ea2509ad-3494-4bb9-9fdd-6381b491cfa0",
                        "ed748247-965b-4857-a004-7531209fa975",
                        "eef1ec6d-1aed-47a3-831d-b0feb5432851",
                        "f51b782d-815b-4b0d-b9d6-8e676b413969",
                        "f6ea2106-9ff3-4a2b-a195-6f81979f942d",
                        "fc603eb6-d237-4584-842c-c80805f31370"
                    ],
                    "keyword": [
                        "work",
                        "selecting",
                        "relevant",
                        "problem",
                        "methods",
                        "machine",
                        "learning",
                        "topics",
                        "theoretical",
                        "survey"
                    ],
                    "group": [],
                    "_id": "95fdc823-57bc-4e49-8e5b-8fac0c4cfb7f",
                    "abstract": "Copyright (c) 1997 Elsevier Science B.V. All rights reserved. In this survey, we review work in machine learning on methods for handling data sets containing large amounts of irrelevant information. We focus on two key issues: the problem of selecting relevant features, and the problem of selecting relevant examples. We describe the advances that have been made on these topics in both empirical and theoretical work in machine learning, and we present a general framework that we use to compare different methods. We close with some challenges for future work in this area.",
                    "title": "Selection of relevant features and examples in machine learning",
                    "venue": "Artificial Intelligence",
                    "year": 1997,
                    "__v": 1,
                    "citationCount": 948,
                    "result": 6.869806010982482
                },
                "e85a4f52-0e1c-447b-98b4-33ec8b9ee6f3": {
                    "authors": [
                        "Isabelle Guyon",
                        "Vladimir Vapnik",
                        "Bernhard E. Boser",
                        "Léon Bottou",
                        "Sara A. Solla"
                    ],
                    "references": [
                        "3fff50e3-6a11-415b-8c8d-6f2c651f658d",
                        "ae3e7593-586f-495f-9416-4b50ed1fcd10",
                        "b66db0fd-96bf-4811-a9b9-61e5a3463d90",
                        "c6eb4f74-fb55-4fb3-85ac-5e9e95ee9f8a"
                    ],
                    "keyword": [
                        "classifier",
                        "capacity",
                        "structural",
                        "factors",
                        "tuning",
                        "training",
                        "space",
                        "risk",
                        "refers",
                        "recognition"
                    ],
                    "group": [],
                    "_id": "e85a4f52-0e1c-447b-98b4-33ec8b9ee6f3",
                    "abstract": "The method of Structural Risk Minimization refers to tuning the capacity of the classifier to the available amount of training data. This capacity is influenced by several factors, including: (1) properties of the input space, (2) nature and structure of the classifier, and (3) learning algorithm. Actions based on these three factors are combined here to control the capacity of linear classifiers and improve generalization on the problem of handwritten digit recognition.",
                    "title": "Structural Risk Minimization for Character Recognition",
                    "venue": "neural information processing systems",
                    "year": 1992,
                    "__v": 2,
                    "citationCount": 28,
                    "result": 2.9385878397488296
                },
                "ec039631-17e8-4794-bc48-2840c96ba044": {
                    "authors": [
                        "Isabelle Guyon",
                        "John Makhoul",
                        "Richard M. Schwartz",
                        "Vladimir Vapnik"
                    ],
                    "references": [
                        "b4c5a572-c0a9-41e3-8782-9d4ee8105d81"
                    ],
                    "keyword": [
                        "character",
                        "rate",
                        "error",
                        "recognition",
                        "test",
                        "statistically",
                        "set",
                        "expected",
                        "significant",
                        "recognizer"
                    ],
                    "group": [],
                    "_id": "ec039631-17e8-4794-bc48-2840c96ba044",
                    "abstract": "We address the problem of determining what size test set guarantees statistically significant results in a character recognition task, as a function of the expected error rate. We provide a statistical analysis showing that if, for example, the expected character error rate is around 1 percent, then, with a test set of at least 10,000 statistically independent handwritten characters (which could be obtained by taking 100 characters from each of 100 different writers), we guarantee, with 95 percent confidence, that: (1) the expected value of the character error rate is not worse than 1.25 E, where E is the empirical character error rate of the best recognizer, calculated on the test set; and (2) a difference of 0.3 E between the error rates of two recognizers is significant. We developed this framework with character recognition applications in mind, but it applies as well to speech recognition and to other pattern recognition problems.",
                    "title": "What size test set gives good error rate estimates",
                    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "year": 1998,
                    "__v": 2,
                    "citationCount": 60,
                    "result": 4.47108577696813
                }
            }
        ],
        "_id": "9fa61eb1-0984-4492-955a-4f7aedbdc368",
        "abstract": "DNA micro-arrays now permit scientists to screen thousands of genes simultaneously and determine whether those genes are active, hyperactive or silent in normal or cancerous tissue. Because these new micro-array devices generate bewildering amounts of raw data, new analytical methods must be developed to sort out whether cancer tissues have distinctive signatures of gene expression over normal tissues or other types of cancer tissues.#R##N##R##N#In this paper, we address the problem of selection of a small subset of genes from broad patterns of gene expression data, recorded on DNA micro-arrays. Using available training examples from cancer and normal patients, we build a classifier suitable for genetic diagnosis, as well as drug discovery. Previous attempts to address this problem select genes with correlation techniques. We propose a new method of gene selection utilizing Support Vector Machine methods based on Recursive Feature Elimination (RFE). We demonstrate experimentally that the genes selected by our techniques yield better classification performance and are biologically relevant to cancer.#R##N##R##N#In contrast with the baseline method, our method eliminates gene redundancy automatically and yields better and more compact gene subsets. In patients with leukemia our method discovered 2 genes that yield zero leave-one-out error, while 64 genes are necessary for the baseline method to get the best result (one leave-one-out error). In the colon cancer database, using only 4 genes our method is 98% accurate, while the baseline method is only 86% accurate.",
        "title": "Gene Selection for Cancer Classification using Support Vector Machines",
        "venue": "Machine Learning",
        "year": 2002,
        "__v": 2,
        "citationCount": 2006
    },
    {
        "authors": [
            "Ian F. Akyildiz",
            "Won-Yeol Lee",
            "Mehmet C. Vuran",
            "Shantidev Mohanty"
        ],
        "references": [
            "04c58307-939e-481d-b4d7-6579d1607543",
            "097d282b-beed-47c1-9e6f-07255fee1a3a",
            "17d3c566-60ad-491a-b63c-ae7f3b46dd54",
            "269e006a-d493-4ade-be8b-cfc3b56d5752",
            "4d4338a1-d3e7-482a-9f8c-9bd3a4eae9c3",
            "602e89cc-75ec-4d21-925a-39fb38e46877",
            "9683e149-7dd9-40d0-be7c-2bd6303588c4",
            "b857298c-92c9-4f05-a704-3b9fc6be06e3",
            "c0beb0e0-d0a2-4a9e-a99c-39f5e975849e",
            "caa552a1-c1b7-48d6-9d30-046d360f8ce9",
            "d1ba534e-3f80-4366-bb83-be16006f9e18",
            "d75e2955-a86c-44dd-b3e2-37d87559c9a1",
            "e6a15cfd-755e-4f05-b47c-e77190473a9b",
            "f0ce34fb-5858-4dac-bd79-d3b020ec4270",
            "fba22e0f-c734-41c0-804a-51ffac08e852"
        ],
        "keyword": [
            "spectrum",
            "networks",
            "xg",
            "functionalities",
            "assignment"
        ],
        "group": [
            {
                "17d3c566-60ad-491a-b63c-ae7f3b46dd54": {
                    "authors": [
                        "Ryan W. Thomas",
                        "L.A. DaSilva",
                        "Allen B. MacKenzie"
                    ],
                    "references": [
                        "069a13b0-1bd7-4da3-98fb-7355cc23603a",
                        "08c6c985-93ee-409c-b0f4-fa726cc05ec3",
                        "12e8953f-930b-42e1-a368-64733c075952",
                        "2222ebac-20e1-4554-bf5e-85f8aa072a3f",
                        "33c5084a-0ff0-47e5-8c4a-33b04f014933",
                        "3400487b-3284-4ce4-9622-aed44a54d15e",
                        "3ab7b14e-a64a-4f90-84ae-03502eee605e",
                        "3acc2d6b-c3b6-4478-a795-6674c9386109",
                        "3ade9a64-67c0-4405-b8cb-a9888b1d9a3a",
                        "48467e74-1b97-42ef-8ca7-2d8fb6af8616",
                        "50e845dc-e2df-4025-9358-8cb0ddacd50d",
                        "56b24380-34aa-4bbc-910f-3e891bcade75",
                        "5745bdca-8edf-48f8-9bf5-52a8b946dbe8",
                        "598e8c91-b6c3-42c2-a0e5-adc178773b5c",
                        "60ef3852-fa16-44bf-9434-9909268ba5d8",
                        "63f0f592-f649-4343-8d4f-71718072df89",
                        "68f3a7d4-d842-4d5f-ab20-f20b8a43444d",
                        "6a7ce1b5-fcee-4a2a-8bc0-5ce9dbf09fcc",
                        "6aa445a1-8cd7-40b5-b506-844272453984",
                        "6e671665-f037-41a2-ba11-a881d9f119df",
                        "749cefe5-bcab-4f6c-aa62-c3001664c53a",
                        "7a51b253-f99e-44b8-9c9e-13615bfce9cf",
                        "7e95e53b-930f-45c2-8235-deb6e2bdea88",
                        "7ffad281-b4a6-41eb-8653-e405a0a2be2d",
                        "8cbb609a-12e4-4d5a-a6ce-5187ab5b3974",
                        "8e4b6895-ed53-4022-a2ef-807b9a034a38",
                        "8ffa6c41-5dda-4413-bc3a-908118f5ae8e",
                        "939186bf-1ff8-4789-8fe1-94b81cc49a43",
                        "9abd9936-3022-4a10-9aad-2937c08fb892",
                        "9ccd6edf-2c58-45fd-ac68-f4270a5dfbb7",
                        "9e36872e-fd97-41b8-8ac7-f50dc2da7cbc",
                        "a6a2edbb-bbb3-44a2-992b-10acd5176128",
                        "a8bef77c-89c4-4832-9a86-e46ead6dc99f",
                        "a9ac8922-ab4b-4aa4-b0a3-526695d91e6c",
                        "b686bf21-30d3-45de-87b9-13e1d0f33cf2",
                        "b6abdcec-03cb-4399-bbe8-d7f44a342403",
                        "ba0e6d65-9f87-4ff9-9d8d-4aad39934d8b",
                        "bee4f656-10d8-4de2-9ee1-19ad4b8ef043",
                        "d1ba534e-3f80-4366-bb83-be16006f9e18",
                        "d8826492-559a-4774-a336-4d7b5d1148d8",
                        "d90da43f-f77a-48f9-9cb4-1e3cc168227b",
                        "e5314e77-4d67-4071-9f4c-7fc85e2958d1",
                        "e76a55f6-ac58-4a4e-a7e7-36225705dfd3",
                        "efbc01c0-040e-4d73-9db0-dbbb8795f65a",
                        "f1e74152-3f7c-4c44-b628-cdf47a17587f",
                        "f21ddade-c9ae-4234-b344-83d55295136f",
                        "f3046808-ca07-4fb2-a8d5-9821b37e4f7b",
                        "f7e70882-8aae-424f-9f08-5503487a5838",
                        "f8635816-3ec1-4a18-a703-e0a635b90584",
                        "f9532880-407d-40b7-8a3c-fb70fa2d50d8"
                    ],
                    "keyword": [
                        "network",
                        "cognitive",
                        "goals",
                        "endtoend",
                        "data",
                        "adaptive"
                    ],
                    "group": [],
                    "_id": "17d3c566-60ad-491a-b63c-ae7f3b46dd54",
                    "abstract": "This paper presents a definition and framework for a novel type of adaptive data network: the cognitive network. In a cognitive network, the collection of elements that make up the network observes network conditions and then, using prior knowledge gained from previous interactions with the network, plans, decides and acts on this information. Cognitive networks are different from other \"intelligent\" communication technologies because these actions are taken with respect to the end-to-end goals of a data flow. In addition to the cognitive aspects of the network, a specification language is needed to translate the user's end-to-end goals into a form understandable by the cognitive process. The cognitive network also depends on a software adaptable network that has both an external interface accessible to the cognitive network and network status sensors. These devices are used to provide control and feedback. The paper concludes by presenting a simple case study to illustrate a cognitive network and its framework",
                    "title": "Cognitive networks",
                    "venue": "",
                    "year": 2005,
                    "__v": 2,
                    "citationCount": 183,
                    "result": 2.2205580367345075
                },
                "4d4338a1-d3e7-482a-9f8c-9bd3a4eae9c3": {
                    "authors": [
                        "Mehmet C. Vuran",
                        "Ian F. Akyildiz"
                    ],
                    "references": [
                        "27211375-3d42-415b-b6a9-859d064c7e67",
                        "4d994ac6-8a2d-4070-b7de-473dbb2233bb",
                        "5e1e2336-c7af-457d-83ac-f4744a62bfcb",
                        "66c490f1-f6c9-4742-b9a8-acd5ccc504af",
                        "78852091-d729-491f-80fa-9298eaba993a",
                        "82d0f749-2615-4add-97f3-c0fc4bbf3839",
                        "87f492ee-3b63-4100-b811-2725d0ff98b2",
                        "989a731b-bdb2-4c23-a0c7-5b546238096d",
                        "d0d0f91e-4666-40d8-8e16-767c010f5dc9",
                        "d86310ef-3606-4bf3-9ab4-2c9f0b3d5382",
                        "dbdfc0c5-616f-45c7-83a8-9376b9f84094",
                        "ddf2ab85-8a67-432a-821d-512b78918143"
                    ],
                    "keyword": [
                        "networks",
                        "heterogeneous",
                        "access",
                        "wireless",
                        "requirements",
                        "architectures",
                        "amac",
                        "ng",
                        "medium",
                        "adaptive"
                    ],
                    "group": [],
                    "_id": "4d4338a1-d3e7-482a-9f8c-9bd3a4eae9c3",
                    "abstract": "Next Generation (NG) wireless networks are envisioned to provide high bandwidth to mobile users via bandwidth aggregation over heterogeneous wireless architectures. NG wireless networks, however, impose challenges due to their architectural heterogeneity in terms of different access schemes, resource allocation techniques as well as diverse quality of service requirements. These heterogeneities must be captured and handled dynamically as mobile terminals roam between different wireless architectures. However, to address these challenges, the existing proposals require either a significant modification in the network structure and in base stations or a completely new architecture, which lead to integration problems in terms of implementation costs, scalability and backward compatibility. Thus, the integration of the existing medium access schemes, e.g., CSMA, TDMA and CDMA, dictates an adaptive and seamless medium access control (MAC) layer that can achieve high network utilization and meet diverse Quality of Service (QoS) requirements.   In this paper, an adaptive medium access control (A-MAC) layer is proposed to address the heterogeneities posed by the NG wireless networks. A-MAC introduces a two-layered MAC framework that accomplishes the adaptivity to both architectural heterogeneities and diverse QoS requirements. A novel virtual cube concept is introduced as a unified metric to model heterogeneous access schemes and capture their behavior. Based on the Virtual Cube concept, A-MAC provides architecture-independent decision and QoS based scheduling algorithms for efficient multinetwork access. A-MAC performs seamless medium access to multiple networks without requiring any additional modifications in the existing network structures. It is shown via extensive simulations that A-MAC provides adaptivity to the heterogeneities in NG wireless networks and achieves high performance.",
                    "title": "A-MAC: adaptive medium access control for next generation wireless terminals",
                    "venue": "IEEE\\/ACM Transactions on Networking",
                    "year": 2007,
                    "__v": 2,
                    "citationCount": 12,
                    "result": 2.9201802583381533
                },
                "b857298c-92c9-4f05-a704-3b9fc6be06e3": {
                    "authors": [
                        "Ian F. Akyildiz",
                        "Xudong Wang",
                        "Weilin Wang"
                    ],
                    "references": [
                        "02eefe0f-b029-4fbb-b41a-906e8f04639d",
                        "03a67937-3823-48ca-8b6c-98bf2774800b",
                        "04d08d28-706c-492a-b2a2-68be407e3ce4",
                        "0998b7fa-b6ab-4494-8f8a-80136f4ddbd2",
                        "11ce2a5f-c26f-4d92-83da-65ba632c1195",
                        "12b6f373-f5d1-46f4-85ee-16ee239ee862",
                        "14a274e3-6ec3-40f7-80ad-334711dc3222",
                        "190378e2-8617-4add-835c-3e7ed4805bd1",
                        "1b7ff6d2-5664-4f68-b6b0-7ec24900db9e",
                        "22b55f59-1aa1-4dc4-92fe-5e82014652cf",
                        "2659531e-eb9d-4dd5-b46f-10f66a4819c6",
                        "269e006a-d493-4ade-be8b-cfc3b56d5752",
                        "29424b9c-c448-4679-8472-044e701a11ea",
                        "2962277b-7da6-4a64-9dbd-6ca9370c577d",
                        "29f75862-97b4-4116-9e91-70bde085bcca",
                        "2b06e029-ba76-4924-96ce-815670c8e2e3",
                        "32591c3e-f867-4910-91ec-ce8d8113767a",
                        "35239e8a-a6d8-4297-8818-e8965b5d2472",
                        "380c3e95-47c3-4e83-ba1a-be8351b787d8",
                        "3a8d5801-1361-43d4-a4cd-e70133c245d4",
                        "3d32516c-e687-4b1d-8788-646dddfd7008",
                        "3f538b4c-767e-4749-82f9-9a970e9f83e6",
                        "425664d5-08ce-49f6-979d-5e6eff993ed2",
                        "42f3128f-69d0-4659-8039-d2e45f4cbb4f",
                        "474dd419-342a-4a4b-9f04-85803e77459c",
                        "4cfd1b21-4c46-47c5-88ed-9bff442a8165",
                        "53509df6-4f4f-4652-bf8a-43098126e01b",
                        "58d586c7-9f54-45ee-8349-62526bbdc1f9",
                        "5a878cce-f516-4bcb-84fa-8f19f1656099",
                        "66a2e736-3c79-46db-bfa4-340cb1cd1c1a",
                        "6b4920a9-9dbd-411e-9618-0dd545bc97d7",
                        "71cec942-481a-4e22-a5e9-ff40ba582e5d",
                        "735f0549-832b-4c65-bf41-70039c3d63b8",
                        "809c50af-7512-4ca9-ad47-b8e1dd6ba77b",
                        "83034d86-0f0f-4082-8752-91759086afaa",
                        "83b5fe2e-6156-4963-9a80-1dd52c4d71bc",
                        "880c15cf-7b29-4c58-a601-c1f0affd1808",
                        "8c1ed25a-4316-48e1-9dab-9185e4b9af42",
                        "8ca979cf-f9d5-451a-84a7-e91ca2a592e2",
                        "8cc9ea80-563f-4e62-bda9-8ff6d71cf6ae",
                        "8d372af4-9bbd-499c-a00d-c6cfd91f6dfb",
                        "96318e18-6d91-4f89-8739-24f6d2a30b5f",
                        "96b245c2-47a5-4aec-89f0-d2a362124845",
                        "98783db9-d399-4537-9eaa-8964f92d99c7",
                        "9de43d04-c7fa-48a9-b092-67c2888745d4",
                        "a08d8f1a-5612-46dc-9af0-9ee800438b0a",
                        "a301962a-6d47-4fcc-9a89-5c67e1fac20f",
                        "a7be922e-d9fc-4df1-98ba-02afcbb0cb37",
                        "aed9b791-eaec-40f8-94df-fdef3291f6d5",
                        "af92cf97-d046-4072-a64b-001789344745",
                        "b5741c8a-84a5-4b8d-9e5e-29d97732b48f",
                        "b612af14-d537-4a3d-8bb7-cd5c6d248927",
                        "b68a422e-b2f3-4cf4-86ec-453b1de928dc",
                        "b97cdda8-3d21-4197-8c05-235cd9ff447f",
                        "bc3c7b56-c0cd-4762-b8f1-dd53fa3905aa",
                        "c041e7c4-39f4-4b29-aed9-95a346efb2ea",
                        "c7a0e971-e3f6-457b-8de5-693528bc6d9a",
                        "c9985150-ff5a-489c-93ca-8e626dc4dc46",
                        "ca44ad79-a14d-4ba2-a118-e0dde960d3ba",
                        "ccabb476-c38d-4867-bf93-60f1abe6e95b",
                        "cd7b4b1f-8614-4fab-8c33-a89394f0d6f9",
                        "d158cc4a-309b-4425-82b1-4f7f336c5c42",
                        "d33673af-391e-43b0-bd73-f5e02fb81531",
                        "d7bebab6-5327-4744-b315-a1d19e3989ab",
                        "e01cbb09-7ac9-480b-b49b-e1198c5e33e0",
                        "e2d56e70-7eb7-495c-91b4-b11b127cd278",
                        "e4047eee-fc9e-4f97-b354-64ef1d941719",
                        "eda5c9f4-7ed3-4663-a1a0-15ec4828af4d",
                        "ee99bfa9-086e-4d9a-9494-56a8281b8b78",
                        "f09510a5-a108-46c3-917d-0d8d145c4a0e",
                        "f3046808-ca07-4fb2-a8d5-9821b37e4f7b",
                        "f3267c01-b670-4b7a-a3a5-79088c0d90ab",
                        "f5a0a0a7-e045-4da5-815b-41964cffbaab",
                        "f65a4365-2696-47f3-849b-501792da7e23",
                        "f85ab3f5-3596-4704-a57e-873e6e0a80a9",
                        "fb2003f6-ed7b-424e-94b2-6b150f8e7302",
                        "fc160e6d-da14-40c6-8b68-725aa841f6b2"
                    ],
                    "keyword": [
                        "networks",
                        "wmns",
                        "mesh",
                        "wireless",
                        "protocol",
                        "routers",
                        "research",
                        "clients",
                        "area"
                    ],
                    "group": [],
                    "_id": "b857298c-92c9-4f05-a704-3b9fc6be06e3",
                    "abstract": "Wireless mesh networks (WMNs) consist of mesh routers and mesh clients, where mesh routers have minimal mobility and form the backbone of WMNs. They provide network access for both mesh and conventional clients. The integration of WMNs with other networks such as the Internet, cellular, IEEE 802.11, IEEE 802.15, IEEE 802.16, sensor networks, etc., can be accomplished through the gateway and bridging functions in the mesh routers. Mesh clients can be either stationary or mobile, and can form a client mesh network among themselves and with mesh routers. WMNs are anticipated to resolve the limitations and to significantly improve the performance of ad hoc networks, wireless local area networks (WLANs), wireless personal area networks (WPANs), and wireless metropolitan area networks (WMANs). They are undergoing rapid progress and inspiring numerous deployments. WMNs will deliver wireless services for a large variety of applications in personal, local, campus, and metropolitan areas. Despite recent advances in wireless mesh networking, many research challenges remain in all protocol layers. This paper presents a detailed study on recent advances and open research issues in WMNs. System architectures and applications of WMNs are described, followed by discussing the critical factors influencing protocol design. Theoretical network capacity and the state-of-the-art protocols for WMNs are explored with an objective to point out a number of open research issues. Finally, testbeds, industrial practice, and current standard activities related to WMNs are highlighted. ed by discussing the critical factors influencing protocol design. Theoretical network capacity and the state-of-the-art protocols for WMNs are explored with an objective to outline a number of open research issues. Finally, testbeds, industrial practice, and current standard activities related to WMNs are highlighted.",
                    "title": "Wireless mesh networks: a survey",
                    "venue": "Computer Networks",
                    "year": 2005,
                    "__v": 2,
                    "citationCount": 1690,
                    "result": 2.73312324929972
                },
                "e6a15cfd-755e-4f05-b47c-e77190473a9b": {
                    "authors": [
                        "Fadel F. Digham",
                        "Mohamed-Slim Alouini",
                        "Marvin K. Simon"
                    ],
                    "references": [
                        "c09e7e8c-7af4-43f2-ba40-e066ecf67e02",
                        "d1f9e823-29e6-4ee4-8b98-784545109062",
                        "f478067d-8d6a-433b-88c6-99806dcd81ee"
                    ],
                    "keyword": [
                        "probability",
                        "presents",
                        "diversity",
                        "detection",
                        "combining",
                        "ssc",
                        "sc",
                        "psub",
                        "performance",
                        "orders"
                    ],
                    "group": [],
                    "_id": "e6a15cfd-755e-4f05-b47c-e77190473a9b",
                    "abstract": "This paper presents another look at the problem of energy detection of unknown signals over different fading channels. We start with the no diversity case and present some alternative closed-form expressions for the probability of detection (P/sub d/) to those recently reported in [V.I. Kostylev, May 2002]. We then investigate the system performance when different diversity schemes are employed. It is shown that there is not much improvement in the probability of detection when either the probability of false alarm (P/sub f/) exceeds 0/1 or the average signal-to-noise ratio (SNR) exceeds 20 dB. In addition, receiver operating characteristic (ROC) curves comparing the performance of equal-gain combining (EGC), selection combining (SC), and switch and stay combining (SSC) are presented. As an example, EGC introduces a gain of two orders of magnitude from the probability of miss perspective compared to the no diversity case while both SC and SSC introduce a gain of about one order of magnitude.",
                    "title": "On the energy detection of unknown signals over fading channels",
                    "venue": "international conference on communications",
                    "year": 2003,
                    "__v": 2,
                    "citationCount": 637,
                    "result": 2.1512095747389863
                },
                "f0ce34fb-5858-4dac-bd79-d3b020ec4270": {
                    "authors": [
                        "Haitao Zheng",
                        "Chunyi Peng"
                    ],
                    "references": [
                        "d31b5688-1b55-4dd7-b512-0c63b6b0997e"
                    ],
                    "keyword": [
                        "spectrum",
                        "users",
                        "access",
                        "utilization",
                        "significant",
                        "optimize",
                        "opportunistically",
                        "network",
                        "interference",
                        "collaboratively"
                    ],
                    "group": [],
                    "_id": "f0ce34fb-5858-4dac-bd79-d3b020ec4270",
                    "abstract": "The open spectrum approach to spectrum access can achieve near-optimal spectrum utilization by letting users sense and utilize available spectrum opportunistically. However, naive spectrum assignment can lead to significant interference. We propose a network controlled spectrum access scheme where users behave collaboratively to optimize spectrum allocation for the entire network. We develop a graph-theoretical model to characterize the spectrum access problem under a number of different optimization functions, and devise rules for users to utilize available spectrum while avoiding interference with their neighbors. Experimental results confirm that user collaboration yields significant benefits (as much as 50% improvement) in opportunistic spectrum access.",
                    "title": "Collaboration and fairness in opportunistic spectrum access",
                    "venue": "international conference on communications",
                    "year": 2005,
                    "__v": 2,
                    "citationCount": 160,
                    "result": 3.9330159009564047
                },
                "fba22e0f-c734-41c0-804a-51ffac08e852": {
                    "authors": [
                        "Chunyi Peng",
                        "Haitao Zheng",
                        "Ben Y. Zhao"
                    ],
                    "references": [
                        "10f58ff9-c14e-4bf5-9c44-0a3f14626d3f",
                        "19581d69-1068-4279-b339-eeaacd277008",
                        "3e3203a9-017e-4edb-9b34-a62012f71f4f",
                        "46cecb1b-007a-4e04-b1ca-9d478fdf18fd",
                        "5799bd85-1e5e-45d2-950e-1cfaec644c35",
                        "865d817f-2607-4082-bd9f-3298395cc316",
                        "a301962a-6d47-4fcc-9a89-5c67e1fac20f",
                        "bed81d8b-9c95-4e95-9629-fb249059f83f",
                        "d31b5688-1b55-4dd7-b512-0c63b6b0997e",
                        "dd3151e6-9756-4260-bc37-3507976fa578",
                        "f0ce34fb-5858-4dac-bd79-d3b020ec4270"
                    ],
                    "keyword": [
                        "spectrum",
                        "problem",
                        "global",
                        "assignment",
                        "allocation",
                        "utilization",
                        "show",
                        "distributed",
                        "devices",
                        "centralized"
                    ],
                    "group": [],
                    "_id": "fba22e0f-c734-41c0-804a-51ffac08e852",
                    "abstract": "The Open Spectrum approach to spectrum access can achieve near-optimal utilization by allowing devices to sense and utilize available spectrum opportunistically. However, a naive distributed spectrum assignment can lead to significant interference between devices. In this paper, we define a general framework that defines the spectrum access problem for several definitions of overall system utility. By reducing the allocation problem to a variant of the graph coloring problem, we show that the global optimization problem is NP-hard, and provide a general approximation methodology through vertex labeling. We examine both a centralized strategy, where a central server calculates an allocation assignment based on global knowledge, and a distributed approach, where devices collaborate to negotiate local channel assignments towards global optimization. Our experimental results show that our allocation algorithms can dramatically reduce interference and improve throughput (as much as 12-fold). Further simulations show that our distributed algorithms generate allocation assignments similar in quality to our centralized algorithms using global knowledge, while incurring substantially less computational complexity in the process.",
                    "title": "Utilization and fairness in spectrum assignment for opportunistic spectrum access",
                    "venue": "Mobile Networks and Applications",
                    "year": 2006,
                    "__v": 2,
                    "citationCount": 214,
                    "result": 4.344147773525886
                }
            }
        ],
        "_id": "a2cd0e23-f184-441d-b90e-d4492a9ef508",
        "abstract": "Today's wireless networks are characterized by a fixed spectrum assignment policy. However, a large portion of the assigned spectrum is used sporadically and geographical variations in the utilization of assigned spectrum ranges from 15% to 85% with a high variance in time. The limited available spectrum and the inefficiency in the spectrum usage necessitate a new communication paradigm to exploit the existing wireless spectrum opportunistically. This new networking paradigm is referred to as NeXt Generation (xG) Networks as well as Dynamic Spectrum Access (DSA) and cognitive radio networks. The term xG networks is used throughout the paper. The novel functionalities and current research challenges of the xG networks are explained in detail. More specifically, a brief overview of the cognitive radio technology is provided and the xG network architecture is introduced. Moreover, the xG network functions such as spectrum management, spectrum mobility and spectrum sharing are explained in detail. The influence of these functions on the performance of the upper layer protocols such as routing and transport are investigated and open research issues in these areas are also outlined. Finally, the cross-layer design challenges in xG networks are discussed.",
        "title": "NeXt generation/dynamic spectrum access/cognitive radio wireless networks: a survey",
        "venue": "Computer Networks",
        "year": 2006,
        "__v": 1,
        "citationCount": 2483
    },
    {
        "authors": [
            "Emmanuel J. Candès",
            "Justin K. Romberg",
            "Terence Tao"
        ],
        "references": [
            "2d75f21b-8617-4c21-a1bf-467a82458459",
            "4114181f-6f48-4cb6-b6d3-b337515d57f8",
            "449bfdfc-f916-422c-ac0d-ebfdd2ab773a",
            "53c1d13a-863d-4db2-bc77-bbc7f8a45fa8",
            "5eb8608d-d0a1-4f14-af98-8a26bab51fae",
            "7291a02d-1d94-48b7-a4e2-35406c0e52ad",
            "87a4faed-c1a5-45c8-81eb-3bf19ae19011",
            "d2104367-6389-4b06-8dbe-bab7e05b903b",
            "f11bfae2-e272-4acc-b231-a9619f1e4d6c"
        ],
        "keyword": [
            "spl",
            "frequency",
            "samples",
            "reconstructing",
            "spikes",
            "set",
            "problem",
            "probability",
            "omega",
            "convex"
        ],
        "group": [
            {
                "449bfdfc-f916-422c-ac0d-ebfdd2ab773a": {
                    "authors": [
                        "Joel A. Tropp"
                    ],
                    "references": [
                        "38c8c7a7-e6f4-4f59-91de-76d74e801418",
                        "4114181f-6f48-4cb6-b6d3-b337515d57f8",
                        "5d887090-2713-49d5-9f0e-8ecbc57d6862",
                        "87a4faed-c1a5-45c8-81eb-3bf19ae19011",
                        "913bb59b-71fe-4bd1-8f97-1c974a93575c",
                        "bb3c38fa-c2b0-4d4f-8c9d-ca1884343474",
                        "cb17c20e-e335-43dc-b2ae-350e43b74faa",
                        "dbb8606e-3419-45c0-84ee-8872c86fdcd8",
                        "eacf08f1-1e8b-44ee-90b5-234724ae8355",
                        "f11bfae2-e272-4acc-b231-a9619f1e4d6c"
                    ],
                    "keyword": [],
                    "group": [],
                    "_id": "449bfdfc-f916-422c-ac0d-ebfdd2ab773a",
                    "abstract": "This article presents new results on using a greedy algorithm, orthogonal matching pursuit (OMP), to solve the sparse approximation problem over redundant dictionaries. It provides a sufficient condition under which both OMP and Donoho's basis pursuit (BP) paradigm can recover the optimal representation of an exactly sparse signal. It leverages this theory to show that both OMP and BP succeed for every sparse input signal from a wide class of dictionaries. These quasi-incoherent dictionaries offer a natural generalization of incoherent dictionaries, and the cumulative coherence function is introduced to quantify the level of incoherence. This analysis unifies all the recent results on BP and extends them to OMP. Furthermore, the paper develops a sufficient condition under which OMP can identify atoms from an optimal approximation of a nonsparse signal. From there, it argues that OMP is an approximation algorithm for the sparse problem over a quasi-incoherent dictionary. That is, for every input signal, OMP calculates a sparse approximant whose error is only a small factor worse than the minimal error that can be attained with the same number of terms.",
                    "title": "Greed is good: algorithmic results for sparse approximation",
                    "venue": "IEEE Transactions on Information Theory",
                    "year": 2004,
                    "__v": 0,
                    "citationCount": 1107,
                    "result": 3.333333333333333
                },
                "5eb8608d-d0a1-4f14-af98-8a26bab51fae": {
                    "authors": [
                        "Anna C. Gilbert",
                        "Sudipto Guha",
                        "Piotr Indyk",
                        "S. Muthukrishnan",
                        "Martin J. Strauss"
                    ],
                    "references": [
                        "8bae3a3e-3a6f-421d-b8d0-8112060ce532",
                        "a2ab670d-6866-4df9-9160-483987840b09",
                        "b976d168-45d2-4c08-9a31-518d33f7b438",
                        "bb3c38fa-c2b0-4d4f-8c9d-ca1884343474",
                        "c385db5b-803b-4d88-b756-f7cc417bbfb0",
                        "d7953b97-e51b-45e2-b0f7-5e2eed1f9bd3"
                    ],
                    "keyword": [
                        "sample",
                        "algorithm",
                        "signal",
                        "log",
                        "values",
                        "total",
                        "time",
                        "terms",
                        "smallest",
                        "similar"
                    ],
                    "group": [],
                    "_id": "5eb8608d-d0a1-4f14-af98-8a26bab51fae",
                    "abstract": "(MATH) We give an algorithm for finding a Fourier representation  R  of  B  terms for a given discrete signal signal  A  of length  N , such that $\\|\\signal-\\repn\\|_2^2$ is within the factor (1 +e) of best possible $\\|\\signal-\\repn_\\opt\\|_2^2$. Our algorithm can access  A  by reading its values on a sample set   T   ⊆[0, N ), chosen randomly from a (non-product) distribution of our choice, independent of  A . That is, we sample non-adaptively. The total time cost of the algorithm is polynomial in  B  log( N )log( M )e (where  M  is the ratio of largest to smallest numerical quantity encountered), which implies a similar bound for the number of samples.",
                    "title": "Near-optimal sparse fourier representations via sampling",
                    "venue": "symposium on the theory of computing",
                    "year": 2002,
                    "__v": 1,
                    "citationCount": 100,
                    "result": 3.287318237318237
                },
                "7291a02d-1d94-48b7-a4e2-35406c0e52ad": {
                    "authors": [
                        "Ping Feng",
                        "Yoram Bresler"
                    ],
                    "references": [
                        "627ff7f2-4db7-4db3-900a-38458d20ef6d",
                        "9964c906-b6bf-45de-8827-467114ee5493",
                        "c2edcc45-5cbc-403c-85c2-a125e7d80572"
                    ],
                    "keyword": [
                        "sampling",
                        "reconstruction",
                        "pattern",
                        "universal",
                        "spectral",
                        "signals",
                        "criterion",
                        "wellconditioned",
                        "support",
                        "shown"
                    ],
                    "group": [],
                    "_id": "7291a02d-1d94-48b7-a4e2-35406c0e52ad",
                    "abstract": "We propose a universal sampling pattern and corresponding reconstruction algorithms that guarantee well-conditioned reconstruction of all multiband signals with a given spectral occupancy bound without prior knowledge of the spectral support. It is shown that such a universal sampling pattern can asymptotically achieve the Nyquist-Landau (1957) minimal sampling rate. Also, the new design method replaces the nonaliasing or packability criterion for a reconstructive sampling pattern with a more lenient criterion, allowing reconstruction of signals aliased by sampling.",
                    "title": "Spectrum-blind minimum-rate sampling and reconstruction of multiband signals",
                    "venue": "international conference on acoustics speech and signal processing",
                    "year": 1996,
                    "__v": 2,
                    "citationCount": 118,
                    "result": 4.1807374771771055
                },
                "87a4faed-c1a5-45c8-81eb-3bf19ae19011": {
                    "authors": [
                        "Rémi Gribonval",
                        "Morten Nielsen"
                    ],
                    "references": [
                        "4114181f-6f48-4cb6-b6d3-b337515d57f8",
                        "f11bfae2-e272-4acc-b231-a9619f1e4d6c"
                    ],
                    "keyword": [
                        "dictionaries",
                        "sparse",
                        "rsup",
                        "representations",
                        "union",
                        "signals",
                        "result",
                        "redundant",
                        "problem",
                        "orthonormal"
                    ],
                    "group": [],
                    "_id": "87a4faed-c1a5-45c8-81eb-3bf19ae19011",
                    "abstract": "The purpose of this correspondence is to generalize a result by Donoho and Huo and Elad and Bruckstein on sparse representations of signals in a union of two orthonormal bases for R/sup N/. We consider general (redundant) dictionaries for R/sup N/, and derive sufficient conditions for having unique sparse representations of signals in such dictionaries. The special case where the dictionary is given by the union of L/spl ges/2 orthonormal bases for R/sup N/ is studied in more detail. In particular, it is proved that the result of Donoho and Huo, concerning the replacement of the /spl lscr//sup 0/ optimization problem with a linear programming problem when searching for sparse representations, has an analog for dictionaries that may be highly redundant.",
                    "title": "Sparse representations in unions of bases",
                    "venue": "IEEE Transactions on Information Theory",
                    "year": 2003,
                    "__v": 2,
                    "citationCount": 284,
                    "result": 7.677111324510033
                },
                "d2104367-6389-4b06-8dbe-bab7e05b903b": {
                    "authors": [
                        "Martin Vetterli",
                        "Pina Marziliano",
                        "Thierry Blu"
                    ],
                    "references": [
                        "3c262768-4473-4806-b3f6-ba919d438471",
                        "57efc18d-3b8d-4fe0-b9c0-c19518159042",
                        "609eb56f-2252-48a8-9d53-7ec9a6172eb3",
                        "70694f68-0ecd-47ea-9f61-f464c0ef7a97",
                        "f8e77898-9f6b-4d14-9b14-06dc94ff0094"
                    ],
                    "keyword": [
                        "signals",
                        "sampled",
                        "kernel",
                        "innovation",
                        "show",
                        "rate",
                        "splines",
                        "reconstructed",
                        "finite",
                        "diracs"
                    ],
                    "group": [],
                    "_id": "d2104367-6389-4b06-8dbe-bab7e05b903b",
                    "abstract": "The authors consider classes of signals that have a finite number of degrees of freedom per unit of time and call this number the rate of innovation. Examples of signals with a finite rate of innovation include streams of Diracs (e.g., the Poisson process), nonuniform splines, and piecewise polynomials. Even though these signals are not bandlimited, we show that they can be sampled uniformly at (or above) the rate of innovation using an appropriate kernel and then be perfectly reconstructed. Thus, we prove sampling theorems for classes of signals and kernels that generalize the classic \"bandlimited and sinc kernel\" case. In particular, we show how to sample and reconstruct periodic and finite-length streams of Diracs, nonuniform splines, and piecewise polynomials using sinc and Gaussian kernels. For infinite-length signals with finite local rate of innovation, we show local sampling and reconstruction based on spline kernels. The key in all constructions is to identify the innovative part of a signal (e.g., time instants and weights of Diracs) using an annihilating or locator filter: a device well known in spectral analysis and error-correction coding. This leads to standard computational procedures for solving the sampling problem, which we show through experimental results. Applications of these new sampling results can be found in signal processing, communications systems, and biological systems.",
                    "title": "Sampling signals with finite rate of innovation",
                    "venue": "IEEE Transactions on Signal Processing",
                    "year": 2002,
                    "__v": 2,
                    "citationCount": 349,
                    "result": 4.672555832540354
                },
                "f11bfae2-e272-4acc-b231-a9619f1e4d6c": {
                    "authors": [
                        "Michael Elad",
                        "Alfred M. Bruckstein"
                    ],
                    "references": [
                        "bb3c38fa-c2b0-4d4f-8c9d-ca1884343474",
                        "de4fea1d-2739-4e0f-b5a3-08f0df58d787"
                    ],
                    "keyword": [
                        "representations",
                        "vectors",
                        "uniqueness",
                        "sparse",
                        "result",
                        "pairs",
                        "orthonormal",
                        "bases",
                        "uncertainty",
                        "stronger"
                    ],
                    "group": [],
                    "_id": "f11bfae2-e272-4acc-b231-a9619f1e4d6c",
                    "abstract": "An elementary proof of a basic uncertainty principle concerning pairs of representations of R/sup N/ vectors in different orthonormal bases is provided. The result, slightly stronger than stated before, has a direct impact on the uniqueness property of the sparse representation of such vectors using pairs of orthonormal bases as overcomplete dictionaries. The main contribution in this paper is the improvement of an important result due to Donoho and Huo (2001) concerning the replacement of the l/sub 0/ optimization problem by a linear programming (LP) minimization when searching for the unique sparse representation.",
                    "title": "A generalized uncertainty principle and sparse representation in pairs of bases",
                    "venue": "IEEE Transactions on Information Theory",
                    "year": 2002,
                    "__v": 2,
                    "citationCount": 187,
                    "result": 5.791584361381777
                }
            }
        ],
        "_id": "a53a3dda-b003-4d5c-96b1-e9afd8e35692",
        "abstract": "This paper considers the model problem of reconstructing an object from incomplete frequency samples. Consider a discrete-time signal f/spl isin/C/sup N/ and a randomly chosen set of frequencies /spl Omega/. Is it possible to reconstruct f from the partial knowledge of its Fourier coefficients on the set /spl Omega/? A typical result of this paper is as follows. Suppose that f is a superposition of |T| spikes f(t)=/spl sigma//sub /spl tau//spl isin/T/f(/spl tau/)/spl delta/(t-/spl tau/) obeying |T|/spl les/C/sub M//spl middot/(log N)/sup -1/ /spl middot/ |/spl Omega/| for some constant C/sub M/>0. We do not know the locations of the spikes nor their amplitudes. Then with probability at least 1-O(N/sup -M/), f can be reconstructed exactly as the solution to the /spl lscr//sub 1/ minimization problem. In short, exact recovery may be obtained by solving a convex optimization problem. We give numerical values for C/sub M/ which depend on the desired probability of success. Our result may be interpreted as a novel kind of nonlinear sampling theorem. In effect, it says that any signal made out of |T| spikes may be recovered by convex programming from almost every set of frequencies of size O(|T|/spl middot/logN). Moreover, this is nearly optimal in the sense that any method succeeding with probability 1-O(N/sup -M/) would in general require a number of frequency samples at least proportional to |T|/spl middot/logN. The methodology extends to a variety of other situations and higher dimensions. For example, we show how one can reconstruct a piecewise constant (one- or two-dimensional) object from incomplete frequency samples - provided that the number of jumps (discontinuities) obeys the condition above - by minimizing other convex functionals such as the total variation of f.",
        "title": "Robust uncertainty principles: exact signal reconstruction from highly incomplete frequency information",
        "venue": "IEEE Transactions on Information Theory",
        "year": 2006,
        "__v": 3,
        "citationCount": 3800
    },
    {
        "authors": [
            "Nick McKeown",
            "Thomas E. Anderson",
            "Hari Balakrishnan",
            "Guru M. Parulkar",
            "Larry L. Peterson",
            "Jennifer Rexford",
            "Scott Shenker",
            "Jonathan S. Turner"
        ],
        "references": [
            "2305da97-ee8b-4023-9f94-c0a9ea7e580f",
            "5477474b-c802-4696-b2e5-57a8f6bd14ae",
            "5ad83b9b-6ae3-42ea-9b5f-e2fabe669c74",
            "72db976e-5886-4750-a650-0ef209e3a51c",
            "cdadb79e-6542-4947-8b3b-e4a0341e8389"
        ],
        "keyword": [
            "openflow",
            "switch",
            "run",
            "researchers",
            "networks",
            "vendors",
            "proposes",
            "internal",
            "hand",
            "ethernet"
        ],
        "group": [
            {
                "5477474b-c802-4696-b2e5-57a8f6bd14ae": {
                    "authors": [
                        "Martin Casado",
                        "Michael J. Freedman",
                        "Justin Pettit",
                        "Jianying Luo",
                        "Nick McKeown",
                        "Scott Shenker"
                    ],
                    "references": [
                        "0b9a70b6-17f8-4ce3-952e-732e8e32d8f7",
                        "1e0b2415-13ae-4ee3-8ab6-d70e9e4cdfe2",
                        "1e37650f-5ca1-4980-b656-71e8d6861724",
                        "24bd4bf6-5665-4bd5-a224-dbfc21bea513",
                        "2d82069d-ef61-4e7c-ab4d-02bb11159f64",
                        "2f957be5-a283-45e3-9aa8-2f5e3aac912f",
                        "3f0285ce-cdd6-43d4-b052-8511a3851f95",
                        "6f012a8f-f9d7-4078-af00-fc2cf04fdc05",
                        "93abb917-900c-469f-89a4-40a29bcfa497",
                        "9905dd32-5ca5-491a-8558-1b78e013cad2",
                        "d50b1057-5496-4ac2-96ad-e325b3b8ec42",
                        "e53c8efb-d371-4e26-910a-a57bdac34982",
                        "ee3a15e2-3731-437c-9bf7-3fa3a37cdc89"
                    ],
                    "keyword": [
                        "ethane",
                        "network",
                        "hosts",
                        "switches",
                        "supporting",
                        "managers",
                        "design"
                    ],
                    "group": [],
                    "_id": "5477474b-c802-4696-b2e5-57a8f6bd14ae",
                    "abstract": "This paper presents Ethane, a new network architecture for the enterprise. Ethane allows managers to define a single network-wide fine-grain policy, and then enforces it directly. Ethane couples extremely simple flow-based Ethernet switches with a centralized controller that manages the admittance and routing of flows. While radical, this design is backwards-compatible with existing hosts and switches.   We have implemented Ethane in both hardware and software, supporting both wired and wireless hosts. Our operational Ethane network has supported over 300 hosts for the past four months in a large university network, and this deployment experience has significantly affected Ethane's design.",
                    "title": "Ethane: taking control of the enterprise",
                    "venue": "acm special interest group on data communication",
                    "year": 2007,
                    "__v": 2,
                    "citationCount": 290,
                    "result": 6.210621241503595
                },
                "5ad83b9b-6ae3-42ea-9b5f-e2fabe669c74": {
                    "authors": [
                        "Eddie Kohler",
                        "Robert Morris",
                        "Benjie Chen",
                        "John Jannotti",
                        "M. Frans Kaashoek"
                    ],
                    "references": [
                        "022d0740-e121-4c5e-8a75-d3e9c878e127",
                        "02b14a3a-5fd4-4a91-9808-8223a318b8b4",
                        "04b1dabc-f582-4bd2-b6ba-1019ef5d3f6e",
                        "23b95c92-595d-419a-b3ce-9979ad95a7a6",
                        "35bf84dd-82f4-4a45-a114-bfe8c635c2c4",
                        "371e3a51-581b-416a-b59f-1cbe80471f31",
                        "442c1301-b25b-4721-98ef-19cb1e1bf1ff",
                        "615e52e2-ba70-4bf9-8c9c-36b74fd083a7",
                        "66af02bc-ff71-4504-9425-53227b29573b",
                        "6b1dfe1c-989e-429b-a6ad-7023b02d6f37",
                        "71d05877-2afe-4880-8cee-8d6d7c7e8005",
                        "81435071-cb68-4ceb-8ddb-7852f2b300b6",
                        "84b58288-c05b-46a0-b77d-fff1ac822ffd",
                        "8ed0c977-c4e4-4183-8ec3-b2fc7bea41cf",
                        "9ec23b98-e7c2-4747-bbb5-dc65a48f974d",
                        "9edbce2d-19c9-4005-9826-14d06306df16",
                        "aa18f452-d13c-4301-89c7-ca2bb0b89e85",
                        "ae941637-b658-4a15-be8d-f32109e5f510",
                        "c21f493e-5687-4a14-8d5c-cf0e3bc97f05",
                        "cc849faf-6cc4-4203-83d5-25d22e5cddf9",
                        "cdedb3ff-5c7d-402f-a03c-18c0ee6748ce",
                        "d2b7db5d-bc47-48c7-a173-865fed9bff96",
                        "dea6d574-254f-4097-9a95-74cc01db7154"
                    ],
                    "keyword": [
                        "elements",
                        "routers",
                        "clicks",
                        "packet",
                        "configurable",
                        "ip",
                        "flow"
                    ],
                    "group": [],
                    "_id": "5ad83b9b-6ae3-42ea-9b5f-e2fabe669c74",
                    "abstract": "Clicks is a new software architecture for building flexible and configurable routers. A Click router is assembled from packet processing modules called  elements . Individual elements implement simple router functions like packet classification, queuing, scheduling, and interfacing with network devices. A router configurable is a directed graph with elements at the vertices; packets flow along the edges of the graph. Several features make individual elements more powerful and complex configurations easier to write, including  pull connections,  which model packet flow drivn by transmitting hardware devices, and  flow-based router context,  which helps an element locate other interesting elements. Click configurations are modular and easy to extend. A standards-compliant Click IP router has 16 elements on its forwarding path; some of its elements are also useful in Ethernet switches and IP tunnelling configurations. Extending the IP router to support dropping policies, fairness among flows, or Differentiated Services simply requires adding a couple of element at the right place. On conventional PC hardware, the Click IP router achieves a maximum loss-free forwarding rate of 333,000 64-byte packets per second, demonstrating that Click's modular and flexible architecture is compatible with good performance.",
                    "title": "The click modular router",
                    "venue": "ACM Transactions on Computer Systems",
                    "year": 2000,
                    "__v": 1,
                    "citationCount": 1059,
                    "result": 2.682722832722833
                }
            }
        ],
        "_id": "abf7f290-5b74-4b9a-9661-a1af46b0083a",
        "abstract": "This whitepaper proposes OpenFlow: a way for researchers to run experimental protocols in the networks they use every day. OpenFlow is based on an Ethernet switch, with an internal flow-table, and a standardized interface to add and remove flow entries. Our goal is to encourage networking vendors to add OpenFlow to their switch products for deployment in college campus backbones and wiring closets. We believe that OpenFlow is a pragmatic compromise: on one hand, it allows researchers to run experiments on heterogeneous switches in a uniform way at line-rate and with high port-density; while on the other hand, vendors do not need to expose the internal workings of their switches. In addition to allowing researchers to evaluate their ideas in real-world traffic settings, OpenFlow could serve as a useful campus component in proposed large-scale testbeds like GENI. Two buildings at Stanford University will soon run OpenFlow networks, using commercial Ethernet switches and routers. We will work to encourage deployment at other schools; and We encourage you to consider deploying OpenFlow in your university network too",
        "title": "OpenFlow: enabling innovation in campus networks",
        "venue": "acm special interest group on data communication",
        "year": 2008,
        "__v": 2,
        "citationCount": 2359
    },
    {
        "authors": [
            "John D. Lafferty",
            "Andrew McCallum",
            "Fernando Pereira"
        ],
        "references": [
            "01f443e7-ea4c-48a7-8081-745c3fa62769",
            "48c96aa0-6337-4431-bee6-abe55cfce8f2",
            "5538b634-04f3-4d09-bb4e-90055817e3b1",
            "594e1c78-0c50-4ab2-a0d1-08b5c5d7e168",
            "61553c41-20ea-4502-9a66-9884c6b179d3",
            "63ea9425-d22a-4c65-814c-58e67ae712fc",
            "85415160-c71b-49de-b62a-7cf8ee2a60a8",
            "97211b46-a46d-4886-912e-138333aa50bc",
            "a8110bb3-072b-45e7-a5ee-72218e958a84",
            "ba733803-6b30-4a2b-b76a-0bbe17baa2f0",
            "bc95970b-34c5-4860-a832-41bc04a50889",
            "db26488d-78be-44b1-a343-e896f43c5d29",
            "db3f258e-9c9f-4299-a616-6a456e123fdc",
            "e91a0a81-da9c-4009-9007-18ba9b8595b2"
        ],
        "keyword": [],
        "group": [],
        "_id": "ae829318-5d10-461d-9c99-34a95a3f8732",
        "title": "Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data",
        "venue": "international conference on machine learning",
        "year": 2001,
        "abstract": "",
        "__v": 0,
        "citationCount": 4655
    },
    {
        "authors": [
            "M. E. J. Newman"
        ],
        "references": [
            "008d95fd-26f0-47f3-8774-6a896446baea",
            "05332f60-3d2e-45bb-9ecd-a7c7aa7774dc",
            "05f5fba9-e7ca-4c46-be79-df57944a8b41",
            "0718dc34-4b49-4b24-8a2e-b5cd0d9d82c6",
            "0d8eb1a3-5b89-419b-9eea-8fffd03c78a1",
            "16e3c2f7-37fb-4192-bf76-20fe7838958a",
            "18819165-7f73-4da1-9bf2-792c258be677",
            "19f41085-f8c3-4087-a48a-27205b43bdb8",
            "1a24e9c7-d0ce-4be4-8e3a-c849b4630851",
            "1b41d9a0-3857-4fb6-b7ba-d39da73c04dd",
            "27e4ec4d-0ce3-437b-9511-db610b7ba805",
            "2a2fd168-2bcf-4527-afcd-5c99e75ad511",
            "38135245-8eff-4078-af6a-ea559ffa660b",
            "3bbad1d7-7c16-4c85-ae98-4cfd6913794f",
            "3f610d75-809b-4a12-858f-95e346c17e8c",
            "424bab1d-a362-4bd2-a878-eb81372b689d",
            "4c343995-619f-4859-bd00-321c87adcd3c",
            "597ecf84-4084-4057-a40d-30988ef74121",
            "5ea35ec7-ab9f-4d0e-9a85-ef4add482ec7",
            "606e4423-5a84-4c3b-bfb1-0cf549bf21e9",
            "60c814e2-c4d1-47d7-9a5a-68f4141505ae",
            "60ef3852-fa16-44bf-9434-9909268ba5d8",
            "63245010-95d3-4eb1-a0d0-62894531d092",
            "686c5563-3f13-4744-ac6d-1020e39953bf",
            "6e6cac85-1ca8-4d49-8e16-aa3d353fc20a",
            "71414cbd-e8f3-43ce-b536-029959d08b14",
            "7192626f-12df-45f7-889d-c78e4da08773",
            "7291c68d-db95-48a0-b856-6545ef18b503",
            "8a4d517a-da96-4f80-879d-dda81e69d9c9",
            "8f12317e-0ea6-455c-a973-7c7440af5f37",
            "8f9e92cf-f266-4e51-807f-c098a260a0dc",
            "98c4a2e2-f046-4e49-9173-91779f961cc0",
            "9dbdc129-b8f3-4712-9c95-406bc8911bee",
            "a0181d7d-c725-4bc4-8371-2510c70c96a4",
            "a08549f5-fa6a-4adb-b643-714867228a0c",
            "a0c94b9b-d64e-40d5-ba44-4208dec791d0",
            "a22c015f-fa44-4b73-b906-ef030405d9c9",
            "a4a93e4a-68f2-4509-bf87-5b33122ff614",
            "a78ddf3f-d0ac-4262-bd99-ca8d5bd8309e",
            "af8a7a02-c5f2-4367-9a67-7593d92f6003",
            "b2f1d79b-d47a-4f2a-b810-ac3c837d7ee4",
            "b407837a-0eae-4882-9a2c-2c185d5c16e0",
            "baad4ab4-a3f2-45fc-b87d-954f608e8db7",
            "bd34626f-94ae-46a2-8037-8c367831fa78",
            "c2165f5b-d07b-4cd2-9d2b-e6f3002c80db",
            "c4716aad-c8bc-431b-8173-0300064a77b0",
            "c7e4e04b-45da-4bae-8c8a-d17ca0087361",
            "ce115523-6b89-47ad-8cf3-1cb3e2a865d3",
            "d71f089c-0658-478a-b58e-bb8e6f131c21",
            "dd38911a-f68b-4bb5-a817-fd7153f0ff2f",
            "df4b8e90-b404-47f8-a384-c93aa1313694",
            "e2a97ffb-90b0-4f1a-b01d-b15a77a820de",
            "e4f056cc-ab1e-4ca0-8754-fc81b133a47d",
            "f15b19f2-4b37-454c-851e-a71cccf3e53a",
            "f8088d69-04af-49f3-84b9-daf7682cc5f5"
        ],
        "keyword": [
            "networked",
            "models",
            "systems",
            "developed",
            "years",
            "variety",
            "understand",
            "techniques",
            "studies",
            "social"
        ],
        "group": [
            {
                "4c343995-619f-4859-bd00-321c87adcd3c": {
                    "authors": [
                        "Carolyn J. Anderson",
                        "Stanley Wasserman",
                        "Bradley Crouch"
                    ],
                    "references": [],
                    "keyword": [
                        "models",
                        "pp",
                        "networks",
                        "statistical",
                        "wasserman",
                        "social",
                        "journal",
                        "data"
                    ],
                    "group": [],
                    "_id": "4c343995-619f-4859-bd00-321c87adcd3c",
                    "abstract": "A major criticism of the statistical models for analyzing social networks developed by Holland, Leinhardt, and others [Holland, P.W., Leinhardt, S., 1977. Notes on the statistical analysis of social network data; Holland, P.W., Leinhardt, S., 1981. An exponential family of probability distributions for directed graphs. Journal of the American Statistical Association. 76, pp. 33–65 (with discussion); Fienberg, S.E., Wasserman, S., 1981. Categorical data analysis of single sociometric relations. In: Leinhardt, S. (Ed.), Sociological Methodology 1981, San Francisco: Jossey-Bass, pp. 156–192; Fienberg, S.E., Meyer, M.M., Wasserman, S., 1985. Statistical analysis of multiple sociometric relations. Journal of the American Statistical Association, 80, pp. 51–67; Wasserman, S., Weaver, S., 1985. Statistical analysis of binary relational data: Parameter estimation. Journal of Mathematical Psychology. 29, pp. 406–427; Wasserman, S., 1987. Conformity of two sociometric relations. Psychometrika. 52, pp. 3–18] is the very strong independence assumption made on interacting individuals or units within a network or group. This limiting assumption is no longer necessary given recent developments on models for random graphs made by Frank and Strauss [Frank, O., Strauss, D., 1986. Markov graphs. Journal of the American Statistical Association. 81, pp. 832–842] and Strauss and Ikeda [Strauss, D., Ikeda, M., 1990. Pseudolikelihood estimation for social networks. Journal of the American Statistical Association. 85, pp. 204–212]. The resulting models are extremely flexible and easy to fit to data. Although Wasserman and Pattison [Wasserman, S., Pattison, P., 1996. Logit models and logistic regressions for social networks: I. An introduction to Markov random graphs and  p *. Psychometrika. 60, pp. 401–426] present a derivation and extension of these models, this paper is a primer on how to use these important breakthroughs to model the relationships between actors (individuals, units) within a single network and provides an extension of the models to multiple networks. The models for multiple networks permit researchers to study how groups are similar and/or how they are different. The models for single and multiple networks and the modeling process are illustrated using friendship data from elementary school children from a study by Parker and Asher [Parker, J.G., Asher, S.R., 1993. Friendship and friendship quality in middle childhood: Links with peer group acceptance and feelings of loneliness and social dissatisfaction. Developmental Psychology. 29, pp. 611–621].",
                    "title": "A p* primer: Logit models for social networks",
                    "venue": "Social Networks",
                    "year": 1999,
                    "__v": 1,
                    "citationCount": 46,
                    "result": 4.5820342196503185
                },
                "597ecf84-4084-4057-a40d-30988ef74121": {
                    "authors": [
                        "Petter Holme",
                        "Mikael Huss",
                        "Hawoong Jeong"
                    ],
                    "references": [
                        "a6a89259-271d-43af-afb6-b6d6e9318e4e",
                        "cf8e8e5f-67b3-48d6-b6ba-df301b76b7e2",
                        "d536f87d-bbda-42a1-b55f-63f83bfd85da",
                        "ee10a31e-7efd-4a19-8c15-4b5a0ac0907d"
                    ],
                    "keyword": [
                        "networks",
                        "vastness",
                        "subnetworks",
                        "nonlocal",
                        "motivation",
                        "modern",
                        "mapped",
                        "inherent",
                        "genomics",
                        "decomposition"
                    ],
                    "group": [],
                    "_id": "597ecf84-4084-4057-a40d-30988ef74121",
                    "abstract": "Motivation: The vastness and complexity of the biochemical networks that have been mapped out by modern genomics calls for decomposition into subnetworks. Such networks can have inherent non-local  ...",
                    "title": "Subnetwork hierarchies of biochemical pathways",
                    "venue": "Bioinformatics",
                    "year": 2003,
                    "__v": 2,
                    "citationCount": 79,
                    "result": 5.521310062486531
                },
                "606e4423-5a84-4c3b-bfb1-0cf549bf21e9": {
                    "authors": [
                        "Jeffrey O. Kephart",
                        "Steve R. White"
                    ],
                    "references": [
                        "197fb86d-c652-4260-bb02-b583470d863e",
                        "34225cc1-75a2-4231-bb57-34e604ceee1b",
                        "386d7774-b210-4333-9a1b-38650808d208",
                        "8612ceda-f52e-4acb-94db-2fb5b2774c7a",
                        "98dbbea8-a76b-4817-98b7-9281a5b494ab",
                        "a2dc3d75-8eed-4db9-9d23-f5f34031edb6"
                    ],
                    "keyword": [
                        "viruses",
                        "computational",
                        "study",
                        "infected",
                        "epidemiology",
                        "epidemics"
                    ],
                    "group": [],
                    "_id": "606e4423-5a84-4c3b-bfb1-0cf549bf21e9",
                    "abstract": "The strong analogy between biological viruses and their computational counterparts has motivated the authors to adapt the techniques of mathematical epidemiology to the study of computer virus propagation. In order to allow for the most general patterns of program sharing, a standard epidemiological model is extended by placing it on a directed graph and a combination of analysis and simulation is used to study its behavior. The conditions under which epidemics are likely to occur are determined, and, in cases where they do, the dynamics of the expected number of infected individuals are examined as a function of time. It is concluded that an imperfect defense against computer viruses can still be highly effective in preventing their widespread proliferation, provided that the infection rate does not exceed a well-defined critical epidemic threshold. >",
                    "title": "Directed-graph epidemiological models of computer viruses",
                    "venue": "ieee symposium on security and privacy",
                    "year": 1991,
                    "__v": 2,
                    "citationCount": 290,
                    "result": 3.2297678585604284
                },
                "60ef3852-fa16-44bf-9434-9909268ba5d8": {
                    "authors": [
                        "Réka Albert",
                        "Albert-László Barabási"
                    ],
                    "references": [],
                    "keyword": [
                        "networks",
                        "nodes",
                        "degree",
                        "systems",
                        "real",
                        "distribution",
                        "topology",
                        "random",
                        "modeling"
                    ],
                    "group": [
                        null
                    ],
                    "_id": "60ef3852-fa16-44bf-9434-9909268ba5d8",
                    "abstract": "The emergence of order in natural systems is a constant source of inspiration for both physical and biological sciences. While the spatial order characterizing for example the crystals has been the basis of many advances in contemporary physics, most complex systems in nature do not offer such high degree of order. Many of these systems form complex networks whose nodes are the elements of the system and edges represent the interactions between them. #R##N#Traditionally complex networks have been described by the random graph theory founded in 1959 by Paul Erdohs and Alfred Renyi. One of the defining features of random graphs is that they are statistically homogeneous, and their degree distribution (characterizing the spread in the number of edges starting from a node) is a Poisson distribution. In contrast, recent empirical studies, including the work of our group, indicate that the topology of real networks is much richer than that of random graphs. In particular, the degree distribution of real networks is a power-law, indicating a heterogeneous topology in which the majority of the nodes have a small degree, but there is a significant fraction of highly connected nodes that play an important role in the connectivity of the network. #R##N#The scale-free topology of real networks has very important consequences on their functioning. For example, we have discovered that scale-free networks are extremely resilient to the random disruption of their nodes. On the other hand, the selective removal of the nodes with highest degree induces a rapid breakdown of the network to isolated subparts that cannot communicate with each other. #R##N#The non-trivial scaling of the degree distribution of real networks is also an indication of their assembly and evolution. Indeed, our modeling studies have shown us that there are general principles governing the evolution of networks. Most networks start from a small seed and grow by the addition of new nodes which attach to the nodes already in the system. This process obeys preferential attachment: the new nodes are more likely to connect to nodes with already high degree. We have proposed a simple model based on these two principles wich was able to reproduce the power-law degree distribution of real networks. Perhaps even more importantly, this model paved the way to a new paradigm of network modeling, trying to capture the evolution of networks, not just their static topology.",
                    "title": "Statistical mechanics of complex networks",
                    "venue": "Reviews of Modern Physics",
                    "year": 2001,
                    "__v": 3,
                    "citationCount": 3029,
                    "result": 6.719703009408893
                },
                "63245010-95d3-4eb1-a0d0-62894531d092": {
                    "authors": [
                        "Mark Steyvers",
                        "Joshua B. Tenenbaum"
                    ],
                    "references": [
                        "60ef3852-fa16-44bf-9434-9909268ba5d8",
                        "7192626f-12df-45f7-889d-c78e4da08773",
                        "bbabe882-1e9a-44d1-893b-28636719af53",
                        "bc95970b-34c5-4860-a832-41bc04a50889",
                        "c7e4e04b-45da-4bae-8c8a-d17ca0087361",
                        "ce115523-6b89-47ad-8cf3-1cb3e2a865d3",
                        "cfb7733b-1cb4-4308-9f1e-943f2e86e87e",
                        "e4f056cc-ab1e-4ca0-8754-fc81b133a47d",
                        "f15b19f2-4b37-454c-851e-a71cccf3e53a"
                    ],
                    "keyword": [
                        "connectivity",
                        "semantic",
                        "networks",
                        "structure",
                        "word",
                        "models"
                    ],
                    "group": [],
                    "_id": "63245010-95d3-4eb1-a0d0-62894531d092",
                    "abstract": "We present statistical analyses of the large-scale structure of 3 types of semantic networks: word associations, WordNet, and Roget’s Thesaurus. We show that they have a small-world structure, characterized by sparse connectivity, short average path lengths between words, and strong local clustering. In addition, the distributions of the number of connections follow power laws that indicate a scale-free pattern of connectivity, with most nodes having relatively few connections joined together through a small number of hubs with many connections. These regularities have also been found in certain other complex natural networks, such as the World Wide Web, but they are not consistent with many conventional models of semantic organization, based on inheritance hierarchies, arbitrarily structured networks, or high-dimensional vector spaces. We propose that these structures reflect the mechanisms by which semantic networks grow. We describe a simple model for semantic growth, in which each new word or concept is connected to an existing network by differentiating the connectivity pattern of an existing node. This model generates appropriate small-world statistics and power-law connectivity distributions, and it also suggests one possible mechanistic basis for the effects of learning history variables (age of acquisition, usage frequency) on behavioral performance in semantic processing tasks.",
                    "title": "The Large-Scale Structure of Semantic Networks: Statistical Analyses and a Model of Semantic Growth.",
                    "venue": "Cognitive Science",
                    "year": 2005,
                    "__v": 2,
                    "citationCount": 184,
                    "result": 5.006915916900436
                },
                "6e6cac85-1ca8-4d49-8e16-aa3d353fc20a": {
                    "authors": [
                        "Jon M. Kleinberg"
                    ],
                    "references": [
                        "62c0d7d2-9cc5-4b96-9a84-42d5ba0bed10",
                        "b9a9151a-158f-4d23-acb4-b1a45b6c527e",
                        "c66d83cd-0fd9-4d4b-a42e-cd9754bf5aca",
                        "ce115523-6b89-47ad-8cf3-1cb3e2a865d3",
                        "f15b19f2-4b37-454c-851e-a71cccf3e53a",
                        "f836e483-3269-4c45-9470-a81bb31c0e80"
                    ],
                    "keyword": [
                        "models",
                        "network",
                        "short",
                        "paths",
                        "algorithmic",
                        "work",
                        "family",
                        "decentralized"
                    ],
                    "group": [],
                    "_id": "6e6cac85-1ca8-4d49-8e16-aa3d353fc20a",
                    "abstract": "Long a matter of folklore, the ``small-world phenomenon'''' --the principle that we are all linked by short chains of acquaintances --was inaugurated as an area of experimental study in the social sciences through the pioneering work of Stanley Milgram in the 1960''s. This work was among the first to make the phenomenon quantitative, allowing people to speak of the ``six degrees of separation'''' between any two people in the United States. Since then, a number of network models have been proposed as frameworks in which to study the problem analytically. One of the most refined of these models was formulated in recent work of Watts and Strogatz; their framework provided compelling evidence that the small-world phenomenon is pervasive in a range of networks arising in nature and technology, and a fundamental ingredient in the evolution of the World Wide Web. But existing models are insufficient to explain the striking algorithmic component of Milgram''s original findings: that individuals using local information are collectively very effective at actually constructing short paths between two points in a social network. Although recently proposed network models are rich in short paths, we prove that no decentralized algorithm, operating with local information only, can construct short paths in these networks with non-negligible probability. We then define an infinite family of network models that naturally generalizes the Watts-Strogatz model, and show that for one of these models, there is a decentralized algorithm capable of finding short paths with high probability. More generally, we provide a strong characterization of this family of network models, showing that there is in fact a unique model within the family for which decentralized algorithms are effective.",
                    "title": "The small-world phenomenon: an algorithmic perspective",
                    "venue": "symposium on the theory of computing",
                    "year": 2000,
                    "__v": 2,
                    "citationCount": 838,
                    "result": 4.6453313026842435
                },
                "71414cbd-e8f3-43ce-b536-029959d08b14": {
                    "authors": [
                        "Petra M. Gleiss",
                        "Peter F. Stadler",
                        "Andreas Wagner",
                        "David A. Fell"
                    ],
                    "references": [
                        "06970b43-cca8-44e3-8ce4-c7e771eb334e",
                        "2d536378-5aed-4d66-b21c-986d359f6b69",
                        "6fbc81cd-dd14-44c2-9332-7dc382d6e697",
                        "a48d5360-3227-4e3b-a49c-03b302582c4d",
                        "b22e593a-2844-4d62-a815-84a27e39df0c",
                        "b95c3b75-2be3-4913-968f-d47c6a3b3bf6",
                        "ed93940a-4cc5-41b7-ac7f-bcb3cfea6fce"
                    ],
                    "keyword": [
                        "network",
                        "cycles",
                        "metabolic",
                        "large",
                        "world",
                        "small",
                        "short",
                        "reduce",
                        "random",
                        "distributions"
                    ],
                    "group": [],
                    "_id": "71414cbd-e8f3-43ce-b536-029959d08b14",
                    "abstract": "We characterize the distributions of short cycles in a large metabolic network previously shown to have small world characteristics and a power law degree distribution. Compared with three classes of random networks, including Erdős–Renyi random graphs and synthetic small world networks of the same connectivity, both the metabolic network and models for the chemical reaction networks of planetary atmospheres have a particularly large number of triangles and a deficit in large cycles. Short cycles reduce the length of detours when a connection is clipped, so we propose that long cycles in metabolism may have been selected against in order to shorten transition times and reduce the likelihood of oscillations in response to external perturbations.",
                    "title": "Relevant Cycles in Chemical Reaction Networks",
                    "venue": "Advances in Complex Systems",
                    "year": 2001,
                    "__v": 1,
                    "citationCount": 13,
                    "result": 4.039300405476876
                },
                "7192626f-12df-45f7-889d-c78e4da08773": {
                    "authors": [
                        "Jon M. Kleinberg",
                        "Ravi Kumar",
                        "Prabhakar Raghavan",
                        "Sridhar Rajagopalan",
                        "Andrew Tomkins"
                    ],
                    "references": [
                        "0c27b3d5-9b1a-4dd0-91db-bfd51dac5be3",
                        "27e4ec4d-0ce3-437b-9511-db610b7ba805",
                        "30cca30a-786b-4c06-ad4b-e122ec04e335",
                        "34b7e270-80d7-46d5-a6f1-e50087a8d045",
                        "3f610d75-809b-4a12-858f-95e346c17e8c",
                        "529f0775-01b2-4f1e-9d89-fc5227058019",
                        "66569d9a-07d1-4946-842a-80edcc26b15b",
                        "7b7f7c19-60f6-4d43-a641-4e6fab8aaeca",
                        "7dce00bc-8d45-4886-a341-63b5039217a7",
                        "8f9e92cf-f266-4e51-807f-c098a260a0dc",
                        "a5f0deb7-ce61-46d5-8cc2-b8362fd63db3",
                        "b9a25393-edf2-4e39-8252-64d332f225dd",
                        "bb02f0c6-3f59-4545-b72b-95dfdacea506",
                        "c7e4e04b-45da-4bae-8c8a-d17ca0087361",
                        "d40024e6-73fc-4aa7-bebb-2a54521cba83",
                        "da0f35bf-8a7b-4d2e-8626-0a098a4bc854",
                        "e127b1a6-04b4-4a24-9caf-59738ad3ee4b",
                        "ef78330f-d706-48b4-a37d-4a971ab0c1d5",
                        "f89fb319-6bc6-440c-bc44-d9a183ffe2e1"
                    ],
                    "keyword": [
                        "graph",
                        "web",
                        "study",
                        "random",
                        "models",
                        "algorithms",
                        "observe",
                        "nodes"
                    ],
                    "group": [],
                    "_id": "7192626f-12df-45f7-889d-c78e4da08773",
                    "abstract": "The pages and hyperlinks of the World-Wide Web may be viewed as nodes and edges in a directed graph. This graph is a fascinating object of study: it has several hundred million nodes today, over a billion links, and appears to grow exponentially with time. There are many reasons -- mathematical, sociological, and commercial -- for studying the evolution of this graph. In this paper we begin by describing two algorithms that operate on the Web graph, addressing problems from Web search and automatic community discovery. We then report a number of measurements and properties of this graph that manifested themselves as we ran these algorithms on the Web. Finally, we observe that traditional random graph models do not explain these observations, and we propose a new family of random graph models. These models point to a rich new sub-field of the study of random graphs, and raise questions about the analysis of graph algorithms on the Web.",
                    "title": "The web as a graph: measurements, models, and methods",
                    "venue": "computing and combinatorics conference",
                    "year": 1999,
                    "__v": 2,
                    "citationCount": 369,
                    "result": 5.339547380723851
                },
                "7291c68d-db95-48a0-b856-6545ef18b503": {
                    "authors": [
                        "Michael Molloy",
                        "Bruce A. Reed"
                    ],
                    "references": [
                        "2f50d4ce-379c-4784-89e1-4e2d9ffe1d86",
                        "424bab1d-a362-4bd2-a878-eb81372b689d",
                        "5bde5552-01ff-4b99-a3ff-e7651d3e3478",
                        "9dbdc129-b8f3-4712-9c95-406bc8911bee",
                        "f8088d69-04af-49f3-84b9-daf7682cc5f5"
                    ],
                    "keyword": [
                        "graph",
                        "component",
                        "vertices",
                        "giant",
                        "structure",
                        "random",
                        "ii2i0",
                        "deleting",
                        "degree",
                        "sum"
                    ],
                    "group": [],
                    "_id": "7291c68d-db95-48a0-b856-6545ef18b503",
                    "abstract": "Given a sequence of nonnegative real numbers λ0, λ1, … that sum to 1, we consider a random graph having approximately λin vertices of degree i. In [12] the authors essentially show that if ∑i(i−2)λi>0 then the graph a.s. has a giant component, while if ∑i(i−2)λi<0 then a.s. all components in the graph are small. In this paper we analyse the size of the giant component in the former case, and the structure of the graph formed by deleting that component. We determine e, λ′0, λ′1 … such that a.s. the giant component, C, has en+o(n) vertices, and the structure of the graph remaining after deleting C is basically that of a random graph with n′=n−∣C∣ vertices, and with λ′in′ of them of degree i.",
                    "title": "The Size of the Giant Component of a Random Graph with a Given Degree Sequence",
                    "venue": "Combinatorics, Probability & Computing",
                    "year": 1998,
                    "__v": 2,
                    "citationCount": 144,
                    "result": 3.9245179656944353
                },
                "8a4d517a-da96-4f80-879d-dda81e69d9c9": {
                    "authors": [
                        "M. E. J. Newman"
                    ],
                    "references": [
                        "1a24e9c7-d0ce-4be4-8e3a-c849b4630851",
                        "f15b19f2-4b37-454c-851e-a71cccf3e53a"
                    ],
                    "keyword": [
                        "networks",
                        "sampling",
                        "neighbors",
                        "egocentered",
                        "demonstrated",
                        "concepts",
                        "acquaintances",
                        "work",
                        "vertex",
                        "substantial"
                    ],
                    "group": [],
                    "_id": "8a4d517a-da96-4f80-879d-dda81e69d9c9",
                    "abstract": "Recent work has demonstrated that many networks have broad distributions of vertex degree. Here we show that this has a substantial impact on the shape of ego-centered networks and on concepts and methods based on ego-centered networks, such as snowball sampling and the “ripple effect”. In particular, we argue that one’s acquaintances, one’s immediate neighbors in the acquaintance network, are far from being a random sample of the population, and that this biases the numbers of neighbors two and more steps away. We demonstrate this concept using data on academic collaboration networks.",
                    "title": "Ego-centered networks and the ripple effect",
                    "venue": "Social Networks",
                    "year": 2003,
                    "__v": 1,
                    "citationCount": 49,
                    "result": 6.370608622543607
                },
                "8f9e92cf-f266-4e51-807f-c098a260a0dc": {
                    "authors": [
                        "Jon M. Kleinberg"
                    ],
                    "references": [
                        "0c23971f-2165-4a9b-83b1-00b08556d421",
                        "18b76b58-2d45-4dae-9f1f-0f4f7aae043c",
                        "27e4ec4d-0ce3-437b-9511-db610b7ba805",
                        "373b4f77-3e42-4683-9ae4-0378241e7325",
                        "3ed1f08a-a411-4078-b187-d95da5a38c4f",
                        "407ceb18-464f-4ab3-b731-68f7681fb26d",
                        "50d9a0e1-00a5-4445-b8b2-9f1405cbe6e1",
                        "529f0775-01b2-4f1e-9d89-fc5227058019",
                        "5a7d936d-b433-47c4-8955-a529c23e1498",
                        "5cc06390-77b7-4589-b42b-8b3254d755ad",
                        "6e551a7c-6769-49c1-93c5-037a06f4aaef",
                        "7dce00bc-8d45-4886-a341-63b5039217a7",
                        "8f6cafa9-28c3-424e-87bd-c28c8e57a44f",
                        "9785caef-a673-488d-9eaf-cf6d24108013",
                        "9cbb490c-d8e9-4dc9-84a7-8238ca21d0a5",
                        "a5f0deb7-ce61-46d5-8cc2-b8362fd63db3",
                        "ac14afe6-de4d-4056-b2ac-0f6e36f369a2",
                        "afa37e9f-2a18-4d29-bae1-ba93edd2a163",
                        "afa3a972-e82d-49fb-ad16-be307431134f",
                        "b84a20e0-0f9a-4a1c-82d3-1a940ffc4163",
                        "b9a25393-edf2-4e39-8252-64d332f225dd",
                        "c19c233b-6b1d-40a9-b553-a6efbe11932c",
                        "c7e4e04b-45da-4bae-8c8a-d17ca0087361",
                        "d7953b97-e51b-45e2-b0f7-5e2eed1f9bd3",
                        "e127b1a6-04b4-4a24-9caf-59738ad3ee4b",
                        "ed52603b-0cce-4606-a75c-a700bc4305bf",
                        "f1011b3e-1a8f-4cd2-bdb8-d5b6dce8f77a",
                        "ff269dbf-6570-4409-8cab-6ac142450d05"
                    ],
                    "keyword": [
                        "structure",
                        "set",
                        "link",
                        "information",
                        "environment",
                        "topics",
                        "source",
                        "pages",
                        "formulation",
                        "effective"
                    ],
                    "group": [],
                    "_id": "8f9e92cf-f266-4e51-807f-c098a260a0dc",
                    "abstract": "The network structure of a hyperlinked environment can be a rich source of information about the content of the environment, provided we have effective means for understanding it. We develop a set of algorithmic tools for extracting information from the link structures of such environments, and report on experiments that demonstrate their effectiveness in a variety of context on the World Wide Web. The central issue we address within our framework is the distillation of broad search topics, through the discovery of “authorative” information sources on such topics. We propose and test an algorithmic formulation of the notion of authority, based on the relationship between a set of relevant authoritative pages and the set of “hub pages” that join them together in  the link structure. Our formulation has connections to the eigenvectors of certain matrices associated with the link graph; these connections in turn motivate additional heuristrics for link-based analysis.",
                    "title": "Authoritative sources in a hyperlinked environment",
                    "venue": "Journal of the ACM",
                    "year": 1999,
                    "__v": 2,
                    "citationCount": 3448,
                    "result": 2.532416439769381
                },
                "98c4a2e2-f046-4e49-9173-91779f961cc0": {
                    "authors": [
                        "Howard D. White",
                        "Barry Wellman",
                        "Nancy Nazer"
                    ],
                    "references": [
                        "2de6edaf-1dbe-4296-b800-8f45bfaf9dab",
                        "497e18ee-e54b-42f5-aad1-6fbdecebcb03",
                        "4dc2ddcb-3d56-4290-9ddd-a177762b3459",
                        "50d9a0e1-00a5-4445-b8b2-9f1405cbe6e1",
                        "5b079a9a-e977-471a-abd4-d631264997bd",
                        "9b5ef0d0-5f0c-464d-ac84-18a4e676458c",
                        "a906b592-b3f5-46a3-b806-2eba844134b6",
                        "b740af6f-a04b-4dfe-9036-62c90aba6f18",
                        "cca29f25-98af-4192-ac37-516aa52bc5fc",
                        "ed8db3e2-549d-446f-b29f-57b84a1f22f0",
                        "f2d49e77-4623-43a6-b947-f1722062aeb4",
                        "fb9abe97-2d22-4a7b-94a0-c4636e8f8938"
                    ],
                    "keyword": [
                        "intercited",
                        "globenet",
                        "data",
                        "communication",
                        "citation",
                        "social",
                        "predictor",
                        "members"
                    ],
                    "group": [],
                    "_id": "98c4a2e2-f046-4e49-9173-91779f961cc0",
                    "abstract": "Many authors have posited a social component in citation, the consensus being that the citers and citees often have interpersonal as well as intellectual ties. Evidence for this belief has been rather meager, however, in part because social networks researchers have lacked bibliometric data (e.g., pairwise citation counts from online databases), and citation analysts have lacked sociometric data (e.g., pairwise measures of acquaintanceship). In 1997 Nazer extensively measured personal relationships and communication behaviors in what we call \"Globenet,\" an international group of 16 researchers from seven disciplines that was established in 1993 to study human development. Since Globenet's membership is known, it was possible during 2002 to obtain citation records for all members in databases of the Institute for Scientific Information. This permitted examination of how members cited each other (intercited) in journal articles over the past three decades and in a 1999 book to which they all contributed. It was also possible to explore links between the intercitation data and the social and communication data. Using network-analytic techniques, we look at the growth of intercitation over time, the extent to which it follows disciplinary or inter-disciplinary lines, whether it covaries with degrees of acquaintanceship, whether it reflects Globenet's organizational structure, whether it is associated with particular in-group communication patterns, and whether it is related to the cocitation of Globenet members. Results show cocitation to be a powerful predictor of intercitation in the journal articles, while being an editor or co-author is an important predictor in the book. Intellectualties based on shared content did better as predictors than content-neutral socialties like friendship. However, interciters in Globenet communicated more than did noninterciters.",
                    "title": "Does citation reflect social structure?: longitudinal evidence from the Globenet interdisciplinary research group",
                    "venue": "Journal of the Association for Information Science and Technology",
                    "year": 2004,
                    "__v": 2,
                    "citationCount": 50,
                    "result": 4.087552969905911
                },
                "a08549f5-fa6a-4adb-b643-714867228a0c": {
                    "authors": [
                        "Alexei Vazquez",
                        "Martin Weigt"
                    ],
                    "references": [],
                    "keyword": [
                        "networks",
                        "correlations",
                        "vertex",
                        "uncorrelated",
                        "simple",
                        "optimization",
                        "minimal",
                        "finding",
                        "degree",
                        "covers"
                    ],
                    "group": [],
                    "_id": "a08549f5-fa6a-4adb-b643-714867228a0c",
                    "abstract": "We apply a Bethe-Peierls approach to statistical-mechanics models defined on random networks of arbitrary degree distribution and arbitrary correlations between the degrees of neighboring vertices. Using the nondeterministic polynomial time hard optimization problem of finding minimal vertex covers on these graphs, we show that such correlations may lead to a qualitatively different solution structure as compared to uncorrelated networks. This results in a higher complexity of the network in a computational sense: Simple heuristic algorithms fail to find a minimal vertex cover in the highly correlated case, whereas uncorrelated networks seem to be simple from the point of view of combinatorial optimization.",
                    "title": "Computational complexity arising from degree correlations in networks",
                    "venue": "Physical Review E",
                    "year": 2003,
                    "__v": 2,
                    "citationCount": 10,
                    "result": 4.653351412948936
                },
                "a0c94b9b-d64e-40d5-ba44-4208dec791d0": {
                    "authors": [
                        "P. L. Krapivsky",
                        "Sidney Redner"
                    ],
                    "references": [
                        "7291c68d-db95-48a0-b856-6545ef18b503",
                        "9dbdc129-b8f3-4712-9c95-406bc8911bee",
                        "f15b19f2-4b37-454c-851e-a71cccf3e53a"
                    ],
                    "keyword": [
                        "distribution",
                        "network",
                        "degree",
                        "nodes",
                        "subnetworks",
                        "web",
                        "obtain",
                        "models",
                        "independent",
                        "growth"
                    ],
                    "group": [],
                    "_id": "a0c94b9b-d64e-40d5-ba44-4208dec791d0",
                    "abstract": "Approaches from statistical physics are applied to investigate the structure of network models whose growth rules mimic aspects of the evolution of the World Wide Web. We first determine the degree distribution of a growing network in which nodes are introduced one at a time and attach to an earlier node of degree k with rate Akk c . Very different behaviors arise for c   1. We also analyze the degree distribution of a heterogeneous network, the joint age-degree distribution, the correlation between degrees of neighboring nodes, as well as global network prop- erties. An extension to directed networks is then presented. By tuning model parameters to reasonable values, we obtain distinct power-law forms for the in-degree and out-degree distributions with exponents that are in good agreement with current data for the web. Finally, a general growth process with independent introduction of nodes and links is in- vestigated. This leads to independently growing sub-networks that may coalesce with other sub-networks. General results for both the size distribution of sub-networks and the degree distribution are obtained. � 2002 Elsevier Science Ltd. All rights reserved.",
                    "title": "A Statistical Physics Perspective on Web Growth",
                    "venue": "Computer Networks",
                    "year": 2002,
                    "__v": 1,
                    "citationCount": 12,
                    "result": 6.811777309377931
                },
                "a22c015f-fa44-4b73-b906-ef030405d9c9": {
                    "authors": [
                        "Petter Holme",
                        "Christofer Edling",
                        "Fredrik Liljeros"
                    ],
                    "references": [
                        "60ef3852-fa16-44bf-9434-9909268ba5d8",
                        "97c702be-2dc2-44c9-994b-3c4118d0e2e8",
                        "b0ef6e4d-4c86-4b10-9e0a-7b630ca8d7f7",
                        "c01f3bea-1bdf-4492-871b-f717731e6e0f",
                        "de4c32d2-c1ee-4056-a410-75874a0426f6"
                    ],
                    "keyword": [
                        "time",
                        "network",
                        "mixing",
                        "length",
                        "internet",
                        "geodesic",
                        "evolution",
                        "degree",
                        "community",
                        "clustering"
                    ],
                    "group": [],
                    "_id": "a22c015f-fa44-4b73-b906-ef030405d9c9",
                    "abstract": "We present statistics for the structure and time evolution of a network constructed from user activity in an Internet community. The vastness and precise time resolution of an Internet community offers unique possibilities to monitor social network formation and dynamics. Time evolution of well-known quantities, such as clustering, mixing (degree-degree correlations), average geodesic length, degree, and reciprocity is studied. In contrast to earlier analyses of scientific collaboration networks, mixing by degree between vertices is found to be disassortative. Furthermore, both the evolutionary trajectories of the average geodesic length and of the clustering coefficients are found to have minima.",
                    "title": "Structure and time evolution of an Internet dating community",
                    "venue": "Social Networks",
                    "year": 2004,
                    "__v": 2,
                    "citationCount": 66,
                    "result": 4.767020724373665
                },
                "a4a93e4a-68f2-4509-bf87-5b33122ff614": {
                    "authors": [
                        "Ricard V. Solé",
                        "Romualdo Pastor-Satorras",
                        "Eric Smith",
                        "Thomas B. Kepler"
                    ],
                    "references": [
                        "8cd37341-bb87-4e13-978a-3cc66778405e"
                    ],
                    "keyword": [
                        "proteomics",
                        "understanding",
                        "topology",
                        "observed",
                        "networks"
                    ],
                    "group": [],
                    "_id": "a4a93e4a-68f2-4509-bf87-5b33122ff614",
                    "abstract": "The next step in the understanding of the genome organization, after the determination of complete sequences, involves proteomics. The proteome includes the whole set of protein-protein interactions, and two recent independent studies have shown that its topology displays a number of surprising features shared by other complex networks, both natural and artificial. In order to understand the origins of this topology and its evolutionary implications, we present a simple model of proteome evolution that is able to reproduce many of the observed statistical regularities reported from the analysis of the yeast proteome. Our results suggest that the observed patterns can be explained by a process of gene duplication and diversification that would evolve proteome networks under a selection pressure, favoring robustness against failure of its individual components.",
                    "title": "A MODEL OF LARGE-SCALE PROTEOME EVOLUTION",
                    "venue": "Advances in Complex Systems",
                    "year": 2002,
                    "__v": 1,
                    "citationCount": 46,
                    "result": 3.523080514256985
                },
                "b407837a-0eae-4882-9a2c-2c185d5c16e0": {
                    "authors": [
                        "Béla Bollobás",
                        "Oliver Riordan",
                        "Joel Spencer",
                        "Gábor E. Tusnády"
                    ],
                    "references": [
                        "11e51e56-8f6b-4b74-89e1-879ae032b0b7",
                        "159539d4-5499-441e-837d-4178625e34dd",
                        "7192626f-12df-45f7-889d-c78e4da08773",
                        "8098554b-a355-425c-8300-4dcfe672c56d",
                        "bd34626f-94ae-46a2-8037-8c367831fa78"
                    ],
                    "keyword": [
                        "vertices",
                        "suggested",
                        "random",
                        "proportional",
                        "pd",
                        "obtained",
                        "number",
                        "graph",
                        "degrees",
                        "barabasi"
                    ],
                    "group": [],
                    "_id": "b407837a-0eae-4882-9a2c-2c185d5c16e0",
                    "abstract": "Abstract#R##N##R##N#Recently, Barabasi and Albert [2] suggested modeling complex real-world networks such as the worldwide web as follows: consider a random graph process in which vertices are added to the graph one at a time and joined to a fixed number of earlier vertices, selected with probabilities proportional to their degrees. In [2] and, with Jeong, in [3], Barabasi and Albert suggested that after many steps the proportion P(d) of vertices with degree d should obey a power law P(d)αd−γ. They obtained γ=2.9±0.1 by experiment and gave a simple heuristic argument suggesting that γ=3. Here we obtain P(d) asymptotically for all d≤n1/15, where n is the number of vertices, proving as a consequence that γ=3. © 2001 John Wiley & Sons, Inc. Random Struct. Alg., 18, 279–290, 2001",
                    "title": "The degree sequence of a scale-free random graph process",
                    "venue": "Random Structures and Algorithms",
                    "year": 2001,
                    "__v": 1,
                    "citationCount": 184,
                    "result": 4.4579563367489055
                },
                "c4716aad-c8bc-431b-8173-0300064a77b0": {
                    "authors": [
                        "Lada A. Adamic",
                        "Eytan Adar"
                    ],
                    "references": [
                        "088805a7-e9bd-41d0-987f-2c9dd5d62bdd",
                        "270c2f13-926f-4ab5-8097-9eb5d719d113",
                        "287df3fe-6f46-4071-8ab5-99274b9887b1",
                        "6e551a7c-6769-49c1-93c5-037a06f4aaef",
                        "945b87e0-f8bc-4b3e-b0cf-1edc3c3f3419",
                        "ce115523-6b89-47ad-8cf3-1cb3e2a865d3",
                        "f15b19f2-4b37-454c-851e-a71cccf3e53a"
                    ],
                    "keyword": [
                        "users",
                        "social",
                        "world",
                        "techniques",
                        "real",
                        "networks",
                        "information",
                        "indicators",
                        "factors",
                        "connections"
                    ],
                    "group": [],
                    "_id": "c4716aad-c8bc-431b-8173-0300064a77b0",
                    "abstract": "The Internet has become a rich and large repository of information about us as individuals. Anything from the links and text on a user’s homepage to the mailing lists the user subscribes to are reflections of social interactions a user has in the real world. In this paper we devise techniques and tools to mine this information in order to extract social networks and the exogenous factors underlying the networks’ structure. In an analysis of two data sets, from Stanford University and the Massachusetts Institute of Technology (MIT), we show that some factors are better indicators of social connections than others, and that these indicators vary between user populations. Our techniques provide potential applications in automatically inferring real world connections and discovering, labeling, and characterizing communities.",
                    "title": "Friends and neighbors on the Web",
                    "venue": "Social Networks",
                    "year": 2003,
                    "__v": 2,
                    "citationCount": 628,
                    "result": 6.441613735421785
                },
                "df4b8e90-b404-47f8-a384-c93aa1313694": {
                    "authors": [
                        "Filippo Menczer",
                        "Gautam Pant",
                        "Padmini Srinivasan",
                        "Miguel E. Ruiz"
                    ],
                    "references": [
                        "0895c22d-37c5-4c8f-9202-a32ebd2cb0c0",
                        "1474446b-580c-4a5d-bb69-4c228264f66e",
                        "2256cad0-cf03-42da-bcf3-4a89be0ebf8e",
                        "25f9dfdb-4cb7-4dd2-9b42-90992fd5d8b8",
                        "3f394e9d-c50a-4505-9b76-458f5e8be345",
                        "529f0775-01b2-4f1e-9d89-fc5227058019",
                        "7c18733d-45f8-4801-af64-008bdbb90406",
                        "7f9d5474-f731-4939-95e3-156e2cfc42a4",
                        "98cab4c5-36e8-408c-b37b-7095b13809ff",
                        "a677a749-cb49-4d5e-a2d8-2078230e4f88",
                        "bb74ee29-c9bd-4ed8-978c-295045e24594",
                        "c7e4e04b-45da-4bae-8c8a-d17ca0087361",
                        "cd17473b-9aec-4099-bf27-b116490b43ea",
                        "e127b1a6-04b4-4a24-9caf-59738ad3ee4b",
                        "ebbb79d0-b178-4f0e-ac58-70c9c1820390"
                    ],
                    "keyword": [
                        "crawling",
                        "web",
                        "strategies",
                        "search",
                        "page",
                        "relevance",
                        "propose",
                        "index",
                        "evaluate",
                        "engines"
                    ],
                    "group": [],
                    "_id": "df4b8e90-b404-47f8-a384-c93aa1313694",
                    "abstract": "Due to limited bandwidth, storage, and computational resources, and to the dynamic nature of the Web, search engines cannot index every Web page, and even the covered portion of the Web cannot be monitored continuously for changes.  Therefore it is essential to develop effective crawling strategies to prioritize the pages to be indexed. The issue is even more important for topic-specific search engines, where crawlers must make additional decisions based on the relevance of visited pages.  However, it is difficult to evaluate alternative crawling strategies because relevant sets are unknown and the search space is changing.  We propose three different methods to evaluate crawling strategies.  We apply the proposed metrics to compare three topic-driven crawling algorithms based on similarity ranking, link analysis, and adaptive agents.",
                    "title": "Evaluating topic-driven web crawlers",
                    "venue": "international acm sigir conference on research and development in information retrieval",
                    "year": 2001,
                    "__v": 2,
                    "citationCount": 96,
                    "result": 4.763609429785901
                }
            }
        ],
        "_id": "b0ef6e4d-4c86-4b10-9e0a-7b630ca8d7f7",
        "abstract": "Inspired by empirical studies of networked systems such as the Internet, social networks, and biological networks, researchers have in recent years developed a variety of techniques and models to help us understand or predict the behavior of these systems. Here we review developments in this field, including such concepts as the small-world effect, degree distributions, clustering, network correlations, random graph models, models of network growth and preferential attachment, and dynamical processes taking place on networks.",
        "title": "The Structure and Function of Complex Networks",
        "venue": "Siam Review",
        "year": 2003,
        "__v": 3,
        "citationCount": 3109
    },
    {
        "authors": [
            "Andrew Sendonaris",
            "Elza Erkip",
            "Behnaam Aazhang"
        ],
        "references": [
            "2861a324-b628-4668-96be-143b94b5e938",
            "2898d033-bbfd-49c8-ba3a-b15187e815fe",
            "4296a611-0cd3-4c26-9229-22b591d59028",
            "51bc0d88-d328-4d53-9340-00aa948cf11d",
            "73fec0bf-70f7-4eec-aac4-9c22f48cded5",
            "748a2ab3-8b5f-4d0a-9e2d-af685089843a",
            "93ae61c8-57f9-452e-a7b3-83aa1cdd1be4",
            "e0bcaa03-f72d-400b-89eb-97f17b5f0693",
            "e7ce6f9e-715f-4f6c-b7cb-c26cd42ca188",
            "efcbfcea-e8b0-4ca9-a883-92f42f862307"
        ],
        "keyword": [
            "users'",
            "diversity",
            "cooperation",
            "variations",
            "rate",
            "part",
            "mobile",
            "channel",
            "achieved"
        ],
        "group": [
            {
                "51bc0d88-d328-4d53-9340-00aa948cf11d": {
                    "authors": [
                        "Chao-Ming Zeng",
                        "Federico Kuhlmann",
                        "Andres Buzo"
                    ],
                    "references": [
                        "6b638ffe-e01f-498a-a381-7fe9e33e3698",
                        "850e2885-2353-4f5f-b1fd-632c68317493",
                        "8854882a-40a7-4059-9db4-862cf68f25a7",
                        "cac3fc3f-ffc3-4b8f-a77d-078358ea6e4c",
                        "cdd26d4b-3066-4e76-918e-5b11d5d39680",
                        "e0bcaa03-f72d-400b-89eb-97f17b5f0693",
                        "e7ce6f9e-715f-4f6c-b7cb-c26cd42ca188",
                        "efcbfcea-e8b0-4ca9-a883-92f42f862307",
                        "f4ac49a9-4dd2-49a8-8e4b-07c41f76b465"
                    ],
                    "keyword": [
                        "presented",
                        "mac",
                        "feedback",
                        "channel",
                        "wellknown",
                        "theorems",
                        "technique",
                        "simpler",
                        "signals",
                        "relay"
                    ],
                    "group": [],
                    "_id": "51bc0d88-d328-4d53-9340-00aa948cf11d",
                    "abstract": "New and simpler achievability proofs that are based on the backward decoding technique are presented for the well-known coding theorems for the multiple-access channel (MAC) with perfect feedback and the degraded relay channel. A class of MACs with different generalized feedback signals is also considered, and achievable-rate regions that are larger than those previously presented in the literature are established. >",
                    "title": "Achievability proof of some multiuser channel coding theorems using backward decoding",
                    "venue": "IEEE Transactions on Information Theory",
                    "year": 1989,
                    "__v": 1,
                    "citationCount": 28,
                    "result": 6.848853923853923
                },
                "73fec0bf-70f7-4eec-aac4-9c22f48cded5": {
                    "authors": [
                        "Andrew Sendonaris",
                        "Elza Erkip",
                        "Behnaam Aazhang"
                    ],
                    "references": [
                        "2898d033-bbfd-49c8-ba3a-b15187e815fe",
                        "748a2ab3-8b5f-4d0a-9e2d-af685089843a",
                        "b22134b3-2419-4d39-b6b8-d7ad60abac26"
                    ],
                    "keyword": [
                        "cooperation",
                        "part",
                        "implementation",
                        "cdma",
                        "users",
                        "system",
                        "strategy",
                        "proposed",
                        "investigates",
                        "diversity"
                    ],
                    "group": [],
                    "_id": "73fec0bf-70f7-4eec-aac4-9c22f48cded5",
                    "abstract": "For pt.I see ibid., p.1927-38. This is the second of a two-part paper on a new form of spatial diversity, where diversity gains are achieved through the cooperation of mobile users. Part I described the user cooperation concept and proposed a cooperation strategy for a conventional code-division multiple-access (CDMA) system. Part II investigates the cooperation concept further and considers practical issues related to its implementation. In particular, we investigate the optimal and suboptimal receiver design, and present performance analysis for the conventional CDMA implementation proposed in Part I. We also consider a high-rate CDMA implementation and a cooperation strategy when assumptions about the channel state information at the transmitters are relaxed. We illustrate that, under all scenarios studied, cooperation is beneficial in terms of increasing system throughput and cell coverage, as well as decreasing sensitivity to channel variations.",
                    "title": "User cooperation diversity. Part II. Implementation aspects and performance analysis",
                    "venue": "IEEE Transactions on Communications",
                    "year": 2003,
                    "__v": 2,
                    "citationCount": 1300,
                    "result": 11.5346754604932
                },
                "748a2ab3-8b5f-4d0a-9e2d-af685089843a": {
                    "authors": [
                        "Emre Telatar"
                    ],
                    "references": [
                        "52787900-26ba-4272-9e1f-42d9fd36943b",
                        "68198b02-3da0-4565-a176-9d29195b4313"
                    ],
                    "keyword": [
                        "systems",
                        "receiving",
                        "formulas",
                        "fading",
                        "channel",
                        "antennas",
                        "user",
                        "transmitting",
                        "singleantenna",
                        "single"
                    ],
                    "group": [],
                    "_id": "748a2ab3-8b5f-4d0a-9e2d-af685089843a",
                    "abstract": "Abstract#R##N##R##N#We investigate the use of multiple transmitting and/or receiving antennas for single user communications over the additive Gaussian channel with and without fading. We derive formulas for the capacities and error exponents of such channels, and describe computational procedures to evaluate such formulas. We show that the potential gains of such multi-antenna systems over single-antenna systems is rather large under independenceassumptions for the fades and noises at different receiving antennas.",
                    "title": "Capacity of multi-antenna Gaussian channels",
                    "venue": "European Transactions on Telecommunications",
                    "year": 1999,
                    "__v": 2,
                    "citationCount": 5059,
                    "result": 4.931563491548012
                },
                "93ae61c8-57f9-452e-a7b3-83aa1cdd1be4": {
                    "authors": [
                        "Frans M. J. Willems"
                    ],
                    "references": [
                        "6b638ffe-e01f-498a-a381-7fe9e33e3698"
                    ],
                    "keyword": [
                        "encoders",
                        "communication",
                        "partially",
                        "multiple",
                        "give",
                        "cooperating",
                        "conference",
                        "channel",
                        "capacities",
                        "access"
                    ],
                    "group": [],
                    "_id": "93ae61c8-57f9-452e-a7b3-83aa1cdd1be4",
                    "abstract": "We introduce the communication situation in which the encoders of a multiple access channel are partially cooperating. These encoders are connected by communication links with finite capacities, which permit both encoders to communicate with each other. First we give a general definition of such a communication process (conference). Then, by proving a converse and giving an achievability proof, we establish the capacity region of the multiple access channel with partially cooperating encoders. It turns out that the optimal conference is very simple.",
                    "title": "The discrete memoryless multiple access channel with partially cooperating encoders (Corresp.)",
                    "venue": "IEEE Transactions on Information Theory",
                    "year": 1983,
                    "__v": 1,
                    "citationCount": 137,
                    "result": 8.107850878052115
                },
                "e0bcaa03-f72d-400b-89eb-97f17b5f0693": {
                    "authors": [
                        "Thomas M. Cover",
                        "Cyril Leung"
                    ],
                    "references": [
                        "6b638ffe-e01f-498a-a381-7fe9e33e3698",
                        "850e2885-2353-4f5f-b1fd-632c68317493",
                        "f1b53f72-b185-4e4e-9b75-ebc637857809"
                    ],
                    "keyword": [
                        "rate",
                        "region",
                        "information",
                        "feedback",
                        "achievable",
                        "transmitters",
                        "leq",
                        "x2",
                        "transmissions",
                        "time"
                    ],
                    "group": [],
                    "_id": "e0bcaa03-f72d-400b-89eb-97f17b5f0693",
                    "abstract": "An achievable rate region R_{1} \\leq I(X_{1};Y|X_{2},U), R_{2} \\leq I(X_{2}; Y|X_{1},U), R_{1}+R_{2} \\leq I(X_{1}, X_{2};Y) , where p(u,x_{l},x_{2},y)= p(u)p(x_{l}|u)p(x_{2}|u)p(y|x_{l},x_{2}) , is established for the multiple-access channel with feedback. Time sharing of these achievable rates yields the rate region of this paper. This region generally exceeds the achievable rate region without feedback and exceeds the rate point found by Gaarder and Wolf for the binary erasure multiple-access channel with feedback. The presence of feedback allows the independent transmitters to understand each other's intended transmissions before the receiver has sufficient information to achieve the desired decoding. This allows the transmitters to cooperate in the transmission of information that resolves the residual uncertainty of the receiver. At the same time, independent information from the transmitters is superimposed on the cooperative correction information. The proof involves list codes and block Markov encoding.",
                    "title": "An achievable rate region for the multiple-access channel with feedback",
                    "venue": "IEEE Transactions on Information Theory",
                    "year": 1981,
                    "__v": 2,
                    "citationCount": 112,
                    "result": 7.068394702992226
                },
                "e7ce6f9e-715f-4f6c-b7cb-c26cd42ca188": {
                    "authors": [
                        "Frans M. J. Willems",
                        "E.C. van der Meulen"
                    ],
                    "references": [
                        "6b638ffe-e01f-498a-a381-7fe9e33e3698",
                        "848461ba-2db6-47b3-9bdc-e9e40d882aea",
                        "850e2885-2353-4f5f-b1fd-632c68317493",
                        "8854882a-40a7-4059-9db4-862cf68f25a7",
                        "b6f6073b-c30d-48c6-89ab-67f6571599b7",
                        "c885e4cf-37b0-43ea-b2a2-c836eddeff8a",
                        "cac3fc3f-ffc3-4b8f-a77d-078358ea6e4c",
                        "cdd26d4b-3066-4e76-918e-5b11d5d39680",
                        "e0bcaa03-f72d-400b-89eb-97f17b5f0693",
                        "efcbfcea-e8b0-4ca9-a883-92f42f862307"
                    ],
                    "keyword": [
                        "encoders",
                        "situations",
                        "regions",
                        "decoding",
                        "channel",
                        "capacity",
                        "achievability",
                        "total",
                        "strategies",
                        "shannon"
                    ],
                    "group": [],
                    "_id": "e7ce6f9e-715f-4f6c-b7cb-c26cd42ca188",
                    "abstract": "The capacity regions are determined for various communication situations in which one or both encoders for a multiple access channel crib from the other encoder and learn the channel input(s) (to be) emitted by this encoder. Most of the achievability proofs in this paper hinge upon the new concept of backward decoding. Also, the notion of Shannon strategies seems to be of crucial importance. It is demonstrated that in some situations parts of the total cooperation line are achievable. Moreover, it is proved that if the encoders and the decoder are allowed to be nondeterministic, the capacity regions are not increased.",
                    "title": "The discrete memoryless multiple-access channel with cribbing encoders",
                    "venue": "IEEE Transactions on Information Theory",
                    "year": 1985,
                    "__v": 2,
                    "citationCount": 114,
                    "result": 9.751143318325981
                }
            }
        ],
        "_id": "b22134b3-2419-4d39-b6b8-d7ad60abac26",
        "abstract": "Mobile users' data rate and quality of service are limited by the fact that, within the duration of any given call, they experience severe variations in signal attenuation, thereby necessitating the use of some type of diversity. In this two-part paper, we propose a new form of spatial diversity, in which diversity gains are achieved via the cooperation of mobile users. Part I describes the user cooperation strategy, while Part II (see ibid., p.1939-48) focuses on implementation issues and performance analysis. Results show that, even though the interuser channel is noisy, cooperation leads not only to an increase in capacity for both users but also to a more robust system, where users' achievable rates are less susceptible to channel variations.",
        "title": "User cooperation diversity. Part I. System description",
        "venue": "IEEE Transactions on Communications",
        "year": 2003,
        "__v": 3,
        "citationCount": 3364
    },
    {
        "authors": [
            "David G. Lowe"
        ],
        "references": [
            "00a4e16f-6b65-4ad2-bedc-b19d9cbc2cfe",
            "01a0f825-a308-455b-93fc-e62defc0e3b0",
            "035f8537-61a7-4c4f-b9fe-120f913a38b0",
            "03a42efa-a19c-4b19-a881-9c7ff63865ce",
            "05c3e696-6add-4b0d-b867-e6f1c98deb9b",
            "2fa2e5ba-11d3-4691-91e1-807b8ef7d8a5",
            "32d9eaee-c68f-4479-aa67-837d3cc91a05",
            "34758e0a-3def-447b-9c5e-e82a206426b5",
            "5437c0a0-8f20-49c3-86e5-9d860f3e4f04",
            "5dcd5949-faa9-4af3-8c6f-b285dd3b6566",
            "5f1992df-975f-49e7-bd88-aee0740317cf",
            "5f84f09f-7644-447c-89e1-8dc9ee334197",
            "6018a516-8149-4bce-bc33-5449d86e58c2",
            "60285266-7da2-474e-b05a-b380c836f665",
            "768eea6d-8e82-4bbf-8bdd-1f2338ded29f",
            "791e9257-d7a0-41fe-b471-bde48f3c4a04",
            "7ab7b36d-baae-4b21-89fc-69389fcabc44",
            "7b3f5f5b-a965-4656-9a6f-2f9740625176",
            "899de8c7-9cd9-4dd5-82f1-ad9acb801f8e",
            "a00704dc-a2fa-4267-b7a6-427167d99521",
            "a0fa7ae2-61e5-48a9-be10-86440416129f",
            "a748e0f4-ee6f-41ad-a2a5-1a5a6751086d",
            "b3e60214-b54c-4e8f-9315-a6975c760f4c",
            "b4685927-0ad9-466b-b2c6-2e1764475726",
            "c455fb04-4566-4648-ad6f-3cf2245e507c",
            "ccdefe89-9b16-4c22-8bb8-bd314ccad6e1",
            "d20995f6-529c-41c6-b75e-a169b005fb5c",
            "d9b9f667-9d8a-4723-a6c4-c19b941acd46",
            "df9fe96c-752e-49be-a8c4-8b098ab51e22",
            "ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d",
            "f6272ea9-0360-47ed-90a5-651ea958143f"
        ],
        "keyword": [
            "features",
            "object",
            "matching",
            "recognition",
            "perform",
            "images",
            "single",
            "robust",
            "paper",
            "invariant"
        ],
        "group": [
            {
                "5437c0a0-8f20-49c3-86e5-9d860f3e4f04": {
                    "authors": [
                        "Sunil Arya",
                        "David M. Mount",
                        "Nathan S. Netanyahu",
                        "Ruth Silverman",
                        "Angela Y. Wu"
                    ],
                    "references": [
                        "0d41d9b5-6e7d-476e-a484-36758a6b209a",
                        "0f094852-0668-4dfe-92cc-ae5659ffc1d9",
                        "12196e53-1567-458b-9d49-6a66fd6e6adf",
                        "1333cbbd-dbc1-457f-a16d-bd057c347156",
                        "1c7f6b4c-ea89-45d4-9778-8d64987f8a0f",
                        "2713ce7e-3ad8-4654-90db-2a035d588713",
                        "413a659f-2cb8-4ae5-89b5-5f773685c82f",
                        "4279b898-2775-4f22-bdf8-f289d54b4867",
                        "43dfd110-6a4d-4463-838a-dad26db1b846",
                        "485d6dc2-0ef4-4955-875b-c245a131a6a9",
                        "4ca9b504-fdf7-4963-89a1-170608086f35",
                        "510eec1d-f82c-4b19-b116-b8fd4c66531a",
                        "5660105d-43ae-4091-a6b7-380dc22cd9b5",
                        "5880d47f-8b99-416d-a743-28d6b49f7ba9",
                        "593a7087-a716-40ee-af9f-caa3d41a1b6e",
                        "5ce1553b-2b02-4469-ae72-04a31418fc52",
                        "6b32b11e-238f-4500-b513-ccd53424637a",
                        "71e7d436-a839-4f9d-ad70-d9faf15e8034",
                        "768eea6d-8e82-4bbf-8bdd-1f2338ded29f",
                        "76c004a0-487a-4313-a344-fc4a299e4b66",
                        "7850841f-2874-48cc-aa4e-83ca63f77aeb",
                        "7de3ee18-6bc8-42b2-98d0-745e02c372c1",
                        "8b4e6725-0e70-4801-9ce5-78fab6158fbc",
                        "8fda0651-1e04-4439-afb0-e8e7e5ae8072",
                        "a0304326-321c-49c0-843e-6ad5ea9f5815",
                        "a6d1807f-6c63-470e-8767-31a9f14f3962",
                        "aa5afbbc-13b9-4685-bc36-5f7f06d8d2a4",
                        "adf6fdf9-01a0-4051-9d99-965f4a5baa4d",
                        "af6ea43b-eb0f-4aa5-aeb3-e6e435e43263",
                        "b546dd1a-7e2d-4527-ba3c-2e6ce5e0a405",
                        "b7e8c571-d956-4072-b028-754dc40a0e56",
                        "be9cbf3c-2975-4226-b6b9-3d4b4ebe8a66",
                        "c8dad09e-e7b4-4a2d-b4b3-0ea3cd49ac52",
                        "ce05fc9f-0abd-4843-8d77-ceb4ce9a6ebf",
                        "d11d6520-e64b-4a9b-abc9-3729ab6ca8e7",
                        "d20995f6-529c-41c6-b75e-a169b005fb5c",
                        "d6ffd0e7-61aa-4dea-9fe0-4345e2382e96",
                        "da4e248d-7eec-4400-a0e7-97ab5d4b3698",
                        "ea3dd2d7-2031-4938-b8b9-495eba8886a8",
                        "f6272ea9-0360-47ed-90a5-651ea958143f"
                    ],
                    "keyword": [
                        "points",
                        "neighbor",
                        "nearest",
                        "time",
                        "log",
                        "distances",
                        "data",
                        "space",
                        "show",
                        "set"
                    ],
                    "group": [],
                    "_id": "5437c0a0-8f20-49c3-86e5-9d860f3e4f04",
                    "abstract": "Consider a set of  S  of  n  data points  in real  d -dimensional space, R d , where distances are measured using any Minkowski metric. In nearest neighbor searching, we preprocess  S  into a data structure, so that given any query point  q    ∈   R d , is the closest point of S to  q  can be reported quickly. Given any positive real e, data point  p  is a (1 +e)- approximate nearest neighbor  of  q  if its distance from  q  is within a factor of (1 + e) of the distance to the true nearest neighbor. We show that it is possible to preprocess a    set of  n  points in     R d  in  O(dn  log  n ) time and  O(dn)  space, so that given a query point   q     ∈   R d , and e > 0, a (1 + e)-approximate nearest neighbor of  q  can be computed in  O ( c   d , e  log  n ) time, where  c d,e  ≤ d      1 + 6d/ e     ; d  is a factor depending only on dimension and e. In general, we show that given an integer  k  ≥ 1, (1 + e)-approximations  to the   k  nearest neighbors of  q  can  be computed in additional  O(kd  log  n ) time.",
                    "title": "An optimal algorithm for approximate nearest neighbor searching fixed dimensions",
                    "venue": "Journal of the ACM",
                    "year": 1998,
                    "__v": 1,
                    "citationCount": 928,
                    "result": 4.675517493259429
                },
                "5dcd5949-faa9-4af3-8c6f-b285dd3b6566": {
                    "authors": [
                        "Zhengyou Zhang",
                        "Rachid Deriche",
                        "Olivier D. Faugeras",
                        "Quang-Tuan Luong"
                    ],
                    "references": [
                        "04e444f3-d7b6-4925-b3dc-0b2d3b0e88a7",
                        "17b297e4-894c-4b2f-a51b-984a7e14b5bf",
                        "1f47e848-ab80-41af-88b1-b58dae33ea77",
                        "2558c1e5-b937-4d00-a701-493a943e9e87",
                        "257b1c21-a457-4fdc-abca-01eb086b73d5",
                        "34758e0a-3def-447b-9c5e-e82a206426b5",
                        "3dc04fea-4389-4694-87bc-b373401cb9eb",
                        "41c0cec5-a359-4e75-aa81-674711d27cae",
                        "427a47f2-3358-41ee-9ff8-c288b1cd0229",
                        "4e0d86d9-4ca3-43e4-b5dd-a463ed10134b",
                        "585db1b6-f97b-4b90-a113-a75ea1b6f5af",
                        "5881c5b2-527b-48e5-a4d4-eaeeab3ca9cb",
                        "5d2e7673-8c8f-411c-a7a9-ebb771cdf453",
                        "643913d9-b72a-4ee3-9c3f-63c1249e9a3c",
                        "6a9dfcc3-8914-4ca3-ab60-5ca5fea44d5a",
                        "6e9685ed-b10d-4023-be53-ceab0010381c",
                        "723c19d5-eb5e-41b9-b2fa-e4d881f0fb55",
                        "7244c693-319b-4d19-af18-954123baad88",
                        "79033374-75da-4895-9797-1ad232675f10",
                        "79050acb-3012-4d4b-af60-66040a28043d",
                        "873c1c6b-ef62-4731-8d1d-e2a9cff16fd2",
                        "af7e4274-dbfc-4fd3-a59c-35f56b2cd7cc",
                        "b3b5b1d4-64d9-42b5-98ba-a28b13524465",
                        "b4c0a22e-7fa3-4536-b4c2-b010364356b1",
                        "b66d9f28-7f97-436b-a6f3-1a466a6435a9",
                        "bcf3e7a6-dc04-4f23-906f-0824bd184d2f",
                        "c4560fa0-1209-49a3-a574-b231f2e68c50",
                        "c5df7d5d-c642-4943-9b2b-f26b735eb345",
                        "e389fa97-0461-4d42-876f-31d67c0690ca",
                        "e4879a25-d620-45a1-94f3-dc4311d510c7",
                        "e7fc1e96-b55a-435a-ab64-f114ad6974cd",
                        "f3bc4642-9164-4a05-84b6-b4a57e374720",
                        "f7037864-4b92-437b-a90e-509d4ec350c8"
                    ],
                    "keyword": [
                        "matching",
                        "image",
                        "epipolar",
                        "geometry",
                        "camera"
                    ],
                    "group": [],
                    "_id": "5dcd5949-faa9-4af3-8c6f-b285dd3b6566",
                    "abstract": "Copyright (c) 1996 Elsevier Science B.V. All rights reserved. This paper proposes a robust approach to image matching by exploiting the only available geometric constraint, namely, the epipolar constraint. The images are uncalibrated, namely the motion between them and the camera parameters are not known. Thus, the images can be taken by different cameras or a single camera at different time instants. If we make an exhaustive search for the epipolar geometry, the complexity is prohibitively high. The idea underlying our approach is to use classical techniques (correlation and relaxation methods in our particular implementation) to find an initial set of matches, and then use a robust techniquemthe Least Median of Squares (LMedS)mto discard false matches in this set. The epipolar geometry can then be accurately estimated using a meaningful image criterion. More matches are eventually found, as in stereo matching, by using the recovered epipolar geometry. A large number of experiments have been carried out, and very good results have been obtained.Regarding the relaxation technique, we define a new measure of matching support, which allows a higher tolerance to deformation with respect to rigid transformations in the image plane and a smaller contribution for distant matches than for nearby ones. A new strategy for updating matches is developed, which only selects those matches having both high matching support and low matching ambiguity. The update strategy is different from the classical winner-take-all , which is easily stuck at a local minimum, and also from loser-take-nothing , which is usually very slow. The proposed algorithm has been widely tested and works remarkably well in a scene with many repetitive patterns.",
                    "title": "A robust technique for matching two uncalibrated images through the recovery of the unknown epipolar geometry",
                    "venue": "Artificial Intelligence",
                    "year": 1995,
                    "__v": 1,
                    "citationCount": 627,
                    "result": 3.8735185960992413
                },
                "5f1992df-975f-49e7-bd88-aee0740317cf": {
                    "authors": [
                        "Cordelia Schmid",
                        "Roger Mohr"
                    ],
                    "references": [
                        "00909251-9935-44f3-94a1-629023b5015b",
                        "2fa2e5ba-11d3-4691-91e1-807b8ef7d8a5",
                        "34758e0a-3def-447b-9c5e-e82a206426b5",
                        "3bb5658b-131c-4072-9f9c-5f18a8272054",
                        "46da0145-fc17-4096-9624-4828cb32e116",
                        "4ea088d2-1d7e-433e-87ca-f31ad9b1e322",
                        "5dcd5949-faa9-4af3-8c6f-b285dd3b6566",
                        "5ebbd1f5-dfe5-4eec-9883-b8b5efea366c",
                        "643913d9-b72a-4ee3-9c3f-63c1249e9a3c",
                        "774c108a-4002-4123-861f-edd3b7ccb0e7",
                        "79bd9613-8976-41a1-b0b7-133b80b8477e",
                        "7a624075-0930-4956-8d8c-2910a80bdbca",
                        "7d5e97d2-5ebe-4be2-ac67-3c15fcde2c8d",
                        "8ec028ec-a8d0-4963-9e6f-231f0d6104ed",
                        "92551b72-99c5-4882-801c-a419e4eb705e",
                        "a8c76816-3583-47e8-98e1-18db34cb5b67",
                        "c083f584-daa0-4058-9a89-6b03409acfef",
                        "c38cebd1-1503-4321-ab02-28712487b9d3",
                        "c39c2ff9-1401-474d-917e-3776f528b204",
                        "d9b9f667-9d8a-4723-a6c4-c19b941acd46",
                        "dda837ee-640b-48b1-bb19-a00c5894f003"
                    ],
                    "keyword": [
                        "retrieving",
                        "images",
                        "databases",
                        "voting",
                        "visibility",
                        "transformations",
                        "small",
                        "similarity",
                        "show",
                        "semilocal"
                    ],
                    "group": [],
                    "_id": "5f1992df-975f-49e7-bd88-aee0740317cf",
                    "abstract": "This paper addresses the problem of retrieving images from large image databases. The method is based on local grayvalue invariants which are computed at automatically detected interest points. A voting algorithm and semilocal constraints make retrieval possible. Indexing allows for efficient retrieval from a database of more than 1,000 images. Experimental results show correct retrieval in the case of partial visibility, similarity transformations, extraneous features, and small perspective deformations.",
                    "title": "Local grayvalue invariants for image retrieval",
                    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "year": 1997,
                    "__v": 2,
                    "citationCount": 720,
                    "result": 7.50960525016003
                },
                "5f84f09f-7644-447c-89e1-8dc9ee334197": {
                    "authors": [
                        "Matthew A. Brown",
                        "David G. Lowe"
                    ],
                    "references": [
                        "16d59a75-441a-440d-963d-5a283c15ccff",
                        "27dfa95c-90d4-4d56-b987-0d2721b4b9b0",
                        "2d6c9f60-ea78-44a8-b5f9-6964575dd196",
                        "33711daf-2a44-4f42-8466-c7801f29959b",
                        "509e1ae2-768b-4417-bebe-d90cf1e0fdae",
                        "5149d3c0-5ac9-47ba-9fb0-3d2ef757b0e8",
                        "5dcd5949-faa9-4af3-8c6f-b285dd3b6566",
                        "5f1992df-975f-49e7-bd88-aee0740317cf",
                        "6018a516-8149-4bce-bc33-5449d86e58c2",
                        "8ac30372-c1ac-48bc-8370-cc550fc41d91",
                        "e46bb6ea-7b67-4edf-8cd4-a51ce64cff19"
                    ],
                    "keyword": [
                        "matching",
                        "images",
                        "points'",
                        "interest",
                        "form",
                        "features",
                        "descriptors",
                        "work",
                        "robustly",
                        "reject"
                    ],
                    "group": [],
                    "_id": "5f84f09f-7644-447c-89e1-8dc9ee334197",
                    "abstract": "This paper approaches the problem of ¯nding correspondences between images in which there are large changes in viewpoint, scale and illumi- nation. Recent work has shown that scale-space `interest points' may be found with good repeatability in spite of such changes. Further- more, the high entropy of the surrounding image regions means that local descriptors are highly discriminative for matching. For descrip- tors at interest points to be robustly matched between images, they must be as far as possible invariant to the imaging process. In this work we introduce a family of features which use groups of interest points to form geometrically invariant descriptors of image regions. Feature descriptors are formed by resampling the image rel- ative to canonical frames de¯ned by the points. In addition to robust matching, a key advantage of this approach is that each match implies a hypothesis of the local 2D (projective) transformation. This allows us to immediately reject most of the false matches using a Hough trans- form. We reject remaining outliers using RANSAC and the epipolar constraint. Results show that dense feature matching can be achieved in a few seconds of computation on 1GHz Pentium III machines.",
                    "title": "Invariant Features from Interest Point Groups",
                    "venue": "british machine vision conference",
                    "year": 2002,
                    "__v": 1,
                    "citationCount": 174,
                    "result": 11.183678449949799
                },
                "6018a516-8149-4bce-bc33-5449d86e58c2": {
                    "authors": [
                        "David G. Lowe"
                    ],
                    "references": [
                        "01a0f825-a308-455b-93fc-e62defc0e3b0",
                        "035f8537-61a7-4c4f-b9fe-120f913a38b0",
                        "5dcd5949-faa9-4af3-8c6f-b285dd3b6566",
                        "5ebbd1f5-dfe5-4eec-9883-b8b5efea366c",
                        "5f1992df-975f-49e7-bd88-aee0740317cf",
                        "78dd7c1a-bc00-4993-bd41-8e5da9a7fe5b",
                        "8678514b-e795-4972-b891-c0d31d0d46cf",
                        "899de8c7-9cd9-4dd5-82f1-ad9acb801f8e",
                        "92551b72-99c5-4882-801c-a419e4eb705e",
                        "a00704dc-a2fa-4267-b7a6-427167d99521",
                        "caeecc11-ec92-47d8-b112-c43b88dd4491",
                        "e46bb6ea-7b67-4edf-8cd4-a51ce64cff19",
                        "ee11b7f0-4aeb-4e0f-a808-2126f1590163"
                    ],
                    "keyword": [
                        "image",
                        "object",
                        "features",
                        "scaling",
                        "recognition",
                        "partially",
                        "multiple",
                        "matches",
                        "local",
                        "keys"
                    ],
                    "group": [],
                    "_id": "6018a516-8149-4bce-bc33-5449d86e58c2",
                    "abstract": "An object recognition system has been developed that uses a new class of local image features. The features are invariant to image scaling, translation, and rotation, and partially invariant to illumination changes and affine or 3D projection. These features share similar properties with neurons in inferior temporal cortex that are used for object recognition in primate vision. Features are efficiently detected through a staged filtering approach that identifies stable points in scale space. Image keys are created that allow for local geometric deformations by representing blurred image gradients in multiple orientation planes and at multiple scales. The keys are used as input to a nearest neighbor indexing method that identifies candidate object matches. Final verification of each match is achieved by finding a low residual least squares solution for the unknown model parameters. Experimental results show that robust object recognition can be achieved in cluttered partially occluded images with a computation time of under 2 seconds.",
                    "title": "Object recognition from local scale-invariant features",
                    "venue": "international conference on computer vision",
                    "year": 1999,
                    "__v": 2,
                    "citationCount": 4272,
                    "result": 9.93066613967942
                },
                "60285266-7da2-474e-b05a-b380c836f665": {
                    "authors": [
                        "Jiri Matas",
                        "Ondrej Chum",
                        "M. Urban",
                        "Tomas Pajdla"
                    ],
                    "references": [
                        "1dc84769-ff4c-4de6-a1c9-8d3af9299701",
                        "2beaa150-6293-4f05-ba04-8e001993e766",
                        "509e1ae2-768b-4417-bebe-d90cf1e0fdae",
                        "5f1992df-975f-49e7-bd88-aee0740317cf",
                        "5fadd790-4d5c-4a63-9d0c-39661713cf69",
                        "6018a516-8149-4bce-bc33-5449d86e58c2",
                        "63dbad19-24d8-4646-8e6a-65d85a5c2af3",
                        "7a9f04e3-2883-4204-8fb3-7db1ce5ddc09",
                        "7ab7b36d-baae-4b21-89fc-69389fcabc44",
                        "8f9d2434-c08a-43e5-8152-d41f2784ddc2",
                        "a0be9da4-c423-4f87-a387-822fe304aa03",
                        "beb947f3-b954-4bb9-8379-e33474f07c6d",
                        "ceb9e934-951e-47d6-a256-9ed1bb44b4b6",
                        "e86ce68d-0d77-4f44-a212-518e7d8f394b",
                        "ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d"
                    ],
                    "keyword": [
                        "regions",
                        "images",
                        "extremal",
                        "correspondences",
                        "robust",
                        "problem",
                        "mser",
                        "measure",
                        "invariant",
                        "establishing"
                    ],
                    "group": [],
                    "_id": "60285266-7da2-474e-b05a-b380c836f665",
                    "abstract": "The wide-baseline stereo problem, i.e. the problem of establishing correspondences between a pair of images taken from different viewpoints is studied.#R##N##R##N#A new set of image elements that are put into correspondence, the so called extremal regions, is introduced. Extremal regions possess highly desirable properties: the set is closed under (1) continuous (and thus projective) transformation of image coordinates and (2) monotonic transformation of image intensities. An efficient (near linear complexity) and practically fast detection algorithm (near frame rate) is presented for an affinely invariant stable subset of extremal regions, the maximally stable extremal regions (MSER).#R##N##R##N#A new robust similarity measure for establishing tentative correspondences is proposed. The robustness ensures that invariants from multiple measurement regions (regions obtained by invariant constructions from extremal regions), some that are significantly larger (and hence discriminative) than the MSERs, may be used to establish tentative correspondences.#R##N##R##N#The high utility of MSERs, multiple measurement regions and the robust metric is demonstrated in wide-baseline experiments on image pairs from both indoor and outdoor scenes. Significant change of scale (3.5×), illumination conditions, out-of-plane rotation, occlusion, locally anisotropic scale change and 3D translation of the viewpoint are all present in the test problems. Good estimates of epipolar geometry (average distance from corresponding points to the epipolar line below 0.09 of the inter-pixel distance) are obtained.",
                    "title": "Robust wide-baseline stereo from maximally stable extremal regions",
                    "venue": "Image and Vision Computing",
                    "year": 2004,
                    "__v": 2,
                    "citationCount": 1575,
                    "result": 9.726904213666424
                },
                "791e9257-d7a0-41fe-b471-bde48f3c4a04": {
                    "authors": [
                        "David Pritchard",
                        "Wolfgang Heidrich"
                    ],
                    "references": [
                        "01a0f825-a308-455b-93fc-e62defc0e3b0",
                        "02cb51dd-4a5e-4057-919e-0856f08f9f82",
                        "1f520d1a-5870-477d-85d7-0f50be690ea7",
                        "32d9eaee-c68f-4479-aa67-837d3cc91a05",
                        "352924a1-d9a9-48de-bf81-08a2a29f3a6b",
                        "52d886bb-c79f-4ab1-b85d-82a9c15a23b5",
                        "5a7a71af-40fe-49ee-bd7d-a84dfb82d976",
                        "5c4bc08d-02e3-4ebf-a5cb-125a43dbfad1",
                        "6018a516-8149-4bce-bc33-5449d86e58c2",
                        "afcc6115-bd49-4456-9320-24e5b5075b8b",
                        "de2cff8e-177b-49db-8194-2569d3e4e5f1",
                        "f0aaac0e-4386-4f04-86b5-71853bc88b97"
                    ],
                    "keyword": [
                        "geometry",
                        "systems",
                        "motion",
                        "sift",
                        "parameterisation",
                        "feature",
                        "deformable",
                        "cloth",
                        "capture"
                    ],
                    "group": [],
                    "_id": "791e9257-d7a0-41fe-b471-bde48f3c4a04",
                    "abstract": "Recent years have seen an increased interest in motion capture systems. Current systems, however, are limited to only a few degrees of freedom, so that effectively only the motion of linked rigid bodies can be acquired. We present a system for the capture of deformable surfaces, most notably moving cloth, including both geometry and parameterisation. We recover geometry using stereo correspondence, and use the Scale Invariant Feature Transform (SIFT) to identify an arbitrary pattern printed on the cloth, even in the presence of fast motion. We describe a novel seed-and-grow approach to adapt the SIFT algorithm to deformable geometry. Finally, we interpolate feature points to parameterise the complete geometry.",
                    "title": "Cloth motion capture",
                    "venue": "international conference on computer graphics and interactive techniques",
                    "year": 2003,
                    "__v": 1,
                    "citationCount": 11,
                    "result": 5.6668982444685545
                },
                "7b3f5f5b-a965-4656-9a6f-2f9740625176": {
                    "authors": [
                        "Ali Shokoufandeh",
                        "Ivan Marsic",
                        "Sven J. Dickinson"
                    ],
                    "references": [
                        "27c3c741-4f38-430f-80ee-06cec8278cbe",
                        "28b8d07b-a802-4e3a-9dfb-2735d0ef7dfb",
                        "4c4ac71b-e5ac-4255-bcde-4fb350352337",
                        "54a5822c-e405-44ad-84e3-cea51e7349c2",
                        "5ebbd1f5-dfe5-4eec-9883-b8b5efea366c",
                        "732e611c-6996-4765-af4f-f9aaa80ff258",
                        "899de8c7-9cd9-4dd5-82f1-ad9acb801f8e",
                        "8d26e52c-b697-4e69-bb07-6a63ddeae5e4",
                        "9633d278-6961-4c38-8a2e-0e53a955e4d5",
                        "a00704dc-a2fa-4267-b7a6-427167d99521",
                        "a15cddb4-131e-4c80-ac81-e67febff8f4a",
                        "adda2917-0ddc-4d6e-b7b3-86c043022042",
                        "b16917e7-1d9e-453c-b4b2-78039072cda7",
                        "bd5acb06-2698-4ce9-a0ae-cbd687e03278",
                        "cadbc693-2f8d-4468-b1e4-622081afa465",
                        "d6ede40e-7ad9-477e-bb3a-2c0bbae93131",
                        "f3321f19-f59e-43fa-a9d0-825a57e08fb5"
                    ],
                    "keyword": [
                        "graph",
                        "object",
                        "similarity",
                        "representation",
                        "view",
                        "smgs",
                        "scales",
                        "saliency",
                        "providing",
                        "matching"
                    ],
                    "group": [],
                    "_id": "7b3f5f5b-a965-4656-9a6f-2f9740625176",
                    "abstract": "We introduce a novel view-based object representation, called the saliency map graph (SMG), which captures the salient regions of an object view at multiple scales using a wavelet transform. This compact representation is highly invariant to translation, rotation (image and depth), and scaling, and offers the locality of representation required for occluded object recognition. To compare two saliency map graphs, we introduce two graph similarity algorithms. The first computes the topological similarity between two SMGs, providing a coarse-level matching of two graphs. The second computes the geometrical similarity between two SMGs, providing a fine-level matching of two graphs. We test and compare these two algorithms on a large database of model object views.",
                    "title": "View-based object recognition using saliency maps",
                    "venue": "Image and Vision Computing",
                    "year": 1999,
                    "__v": 1,
                    "citationCount": 60,
                    "result": 7.005003749279996
                },
                "899de8c7-9cd9-4dd5-82f1-ad9acb801f8e": {
                    "authors": [
                        "Tony Lindeberg"
                    ],
                    "references": [
                        "086481a4-9404-4eb3-8fab-94014e54a77d",
                        "0d66d358-49fa-4d9c-931e-98c828313246",
                        "0f3f889d-417c-466a-acdc-8e5c2d23f01d",
                        "14582bca-c63d-4f41-8e8e-dedffb742728",
                        "1c63e1d5-b963-455b-829d-e4f3eb63a36a",
                        "3c1e64c0-8e48-45d3-96e8-f2c3252b4b83",
                        "41c0cec5-a359-4e75-aa81-674711d27cae",
                        "44cff942-c51c-4e97-8404-e918c971222e",
                        "497e3634-6d30-49d5-b10e-a84036394e14",
                        "5c0dc59e-043e-4f0a-af9c-907306684456",
                        "5c9b1df4-f013-469d-8074-0b636194e7d9",
                        "5d14edfe-9048-41b7-b216-bfbf5ba4ad16",
                        "624e6b79-ac9c-4b1e-b099-08052dc7ff28",
                        "75330ac9-8151-4d73-a239-881589aadedd",
                        "775d8200-d1e0-40ac-8c47-a6edf4b6be72",
                        "81f1e721-8677-4323-8e03-c94a5f844d72",
                        "97836b4b-6178-49ca-8e15-806c7b25d6d4",
                        "a00704dc-a2fa-4267-b7a6-427167d99521",
                        "a67e2c9f-62b0-4cb0-8cc1-f5e424ba7f9d",
                        "ac129832-39b9-407d-aff3-582c209145f3",
                        "b2029330-3645-4e27-b008-c533cab3c781",
                        "b5606a91-ee76-4ba1-97db-01441e204348",
                        "b7970f15-1d0e-4f92-ad6a-f4da1f47d153",
                        "c08d06c9-4f52-4c17-aef4-14787b83e90d",
                        "ec35fe29-01e2-4229-8f36-3e68b69736c2",
                        "eff4229a-5c33-47a9-bc20-6ebea2570a6f",
                        "f3321f19-f59e-43fa-a9d0-825a57e08fb5",
                        "f5ffcb52-9aae-4b1e-bfa5-a9fbe67772f7",
                        "fce470ab-6e77-4ea6-ae67-bae5560d9707"
                    ],
                    "keyword": [
                        "structures",
                        "scalespace",
                        "representation",
                        "visual",
                        "sketch",
                        "significant",
                        "shape",
                        "scales",
                        "relations",
                        "proposed"
                    ],
                    "group": [],
                    "_id": "899de8c7-9cd9-4dd5-82f1-ad9acb801f8e",
                    "abstract": "This article presents: (i) a multiscale representation of grey-level shape called the scale-space primal sketch, which makes explicit both features in scale-space and the relations between structures at different scales, (ii) a methodology for extracting significant blob-like image structures from this representation, and (iii) applications to edge detection, histogram analysis, and junction classification demonstrating how the proposed method can be used for guiding later-stage visual processes.",
                    "title": "Detecting salient blob-like image structures and their scales with a scale-space primal sketch: a method for focus-of-attention",
                    "venue": "International Journal of Computer Vision",
                    "year": 1993,
                    "__v": 1,
                    "citationCount": 205,
                    "result": 6.041817631160292
                },
                "a00704dc-a2fa-4267-b7a6-427167d99521": {
                    "authors": [
                        "James L. Crowley",
                        "Alice C. Parker"
                    ],
                    "references": [
                        "3fab6b4f-4a77-44c4-85e1-07585ba89e4d",
                        "744f18ad-c9ec-47c9-a59c-4d1d9c7cfd18",
                        "856111d1-029d-424b-b667-71c60e025ac3"
                    ],
                    "keyword": [
                        "shapes",
                        "resolution",
                        "peaks",
                        "dolp",
                        "linking",
                        "image",
                        "transform",
                        "ridges",
                        "representation",
                        "multiple"
                    ],
                    "group": [],
                    "_id": "a00704dc-a2fa-4267-b7a6-427167d99521",
                    "abstract": "This paper defines a multiple resolution representation for the two-dimensional gray-scale shapes in an image. This representation is constructed by detecting peaks and ridges in the difference of lowpass (DOLP) transform. Descriptions of shapes which are encoded in this representation may be matched efficiently despite changes in size, orientation, or position. Motivations for a multiple resolution representation are presented first, followed by the definition of the DOLP transform. Techniques are then presented for encoding a symbolic structural description of forms from the DOLP transform. This process involves detecting local peaks and ridges in each bandpass image and in the entire three-dimensional space defined by the DOLP transform. Linking adjacent peaks in different bandpass images gives a multiple resolution tree which describes shape. Peaks which are local maxima in this tree provide landmarks for aligning, manipulating, and matching shapes. Detecting and linking the ridges in each DOLP bandpass image provides a graph which links peaks within a shape in a bandpass image and describes the positions of the boundaries of the shape at multiple resolutions. Detecting and linking the ridges in the DOLP three-space describes elongated forms and links the largest peaks in the tree. The principles for determining the correspondence between symbols in pairs of such descriptions are then described. Such correspondence matching is shown to be simplified by using the correspondence at lower resolutions to constrain the possible correspondence at higher resolutions.",
                    "title": "A Representation for Shape Based on Peaks and Ridges in the Difference of Low-Pass Transform",
                    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "year": 1984,
                    "__v": 2,
                    "citationCount": 112,
                    "result": 6.836123401956623
                },
                "a748e0f4-ee6f-41ad-a2a5-1a5a6751086d": {
                    "authors": [
                        "Quang-Tuan Luong",
                        "Olivier D. Faugeras"
                    ],
                    "references": [
                        "021b598c-9112-43cc-b5ba-e3a47c6373aa",
                        "05a89f3a-47ae-44a6-be5c-530244feb123",
                        "088c2ef8-eef2-42a6-a417-426365aec11a",
                        "1fd3f422-1e94-4bea-afc7-30997df0096f",
                        "214a9f8e-1f8c-4322-83f7-fdd2bcd2988c",
                        "25b0c9f9-0c8a-4f2a-b075-90d339b6faa3",
                        "45699e05-87ad-4231-bf5f-bac7e7a3389f",
                        "47586fa0-840e-46ca-ad86-98a34a52cb98",
                        "4a5448bf-2fbf-4a44-b99c-66b4fe833dde",
                        "4d77aa8c-13cb-426b-81d4-489b295f5558",
                        "6a9dfcc3-8914-4ca3-ab60-5ca5fea44d5a",
                        "7836ab15-2a5f-4c17-a507-879e6dbc6bbd",
                        "78e44263-a6ca-41df-9684-ca1a8245d440",
                        "79033374-75da-4895-9797-1ad232675f10",
                        "80552242-fefa-4393-9f59-deb9f660c8a6",
                        "80e46604-c56f-4fc6-ad87-aefd96da22ad",
                        "95bda677-fc12-4881-93a6-a632c10c4885",
                        "9b542eef-7ea8-4d13-ab3b-f502e9d84b51",
                        "b4c0a22e-7fa3-4536-b4c2-b010364356b1",
                        "b69325ef-8234-4ad2-aeeb-47daa41124fe",
                        "b9fa1cc4-f358-4c0f-82ad-3ca72301498f",
                        "ba090582-262b-4640-a5b3-714c472736ba",
                        "bcf3e7a6-dc04-4f23-906f-0824bd184d2f",
                        "bfc1aacf-eff6-4285-b5cb-196cbe075db1",
                        "c5df7d5d-c642-4943-9b2b-f26b735eb345",
                        "c60c291a-d4c0-458d-864c-7e0eca65c776",
                        "c73b35df-1a1c-4a88-94c5-357e0539aa58",
                        "ca4b9a7a-de70-454c-b16c-074d41fc0420",
                        "eae41ceb-e7c8-404c-b8dd-2ccb8e1340bf",
                        "edd3284f-dd7a-4b58-9ced-1bf116f8c606",
                        "ee0574fb-b372-4317-822e-7711ddeddd52",
                        "f3bc4642-9164-4a05-84b6-b4a57e374720",
                        "f62d3ca6-ef53-47aa-8ff6-bb08db9ccefc",
                        "f6578026-7dd8-46ca-b4b7-74edf21ae1d1"
                    ],
                    "keyword": [
                        "stereo",
                        "matrix",
                        "projective",
                        "parameters",
                        "paper",
                        "pair",
                        "information",
                        "geometry",
                        "fundamentally",
                        "correspondences"
                    ],
                    "group": [],
                    "_id": "a748e0f4-ee6f-41ad-a2a5-1a5a6751086d",
                    "abstract": "In this paper we analyze in some detail the geometry of a pair of cameras, i.e., a stereo rig. Contrarily to what has been done in the past and is still done currently, for example in stereo or motion analysis, we do not assume that the intrinsic parameters of the cameras are known (coordinates of the principal points, pixels aspect ratio and focal lengths). This is important for two reasons. First, it is more realistic in applications where these parameters may vary according to the task (active vision). Second, the general case considered here, captures all the relevant information that is necessary for establishing correspondences between two pairs of images. This information is fundamentally projective and is hidden in a confusing manner in the commonly used formalism of the Essential matrix introduced by Longuet-Higgins (1981). This paper clarifies the projective nature of the correspondence problem in stereo and shows that the epipolar geometry can be summarized in one 3×3 matrix of rank 2 which we propose to call the Fundamental matrix.",
                    "title": "The Fundamental Matrix: Theory, Algorithms, and Stability Analysis",
                    "venue": "International Journal of Computer Vision",
                    "year": 1996,
                    "__v": 2,
                    "citationCount": 265,
                    "result": 7.220000458777549
                },
                "b3e60214-b54c-4e8f-9315-a6975c760f4c": {
                    "authors": [
                        "Krystian Mikolajczyk",
                        "Andrew Zisserman",
                        "Cordelia Schmid"
                    ],
                    "references": [
                        "27dfa95c-90d4-4d56-b987-0d2721b4b9b0",
                        "2958fc5c-15e8-45e7-8da8-d2e0fa46f0c7",
                        "34758e0a-3def-447b-9c5e-e82a206426b5",
                        "509e1ae2-768b-4417-bebe-d90cf1e0fdae",
                        "5149d3c0-5ac9-47ba-9fb0-3d2ef757b0e8",
                        "5ebbd1f5-dfe5-4eec-9883-b8b5efea366c",
                        "5f1992df-975f-49e7-bd88-aee0740317cf",
                        "5f84f09f-7644-447c-89e1-8dc9ee334197",
                        "6018a516-8149-4bce-bc33-5449d86e58c2",
                        "60285266-7da2-474e-b05a-b380c836f665",
                        "613841ae-c925-4aee-9c2e-8675213e4bbf",
                        "6fe37c18-8dc5-4baa-b6e0-5546353907bb",
                        "7283fa2b-1f6a-4138-a3da-4bf69809a1a9",
                        "75c6e7ad-f17c-40e1-8c39-965534096b2b",
                        "937cc256-e6e2-4bfa-928b-52f01cd416f4",
                        "97df7134-9cbf-43ea-9809-472115004999",
                        "a0be9da4-c423-4f87-a387-822fe304aa03",
                        "b1a8637d-9b27-4128-8c10-364a38230afc",
                        "b592576f-ff29-4a68-9b2f-8a8ad02e9c70",
                        "c591c440-b19b-4d7b-b067-cd8c366b7d6d",
                        "ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d"
                    ],
                    "keyword": [
                        "objects",
                        "feature",
                        "recognizing",
                        "neighbourhood",
                        "local",
                        "invariant",
                        "image",
                        "geometric",
                        "edges",
                        "descriptor"
                    ],
                    "group": [],
                    "_id": "b3e60214-b54c-4e8f-9315-a6975c760f4c",
                    "abstract": "In this paper we describe an approach to recognizing poorly textured objects, that may contain holes and tubular parts, in cluttered scenes under arbitrary viewing conditions. To this end we develop a number of novel components. First, we introduce a new edge-based local feature detector that is invariant to similarity transformations. The features are localized on edges and a neighbourhood is estimated in a scale invariant manner. Second, the neighbourhood descriptor computed for foreground features is not affected by background clutter, even if the feature is on an object boundary. Third, the descriptor generalizes Lowe's SIFT method to edges. An object model is learnt from a single training image. The object is then recognized in new images in a series of steps which apply progressively tighter geometric restrictions. A final contribution of this work is to allow sufficient flexibility in the geometric representation that objects in the same visual class can be recognized. Results are demonstrated for various object classes including bikes and rackets.",
                    "title": "Shape recognition with edge-based features.",
                    "venue": "british machine vision conference",
                    "year": 2003,
                    "__v": 1,
                    "citationCount": 91,
                    "result": 9.70446435728569
                },
                "b4685927-0ad9-466b-b2c6-2e1764475726": {
                    "authors": [
                        "Stephen Se",
                        "David G. Lowe",
                        "James J. Little"
                    ],
                    "references": [
                        "03a42efa-a19c-4b19-a881-9c7ff63865ce",
                        "202795f4-2db3-4b1b-9e81-01b7094d9f1f",
                        "34758e0a-3def-447b-9c5e-e82a206426b5",
                        "3936de47-94f1-4aa1-9e67-db8ccb8965f1",
                        "5a73ebfb-0c9b-4c63-9ccf-14720c815bfa",
                        "5d5a4e5f-da6e-42cd-b955-f2693926b9a6",
                        "6018a516-8149-4bce-bc33-5449d86e58c2",
                        "66322b0e-b724-483a-bd26-b5b55d6315e2",
                        "760bd9a4-ca62-420e-af44-bb2408e9ff5e",
                        "7f7dec03-1d9d-442b-ab89-7a90c3e1316e",
                        "a115b797-205c-43d6-a1cf-f1fc76c37641",
                        "b0c58756-9975-4c4e-8671-12902204b0ef",
                        "ebfca554-7a3c-4597-954b-07336a2e3030"
                    ],
                    "keyword": [
                        "localize",
                        "global",
                        "robot",
                        "ransac",
                        "matching",
                        "map",
                        "landmarks",
                        "frame",
                        "approach",
                        "achieved"
                    ],
                    "group": [],
                    "_id": "b4685927-0ad9-466b-b2c6-2e1764475726",
                    "abstract": "We have previously developed a mobile robot system which uses scale invariant visual landmarks to localize and simultaneously build a 3D map of the environment In this paper, we look at global localization, also known as the kidnapped robot problem, where the robot localizes itself globally, without any prior location estimate. This is achieved by matching distinctive landmarks in the current frame to a database map. A Hough transform approach and a random sample consensus (RANSAC) approach for global localization are compared, showing that RANSAC is much more efficient. Moreover, robust global localization can be achieved by matching a small sub-map of the local region built from multiple frames.",
                    "title": "Global localization using distinctive visual features",
                    "venue": "intelligent robots and systems",
                    "year": 2002,
                    "__v": 2,
                    "citationCount": 74,
                    "result": 6.319950837692773
                },
                "c455fb04-4566-4648-ad6f-3cf2245e507c": {
                    "authors": [
                        "Rob Fergus",
                        "Pietro Perona",
                        "Andrew Zisserman"
                    ],
                    "references": [
                        "2d6c9f60-ea78-44a8-b5f9-6964575dd196",
                        "473cf1a4-9f42-4e6d-b34f-77787f329079",
                        "509e1ae2-768b-4417-bebe-d90cf1e0fdae",
                        "613841ae-c925-4aee-9c2e-8675213e4bbf",
                        "bf664a72-1007-43e6-8dff-f1b0de9b5740",
                        "c591c440-b19b-4d7b-b067-cd8c366b7d6d",
                        "c7f93552-c1ef-4ae4-b1f5-2317e1c9d904",
                        "ccdefe89-9b16-4c22-8bb8-bd314ccad6e1",
                        "d5e5a24d-f80e-4f1a-b48b-22403b653276",
                        "d6e37fb1-5f7e-448e-847b-7d1f1271c574",
                        "d7b1fba1-b5f8-4377-88a8-d2fc69f723b7",
                        "df152036-9859-492f-998f-1ff9769b6d95",
                        "e649a9fd-f6d9-4aac-b428-29b82c20a484",
                        "ef35a024-f5f3-4a7b-b6f6-61d9167385e6",
                        "f111ff97-89a3-4df6-8f02-962d7b4fe985"
                    ],
                    "keyword": [
                        "object",
                        "models",
                        "scale",
                        "flexible",
                        "manner",
                        "learn",
                        "image",
                        "class"
                    ],
                    "group": [],
                    "_id": "c455fb04-4566-4648-ad6f-3cf2245e507c",
                    "abstract": "We present a method to learn and recognize object class models from unlabeled and unsegmented cluttered scenes in a scale invariant manner. Objects are modeled as flexible constellations of parts. A probabilistic representation is used for all aspects of the object: shape, appearance, occlusion and relative scale. An entropy-based feature detector is used to select regions and their scale within the image. In learning the parameters of the scale-invariant object model are estimated. This is done using expectation-maximization in a maximum-likelihood setting. In recognition, this model is used in a Bayesian manner to classify images. The flexible nature of the model is demonstrated by excellent results over a range of datasets including geometrically constrained classes (e.g. faces, cars) and flexible objects (such as animals).",
                    "title": "Object class recognition by unsupervised scale-invariant learning",
                    "venue": "computer vision and pattern recognition",
                    "year": 2003,
                    "__v": 2,
                    "citationCount": 1184,
                    "result": 4.6107702333508795
                },
                "d9b9f667-9d8a-4723-a6c4-c19b941acd46": {
                    "authors": [
                        "Brian V. Funt",
                        "Graham D. Finlayson"
                    ],
                    "references": [
                        "2d90b95f-130e-4f59-b68f-30271a8718c5",
                        "3cab9395-9004-4b15-b1ff-e5cf05be9c28",
                        "93378e13-0f38-429d-964b-abf990d6a37d",
                        "b9806191-3ec3-419d-a37a-aea812973ac8"
                    ],
                    "keyword": [
                        "color",
                        "illumination",
                        "varies",
                        "spatially",
                        "ratios",
                        "preprocessing",
                        "indexing",
                        "incident",
                        "histograms",
                        "constancy"
                    ],
                    "group": [],
                    "_id": "d9b9f667-9d8a-4723-a6c4-c19b941acd46",
                    "abstract": "Objects can be recognized on the basis of their color alone by color indexing, a technique developed by Swain-Ballard (1991) which involves matching color-space histograms. Color indexing fails, however, when the incident illumination varies either spatially or spectrally. Although this limitation might be overcome by preprocessing with a color constancy algorithm, we instead propose histogramming color ratios. Since the ratios of color RGB triples from neighboring locations are relatively insensitive to changes in the incident illumination, this circumvents the need for color constancy preprocessing. Results of tests with the new color-constant-color-indexing algorithm on synthetic and real images show that it works very well even when the illumination varies spatially in its intensity and color. >",
                    "title": "Color constant color indexing",
                    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "year": 1995,
                    "__v": 2,
                    "citationCount": 293,
                    "result": 6.692774614446442
                },
                "df9fe96c-752e-49be-a8c4-8b098ab51e22": {
                    "authors": [
                        "David G. Lowe"
                    ],
                    "references": [
                        "01a0f825-a308-455b-93fc-e62defc0e3b0",
                        "509e1ae2-768b-4417-bebe-d90cf1e0fdae",
                        "5521491f-f82e-4f09-b333-bdced2edcfcb",
                        "5ebbd1f5-dfe5-4eec-9883-b8b5efea366c",
                        "5f1992df-975f-49e7-bd88-aee0740317cf",
                        "6018a516-8149-4bce-bc33-5449d86e58c2",
                        "78dd7c1a-bc00-4993-bd41-8e5da9a7fe5b",
                        "a0fa7ae2-61e5-48a9-be10-86440416129f",
                        "adda2917-0ddc-4d6e-b7b3-86c043022042"
                    ],
                    "keyword": [
                        "image",
                        "model",
                        "matching",
                        "object",
                        "3d",
                        "view",
                        "based",
                        "training",
                        "robustness",
                        "representation"
                    ],
                    "group": [],
                    "_id": "df9fe96c-752e-49be-a8c4-8b098ab51e22",
                    "abstract": "There have been important recent advances in object recognition through the matching of invariant local image features. However, the existing approaches are based on matching to individual training images. This paper presents a method for combining multiple images of a 3D object into a single model representation. This provides for recognition of 3D objects from any viewpoint, the generalization of models to non-rigid changes, and improved robustness through the combination of features acquired under a range of imaging conditions. The decision of whether to cluster a training image into an existing view representation or to treat it as a new view is based on the geometric accuracy of the match to previous model views. A new probabilistic model is developed to reduce the false positive matches that would otherwise arise due to loosened geometric constraints on matching 3D and non-rigid models. A system has been developed based on these approaches that is able to robustly recognize 3D objects in cluttered natural images in sub-second times.",
                    "title": "Local feature view clustering for 3D object recognition",
                    "venue": "computer vision and pattern recognition",
                    "year": 2001,
                    "__v": 2,
                    "citationCount": 180,
                    "result": 8.419756765386252
                }
            }
        ],
        "_id": "b944f77f-113b-4a02-ae5e-d4a124b8fd5b",
        "abstract": "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance.",
        "title": "Distinctive Image Features from Scale-Invariant Keypoints",
        "venue": "International Journal of Computer Vision",
        "year": 2004,
        "__v": 3,
        "citationCount": 16229
    },
    {
        "authors": [
            "Timothy F. Cootes",
            "G. Edwards",
            "Christopher J. Taylor"
        ],
        "references": [
            "13c491a8-d910-4451-9cc9-fe4a8033976b",
            "1b2ca840-c231-4d15-b1d5-09fd8d61400c",
            "1ba94a3f-ba8a-4aff-8151-3a855803711c",
            "1d150ea3-d6c0-4c75-822f-433639a7dbcc",
            "45521624-faa8-4fed-a2e1-fdcdf96a7c56",
            "504af9f2-1981-4066-b835-1b69f6536b0f",
            "700061b6-54a5-4f50-a1ef-1d8de3015c43",
            "7cdaaa8a-8ddc-4ccd-89b0-d85ff20c41b7",
            "923f5d0a-23a3-4fb1-bee7-ec72122709a4",
            "9a342fc2-984f-443e-9597-99b3432afbd0",
            "ae66f3ec-b67d-4193-bb89-a19576fe3eb2",
            "ae9fd662-5816-4bc6-8cdf-390d15c2d6f2",
            "f6f9c3fa-6575-4408-ac39-3c7431c5a818"
        ],
        "keyword": [
            "models",
            "set",
            "parameters",
            "matching",
            "learned",
            "images",
            "variation",
            "training",
            "statistical",
            "shape"
        ],
        "group": [
            {
                "13c491a8-d910-4451-9cc9-fe4a8033976b": {
                    "authors": [
                        "Stan Sclaroff",
                        "John Isidoro"
                    ],
                    "references": [
                        "002ab882-8ba0-485c-8a7a-a0176b805a60",
                        "077a63e4-d549-4ef7-8acc-6793dcba7728",
                        "0c3cac6b-305e-4f1c-8ab8-72c6a3a551fe",
                        "0e3c573b-8cfc-44b7-9582-0bd52924d470",
                        "17531ea7-8696-4c30-87e0-56cbe74b838f",
                        "198bb43a-bbb0-404b-8368-f96e71a247c0",
                        "1c63e1d5-b963-455b-829d-e4f3eb63a36a",
                        "1d150ea3-d6c0-4c75-822f-433639a7dbcc",
                        "21c687ae-f66b-4ca6-8167-9c206913a1d1",
                        "23c61d04-333b-42c1-b8f8-a93cc33f4411",
                        "2adc6292-f788-498d-823e-9c3ea3145a8b",
                        "2da8025a-06d3-41f6-8b93-917219ad9792",
                        "3f4cc95c-5f47-4031-8671-e23ff4fe2ed2",
                        "64fa74e8-db02-4190-87d7-bf23e9859a7c",
                        "70e017b3-5711-4eae-aaa5-099139440342",
                        "7ad59e4b-8c98-4d12-98fe-0aa06a443862",
                        "936e0ae4-e6e1-4b3b-9d0a-a6bff589fc7b",
                        "9ecac0ea-d548-4b3d-b77d-bed14dc8c030",
                        "b62a32f3-eb04-429f-93ca-f20dadf916a5",
                        "b9466c12-f15f-46d1-845b-a6abb14d2d35",
                        "f0176e5b-d3a7-4214-b4e2-cf22720f6df4",
                        "f27cb993-16cd-44f9-b0c8-6bbeb3ecf297",
                        "f484f56b-640f-4f4a-a9cf-05f9adcafe8d",
                        "f6c95c19-7bd5-434b-bbd0-fc0be170c729"
                    ],
                    "keyword": [
                        "tracking",
                        "shape",
                        "nonrigid",
                        "approach",
                        "texture",
                        "robust",
                        "object",
                        "motion",
                        "map",
                        "captures"
                    ],
                    "group": [],
                    "_id": "13c491a8-d910-4451-9cc9-fe4a8033976b",
                    "abstract": "A new region-based approach to nonrigid motion tracking is described. Shape is defined in terms of a deformable triangular mesh that captures object shape plus a color texture map that captures object appearance. Photometric variations are also modeled. Nonrigid shape registration and motion tracking are achieved by posing the problem as an energy-based, robust minimization procedure. The approach provides robustness to occlusions, wrinkles, shadows, and specular highlights. The formulation is tailored to rake advantage of texture mapping hardware available in many workstations, PCs, and game consoles. This enables nonrigid tracking at speeds approaching video rate.",
                    "title": "Active blobs",
                    "venue": "international conference on computer vision",
                    "year": 1998,
                    "__v": 2,
                    "citationCount": 79,
                    "result": 5.711655827832297
                },
                "45521624-faa8-4fed-a2e1-fdcdf96a7c56": {
                    "authors": [
                        "G. Edwards",
                        "Timothy F. Cootes",
                        "Christopher J. Taylor"
                    ],
                    "references": [
                        "00909251-9935-44f3-94a1-629023b5015b",
                        "137456ad-4f9c-4083-9e2a-362b21248976",
                        "5f9f2346-d1e3-4716-a8af-8c14f1490e00",
                        "700061b6-54a5-4f50-a1ef-1d8de3015c43",
                        "923f5d0a-23a3-4fb1-bee7-ec72122709a4",
                        "ae66f3ec-b67d-4193-bb89-a19576fe3eb2",
                        "ae9fd662-5816-4bc6-8cdf-390d15c2d6f2",
                        "c38bddce-cba4-4096-92d7-07b248df5979",
                        "f6f9c3fa-6575-4408-ac39-3c7431c5a818"
                    ],
                    "keyword": [],
                    "group": [],
                    "_id": "45521624-faa8-4fed-a2e1-fdcdf96a7c56",
                    "abstract": "We present a new framework for interpreting face images and image sequences using an Active Appearance Model (AAM). The AAM contains a statistical, photo-realistic model of the shape and grey-level appearance of faces. This paper demonstrates the use of the AAM's efficient iterative matching scheme for image interpretation. We use the AAM as a basis for face recognition, obtain good results for difficult images. We show how the AAM framework allows identity information to be decoupled from other variation, allowing evidence of identity to be integrated over a sequence. The AAM approach makes optimal use of the evidence from either a single image or image sequence. Since we derive a complete description of a given image our method can be used as the basis for a range of face image interpretation tasks.",
                    "title": "Face Recognition Using Active Appearance Models",
                    "venue": "european conference on computer vision",
                    "year": 1998,
                    "__v": 0,
                    "citationCount": 151,
                    "result": 3.8461538461538463
                },
                "504af9f2-1981-4066-b835-1b69f6536b0f": {
                    "authors": [
                        "G. Edwards",
                        "Christopher J. Taylor",
                        "Timothy F. Cootes"
                    ],
                    "references": [
                        "0c74037a-2723-4134-b0a6-3ddef3bc15c8",
                        "13c491a8-d910-4451-9cc9-fe4a8033976b",
                        "5a4024a0-43d3-4cb8-864a-6f1b0bfd4437",
                        "700061b6-54a5-4f50-a1ef-1d8de3015c43",
                        "97571808-28e5-400a-8793-5ca824c4fc6e",
                        "ae66f3ec-b67d-4193-bb89-a19576fe3eb2",
                        "ae9fd662-5816-4bc6-8cdf-390d15c2d6f2",
                        "e6c03ded-e92c-4a46-b647-f9011b04eb71"
                    ],
                    "keyword": [],
                    "group": [],
                    "_id": "504af9f2-1981-4066-b835-1b69f6536b0f",
                    "abstract": "We demonstrate a fast, robust method of interpreting face images using an Active Appearance Model (AAM). An AAM contains a statistical model of shape and grey level appearance which can generalise to almost any face. Matching to an image involves finding model parameters which minimise the difference between the image and a synthesised face. We observe that displacing each model parameter from the correct value induces a particular pattern in the residuals. In a training phase, the AAM learns a linear model of the correlation between parameter displacements and the induced residuals. During search it measures the residuals and uses this model to correct the current parameters, leading to a better fit. A good overall match is obtained in a few iterations, even from poor starting estimates. We describe the technique in detail and show it matching to new face images.",
                    "title": "Interpreting face images using active appearance models",
                    "venue": "ieee international conference on automatic face and gesture recognition",
                    "year": 1998,
                    "__v": 0,
                    "citationCount": 220,
                    "result": 3.076923076923077
                },
                "700061b6-54a5-4f50-a1ef-1d8de3015c43": {
                    "authors": [
                        "Andreas Lanitis",
                        "Christopher J. Taylor",
                        "Timothy F. Cootes"
                    ],
                    "references": [
                        "00909251-9935-44f3-94a1-629023b5015b",
                        "019fb6c8-c81b-4ef9-94be-18083093da48",
                        "1c63e1d5-b963-455b-829d-e4f3eb63a36a",
                        "3b3d7569-08b1-4017-9910-2a017a00e43e",
                        "3bd3e603-fdd6-401a-a28c-70b5b2c8be75",
                        "46bf03a3-2f99-43f5-8e3b-5505faa0aebd",
                        "5f9f2346-d1e3-4716-a8af-8c14f1490e00",
                        "644bec95-ebd2-4f36-91a3-83ff08b24c9f",
                        "64fa74e8-db02-4190-87d7-bf23e9859a7c",
                        "6d86ad90-fe62-40e5-b917-7e3f31350523",
                        "85114f9d-70a8-4940-83aa-af504b75acf8",
                        "923f5d0a-23a3-4fb1-bee7-ec72122709a4",
                        "9b9c96fb-f880-49fd-bdae-651407dc2e30",
                        "cacef546-cc48-4fb9-814f-9c12141662d8",
                        "ced3f93b-687c-4044-b995-37a419a58e28",
                        "ef50568a-329a-42d8-bb6b-3e10f34ca75a"
                    ],
                    "keyword": [
                        "images",
                        "face",
                        "facial",
                        "variable",
                        "pose",
                        "model",
                        "expression",
                        "3d",
                        "tasks",
                        "sources"
                    ],
                    "group": [],
                    "_id": "700061b6-54a5-4f50-a1ef-1d8de3015c43",
                    "abstract": "Face images are difficult to interpret because they are highly variable. Sources of variability include individual appearance, 3D pose, facial expression, and lighting. We describe a compact parametrized model of facial appearance which takes into account all these sources of variability. The model represents both shape and gray-level appearance, and is created by performing a statistical analysis over a training set of face images. A robust multiresolution search algorithm is used to fit the model to faces in new images. This allows the main facial features to be located, and a set of shape, and gray-level appearance parameters to be recovered. A good approximation to a given face can be reconstructed using less than 100 of these parameters. This representation can be used for tasks such as image coding, person identification, 3D pose recovery, gender recognition, and expression recognition. Experimental results are presented for a database of 690 face images obtained under widely varying conditions of 3D pose, lighting, and facial expression. The system performs well on all the tasks listed above.",
                    "title": "Automatic interpretation and coding of face images using flexible models",
                    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "year": 1997,
                    "__v": 2,
                    "citationCount": 301,
                    "result": 5.18081803817098
                },
                "7cdaaa8a-8ddc-4ccd-89b0-d85ff20c41b7": {
                    "authors": [
                        "M. La Cascia",
                        "Stan Sclaroff",
                        "Vassilis Athitsos"
                    ],
                    "references": [
                        "019fb6c8-c81b-4ef9-94be-18083093da48",
                        "13c491a8-d910-4451-9cc9-fe4a8033976b",
                        "15d1e544-36a4-454a-94c3-1dd11098a36d",
                        "1ba94a3f-ba8a-4aff-8151-3a855803711c",
                        "1d150ea3-d6c0-4c75-822f-433639a7dbcc",
                        "25628852-b94d-441b-b3ad-0457653b60ae",
                        "2da8025a-06d3-41f6-8b93-917219ad9792",
                        "31b6a50a-c6ec-421d-965c-43b1df24b8f2",
                        "37e37831-6d5d-4093-99d4-95e1901629ac",
                        "3a2861b4-a6f7-4ab0-9f88-480006b53bb0",
                        "4423e524-cda6-4d7b-a81f-1fad66125b04",
                        "4e66dcf4-0228-4e26-9219-3d026b66698d",
                        "528f4f4d-7995-48ca-8e9a-83182d9d1c36",
                        "57eadb55-c2fa-42e1-a0c4-9da5e1658ff9",
                        "6300a64b-4e61-472d-8e92-4daaf85c2163",
                        "644bec95-ebd2-4f36-91a3-83ff08b24c9f",
                        "64fa74e8-db02-4190-87d7-bf23e9859a7c",
                        "6c8e9a18-6101-42a2-b97b-083ee288c431",
                        "6e8cc926-79a1-4676-a2bd-f9d49f3144cf",
                        "74ffdb73-6e2b-455d-bdf0-d089daad8329",
                        "843a8154-e055-43a8-abc6-0f441eb8cc49",
                        "91f6094c-f0e1-45ac-b887-89d5c09aa3d2",
                        "b5c70352-d0a3-4a6b-b961-ed59491ad43f",
                        "c97a48bf-396c-4c73-af34-feab9f4039d5",
                        "d6e37fb1-5f7e-448e-847b-7d1f1271c574",
                        "da19c758-4c30-472b-91e4-3ef0c4b8270f",
                        "f2c8158c-ff5d-43dd-872e-9b52caa02597",
                        "fc3749ea-d66b-4bcd-929a-02a4e1ad3f7d"
                    ],
                    "keyword": [
                        "tracking",
                        "texture",
                        "mapped",
                        "illumination",
                        "face",
                        "templates",
                        "technique",
                        "regularized",
                        "registration",
                        "modeled"
                    ],
                    "group": [],
                    "_id": "7cdaaa8a-8ddc-4ccd-89b0-d85ff20c41b7",
                    "abstract": "A technique for 3D head tracking under varying illumination is proposed. The head is modeled as a texture mapped cylinder. Tracking is formulated as an image registration problem in the cylinder's texture map image. The resulting dynamic texture map provides a stabilized view of the face that can be used as input to many existing 2D techniques for face recognition, facial expressions analysis, lip reading, and eye tracking. To solve the registration problem with lighting variation and head motion, the residual registration error is modeled as a linear combination of texture warping templates and orthogonal illumination templates. Fast stable online tracking is achieved via regularized weighted least-squares error minimization. The regularization tends to limit potential ambiguities that arise in the warping and illumination templates. It enables stable tracking over extended sequences. Tracking does not require a precise initial model fit; the system is initialized automatically using a simple 2D face detector. It is assumed that the target is facing the camera in the first frame. The formulation uses texture mapping hardware. The nonoptimized implementation runs at about 15 frames per second on a SGI O2 graphic workstation. Extensive experiments evaluating the effectiveness of the formulation are reported. The sensitivity of the technique to illumination, regularization parameters, errors in the initial positioning, and internal camera parameters are analyzed. Examples and applications of tracking are reported.",
                    "title": "Fast, reliable head tracking under varying illumination: an approach based on registration of texture-mapped 3D models",
                    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "year": 2000,
                    "__v": 2,
                    "citationCount": 324,
                    "result": 9.259641115678267
                },
                "923f5d0a-23a3-4fb1-bee7-ec72122709a4": {
                    "authors": [
                        "Timothy F. Cootes",
                        "Christopher J. Taylor",
                        "David H. Cooper",
                        "Jim Graham"
                    ],
                    "references": [
                        "035f8537-61a7-4c4f-b9fe-120f913a38b0",
                        "250f917f-a84e-4018-9e6b-43995d0c2bc6",
                        "560f44a5-d696-449d-9163-662c4cf2a538",
                        "6d24a893-dbf9-4baf-9a3d-2b7b6951ac37",
                        "9980a8c8-2c38-437f-b269-2a5bb1c976cb",
                        "9be82f37-3656-4bb8-bfea-b9f399593807",
                        "b9466c12-f15f-46d1-845b-a6abb14d2d35"
                    ],
                    "keyword": [
                        "model",
                        "images",
                        "objects",
                        "methods",
                        "variability",
                        "training",
                        "set",
                        "robust",
                        "modelbased",
                        "locating"
                    ],
                    "group": [],
                    "_id": "923f5d0a-23a3-4fb1-bee7-ec72122709a4",
                    "abstract": "!, Model-based vision is firmly established as a robust approach to recognizing and locating known rigid objects in the presence of noise, clutter, and occlusion. It is more problematic to apply modelbased methods to images of objects whose appearance can vary, though a number of approaches based on the use of flexible templates have been proposed. The problem with existing methods is that they sacrifice model specificity in order to accommodate variability, thereby compromising robustness during image interpretation. We argue that a model should only be able to deform in ways characteristic of the class of objects it represents. We describe a method for building models by learning patterns of variability from a training set of correctly annotated images. These models can be used for image search in an iterative refinement algorithm analogous to that employed by Active Contour Models (Snakes). The key difference is that our Active Shape Models can only deform to fit the data in ways consistent with the training set. We show several practical examples where we have built such models and used them to locate partially occluded objects in noisy, cluttered images. Q 199s A&& prrss, IN.",
                    "title": "Active shape models—their training and application",
                    "venue": "Computer Vision and Image Understanding",
                    "year": 1995,
                    "__v": 1,
                    "citationCount": 2999,
                    "result": 8.375087451248442
                },
                "9a342fc2-984f-443e-9597-99b3432afbd0": {
                    "authors": [
                        "Thomas Vetter"
                    ],
                    "references": [
                        "123dbd0e-74f1-428b-9f16-00d04583f937",
                        "923f5d0a-23a3-4fb1-bee7-ec72122709a4",
                        "a7da5f11-1302-4305-a67a-9503dea05eb7"
                    ],
                    "keyword": [
                        "faces",
                        "images",
                        "3d",
                        "viewpoints",
                        "technique",
                        "single",
                        "poses",
                        "model",
                        "knowledge",
                        "head"
                    ],
                    "group": [],
                    "_id": "9a342fc2-984f-443e-9597-99b3432afbd0",
                    "abstract": "A new technique is described for synthesizing images of faces from new viewpoints, when only a single 2D image from a known viewpoint is available. A novel 2D image of a face can be computed without knowledge about the 3D structure of the head. The technique draws on prior knowledge of faces based on example images of other faces seen in different poses and on a single generic 3D model of a human head. The example images are used to learn a pose-invariant shape and texture description of a new face. The 3D model is used to solve the correspondence problem between images showing faces in different poses. Examples of synthetic \"rotations\" over 24/spl deg/ based on a training set of 100 faces are shown.",
                    "title": "Learning novel views to a single face image",
                    "venue": "",
                    "year": 1996,
                    "__v": 2,
                    "citationCount": 18,
                    "result": 5.747145338321809
                },
                "ae9fd662-5816-4bc6-8cdf-390d15c2d6f2": {
                    "authors": [
                        "Tony Ezzat",
                        "Tomaso Poggio"
                    ],
                    "references": [
                        "09410999-540a-409b-870c-d355c08e3619",
                        "9d96d55b-65a1-4872-9960-994fe14fd0e4",
                        "afeea258-2e1c-4c65-9721-7bbc515df849"
                    ],
                    "keyword": [
                        "modeling",
                        "parameters",
                        "imagebased",
                        "set",
                        "images",
                        "views",
                        "network",
                        "movements",
                        "facial",
                        "faces"
                    ],
                    "group": [],
                    "_id": "ae9fd662-5816-4bc6-8cdf-390d15c2d6f2",
                    "abstract": "In this paper we describe image-based modeling techniques that make possible the creation of photo-realistic computer models of real human faces. The image-based model is built using example views of the face, bypassing the need for any three-dimensional computer graphics models. A learning network is trained to associate each of the example images with a set of pose and expression parameters. For a novel set of parameters, the network synthesizes a novel, intermediate view using a morphing approach. This image-based synthesis paradigm can adequately model both rigid and non-rigid facial movements. We also describe an analysis-by-synthesis algorithm, which is capable of extracting a set of high-level parameters from an image sequence involving facial movement using embedded image-based models. The parameters of the models are perturbed in a local and independent manner for each image until a correspondence-based error metric is minimized. A small sample of experimental results is presented.",
                    "title": "Facial analysis and synthesis using image-based models",
                    "venue": "",
                    "year": 1996,
                    "__v": 2,
                    "citationCount": 34,
                    "result": 7.486853669206612
                },
                "f6f9c3fa-6575-4408-ac39-3c7431c5a818": {
                    "authors": [
                        "G. Edwards",
                        "Andreas Lanitis",
                        "Christopher J. Taylor",
                        "Timothy F. Cootes"
                    ],
                    "references": [
                        "00909251-9935-44f3-94a1-629023b5015b",
                        "019fb6c8-c81b-4ef9-94be-18083093da48",
                        "0aaed614-9b84-43c5-af94-9cf7d8224251",
                        "0e8b9fa7-733c-4434-8244-c0a101c0c978",
                        "137456ad-4f9c-4083-9e2a-362b21248976",
                        "13769a56-92cf-4920-8428-9549926b7ffc",
                        "291bceb3-9d76-46ce-b9ea-5dbef5dc2560",
                        "3b3d7569-08b1-4017-9910-2a017a00e43e",
                        "46bf03a3-2f99-43f5-8e3b-5505faa0aebd",
                        "56f4b72a-ec39-47ac-8220-899296e7fb18",
                        "5f9f2346-d1e3-4716-a8af-8c14f1490e00",
                        "62157500-e397-46f1-93be-5b215ddbc092",
                        "644bec95-ebd2-4f36-91a3-83ff08b24c9f",
                        "64fa74e8-db02-4190-87d7-bf23e9859a7c",
                        "6d4dd8a3-a299-4f19-8852-eff3fa729758",
                        "700061b6-54a5-4f50-a1ef-1d8de3015c43",
                        "85114f9d-70a8-4940-83aa-af504b75acf8",
                        "923f5d0a-23a3-4fb1-bee7-ec72122709a4",
                        "94a0b002-578e-4581-ad1d-8fc52a7052ea",
                        "9b9c96fb-f880-49fd-bdae-651407dc2e30",
                        "9be82f37-3656-4bb8-bfea-b9f399593807",
                        "a1f1edad-49c5-46f6-a3db-8bbe9e6613b9",
                        "ae66f3ec-b67d-4193-bb89-a19576fe3eb2",
                        "ef50568a-329a-42d8-bb6b-3e10f34ca75a",
                        "f5cba99d-69df-4916-b907-ff6f8fa0b593"
                    ],
                    "keyword": [],
                    "group": [],
                    "_id": "f6f9c3fa-6575-4408-ac39-3c7431c5a818",
                    "abstract": "Model-based approaches to the interpretation of face images have proved very successful. We have previously described statistically based models of face shape and grey-level appearance and shown how they can be used to perform various coding and interpretation tasks. In the paper we describe improved methods of modelling which couple shape and grey-level information more directly than our existing methods, isolate the changes in appearance due to different sources of variability (person, expression, pose, lighting) and deal with non-linear shape variation. We show that the new methods are better suited to interpretation and tracking tasks.",
                    "title": "Statistical models of face images - improving specificity",
                    "venue": "Image and Vision Computing",
                    "year": 1998,
                    "__v": 0,
                    "citationCount": 63,
                    "result": 2.307692307692308
                }
            }
        ],
        "_id": "bf03f268-de9d-4a80-aee1-200990056503",
        "abstract": "We describe a new method of matching statistical models of appearance to images. A set of model parameters control modes of shape and gray-level variation learned from a training set. We construct an efficient iterative matching algorithm by learning the relationship between perturbations in the model parameters and the induced image errors.",
        "title": "Active appearance models",
        "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
        "year": 2001,
        "__v": 2,
        "citationCount": 2362
    },
    {
        "authors": [
            "Chih-Chung Chang",
            "Chih-Jen Lin"
        ],
        "references": [
            "036a2a1b-8729-431d-b260-3d6b33c6c6a4",
            "078b095c-7687-43f2-a0bf-30ea78f787db",
            "11f27d27-6bd9-4691-834e-9864871a65f4",
            "1f556c88-b553-4c75-b243-92d8200f8149",
            "2d768672-0070-4a38-87c8-f0cce1dd2f44",
            "33184e74-4574-4856-a969-e497fdc2fec8",
            "41087d29-5163-4a9f-b55a-3f407b8a040d",
            "4317334f-595f-45be-a095-efe8f258b558",
            "50dd56db-151d-4d62-8576-65f0ef6f381b",
            "5ffac6f9-2456-42cf-830c-9049ce37c899",
            "633e2247-d487-4ae7-b6ab-a17a075b83aa",
            "7c6a970a-0d6f-4e4b-b50e-6c6fbd23a9ab",
            "7f03746d-ba06-4b34-828e-683192e9ee42",
            "8b26f4a9-380f-432d-aea1-66a86ce407e8",
            "8c0ec27c-e654-4e0e-8c49-9b427117a98e",
            "90925435-d33a-4abd-892d-abbe52e547c4",
            "92a420a1-f54b-4cdd-b5a4-2669ac2e7c5d",
            "962d4022-ff67-4067-a544-828604d8db52",
            "9764de87-e34e-4ea1-8de3-12d9bffc4f55",
            "97bfd03c-335a-4f39-89d3-cf0a22769383",
            "a2e5c222-c380-42d7-8846-cbc232f46a69",
            "a5d347a7-9984-45f4-821e-df7356477185",
            "b532d930-ad51-4a05-9c5c-9a75d6b021a2",
            "b90f9310-726f-4116-9322-6fc01ab598fd",
            "bb693c93-e418-46ea-8b38-9c53df27bdf2",
            "cdbd2ef9-d4b1-4dff-9037-3ea84627424d",
            "dd5a3ef5-9d44-4dde-bcdb-dc4d17c69073",
            "f006e236-59ad-4647-a59f-4f46dc2c85be",
            "feff8862-f47d-4591-a7cb-b62d7efc81a2"
        ],
        "keyword": [
            "libsvm",
            "svm",
            "machines",
            "details",
            "year",
            "wide",
            "vector",
            "users",
            "theoretical",
            "svms"
        ],
        "group": [
            {
                "036a2a1b-8729-431d-b260-3d6b33c6c6a4": {
                    "authors": [
                        "Nicola Segata",
                        "Enrico Blanzieri"
                    ],
                    "references": [
                        "00fd0089-c42a-48eb-8d04-1063b322ba0b",
                        "0346bdc2-a206-4dc7-90e7-413ab0135d62",
                        "050360ca-fadd-4f9c-8100-17813ded6893",
                        "0bc91666-8a77-4055-9819-d51b518d5550",
                        "0f115eea-2272-431f-9f21-6d6789b2bbc9",
                        "12fa9885-b0a9-4ea3-a0de-e020c333c3f0",
                        "1cf68c27-336c-4001-8e56-da45a2b8c962",
                        "1f6caa35-3d3f-481f-a820-a5d6e6b130d1",
                        "213eb9e8-df2a-40ad-b9af-4719f5aa9991",
                        "21873321-4d54-456b-b858-ac914b7e6db4",
                        "27002288-c316-4416-97b4-a6d582ec83b2",
                        "295a6daa-5774-4960-b5a2-25910deea0eb",
                        "2d768672-0070-4a38-87c8-f0cce1dd2f44",
                        "2f19f958-949f-4ce8-91cf-bf35ed3f6841",
                        "37d0d3d2-51be-406d-9743-62f7b1813e51",
                        "4317334f-595f-45be-a095-efe8f258b558",
                        "4cbd7765-c47a-4004-a5f8-c2da7c7d1c7b",
                        "505f493b-e09d-444d-9ee2-5e5db6a5b8ac",
                        "50dd56db-151d-4d62-8576-65f0ef6f381b",
                        "526a0ecb-c2a8-4c64-97b1-68f91eb0815f",
                        "53902d71-aa9b-477e-8704-66d822469e9b",
                        "640bfef8-3c8b-4f57-8db8-5184529ffe1b",
                        "6ded8970-1ba8-4422-bcab-9e7c291d85f4",
                        "702351ac-1e46-487c-bf41-ae43a91ae574",
                        "7dd74f36-3b44-40d5-9fe3-55c810d731b0",
                        "81cee2dc-6761-4a2f-b67d-2ad62ed64bf1",
                        "833da8cb-e068-44eb-955c-48b52adabfae",
                        "834f73f1-7468-499e-bbf6-67810694bcc8",
                        "83dfb6ca-659f-4f84-99fb-f11e16d88552",
                        "89022b09-5732-4493-9e2d-2046059dd2e5",
                        "89673e95-9269-4a99-addc-6d2ab81e36d2",
                        "8b26f4a9-380f-432d-aea1-66a86ce407e8",
                        "8beb26d1-fb4d-4e14-8ad3-737eab76ca27",
                        "8bfb1563-5f31-4127-a98c-8d36c630fce8",
                        "92647e2f-3ddc-4a26-8f1a-dfab46e4053f",
                        "92d458ce-e2d0-4941-8937-14c47de1f41b",
                        "95f18c30-6538-44f1-baba-45be64d96c47",
                        "a083a1b9-8dfb-45d6-99a9-fa30c4a6e9f5",
                        "aa767a83-de19-4421-bfb4-f63808992758",
                        "b4c5a572-c0a9-41e3-8782-9d4ee8105d81",
                        "b5cb7bcd-7b41-4488-a202-1429314fd5fe",
                        "c07168e6-1a36-47ca-864b-b29f6677fbdd",
                        "c1b6b493-01ef-420f-be44-7bacfe34e846",
                        "c7553d0c-160f-49d7-9bff-ec5d6b3fc043",
                        "ca18d709-eec1-4355-9abc-1ad5576ca3d1",
                        "cd1f4a53-5ab5-408b-bb60-55b67e81d8d7",
                        "cdbd2ef9-d4b1-4dff-9037-3ea84627424d",
                        "de201392-a6c7-4465-a966-c26b3ca31830",
                        "e1b31adb-4438-438d-be20-cd91ea4361b0",
                        "ea64f6ce-6ad4-4e2d-ad18-24c25ff99870",
                        "eadb0f66-1fb0-4b1c-9b8b-76cf5edbfad1",
                        "ed869b16-2abb-4ac8-bb5f-790948d0bd56",
                        "fab009f6-19f4-4eed-af8c-62776947aef3",
                        "feff8862-f47d-4591-a7cb-b62d7efc81a2"
                    ],
                    "keyword": [],
                    "group": [],
                    "_id": "036a2a1b-8729-431d-b260-3d6b33c6c6a4",
                    "abstract": "A computationally efficient approach to local learning with kernel methods is presented. The Fast Local Kernel Support Vector Machine (FaLK-SVM) trains a set of local SVMs on redundant neighbourhoods in the training set and an appropriate model for each query point is selected at testing time according to a proximity strategy. Supported by a recent result by Zakai and Ritov (2009) relating consistency and localizability, our approach achieves high classification accuracies by dividing the separation function in local optimisation problems that can be handled very efficiently from the computational viewpoint. The introduction of a fast local model selection further speeds-up the learning process. Learning and complexity bounds are derived for FaLK-SVM, and the empirical evaluation of the approach (with data sets up to 3 million points) showed that it is much faster and more accurate and scalable than state-of-the-art accurate and approximated SVM solvers at least for non high-dimensional data sets. More generally, we show that locality can be an important factor to sensibly speed-up learning approaches and kernel methods, differently from other recent techniques that tend to dismiss local information in order to improve scalability.",
                    "title": "Fast and Scalable Local Kernel Machines",
                    "venue": "Journal of Machine Learning Research",
                    "year": 2010,
                    "__v": 0,
                    "citationCount": 33,
                    "result": 2.0689655172413794
                },
                "4317334f-595f-45be-a095-efe8f258b558": {
                    "authors": [
                        "Rong-En Fan",
                        "P. Chen",
                        "Chih-Jen Lin"
                    ],
                    "references": [
                        "4aa6fe33-d146-4e6f-ac35-cbeb43c65866",
                        "50dd56db-151d-4d62-8576-65f0ef6f381b",
                        "5ffac6f9-2456-42cf-830c-9049ce37c899",
                        "90925435-d33a-4abd-892d-abbe52e547c4",
                        "9764de87-e34e-4ea1-8de3-12d9bffc4f55",
                        "97bfd03c-335a-4f39-89d3-cf0a22769383",
                        "9c01a502-04f3-4adb-9bde-f06253818cb9",
                        "a2e5c222-c380-42d7-8846-cbc232f46a69",
                        "b90f9310-726f-4116-9322-6fc01ab598fd",
                        "c1b6b493-01ef-420f-be44-7bacfe34e846",
                        "dd5a3ef5-9d44-4dde-bcdb-dc4d17c69073",
                        "f006e236-59ad-4647-a59f-4f46dc2c85be",
                        "fb6acee9-6dfe-47ef-a8c3-20bbbbb3ff8a"
                    ],
                    "keyword": [],
                    "group": [],
                    "_id": "4317334f-595f-45be-a095-efe8f258b558",
                    "abstract": "Working set selection is an important step in decomposition methods for training support vector machines (SVMs). This paper develops a new technique for working set selection in SMO-type decomposition methods. It uses second order information to achieve fast convergence. Theoretical properties such as linear convergence are established. Experiments demonstrate that the proposed method is faster than existing selection methods using first order information.",
                    "title": "Working Set Selection Using Second Order Information for Training Support Vector Machines",
                    "venue": "Journal of Machine Learning Research",
                    "year": 2005,
                    "__v": 0,
                    "citationCount": 510,
                    "result": 3.103448275862069
                },
                "50dd56db-151d-4d62-8576-65f0ef6f381b": {
                    "authors": [
                        "Corinna Cortes",
                        "Vladimir Vapnik"
                    ],
                    "references": [
                        "c4dc7b46-01d3-44f5-91ca-0cc063d38c8c",
                        "f006e236-59ad-4647-a59f-4f46dc2c85be"
                    ],
                    "keyword": [
                        "supportvector",
                        "network",
                        "machine",
                        "learning",
                        "training",
                        "surface",
                        "space",
                        "input",
                        "implements",
                        "idea"
                    ],
                    "group": [],
                    "_id": "50dd56db-151d-4d62-8576-65f0ef6f381b",
                    "abstract": "The support-vector network is a new learning machine for two-group classification problems. The machine conceptually implements the following idea: input vectors are non-linearly mapped to a very high-dimension feature space. In this feature space a linear decision surface is constructed. Special properties of the decision surface ensures high generalization ability of the learning machine. The idea behind the support-vector network was previously implemented for the restricted case where the training data can be separated without errors. We here extend this result to non-separable training data.#R##N##R##N#High generalization ability of support-vector networks utilizing polynomial input transformations is demonstrated. We also compare the performance of the support-vector network to various classical learning algorithms that all took part in a benchmark study of Optical Character Recognition.",
                    "title": "Support-Vector Networks",
                    "venue": "Machine Learning",
                    "year": 1995,
                    "__v": 2,
                    "citationCount": 6683,
                    "result": 5.278645075906739
                },
                "5ffac6f9-2456-42cf-830c-9049ce37c899": {
                    "authors": [
                        "Edgar Osuna",
                        "Robert M. Freund",
                        "Federico Girosit"
                    ],
                    "references": [
                        "0150e8cd-09bc-4991-92b4-454fe4b0bfac",
                        "50dd56db-151d-4d62-8576-65f0ef6f381b",
                        "648675c6-6ea7-4fa5-a91d-9d3156d09692",
                        "a689c833-ccce-475c-87af-526da83ebb29",
                        "d42f853d-12d7-416d-8b27-c314ef563eed",
                        "d46e68dc-dbb7-4296-8f40-f3c513b432bc",
                        "d5e5a24d-f80e-4f1a-b48b-22403b653276",
                        "eb2dc957-4aae-4d39-a99d-8adab1effb39",
                        "f006e236-59ad-4647-a59f-4f46dc2c85be"
                    ],
                    "keyword": [
                        "data",
                        "svm",
                        "problem",
                        "optimization",
                        "training",
                        "sets",
                        "quadratic",
                        "present",
                        "points",
                        "iterative"
                    ],
                    "group": [],
                    "_id": "5ffac6f9-2456-42cf-830c-9049ce37c899",
                    "abstract": "We investigate the application of Support Vector Machines (SVMs) in computer vision. SVM is a learning technique developed by V. Vapnik and his team (AT&T Bell Labs., 1985) that can be seen as a new method for training polynomial, neural network, or Radial Basis Functions classifiers. The decision surfaces are found by solving a linearly constrained quadratic programming problem. This optimization problem is challenging because the quadratic form is completely dense and the memory requirements grow with the square of the number of data points. We present a decomposition algorithm that guarantees global optimality, and can be used to train SVM's over very large data sets. The main idea behind the decomposition is the iterative solution of sub-problems and the evaluation of optimality conditions which are used both to generate improved iterative values, and also establish the stopping criteria for the algorithm. We present experimental results of our implementation of SVM, and demonstrate the feasibility of our approach on a face detection problem that involves a data set of 50,000 data points.",
                    "title": "Training support vector machines: an application to face detection",
                    "venue": "computer vision and pattern recognition",
                    "year": 1997,
                    "__v": 2,
                    "citationCount": 975,
                    "result": 5.636388994147614
                },
                "7c6a970a-0d6f-4e4b-b50e-6c6fbd23a9ab": {
                    "authors": [
                        "Bernhard Schölkopf",
                        "John Platt",
                        "John Shawe-Taylor",
                        "Alexander J. Smola",
                        "Robert C. Williamson"
                    ],
                    "references": [
                        "01b486c4-8955-403b-a0c6-1de74298b215",
                        "14e8bffe-590f-4592-801d-89e9848e608b",
                        "24627c32-96e9-4f6d-8193-059b20e2f57e",
                        "29e06cb4-0ae3-4c7b-863a-d63ced9b1fa2",
                        "2cbdd97b-393f-4def-b945-b0694dea2db8",
                        "34ae3c66-089c-479d-bb47-588a25ebdc84",
                        "5179ae8d-c2b7-474c-8dd2-f4a2aa53788f",
                        "549f0527-0f13-4447-9dc0-ca699e2dc219",
                        "6551c5ce-f20f-4c10-ac3b-175a9df74644",
                        "87969fc2-8332-4ee5-b6b0-e1b26d01ebd4",
                        "9f4b7cd7-ff01-4eea-9915-e9c12b95a532",
                        "ac3320cd-9db9-406b-b672-27230d95725d",
                        "b49b6e49-b084-4255-96f8-09c1de7bc1d2",
                        "b7a9291d-1b91-45da-a24c-72a9d60b87b4",
                        "b90f9310-726f-4116-9322-6fc01ab598fd",
                        "bb0530f9-f248-43b4-a465-d738806b20f4",
                        "c358ee37-4afb-4603-9b65-59d2536d0866",
                        "cb4fbf1c-02e4-4ca9-995d-29f5282fdb4a",
                        "dab15bfb-fb2c-4cc4-b6f0-6fb7d19a73c2",
                        "dd5a3ef5-9d44-4dde-bcdb-dc4d17c69073",
                        "ef781e5f-5519-4a20-93fc-25f7d14039a1",
                        "f006e236-59ad-4647-a59f-4f46dc2c85be"
                    ],
                    "keyword": [
                        "data",
                        "algorithm",
                        "vector",
                        "subset",
                        "space",
                        "problem",
                        "probability",
                        "input",
                        "function",
                        "expansion"
                    ],
                    "group": [],
                    "_id": "7c6a970a-0d6f-4e4b-b50e-6c6fbd23a9ab",
                    "abstract": "Suppose you are given some data set drawn from an underlying probability distribution P and you want to estimate a \"simple\" subset S of input space such that the probability that a test point drawn from P lies outside of S equals some a priori specified value between 0 and 1. We propose a method to approach this problem by trying to estimate a function f that is positive on S and negative on the complement. The functional form of f is given by a kernel expansion in terms of a potentially small subset of the training data; it is regularized by controlling the length of the weight vector in an associated feature space. The expansion coefficients are found by solving a quadratic programming problem, which we do by carrying out sequential optimization over pairs of input patterns. We also provide a theoretical analysis of the statistical performance of our algorithm. The algorithm is a natural extension of the support vector algorithm to the case of unlabeled data.",
                    "title": "Estimating the Support of a High-Dimensional Distribution",
                    "venue": "Neural Computation",
                    "year": 2001,
                    "__v": 2,
                    "citationCount": 1337,
                    "result": 4.520874961189363
                },
                "8b26f4a9-380f-432d-aea1-66a86ce407e8": {
                    "authors": [
                        "S. Sathiya Keerthi",
                        "Olivier Chapelle",
                        "Dennis DeCoste"
                    ],
                    "references": [
                        "0781e713-d8ca-4f62-89e8-3047b77dd6e6",
                        "08b5ac13-f0b0-46ba-a21a-8944a720715b",
                        "108c59b1-0dc5-48ef-8ae2-d928a07fae8b",
                        "1fb398c5-0953-4b37-8d45-3e50501c01d9",
                        "216f96d1-a72e-4958-a866-cc2761771057",
                        "27002288-c316-4416-97b4-a6d582ec83b2",
                        "2d768672-0070-4a38-87c8-f0cce1dd2f44",
                        "40552b91-8a96-4519-9972-8c264bc6b70c",
                        "4fb87930-7f6c-4f03-ae22-32445138ec83",
                        "5dc3a3dc-0165-4db1-ab4f-163ab27b6e62",
                        "7233a003-b1fe-4e5e-918a-00d05252a7ff",
                        "8bb47288-c305-4131-9a23-3635d1bc15ad",
                        "8d649995-283f-4cf4-9250-aafd716cb2ac",
                        "8dacb95e-ec6f-40a8-bc7d-3c5b1a524455",
                        "9b467767-2c1f-4f97-adf2-d341055245d1",
                        "9bf81d3d-27e1-415a-97f1-c932d40c8a10",
                        "a87c2dc9-ca53-4c31-9ac5-4b3bf995dd19",
                        "abd639b6-5255-4f9b-beb2-e9caf5798b30",
                        "aca0f38f-0488-4460-b3bc-fc38a2a6879a",
                        "ae91d4b9-5de0-4e90-aad1-9ad99415d40c",
                        "b744b588-52eb-4916-b158-2e0eadd79770",
                        "bb3c38fa-c2b0-4d4f-8c9d-ca1884343474",
                        "ca0d22e6-1b1c-4ffd-94c7-1ce3e7fac2a5",
                        "d3898d76-df7a-43e9-be36-947d18023d9e",
                        "d6104d9a-faaa-4db4-8c4e-748176157ef2",
                        "f15b056f-a577-4391-9724-a5be885e2bd2",
                        "f77c1d0e-84e2-436d-93a1-8c8f0085b503"
                    ],
                    "keyword": [
                        "vector",
                        "support",
                        "number",
                        "functions",
                        "svm",
                        "basis",
                        "requiring",
                        "primal",
                        "accuracy"
                    ],
                    "group": [],
                    "_id": "8b26f4a9-380f-432d-aea1-66a86ce407e8",
                    "abstract": "Support vector machines (SVMs), though accurate, are not preferred in applications requiring great classification speed, due to the number of support vectors being large. To overcome this problem we devise a primal method with the following properties: (1) it decouples the idea of basis functions from the concept of support vectors; (2) it greedily finds a set of kernel basis functions of a specified maximum size (dmax) to approximate the SVM primal cost function well; (3) it is efficient and roughly scales as O(ndmax2) where n is the number of training examples; and, (4) the number of basis functions it requires to achieve an accuracy close to the SVM accuracy is usually far less than the number of SVM support vectors.",
                    "title": "Building Support Vector Machines with Reduced Classifier Complexity",
                    "venue": "Journal of Machine Learning Research",
                    "year": 2006,
                    "__v": 2,
                    "citationCount": 141,
                    "result": 5.330888747268058
                },
                "8c0ec27c-e654-4e0e-8c49-9b427117a98e": {
                    "authors": [
                        "Shai Fine",
                        "Katya Scheinberg"
                    ],
                    "references": [
                        "2190c590-c037-4170-9a93-a9d0c4468077",
                        "29e06cb4-0ae3-4c7b-863a-d63ced9b1fa2",
                        "2c9d89db-dda3-4003-b73e-6b802f4969fa",
                        "8dacb95e-ec6f-40a8-bc7d-3c5b1a524455",
                        "9a52d630-1ac2-4e04-9951-893fd9350322",
                        "ec8c9e00-d026-4d33-b102-ffd5389234cd",
                        "f006e236-59ad-4647-a59f-4f46dc2c85be",
                        "fdc43e5e-9902-4dd0-86b3-9f30afb57c40"
                    ],
                    "keyword": [
                        "training",
                        "matrix",
                        "scales",
                        "rank",
                        "kernel",
                        "approximate",
                        "techniques",
                        "problem",
                        "optimization",
                        "method"
                    ],
                    "group": [],
                    "_id": "8c0ec27c-e654-4e0e-8c49-9b427117a98e",
                    "abstract": "SVM training is a convex optimization problem which scales with the training set size rather than the feature space dimension. While this is usually considered to be a desired quality, in large scale problems it may cause training to be impractical. The common techniques to handle this difficulty basically build a solution by solving a sequence of small scale subproblems. Our current effort is concentrated on the rank of the kernel matrix as a source for further enhancement of the training procedure. We first show that for a low rank kernel matrix it is possible to design a better interior point method (IPM) in terms of storage requirements as well as computational complexity. We then suggest an efficient use of a known factorization technique to approximate a given kernel matrix by a low rank matrix, which in turn will be used to feed the optimizer. Finally, we derive an upper bound on the change in the objective function value based on the approximation error and the number of active constraints (support vectors). This bound is general in the sense that it holds regardless of the approximation method.",
                    "title": "Efficient svm training using low-rank kernel representations",
                    "venue": "Journal of Machine Learning Research",
                    "year": 2002,
                    "__v": 2,
                    "citationCount": 271,
                    "result": 2.6846469172026977
                },
                "90925435-d33a-4abd-892d-abbe52e547c4": {
                    "authors": [
                        "Chih-Jen Lin"
                    ],
                    "references": [
                        "0cba8ef9-d3db-4ce1-9933-463ed71f5153",
                        "5ffac6f9-2456-42cf-830c-9049ce37c899",
                        "962d4022-ff67-4067-a544-828604d8db52",
                        "a2e5c222-c380-42d7-8846-cbc232f46a69",
                        "b90f9310-726f-4116-9322-6fc01ab598fd",
                        "c1b6b493-01ef-420f-be44-7bacfe34e846"
                    ],
                    "keyword": [
                        "assumptions",
                        "algorithm",
                        "2001",
                        "smo",
                        "shows",
                        "sequential",
                        "optimization",
                        "modified",
                        "minimal",
                        "lin"
                    ],
                    "group": [],
                    "_id": "90925435-d33a-4abd-892d-abbe52e547c4",
                    "abstract": "The asymptotic convergence of C.-J. Lin (2001) can be applied to a modified SMO (sequential minimal optimization) algorithm by S.S. Keerthi et al. (2001) with some assumptions. The author shows that for this algorithm those assumptions are not necessary.",
                    "title": "Asymptotic convergence of an SMO algorithm without any assumptions",
                    "venue": "IEEE Transactions on Neural Networks",
                    "year": 2002,
                    "__v": 2,
                    "citationCount": 63,
                    "result": 3.366729212509612
                },
                "92a420a1-f54b-4cdd-b5a4-2669ac2e7c5d": {
                    "authors": [
                        "Nikolas List",
                        "Hans Ulrich Simon"
                    ],
                    "references": [
                        "0ed949f7-7118-45fa-8a4c-63fcf9f4bd8f",
                        "1258d930-e21d-4214-b635-6c50c7c37512",
                        "1f77802a-50d5-4520-9a1a-07b3b2aceca0",
                        "33184e74-4574-4856-a969-e497fdc2fec8",
                        "394fcdc7-5d9b-4180-9c32-1be37a0c7061",
                        "402c1d45-5bf6-4f7a-806b-10df639f81c6",
                        "591548b3-16de-485d-9ee2-8074c767a0eb",
                        "5ffac6f9-2456-42cf-830c-9049ce37c899",
                        "7f03746d-ba06-4b34-828e-683192e9ee42",
                        "90925435-d33a-4abd-892d-abbe52e547c4",
                        "962d4022-ff67-4067-a544-828604d8db52",
                        "9764de87-e34e-4ea1-8de3-12d9bffc4f55",
                        "97bfd03c-335a-4f39-89d3-cf0a22769383",
                        "a2e5c222-c380-42d7-8846-cbc232f46a69",
                        "a5d347a7-9984-45f4-821e-df7356477185",
                        "b90f9310-726f-4116-9322-6fc01ab598fd",
                        "bcd9b3de-3f73-457d-a000-0776ddf2f9c1",
                        "be003015-ba80-4492-ab82-76b91a70c71e",
                        "c1b6b493-01ef-420f-be44-7bacfe34e846",
                        "f006e236-59ad-4647-a59f-4f46dc2c85be",
                        "f39b7a92-faec-4ecb-8007-e2b53fddee74",
                        "fabaa590-549f-4046-8c32-1650392af7da",
                        "fb6acee9-6dfe-47ef-a8c3-20bbbbb3ff8a"
                    ],
                    "keyword": [
                        "results",
                        "optimization",
                        "rate",
                        "quadratic",
                        "general",
                        "set",
                        "convex",
                        "working",
                        "svmoptimization",
                        "scovel"
                    ],
                    "group": [],
                    "_id": "92a420a1-f54b-4cdd-b5a4-2669ac2e7c5d",
                    "abstract": "We present a general decomposition algorithm that is uniformly applicable to every (suitably normalized) instance of Convex Quadratic Optimization and efficiently approaches an optimal solution. The number of iterations required to be within e of optimality grows linearly with 1/e and quadratically with the number m of variables. The working set selection can be performed in polynomial time. If we restrict our considerations to instances of Convex Quadratic Optimization with at most k0 equality constraints for some fixed constant k0 plus some so-called box-constraints (conditions that hold for most variants of SVM-optimization), the working set is found in linear time. Our analysis builds on a generalization of the concept of rate certifying pairs that was introduced by Hush and Scovel. In order to extend their results to arbitrary instances of Convex Quadratic Optimization, we introduce the general notion of a rate certifying q-set. We improve on the results by Hush and Scovel (2003) in several ways. First our result holds for Convex Quadratic Optimization whereas the results by Hush and Scovel are specialized to SVM-optimization. Second, we achieve a higher rate of convergence even for the special case of SVM-optimization (despite the generality of our approach). Third, our analysis is technically simpler.#R##N##R##N#We prove furthermore that the strategy for working set selection which is based on rate certifying sets coincides with a strategy which is based on a so-called \"sparse witness of sub-optimality\". Viewed from this perspective, our main result improves on convergence results by List and Simon (2004) and Simon (2004) by providing convergence rates (and by holding under more general conditions).",
                    "title": "General Polynomial Time Decomposition Algorithms",
                    "venue": "computational learning theory",
                    "year": 2007,
                    "__v": 2,
                    "citationCount": 14,
                    "result": 7.2580741758626885
                },
                "962d4022-ff67-4067-a544-828604d8db52": {
                    "authors": [
                        "S. Sathiya Keerthi",
                        "Elmer G. Gilbert"
                    ],
                    "references": [
                        "33184e74-4574-4856-a969-e497fdc2fec8",
                        "591548b3-16de-485d-9ee2-8074c767a0eb",
                        "7c6a970a-0d6f-4e4b-b50e-6c6fbd23a9ab",
                        "a2e5c222-c380-42d7-8846-cbc232f46a69",
                        "b90f9310-726f-4116-9322-6fc01ab598fd",
                        "cc0e7eee-4afa-4af7-8db5-ae7c96c89e61",
                        "dd5a3ef5-9d44-4dde-bcdb-dc4d17c69073"
                    ],
                    "keyword": [
                        "svm",
                        "smo",
                        "modified",
                        "convergence",
                        "classifier",
                        "algorithms",
                        "version",
                        "solving",
                        "results",
                        "proved"
                    ],
                    "group": [],
                    "_id": "962d4022-ff67-4067-a544-828604d8db52",
                    "abstract": "Convergence of a generalized version of the modified SMO algorithms given by Keerthi et al. for SVM classifier design is proved. The convergence results are also extended to modified SMO algorithms for solving ν-SVM classifier problems.",
                    "title": "Convergence of a Generalized SMO Algorithm for SVM Classifier Design",
                    "venue": "Machine Learning",
                    "year": 2002,
                    "__v": 2,
                    "citationCount": 94,
                    "result": 6.365426905218194
                },
                "97bfd03c-335a-4f39-89d3-cf0a22769383": {
                    "authors": [
                        "P. Chen",
                        "Rong-En Fan",
                        "Chih-Jen Lin"
                    ],
                    "references": [
                        "1f77802a-50d5-4520-9a1a-07b3b2aceca0",
                        "33184e74-4574-4856-a969-e497fdc2fec8",
                        "4317334f-595f-45be-a095-efe8f258b558",
                        "4b9b83f6-c076-4545-ad56-0bb0d0b95509",
                        "4bbd7777-9751-415d-bb7a-6ce26f6d9271",
                        "50dd56db-151d-4d62-8576-65f0ef6f381b",
                        "5ffac6f9-2456-42cf-830c-9049ce37c899",
                        "7c6a970a-0d6f-4e4b-b50e-6c6fbd23a9ab",
                        "90925435-d33a-4abd-892d-abbe52e547c4",
                        "93b5a3ee-a59b-42f1-9b62-8811c4a64c74",
                        "962d4022-ff67-4067-a544-828604d8db52",
                        "9764de87-e34e-4ea1-8de3-12d9bffc4f55",
                        "a2e5c222-c380-42d7-8846-cbc232f46a69",
                        "a5d347a7-9984-45f4-821e-df7356477185",
                        "b90f9310-726f-4116-9322-6fc01ab598fd",
                        "c1b6b493-01ef-420f-be44-7bacfe34e846",
                        "dd5a3ef5-9d44-4dde-bcdb-dc4d17c69073",
                        "f006e236-59ad-4647-a59f-4f46dc2c85be"
                    ],
                    "keyword": [
                        "methods",
                        "working",
                        "vector",
                        "support",
                        "set",
                        "selections",
                        "machines",
                        "general",
                        "decomposition",
                        "convergence"
                    ],
                    "group": [],
                    "_id": "97bfd03c-335a-4f39-89d3-cf0a22769383",
                    "abstract": "Decomposition methods are currently one of the major methods for training support vector machines. They vary mainly according to different working set selections. Existing implementations and analysis usually consider some specific selection rules. This paper studies sequential minimal optimization type decomposition methods under a general and flexible way of choosing the two-element working set. The main results include: 1) a simple asymptotic convergence proof, 2) a general explanation of the shrinking and caching techniques, and 3) the linear convergence of the methods. Extensions to some support vector machine variants are also discussed.",
                    "title": "A study on SMO-type decomposition methods for support vector machines",
                    "venue": "IEEE Transactions on Neural Networks",
                    "year": 2006,
                    "__v": 2,
                    "citationCount": 91,
                    "result": 10.303101959841044
                },
                "a2e5c222-c380-42d7-8846-cbc232f46a69": {
                    "authors": [
                        "Chih-Jen Lin"
                    ],
                    "references": [
                        "01b486c4-8955-403b-a0c6-1de74298b215",
                        "05fce530-0e1b-48a4-bf15-7c804c753640",
                        "0cba8ef9-d3db-4ce1-9933-463ed71f5153",
                        "0ed949f7-7118-45fa-8a4c-63fcf9f4bd8f",
                        "2190c590-c037-4170-9a93-a9d0c4468077",
                        "33184e74-4574-4856-a969-e497fdc2fec8",
                        "402c1d45-5bf6-4f7a-806b-10df639f81c6",
                        "50dd56db-151d-4d62-8576-65f0ef6f381b",
                        "591548b3-16de-485d-9ee2-8074c767a0eb",
                        "5ffac6f9-2456-42cf-830c-9049ce37c899",
                        "7c6a970a-0d6f-4e4b-b50e-6c6fbd23a9ab",
                        "7f03746d-ba06-4b34-828e-683192e9ee42",
                        "962d4022-ff67-4067-a544-828604d8db52",
                        "b90f9310-726f-4116-9322-6fc01ab598fd",
                        "c1b6b493-01ef-420f-be44-7bacfe34e846",
                        "dd5a3ef5-9d44-4dde-bcdb-dc4d17c69073",
                        "ef3d9941-f114-416a-8691-ea739d62ea68"
                    ],
                    "keyword": [
                        "convergence",
                        "working",
                        "set",
                        "svm",
                        "size",
                        "proved",
                        "method",
                        "implementation",
                        "asymptotic"
                    ],
                    "group": [],
                    "_id": "a2e5c222-c380-42d7-8846-cbc232f46a69",
                    "abstract": "The decomposition method is currently one of the major methods for solving support vector machines (SVM). Its convergence properties have not been fully understood. The general asymptotic convergence was first proposed by Chang et al. However, their working set selection does not coincide with existing implementation. A later breakthrough by Keerthi and Gilbert (2000, 2002) proved the convergence finite termination for practical cases while the size of the working set is restricted to two. In this paper, we prove the asymptotic convergence of the algorithm used by the software SVM/sup light/ and other later implementation. The size of the working set can be any even number. Extensions to other SVM formulations are also discussed.",
                    "title": "On the convergence of the decomposition method for support vector machines",
                    "venue": "IEEE Transactions on Neural Networks",
                    "year": 2001,
                    "__v": 1,
                    "citationCount": 95,
                    "result": 7.810992059703888
                },
                "a5d347a7-9984-45f4-821e-df7356477185": {
                    "authors": [
                        "Chih-Jen Lin"
                    ],
                    "references": [
                        "50dd56db-151d-4d62-8576-65f0ef6f381b",
                        "5ffac6f9-2456-42cf-830c-9049ce37c899",
                        "90925435-d33a-4abd-892d-abbe52e547c4",
                        "962d4022-ff67-4067-a544-828604d8db52",
                        "a2e5c222-c380-42d7-8846-cbc232f46a69",
                        "c1b6b493-01ef-420f-be44-7bacfe34e846",
                        "cf93558f-c1b2-4292-8284-1be8d4316af1",
                        "dd5a3ef5-9d44-4dde-bcdb-dc4d17c69073",
                        "feff8862-f47d-4591-a7cb-b62d7efc81a2"
                    ],
                    "keyword": [
                        "proved",
                        "method",
                        "decomposition",
                        "convergence",
                        "svm",
                        "support",
                        "stopping",
                        "result",
                        "paper",
                        "multiclass"
                    ],
                    "group": [],
                    "_id": "a5d347a7-9984-45f4-821e-df7356477185",
                    "abstract": "In a previous paper, the author (2001) proved the convergence of a commonly used decomposition method for support vector machines (SVMs). However, there is no theoretical justification about its stopping criterion, which is based on the gap of the violation of the optimality condition. It is essential to have the gap asymptotically approach zero, so we are sure that existing implementations stop in a finite number of iterations after reaching a specified tolerance. Here, we prove this result and illustrate it by two extensions: /spl nu/-SVM and a multiclass SVM by Crammer and Singer (2001). A further result shows that, in final iterations of the decomposition method, only a particular set of variables are still being modified. This supports the use of the shrinking and caching techniques in some existing implementations. Finally, we prove the asymptotic convergence of a decomposition method for this multiclass SVM. Discussions on the difference between this convergence proof and the one in another paper by Lin are also included.",
                    "title": "A formal analysis of stopping criteria of decomposition methods for support vector machines",
                    "venue": "IEEE Transactions on Neural Networks",
                    "year": 2002,
                    "__v": 2,
                    "citationCount": 44,
                    "result": 7.539765900860701
                },
                "b532d930-ad51-4a05-9c5c-9a75d6b021a2": {
                    "authors": [
                        "Hsuan-Tien Lin",
                        "Chih-Jen Lin",
                        "Ruby C. Weng"
                    ],
                    "references": [
                        "c1b6b493-01ef-420f-be44-7bacfe34e846",
                        "f4fdd596-0dc6-4c3d-80ae-fda72729d228"
                    ],
                    "keyword": [
                        "platt's",
                        "vector",
                        "theoretically",
                        "support",
                        "smola",
                        "simple",
                        "require",
                        "readytouse",
                        "pseudo",
                        "propose"
                    ],
                    "group": [],
                    "_id": "b532d930-ad51-4a05-9c5c-9a75d6b021a2",
                    "abstract": "Platt's probabilistic outputs for Support Vector Machines (Platt, J. in Smola, A., et al. (eds.) Advances in large margin classifiers. Cambridge, 2000) has been popular for applications that require posterior class probabilities. In this note, we propose an improved algorithm that theoretically converges and avoids numerical difficulties. A simple and ready-to-use pseudo code is included.",
                    "title": "A note on Platt's probabilistic outputs for support vector machines",
                    "venue": "Machine Learning",
                    "year": 2007,
                    "__v": 1,
                    "citationCount": 327,
                    "result": 3.847702091510141
                },
                "b90f9310-726f-4116-9322-6fc01ab598fd": {
                    "authors": [
                        "S. Sathiya Keerthi",
                        "Shirish Krishnaj Shevade",
                        "Chiranjib Bhattacharyya",
                        "K. R. K. Murthy"
                    ],
                    "references": [
                        "0ed949f7-7118-45fa-8a4c-63fcf9f4bd8f",
                        "1f888552-7aec-43bc-80c7-60a791479e8a",
                        "91979159-37d8-410f-a245-a33ef80a092b",
                        "ebea33c6-68f6-450d-9d79-65507040d3cf"
                    ],
                    "keyword": [
                        "smo",
                        "threshold",
                        "algorithm",
                        "source",
                        "single",
                        "significantly",
                        "sets",
                        "sequential",
                        "problem",
                        "points"
                    ],
                    "group": [],
                    "_id": "b90f9310-726f-4116-9322-6fc01ab598fd",
                    "abstract": "This article points out an important source of inefficiency in Platt's sequential minimal optimization (SMO) algorithm that is caused by the use of a single threshold value. Using clues from the KKT conditions for the dual problem, two threshold parameters are employed to derive modifications of SMO. These modified algorithms perform significantly faster than the original SMO on all benchmark data sets tried.",
                    "title": "Improvements to Platt's SMO Algorithm for SVM Classifier Design",
                    "venue": "Neural Computation",
                    "year": 2001,
                    "__v": 2,
                    "citationCount": 609,
                    "result": 2.384041689304847
                },
                "bb693c93-e418-46ea-8b38-9c53df27bdf2": {
                    "authors": [
                        "Kevin C. Dorff",
                        "Nyasha Chambwe",
                        "Marko Srdanovic",
                        "Fabien Campagne"
                    ],
                    "references": [
                        "979571db-2734-4035-9f3a-e820347fa315",
                        "9fa61eb1-0984-4492-955a-4f7aedbdc368"
                    ],
                    "keyword": [
                        "models",
                        "predictive",
                        "datasets",
                        "construction",
                        "programs",
                        "process",
                        "develop",
                        "data",
                        "bdval",
                        "automating"
                    ],
                    "group": [],
                    "_id": "bb693c93-e418-46ea-8b38-9c53df27bdf2",
                    "abstract": "Summary: High-throughput data can be used in conjunction with clinical information to develop predictive models. Automating the process of developing, evaluating and testing such predictive models on different datasets would minimize operator errors and facilitate the comparison of different modeling approaches on the same dataset. Complete automation would also yield unambiguous documentation of the process followed to develop each model. We present the BDVal suite of programs that fully automate the construction of predictive classification models from high-throughput data and generate detailed reports about the model construction process. We have used BDVal to construct models from microarray and proteomics data, as well as from DNA-methylation datasets. The programs are designed for scalability and support the construction of thousands of alternative models from a given dataset and prediction task.#R##N##R##N#Availability and Implementation: The BDVal programs are implemented in Java, provided under the GNU General Public License and freely available at http://bdval.campagnelab.org#R##N##R##N#Contact: ude.llenroc.dem@3002caf",
                    "title": "BDVal: reproducible large-scale predictive model development and validation in high-throughput datasets",
                    "venue": "Bioinformatics",
                    "year": 2010,
                    "__v": 2,
                    "citationCount": 2,
                    "result": 3.8302886569914434
                },
                "cdbd2ef9-d4b1-4dff-9037-3ea84627424d": {
                    "authors": [
                        "John Platt",
                        "Nello Cristianini",
                        "John Shawe-Taylor"
                    ],
                    "references": [
                        "5ee879b9-9364-4d66-a1b4-41b9ad487485",
                        "b0159e1d-cce3-47f8-86c4-23fe0d21f32e"
                    ],
                    "keyword": [
                        "classifiers",
                        "ddag",
                        "algorithm",
                        "twoclass",
                        "space",
                        "present",
                        "node",
                        "margin",
                        "hyperplanes",
                        "dagsvm"
                    ],
                    "group": [],
                    "_id": "cdbd2ef9-d4b1-4dff-9037-3ea84627424d",
                    "abstract": "We present a new learning architecture: the Decision Directed Acyclic Graph (DDAG), which is used to combine many two-class classifiers into a multiclass classifier. For an N-class problem, the DDAG contains N(N - 1)/2 classifiers, one for each pair of classes. We present a VC analysis of the case when the node classifiers are hyperplanes; the resulting bound on the test error depends on N and on the margin achieved at the nodes, but not on the dimension of the space. This motivates an algorithm, DAGSVM, which operates in a kernel-induced feature space and uses two-class maximal margin hyperplanes at each decision-node of the DDAG. The DAGSVM is substantially faster to train and evaluate than either the standard algorithm or Max Wins, while maintaining comparable accuracy to both of these algorithms.",
                    "title": "Large Margin DAGs for Multiclass Classification",
                    "venue": "neural information processing systems",
                    "year": 2000,
                    "__v": 2,
                    "citationCount": 618,
                    "result": 4.422026829379771
                },
                "dd5a3ef5-9d44-4dde-bcdb-dc4d17c69073": {
                    "authors": [
                        "Bernhard Schölkopf",
                        "Alexander J. Smola",
                        "Robert C. Williamson",
                        "Peter L. Bartlett"
                    ],
                    "references": [
                        "049edc28-e3d9-4855-bd54-9a2b9f534502",
                        "09ddc504-bc30-4a5e-b29f-09644e174375",
                        "24627c32-96e9-4f6d-8193-059b20e2f57e",
                        "29e06cb4-0ae3-4c7b-863a-d63ced9b1fa2",
                        "2cbdd97b-393f-4def-b945-b0694dea2db8",
                        "3e2664f4-109e-4b0b-b86f-2e7a26b241cf",
                        "45c5de6e-c600-4ed4-af53-e9f29f6286dc",
                        "50dd56db-151d-4d62-8576-65f0ef6f381b",
                        "549f0527-0f13-4447-9dc0-ca699e2dc219",
                        "7c6a970a-0d6f-4e4b-b50e-6c6fbd23a9ab",
                        "8656626a-3247-42f0-8d96-4661709b62f1",
                        "87969fc2-8332-4ee5-b6b0-e1b26d01ebd4",
                        "91979159-37d8-410f-a245-a33ef80a092b",
                        "94898e1d-1e50-41ab-9dcc-2c2e030cddd0",
                        "a2e5c222-c380-42d7-8846-cbc232f46a69",
                        "b25d230c-cf98-48d6-a351-a208f7c9ee07",
                        "b49b6e49-b084-4255-96f8-09c1de7bc1d2",
                        "c1f94cf8-05cf-4c5f-a8cf-c13cb0d618eb",
                        "c2fa09e5-7373-41b0-be44-10557724d064",
                        "c3464e8d-25d3-43b3-b786-19f9eb7700ab",
                        "c358ee37-4afb-4603-9b65-59d2536d0866",
                        "cb4fbf1c-02e4-4ca9-995d-29f5282fdb4a",
                        "d9b4e383-db58-4760-8292-c390cdf5a86b",
                        "dab15bfb-fb2c-4cc4-b6f0-6fb7d19a73c2",
                        "ef781e5f-5519-4a20-93fc-25f7d14039a1",
                        "f006e236-59ad-4647-a59f-4f46dc2c85be",
                        "f6c418d7-c420-492f-8d24-de3827674b93"
                    ],
                    "keyword": [
                        "algorithms",
                        "parameter",
                        "vector",
                        "support",
                        "results",
                        "regression",
                        "classification",
                        "case",
                        "theoretical",
                        "report"
                    ],
                    "group": [],
                    "_id": "dd5a3ef5-9d44-4dde-bcdb-dc4d17c69073",
                    "abstract": "We propose a new class of support vector algorithms for regression and classification. In these algorithms, a parameter ν lets one effectively control the number of support vectors. While this can be useful in its own right, the parameterization has the additional benefit of enabling us to eliminate one of the other free parameters of the algorithm: the accuracy parameter epsilon in the regression case, and the regularization constant C in the classification case. We describe the algorithms, give some theoretical results concerning the meaning and the choice of ν, and report experimental results.",
                    "title": "New Support Vector Algorithms",
                    "venue": "Neural Computation",
                    "year": 2000,
                    "__v": 2,
                    "citationCount": 781,
                    "result": 6.981767562158946
                },
                "feff8862-f47d-4591-a7cb-b62d7efc81a2": {
                    "authors": [
                        "Chih-Wei Hsu",
                        "Chih-Jen Lin"
                    ],
                    "references": [
                        "0ed949f7-7118-45fa-8a4c-63fcf9f4bd8f",
                        "1e37aa02-2911-45db-867f-bc2043492c08",
                        "2190c590-c037-4170-9a93-a9d0c4468077",
                        "50dd56db-151d-4d62-8576-65f0ef6f381b",
                        "5ffac6f9-2456-42cf-830c-9049ce37c899",
                        "7f03746d-ba06-4b34-828e-683192e9ee42",
                        "a5d347a7-9984-45f4-821e-df7356477185",
                        "c5d59aca-dd59-4640-a80b-e7e585430b54",
                        "f33acc76-f25e-446f-a834-9d898907b326"
                    ],
                    "keyword": [
                        "methods",
                        "problems",
                        "multiclass",
                        "classification",
                        "binary",
                        "vector",
                        "svm",
                        "support",
                        "solve",
                        "proposed"
                    ],
                    "group": [],
                    "_id": "feff8862-f47d-4591-a7cb-b62d7efc81a2",
                    "abstract": "Support vector machines (SVMs) were originally designed for binary classification. How to effectively extend it for multiclass classification is still an ongoing research issue. Several methods have been proposed where typically we construct a multiclass classifier by combining several binary classifiers. Some authors also proposed methods that consider all classes at once. As it is computationally more expensive to solve multiclass problems, comparisons of these methods using large-scale problems have not been seriously conducted. Especially for methods solving multiclass SVM in one step, a much larger optimization problem is required so up to now experiments are limited to small data sets. In this paper we give decomposition implementations for two such \"all-together\" methods. We then compare their performance with three methods based on binary classifications: \"one-against-all,\" \"one-against-one,\" and directed acyclic graph SVM (DAGSVM). Our experiments indicate that the \"one-against-one\" and DAG methods are more suitable for practical use than the other methods. Results also show that for large problems methods by considering all data at once in general need fewer support vectors.",
                    "title": "A comparison of methods for multiclass support vector machines",
                    "venue": "IEEE Transactions on Neural Networks",
                    "year": 2002,
                    "__v": 2,
                    "citationCount": 1836,
                    "result": 7.099660049788276
                }
            }
        ],
        "_id": "c1b6b493-01ef-420f-be44-7bacfe34e846",
        "abstract": "LIBSVM is a library for Support Vector Machines (SVMs). We have been actively developing this package since the year 2000. The goal is to help users to easily apply SVM to their applications. LIBSVM has gained wide popularity in machine learning and many other areas. In this article, we present all implementation details of LIBSVM. Issues such as solving SVM optimization problems theoretical convergence multiclass classification probability estimates and parameter selection are discussed in detail.",
        "title": "LIBSVM: A library for support vector machines",
        "venue": "ACM Transactions on Intelligent Systems and Technology",
        "year": 2011,
        "__v": 3,
        "citationCount": 13475
    },
    {
        "authors": [
            "Martin Fowler"
        ],
        "references": [
            "7ba63bd0-be52-4311-831a-532f1554b1d6",
            "834ebcdf-ba30-4aaa-ad45-fdd4dfb3c169",
            "a60f5b27-99de-4929-af9e-12e767026d60",
            "a8e9ece1-977d-4a0b-bf9f-9158478c24e7",
            "bcfa87fb-47c7-43c2-94c4-ffda08ecc9b7",
            "ff8ef2b7-6bb3-43eb-9c48-d3d35a173e3f"
        ],
        "keyword": [
            "code",
            "function",
            "development",
            "base",
            "patch",
            "lucky",
            "leads",
            "iterative",
            "complex",
            "add"
        ],
        "group": [
            {
                "7ba63bd0-be52-4311-831a-532f1554b1d6": {
                    "authors": [
                        "Ralph E. Johnson",
                        "William F. Opdyke"
                    ],
                    "references": [
                        "254e1e95-9d17-477c-8be0-b07228bee8f9",
                        "41f467ce-6d48-4750-8522-414d68f697fc",
                        "5b55e079-5a57-4f49-b9a9-e328f3049d7e",
                        "631b6e0c-d048-40ba-bb79-75f92679948b",
                        "79b15730-feb1-4d01-9d19-98af0a324e32",
                        "834ebcdf-ba30-4aaa-ad45-fdd4dfb3c169",
                        "8780915a-cf08-4b7e-8336-27470235c93d",
                        "97f5044f-91f4-4cf8-be59-5f2ebf1d8335",
                        "9d84acca-20f2-41d1-844c-1b223a7f2eda",
                        "b6cfbe21-5bf7-4a0b-bf42-5d66ab566518",
                        "bcfa87fb-47c7-43c2-94c4-ffda08ecc9b7",
                        "c03f7308-b4ec-45d2-97a5-eb639f417b09",
                        "c540b2df-6ebe-4314-b5aa-7acc96044ef9",
                        "e65d1b23-a595-4a2e-acb1-57a138d08ef1"
                    ],
                    "keyword": [],
                    "group": [],
                    "_id": "7ba63bd0-be52-4311-831a-532f1554b1d6",
                    "title": "Refactoring and Aggregation",
                    "venue": "",
                    "year": 1993,
                    "abstract": "",
                    "__v": 0,
                    "citationCount": 41,
                    "result": 3.333333333333333
                },
                "834ebcdf-ba30-4aaa-ad45-fdd4dfb3c169": {
                    "authors": [
                        "William F. Opdyke",
                        "Ralph E. Johnson"
                    ],
                    "references": [
                        "16f41e20-71ee-4131-83ba-cc488aca930f",
                        "1f5543df-bdf2-41ed-b969-7389afd94455",
                        "254e1e95-9d17-477c-8be0-b07228bee8f9",
                        "33dd7ce8-453e-4824-b700-6d29d69d5502",
                        "5ae56b47-af4a-4b80-93e7-79c16f179423",
                        "5b55e079-5a57-4f49-b9a9-e328f3049d7e",
                        "73e7debb-b80e-4332-b3b2-eddea02596a7",
                        "9373b0cd-a177-4605-87f5-f54559c494c2",
                        "b6cfbe21-5bf7-4a0b-bf42-5d66ab566518",
                        "bcfa87fb-47c7-43c2-94c4-ffda08ecc9b7",
                        "c540b2df-6ebe-4314-b5aa-7acc96044ef9"
                    ],
                    "keyword": [
                        "refactoring",
                        "superclasses",
                        "steps",
                        "satisfied",
                        "programming",
                        "objectoriented",
                        "finding",
                        "conditions",
                        "abstract",
                        "unique"
                    ],
                    "group": [],
                    "_id": "834ebcdf-ba30-4aaa-ad45-fdd4dfb3c169",
                    "abstract": "This paper focuses on object-oriented programming and one kind of structure-improving transformation (refactoring) that is unique to object-oriented programming: finding abstract superclasses. We decompose the operation of finding an abstract superclass into a set of refactoring steps, and provide examples. We discuss techniques that can automate or automatically support these steps. We also consider some of the conditions that must be satisfied to perform a refactoring safely; sometimes to satisfy these conditions other refactorings must first be applied.",
                    "title": "Creating abstract superclasses by refactoring",
                    "venue": "conference on scientific computing",
                    "year": 1993,
                    "__v": 1,
                    "citationCount": 56,
                    "result": 4.725371346097554
                },
                "a8e9ece1-977d-4a0b-bf9f-9158478c24e7": {
                    "authors": [
                        "Karl J. Lieberherr",
                        "Ian M. Holland"
                    ],
                    "references": [
                        "0ab2a3f8-b8cd-4d1f-a226-eb7ccccb5c40",
                        "133982df-1fe4-40f3-8d8d-fe65cffbad99",
                        "89dd6af2-1227-430f-8337-bdc0693929c8",
                        "f3e432c5-9751-4529-985e-36e5447074a5",
                        "f3e8d865-49d5-4921-8d50-95cefdef4fc6"
                    ],
                    "keyword": [
                        "law",
                        "information",
                        "form",
                        "system",
                        "objectoriented",
                        "modularity",
                        "demeter"
                    ],
                    "group": [],
                    "_id": "a8e9ece1-977d-4a0b-bf9f-9158478c24e7",
                    "abstract": "The language-independent Law of Demeter, which encodes the ideas of encapsulation and modularity in an easy-to-follow form for object-oriented programmers, is presented. The law was developed during the design and implementation of the Demeter system, which provides a high-level interface to class-based, object-oriented systems. Two forms of the law, the class and object forms, are described. Its motivation is to ensure that the software is as modular as possible. Principles covered by the law include coupling control, information hiding, information restriction, information localization, and structured induction. An example is given to show how the law is applied, and valid violations are identified. It is shown how to transform a method that does not satisfy the law into one that does. >",
                    "title": "Assuring good style for object-oriented programs",
                    "venue": "IEEE Software",
                    "year": 1989,
                    "__v": 1,
                    "citationCount": 84,
                    "result": 2.2832680675391672
                },
                "bcfa87fb-47c7-43c2-94c4-ffda08ecc9b7": {
                    "authors": [
                        "Jay Banerjee",
                        "Won Kim",
                        "Hyoung-Joo Kim",
                        "Henry F. Korth"
                    ],
                    "references": [
                        "50689679-8346-48f2-8d70-4dfd29f8b470",
                        "59333583-92f3-49c8-95fc-12c17003f75d",
                        "7431d295-c57d-4813-80d8-55ccb6d677ec",
                        "8cd7f12b-af69-4535-8bf3-ab3054d64ff8",
                        "e3ba6428-74ba-41c2-9bd7-148a2c6308a8",
                        "f99c3014-e522-426d-b9c2-22d3d3bb2697"
                    ],
                    "keyword": [
                        "schema",
                        "objectoriented",
                        "evolution",
                        "application",
                        "systems",
                        "support",
                        "programming",
                        "orion",
                        "implemented",
                        "database"
                    ],
                    "group": [],
                    "_id": "bcfa87fb-47c7-43c2-94c4-ffda08ecc9b7",
                    "abstract": "Object-oriented programming is well-suited to such data-intensive application domains as CAD/CAM, AI, and OIS (office information systems) with multimedia documents. At MCC we have built a prototype object-oriented database system, called ORION. It adds persistence and sharability to objects created and manipulated in applications implemented in an object-oriented programming environment. One of the important requirements of these applications is schema evolution, that is, the ability to dynamically make a wide variety of changes to the database schema. In this paper, following a brief review of the object-oriented data model that we support in ORION, we establish a framework for supporting schema evolution, define the semantics of schema evolution, and discuss its implementation.",
                    "title": "Semantics and implementation of schema evolution in object-oriented databases",
                    "venue": "international conference on management of data",
                    "year": 1987,
                    "__v": 2,
                    "citationCount": 354,
                    "result": 4.698896066990696
                },
                "ff8ef2b7-6bb3-43eb-9c48-d3d35a173e3f": {
                    "authors": [
                        "Don Roberts",
                        "John Brant",
                        "Ralph E. Johnson"
                    ],
                    "references": [
                        "1bbae953-0819-4353-9640-9a0855a1fc3f",
                        "4061e35e-77bd-4c1e-b6ad-c8af83b193a7",
                        "7ba63bd0-be52-4311-831a-532f1554b1d6",
                        "834ebcdf-ba30-4aaa-ad45-fdd4dfb3c169",
                        "9d84acca-20f2-41d1-844c-1b223a7f2eda",
                        "a60f5b27-99de-4929-af9e-12e767026d60",
                        "e65d1b23-a595-4a2e-acb1-57a138d08ef1"
                    ],
                    "keyword": [
                        "refactor",
                        "program",
                        "tool",
                        "software",
                        "smalltalk",
                        "reusable",
                        "important"
                    ],
                    "group": [],
                    "_id": "ff8ef2b7-6bb3-43eb-9c48-d3d35a173e3f",
                    "abstract": "Abstract#R##N##R##N#Refactoring is an important part of the evolution of reusable software and frameworks. Its uses range from the seemingly trivial, such as renaming program elements, to the profound, such as retrofitting design patterns into an existing system. Despite its importance, lack of tool support forces programmers to refactor programs by hand, which can be tedious and error-prone. The Smalltalk Refactoring Browser is a tool that carries out many refactorings automatically, and provides an environment for improving the structure of Smalltalk programs. It makes refactoring safe and simple, and so reduces the cost of making reusable software. © 1997 John Wiley & Sons, Inc.",
                    "title": "A refactoring tool for Smalltalk",
                    "venue": "Theory and Practice of Object Systems",
                    "year": 1997,
                    "__v": 2,
                    "citationCount": 183,
                    "result": 5.875346875346875
                }
            }
        ],
        "_id": "c28cf51b-79cf-4b24-9234-8b304f11e6ca",
        "abstract": "Almost every expert in Object-Oriented Development stresses the importance of iterative development. As you proceed with the iterative development, you need to add function to the existing code base. If you are really lucky that code base is structured just right to support the new function while still preserving its design integrity. Of course most of the time we are not lucky, the code does not quite fit what we want to do. You could just add the function on top of the code base. But soon this leads to applying patch upon patch making your system more complex than it needs to be. This complexity leads to bugs, and cripples your productivity.",
        "title": "Refactoring: Improving the Design of Existing Code",
        "venue": "",
        "year": 2002,
        "__v": 2,
        "citationCount": 2179
    },
    {
        "authors": [
            "Ian T. Foster",
            "Carl Kesselman",
            "Steven Tuecke"
        ],
        "references": [
            "00231608-2174-4478-8bc4-5e8705c6a104",
            "08e02aa6-3ef9-4b25-8de6-a42ca9a60577",
            "0e99f68d-e44d-4108-8ddb-1df090a2aaae",
            "0f267b92-aac1-476b-be8f-cdd929149783",
            "18831dc8-e399-499d-8da1-a7befe5d7055",
            "30fe84b9-cc5e-4951-a21b-662ab3291aec",
            "3f7f755b-cc31-437d-8e73-9d7ce711d33a",
            "432a75f0-4a68-4700-954b-56a8eb920dab",
            "441d7697-8548-4ee5-8f6d-2765c8492b7a",
            "522a0bfa-5b9d-42dd-a0fb-86743493a164",
            "68414a1e-11d6-4d1e-bff0-eef3f924a691",
            "698fc1a5-7700-4108-9957-530e0da64595",
            "6cec07de-4318-4168-954f-38246a885091",
            "73443d97-5346-428a-847c-7a9e05b12ce7",
            "740d054f-67e6-4e6e-a54d-f09e4ab41bb7",
            "8dedecd2-47b1-4229-a0b4-7d26d6561921",
            "9553fde5-7523-4944-abb2-ce12a6d02afc",
            "9cdc54f0-f1a0-4422-ac16-d9164d9371ee",
            "9e7f1ba6-2e03-49ee-9c8f-8accc6473d3d",
            "acb72100-1da2-4585-aa35-df61f39014e0",
            "b6457b57-76f8-4d6e-afdd-594864aef737",
            "bf4c5985-8390-434e-945d-c02f65e688da",
            "c0ea675b-2479-48ae-817e-3ecedd175ecf",
            "c8311815-4163-4e5c-8a25-c4a3205cb6d9",
            "d0811c1c-0eb1-4112-8dc1-1e33e795f7af",
            "db413eda-50e9-479a-9dd1-033f4e1d5ab8",
            "e593759c-0dd4-4e2f-9fde-40d6a64a521c",
            "e9065010-fc6a-4170-8087-7c99eaa84b4c",
            "eaa13a22-26c7-4b6c-bd02-2fe23a5f62a4",
            "fd48b87f-50a1-40c0-95e5-749fa5022bb9"
        ],
        "keyword": [
            "grid",
            "resource",
            "authors",
            "technologies",
            "sharing",
            "services",
            "define",
            "computing",
            "applications"
        ],
        "group": [
            {
                "08e02aa6-3ef9-4b25-8de6-a42ca9a60577": {
                    "authors": [
                        "James S. Frey",
                        "Todd Tannenbaum",
                        "Miron Livny",
                        "Ian T. Foster",
                        "Steven Tuecke"
                    ],
                    "references": [
                        "02010d4e-8bd5-48f0-be44-44e71c35f8ed",
                        "18831dc8-e399-499d-8da1-a7befe5d7055",
                        "32302597-c054-4beb-b0fe-64128eca4d8e",
                        "493fd722-ed06-4a05-a44d-0fd76cfcacbd",
                        "522a0bfa-5b9d-42dd-a0fb-86743493a164",
                        "740d054f-67e6-4e6e-a54d-f09e4ab41bb7",
                        "8691f268-70fe-471d-9745-b2a07b222af8",
                        "9553fde5-7523-4944-abb2-ce12a6d02afc",
                        "9810d6f5-6935-43fb-8438-282ef53b3a5b",
                        "9cdc54f0-f1a0-4422-ac16-d9164d9371ee",
                        "b6457b57-76f8-4d6e-afdd-594864aef737",
                        "c2616a84-7e61-4805-a038-be2817406a42",
                        "c2f67467-3138-4d37-a743-10340dc3ea44",
                        "c49a3831-68ed-4800-8cfa-88baa6f15df3",
                        "c8311815-4163-4e5c-8a25-c4a3205cb6d9",
                        "d0811c1c-0eb1-4112-8dc1-1e33e795f7af",
                        "fd48b87f-50a1-40c0-95e5-749fa5022bb9"
                    ],
                    "keyword": [],
                    "group": [],
                    "_id": "08e02aa6-3ef9-4b25-8de6-a42ca9a60577",
                    "abstract": "In recent years, there has been a dramatic increase in the number of available computing and storage resources. Yet few tools exist that allow these resources to be exploited effectively in an aggregated form. We present the Condor-G system, which leverages software from Globus and Condor to enable users to harness multi-domain resources as if they all belong to one personal domain. We describe the structure of Condor-G and how it handles job management, resource selection, security, and fault tolerance. We also present results from application experiments with the Condor-G system. We assert that Condor-G can serve as a general-purpose interface to Grid resources, for use by both end users and higher-level program development tools.",
                    "title": "Condor-G: A Computation Management Agent for Multi-Institutional Grids",
                    "venue": "Cluster Computing",
                    "year": 2002,
                    "__v": 0,
                    "citationCount": 661,
                    "result": 3
                },
                "522a0bfa-5b9d-42dd-a0fb-86743493a164": {
                    "authors": [
                        "Richard L. Stevens",
                        "Paul R. Woodward",
                        "Thomas A. DeFanti",
                        "Charles E. Catlett"
                    ],
                    "references": [
                        "32302597-c054-4beb-b0fe-64128eca4d8e",
                        "36c05ec1-7f89-44d4-a180-49820c36e4a0",
                        "43929afa-45e7-429f-8769-cb8699dc63b7",
                        "b7aff680-9ef4-44af-ab5b-b8ae8ae42c76",
                        "e7a43415-494f-4660-aed5-86f52cca3598"
                    ],
                    "keyword": [
                        "world",
                        "wide",
                        "web",
                        "transformation",
                        "tool",
                        "science",
                        "promote",
                        "powerful",
                        "internet",
                        "'grid"
                    ],
                    "group": [],
                    "_id": "522a0bfa-5b9d-42dd-a0fb-86743493a164",
                    "abstract": "The authors promote the transformation of the Internet and the World Wide Web into a powerful tool for advancing computer science and engineering, which they call the 'Grid.'",
                    "title": "From the I-WAY to the National Technology Grid",
                    "venue": "Communications of The ACM",
                    "year": 1997,
                    "__v": 1,
                    "citationCount": 29,
                    "result": 4.303683038667559
                },
                "68414a1e-11d6-4d1e-bff0-eef3f924a691": {
                    "authors": [
                        "Richard Wolski"
                    ],
                    "references": [
                        "09024120-ea26-415c-8ef9-d6d3c355f6bf",
                        "12fd0e5f-adf6-4d18-a425-d6d025f3442a",
                        "1357648a-cb58-4495-a672-a77cea4e47ee",
                        "16277fbe-9ef0-4629-a66f-72612d0ba35f",
                        "2222f1f9-b357-45ef-8943-ae096e660c5f",
                        "4edfb968-76e6-45c7-a02d-a7b2d9f1bc31",
                        "7d371899-f6a5-4e16-8365-835827db041e",
                        "b7aff680-9ef4-44af-ab5b-b8ae8ae42c76",
                        "c82d6f8e-5ad6-4317-af5a-86d4b6bcf225",
                        "c94a3952-f1f2-4a1e-9254-96f195ca7e5b",
                        "d0811c1c-0eb1-4112-8dc1-1e33e795f7af",
                        "d879d9a0-4185-48d3-9a7c-e6ba36d5c89b"
                    ],
                    "keyword": [
                        "forecasts",
                        "predictive",
                        "performance",
                        "network",
                        "metacomputing",
                        "designed",
                        "weather",
                        "throughput",
                        "tcpip",
                        "systems"
                    ],
                    "group": [],
                    "_id": "68414a1e-11d6-4d1e-bff0-eef3f924a691",
                    "abstract": "The Network Weather Service is a generalizable and extensible facility designed to provide dynamic resource performance forecasts in metacomputing environments. In this paper, we outline its design and detail the predictive performance of the forecasts it generates. While the forecasting methods are general, we focus on their ability to predict the TCP/IP end-to-end throughput and latency that is attainable by an application using systems located at different sites. Such network forecasts are needed both to support scheduling, and by the metacomputing software infrastructure to develop quality-of-service guarantees.",
                    "title": "Forecasting network performance to support dynamic scheduling using the network weather service",
                    "venue": "high performance distributed computing",
                    "year": 1997,
                    "__v": 2,
                    "citationCount": 128,
                    "result": 5.4649865756205775
                },
                "698fc1a5-7700-4108-9957-530e0da64595": {
                    "authors": [
                        "Jon Howell",
                        "David Kotz"
                    ],
                    "references": [
                        "07c0b505-8ff7-4bff-a609-f9612a521f55",
                        "0be07016-d242-46d0-8f39-72220fcd60cd",
                        "139f0f7c-ad2f-4961-9fea-c5af8b717201",
                        "21d9f77f-2c93-4a47-a8eb-49b8666fef32",
                        "32b6ee76-33bb-414d-b7e2-6fc7a0f3b457",
                        "4ec0711d-c218-45d3-9fd1-29dcdb14716e",
                        "4f4498ee-ed1e-4e3a-ad12-ea64f27a5068",
                        "6a9c2062-e8eb-4584-8d40-35f8ed4e40d2",
                        "f0fa4606-b592-4388-986b-5317b1312e20",
                        "fe5ab90e-5f3e-44ce-9260-a2ecfc2dd27c"
                    ],
                    "keyword": [
                        "authorization",
                        "approaches",
                        "systems",
                        "boundaries",
                        "unified",
                        "endtoend",
                        "applications",
                        "span",
                        "describe"
                    ],
                    "group": [],
                    "_id": "698fc1a5-7700-4108-9957-530e0da64595",
                    "abstract": "Many boundaries impede the flow of authorization information, forcing applications that span those boundaries into hop-by-hop approaches to authorization. We present a unified approach to authorization. Our approach allows applications that span administrative, network, abstraction, and protocol boundaries to understand the end-to-end authority that justifies any given request. The resulting distributed systems are more secure and easier to audit.   We describe boundaries that can interfere with end-to-end authorization, and outline our unified approach. We describe the system we built and the applications we adapted to use our unified authorization system, and measure its costs. We conclude that our system is a practical approach to the desirable goal of end-to-end authorization.",
                    "title": "End-to-end authorization",
                    "venue": "operating systems design and implementation",
                    "year": 2000,
                    "__v": 2,
                    "citationCount": 24,
                    "result": 5.556984206099161
                },
                "6cec07de-4318-4168-954f-38246a885091": {
                    "authors": [
                        "Hidemoto Nakada",
                        "Mitsuhisa Sato",
                        "Satoshi Sekiguchi"
                    ],
                    "references": [
                        "36c05ec1-7f89-44d4-a180-49820c36e4a0",
                        "430ec9a8-bc60-441f-815e-90f3d6412070",
                        "b9526df3-de18-4214-97a9-c131a674341a",
                        "d0811c1c-0eb1-4112-8dc1-1e33e795f7af",
                        "df36b6d1-fc51-4bc6-be5d-854685e608c0",
                        "e77bc0ae-b551-4645-ac81-ce400c762f68"
                    ],
                    "keyword": [
                        "computing",
                        "user",
                        "network",
                        "worldwide",
                        "technology",
                        "software",
                        "services",
                        "location",
                        "infrastructure",
                        "information"
                    ],
                    "group": [],
                    "_id": "6cec07de-4318-4168-954f-38246a885091",
                    "abstract": "The world-wide computing infrastructure on the growing computer network technology is a leading technology to make a variety of information services accessible through the Internet for every user from the high-performance computing users through many of personal computing users. The important feature of such services is location transparency; information can be obtained irrespective of time or location in virtually shared manner. In this article, we overview Ninf, an ongoing global network-wide computing infrastructure project which allows users to access computational resources including hardware, software and scientific data distributed across a wide area network. Preliminary performance result on measuring software and network overhead is shown, and that promises the future reality of world-wide network computing.",
                    "title": "Design and implementations of Ninf: towards a global computing infrastructure",
                    "venue": "Future Generation Computer Systems",
                    "year": 1999,
                    "__v": 1,
                    "citationCount": 93,
                    "result": 8.293637648900807
                },
                "740d054f-67e6-4e6e-a54d-f09e4ab41bb7": {
                    "authors": [
                        "Jason Novotny",
                        "Steven Tuecke",
                        "Von Welch"
                    ],
                    "references": [
                        "08e02aa6-3ef9-4b25-8de6-a42ca9a60577",
                        "18831dc8-e399-499d-8da1-a7befe5d7055",
                        "36c05ec1-7f89-44d4-a180-49820c36e4a0",
                        "95475ef7-fcf3-42eb-b244-4bc7fd05c4ab",
                        "b6457b57-76f8-4d6e-afdd-594864aef737",
                        "be02a3ad-38e5-4561-aa20-4f8c29c06bb5",
                        "c2f67467-3138-4d37-a743-10340dc3ea44",
                        "ee3156f4-7727-4e4d-b4d4-5e229d8513e6"
                    ],
                    "keyword": [
                        "grid",
                        "security",
                        "portals",
                        "myproxy",
                        "systems",
                        "gsi",
                        "web",
                        "standard"
                    ],
                    "group": [],
                    "_id": "740d054f-67e6-4e6e-a54d-f09e4ab41bb7",
                    "abstract": "Grid portals, based on standard Web technologies, are increasingly used to provide user interfaces for computational and data grids. However, such Grid portals do not integrate cleanly with existing Grid security systems such as the Grid Security Infrastructure (GSI), due to lack of delegation capabilities in Web security mechanisms. We solve this problem using an online credentials repository system, called MyProxy. MyProxy allows Grid portals to use the GSI to interact with Grid resources in a standard, secure manner. We examine the requirements of Grid portals, give an overview of the GSI, and demonstrate how MyProxy enables them to function together. The architecture and security of the MyProxy system are described in detail.",
                    "title": "An online credential repository for the Grid: MyProxy",
                    "venue": "high performance distributed computing",
                    "year": 2001,
                    "__v": 2,
                    "citationCount": 217,
                    "result": 3.4110536522301227
                },
                "8dedecd2-47b1-4229-a0b4-7d26d6561921": {
                    "authors": [
                        "John Barry",
                        "Manuel Aparicio",
                        "Timothy Durniak",
                        "Peter Herman",
                        "Jagan Karuturi",
                        "Charles Woods",
                        "Charles R. Gilman",
                        "Herman Lam",
                        "Rajiv Ramnath"
                    ],
                    "references": [
                        "01f6a3b8-eef1-4de2-af44-e0cef74f2f82",
                        "2553bf29-75f8-4054-ab2b-5f905eee09d6",
                        "9811a41a-bd2f-4de4-aec3-5b098acce78d",
                        "a3338113-ab1a-44bb-82de-dea086907ca2",
                        "af9373ea-efab-4de5-9338-902635670db1",
                        "ba253d8e-149a-4390-9b46-d024017b0243",
                        "d85bd77d-5d15-4955-ad2d-42ab8b83b199",
                        "e52ab5b7-8747-41c5-bd80-04e06e99d738"
                    ],
                    "keyword": [
                        "systems",
                        "mes",
                        "manufacturing",
                        "information",
                        "enterprise",
                        "technology",
                        "smart",
                        "product",
                        "policy",
                        "object"
                    ],
                    "group": [],
                    "_id": "8dedecd2-47b1-4229-a0b4-7d26d6561921",
                    "abstract": "The National Industrial Information Infrastructure Protocols (NIIIP) consortium's solutions for MES adaptable replicable technology (SMART) subgroup is developing an information infrastructure to enable the integration and interoperation among manufacturing execution systems (MES) and enterprise information systems within or among enterprises. The goal of these developments is an adaptable, affordable, reconfigurable, integratable manufacturing system. Key innovative aspects of NIIIP SMART are: Design of a standards-oriented configurable object model that represents the diverse aspects of MES. Application of distributed object architecture, work-flow, events, policy rules, intelligent agents, and knowledge management technologies to implement manufacturing and business procedures and policy. Product data exchange based on standard for the exchange of product data (STEP) and EXPRESS (ISO 10303), and enterprise resource planning interaction using open application group interface specification (OAGIS) business service requests (BSR).",
                    "title": "NIIIP-SMART: an investigation of distributed object approaches to support MES development and deployment in a virtual enterprise",
                    "venue": "enterprise distributed object computing",
                    "year": 1998,
                    "__v": 2,
                    "citationCount": 14,
                    "result": 4.908689143673664
                },
                "9553fde5-7523-4944-abb2-ce12a6d02afc": {
                    "authors": [
                        "Michael J. Litzkow",
                        "Miron Livny",
                        "Matt W. Mutka"
                    ],
                    "references": [
                        "62da97a7-b9fe-4df7-b198-7d8eb2eda527",
                        "a09dc7b2-217f-4be9-a90a-5c2bdb95fb05",
                        "a92590bb-3e2a-4670-97ca-67e9ab17f9b5",
                        "ac54f66a-fec3-4e4d-b6e5-76e130b02d47",
                        "b64bc06a-4989-469c-8a60-78115e8e9f26",
                        "bc11333f-9145-4df6-8ae7-1f5666a94272"
                    ],
                    "keyword": [
                        "workstation",
                        "system",
                        "jobs",
                        "station",
                        "scheduling",
                        "performance",
                        "presented",
                        "condor",
                        "activities"
                    ],
                    "group": [],
                    "_id": "9553fde5-7523-4944-abb2-ce12a6d02afc",
                    "abstract": "The design, implementation, and performance of the Condor scheduling system, which operates in a workstation environment, are presented. The system aims to maximize the utilization of workstations with as little interference as possible between the jobs it schedules and the activities of the people who own workstations. It identifies idle workstations and schedules background jobs on them. When the owner of a workstation resumes activity at a station, Condor checkpoints the remote job running on the station and transfers it to another workstation. The system guarantees that the job will eventually complete, and that very little, if any, work will be performed more than once. A performance profile of the system is presented that is based on data accumulated from 23 stations during one month. >",
                    "title": "Condor-a hunter of idle workstations",
                    "venue": "international conference on distributed computing systems",
                    "year": 1988,
                    "__v": 2,
                    "citationCount": 1197,
                    "result": 4.67543901746688
                },
                "9cdc54f0-f1a0-4422-ac16-d9164d9371ee": {
                    "authors": [
                        "Karl Czajkowski",
                        "Steven M. Fitzgerald",
                        "Ian T. Foster",
                        "Carl Kesselman"
                    ],
                    "references": [
                        "123e9dfc-2132-4150-a599-48482f674799",
                        "1a1e1d4c-6057-45c8-b296-336e6991d2e2",
                        "31c5e39a-3f24-4d20-bf8c-3d00036baf95",
                        "36c05ec1-7f89-44d4-a180-49820c36e4a0",
                        "59084791-6ebd-4d0d-8f93-2c1da8d47490",
                        "68414a1e-11d6-4d1e-bff0-eef3f924a691",
                        "765a5f62-24d9-4ae0-a6d9-79c143d6d5eb",
                        "7f113972-fc3f-46fa-a398-fa5d843ae8dd",
                        "7ffec2f8-420b-43cf-8ad5-550e332f5d6d",
                        "83cff325-43e0-4161-aedd-01bd59463cc7",
                        "914e0245-e455-45da-88f5-c623aa1a320d",
                        "9810d6f5-6935-43fb-8438-282ef53b3a5b",
                        "abb6e113-b288-46a1-91de-7b48a3cce765",
                        "c1a0f931-e38f-4047-9f63-942f1887dfe7",
                        "c2f67467-3138-4d37-a743-10340dc3ea44",
                        "c8311815-4163-4e5c-8a25-c4a3205cb6d9",
                        "d203eca6-41a1-4e8f-9262-77ce686366e7",
                        "df36b6d1-fc51-4bc6-be5d-854685e608c0",
                        "f4fb00e5-7751-49a7-9e31-33e0d95ae056"
                    ],
                    "keyword": [
                        "services",
                        "informal",
                        "grid",
                        "protocols",
                        "monitoring",
                        "discovery",
                        "architecture"
                    ],
                    "group": [],
                    "_id": "9cdc54f0-f1a0-4422-ac16-d9164d9371ee",
                    "abstract": "Grid technologies enable large-scale sharing of resources within formal or informal consortia of individuals and/or institutions: what are sometimes called virtual organizations. In these settings, the discovery, characterization, and monitoring of resources, services, and computations are challenging problems due to the considerable diversity; large numbers, dynamic behavior, and geographical distribution of the entities in which a user might be interested. Consequently, information services are a vital part of any Grid software infrastructure, providing fundamental mechanisms for discovery and monitoring, and hence for planning and adapting application behavior. We present an information services architecture that addresses performance, security, scalability, and robustness requirements. Our architecture defines simple low-level enquiry and registration protocols that make it easy to incorporate individual entities into various information structures, such as aggregate directories that support a variety of different query languages and discovery strategies. These protocols can also be combined with other Grid protocols to construct additional higher-level services and capabilities such as brokering, monitoring, fault detection, and troubleshooting. Our architecture has been implemented as MDS-2, which forms part of the Globus Grid toolkit and has been widely deployed and applied.",
                    "title": "Grid information services for distributed resource sharing",
                    "venue": "high performance distributed computing",
                    "year": 2001,
                    "__v": 2,
                    "citationCount": 793,
                    "result": 6.394973121134113
                },
                "acb72100-1da2-4585-aa35-df61f39014e0": {
                    "authors": [
                        "Amin Vahdat",
                        "Thomas E. Anderson",
                        "Michael Dahlin",
                        "Eshwar Belani",
                        "David E. Culler",
                        "Paul Eastham",
                        "Chad Yoshikawa"
                    ],
                    "references": [
                        "0998db5f-76df-445f-8aff-82da5f8e9bdd",
                        "0ab8c0f9-fdba-428d-81a3-da79d759598e",
                        "0ce74249-8be4-45f5-96de-c5fb2c69c2e9",
                        "139f0f7c-ad2f-4961-9fea-c5af8b717201",
                        "279ea9a1-32e3-4aa0-80c6-f81901fb3f9a",
                        "2eb2cd2e-7163-48a3-9d59-a38bec66055e",
                        "32b6ee76-33bb-414d-b7e2-6fc7a0f3b457",
                        "33b89c99-821c-450a-9580-948e7bbde37e",
                        "36c05ec1-7f89-44d4-a180-49820c36e4a0",
                        "3fb43b00-905c-4a08-934d-198ea4eb66c3",
                        "49cafff8-eae2-47d7-919d-cf07c08a7e66",
                        "4ae908db-c25f-4879-b1d9-bd0db7878737",
                        "514c9514-301e-4ff0-9095-ecdae3d37008",
                        "5376f94d-6ba7-487c-ada2-e7f621c0ed50",
                        "537d266a-952c-4d06-840b-8abd29ee0de5",
                        "59084791-6ebd-4d0d-8f93-2c1da8d47490",
                        "5f0e3bf6-a29f-456d-81be-f4c89bd62912",
                        "5f426025-153d-402a-82d9-fd4e77473fc0",
                        "5fa0709f-7330-417f-8da7-3ab31d91da5b",
                        "6c82b32c-a6d1-48d8-8912-0072c7de09d4",
                        "78001675-2215-4b4e-8a92-cd30f6409d70",
                        "7da6afbd-aa52-47f9-b6ca-9e7f709fb9c4",
                        "90178a5f-688b-47f5-a59d-32845e332984",
                        "93f501e9-78e2-41a1-ab3e-d7923995967c",
                        "94fbc0ff-4485-4899-a1ea-e317bbdc07e3",
                        "9d11aa6c-586e-40dc-a475-094bf043431f",
                        "a959d6a3-a32b-4659-9ef4-e85afc1beb19",
                        "b5bf7637-40a1-4390-ba25-6329d57c4084",
                        "b9442fce-3e06-4c6a-8818-e41ec6ec591e",
                        "b9d8272a-60f0-4ca6-95ab-0a930b27480d",
                        "c8f261be-0b14-4881-b376-36abe5253669",
                        "cf153ee9-156d-41d6-b423-230746a4eec8",
                        "ddda4cca-8fb5-4518-a1cd-c66aba4cbea1",
                        "e5d1d9b9-73d8-44cc-bf0a-a152e6bc21c8",
                        "e883ae1e-0c54-4fcb-9c38-4165bb0fcc7a"
                    ],
                    "keyword": [
                        "system",
                        "applications",
                        "developers",
                        "webos",
                        "services",
                        "resource",
                        "providing",
                        "operating",
                        "build",
                        "wide"
                    ],
                    "group": [],
                    "_id": "acb72100-1da2-4585-aa35-df61f39014e0",
                    "abstract": "Demonstrates the power of providing a common set of operating system services to wide-area applications, including mechanisms for naming, persistent storage, remote process execution, resource management, authentication and security. On a single machine, application developers can rely on the local operating system to provide these abstractions. In the wide area, however, application developers are forced to build these abstractions themselves or to do without. This ad-hoc approach often results in individual programmers implementing non-optimal solutions, wasting both programmer effort and system resources. To address these problems, we are building a system, WebOS, that provides the basic operating systems services needed to build applications that are geographically distributed, highly available, incrementally scalable and dynamically reconfigurable. Experience with a number of applications developed under WebOS indicates that it simplifies system development and improves resource utilization. In particular, we use WebOS to implement Rent-A-Server to provide dynamic replication of overloaded Web services across the wide area in response to client demands.",
                    "title": "WebOS: operating system services for wide area applications",
                    "venue": "high performance distributed computing",
                    "year": 1998,
                    "__v": 2,
                    "citationCount": 85,
                    "result": 7.493792026686765
                },
                "db413eda-50e9-479a-9dd1-033f4e1d5ab8": {
                    "authors": [
                        "Jean-Pierre Goux",
                        "Sanjeev Kulkarni",
                        "Jeff Linderoth",
                        "M. F. Yoder"
                    ],
                    "references": [
                        "1af8666a-2bc3-43e8-aa07-f216a8fd2417",
                        "32302597-c054-4beb-b0fe-64128eca4d8e",
                        "36c05ec1-7f89-44d4-a180-49820c36e4a0",
                        "3de3f990-e9b8-45f6-8723-18a5239835de",
                        "4c650c88-33ac-41ff-8fdf-02a4e9b0cea9",
                        "4fa95faf-0639-471d-bdd3-0078549abbbe",
                        "792b33b5-d338-4928-bcf0-d556c8ad639b",
                        "a7d8fc07-6137-4d03-ac62-d72a4cb7996e",
                        "b7f704e3-c0ec-47fc-9d42-47852e39f4ec",
                        "cbdc8a1a-e486-43f0-a9e0-33f9f00ed85b",
                        "e802a547-7703-4fb5-bc96-ccb08d1a4aba",
                        "ff086b09-5553-429f-b80c-c78a13ee6bbc"
                    ],
                    "keyword": [
                        "computations",
                        "interface",
                        "grid",
                        "software",
                        "mw",
                        "masterworker",
                        "application",
                        "users",
                        "unprecedented",
                        "toplevel"
                    ],
                    "group": [],
                    "_id": "db413eda-50e9-479a-9dd1-033f4e1d5ab8",
                    "abstract": "Describes MW (Master-Worker) - a software framework that allows users to quickly and easily parallelize scientific computations using the master-worker paradigm on the Computational Grid. MW provides both a \"top-level\" interface to application software and a \"bottom-level\" interface to existing Grid computing toolkits. Both interfaces are briefly described. We conclude with a case study, where the necessary Grid services are provided by the Condor high-throughput computing system, and the MW-enabled application code is used to solve a combinatorial optimization problem of unprecedented complexity.",
                    "title": "An enabling framework for master-worker applications on the Computational Grid",
                    "venue": "high performance distributed computing",
                    "year": 2000,
                    "__v": 2,
                    "citationCount": 130,
                    "result": 6.575424011010899
                },
                "e593759c-0dd4-4e2f-9fde-40d6a64a521c": {
                    "authors": [
                        "Peter A. Dinda",
                        "David R. O'Hallaron"
                    ],
                    "references": [
                        "16277fbe-9ef0-4629-a66f-72612d0ba35f",
                        "33e82d3d-821c-4f4d-a612-a2b2d8cae9a9",
                        "3a22ab2a-2428-4db5-ab33-0d8a098bd0da",
                        "68414a1e-11d6-4d1e-bff0-eef3f924a691",
                        "717c97f3-8a91-4f7c-acc6-e2738cd7e1bc",
                        "726a2730-1df7-4e37-906e-4226c2043207",
                        "8ed9e0bc-4816-44f3-8495-75f4bf685756",
                        "96fead9d-0bcc-4fae-b400-30ed44e82666",
                        "c94a3952-f1f2-4a1e-9254-96f195ca7e5b",
                        "cbd46ce7-a3c8-4e82-bd3f-50f6db2e5fc6"
                    ],
                    "keyword": [
                        "models",
                        "load",
                        "predicting",
                        "traces",
                        "number",
                        "large",
                        "evaluates",
                        "average",
                        "ar"
                    ],
                    "group": [],
                    "_id": "e593759c-0dd4-4e2f-9fde-40d6a64a521c",
                    "abstract": "Evaluates linear models for predicting the Digital Unix five-second host load average from 1 to 30 seconds into the future. A detailed statistical study of a large number of long, fine-grain load traces from a variety of real machines leads to consideration of the Box-Jenkins (1994) models (AR, MA, ARMA, ARIMA), and the ARFIMA (autoregressive fractional integrated moving average) models (due to self-similarity). These models, as well as a simple windowed-mean scheme, are then rigorously evaluated by running a large number of randomized test cases on the load traces and by data-mining their results. The main conclusions are that the load is consistently predictable to a very useful degree, and that the simpler models, such as AR, are sufficient for performing this prediction.",
                    "title": "An evaluation of linear models for host load prediction",
                    "venue": "high performance distributed computing",
                    "year": 1999,
                    "__v": 2,
                    "citationCount": 61,
                    "result": 4.069005375429524
                },
                "e9065010-fc6a-4170-8087-7c99eaa84b4c": {
                    "authors": [
                        "Sharon Brunett",
                        "Karl Czajkowski",
                        "Steven M. Fitzgerald",
                        "Ian T. Foster",
                        "Andrew E. Johnson",
                        "Carl Kesselman",
                        "Jason Leigh",
                        "Steven Tuecke"
                    ],
                    "references": [
                        "05f6103e-11d9-4f89-af12-6184526b0442",
                        "08cdcea0-6512-49e6-bbe1-31ad93e7d9a9",
                        "18831dc8-e399-499d-8da1-a7befe5d7055",
                        "25c06fe9-d346-40cb-85d5-ee193df3c4d9",
                        "432a75f0-4a68-4700-954b-56a8eb920dab",
                        "72ecd564-096e-46b7-b793-98e7f3023e97",
                        "8d38c484-9a4b-44d7-9404-c23951ed274f",
                        "8e776077-e644-427a-96be-ac4d353f622f",
                        "914e0245-e455-45da-88f5-c623aa1a320d",
                        "9eac8f56-e6ce-4d57-89ba-6f1119209b9a",
                        "a959d6a3-a32b-4659-9ef4-e85afc1beb19",
                        "acb72100-1da2-4585-aa35-df61f39014e0",
                        "c9363f83-0725-4ea4-b93a-0c4a1ccbacf8",
                        "fc09fd19-1a56-4bed-b900-4a473c3b30ce"
                    ],
                    "keyword": [
                        "development",
                        "applications",
                        "toolkit",
                        "distributed",
                        "computational",
                        "highperformance",
                        "describe"
                    ],
                    "group": [],
                    "_id": "e9065010-fc6a-4170-8087-7c99eaa84b4c",
                    "abstract": "The development of applications and tools for high-performance \"computational grids\" is complicated by the heterogeneity and frequently dynamic behavior of the underlying resources; by the complexity of the applications themselves, which often combine aspects of supercomputing and distributed computing; and by the need to achieve high levels of performance. The Globus toolkit has been developed with the goal of simplifying this application development task, by providing implementations of various core services deemed essential for high-performance distributed computing. In this paper, we describe two large applications developed with this toolkit: a distributed interactive simulation and a teleimmersion system. We describe the process used to develop the applications, review the lessons learned and draw conclusions regarding the effectiveness of the toolkit approach.",
                    "title": "Application experiences with the Globus toolkit",
                    "venue": "high performance distributed computing",
                    "year": 1998,
                    "__v": 2,
                    "citationCount": 34,
                    "result": 5.534777817716302
                }
            }
        ],
        "_id": "c2f67467-3138-4d37-a743-10340dc3ea44",
        "abstract": "\"Grid\" computing has emerged as an important new field, distinguished from conventional distributed computing by its focus on large-scale resource sharing, innovative applications, and, in some cases, high performance orientation. In this article, the authors define this new field. First, they review the \"Grid problem,\" which is defined as flexible, secure, coordinated resource sharing among dynamic collections of individuals, institutions, and resources--what is referred to as virtual organizations. In such settings, unique authentication, authorization, resource access, resource discovery, and other challenges are encountered. It is this class of problem that is addressed by Grid technologies. Next, the authors present an extensible and open Grid architecture, in which protocols, services, application programming interfaces, and software development kits are categorized according to their roles in enabling resource sharing. The authors describe requirements that they believe any such mechanisms must satisfy and discuss the importance of defining a compact set of intergrid protocols to enable interoperability among different Grid systems. Finally, the authors discuss how Grid technologies relate to other contemporary technologies, including enterprise integration, application service provider, storage service provider, and peer-to-peer computing. They maintain that Grid concepts and technologies complement and have much to contribute to these other approaches.",
        "title": "The Anatomy of the Grid: Enabling Scalable Virtual Organizations",
        "venue": "ieee international conference on high performance computing data and analytics",
        "year": 2001,
        "__v": 3,
        "citationCount": 3203
    },
    {
        "authors": [
            "Yangqing Jia",
            "Evan Shelhamer",
            "Jeff Donahue",
            "Sergey Karayev",
            "Jonathan Long",
            "Ross B. Girshick",
            "Sergio Guadarrama",
            "Trevor Darrell"
        ],
        "references": [
            "0fb0a842-cb06-4b37-9738-a4d18a55ec23",
            "16ebaec4-79d6-4c4a-bc44-50c79204faf2",
            "176a7436-78ea-4c2a-82e6-7930ab023bd1",
            "acf46750-428a-4f63-95b2-aabf1d40b6b6",
            "bc9dae46-1c04-47bb-b93a-9c830f06f1bf",
            "c812244d-0de8-4e3c-8133-1e834bc9dbd0",
            "e2f7a74a-8430-4463-94ce-fe85dfd309f9",
            "ebc82bdd-1afb-419d-983c-a313713c6367",
            "f1639cc6-356f-4170-9dea-9be79c84f899"
        ],
        "keyword": [
            "caffe",
            "models",
            "vision",
            "prototyping",
            "multimedia",
            "learning",
            "industry",
            "images",
            "gpu",
            "framework"
        ],
        "group": [
            {
                "0fb0a842-cb06-4b37-9738-a4d18a55ec23": {
                    "authors": [
                        "Pierre Sermanet",
                        "David Eigen",
                        "Xiang Zhang",
                        "Michael Mathieu",
                        "Rob Fergus",
                        "Yann LeCun"
                    ],
                    "references": [
                        "2b6a3d0f-368f-45bb-be23-4e82f62fbbf7",
                        "2d94566b-ac2d-49b0-a867-2392c41a2172",
                        "37b7b3cf-3f16-4112-88cc-1e887672098f",
                        "3b424c3b-fbe1-45e5-9513-04b5d4ab4945",
                        "45a2ff7e-d1e6-4e7e-9f69-b6bdaca34740",
                        "4bbacb77-1097-4cc5-b001-6554ea01fb75",
                        "5b08cd47-f0e2-45d4-99a5-ac11c0b20228",
                        "690a5e66-a7d5-44a0-b64e-4d7c04fce1b5",
                        "725ff5fd-76fe-41b4-b50d-00405a51ac27",
                        "72c6c663-330b-400f-94f1-1abd68991fc2",
                        "75883e63-4f9a-41c8-941f-5fbbc8943867",
                        "820b9eee-e009-4dc1-b464-f5fd4485d6b3",
                        "95f28b74-9e22-4dc0-8acc-9cdf7e716b61",
                        "97fa1c18-05bf-47c9-b72d-5d712b186ccd",
                        "c1823a4b-d7ad-41ad-b5c9-c0ddff288a25",
                        "c4dc7b46-01d3-44f5-91ca-0cc063d38c8c",
                        "d2de642b-7044-4d04-85ea-1e05eea964c6",
                        "e016d598-1090-4b61-98ab-f47c8650dfa7",
                        "e2f7a74a-8430-4463-94ce-fe85dfd309f9",
                        "ec70631e-0fe0-4af1-9c08-d49eb0d11577",
                        "f1639cc6-356f-4170-9dea-9be79c84f899",
                        "fb1e85b8-5ae8-4074-88cf-4e9270d625ff"
                    ],
                    "keyword": [],
                    "group": [],
                    "_id": "0fb0a842-cb06-4b37-9738-a4d18a55ec23",
                    "abstract": "Abstract: We present an integrated framework for using Convolutional Networks for classification, localization and detection. We show how a multiscale and sliding window approach can be efficiently implemented within a ConvNet. We also introduce a novel deep learning approach to localization by learning to predict object boundaries. Bounding boxes are then accumulated rather than suppressed in order to increase detection confidence. We show that different tasks can be learned simultaneously using a single shared network. This integrated framework is the winner of the localization task of the ImageNet Large Scale Visual Recognition Challenge 2013 (ILSVRC2013) and obtained very competitive results for the detection and classifications tasks. In post-competition work, we establish a new state of the art for the detection task. Finally, we release a feature extractor from our best model called OverFeat.",
                    "title": "OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks",
                    "venue": "international conference on learning representations",
                    "year": 2014,
                    "__v": 0,
                    "citationCount": 793,
                    "result": 2.2222222222222223
                },
                "176a7436-78ea-4c2a-82e6-7930ab023bd1": {
                    "authors": [
                        "Ross B. Girshick",
                        "Jeff Donahue",
                        "Trevor Darrell",
                        "Jitendra Malik"
                    ],
                    "references": [
                        "0105e97e-ef22-402e-8ba6-5de027d57dbe",
                        "1bbaae78-1bb8-4184-b01c-4216e6879c56",
                        "2b6a3d0f-368f-45bb-be23-4e82f62fbbf7",
                        "2f4bbdb0-55cc-48e9-a986-71fc20a69a5c",
                        "30d96b63-ab8b-4a93-904d-65e87ba32327",
                        "3609ce2c-c21e-4e94-a17e-de31443ecb90",
                        "414732f4-8fd6-4fdb-9039-553367150535",
                        "493f502b-b1b8-412c-95fd-3c1103480f1d",
                        "589efc91-a3df-4c70-a613-67f249d7b33f",
                        "6e1c18af-5c7f-4915-a611-702a3d4b9c53",
                        "725ff5fd-76fe-41b4-b50d-00405a51ac27",
                        "73dbdf1f-da95-4b8c-9109-c966e08c6f13",
                        "83c737b8-e084-4766-ba6e-131e6a1c017c",
                        "86c0687e-74fb-44b1-a467-7f469a1486b9",
                        "95f28b74-9e22-4dc0-8acc-9cdf7e716b61",
                        "983a2eff-22fe-40d2-bb87-fea35e63db6c",
                        "9be390e8-c4e6-41a2-b9b2-74de449f0768",
                        "9d24b0a5-fc3e-486e-9706-da560154b63c",
                        "a0a69af2-8b51-455e-bbac-a1aa5b24bd8b",
                        "a13418d7-3585-4888-a027-85e441bfd354",
                        "a4382b8f-f7fd-4d84-93ba-04c068c9abf0",
                        "ab3afb93-8ca0-4556-ae60-11199dc263c2",
                        "ae3e7593-586f-495f-9416-4b50ed1fcd10",
                        "b916e575-9eba-4989-ad10-00b615e358a6",
                        "b944f77f-113b-4a02-ae5e-d4a124b8fd5b",
                        "c7def717-ad62-4168-9ae3-5484a67399c1",
                        "c812244d-0de8-4e3c-8133-1e834bc9dbd0",
                        "d5e5a24d-f80e-4f1a-b48b-22403b653276",
                        "d6e37fb1-5f7e-448e-847b-7d1f1271c574",
                        "daa22c50-e3a3-42f0-85b5-4cad99989511",
                        "dd83785a-dd19-41e3-9b25-ebabbd48d336",
                        "e016d598-1090-4b61-98ab-f47c8650dfa7",
                        "e2f7a74a-8430-4463-94ce-fe85dfd309f9",
                        "e407acd7-dfcf-4ee8-9140-6726c01abf4e",
                        "e7f6e82d-380c-427b-98bc-5c79471a7336",
                        "f1639cc6-356f-4170-9dea-9be79c84f899",
                        "f2d49150-35de-4fd5-ac46-eb071d1cc73e"
                    ],
                    "keyword": [],
                    "group": [],
                    "_id": "176a7436-78ea-4c2a-82e6-7930ab023bd1",
                    "abstract": "Object detection performance, as measured on the canonical PASCAL VOC dataset, has plateaued in the last few years. The best-performing methods are complex ensemble systems that typically combine multiple low-level image features with high-level context. In this paper, we propose a simple and scalable detection algorithm that improves mean average precision (mAP) by more than 30% relative to the previous best result on VOC 2012 -- achieving a mAP of 53.3%. Our approach combines two key insights: (1) one can apply high-capacity convolutional neural networks (CNNs) to bottom-up region proposals in order to localize and segment objects and (2) when labeled training data is scarce, supervised pre-training for an auxiliary task, followed by domain-specific fine-tuning, yields a significant performance boost. Since we combine region proposals with CNNs, we call our method R-CNN: Regions with CNN features. We also present experiments that provide insight into what the network learns, revealing a rich hierarchy of image features. Source code for the complete system is available at http://www.cs.berkeley.edu/~rbg/rcnn.",
                    "title": "Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation",
                    "venue": "computer vision and pattern recognition",
                    "year": 2014,
                    "__v": 0,
                    "citationCount": 1815,
                    "result": 3.333333333333333
                },
                "acf46750-428a-4f63-95b2-aabf1d40b6b6": {
                    "authors": [
                        "Ning Zhang",
                        "Manohar Paluri",
                        "Marc'Aurelio Ranzato",
                        "Trevor Darrell",
                        "Lubomir D. Bourdev"
                    ],
                    "references": [
                        "06546bec-4d27-4ecf-a0ff-c96571dfec5f",
                        "096b2319-7282-4964-9136-52bc12348bc3",
                        "125e92b0-d879-43ac-bf56-9408a6fea183",
                        "17d870e0-2fd7-4878-af7d-e6f81fa9ae44",
                        "32a643b0-7334-4553-adb4-459ad560654e",
                        "3daf5a32-5275-4c48-ae25-cd47cfec0f33",
                        "4bbacb77-1097-4cc5-b001-6554ea01fb75",
                        "4e20f374-db4e-4c9e-ba2b-6b1af2a4b9c3",
                        "614adea0-684f-4711-84fa-8cb6cc7d49db",
                        "6e083300-a74c-43f0-8a56-4e7c015e3892",
                        "81163e27-8feb-48e0-b21b-a69d8555e64c",
                        "86c0687e-74fb-44b1-a467-7f469a1486b9",
                        "8fb49bff-96c8-47ce-8b2f-f2ba16801621",
                        "924fe569-7b4c-4968-bcc9-35aa73dbb587",
                        "a04310cc-9dda-4137-a187-0891b0569005",
                        "ae3e7593-586f-495f-9416-4b50ed1fcd10",
                        "c812244d-0de8-4e3c-8133-1e834bc9dbd0",
                        "e016d598-1090-4b61-98ab-f47c8650dfa7",
                        "e0ac4812-7729-4a2d-8a1f-74b1b7c8eb5d",
                        "e16196fc-ad79-42a7-a19c-92256a179a78",
                        "e2f7a74a-8430-4463-94ce-fe85dfd309f9",
                        "e4de3243-9d16-4fef-ad76-c388fe41240e",
                        "e850c4c4-203c-4e23-8ac8-a9b9067432b5",
                        "f2d49150-35de-4fd5-ac46-eb071d1cc73e"
                    ],
                    "keyword": [
                        "method",
                        "training",
                        "problems",
                        "pose",
                        "partbased",
                        "large",
                        "images",
                        "attributes",
                        "viewpoint",
                        "variation"
                    ],
                    "group": [],
                    "_id": "acf46750-428a-4f63-95b2-aabf1d40b6b6",
                    "abstract": "We propose a method for inferring human attributes (such as gender, hair style, clothes style, expression, action) from images of people under large variation of viewpoint, pose, appearance, articulation and occlusion. Convolutional Neural Nets (CNN) have been shown to perform very well on large scale object recognition problems. In the context of attribute classification, however, the signal is often subtle and it may cover only a small part of the image, while the image is dominated by the effects of pose and viewpoint. Discounting for pose variation would require training on very large labeled datasets which are not presently available. Part-based models, such as poselets [4] and DPM [12] have been shown to perform well for this problem but they are limited by shallow low-level features. We propose a new method which combines part-based models and deep learning by training pose-normalized CNNs. We show substantial improvement vs. state-of-the-art methods on challenging attribute classification tasks in unconstrained settings. Experiments confirm that our method outperforms both the best part-based methods on this problem and conventional CNNs trained on the full bounding box of the person.",
                    "title": "PANDA: Pose Aligned Networks for Deep Attribute Modeling",
                    "venue": "computer vision and pattern recognition",
                    "year": 2014,
                    "__v": 2,
                    "citationCount": 116,
                    "result": 7.578668716904012
                },
                "c812244d-0de8-4e3c-8133-1e834bc9dbd0": {
                    "authors": [
                        "Jeff Donahue",
                        "Yangqing Jia",
                        "Oriol Vinyals",
                        "Judy Hoffman",
                        "Ning Zhang",
                        "Eric Tzeng",
                        "Trevor Darrell"
                    ],
                    "references": [
                        "125e92b0-d879-43ac-bf56-9408a6fea183",
                        "1a37fbdf-91e9-4e28-8de7-d0789d6ef59a",
                        "1a77be09-4fd7-4798-8caf-91c577aab110",
                        "2b370c2e-beb6-4101-a65f-c224fe8c262a",
                        "2b6a3d0f-368f-45bb-be23-4e82f62fbbf7",
                        "2d94566b-ac2d-49b0-a867-2392c41a2172",
                        "412c8967-f801-4872-bdfc-4407da2e72ed",
                        "45312d4d-40d5-4262-baa0-0885a7229e69",
                        "493f502b-b1b8-412c-95fd-3c1103480f1d",
                        "4bbacb77-1097-4cc5-b001-6554ea01fb75",
                        "4d1bf1ee-d4c4-4faa-9d13-dff3e65af340",
                        "4fea6b18-b7aa-4331-90a5-70166572398f",
                        "59e5e0b0-db01-438e-8763-319477f9baf1",
                        "5b35e6b8-3077-4ca4-aa34-5e211cace1b9",
                        "6e083300-a74c-43f0-8a56-4e7c015e3892",
                        "75daefc9-df12-4f97-a595-5fa69629fd74",
                        "7cdd68ef-876b-4214-bd85-38dd01ac99c9",
                        "7ce4a38d-0732-48b8-b72a-6f5d87c5782d",
                        "837e056f-ea71-4be1-bde0-e3166cfee2fd",
                        "9e9373eb-decd-4bfa-a31d-d9e8ed19e8f2",
                        "9f80f79f-822b-44d5-ad4e-01edf9edbf11",
                        "a7621af4-d387-4134-912b-33c00ec0db32",
                        "a955159c-3d20-4b43-abcb-0411ed1a5c02",
                        "ab3afb93-8ca0-4556-ae60-11199dc263c2",
                        "ae3e7593-586f-495f-9416-4b50ed1fcd10",
                        "b3cdf81a-65a2-458a-ac40-ac598a1729eb",
                        "c9482f1f-6600-44a7-a69a-e63ef13cdff8",
                        "daa22c50-e3a3-42f0-85b5-4cad99989511",
                        "db807124-0169-4fdf-83b7-3157739d2c07",
                        "dd83785a-dd19-41e3-9b25-ebabbd48d336",
                        "e16196fc-ad79-42a7-a19c-92256a179a78",
                        "e2f7a74a-8430-4463-94ce-fe85dfd309f9",
                        "e9c7e788-78d7-41f1-bf29-fa85bd7dc137",
                        "f225f439-4389-4312-a503-f8c1b0aa02de",
                        "f2d49150-35de-4fd5-ac46-eb071d1cc73e",
                        "f592195b-ced2-408d-a5c0-86a57aba9947",
                        "f6f6b46e-17f7-4dfe-9ef3-b20503b5464d"
                    ],
                    "keyword": [
                        "tasks",
                        "deep",
                        "features",
                        "trained",
                        "recognition",
                        "network",
                        "convolutional",
                        "visualize",
                        "vision",
                        "significantly"
                    ],
                    "group": [],
                    "_id": "c812244d-0de8-4e3c-8133-1e834bc9dbd0",
                    "abstract": "We evaluate whether features extracted from the activation of a deep convolutional network trained in a fully supervised fashion on a large, fixed set of object recognition tasks can be repurposed to novel generic tasks. Our generic tasks may differ significantly from the originally trained tasks and there may be insufficient labeled or unlabeled data to conventionally train or adapt a deep architecture to the new tasks. We investigate and visualize the semantic clustering of deep convolutional features with respect to a variety of such tasks, including scene recognition, domain adaptation, and fine-grained recognition challenges. We compare the efficacy of relying on various network levels to define a fixed feature, and report novel results that significantly outperform the state-of-the-art on several important vision challenges. We are releasing DeCAF, an open-source implementation of these deep convolutional activation features, along with all associated network parameters to enable vision researchers to be able to conduct experimentation with deep representations across a range of visual concept learning paradigms.",
                    "title": "DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition",
                    "venue": "international conference on machine learning",
                    "year": 2014,
                    "__v": 2,
                    "citationCount": 865,
                    "result": 5.619465089434129
                },
                "e2f7a74a-8430-4463-94ce-fe85dfd309f9": {
                    "authors": [
                        "Alex Krizhevsky",
                        "Ilya Sutskever",
                        "Geoffrey E. Hinton"
                    ],
                    "references": [
                        "2b6a3d0f-368f-45bb-be23-4e82f62fbbf7",
                        "2caf053c-09a4-4536-b303-6d4c834e429a",
                        "2d94566b-ac2d-49b0-a867-2392c41a2172",
                        "32a53bab-1ede-4869-98ad-d2ff0c1e3367",
                        "4bbacb77-1097-4cc5-b001-6554ea01fb75",
                        "657e0ce9-3a0c-4cc3-ac69-0f60aaf955f1",
                        "73ec9d29-4fc5-4019-97d3-c496c8509f37",
                        "820b9eee-e009-4dc1-b464-f5fd4485d6b3",
                        "a21b42c9-dff1-4cf2-becd-0bc9f922ea72",
                        "adea0a98-d74d-43be-a238-a1ef027c6a58",
                        "bd62aacb-5037-43d3-926a-af4d38ec3bfc",
                        "c700dc12-7eac-4091-8462-527773668dfa",
                        "c9482f1f-6600-44a7-a69a-e63ef13cdff8",
                        "ca250ca4-70fd-411f-8cc7-fb17be31cd9e",
                        "f6bd8b64-684d-429a-aab5-8ff3a2c23cd6",
                        "f7ac19b7-daaf-4dc1-bbb9-7f4ffd7385ba"
                    ],
                    "keyword": [
                        "layers",
                        "convolutional",
                        "achieved",
                        "trained",
                        "top5",
                        "test",
                        "rates",
                        "neurons",
                        "neural",
                        "network"
                    ],
                    "group": [
                        null
                    ],
                    "_id": "e2f7a74a-8430-4463-94ce-fe85dfd309f9",
                    "abstract": "We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0% which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully-connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overriding in the fully-connected layers we employed a recently-developed regularization method called \"dropout\" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry.",
                    "title": "ImageNet Classification with Deep Convolutional Neural Networks",
                    "venue": "neural information processing systems",
                    "year": 2012,
                    "__v": 3,
                    "citationCount": 5094,
                    "result": 3.200231957584898
                },
                "ebc82bdd-1afb-419d-983c-a313713c6367": {
                    "authors": [
                        "Sergey Karayev",
                        "Matthew Trentacoste",
                        "Helen Han",
                        "Aseem Agarwala",
                        "Trevor Darrell",
                        "Aaron Hertzmann",
                        "Holger Winnemoeller"
                    ],
                    "references": [
                        "212c2b0e-5436-4f57-8e30-11c52b22e01f",
                        "2b6a3d0f-368f-45bb-be23-4e82f62fbbf7",
                        "3c6b3cfa-e8a8-453a-9529-4453bb32e5af",
                        "469d9c03-c76a-4b4f-9789-9fa4713ce19d",
                        "5969fe2e-560d-4821-9143-4e376b5b2af5",
                        "6f300d15-3ac3-4266-b17f-a4840d5aa4af",
                        "86b626a6-f948-45ea-8e92-8102e0dc5ef8",
                        "88cf47f9-b83a-4b13-89e0-605236b82f4f",
                        "922df240-4793-4d5a-99f7-5f84d1f9652e",
                        "93076f6c-926d-4d4f-8af7-b5df54a20d70",
                        "ab3afb93-8ca0-4556-ae60-11199dc263c2",
                        "b8f49e74-117e-4e40-a164-ad18609765a3",
                        "c812244d-0de8-4e3c-8133-1e834bc9dbd0",
                        "ce7b6a10-6f34-45cf-af41-a0b84aed62c9",
                        "d5bb209f-6fab-4154-88e0-a5aa2410ba44",
                        "d8fcf8c9-6eee-4067-b265-28c783397ced",
                        "dccac07c-6834-4399-83bf-5dbcaf09cdae",
                        "df7b0a3c-a57e-4852-8f36-2b60d5335152",
                        "e2f7a74a-8430-4463-94ce-fe85dfd309f9",
                        "e33f93b7-48a7-444b-9929-df2b70244955"
                    ],
                    "keyword": [
                        "style",
                        "perform",
                        "image",
                        "learned",
                        "labels",
                        "dataset",
                        "annotations",
                        "photographic",
                        "features",
                        "approach"
                    ],
                    "group": [],
                    "_id": "ebc82bdd-1afb-419d-983c-a313713c6367",
                    "abstract": "The style of an image plays a significant role in how it is viewed, but style has received little attention in computer vision research. We describe an approach to predicting style of images, and perform a thorough evaluation of different image features for these tasks. We find that features learned in a multi-layer network generally perform best ‐ even when trained with object class (not style) labels. Our large-scale learning methods results in the best published performance on an existing dataset of aesthetic ratings and photographic style annotations. We present two novel datasets: 80K Flickr photographs annotated with 20 curated style labels, and 85K paintings annotated with 25 style/genre labels. Our approach shows excellent classification performance on both datasets. We use the learned classifiers to extend traditional tag-based image search to consider stylistic constraints, and demonstrate cross-dataset understanding of style.",
                    "title": "Recognizing Image Style",
                    "venue": "british machine vision conference",
                    "year": 2014,
                    "__v": 2,
                    "citationCount": 79,
                    "result": 6.557331144947244
                }
            }
        ],
        "_id": "c93eac1a-7d9a-48ab-9fb4-389c85bea00e",
        "abstract": "Caffe provides multimedia scientists and practitioners with a clean and modifiable framework for state-of-the-art deep learning algorithms and a collection of reference models. The framework is a BSD-licensed C++ library with Python and MATLAB bindings for training and deploying general-purpose convolutional neural networks and other deep models efficiently on commodity architectures. Caffe fits industry and internet-scale media needs by CUDA GPU computation, processing over 40 million images a day on a single K40 or Titan GPU (approx 2 ms per image). By separating model representation from actual implementation, Caffe allows experimentation and seamless switching among platforms for ease of development and deployment from prototyping machines to cloud environments.   Caffe is maintained and developed by the Berkeley Vision and Learning Center (BVLC) with the help of an active community of contributors on GitHub. It powers ongoing research projects, large-scale industrial applications, and startup prototypes in vision, speech, and multimedia.",
        "title": "Caffe: Convolutional Architecture for Fast Feature Embedding",
        "venue": "acm multimedia",
        "year": 2014,
        "__v": 2,
        "citationCount": 2101
    },
    {
        "authors": [
            "Ion Stoica",
            "Robert Morris",
            "David R. Karger",
            "M. Frans Kaashoek",
            "Hari Balakrishnan"
        ],
        "references": [
            "1c729f22-9928-4703-92a0-8819569a1bbb",
            "1cc64868-4f72-4939-aed4-fc8fb0b45118",
            "48740ddd-afd1-4331-8af7-224ef5d19ed7",
            "4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4",
            "59084791-6ebd-4d0d-8f93-2c1da8d47490",
            "6500989e-b1e1-4b02-a921-21ec25685b73",
            "6aac8d9c-34bd-42d9-b887-b0a3bd697ee6",
            "6eff83a4-db80-40ea-8c9f-8bda5f506c29",
            "7502e770-12f7-4fd1-8cd6-f54f456f7aa8",
            "a1b950a0-345b-4471-ba60-872e4f8cc058",
            "a369afee-a619-4e9a-9250-5fd2b06e8a05",
            "aa89fd2a-319e-48b1-b0ab-099acbe37617",
            "b7d7ec53-f079-4bd7-a795-8b6fe77f2db6",
            "c0ea675b-2479-48ae-817e-3ecedd175ecf",
            "c37c70cb-3956-4249-934d-848845f2f444",
            "e1263ada-afda-498c-a37d-9b545293118a",
            "e4ee2d81-7629-4445-b4f3-55ef57bd42fd"
        ],
        "keyword": [
            "node",
            "chord",
            "key",
            "item",
            "data",
            "system",
            "stores",
            "problem",
            "maps",
            "locate"
        ],
        "group": [
            {
                "4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4": {
                    "authors": [
                        "Ion Stoica",
                        "Robert Morris",
                        "David Liben-Nowell",
                        "David R. Karger",
                        "M. Frans Kaashoek",
                        "Frank Dabek",
                        "Hari Balakrishnan"
                    ],
                    "references": [
                        "1cc64868-4f72-4939-aed4-fc8fb0b45118",
                        "48740ddd-afd1-4331-8af7-224ef5d19ed7",
                        "59084791-6ebd-4d0d-8f93-2c1da8d47490",
                        "6aac8d9c-34bd-42d9-b887-b0a3bd697ee6",
                        "6eff83a4-db80-40ea-8c9f-8bda5f506c29",
                        "a369afee-a619-4e9a-9250-5fd2b06e8a05",
                        "aa89fd2a-319e-48b1-b0ab-099acbe37617",
                        "abf003a2-6485-41f0-a111-88b80412d539",
                        "b7d7ec53-f079-4bd7-a795-8b6fe77f2db6",
                        "b948f5db-4dc3-4151-a9bd-62a3f5be739e",
                        "c0ea675b-2479-48ae-817e-3ecedd175ecf",
                        "c37c70cb-3956-4249-934d-848845f2f444",
                        "e1263ada-afda-498c-a37d-9b545293118a",
                        "e4ee2d81-7629-4445-b4f3-55ef57bd42fd",
                        "ea44a1ae-ddfe-4694-8df1-0ec69182ec11",
                        "f14df1ed-e3e9-4348-9040-fc06e3411b95",
                        "f49921e2-fb25-48d1-aaf2-1afcfeb8b268",
                        "fad8fc34-ff78-45ac-bc30-ca9e4173740f"
                    ],
                    "keyword": [
                        "node",
                        "chord",
                        "key",
                        "data",
                        "system",
                        "stores",
                        "problem",
                        "maps",
                        "location",
                        "item"
                    ],
                    "group": [
                        null
                    ],
                    "_id": "4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4",
                    "abstract": "A fundamental problem that confronts peer-to-peer applications is the efficient location of the node that stores a desired data item. This paper presents  Chord , a distributed lookup protocol that addresses this problem. Chord provides support for just one operation: given a key, it maps the key onto a node. Data location can be easily implemented on top of Chord by associating a key with each data item, and storing the key/data pair at the node to which the key maps. Chord adapts efficiently as nodes join and leave the system, and can answer queries even if the system is continuously changing. Results from theoretical analysis and simulations show that Chord is scalable: Communication cost and the state maintained by each node scale logarithmically with the number of Chord nodes.",
                    "title": "Chord: a scalable peer-to-peer lookup protocol for Internet applications",
                    "venue": "IEEE\\/ACM Transactions on Networking",
                    "year": 2003,
                    "__v": 3,
                    "citationCount": 5975,
                    "result": 20.278015448603682
                },
                "59084791-6ebd-4d0d-8f93-2c1da8d47490": {
                    "authors": [
                        "Paul V. Mockapetris",
                        "Kevin J. Dunlap"
                    ],
                    "references": [
                        "9b65b2b8-9750-48b5-8f3c-790a85a0de96",
                        "aa18f452-d13c-4301-89c7-ca2bb0b89e85"
                    ],
                    "keyword": [
                        "service",
                        "ideas",
                        "evolution",
                        "dns",
                        "users",
                        "usages",
                        "unique",
                        "today",
                        "system",
                        "surprises"
                    ],
                    "group": [],
                    "_id": "59084791-6ebd-4d0d-8f93-2c1da8d47490",
                    "abstract": "The Domain Name System (DNS) provides name service for the DARPA Internet. It is one of the largest name services in operation today, serves a highly diverse community of hosts, users, and networks, and uses a unique combination of hierarchies, caching, and datagram access.  This paper examines the ideas behind the initial design of the DNS in 1983, discusses the evolution of these ideas into the current implementations and usages, notes conspicuous surprises, successes and shortcomings, and attempts to predict its future evolution.",
                    "title": "Development of the Domain Name System",
                    "venue": "acm special interest group on data communication",
                    "year": 1988,
                    "__v": 2,
                    "citationCount": 161,
                    "result": 3.6578865578865583
                },
                "6500989e-b1e1-4b02-a921-21ec25685b73": {
                    "authors": [
                        "William Adjie-Winoto",
                        "Elliot Schwartz",
                        "Hari Balakrishnan",
                        "Jeremy Lilley"
                    ],
                    "references": [
                        "00ade209-5974-42c1-9089-a3741481d9c7",
                        "1ece4859-34df-4469-bec1-5a6f3d26e8a4",
                        "2915a22c-b1dd-46e9-9082-40793a90abf9",
                        "2b7c69f7-54ce-4a5c-825f-1cb4fd1ea531",
                        "2d8951cc-a672-4a18-b12a-a50df100bcff",
                        "31c5e39a-3f24-4d20-bf8c-3d00036baf95",
                        "49c6311d-6f49-4df2-a2df-96887974ea00",
                        "4ae3d80b-ce75-4c33-8abb-c5358ec01a6d",
                        "59084791-6ebd-4d0d-8f93-2c1da8d47490",
                        "6a9c2062-e8eb-4584-8d40-35f8ed4e40d2",
                        "747c0c4a-1e59-4af3-a9a6-ad0d081a49ce",
                        "7c9f8cd8-d0ef-4954-b4db-4a6c803459c2",
                        "86104574-7932-4182-81f6-355252072a23",
                        "93f501e9-78e2-41a1-ab3e-d7923995967c",
                        "9b65b2b8-9750-48b5-8f3c-790a85a0de96",
                        "9e063b41-0ada-4db8-8846-6e5153a0de55",
                        "a511dcd6-cade-4dc0-aaf4-695df83487db",
                        "b045be7b-3691-41ca-ae2f-00b2dbaa1733",
                        "c2ae33d8-85e5-4d1d-8f17-b71a210b4546",
                        "de0be766-5520-44e1-804b-e65d134cfb46",
                        "e1c7443f-fbc7-4edc-919b-8f3bd2c1a34c"
                    ],
                    "keyword": [
                        "implementation",
                        "system",
                        "service",
                        "performance",
                        "describe",
                        "presents",
                        "networks",
                        "mobile",
                        "late",
                        "language"
                    ],
                    "group": [],
                    "_id": "6500989e-b1e1-4b02-a921-21ec25685b73",
                    "abstract": "This paper presents the design and implementation of the Intentional Naming System (INS), a resource discovery and service location system for dynamic and mobile networks of devices and computers. Such environments require a naming system that is (i) expressive, to describe and make requests based on specific properties of services, (ii) responsive, to track changes due to mobility and performance, (iii) robust, to handle failures, and (iv) easily configurable. INS uses a simple language based on attributes and values for its names. Applications use the language to describe what they are looking for (i.e., their  intent ), not where to find things (i.e., not hostnames). INS implements a  late binding  mechanism that integrates name resolution and message routing, enabling clients to continue communicating with end-nodes even if the name-to-address mappings change while a session is in progress. INS resolvers self-configure to form an application-level overlay network, which they use to discover new services, perform late binding, and maintain weak consistency of names using soft-state name exchanges and updates. We analyze the performance of the INS algorithms and protocols, present measurements of a Java-based implementation, and describe three applications we have implemented that demonstrate the feasibility and utility of INS.",
                    "title": "The design and implementation of an intentional naming system",
                    "venue": "symposium on operating systems principles",
                    "year": 1999,
                    "__v": 2,
                    "citationCount": 325,
                    "result": 6.890472676618187
                },
                "6aac8d9c-34bd-42d9-b887-b0a3bd697ee6": {
                    "authors": [
                        "Maarten van Steen",
                        "Franz J. Hauck",
                        "Gerco Ballintijn",
                        "Andrew S. Tanenbaum"
                    ],
                    "references": [
                        "22dc34f7-bd6a-4f3f-822c-6fe8d6d2bf43",
                        "24829bb4-274a-447b-b7a6-71695fb2e28d",
                        "2b02cc9c-4d97-41ca-94b7-503df0e53134",
                        "38ba7e7b-315a-4617-80fd-0556ee730c5d",
                        "3df02e7b-67df-4f8e-9031-5cf7d7f54a69",
                        "40b5fc96-9009-4201-8b6f-7ccb8e389165",
                        "4e8c7d2e-b6fb-42d5-b543-cba29b4fca7c",
                        "5320bc98-beb8-4b2c-b906-3a05df4e018c",
                        "553e719c-81cd-4191-9c68-f0adf7c15361",
                        "5983f4cf-0d99-444b-8b95-9c635bf20d20",
                        "5c7e3099-b047-4152-bb6d-de884f94cafc",
                        "5e43bfa1-e1fa-428f-847f-b1b575380d14",
                        "5e8be929-7c33-4976-b583-2b41790fe4be",
                        "61058526-954d-4e68-8f11-db9c4dab0689",
                        "747c0c4a-1e59-4af3-a9a6-ad0d081a49ce",
                        "7f1dc63a-9064-4768-a30d-3383d52aa81e",
                        "89ba9c4f-5643-4643-9a65-47bc724723b4",
                        "e9ad62a7-612c-4581-ac73-8b008c5f797a"
                    ],
                    "keyword": [
                        "objects",
                        "location",
                        "distributed",
                        "addresses",
                        "worldwide",
                        "set",
                        "service",
                        "operations",
                        "lookup",
                        "highly"
                    ],
                    "group": [],
                    "_id": "6aac8d9c-34bd-42d9-b887-b0a3bd697ee6",
                    "abstract": "We describe the algorithmic design of a worldwide location service for distributed objects. A distributed object can reside at multiple locations at the same time, and offers a set of addresses to allow client processes to contact it. Objects may be highly mobile like, for example, software agents or Web applets. The proposed location service supports regular updates of an object's set of contact addresses, as well as efficient look-up operations. Our design is based on a worldwide distributed search tree in which addresses are stored at different levels, depending on the migration pattern of the object. By exploiting an object's relative stability with respect to a region, combined with the use of pointer caches, look-up operations can be made highly efficient.",
                    "title": "Algorithmic Design of the Globe Wide-Area Location Service",
                    "venue": "The Computer Journal",
                    "year": 1998,
                    "__v": 2,
                    "citationCount": 16,
                    "result": 3.0400599400599404
                },
                "7502e770-12f7-4fd1-8cd6-f54f456f7aa8": {
                    "authors": [
                        "Frank Dabek",
                        "Emma Brunskill",
                        "M.F. Kaashoek",
                        "David R. Karger",
                        "Robert Morris",
                        "Ion Stoica",
                        "Hamsa Balakrishnan"
                    ],
                    "references": [
                        "1c729f22-9928-4703-92a0-8819569a1bbb",
                        "1cc64868-4f72-4939-aed4-fc8fb0b45118",
                        "48740ddd-afd1-4331-8af7-224ef5d19ed7",
                        "4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4",
                        "6eff83a4-db80-40ea-8c9f-8bda5f506c29",
                        "9f65fe84-a2e3-420a-8fe4-7253e4605422",
                        "c0ea675b-2479-48ae-817e-3ecedd175ecf",
                        "e1263ada-afda-498c-a37d-9b545293118a",
                        "e4ee2d81-7629-4445-b4f3-55ef57bd42fd"
                    ],
                    "keyword": [],
                    "group": [],
                    "_id": "7502e770-12f7-4fd1-8cd6-f54f456f7aa8",
                    "abstract": "We argue that the core problem facing peer-to-peer Systems is locating documents in a decentralized network and propose Chord, a distributed lookup primitive. Chord provides an efficient method of locating documents while placing few constraints on the applications that use it. As proof that Chord's functionality is useful in the development of peer-to-peer applications, we outline the implementation of a peer-to-peer file sharing system based on Chord.",
                    "title": "Building peer-to-peer systems with chord, a distributed lookup service",
                    "venue": "ieee international conference on requirements engineering",
                    "year": 2001,
                    "__v": 0,
                    "citationCount": 108,
                    "result": 4.705882352941177
                },
                "a1b950a0-345b-4471-ba60-872e4f8cc058": {
                    "authors": [
                        "Sally Floyd",
                        "Van Jacobson"
                    ],
                    "references": [
                        "19a6c722-ce16-4044-8469-273c0971ca03",
                        "19c730f7-24d3-4c1f-9c85-af826d0509b5",
                        "5d7d8304-f78d-4332-aefd-4f4d8d78f0e1",
                        "bf785568-5826-4228-998d-e21823dfc8ab"
                    ],
                    "keyword": [
                        "synchronized",
                        "traffic",
                        "processes",
                        "periodic",
                        "network",
                        "inadvertently",
                        "addition",
                        "unsynchronized",
                        "transition",
                        "study"
                    ],
                    "group": [],
                    "_id": "a1b950a0-345b-4471-ba60-872e4f8cc058",
                    "abstract": "The paper considers a network with many apparently-independent periodic processes and discusses one method by which these processes can inadvertently become synchronized. In particular, we study the synchronization of periodic routing messages. We give examples of the harmful effect of these synchronized updates on other network traffic, and offer guidelines on how to avoid inadvertent synchronization. Using simulations and analysis, we study the process of synchronization and show that the transition from unsynchronized to synchronized traffic is not one of gradual degradation but is instead a very abrupt 'phase transition': in general, the addition of a single router will convert a completely unsynchronized traffic stream into a completely synchronized one. We show that synchronization can be avoided by the addition of randomization to the traffic sources and quantify how much randomization is necessary. In addition, we argue that the inadvertent synchronization of periodic processes is likely to become an increasing problem in computer networks.",
                    "title": "The synchronization of periodic routing messages",
                    "venue": "acm special interest group on data communication",
                    "year": 1993,
                    "__v": 2,
                    "citationCount": 37,
                    "result": 3.0649650573025182
                },
                "a369afee-a619-4e9a-9250-5fd2b06e8a05": {
                    "authors": [
                        "David G. Andersen",
                        "Hari Balakrishnan",
                        "M. Frans Kaashoek",
                        "Robert Morris"
                    ],
                    "references": [
                        "01a09d2c-f8d3-40e4-bfee-211533b3f526",
                        "030d5be6-55f2-4776-85fd-c8924e5fac85",
                        "05b6c845-f269-4f70-86ff-a2d89b60e6b5",
                        "1642f59c-10a1-40da-abb1-0934ef864108",
                        "2915a22c-b1dd-46e9-9082-40793a90abf9",
                        "3d02b614-3aa0-4647-9e95-8e3fde4c4371",
                        "4152f693-19b7-4de5-bd38-d25341487814",
                        "436b5fcd-6488-4a4c-b41a-85130718b39a",
                        "4b5c9003-da3b-4a1c-9ddd-0262278668e5",
                        "5de99dee-6647-4ebf-b20b-fe970cfd062b",
                        "69c181d4-c63d-4951-bce6-e44733a2f3c5",
                        "71e44140-b60b-4385-b0f5-31c33c7b5ccc",
                        "8df0f1e0-c75c-4c63-81d9-b8ab58daa4fd",
                        "8ed0c977-c4e4-4183-8ec3-b2fc7bea41cf",
                        "96562dc6-4016-4259-bb10-e29d0e09e6b8",
                        "b3cae739-ffac-48c0-b164-11b3088cc22c",
                        "b893a5b5-0e77-44b8-9cd9-6157c96558af",
                        "c3feb1e8-16d7-43af-946a-7ef9b37ca2bd"
                    ],
                    "keyword": [
                        "ron",
                        "routing",
                        "internet",
                        "path",
                        "improving",
                        "detect",
                        "transfers",
                        "recover",
                        "nodes",
                        "fault"
                    ],
                    "group": [],
                    "_id": "a369afee-a619-4e9a-9250-5fd2b06e8a05",
                    "abstract": "A Resilient Overlay Network (RON) is an architecture that allows distributed Internet applications to detect and recover from path outages and periods of degraded performance within several seconds, improving over today's wide-area routing protocols that take at least several minutes to recover. A RON is an application-layer overlay on top of the existing Internet routing substrate. The RON nodes monitor the functioning and quality of the Internet paths among themselves, and use this information to decide whether to route packets directly over the Internet or by way of other RON nodes, optimizing application-specific routing metrics.Results from two sets of measurements of a working RON deployed at sites scattered across the Internet demonstrate the benefits of our architecture. For instance, over a 64-hour sampling period in March 2001 across a twelve-node RON, there were 32 significant outages, each lasting over thirty minutes, over the 132 measured paths. RON's routing mechanism was able to detect, recover, and route around  all  of them, in less than twenty seconds on average, showing that its methods for fault detection and recovery work well at discovering alternate paths in the Internet. Furthermore, RON was able to improve the loss rate, latency, or throughput perceived by data transfers; for example, about 5% of the transfers doubled their TCP throughput and 5% of our transfers saw their loss probability reduced by 0.05. We found that forwarding packets via at most one intermediate RON node is sufficient to overcome faults and improve performance in most cases. These improvements, particularly in the area of fault detection and recovery, demonstrate the benefits of moving some of the control over routing into the hands of end-systems.",
                    "title": "Resilient overlay networks",
                    "venue": "symposium on operating systems principles",
                    "year": 2001,
                    "__v": 2,
                    "citationCount": 1043,
                    "result": 3.98023088023088
                },
                "b7d7ec53-f079-4bd7-a795-8b6fe77f2db6": {
                    "authors": [
                        "Frank Dabek",
                        "M. Frans Kaashoek",
                        "David R. Karger",
                        "Robert Morris",
                        "Ion Stoica"
                    ],
                    "references": [
                        "1c729f22-9928-4703-92a0-8819569a1bbb",
                        "1cc64868-4f72-4939-aed4-fc8fb0b45118",
                        "1dda408f-2203-4793-bfa8-2fab15bce7cf",
                        "48740ddd-afd1-4331-8af7-224ef5d19ed7",
                        "4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4",
                        "5e354aca-2d93-43f7-8e80-6bc4eb96e7d9",
                        "5fa0709f-7330-417f-8da7-3ab31d91da5b",
                        "6eff83a4-db80-40ea-8c9f-8bda5f506c29",
                        "786e7d9f-6e9a-47e5-8482-7ee37809b922",
                        "9f65fe84-a2e3-420a-8fe4-7253e4605422",
                        "a369afee-a619-4e9a-9250-5fd2b06e8a05",
                        "b1ab8eee-7043-4f04-b440-5765752d4845",
                        "b90c5640-8e10-4f65-9193-c28af80f45e2",
                        "bd61df44-c80e-406c-8c4e-9c13635ce4f5",
                        "c0ea675b-2479-48ae-817e-3ecedd175ecf",
                        "cb0dcdc4-3c84-4301-891b-42535ac74f8c",
                        "cf67f4c1-ff76-4210-ba80-0356733c5be7",
                        "e1263ada-afda-498c-a37d-9b545293118a",
                        "f14df1ed-e3e9-4348-9040-fc06e3411b95"
                    ],
                    "keyword": [
                        "cfs",
                        "servers",
                        "system",
                        "block",
                        "file",
                        "dhash",
                        "storage",
                        "robustness"
                    ],
                    "group": [],
                    "_id": "b7d7ec53-f079-4bd7-a795-8b6fe77f2db6",
                    "abstract": "The Cooperative File System (CFS) is a new peer-to-peer read-only storage system that provides provable guarantees for the efficiency, robustness, and load-balance of file storage and retrieval. CFS does this with a completely decentralized architecture that can scale to large systems. CFS servers provide a distributed hash table (DHash) for block storage. CFS clients interpret DHash blocks as a file system. DHash distributes and caches blocks at a fine granularity to achieve load balance, uses replication for robustness, and decreases latency with server selection. DHash finds blocks using the Chord location protocol, which operates in time logarithmic in the number of servers.CFS is implemented using the SFS file system toolkit and runs on Linux, OpenBSD, and FreeBSD. Experience on a globally deployed prototype shows that CFS delivers data to clients as fast as FTP. Controlled tests show that CFS is scalable: with 4,096 servers, looking up a block of data involves contacting only seven servers. The tests also demonstrate nearly perfect robustness and unimpaired performance even when as many as half the servers fail.",
                    "title": "Wide-area cooperative storage with CFS",
                    "venue": "symposium on operating systems principles",
                    "year": 2001,
                    "__v": 2,
                    "citationCount": 784,
                    "result": 9.276878023936849
                },
                "e1263ada-afda-498c-a37d-9b545293118a": {
                    "authors": [
                        "Sylvia Ratnasamy",
                        "Paul Francis",
                        "Mark Handley",
                        "Richard M. Karp",
                        "Scott Shenker"
                    ],
                    "references": [
                        "00ade209-5974-42c1-9089-a3741481d9c7",
                        "0695070f-320e-4d26-9c68-2c8faa20c944",
                        "0a094924-1b25-43cc-ac8b-dd8cf90a8f78",
                        "1545dfd3-2c25-4ff1-b43c-df4a2a501d06",
                        "1cc64868-4f72-4939-aed4-fc8fb0b45118",
                        "31c5e39a-3f24-4d20-bf8c-3d00036baf95",
                        "39adcd6c-0b60-430c-99ab-21cd9e98b385",
                        "42c70869-0dad-4629-93b5-a2d9e29071a7",
                        "4743d708-b82d-42ec-adaa-a8bf2f23cc38",
                        "483cb980-c968-48e6-b848-714ed2937f98",
                        "48740ddd-afd1-4331-8af7-224ef5d19ed7",
                        "4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4",
                        "88c35cd8-dd49-44f8-9674-96974c8f3650",
                        "c0ea675b-2479-48ae-817e-3ecedd175ecf",
                        "c8771a57-de9c-44b7-966c-1ff156d3091f",
                        "d06f8723-1b89-4684-99c9-c1045ddfb85c",
                        "e4ee2d81-7629-4445-b4f3-55ef57bd42fd",
                        "ec7d1720-3285-4729-b819-b4c58a826ec8",
                        "f6fc4443-7a98-4f9f-92e8-e4e5d94521a7"
                    ],
                    "keyword": [
                        "systems",
                        "scalable",
                        "hash",
                        "functionality",
                        "distributed",
                        "valuable",
                        "values",
                        "tablelike",
                        "tables",
                        "software"
                    ],
                    "group": [
                        null
                    ],
                    "_id": "e1263ada-afda-498c-a37d-9b545293118a",
                    "abstract": "Hash tables - which map \"keys\" onto \"values\" - are an essential building block in modern software systems. We believe a similar functionality would be equally valuable to large distributed systems. In this paper, we introduce the concept of a Content-Addressable Network (CAN) as a distributed infrastructure that provides hash table-like functionality on Internet-like scales. The CAN is scalable, fault-tolerant and completely self-organizing, and we demonstrate its scalability, robustness and low-latency properties through simulation.",
                    "title": "A scalable content-addressable network",
                    "venue": "acm special interest group on data communication",
                    "year": 2001,
                    "__v": 3,
                    "citationCount": 3635,
                    "result": 8.275414454826219
                },
                "e4ee2d81-7629-4445-b4f3-55ef57bd42fd": {
                    "authors": [
                        "Jinyang Li",
                        "John Jannotti",
                        "Douglas S. J. De Couto",
                        "David R. Karger",
                        "Robert Morris"
                    ],
                    "references": [
                        "0d4d0363-07b5-43b6-976d-955e96044709",
                        "1545dfd3-2c25-4ff1-b43c-df4a2a501d06",
                        "39adcd6c-0b60-430c-99ab-21cd9e98b385",
                        "60fb0dc2-bde3-4714-948e-de0ed12ab460",
                        "6eff83a4-db80-40ea-8c9f-8bda5f506c29",
                        "7c9f8cd8-d0ef-4954-b4db-4a6c803459c2",
                        "83a2eb55-b330-4e0c-8dc9-05e9466d5028",
                        "9de43d04-c7fa-48a9-b092-67c2888745d4",
                        "c7b0d60b-9956-4254-b6d3-26fb1f8782bb",
                        "e3af190a-754d-415d-a32d-f1d9999c599f",
                        "ff4259bb-5b84-4f51-b975-146794715d22"
                    ],
                    "keyword": [
                        "node",
                        "location",
                        "gls",
                        "mobile",
                        "networks",
                        "servers",
                        "queries",
                        "predefined",
                        "geographic"
                    ],
                    "group": [],
                    "_id": "e4ee2d81-7629-4445-b4f3-55ef57bd42fd",
                    "abstract": "GLS is a new distributed location service which tracks mobile node locations. GLS combined with geographic forwarding allows the construction of ad hoc mobile networks that scale to a larger number of nodes than possible with previous work. GLS is decentralized and runs on the mobile nodes themselves, requiring no fixed infrastructure. Each mobile node periodically updates a small set of other nodes (its location servers) with its current location. A node sends its position updates to its location servers without knowing their actual identities, assisted by a predefined ordering of node identifiers and a predefined geographic hierarchy. Queries for a mobile node's location also use the predefined identifier ordering and spatial hierarchy to find a location server for that node.  Experiments using the  ns  simulator for up to 600 mobile nodes show that the storage and bandwidth requirements of GLS grow slowly with the size of the network. Furthermore, GLS tolerates node failures well: each failure has only a limited effect and query performance degrades gracefully as nodes fail and restart. The query performance of GLS is also relatively insensitive to node speeds. Simple geographic forwarding combined with GLS compares favorably with Dynamic Source Routing (DSR): in larger networks (over 200 nodes) our approach delivers more packets, but consumes fewer network resources.",
                    "title": "A scalable location service for geographic ad hoc routing",
                    "venue": "acm ieee international conference on mobile computing and networking",
                    "year": 2000,
                    "__v": 2,
                    "citationCount": 786,
                    "result": 3.9583651642475175
                }
            }
        ],
        "_id": "d06f8723-1b89-4684-99c9-c1045ddfb85c",
        "abstract": "A fundamental problem that confronts peer-to-peer applications is to efficiently locate the node that stores a particular data item. This paper presents  Chord , a distributed lookup protocol that addresses this problem. Chord provides support for just one operation: given a key, it maps the key onto a node. Data location can be easily implemented on top of Chord by associating a key with each data item, and storing the key/data item pair at the node to which the key maps. Chord adapts efficiently as nodes join and leave the system, and can answer queries even if the system is continuously changing. Results from theoretical analysis, simulations, and experiments show that Chord is scalable, with communication cost and the state maintained by each node scaling logarithmically with the number of Chord nodes.",
        "title": "Chord: A scalable peer-to-peer lookup service for internet applications",
        "venue": "acm special interest group on data communication",
        "year": 2001,
        "__v": 2,
        "citationCount": 2568
    },
    {
        "authors": [
            "Latanya Sweeney"
        ],
        "references": [
            "0209f687-94ed-4db7-8ae4-67544a5c5db7",
            "51a45f4f-73ab-4b4f-bbb8-706a227fada2",
            "5667dd20-726f-4c54-9cae-3707e5dbf524",
            "81e0014b-324f-4591-bbd7-4df76f4ff3cd",
            "8f481941-6df4-4777-9fbb-489c02b185f5",
            "c84bdc51-9901-4d62-9c9b-5a48394ad4bc",
            "df4b9319-db76-4f7f-b9b2-74f04347269d",
            "e2f4b493-660e-4a12-98c2-eea39795f758",
            "efe2dd1d-706c-4ab6-bd9b-90d35a81d04f",
            "fb733d35-ff61-449f-aa05-d8614cbc761b",
            "ff6cef9f-eb6b-4767-bcbe-6ad0b4c6045d"
        ],
        "keyword": [
            "data",
            "release",
            "protection",
            "kanonymity",
            "holder",
            "version",
            "privately",
            "policies",
            "paper",
            "model"
        ],
        "group": [
            {
                "0209f687-94ed-4db7-8ae4-67544a5c5db7": {
                    "authors": [
                        "Thomas D. Garvey",
                        "Teresa F. Lunt",
                        "Mark E. Stickel"
                    ],
                    "references": [
                        "1acbb25a-3d1d-4948-a5cb-3274a87f6f76",
                        "24290f50-77cf-4935-89ea-919661b26586",
                        "2a73f987-98cc-4d8b-bf27-9d8d0834c57c",
                        "35375ee8-7dcc-4aec-9681-da295f24f969",
                        "3c36cf62-5101-4658-ba45-1301367c2a05",
                        "52dbdaf9-3754-4ee1-9a0a-4bda0029584d",
                        "9454ef50-a153-42b1-bb0c-606fac619396",
                        "c84bdc51-9901-4d62-9c9b-5a48394ad4bc",
                        "df4b9319-db76-4f7f-b9b2-74f04347269d",
                        "fb733d35-ff61-449f-aa05-d8614cbc761b",
                        "fd49e58a-e24d-44a4-9b4d-613195282174",
                        "ff6cef9f-eb6b-4767-bcbe-6ad0b4c6045d"
                    ],
                    "keyword": [],
                    "group": [],
                    "_id": "0209f687-94ed-4db7-8ae4-67544a5c5db7",
                    "abstract": "A serious problem in computer database and knowledge base security is detecting and eliminating so-called inference channels. The existence of such channels enables a user with access to information classified at a low level to infer information classified at a high level, and through the transformation of low level data to high level data may provide an unacceptable information flow. In order to estimate the presence of inference channels, determine the degree of risk which they present, and find ways to eliminate them, one needs a formal model to describe them. The authors introduce abductive reasoning. Abduction provides both the basis for a formal model for the inference problem and a computational mechanism for detecting inference channels. Abduction additionally provides a framework for reasoning with approximate and uncertain information, which enables them to extend the model for inference channels by taking into account the likelihood that a person might believe some statement of interest. >",
                    "title": "Abductive and approximate reasoning models for characterizing inference channels",
                    "venue": "",
                    "year": 1991,
                    "__v": 0,
                    "citationCount": 8,
                    "result": 3.6363636363636367
                },
                "51a45f4f-73ab-4b4f-bbb8-706a227fada2": {
                    "authors": [
                        "Tzong-An Su",
                        "Gultekin Ozsoyoglu"
                    ],
                    "references": [
                        "03428ab6-0ba0-4d0e-909c-4dad7123be75",
                        "24290f50-77cf-4935-89ea-919661b26586",
                        "49de08c1-d0a0-456b-b59f-39d4b10824fd",
                        "5667dd20-726f-4c54-9cae-3707e5dbf524",
                        "62e4a0d2-48f0-44be-9f18-8568cded78d3",
                        "894a8e14-edf6-4321-93b8-337a466adb62",
                        "8e090712-cb99-4457-a10d-cc00e8c35a8c",
                        "a320fce0-572c-4cad-a298-4ecc4563728c",
                        "b6ba1cd3-3297-4eb1-8a18-76fd56f70a77",
                        "c84bdc51-9901-4d62-9c9b-5a48394ad4bc",
                        "cc506bf9-b87f-4f23-a2b9-d7b1ea8c733f"
                    ],
                    "keyword": [
                        "dependencies",
                        "prevent",
                        "functional",
                        "set",
                        "relational",
                        "problems",
                        "mvds",
                        "mvdcompromises",
                        "inference",
                        "due"
                    ],
                    "group": [],
                    "_id": "51a45f4f-73ab-4b4f-bbb8-706a227fada2",
                    "abstract": "The authors investigate the inference problems due to functional dependencies (FD) and multivalued dependencies (MVD) in a multilevel relational database (MDB) with attribute and record classification schemes, respectively. The set of functional dependencies to be taken into account in order to prevent FD-compromises is determined. It is proven that incurring minimum information loss to prevent compromises is an NP-complete problem. An exact algorithm to adjust the attribute levels so that no compromise due to functional dependencies occurs is given. Some necessary and sufficient conditions for MVD-compromises are presented. The set of MVDs to be taken into account for controlling inferences is determined. An algorithm to prevent MVD-compromises in a relation with conflict-free MVDs is given. >",
                    "title": "Controlling FD and MVD inferences in multilevel relational database systems",
                    "venue": "IEEE Transactions on Knowledge and Data Engineering",
                    "year": 1991,
                    "__v": 2,
                    "citationCount": 29,
                    "result": 7.475147685132206
                },
                "5667dd20-726f-4c54-9cae-3707e5dbf524": {
                    "authors": [
                        "Dorothy E. Denning",
                        "Teresa F. Lunt"
                    ],
                    "references": [],
                    "keyword": [
                        "relational",
                        "model",
                        "multilevel",
                        "standard",
                        "data",
                        "operational",
                        "integrity",
                        "consists",
                        "classes",
                        "attributes"
                    ],
                    "group": [],
                    "_id": "5667dd20-726f-4c54-9cae-3707e5dbf524",
                    "abstract": "A multilevel relational data model that meets the basic operational requirements for a multilevel database system is described. The model is an extension of the standard relational model, and consists of multilevel relations, which contain classification attributes as well as data attributes; multilevel relational integrity rules, which extend the integrity constraints of the relational model in order to pro vide consistency for data at different access classes, including data that becomes \"polyinstantiated,\" a decomposition method for mapping all multilevel real relations into standard (single-level) base relations; and multilevel relational operators, which perform the functions of their counterparts in the standard relational model, while also labeling derived tuples with access classes. The model is defined in terms of the standard relational model, but lends itself to a design and implementation that offers a high level of assurance for mandatory security.",
                    "title": "A Multilevel Relational Data Model",
                    "venue": "ieee symposium on security and privacy",
                    "year": 1987,
                    "__v": 1,
                    "citationCount": 67,
                    "result": 9.495485551600103
                },
                "81e0014b-324f-4591-bbd7-4df76f4ff3cd": {
                    "authors": [
                        "George T. Duncan",
                        "Sumitra Mukherjee"
                    ],
                    "references": [
                        "0269384b-c7d8-4419-97a5-45a9482313b9",
                        "3b86307d-ca4a-4bfd-8244-a880a4fbe0f5",
                        "7b7b8ac1-d61f-4b87-b745-73352713e600",
                        "7db69b88-368f-492c-aeb2-12badd95c6f6",
                        "8f481941-6df4-4777-9fbb-489c02b185f5",
                        "b0a98636-3176-4a05-a53d-08b691fc0e3f",
                        "ca42ebb4-5b33-46d1-b03b-07ddeb1247d4",
                        "df4b9319-db76-4f7f-b9b2-74f04347269d"
                    ],
                    "keyword": [
                        "control",
                        "query",
                        "disclosure",
                        "mechanisms",
                        "size",
                        "set",
                        "scheme",
                        "sample",
                        "risk",
                        "results"
                    ],
                    "group": [],
                    "_id": "81e0014b-324f-4591-bbd7-4df76f4ff3cd",
                    "abstract": "A probabilistic framework can be used to assess the risk of disclosure of confidential information in statistical databases that use disclosure control mechanisms. The authors show how the method may be used to assess the strengths and weaknesses of two existing disclosure control mechanisms: the query set size restriction control and random sample query control mechanisms. Results indicate that neither scheme provides adequate security. The framework is then further exploited to analyze an alternative scheme combining query set size restriction and random sample query control. It is shown that this combination results in a significant decrease in the risk of disclosure. >",
                    "title": "Microdata disclosure limitation in statistical databases: query size and random sample query control",
                    "venue": "ieee symposium on security and privacy",
                    "year": 1991,
                    "__v": 2,
                    "citationCount": 9,
                    "result": 4.904662004662004
                },
                "8f481941-6df4-4777-9fbb-489c02b185f5": {
                    "authors": [
                        "Dorothy E. Denning",
                        "Peter J. Denning",
                        "Mayer D. Schwartz"
                    ],
                    "references": [
                        "24226d0c-e599-4122-b8e7-bb3ee70c2bbb",
                        "26394507-f6ed-45c4-93b8-470108a955d1",
                        "4591f25f-7cc0-4f77-a484-b4b4b4ebccb3",
                        "5a1e08ed-4430-4a90-b4d1-33812b0b8691",
                        "5e1ee9bb-e5dc-4617-8f6a-027698a729a7",
                        "7e219fae-4077-40ed-aaad-218c9eb93009",
                        "853ac12c-3ee1-4883-a98a-235ff4c08e46",
                        "a029b610-3471-4010-b467-badec09570a5",
                        "c09f1d86-df13-4c6b-8461-e3545ee8756b",
                        "ca42ebb4-5b33-46d1-b03b-07ddeb1247d4",
                        "d48e012d-fe73-44e1-8a64-d1c08413b977"
                    ],
                    "keyword": [
                        "trackers",
                        "query",
                        "sets",
                        "general",
                        "statistics",
                        "individual",
                        "databases",
                        "characteristic",
                        "small",
                        "report"
                    ],
                    "group": [],
                    "_id": "8f481941-6df4-4777-9fbb-489c02b185f5",
                    "abstract": "The query programs of certain databases report raw statistics for query sets, which are groups of records specified implicitly by a characteristic formula. The raw statistics include query set size and sums of powers of values in the query set. Many users and designers believe that the individual records will remain confidential as long as query programs refuse to report the statistics of query sets which are too small. It is shown that the compromise of small query sets can in fact almost always be accomplished with the help of characteristic formulas called trackers. Schlorer's individual tracker is reviewed; it is derived from known characteristics of a given individual and permits deducing additional characteristics he may have. The general tracker is introduced: It permits calculating statistics for arbitrary query sets, without requiring preknowledge of anything in the database. General trackers always exist if there are enough distinguishable classes of individuals in the database, in which case the trackers have a simple form. Almost all databases have a general tracker, and general trackers are almost always easy to find. Security is not guaranteed by the lack of a general tracker.",
                    "title": "The tracker: a threat to statistical database security",
                    "venue": "ACM Transactions on Database Systems",
                    "year": 1979,
                    "__v": 2,
                    "citationCount": 91,
                    "result": 5.239056815217806
                },
                "e2f4b493-660e-4a12-98c2-eea39795f758": {
                    "authors": [
                        "Xiaolei Qian",
                        "Mark E. Stickel",
                        "Peter D. Karp",
                        "Teresa F. Lunt",
                        "Thomas D. Garvey"
                    ],
                    "references": [
                        "0209f687-94ed-4db7-8ae4-67544a5c5db7",
                        "1e41711b-949a-4109-986c-f213f9830bee",
                        "24290f50-77cf-4935-89ea-919661b26586",
                        "74a50e84-8cd8-4bd3-8163-27ec4e577f67",
                        "c84bdc51-9901-4d62-9c9b-5a48394ad4bc",
                        "d5035f5a-5063-4de8-855f-4a61b92c6bbd",
                        "fb733d35-ff61-449f-aa05-d8614cbc761b"
                    ],
                    "keyword": [
                        "inference",
                        "problem",
                        "upgrading",
                        "security",
                        "information",
                        "database",
                        "classifications",
                        "store",
                        "schemas",
                        "relationships"
                    ],
                    "group": [],
                    "_id": "e2f4b493-660e-4a12-98c2-eea39795f758",
                    "abstract": "Multilevel relational database systems store information at different security classifications. An inference problem exists if it is possible for a user with a low-level clearance to draw conclusions about information at higher classifications. The authors are developing DISSECT, a tool for analyzing multilevel relational database schemas to assist in the detection and elimination of inference problems. A translation is defined from schemas to an equivalent graph representation, which can be presented graphically in DISSECT. The initial focus is on detection of inference problems that depend only on information all of which is stored in the database. In particular, potential inference problems are identified as different sequences of foreign key relationships that connect the same entities. Inferences can be blocked by upgrading the security classification of some of foreign key relationships. A global optimization approach to upgrading is suggested to block a set of inference problems that allows upgrade costs to be considered, and supports security categories as well as levels. >",
                    "title": "Detection and elimination of inference channels in multilevel relational database systems",
                    "venue": "ieee symposium on security and privacy",
                    "year": 1993,
                    "__v": 2,
                    "citationCount": 26,
                    "result": 9.250922491755714
                },
                "ff6cef9f-eb6b-4767-bcbe-6ad0b4c6045d": {
                    "authors": [
                        "Teresa F. Lunt"
                    ],
                    "references": [
                        "24290f50-77cf-4935-89ea-919661b26586",
                        "3356c6f8-6a10-4ebd-894b-eceece1da867",
                        "894a8e14-edf6-4321-93b8-337a466adb62",
                        "c84bdc51-9901-4d62-9c9b-5a48394ad4bc",
                        "df4b9319-db76-4f7f-b9b2-74f04347269d",
                        "fb733d35-ff61-449f-aa05-d8614cbc761b"
                    ],
                    "keyword": [
                        "sensitive",
                        "associations",
                        "types",
                        "problems",
                        "entities",
                        "treated",
                        "inference",
                        "aggregation",
                        "storing",
                        "separately"
                    ],
                    "group": [],
                    "_id": "ff6cef9f-eb6b-4767-bcbe-6ad0b4c6045d",
                    "abstract": "The author examines inference and aggregation problems that can arise in multilevel relational database systems and points out some fallacies in current thinking about these problems that may hinder real progress from being made toward their solution. She distinguishes several different types of aggregation and inference problems and shows that the different types of problems are best addressed by different approaches. In particular, it is shown that sensitive associations among entities of different types are best treated by representing the sensitive association separately and classifying the individual entities low and the relationship high. Sensitive associations among the various properties of an entity are best treated by determining those properties that contribute most to the inference and by storing those separately at a higher classification. Sensitive associations among entities of the same type are best treated by storing the individual data items comprising the aggregate at the aggregate-high classification; they must be sanitized for release to lower-level users. The suggested approaches allow the mandatory reference monitor to protect the sensitive associations, with no additional trusted mechanism needed. >",
                    "title": "Aggregation and inference: facts and fallacies",
                    "venue": "ieee symposium on security and privacy",
                    "year": 1989,
                    "__v": 2,
                    "citationCount": 37,
                    "result": 10.394291278037409
                }
            }
        ],
        "_id": "d3b0635e-5447-435d-9975-a2582d19fc37",
        "abstract": "Consider a data holder, such as a hospital or a bank, that has a privately held collection of person-specific, field structured data. Suppose the data holder wants to share a version of the data with researchers. How can a data holder release a version of its private data with scientific guarantees that the individuals who are the subjects of the data cannot be re-identified while the data remain practically useful? The solution provided in this paper includes a formal protection model named k-anonymity and a set of accompanying policies for deployment. A release provides k-anonymity protection if the information for each person contained in the release cannot be distinguished from at least k-1 individuals whose information also appears in the release. This paper also examines re-identification attacks that can be realized on releases that adhere to k- anonymity unless accompanying policies are respected. The k-anonymity protection model is important because it forms the basis on which the real-world systems known as Datafly, µ-Argus and k-Similar provide guarantees of privacy protection.",
        "title": "k -anonymity: a model for protecting privacy",
        "venue": "International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems",
        "year": 2002,
        "__v": 2,
        "citationCount": 2258
    },
    {
        "authors": [
            "M.S. Arulampalam",
            "Simon Maskell",
            "Neil J. Gordon",
            "T. Clapp"
        ],
        "references": [
            "31548231-500c-4604-b6a5-529d00d691dd",
            "5f54fdf9-4d11-4f33-945a-db3caa7fabce",
            "67efeb3a-56bb-4bd8-bc0b-dca8f84fa3d3",
            "8b5a79a9-8c51-4a30-9be2-f4ee63af7949",
            "ab421de9-79db-4fa2-97a5-f2437bc3cc46",
            "c2542b2b-306a-41a7-b774-be7cd5f3f186",
            "c4140a7e-f036-4816-a82f-9035ca99ed97"
        ],
        "keyword": [
            "particle",
            "filters",
            "sequential",
            "point",
            "model",
            "methods",
            "important",
            "algorithms"
        ],
        "group": [
            {
                "5f54fdf9-4d11-4f33-945a-db3caa7fabce": {
                    "authors": [
                        "Rudolph van der Merwe",
                        "Arnaud Doucet",
                        "Nando de Freitas",
                        "Eric A. Wan"
                    ],
                    "references": [
                        "3d1176ea-1640-4c89-9f19-6d7beb29b64b",
                        "67efeb3a-56bb-4bd8-bc0b-dca8f84fa3d3",
                        "6f31e502-ddfd-4f68-8ee7-abedabf4cd29"
                    ],
                    "keyword": [
                        "filter",
                        "algorithm",
                        "propose",
                        "particle",
                        "importance",
                        "find"
                    ],
                    "group": [],
                    "_id": "5f54fdf9-4d11-4f33-945a-db3caa7fabce",
                    "abstract": "In this paper, we propose a new particle filter based on sequential importance sampling. The algorithm uses a bank of unscented filters to obtain the importance proposal distribution. This proposal has two very \"nice\" properties. Firstly, it makes efficient use of the latest available information and, secondly, it can have heavy tails. As a result, we find that the algorithm outperforms standard particle filtering and other nonlinear filtering methods very substantially. This experimental finding is in agreement with the theoretical convergence proof for the algorithm. The algorithm also includes resampling and (possibly) Markov chain Monte Carlo (MCMC) steps.",
                    "title": "The Unscented Particle Filter",
                    "venue": "neural information processing systems",
                    "year": 2001,
                    "__v": 2,
                    "citationCount": 364,
                    "result": 7.120290004113533
                },
                "67efeb3a-56bb-4bd8-bc0b-dca8f84fa3d3": {
                    "authors": [
                        "Arnaud Doucet",
                        "Simon J. Godsill",
                        "Christophe Andrieu"
                    ],
                    "references": [
                        "86d0e2c0-e62b-411a-99d6-76bbe7295536",
                        "ab421de9-79db-4fa2-97a5-f2437bc3cc46",
                        "b1367519-5742-468f-834f-19421b79b2e3",
                        "be85d125-170b-41b8-8182-4f5680ac30c2"
                    ],
                    "keyword": [
                        "methods",
                        "models",
                        "importance",
                        "proposed",
                        "present",
                        "filtering",
                        "dynamic",
                        "distributions",
                        "developed"
                    ],
                    "group": [],
                    "_id": "67efeb3a-56bb-4bd8-bc0b-dca8f84fa3d3",
                    "abstract": "In this article, we present an overview of methods for sequential simulation from posterior distributions. These methods are of particular interest in Bayesian filtering for discrete time dynamic models that are typically nonlinear and non-Gaussian. A general importance sampling framework is developed that unifies many of the methods which have been proposed over the last few decades in several different scientific disciplines. Novel extensions to the existing methods are also proposed. We show in particular how to incorporate local linearisation methods similar to those which have previously been employed in the deterministic filtering literatures these lead to very effective importance distributions. Furthermore we describe a method which uses Rao-Blackwellisation in order to take advantage of the analytic structure present in some important classes of state-space models. In a final section we develop algorithms for prediction, smoothing and evaluation of the likelihood in dynamic models.",
                    "title": "On sequential Monte Carlo sampling methods for Bayesian filtering",
                    "venue": "Statistics and Computing",
                    "year": 2000,
                    "__v": 2,
                    "citationCount": 1214,
                    "result": 8.010625442668786
                },
                "8b5a79a9-8c51-4a30-9be2-f4ee63af7949": {
                    "authors": [
                        "Arnaud Doucet",
                        "Neil J. Gordon",
                        "Vikram Krishnamurthy"
                    ],
                    "references": [
                        "2f0ec052-dd23-4a10-8156-22e4aa068cb3",
                        "440c82f4-7a7d-42c6-a492-1863625f556b",
                        "5feefedf-772a-4f41-a4b9-592a1d5f5811",
                        "67efeb3a-56bb-4bd8-bc0b-dca8f84fa3d3",
                        "9d853d1d-6f01-4a82-8014-edf45572f5a2",
                        "ab421de9-79db-4fa2-97a5-f2437bc3cc46",
                        "b1367519-5742-468f-834f-19421b79b2e3",
                        "be85d125-170b-41b8-8182-4f5680ac30c2",
                        "d5742d92-f727-4443-af9e-3d1e5165cb4d",
                        "ed4b475e-cacc-44a4-b929-bba692b4d24c"
                    ],
                    "keyword": [
                        "algorithms",
                        "systems",
                        "problem",
                        "optimal",
                        "methods",
                        "markov",
                        "state",
                        "linear",
                        "jmls",
                        "filters"
                    ],
                    "group": [],
                    "_id": "8b5a79a9-8c51-4a30-9be2-f4ee63af7949",
                    "abstract": "Jump Markov linear systems (JMLS) are linear systems whose parameters evolve with time according to a finite state Markov chain. In this paper, our aim is to recursively compute optimal state estimates for this class of systems. We present efficient simulation-based algorithms called particle filters to solve the optimal filtering problem as well as the optimal fixed-lag smoothing problem. Our algorithms combine sequential importance sampling, a selection scheme, and Markov chain Monte Carlo methods. They use several variance reduction methods to make the most of the statistical structure of JMLS. Computer simulations are carried out to evaluate the performance of the proposed algorithms. The problems of on-line deconvolution of impulsive processes and of tracking a maneuvering target are considered. It is shown that our algorithms outperform the current methods.",
                    "title": "Particle filters for state estimation of jump Markov linear systems",
                    "venue": "IEEE Transactions on Signal Processing",
                    "year": 2001,
                    "__v": 2,
                    "citationCount": 221,
                    "result": 8.625339366515838
                }
            }
        ],
        "_id": "d8116977-0962-4d4d-832d-f9b0a095c75c",
        "abstract": "Increasingly, for many application areas, it is becoming important to include elements of nonlinearity and non-Gaussianity in order to model accurately the underlying dynamics of a physical system. Moreover, it is typically crucial to process data on-line as it arrives, both from the point of view of storage costs as well as for rapid adaptation to changing signal characteristics. In this paper, we review both optimal and suboptimal Bayesian algorithms for nonlinear/non-Gaussian tracking problems, with a focus on particle filters. Particle filters are sequential Monte Carlo methods based on point mass (or \"particle\") representations of probability densities, which can be applied to any state-space model and which generalize the traditional Kalman filtering methods. Several variants of the particle filter such as SIR, ASIR, and RPF are introduced within a generic framework of the sequential importance sampling (SIS) algorithm. These are discussed and compared with the standard EKF through an illustrative example.",
        "title": "A tutorial on particle filters for online nonlinear/non-Gaussian Bayesian tracking",
        "venue": "IEEE Transactions on Signal Processing",
        "year": 2002,
        "__v": 2,
        "citationCount": 2793
    },
    {
        "authors": [
            "Reza Olfati-Saber",
            "J.A. Fax",
            "Robin M. Murray"
        ],
        "references": [
            "069aa4a5-017b-49e3-ba71-20bcade4d634",
            "0aed8a11-15e1-4915-9563-f672e773dac6",
            "0bf829c3-d555-4745-b1a5-7c5ce8acbff6",
            "0cb61dc0-15c5-4592-a5fb-fd76d75f03ac",
            "13c9856f-e4f8-4c1c-b728-c8ccff9b7b4b",
            "223edc15-f2f7-4796-8b91-9fab63eda279",
            "2768199c-b9d6-4001-94d3-e6429c93bc5f",
            "306dfd3e-4a33-4c46-93d5-9d85acbf7503",
            "3c70f9d5-7190-4f0b-8fee-259bd8b94bca",
            "423548af-857e-4063-88b5-14cd2d7f2155",
            "6460eee0-033e-4185-8b7c-dbcb931e1b2c",
            "6fc28283-44d9-4329-8724-2fe71234bb4c",
            "83d84ff1-d492-4e05-9576-a32bcff7401e",
            "860a3efc-800e-4e62-8200-7acf3f8d2b8d",
            "888171fc-10d9-4230-a916-b9ab6d1910f5",
            "89253643-14dd-4793-b95a-a54bc59e72ff",
            "8c581627-0fe3-46cf-99cf-c5e3c9af272e",
            "a139ef6c-e79b-4f63-a37d-21f4b2eeb2e2",
            "ab35dc68-62bd-4c54-81d3-9a8406827489",
            "aca928ab-a742-4ff7-bf7c-7ee7f5df4866",
            "b0ef6e4d-4c86-4b10-9e0a-7b630ca8d7f7",
            "bfdd519a-0bb8-4ea6-b0ce-2ad0cb05dfe0",
            "c3b374ba-8057-4dce-8510-cc83c5be2e00",
            "cc259597-c637-451f-96ae-dd92d7f697c9",
            "d63017ca-4753-4a83-92df-7b18c5fc3a2e",
            "d63aeb27-62f3-4d6e-a6df-aed1f6a74609",
            "d7b5aadf-ec30-4fb7-9224-7474169d3744",
            "ea1d5c21-fba6-4fae-9fdc-ee7679ee46c9",
            "ec5cea52-381b-4263-ac39-5f59db9b0f91",
            "efed0c9f-6b90-4c0a-ba67-65d4b2bee0de",
            "fb3683fe-a6d4-4918-b96e-595abd299183"
        ],
        "keyword": [
            "networked",
            "consensus",
            "systems",
            "information",
            "algorithms",
            "theory",
            "analysis"
        ],
        "group": [
            {
                "0aed8a11-15e1-4915-9563-f672e773dac6": {
                    "authors": [
                        "Lin Xiao",
                        "Stephen P. Boyd",
                        "Sanjay Lall"
                    ],
                    "references": [
                        "0bf829c3-d555-4745-b1a5-7c5ce8acbff6",
                        "13c9856f-e4f8-4c1c-b728-c8ccff9b7b4b",
                        "2768199c-b9d6-4001-94d3-e6429c93bc5f",
                        "3e0215ac-0077-4b4a-b8eb-f8cfafe2e22e",
                        "48d356c2-09ec-4d5d-a812-094c5f673ee4",
                        "639941aa-1dad-4dbf-8514-f66954dff570",
                        "6460eee0-033e-4185-8b7c-dbcb931e1b2c",
                        "7f902672-aa10-49f5-9058-c58a4a4c7fa4",
                        "828ef5ed-7429-4d2f-8f11-20aaacf3eeb6",
                        "839602ef-a406-4282-9aa2-29ef2231e281",
                        "9e063b41-0ada-4db8-8846-6e5153a0de55",
                        "cb4ad0c9-1d94-4646-9480-9268704a85b6",
                        "cc259597-c637-451f-96ae-dd92d7f697c9",
                        "d7b5aadf-ec30-4fb7-9224-7474169d3744",
                        "ea1d5c21-fba6-4fae-9fdc-ee7679ee46c9",
                        "ec5cea52-381b-4263-ac39-5f59db9b0f91"
                    ],
                    "keyword": [],
                    "group": [],
                    "_id": "0aed8a11-15e1-4915-9563-f672e773dac6",
                    "abstract": "We consider a network of distributed sensors, where where each sensor takes a linear measurement of some unknown parameters, corrupted by independent Gaussian noises. We propose a simple distributed iterative scheme, based on distributed average consensus in the network, to compute the maximum-likelihood estimate of the parameters. This scheme doesn't involve explicit point-to-point message passing or routing; instead, it diffuses information across the network by updating each node's data with a weighted average of its neighbors' data (they maintain the same data structure). At each step, every node can compute a local weighted least-squares estimate, which converges to the global maximum-likelihood solution. This scheme is robust to unreliable communication links. We show that it works in a network with dynamically changing topology, provided that the infinitely occurring communication graphs are jointly connected.",
                    "title": "A scheme for robust distributed sensor fusion based on average consensus",
                    "venue": "information processing in sensor networks",
                    "year": 2005,
                    "__v": 0,
                    "citationCount": 478,
                    "result": 2.5806451612903225
                },
                "223edc15-f2f7-4796-8b91-9fab63eda279": {
                    "authors": [
                        "Reza Olfati-Saber"
                    ],
                    "references": [
                        "0bf829c3-d555-4745-b1a5-7c5ce8acbff6",
                        "2768199c-b9d6-4001-94d3-e6429c93bc5f",
                        "30932642-fd17-4ae9-9a5b-90e67adcfe41",
                        "51a16a30-666c-4b4a-8962-ec187c59c399",
                        "551b0ff9-7423-4376-a3a0-dd6a352c4079",
                        "6460eee0-033e-4185-8b7c-dbcb931e1b2c",
                        "6fc28283-44d9-4329-8724-2fe71234bb4c",
                        "9e063b41-0ada-4db8-8846-6e5153a0de55",
                        "ab35dc68-62bd-4c54-81d3-9a8406827489",
                        "ad5e3f89-61b7-4e90-9d02-f6df3ab7d927",
                        "b6a0562d-91b9-4b65-a395-0e705e24f3ba",
                        "bf96410c-8b91-41bf-aff4-ed144c1b6e8c",
                        "d65d26b4-a0e0-4112-ae22-2f3a4b51d7b3",
                        "ea1d5c21-fba6-4fae-9fdc-ee7679ee46c9",
                        "efed0c9f-6b90-4c0a-ba67-65d4b2bee0de",
                        "f8ece2c5-c8b1-4a1e-8528-c09357ec23a4",
                        "fb3683fe-a6d4-4918-b96e-595abd299183"
                    ],
                    "keyword": [],
                    "group": [],
                    "_id": "223edc15-f2f7-4796-8b91-9fab63eda279",
                    "abstract": "In this paper, we present a theoretical framework for design and analysis of distributed flocking algorithms. Two cases of flocking in free-space and presence of multiple obstacles are considered. We present three flocking algorithms: two for free-flocking and one for constrained flocking. A comprehensive analysis of the first two algorithms is provided. We demonstrate the first algorithm embodies all three rules of Reynolds. This is a formal approach to extraction of interaction rules that lead to the emergence of collective behavior. We show that the first algorithm generically leads to regular fragmentation, whereas the second and third algorithms both lead to flocking. A systematic method is provided for construction of cost functions (or collective potentials) for flocking. These collective potentials penalize deviation from a class of lattice-shape objects called /spl alpha/-lattices. We use a multi-species framework for construction of collective potentials that consist of flock-members, or /spl alpha/-agents, and virtual agents associated with /spl alpha/-agents called /spl beta/- and /spl gamma/-agents. We show that migration of flocks can be performed using a peer-to-peer network of agents, i.e., \"flocks need no leaders.\" A \"universal\" definition of flocking for particle systems with similarities to Lyapunov stability is given. Several simulation results are provided that demonstrate performing 2-D and 3-D flocking, split/rejoin maneuver, and squeezing maneuver for hundreds of agents using the proposed algorithms.",
                    "title": "Flocking for multi-agent dynamic systems: algorithms and theory",
                    "venue": "IEEE Transactions on Automatic Control",
                    "year": 2006,
                    "__v": 0,
                    "citationCount": 1026,
                    "result": 2.5806451612903225
                },
                "6460eee0-033e-4185-8b7c-dbcb931e1b2c": {
                    "authors": [
                        "Luc Moreau"
                    ],
                    "references": [
                        "223edc15-f2f7-4796-8b91-9fab63eda279",
                        "2768199c-b9d6-4001-94d3-e6429c93bc5f",
                        "51a16a30-666c-4b4a-8962-ec187c59c399",
                        "551b0ff9-7423-4376-a3a0-dd6a352c4079",
                        "6dacf711-539e-4a41-b10a-0732f548bc57",
                        "ab35dc68-62bd-4c54-81d3-9a8406827489",
                        "aca928ab-a742-4ff7-bf7c-7ee7f5df4866",
                        "b8c3411b-4b2b-439c-b000-c4031758b377",
                        "d7b5aadf-ec30-4fb7-9224-7474169d3744",
                        "ea1d5c21-fba6-4fae-9fdc-ee7679ee46c9",
                        "efed0c9f-6b90-4c0a-ba67-65d4b2bee0de",
                        "f4a2e7f5-981d-4b4c-a70c-797e2c72f36c"
                    ],
                    "keyword": [
                        "model",
                        "agents",
                        "convergence",
                        "state",
                        "simple",
                        "presented",
                        "lead",
                        "current",
                        "communication",
                        "based"
                    ],
                    "group": [],
                    "_id": "6460eee0-033e-4185-8b7c-dbcb931e1b2c",
                    "abstract": "We study a simple but compelling model of network of agents interacting via time-dependent communication links. The model finds application in a variety of fields including synchronization, swarming and distributed decision making. In the model, each agent updates his current state based upon the current information received from neighboring agents. Necessary and/or sufficient conditions for the convergence of the individual agents' states to a common value are presented, thereby extending recent results reported in the literature. The stability analysis is based upon a blend of graph-theoretic and system-theoretic tools with the notion of convexity playing a central role. The analysis is integrated within a formal framework of set-valued Lyapunov theory, which may be of independent interest. Among others, it is observed that more communication does not necessarily lead to faster convergence and may eventually even lead to a loss of convergence, even for the simple models discussed in the present paper.",
                    "title": "Stability of multiagent systems with time-dependent communication links",
                    "venue": "IEEE Transactions on Automatic Control",
                    "year": 2005,
                    "__v": 2,
                    "citationCount": 855,
                    "result": 5.112451795516311
                },
                "6fc28283-44d9-4329-8724-2fe71234bb4c": {
                    "authors": [
                        "Mehran Mesbahi"
                    ],
                    "references": [
                        "2768199c-b9d6-4001-94d3-e6429c93bc5f",
                        "435d486d-ddea-4938-8bc4-297067c11dda",
                        "ab35dc68-62bd-4c54-81d3-9a8406827489",
                        "ea1d5c21-fba6-4fae-9fdc-ee7679ee46c9"
                    ],
                    "keyword": [
                        "systems",
                        "graph",
                        "dynamic",
                        "theory",
                        "network",
                        "venue",
                        "unique",
                        "underling",
                        "theoretic",
                        "studied"
                    ],
                    "group": [],
                    "_id": "6fc28283-44d9-4329-8724-2fe71234bb4c",
                    "abstract": "We consider distributed dynamic systems operating over a graph or a network. The geometry of the network is assumed to be a function of the underling system's states-giving it a unique dynamic character. Certain aspects of the resulting abstract structure, having a mixture of combinatorial and system theoretic features, are then studied. In this venue, we will explore an interplay between notions from extremal graph theory and system theory by considering a controllability framework for such state-dependent dynamic graphs.",
                    "title": "On State-dependent dynamic graphs and their controllability properties",
                    "venue": "conference on decision and control",
                    "year": 2004,
                    "__v": 2,
                    "citationCount": 48,
                    "result": 7.18915826425314
                },
                "83d84ff1-d492-4e05-9576-a32bcff7401e": {
                    "authors": [
                        "Dario Bauso",
                        "L. Giarre",
                        "Raffaele Pesenti"
                    ],
                    "references": [
                        "0bf829c3-d555-4745-b1a5-7c5ce8acbff6",
                        "2768199c-b9d6-4001-94d3-e6429c93bc5f",
                        "529d651e-d115-40bd-8c81-7390e606874d",
                        "ab35dc68-62bd-4c54-81d3-9a8406827489",
                        "aca7925e-ca61-4dfc-a3f4-22bdb0ca0575",
                        "d7b5aadf-ec30-4fb7-9224-7474169d3744",
                        "e83ed0d9-6e41-4c99-a4ac-ca295a3eb0d5",
                        "ea1d5c21-fba6-4fae-9fdc-ee7679ee46c9",
                        "f1a73fc7-7682-4223-bd3d-f3c9f2079284",
                        "f983ab8c-ec8a-45bc-b493-bf23a523de01"
                    ],
                    "keyword": [
                        "agents",
                        "consensus",
                        "reach",
                        "state",
                        "protocols",
                        "design"
                    ],
                    "group": [],
                    "_id": "83d84ff1-d492-4e05-9576-a32bcff7401e",
                    "abstract": "We consider stationary consensus protocols for networks of dynamic agents with fixed topologies. At each time instant, each agent knows only its and its neighbors’ state, but must reach consensus on a group decision value that is function of all the agents’ initial state. We show that the agents can reach consensus if the value of such a function is time-invariant when computed over the agents’ state trajectories. We use this basic result to introduce a non-linear protocol design rule allowing consensus on a quite general set of values. Such a set includes, e.g., any generalized mean of order p of the agents’ initial states. As a second contribution we show that our protocol design is the solution of individual optimizations performed by the agents. This notion suggests a game theoretic interpretation of consensus problems as mechanism design problems. Under this perspective a supervisor entails the agents to reach a consensus by imposing individual objectives. We prove that such objectives can be chosen so that rational agents have a unique optimal protocol, and asymptotically reach consensus on a desired group decision value. We use a Lyapunov approach to prove that the asymptotical consensus can be reached when the communication links between nearby agents define a time-invariant undirected network. Finally we perform a simulation study concerning the vertical alignment maneuver of a team of unmanned air vehicles.",
                    "title": "Non-linear protocols for optimal distributed consensus in networks of dynamic agents",
                    "venue": "Systems & Control Letters",
                    "year": 2006,
                    "__v": 2,
                    "citationCount": 61,
                    "result": 3.7123843002875256
                },
                "888171fc-10d9-4230-a916-b9ab6d1910f5": {
                    "authors": [
                        "Andrey V. Savkin"
                    ],
                    "references": [
                        "7598a9fb-b756-44ee-9964-eb6cfaa2f60e",
                        "ab35dc68-62bd-4c54-81d3-9a8406827489",
                        "b0f09b5e-cf02-4299-a4bd-915b7ed69571",
                        "b6a0562d-91b9-4b65-a395-0e705e24f3ba",
                        "ea1d5c21-fba6-4fae-9fdc-ee7679ee46c9",
                        "ee265d03-1a69-4425-b248-bd68bc9ed6e0"
                    ],
                    "keyword": [
                        "robots",
                        "system",
                        "simple",
                        "show",
                        "rules",
                        "qualitative",
                        "note",
                        "neighbor",
                        "nearest",
                        "motion"
                    ],
                    "group": [],
                    "_id": "888171fc-10d9-4230-a916-b9ab6d1910f5",
                    "abstract": "This note gives a qualitative analysis of the dynamics of a system consisting of several mobile robots coordinating their motion using simple local nearest neighbor rules. We show that under some assumptions the headings of all robots will be eventually constant.",
                    "title": "Coordinated collective motion of Groups of autonomous mobile robots: analysis of Vicsek's model",
                    "venue": "IEEE Transactions on Automatic Control",
                    "year": 2004,
                    "__v": 2,
                    "citationCount": 83,
                    "result": 4.1773314851088745
                },
                "8c581627-0fe3-46cf-99cf-c5e3c9af272e": {
                    "authors": [
                        "Jorge Cortes",
                        "Sonia Martinez",
                        "Francesco Bullo"
                    ],
                    "references": [
                        "069aa4a5-017b-49e3-ba71-20bcade4d634",
                        "2768199c-b9d6-4001-94d3-e6429c93bc5f",
                        "6460eee0-033e-4185-8b7c-dbcb931e1b2c",
                        "88467bc8-63a3-4a51-9859-343b9cbc179e",
                        "aca7925e-ca61-4dfc-a3f4-22bdb0ca0575",
                        "b546dd1a-7e2d-4527-ba3c-2e6ce5e0a405",
                        "d65d26b4-a0e0-4112-ae22-2f3a4b51d7b3",
                        "ea1d5c21-fba6-4fae-9fdc-ee7679ee46c9",
                        "efed0c9f-6b90-4c0a-ba67-65d4b2bee0de",
                        "f4a2e7f5-981d-4b4c-a70c-797e2c72f36c"
                    ],
                    "keyword": [
                        "networks",
                        "algorithms",
                        "agents",
                        "weak",
                        "topology",
                        "switching",
                        "results",
                        "requirements",
                        "rendezvous",
                        "provide"
                    ],
                    "group": [],
                    "_id": "8c581627-0fe3-46cf-99cf-c5e3c9af272e",
                    "abstract": "This paper presents coordination algorithms for networks of mobile autonomous agents. The objective of the proposed algorithms is to achieve rendezvous, that is, agreement over the location of the agents in the network. We provide analysis and design results for multiagent networks in arbitrary dimensions under weak requirements on the switching and failing communication topology. The novel correctness proof relies on proximity graphs and their properties and on a general LaSalle invariance principle for nondeterministic discrete-time dynamical systems",
                    "title": "Robust rendezvous for mobile autonomous agents via proximity graphs in arbitrary dimensions",
                    "venue": "IEEE Transactions on Automatic Control",
                    "year": 2006,
                    "__v": 2,
                    "citationCount": 246,
                    "result": 5.5728405880657945
                },
                "ab35dc68-62bd-4c54-81d3-9a8406827489": {
                    "authors": [
                        "J.A. Fax",
                        "Robin M. Murray"
                    ],
                    "references": [
                        "08b14c78-71b4-4937-8d68-b6a5705751a8",
                        "4397e837-6065-407e-8e5b-15fffd69543d",
                        "9b19c27a-34d8-4a90-84a3-40dd9d64a64c",
                        "a21980e4-f56e-4ef8-8137-3169db19e4dc",
                        "aeabc622-720d-44d0-888c-787e7d377f54",
                        "c6fb8895-3ef3-4207-a9bc-5b41a7a17a23",
                        "e60364e5-54de-434e-8f72-a8cc6235437a",
                        "fd3d02fb-7899-4784-b35b-88cc5e5afd9f"
                    ],
                    "keyword": [
                        "stability",
                        "vehicles",
                        "graph",
                        "formation",
                        "communication",
                        "prove",
                        "information",
                        "topology",
                        "intervehicle",
                        "flow"
                    ],
                    "group": [],
                    "_id": "ab35dc68-62bd-4c54-81d3-9a8406827489",
                    "abstract": "We consider the problem of cooperation among a collection of vehicles performing a shared task using intervehicle communication to coordinate their actions. Tools from algebraic graph theory prove useful in modeling the communication network and relating its topology to formation stability. We prove a Nyquist criterion that uses the eigenvalues of the graph Laplacian matrix to determine the effect of the communication topology on formation stability. We also propose a method for decentralized information exchange between vehicles. This approach realizes a dynamical system that supplies each vehicle with a common reference to be used for cooperative motion. We prove a separation principle that decomposes formation stability into two components: Stability of this is achieved information flow for the given graph and stability of an individual vehicle for the given controller. The information flow can thus be rendered highly robust to changes in the graph, enabling tight formation control despite limitations in intervehicle communication capability.",
                    "title": "Information flow and cooperative control of vehicle formations",
                    "venue": "IEEE Transactions on Automatic Control",
                    "year": 2004,
                    "__v": 2,
                    "citationCount": 1101,
                    "result": 3.908226534387525
                },
                "aca928ab-a742-4ff7-bf7c-7ee7f5df4866": {
                    "authors": [
                        "Zhiyun Lin",
                        "Bruce A. Francis",
                        "Manfredi Maggiore"
                    ],
                    "references": [
                        "069aa4a5-017b-49e3-ba71-20bcade4d634",
                        "0cb61dc0-15c5-4592-a5fb-fd76d75f03ac",
                        "476dc53f-2f7d-4111-bc81-e937aa006266",
                        "6460eee0-033e-4185-8b7c-dbcb931e1b2c",
                        "a26591d5-6799-4c7a-8364-bb9de9deacd7",
                        "accb1442-56c1-46bf-b23d-67fb5c25a5f0",
                        "aeabc622-720d-44d0-888c-787e7d377f54",
                        "bf96410c-8b91-41bf-aff4-ed144c1b6e8c",
                        "cc10e581-d1e2-4c9f-bd8f-fc69455691a6",
                        "ea1d5c21-fba6-4fae-9fdc-ee7679ee46c9",
                        "f7a04302-9242-44f6-ac7e-dd0de4b37ad2"
                    ],
                    "keyword": [
                        "formation",
                        "stabilization",
                        "feasibility",
                        "unicycles",
                        "studied",
                        "similar",
                        "sensor",
                        "role",
                        "result",
                        "reachable"
                    ],
                    "group": [],
                    "_id": "aca928ab-a742-4ff7-bf7c-7ee7f5df4866",
                    "abstract": "The feasibility problem is studied of achieving a specified formation among a group of autonomous unicycles by local distributed control. The directed graph defined by the information flow plays a key role. It is proved that formation stabilization to a point is feasible if and only if the sensor digraph has a globally reachable node. A similar result is given for formation stabilization to a line and to more general geometric arrangements.",
                    "title": "Necessary and sufficient graphical conditions for formation control of unicycles",
                    "venue": "IEEE Transactions on Automatic Control",
                    "year": 2005,
                    "__v": 2,
                    "citationCount": 265,
                    "result": 5.207153582460683
                },
                "b0ef6e4d-4c86-4b10-9e0a-7b630ca8d7f7": {
                    "authors": [
                        "M. E. J. Newman"
                    ],
                    "references": [
                        "008d95fd-26f0-47f3-8774-6a896446baea",
                        "05332f60-3d2e-45bb-9ecd-a7c7aa7774dc",
                        "05f5fba9-e7ca-4c46-be79-df57944a8b41",
                        "0718dc34-4b49-4b24-8a2e-b5cd0d9d82c6",
                        "0d8eb1a3-5b89-419b-9eea-8fffd03c78a1",
                        "16e3c2f7-37fb-4192-bf76-20fe7838958a",
                        "18819165-7f73-4da1-9bf2-792c258be677",
                        "19f41085-f8c3-4087-a48a-27205b43bdb8",
                        "1a24e9c7-d0ce-4be4-8e3a-c849b4630851",
                        "1b41d9a0-3857-4fb6-b7ba-d39da73c04dd",
                        "27e4ec4d-0ce3-437b-9511-db610b7ba805",
                        "2a2fd168-2bcf-4527-afcd-5c99e75ad511",
                        "38135245-8eff-4078-af6a-ea559ffa660b",
                        "3bbad1d7-7c16-4c85-ae98-4cfd6913794f",
                        "3f610d75-809b-4a12-858f-95e346c17e8c",
                        "424bab1d-a362-4bd2-a878-eb81372b689d",
                        "4c343995-619f-4859-bd00-321c87adcd3c",
                        "597ecf84-4084-4057-a40d-30988ef74121",
                        "5ea35ec7-ab9f-4d0e-9a85-ef4add482ec7",
                        "606e4423-5a84-4c3b-bfb1-0cf549bf21e9",
                        "60c814e2-c4d1-47d7-9a5a-68f4141505ae",
                        "60ef3852-fa16-44bf-9434-9909268ba5d8",
                        "63245010-95d3-4eb1-a0d0-62894531d092",
                        "686c5563-3f13-4744-ac6d-1020e39953bf",
                        "6e6cac85-1ca8-4d49-8e16-aa3d353fc20a",
                        "71414cbd-e8f3-43ce-b536-029959d08b14",
                        "7192626f-12df-45f7-889d-c78e4da08773",
                        "7291c68d-db95-48a0-b856-6545ef18b503",
                        "8a4d517a-da96-4f80-879d-dda81e69d9c9",
                        "8f12317e-0ea6-455c-a973-7c7440af5f37",
                        "8f9e92cf-f266-4e51-807f-c098a260a0dc",
                        "98c4a2e2-f046-4e49-9173-91779f961cc0",
                        "9dbdc129-b8f3-4712-9c95-406bc8911bee",
                        "a0181d7d-c725-4bc4-8371-2510c70c96a4",
                        "a08549f5-fa6a-4adb-b643-714867228a0c",
                        "a0c94b9b-d64e-40d5-ba44-4208dec791d0",
                        "a22c015f-fa44-4b73-b906-ef030405d9c9",
                        "a4a93e4a-68f2-4509-bf87-5b33122ff614",
                        "a78ddf3f-d0ac-4262-bd99-ca8d5bd8309e",
                        "af8a7a02-c5f2-4367-9a67-7593d92f6003",
                        "b2f1d79b-d47a-4f2a-b810-ac3c837d7ee4",
                        "b407837a-0eae-4882-9a2c-2c185d5c16e0",
                        "baad4ab4-a3f2-45fc-b87d-954f608e8db7",
                        "bd34626f-94ae-46a2-8037-8c367831fa78",
                        "c2165f5b-d07b-4cd2-9d2b-e6f3002c80db",
                        "c4716aad-c8bc-431b-8173-0300064a77b0",
                        "c7e4e04b-45da-4bae-8c8a-d17ca0087361",
                        "ce115523-6b89-47ad-8cf3-1cb3e2a865d3",
                        "d71f089c-0658-478a-b58e-bb8e6f131c21",
                        "dd38911a-f68b-4bb5-a817-fd7153f0ff2f",
                        "df4b8e90-b404-47f8-a384-c93aa1313694",
                        "e2a97ffb-90b0-4f1a-b01d-b15a77a820de",
                        "e4f056cc-ab1e-4ca0-8754-fc81b133a47d",
                        "f15b19f2-4b37-454c-851e-a71cccf3e53a",
                        "f8088d69-04af-49f3-84b9-daf7682cc5f5"
                    ],
                    "keyword": [
                        "networked",
                        "models",
                        "systems",
                        "developed",
                        "years",
                        "variety",
                        "understand",
                        "techniques",
                        "studies",
                        "social"
                    ],
                    "group": [
                        null
                    ],
                    "_id": "b0ef6e4d-4c86-4b10-9e0a-7b630ca8d7f7",
                    "abstract": "Inspired by empirical studies of networked systems such as the Internet, social networks, and biological networks, researchers have in recent years developed a variety of techniques and models to help us understand or predict the behavior of these systems. Here we review developments in this field, including such concepts as the small-world effect, degree distributions, clustering, network correlations, random graph models, models of network growth and preferential attachment, and dynamical processes taking place on networks.",
                    "title": "The Structure and Function of Complex Networks",
                    "venue": "Siam Review",
                    "year": 2003,
                    "__v": 3,
                    "citationCount": 3109,
                    "result": 3.9388314300079
                },
                "bfdd519a-0bb8-4ea6-b0ce-2ad0cb05dfe0": {
                    "authors": [
                        "Nima Moshtagh",
                        "Ali Jadbabaie",
                        "Kostas Daniilidis"
                    ],
                    "references": [
                        "2768199c-b9d6-4001-94d3-e6429c93bc5f",
                        "456f0d12-202c-49b3-b242-c7de7e129fb6",
                        "4cc812e1-1135-4d09-b563-f6cd81763271",
                        "51a16a30-666c-4b4a-8962-ec187c59c399",
                        "6460eee0-033e-4185-8b7c-dbcb931e1b2c",
                        "6c140dba-2a0e-4b9f-a079-63fb5b28a3ee",
                        "6f4225ac-a69e-4236-8868-262678fca345",
                        "860a3efc-800e-4e62-8200-7acf3f8d2b8d",
                        "93135584-ab8f-4f79-b842-063b6589cbaa",
                        "aeabc622-720d-44d0-888c-787e7d377f54",
                        "d65d26b4-a0e0-4112-ae22-2f3a4b51d7b3",
                        "ea1d5c21-fba6-4fae-9fdc-ee7679ee46c9",
                        "ea815a90-cc4d-4f03-bcaf-80f8ab9fe02c",
                        "efed0c9f-6b90-4c0a-ba67-65d4b2bee0de",
                        "f4a2e7f5-981d-4b4c-a70c-797e2c72f36c"
                    ],
                    "keyword": [
                        "measurements",
                        "laws",
                        "control",
                        "agents",
                        "velocity",
                        "resulting",
                        "motion",
                        "graph",
                        "flocking",
                        "develop"
                    ],
                    "group": [],
                    "_id": "bfdd519a-0bb8-4ea6-b0ce-2ad0cb05dfe0",
                    "abstract": "We study the problem of flocking and coordination of a group of kinematic nonholonomic agents in 2 and 3 dimensions. By analyzing the velocity vectors of agents on a circle (for planar motion) or sphere (for 3D motion), we develop geodesic control laws that minimize a misalignment potential based on graph Laplacians resulting in velocity alignment. The proposed control laws are distributed and will provably result in flocking when the underlying proximity graph which represents the neighborhood relation among agents is connected. Furthermore, we develop a vision based control law that does not rely on heading measurements, but only requires measurement of bearing, optical flow and time-to-collision, all of which can be efficiently measured.",
                    "title": "Distributed Geodesic Control Laws for Flocking of Nonholonomic Agents",
                    "venue": "conference on decision and control",
                    "year": 2005,
                    "__v": 2,
                    "citationCount": 59,
                    "result": 3.6493524748717996
                },
                "c3b374ba-8057-4dce-8510-cc83c5be2e00": {
                    "authors": [
                        "Jon Atli Benediktsson",
                        "Philip H. Swain"
                    ],
                    "references": [
                        "f3e3112f-2e57-40fe-9adf-ab47041c1871"
                    ],
                    "keyword": [
                        "methods",
                        "data",
                        "consensus",
                        "theoretic",
                        "sources",
                        "recognition",
                        "pattern",
                        "weight",
                        "theory",
                        "sensing"
                    ],
                    "group": [],
                    "_id": "c3b374ba-8057-4dce-8510-cc83c5be2e00",
                    "abstract": "Consensus theory is adopted as a means of classifying geographic data from multiple sources. The foundations and usefulness of different consensus theoretic methods are discussed in conjunction with pattern recognition. Weight selections for different data sources are considered and modeling of non-Gaussian data is investigated. The application of consensus theory in pattern recognition is tested on two data sets: (1) multisource remote sensing and geographic data, and (2) very-high-dimensional remote sensing data. The results obtained using consensus theoretic methods are found to compare favorably with those obtained using well-known pattern recognition methods. The consensus theoretic methods can be applied in cases where the Gaussian maximum likelihood method cannot. Also, the consensus theoretic methods are computationally less demanding than the Gaussian maximum likelihood method and provide a means for weighting data sources differently. >",
                    "title": "Consensus theoretic classification methods",
                    "venue": "systems man and cybernetics",
                    "year": 1992,
                    "__v": 2,
                    "citationCount": 131,
                    "result": 6.245330280314801
                },
                "cc259597-c637-451f-96ae-dd92d7f697c9": {
                    "authors": [
                        "Demetri Spanos",
                        "Reza Olfati-Saber",
                        "Richard M. Murray"
                    ],
                    "references": [
                        "0aed8a11-15e1-4915-9563-f672e773dac6",
                        "2768199c-b9d6-4001-94d3-e6429c93bc5f",
                        "9e063b41-0ada-4db8-8846-6e5153a0de55",
                        "d7b5aadf-ec30-4fb7-9224-7474169d3744",
                        "f8ece2c5-c8b1-4a1e-8528-c09357ec23a4"
                    ],
                    "keyword": [
                        "distributed",
                        "performance",
                        "topology",
                        "network",
                        "estimation",
                        "connection",
                        "work",
                        "varied",
                        "terms",
                        "systematic"
                    ],
                    "group": [],
                    "_id": "cc259597-c637-451f-96ae-dd92d7f697c9",
                    "abstract": "We analyze the performance of an approximate distributed Kalman filter proposed in recent work on distributed coordination. This approach to distributed estimation is novel in that it admits a systematic analysis of its performance as various network quantities such as connection density, topology, and bandwidth are varied. Our main contribution is a frequency-domain characterization of the distributed estimator's steady-state performance; this is quantified in terms of a special matrix associated with the connection topology called the  graph Laplacian , and also the rate of message exchange between immediate neighbors in the communication network.",
                    "title": "Approximate distributed Kalman filtering in sensor networks with quantifiable performance",
                    "venue": "information processing in sensor networks",
                    "year": 2005,
                    "__v": 2,
                    "citationCount": 82,
                    "result": 8.379269228280517
                },
                "d63017ca-4753-4a83-92df-7b18c5fc3a2e": {
                    "authors": [
                        "Abubakr Muhammad",
                        "Magnus Egerstedt"
                    ],
                    "references": [
                        "ea1d5c21-fba6-4fae-9fdc-ee7679ee46c9"
                    ],
                    "keyword": [
                        "graphs",
                        "structure",
                        "connectivity",
                        "topological",
                        "terms",
                        "systems",
                        "subset",
                        "study",
                        "special",
                        "small"
                    ],
                    "group": [],
                    "_id": "d63017ca-4753-4a83-92df-7b18c5fc3a2e",
                    "abstract": "In this paper, we study graphs that arise from certain sensory and communication limitations on the local interactions in multi-agent systems. In particular, we show that the set of graphs that can represent formations corresponds to a proper subset of all graphs and we denote such graphs as connectivity graphs. Such graphs have a special structure that allows them to be composed from a small number of atomic crossing generators using a certain kind of graph amalgamation. This structure allows us to give connectivity graphs a useful topological characterization in terms of their simplicial complexes.",
                    "title": "Connectivity graphs as models of local interactions",
                    "venue": "conference on decision and control",
                    "year": 2004,
                    "__v": 2,
                    "citationCount": 16,
                    "result": 4.705735880019311
                },
                "ea1d5c21-fba6-4fae-9fdc-ee7679ee46c9": {
                    "authors": [
                        "Ali Jadbabaie",
                        "Jie Lin",
                        "A.S. Morse"
                    ],
                    "references": [
                        "aeabc622-720d-44d0-888c-787e7d377f54",
                        "b6a0562d-91b9-4b65-a395-0e705e24f3ba",
                        "cf772fd2-26e1-49d5-b59c-5854b276ab0d",
                        "ee265d03-1a69-4425-b248-bd68bc9ed6e0"
                    ],
                    "keyword": [
                        "headings",
                        "agents",
                        "vicsek",
                        "neighbors",
                        "model",
                        "system",
                        "rule",
                        "results",
                        "paper",
                        "nearest"
                    ],
                    "group": [],
                    "_id": "ea1d5c21-fba6-4fae-9fdc-ee7679ee46c9",
                    "abstract": "In a recent Physical Review Letters article, Vicsek et al. propose a simple but compelling discrete-time model of n autonomous agents (i.e., points or particles) all moving in the plane with the same speed but with different headings. Each agent's heading is updated using a local rule based on the average of its own heading plus the headings of its \"neighbors.\" In their paper, Vicsek et al. provide simulation results which demonstrate that the nearest neighbor rule they are studying can cause all agents to eventually move in the same direction despite the absence of centralized coordination and despite the fact that each agent's set of nearest neighbors change with time as the system evolves. This paper provides a theoretical explanation for this observed behavior. In addition, convergence results are derived for several other similarly inspired models. The Vicsek model proves to be a graphic example of a switched linear system which is stable, but for which there does not exist a common quadratic Lyapunov function.",
                    "title": "Coordination of groups of mobile autonomous agents using nearest neighbor rules",
                    "venue": "IEEE Transactions on Automatic Control",
                    "year": 2003,
                    "__v": 2,
                    "citationCount": 2265,
                    "result": 2.752748885101826
                },
                "ec5cea52-381b-4263-ac39-5f59db9b0f91": {
                    "authors": [
                        "George Cybenko"
                    ],
                    "references": [
                        "1bb3a3fd-8bec-4c5a-99f3-0629deab2115",
                        "30359da3-bc42-4264-a725-0d92b1e14ff7",
                        "7af11d99-d0e9-46fa-9b3a-54064b7acb5a",
                        "e7fa2460-dbaf-48f8-935a-7d9c8dee632d",
                        "eaf04fdc-50ae-4d1f-9108-1dbe478260df"
                    ],
                    "keyword": [
                        "hypercube",
                        "dynamic",
                        "distribution",
                        "work",
                        "load",
                        "diffusion",
                        "converge",
                        "balancing",
                        "approach",
                        "uniform"
                    ],
                    "group": [],
                    "_id": "ec5cea52-381b-4263-ac39-5f59db9b0f91",
                    "abstract": "In this paper we study diffusion schemes for dynamic load balancing on message passing multiprocessor networks. One of the main results concerns conditions under which these dynamic schemes converge and their rates of convergence for arbitrary topologies. These results use the eigenstructure of the iteration matrices that arise in dynamic load balancing. We completely analyze the hypercube network by explicitly computing the eigenstructure of its node adjacency matrix. Using a realistic model of interprocessor communications, we show that a diffusion approach to load balancing on a hypercube multiprocessor is inferior to another approach which we call the dimension exchange method. For a d-dimensional hypercube, we compute the rate of convergence to a uniform work distribution and show that after d + 1 iterations of a diffusion type approach, we can guarantee that the work distribution is approximately within e-* of the uniform distribution independent of the hypercube dimension d. Both static and dynamic random models of work distribution are studied. o",
                    "title": "Dynamic load balancing for distributed memory multiprocessors",
                    "venue": "Journal of Parallel and Distributed Computing",
                    "year": 1989,
                    "__v": 2,
                    "citationCount": 401,
                    "result": 4.307851909012899
                },
                "efed0c9f-6b90-4c0a-ba67-65d4b2bee0de": {
                    "authors": [
                        "Jorge Cortes",
                        "Sonia Martinez",
                        "Timur Karatas",
                        "Francesco Bullo"
                    ],
                    "references": [
                        "02cc9015-ff2a-4258-b039-b53678c97988",
                        "069aa4a5-017b-49e3-ba71-20bcade4d634",
                        "06d5ee43-254e-4c7c-a401-b6bc29b08579",
                        "079090cb-9ba8-419b-845c-7cccb6039da3",
                        "0cb61dc0-15c5-4592-a5fb-fd76d75f03ac",
                        "133ebe9d-96e4-4931-95c2-9f297dc45dd2",
                        "2553d44c-c384-4ef2-a797-bb77a58a3c54",
                        "2768199c-b9d6-4001-94d3-e6429c93bc5f",
                        "310fcebe-c94f-4af6-8547-879ed732778d",
                        "4c400c8d-656d-4179-bdb1-699fe0eee305",
                        "4e86ab99-7537-44aa-8446-f256922c934d",
                        "551b0ff9-7423-4376-a3a0-dd6a352c4079",
                        "6f16f12e-9029-44f7-9c21-0653598a5b8d",
                        "71914f21-62a0-4bfe-ba1b-f04d97a4a2a4",
                        "72c3f4d6-37ca-433a-a0e9-b4396adfd791",
                        "7f741262-792b-4a1c-a064-58e13ca8d384",
                        "81f90e4d-b37d-4ded-a3df-f8a7fb381451",
                        "8c9574e3-6bde-491e-ba01-e7bc190f9c64",
                        "8dc7fde8-bfbc-466a-be2d-a6c163116126",
                        "8fd6531b-c809-4e63-895b-fb91be11759d",
                        "a1ee3257-7837-45e3-b872-075dfc78b198",
                        "ab0eaa81-81a5-4a3a-8b00-6e6bbc185ff6",
                        "aeabc622-720d-44d0-888c-787e7d377f54",
                        "b058ea0f-bb1f-4a36-98e5-5157d3cf0ab8",
                        "b6a0562d-91b9-4b65-a395-0e705e24f3ba",
                        "beda6340-7194-426a-9964-ba243b71af3d",
                        "ca81522f-d316-4f09-ae76-54ad4e5807c6",
                        "d4c1d840-98e5-4a54-ab78-595d3d31defc",
                        "dfa62851-8003-4e21-975f-edf92a11a70e",
                        "e08302f6-6507-4b68-ace7-e7dfd4b7f4f7",
                        "ea1d5c21-fba6-4fae-9fdc-ee7679ee46c9",
                        "ec835496-802c-4c1b-9f94-12af1dc092b3",
                        "ee330923-f946-4cf2-864e-7b8c249683f4",
                        "eea91761-94ca-4b2b-806f-9722127011a5",
                        "f775d780-526c-486e-8736-e7818597eb7d",
                        "fb3683fe-a6d4-4918-b96e-595abd299183"
                    ],
                    "keyword": [
                        "utility",
                        "tasks",
                        "spatially",
                        "optimal",
                        "laws",
                        "functions",
                        "decentralized",
                        "control",
                        "voronoi",
                        "vehicles"
                    ],
                    "group": [],
                    "_id": "efed0c9f-6b90-4c0a-ba67-65d4b2bee0de",
                    "abstract": "This paper describes decentralized control laws for the coordination of multiple vehicles performing spatially distributed tasks. The control laws are based on a gradient descent scheme applied to a class of decentralized utility functions that encode optimal coverage and sensing policies. These utility functions are studied in geographical optimization problems and they arise naturally in vector quantization and in sensor allocation tasks. The approach exploits the computational geometry of spatial structures such as Voronoi diagrams.",
                    "title": "Coverage control for mobile sensing networks",
                    "venue": "international conference on robotics and automation",
                    "year": 2002,
                    "__v": 2,
                    "citationCount": 775,
                    "result": 5.260366667077942
                }
            }
        ],
        "_id": "d9162547-fd7f-4605-855d-0a3173c4b08e",
        "abstract": "This paper provides a theoretical framework for analysis of consensus algorithms for multi-agent networked systems with an emphasis on the role of directed information flow, robustness to changes in network topology due to link/node failures, time-delays, and performance guarantees. An overview of basic concepts of information consensus in networks and methods of convergence and performance analysis for the algorithms are provided. Our analysis framework is based on tools from matrix theory, algebraic graph theory, and control theory. We discuss the connections between consensus problems in networked dynamic systems and diverse applications including synchronization of coupled oscillators, flocking, formation control, fast consensus in small-world networks, Markov processes and gossip-based algorithms, load balancing in networks, rendezvous in space, distributed sensor fusion in sensor networks, and belief propagation. We establish direct connections between spectral and structural properties of complex networks and the speed of information diffusion of consensus algorithms. A brief introduction is provided on networked systems with nonlocal information flow that are considerably faster than distributed systems with lattice-type nearest neighbor interactions. Simulation results are presented that demonstrate the role of small-world effects on the speed of consensus algorithms and cooperative control of multivehicle formations",
        "title": "Consensus and Cooperation in Networked Multi-Agent Systems",
        "venue": "Proceedings of the IEEE",
        "year": 2007,
        "__v": 2,
        "citationCount": 2275
    },
    {
        "authors": [
            "Navneet Dalal",
            "Bill Triggs"
        ],
        "references": [
            "04d8a9cb-a14d-4ccf-8b19-da1327e86b91",
            "3e812129-beeb-415e-b6f7-ae255695cec7",
            "6f6fe122-6003-498c-a584-b27b3f7a6be3",
            "8d8e7d51-3223-4776-bf6a-40306774b8a1",
            "8fc9506c-3603-4af2-b0c8-02b368863fcb",
            "a5254ae0-1ce1-4390-b9f8-8d5a3dcb1e62",
            "b944f77f-113b-4a02-ae5e-d4a124b8fd5b",
            "bdd58d4a-2e0e-4fb2-8049-cfa50dda7b0d",
            "cb66e49d-077b-4adf-873c-2bc39f78fca6",
            "ed8a9624-3abe-4b5e-bffe-5b3ecc34e841",
            "f200d16f-8e1a-4a51-be50-4eeaafbb4a2f",
            "f3959783-a9aa-48a2-9fcc-978879de365e",
            "ff0d990e-90f3-4973-8541-5f7e595710aa",
            "ffa029cf-7240-4723-8339-51fac57f9f28"
        ],
        "keyword": [
            "human",
            "gradient",
            "descriptors",
            "study",
            "sets",
            "oriented",
            "feature",
            "existing",
            "detection",
            "binning"
        ],
        "group": [
            {
                "6f6fe122-6003-498c-a584-b27b3f7a6be3": {
                    "authors": [
                        "Sergey Ioffe",
                        "David A. Forsyth"
                    ],
                    "references": [
                        "01a82643-758b-46db-917e-144215d3915d",
                        "04d8a9cb-a14d-4ccf-8b19-da1327e86b91",
                        "12fef6fa-0525-4ca2-aff5-f658c57de286",
                        "18c7cefb-09b1-4bba-8029-33676798e910",
                        "1c23ccaa-8c59-4c5a-9b55-c191572fb8f1",
                        "1e4f4b5c-55e0-4d5b-b7cc-9e7fada3e341",
                        "3704f939-09a2-4e9f-b851-1261bcd310df",
                        "4adf54c9-f808-4988-ad8a-bf9cc87c6668",
                        "5fa50960-2eb1-4fe0-b07a-ad2f88bc9bdc",
                        "6184decb-e1b9-407b-8f26-5123aae37412",
                        "648675c6-6ea7-4fa5-a91d-9d3156d09692",
                        "732e611c-6996-4765-af4f-f9aaa80ff258",
                        "7582b055-04ef-4445-9bf5-884317febb39",
                        "82cf52b0-c1d8-4147-b496-451ef66c5825",
                        "8fe139e0-838a-4ee8-8e0e-1e6c9fc3f246",
                        "9438a773-c15c-4ef2-a97c-54f643ce6082",
                        "9e4ce720-a6e2-4d63-b768-559b69adf32f",
                        "a1fb7d7f-fb69-468e-8a17-d3c27a36616c",
                        "a3257b67-d63c-4256-964c-8225a6d4ce1e",
                        "a728900b-bca1-4f30-a9e4-80d846e92971",
                        "c02803c1-324a-4f8d-8e10-b426574deb90",
                        "c34fe4cc-4da6-489a-9e47-f0534b1dc83d",
                        "c4140a7e-f036-4816-a82f-9035ca99ed97",
                        "c42f42f8-d1b5-4965-b7c2-33a0e2d9c8a9",
                        "caeecc11-ec92-47d8-b112-c43b88dd4491",
                        "d5321e41-3281-4557-ac5a-5c0389818822",
                        "d5e5a24d-f80e-4f1a-b48b-22403b653276",
                        "d6e37fb1-5f7e-448e-847b-7d1f1271c574",
                        "e2bbf174-7398-4c3d-a310-6a067bd948a9",
                        "ef52ae7e-761d-4ec7-83c8-c30d9ed6b11b"
                    ],
                    "keyword": [
                        "people",
                        "segments",
                        "approaches",
                        "problem",
                        "images",
                        "finding",
                        "assemblies",
                        "result",
                        "real",
                        "projected"
                    ],
                    "group": [],
                    "_id": "6f6fe122-6003-498c-a584-b27b3f7a6be3",
                    "abstract": "Finding people in pictures presents a particularly difficult object recognition problem. We show how to find people by finding candidate body segments, and then constructing assemblies of segments that are consistent with the constraints on the appearance of a person that result from kinematic properties. Since a reasonable model of a person requires at least nine segments, it is not possible to inspect every group, due to the huge combinatorial complexity.#R##N##R##N#We propose two approaches to this problem. In one, the search can be pruned by using projected versions of a classifier that accepts groups corresponding to people. We describe an efficient projection algorithm for one popular classifier, and demonstrate that our approach can be used to determine whether images of real scenes contain people.#R##N##R##N#The second approach employs a probabilistic framework, so that we can draw samples of assemblies, with probabilities proportional to their likelihood, which allows to draw human-like assemblies more often than the non-person ones. The main performance problem is in segmentation of images, but the overall results of both approaches on real images of people are encouraging.",
                    "title": "Probabilistic Methods for Finding People",
                    "venue": "International Journal of Computer Vision",
                    "year": 2001,
                    "__v": 2,
                    "citationCount": 116,
                    "result": 5.031263911527069
                },
                "8d8e7d51-3223-4776-bf6a-40306774b8a1": {
                    "authors": [
                        "Krystian Mikolajczyk",
                        "Cordelia Schmid"
                    ],
                    "references": [
                        "00a4e16f-6b65-4ad2-bedc-b19d9cbc2cfe",
                        "09346dc3-f4d0-43a4-8f0b-27e02bcd336e",
                        "0aae4e44-abdb-4948-9462-61f6e52162ba",
                        "0d287faa-99bb-42df-98a7-24fcd601b9a4",
                        "19195bc1-7aff-4dd3-91cc-25402c343a19",
                        "21a8e8fd-0172-4e9a-8474-7024eb0bf979",
                        "21c67dad-f0eb-4479-afe7-fdf4a71eef01",
                        "2d6c9f60-ea78-44a8-b5f9-6964575dd196",
                        "33711daf-2a44-4f42-8466-c7801f29959b",
                        "34758e0a-3def-447b-9c5e-e82a206426b5",
                        "36800655-b2ff-4eb7-9070-c6be304c4baa",
                        "37031566-2033-44cb-a87e-91a9bb37996f",
                        "3b744649-d7a0-46c3-b242-9e0060d8ecfa",
                        "4e58f9b5-8562-4f17-830f-f055449867fc",
                        "509e1ae2-768b-4417-bebe-d90cf1e0fdae",
                        "5149d3c0-5ac9-47ba-9fb0-3d2ef757b0e8",
                        "568f1994-f91e-413e-92fd-87dbbb9642a8",
                        "5f1992df-975f-49e7-bd88-aee0740317cf",
                        "6018a516-8149-4bce-bc33-5449d86e58c2",
                        "60285266-7da2-474e-b05a-b380c836f665",
                        "608a581a-0e03-435a-9067-c0e0982567af",
                        "683dd26d-5c59-4feb-9fbd-2bcf3cc1942f",
                        "6fe37c18-8dc5-4baa-b6e0-5546353907bb",
                        "72c27d5a-23c5-4d1b-a000-280b87b368ee",
                        "7ab7b36d-baae-4b21-89fc-69389fcabc44",
                        "853b29ea-c6d1-497e-bad3-b608d370e7e2",
                        "a5254ae0-1ce1-4390-b9f8-8d5a3dcb1e62",
                        "a8c6ead3-d61a-4f6a-a702-08743f19eec9",
                        "b4685927-0ad9-466b-b2c6-2e1764475726",
                        "b592576f-ff29-4a68-9b2f-8a8ad02e9c70",
                        "b944f77f-113b-4a02-ae5e-d4a124b8fd5b",
                        "c455fb04-4566-4648-ad6f-3cf2245e507c",
                        "e2204e92-e6dc-4884-9bbc-200029491fc7",
                        "e927dff1-6ed4-45fd-8852-eb804e11e665",
                        "ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d",
                        "fc9638b8-572c-4b23-aab2-92e2dd3b79f8",
                        "ffa029cf-7240-4723-8339-51fac57f9f28"
                    ],
                    "keyword": [
                        "descriptors",
                        "regions",
                        "performance",
                        "interest",
                        "detector",
                        "filters",
                        "al"
                    ],
                    "group": [],
                    "_id": "8d8e7d51-3223-4776-bf6a-40306774b8a1",
                    "abstract": "In this paper, we compare the performance of descriptors computed for local interest regions, as, for example, extracted by the Harris-Affine detector [Mikolajczyk, K and Schmid, C, 2004]. Many different descriptors have been proposed in the literature. It is unclear which descriptors are more appropriate and how their performance depends on the interest region detector. The descriptors should be distinctive and at the same time robust to changes in viewing conditions as well as to errors of the detector. Our evaluation uses as criterion recall with respect to precision and is carried out for different image transformations. We compare shape context [Belongie, S, et al., April 2002], steerable filters [Freeman, W and Adelson, E, Setp. 1991], PCA-SIFT [Ke, Y and Sukthankar, R, 2004], differential invariants [Koenderink, J and van Doorn, A, 1987], spin images [Lazebnik, S, et al., 2003], SIFT [Lowe, D. G., 1999], complex filters [Schaffalitzky, F and Zisserman, A, 2002], moment invariants [Van Gool, L, et al., 1996], and cross-correlation for different types of interest regions. We also propose an extension of the SIFT descriptor and show that it outperforms the original method. Furthermore, we observe that the ranking of the descriptors is mostly independent of the interest region detector and that the SIFT-based descriptors perform best. Moments and steerable filters show the best performance among the low dimensional descriptors.",
                    "title": "A performance evaluation of local descriptors",
                    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "year": 2005,
                    "__v": 2,
                    "citationCount": 2762,
                    "result": 7.826806690041984
                },
                "8fc9506c-3603-4af2-b0c8-02b368863fcb": {
                    "authors": [
                        "Serge J. Belongie",
                        "Jitendra Malik",
                        "Jan Puzicha"
                    ],
                    "references": [
                        "00909251-9935-44f3-94a1-629023b5015b",
                        "042d18d1-aed3-4a9d-ba8b-fb7f3e14f568",
                        "0fc7a847-923c-4742-9b05-2b46eda24b2e",
                        "13cd743f-beb9-43a1-8e08-2ef08f0d8b3f",
                        "1ef607fe-5348-4658-8964-25a57fc49270",
                        "24187b9b-fe6b-484d-9a0e-0b849362fa18",
                        "2ae7a9b5-6231-45ca-9813-afc3a6b5f5ff",
                        "37032748-43bb-410a-8349-d2808bb6f7fa",
                        "59ade036-678c-42ad-bce8-7aa9301103e1",
                        "5ae4ef7f-b13a-4e78-8afd-1e2d22259b87",
                        "5ebbd1f5-dfe5-4eec-9883-b8b5efea366c",
                        "772654a7-a951-4327-aca5-ba5da8dfec7c",
                        "88f85c71-d474-4d12-9c74-43ac3b7c7ee6",
                        "923f5d0a-23a3-4fb1-bee7-ec72122709a4",
                        "932ef745-7197-4b00-bcd4-781bd048938f",
                        "9f84e529-87a3-42f1-9d63-9af710f40925",
                        "a8c6ead3-d61a-4f6a-a702-08743f19eec9",
                        "b592576f-ff29-4a68-9b2f-8a8ad02e9c70",
                        "bf1d8c69-aefb-4a7a-8b02-f815b754833c",
                        "f3959783-a9aa-48a2-9fcc-978879de365e"
                    ],
                    "keyword": [
                        "shapes",
                        "points",
                        "correspondences",
                        "transform",
                        "similarity",
                        "solving",
                        "measuring",
                        "context",
                        "aligning",
                        "recognition"
                    ],
                    "group": [],
                    "_id": "8fc9506c-3603-4af2-b0c8-02b368863fcb",
                    "abstract": "We present a novel approach to measuring similarity between shapes and exploit it for object recognition. In our framework, the measurement of similarity is preceded by (1) solving for correspondences between points on the two shapes, (2) using the correspondences to estimate an aligning transform. In order to solve the correspondence problem, we attach a descriptor, the shape context, to each point. The shape context at a reference point captures the distribution of the remaining points relative to it, thus offering a globally discriminative characterization. Corresponding points on two similar shapes will have similar shape contexts, enabling us to solve for correspondences as an optimal assignment problem. Given the point correspondences, we estimate the transformation that best aligns the two shapes; regularized thin-plate splines provide a flexible class of transformation maps for this purpose. Dis-similarity between two shapes is computed as a sum of matching errors between corresponding points, together with a term measuring the magnitude of the aligning transform. We treat recognition in a nearest-neighbor classification framework. Results are presented for silhouettes, trademarks, handwritten digits and the COIL dataset.",
                    "title": "Matching shapes",
                    "venue": "international conference on computer vision",
                    "year": 2001,
                    "__v": 2,
                    "citationCount": 155,
                    "result": 7.555685774493823
                },
                "a5254ae0-1ce1-4390-b9f8-8d5a3dcb1e62": {
                    "authors": [
                        "Yan Ke",
                        "Rahul Sukthankar"
                    ],
                    "references": [
                        "28005624-c0e8-4c62-b585-6e362c3dc8d5",
                        "34758e0a-3def-447b-9c5e-e82a206426b5",
                        "36800655-b2ff-4eb7-9070-c6be304c4baa",
                        "509e1ae2-768b-4417-bebe-d90cf1e0fdae",
                        "6018a516-8149-4bce-bc33-5449d86e58c2",
                        "608a581a-0e03-435a-9067-c0e0982567af",
                        "6fe37c18-8dc5-4baa-b6e0-5546353907bb",
                        "7ab7b36d-baae-4b21-89fc-69389fcabc44",
                        "aec2ffaf-e691-4884-9304-7d7e14733b2e",
                        "b944f77f-113b-4a02-ae5e-d4a124b8fd5b",
                        "c455fb04-4566-4648-ad6f-3cf2245e507c",
                        "d7b1fba1-b5f8-4377-88a8-d2fc69f723b7"
                    ],
                    "keyword": [
                        "image",
                        "sift",
                        "descriptor",
                        "local",
                        "results",
                        "representation",
                        "gradient",
                        "feature",
                        "deformations",
                        "component"
                    ],
                    "group": [],
                    "_id": "a5254ae0-1ce1-4390-b9f8-8d5a3dcb1e62",
                    "abstract": "Stable local feature detection and representation is a fundamental component of many image registration and object recognition algorithms. Mikolajczyk and Schmid (June 2003) recently evaluated a variety of approaches and identified the SIFT [D. G. Lowe, 1999] algorithm as being the most resistant to common image deformations. This paper examines (and improves upon) the local image descriptor used by SIFT. Like SIFT, our descriptors encode the salient aspects of the image gradient in the feature point's neighborhood; however, instead of using SIFT's smoothed weighted histograms, we apply principal components analysis (PCA) to the normalized gradient patch. Our experiments demonstrate that the PCA-based local descriptors are more distinctive, more robust to image deformations, and more compact than the standard SIFT representation. We also present results showing that using these descriptors in an image retrieval application results in increased accuracy and faster matching.",
                    "title": "PCA-SIFT: a more distinctive representation for local image descriptors",
                    "venue": "computer vision and pattern recognition",
                    "year": 2004,
                    "__v": 2,
                    "citationCount": 1138,
                    "result": 8.373023404632637
                },
                "b944f77f-113b-4a02-ae5e-d4a124b8fd5b": {
                    "authors": [
                        "David G. Lowe"
                    ],
                    "references": [
                        "00a4e16f-6b65-4ad2-bedc-b19d9cbc2cfe",
                        "01a0f825-a308-455b-93fc-e62defc0e3b0",
                        "035f8537-61a7-4c4f-b9fe-120f913a38b0",
                        "03a42efa-a19c-4b19-a881-9c7ff63865ce",
                        "05c3e696-6add-4b0d-b867-e6f1c98deb9b",
                        "2fa2e5ba-11d3-4691-91e1-807b8ef7d8a5",
                        "32d9eaee-c68f-4479-aa67-837d3cc91a05",
                        "34758e0a-3def-447b-9c5e-e82a206426b5",
                        "5437c0a0-8f20-49c3-86e5-9d860f3e4f04",
                        "5dcd5949-faa9-4af3-8c6f-b285dd3b6566",
                        "5f1992df-975f-49e7-bd88-aee0740317cf",
                        "5f84f09f-7644-447c-89e1-8dc9ee334197",
                        "6018a516-8149-4bce-bc33-5449d86e58c2",
                        "60285266-7da2-474e-b05a-b380c836f665",
                        "768eea6d-8e82-4bbf-8bdd-1f2338ded29f",
                        "791e9257-d7a0-41fe-b471-bde48f3c4a04",
                        "7ab7b36d-baae-4b21-89fc-69389fcabc44",
                        "7b3f5f5b-a965-4656-9a6f-2f9740625176",
                        "899de8c7-9cd9-4dd5-82f1-ad9acb801f8e",
                        "a00704dc-a2fa-4267-b7a6-427167d99521",
                        "a0fa7ae2-61e5-48a9-be10-86440416129f",
                        "a748e0f4-ee6f-41ad-a2a5-1a5a6751086d",
                        "b3e60214-b54c-4e8f-9315-a6975c760f4c",
                        "b4685927-0ad9-466b-b2c6-2e1764475726",
                        "c455fb04-4566-4648-ad6f-3cf2245e507c",
                        "ccdefe89-9b16-4c22-8bb8-bd314ccad6e1",
                        "d20995f6-529c-41c6-b75e-a169b005fb5c",
                        "d9b9f667-9d8a-4723-a6c4-c19b941acd46",
                        "df9fe96c-752e-49be-a8c4-8b098ab51e22",
                        "ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d",
                        "f6272ea9-0360-47ed-90a5-651ea958143f"
                    ],
                    "keyword": [
                        "features",
                        "object",
                        "matching",
                        "recognition",
                        "perform",
                        "images",
                        "single",
                        "robust",
                        "paper",
                        "invariant"
                    ],
                    "group": [
                        null
                    ],
                    "_id": "b944f77f-113b-4a02-ae5e-d4a124b8fd5b",
                    "abstract": "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance.",
                    "title": "Distinctive Image Features from Scale-Invariant Keypoints",
                    "venue": "International Journal of Computer Vision",
                    "year": 2004,
                    "__v": 3,
                    "citationCount": 16229,
                    "result": 5.945625452978394
                },
                "bdd58d4a-2e0e-4fb2-8049-cfa50dda7b0d": {
                    "authors": [
                        "Anuj Mohan",
                        "Constantine Papageorgiou",
                        "Tomaso Poggio"
                    ],
                    "references": [
                        "056e5059-9864-479b-8a2a-fb1cd3d2dd32",
                        "0f115eea-2272-431f-9f21-6d6789b2bbc9",
                        "1e4f4b5c-55e0-4d5b-b7cc-9e7fada3e341",
                        "3704f939-09a2-4e9f-b851-1261bcd310df",
                        "43530fe4-10a9-4ddf-b61d-8844f0ff3f04",
                        "5ebbd1f5-dfe5-4eec-9883-b8b5efea366c",
                        "7ccbdf09-a84e-4ad2-ab20-cb28b6c41155",
                        "82cf52b0-c1d8-4147-b496-451ef66c5825",
                        "91979159-37d8-410f-a245-a33ef80a092b",
                        "a3257b67-d63c-4256-964c-8225a6d4ce1e",
                        "becc43bc-a7b6-46e1-817e-553c84a4a6dd",
                        "c42f42f8-d1b5-4965-b7c2-33a0e2d9c8a9",
                        "d5321e41-3281-4557-ac5a-5c0389818822",
                        "d5e5a24d-f80e-4f1a-b48b-22403b653276",
                        "d6e37fb1-5f7e-448e-847b-7d1f1271c574",
                        "e5e05fd5-f0e6-4660-9b28-a622db44549d",
                        "ff0d990e-90f3-4973-8541-5f7e595710aa"
                    ],
                    "keyword": [
                        "components",
                        "system",
                        "present",
                        "person",
                        "people",
                        "examplebased",
                        "detectors",
                        "classifier",
                        "results",
                        "performs"
                    ],
                    "group": [],
                    "_id": "bdd58d4a-2e0e-4fb2-8049-cfa50dda7b0d",
                    "abstract": "We present a general example-based framework for detecting objects in static images by components. The technique is demonstrated by developing a system that locates people in cluttered scenes. The system is structured with four distinct example-based detectors that are trained to separately find the four components of the human body: the head, legs, left arm, and right arm. After ensuring that these components are present in the proper geometric configuration, a second example-based classifier combines the results of the component detectors to classify a pattern as either a \"person\" or a \"nonperson.\" We call this type of hierarchical architecture, in which learning occurs at multiple stages, an adaptive combination of classifiers (ACC). We present results that show that this system performs significantly better than a similar full-body person detector. This suggests that the improvement in performance is due to the component-based approach and the ACC data classification architecture. The algorithm is also more robust than the full-body person detection method in that it is capable of locating partially occluded views of people and people whose body parts have little contrast with the background.",
                    "title": "Example-based object detection in images by components",
                    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "year": 2001,
                    "__v": 2,
                    "citationCount": 400,
                    "result": 6.531855889208832
                },
                "cb66e49d-077b-4adf-873c-2bc39f78fca6": {
                    "authors": [
                        "Krystian Mikolajczyk",
                        "Cordelia Schmid",
                        "Andrew Zisserman"
                    ],
                    "references": [
                        "04d8a9cb-a14d-4ccf-8b19-da1327e86b91",
                        "3ba1e680-b3cc-40e6-bc90-2af6c781f9bc",
                        "4a5d1ed7-1161-4d67-a229-15f98b62a2fd",
                        "6018a516-8149-4bce-bc33-5449d86e58c2",
                        "67e377ae-20a7-4cc8-9513-cb2665216915",
                        "6f6fe122-6003-498c-a584-b27b3f7a6be3",
                        "6fe37c18-8dc5-4baa-b6e0-5546353907bb",
                        "7237f6e7-205d-4b80-9fe5-4d8fb91b127a",
                        "733eea21-9c61-4935-8ffd-5b8e56dd947d",
                        "899de8c7-9cd9-4dd5-82f1-ad9acb801f8e",
                        "964cd0ae-7afc-42ee-bafd-f7c631fd51cb",
                        "a3257b67-d63c-4256-964c-8225a6d4ce1e",
                        "b5e72744-0105-48bf-95ea-753f52280f48",
                        "bdd58d4a-2e0e-4fb2-8049-cfa50dda7b0d",
                        "c29b523d-e6e8-466c-adf1-0ffef7080029",
                        "c455fb04-4566-4648-ad6f-3cf2245e507c",
                        "c7f93552-c1ef-4ae4-b1f5-2317e1c9d904",
                        "dd096bb0-7c91-4c01-93a2-e9ffeb89705c",
                        "e1f50832-764f-4f22-b3b8-e2dec38c0413",
                        "e3ee2bff-94de-4bd3-8524-af41b9668403",
                        "e649a9fd-f6d9-4aac-b428-29b82c20a484",
                        "f200d16f-8e1a-4a51-be50-4eeaafbb4a2f",
                        "ff0d990e-90f3-4973-8541-5f7e595710aa"
                    ],
                    "keyword": [
                        "parts",
                        "detection",
                        "human",
                        "features",
                        "detectors",
                        "images",
                        "assemblies",
                        "approach"
                    ],
                    "group": [],
                    "_id": "cb66e49d-077b-4adf-873c-2bc39f78fca6",
                    "abstract": "We describe a novel method for human detection in single images which can detect full bodies as well as close-up views in the pres- ence of clutter and occlusion. Humans are modeled as flexible assemblies of parts, and robust part detection is the key to the approach. The parts are represented by co-occurrences of local features which captures the spatial layout of the part's appearance. Feature selection and the part detectors are learnt from training images using AdaBoost. The detection algorithm is very efficient as (i) all part detectors use the same initial features, (ii) a coarse-to-fine cascade approach is used for part detection, (iii) a part assembly strategy reduces the number of spurious detections and the search space. The results outperform existing human detectors.",
                    "title": "Human Detection Based on a Probabilistic Assembly of Robust Part Detectors",
                    "venue": "european conference on computer vision",
                    "year": 2004,
                    "__v": 2,
                    "citationCount": 291,
                    "result": 10.034695653503704
                },
                "ed8a9624-3abe-4b5e-bffe-5b3ecc34e841": {
                    "authors": [
                        "Henry Schneiderman",
                        "Takeo Kanade"
                    ],
                    "references": [
                        "00909251-9935-44f3-94a1-629023b5015b",
                        "133941e6-e23b-4753-9ae9-ee7d2566f20b",
                        "310cbba4-d88d-4bf4-a4f2-738f91b5f8c8",
                        "31364f41-6d21-4efc-866f-954067c23287",
                        "47e8badc-7db1-4e43-99e7-6fea4a6d65e3",
                        "50dd56db-151d-4d62-8576-65f0ef6f381b",
                        "54a5822c-e405-44ad-84e3-cea51e7349c2",
                        "55fa440a-2b98-4e8e-bb45-fa09598b4eca",
                        "5ffac6f9-2456-42cf-830c-9049ce37c899",
                        "8678514b-e795-4972-b891-c0d31d0d46cf",
                        "8f6a657e-e387-4572-bb88-91aee042e8da",
                        "96d6d9b9-6d69-4c9a-b3f5-c8083966d55c",
                        "bb83383f-0de9-408b-9ba2-aa902c63f14a",
                        "cd9494ab-fbd2-401d-8afe-376c0bd24c80",
                        "d5e5a24d-f80e-4f1a-b48b-22403b653276",
                        "d6e37fb1-5f7e-448e-847b-7d1f1271c574",
                        "db26488d-78be-44b1-a343-e896f43c5d29",
                        "e649a9fd-f6d9-4aac-b428-29b82c20a484",
                        "e9eda99f-a7ee-459a-ad22-1fb1cbae2db6",
                        "ed59a2e5-7330-4e07-9edf-cc80872135d0",
                        "ef35a024-f5f3-4a7b-b6f6-61d9167385e6",
                        "f1bd37c4-d033-4cd1-af44-4df9f11c71e4"
                    ],
                    "keyword": [
                        "classifiers",
                        "object",
                        "parts",
                        "image",
                        "detector",
                        "values",
                        "stages",
                        "size",
                        "ratio",
                        "orientation"
                    ],
                    "group": [],
                    "_id": "ed8a9624-3abe-4b5e-bffe-5b3ecc34e841",
                    "abstract": "In this paper we describe a trainable object detector and its instantiations for detecting faces and cars at any size, location, and pose. To cope with variation in object orientation, the detector uses multiple classifiers, each spanning a different range of orientation. Each of these classifiers determines whether the object is present at a specified size within a fixed-size image window. To find the object at any location and size, these classifiers scan the image exhaustively.#R##N##R##N#Each classifier is based on the statistics of localized parts. Each part is a transform from a subset of wavelet coefficients to a discrete set of values. Such parts are designed to capture various combinations of locality in space, frequency, and orientation. In building each classifier, we gathered the class-conditional statistics of these part values from representative samples of object and non-object images. We trained each classifier to minimize classification error on the training set by using Adaboost with Confidence-Weighted Predictions (Shapire and Singer, 1999). In detection, each classifier computes the part values within the image window and looks up their associated class-conditional probabilities. The classifier then makes a decision by applying a likelihood ratio test. For efficiency, the classifier evaluates this likelihood ratio in stages. At each stage, the classifier compares the partial likelihood ratio to a threshold and makes a decision about whether to cease evaluation—labeling the input as non-object—or to continue further evaluation. The detector orders these stages of evaluation from a low-resolution to a high-resolution search of the image. Our trainable object detector achieves reliable and efficient detection of human faces and passenger cars with out-of-plane rotation.",
                    "title": "Object Detection Using the Statistics of Parts",
                    "venue": "International Journal of Computer Vision",
                    "year": 2004,
                    "__v": 2,
                    "citationCount": 167,
                    "result": 5.953704955175543
                },
                "f200d16f-8e1a-4a51-be50-4eeaafbb4a2f": {
                    "authors": [
                        "Rémi Ronfard",
                        "Cordelia Schmid",
                        "Bill Triggs"
                    ],
                    "references": [
                        "04d8a9cb-a14d-4ccf-8b19-da1327e86b91",
                        "13f016e1-bd07-41b6-a190-a8daaabda727",
                        "2cd8042c-88b4-40b6-acfe-b608da036a27",
                        "37d86d82-dd18-4dff-98a3-aa2fdc9c32df",
                        "6759555b-95e6-451d-a447-6b395a0db4d5",
                        "6f6fe122-6003-498c-a584-b27b3f7a6be3",
                        "7f3d9495-7b9e-44ad-a36b-61b8bd7e0e43",
                        "82cf52b0-c1d8-4147-b496-451ef66c5825",
                        "8bb47288-c305-4131-9a23-3635d1bc15ad",
                        "8be8b196-5437-4edc-9823-d4779b4774a5",
                        "91d4d62d-6782-42fa-a53b-b25f29853566",
                        "9f84e529-87a3-42f1-9d63-9af710f40925",
                        "a3257b67-d63c-4256-964c-8225a6d4ce1e",
                        "bdd58d4a-2e0e-4fb2-8049-cfa50dda7b0d",
                        "e702bd2b-e8a2-4e86-98c4-c185e5a16207",
                        "ef52ae7e-761d-4ec7-83c8-c30d9ed6b11b"
                    ],
                    "keyword": [
                        "body",
                        "parts",
                        "learned",
                        "detectors"
                    ],
                    "group": [],
                    "_id": "f200d16f-8e1a-4a51-be50-4eeaafbb4a2f",
                    "abstract": "Detecting people in images is a key problem for video indexing, browsing and retrieval. The main difficulties are the large appearance variations caused by action, clothing, illumination, viewpoint and scale. Our goal is to find people in static video frames using learned models of both the appearance of body parts (head, limbs, hands), and of the geometry of their assemblies. We build on Forsyth & Fleck's general 'body plan' methodology and Felzenszwalb & Huttenlocher's dynamic programming approach for efficiently assembling candidate parts into 'pictorial structures'. However we replace the rather simple part detectors used in these works with dedicated detectors learned for each body part using SupportVector Machines (SVMs) or RelevanceVector Machines (RVMs). We are not aware of any previous work using SVMs to learn articulated body plans, however they have been used to detect both whole pedestrians and combinations of rigidly positioned subimages (typically, upper body, arms, and legs) in street scenes, under a wide range of illumination, pose and clothing variations. RVMs are SVM-like classifiers that offer a well-founded probabilistic interpretation and improved sparsity for reduced computation. We demonstrate their benefits experimentally in a series of results showing great promise for learning detectors in more general situations.",
                    "title": "Learning to Parse Pictures of People",
                    "venue": "european conference on computer vision",
                    "year": 2002,
                    "__v": 1,
                    "citationCount": 104,
                    "result": 4.5527278277278285
                },
                "ffa029cf-7240-4723-8339-51fac57f9f28": {
                    "authors": [
                        "Krystian Mikolajczyk",
                        "Cordelia Schmid"
                    ],
                    "references": [
                        "0d287faa-99bb-42df-98a7-24fcd601b9a4",
                        "1c016f4a-20fb-44b5-84ad-96c10cb8e61b",
                        "2beaa150-6293-4f05-ba04-8e001993e766",
                        "2d6c9f60-ea78-44a8-b5f9-6964575dd196",
                        "33711daf-2a44-4f42-8466-c7801f29959b",
                        "34758e0a-3def-447b-9c5e-e82a206426b5",
                        "36800655-b2ff-4eb7-9070-c6be304c4baa",
                        "457f15ab-c8e1-461d-b768-e044d88f1917",
                        "473cf1a4-9f42-4e6d-b34f-77787f329079",
                        "509e1ae2-768b-4417-bebe-d90cf1e0fdae",
                        "5149d3c0-5ac9-47ba-9fb0-3d2ef757b0e8",
                        "58d0cc4d-9deb-4188-98d2-7ca475ca7221",
                        "5f1992df-975f-49e7-bd88-aee0740317cf",
                        "5f84f09f-7644-447c-89e1-8dc9ee334197",
                        "6018a516-8149-4bce-bc33-5449d86e58c2",
                        "60285266-7da2-474e-b05a-b380c836f665",
                        "643913d9-b72a-4ee3-9c3f-63c1249e9a3c",
                        "64ea9dde-3bd8-4868-9c0b-f15556e67ad5",
                        "7283fa2b-1f6a-4138-a3da-4bf69809a1a9",
                        "79050acb-3012-4d4b-af60-66040a28043d",
                        "7a9f04e3-2883-4204-8fb3-7db1ce5ddc09",
                        "7ab7b36d-baae-4b21-89fc-69389fcabc44",
                        "899de8c7-9cd9-4dd5-82f1-ad9acb801f8e",
                        "8ab773a4-49b4-4755-a070-4ab1b1710690",
                        "a00704dc-a2fa-4267-b7a6-427167d99521",
                        "a0be9da4-c423-4f87-a387-822fe304aa03",
                        "a72802aa-e1ab-4f52-bae8-703d68f9b220",
                        "b3e60214-b54c-4e8f-9315-a6975c760f4c",
                        "c591c440-b19b-4d7b-b067-cd8c366b7d6d",
                        "cc6caca8-1564-4cf8-88a3-f0733c46e0dd",
                        "d4e9734a-a4e7-4c19-be20-c32f55d4d26f",
                        "e86ce68d-0d77-4f44-a212-518e7d8f394b",
                        "eeb31134-612a-42bf-a6c2-8b7d7c17e694",
                        "ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d"
                    ],
                    "keyword": [
                        "scale",
                        "points",
                        "invariant",
                        "affine",
                        "detectors",
                        "neighborhood",
                        "transformations",
                        "shape",
                        "results",
                        "region"
                    ],
                    "group": [],
                    "_id": "ffa029cf-7240-4723-8339-51fac57f9f28",
                    "abstract": "In this paper we propose a novel approach for detecting interest points invariant to scale and affine transformations. Our scale and affine invariant detectors are based on the following recent results: (1) Interest points extracted with the Harris detector can be adapted to affine transformations and give repeatable results (geometrically stable). (2) The characteristic scale of a local structure is indicated by a local extremum over scale of normalized derivatives (the Laplacian). (3) The affine shape of a point neighborhood is estimated based on the second moment matrix.#R##N##R##N#Our scale invariant detector computes a multi-scale representation for the Harris interest point detector and then selects points at which a local measure (the Laplacian) is maximal over scales. This provides a set of distinctive points which are invariant to scale, rotation and translation as well as robust to illumination changes and limited changes of viewpoint. The characteristic scale determines a scale invariant region for each point. We extend the scale invariant detector to affine invariance by estimating the affine shape of a point neighborhood. An iterative algorithm modifies location, scale and neighborhood of each point and converges to affine invariant points. This method can deal with significant affine transformations including large scale changes. The characteristic scale and the affine shape of neighborhood determine an affine invariant region for each point.#R##N##R##N#We present a comparative evaluation of different detectors and show that our approach provides better results than existing methods. The performance of our detector is also confirmed by excellent matching resultss the image is described by a set of scale/affine invariant descriptors computed on the regions associated with our points.",
                    "title": "Scale & Affine Invariant Interest Point Detectors",
                    "venue": "International Journal of Computer Vision",
                    "year": 2004,
                    "__v": 2,
                    "citationCount": 1525,
                    "result": 6.068803418803418
                }
            }
        ],
        "_id": "dd83785a-dd19-41e3-9b25-ebabbd48d336",
        "abstract": "We study the question of feature sets for robust visual object recognition; adopting linear SVM based human detection as a test case. After reviewing existing edge and gradient based descriptors, we show experimentally that grids of histograms of oriented gradient (HOG) descriptors significantly outperform existing feature sets for human detection. We study the influence of each stage of the computation on performance, concluding that fine-scale gradients, fine orientation binning, relatively coarse spatial binning, and high-quality local contrast normalization in overlapping descriptor blocks are all important for good results. The new approach gives near-perfect separation on the original MIT pedestrian database, so we introduce a more challenging dataset containing over 1800 annotated human images with a large range of pose variations and backgrounds.",
        "title": "Histograms of oriented gradients for human detection",
        "venue": "computer vision and pattern recognition",
        "year": 2005,
        "__v": 3,
        "citationCount": 8477
    },
    {
        "authors": [
            "Svetlana Lazebnik",
            "Cordelia Schmid",
            "Jean Ponce"
        ],
        "references": [
            "1ed2cc94-3d0b-4718-80b6-2528e814c921",
            "1f556c88-b553-4c75-b243-92d8200f8149",
            "21a8e8fd-0172-4e9a-8474-7024eb0bf979",
            "26316adf-569e-49bc-a289-c1ba311624f6",
            "2d5181cd-cf99-4afd-afe7-4e37839ea50d",
            "829f9b1f-d04f-49e8-aab7-2c278dff5427",
            "a06e231e-3682-4270-b36a-397d119f504a",
            "ab3afb93-8ca0-4556-ae60-11199dc263c2",
            "ae4a15da-5aec-4876-bec6-7c8ce40761b1",
            "c14bcc73-3061-46a5-9b1e-648faf08f7cf",
            "c2d3dd5b-6fd3-403f-9a03-e1751360e226",
            "c3eee093-b3ff-47ae-a5ac-e005bb060e4a",
            "c455fb04-4566-4648-ad6f-3cf2245e507c",
            "c9482f1f-6600-44a7-a69a-e63ef13cdff8",
            "ea64f6ce-6ad4-4e2d-ad18-24c25ff99870"
        ],
        "keyword": [
            "scene",
            "image",
            "subregions",
            "spatial",
            "pyramid",
            "proposed",
            "method",
            "database",
            "computing",
            "categories"
        ],
        "group": [
            {
                "829f9b1f-d04f-49e8-aab7-2c278dff5427": {
                    "authors": [
                        "Thomas Hofmann"
                    ],
                    "references": [
                        "3c3ce1cf-8c7a-444c-82d8-b428963784e6",
                        "553902a7-99a4-4133-a42f-5bef6a67acfa",
                        "592e8a18-27bf-4561-89d2-01afb204534d",
                        "69df0789-a06f-4166-9c34-93047de2673d",
                        "80fa2024-e935-44a6-8e36-39af74a76dfe",
                        "8622f16e-d502-422d-8fad-cc4fc8ceae7d",
                        "8af55b1b-14a3-49e1-ab6c-d09ac8c6b281",
                        "9707d672-9d01-4f8e-bfa0-028ed63f0837",
                        "9eb4bb10-1cc7-478e-916f-04a072a87751",
                        "ac14afe6-de4d-4056-b2ac-0f6e36f369a2",
                        "b3593e4a-622e-49eb-b375-6ce650003a05",
                        "c3e99ff5-57f9-4012-8b92-48c8d26bf232",
                        "d3ca543b-a6d3-4dac-af08-b8e591340aaf",
                        "dc29fd50-2504-4fb9-b86b-4b2654088e05",
                        "e75d8e62-a86d-4241-953f-1b315005d920",
                        "f7fe9a64-34bc-45d0-aea6-c80355bb8b6c"
                    ],
                    "keyword": [
                        "latent",
                        "analysis",
                        "semantic",
                        "probabilistic",
                        "performs",
                        "method",
                        "text",
                        "technique",
                        "statistical",
                        "results"
                    ],
                    "group": [],
                    "_id": "829f9b1f-d04f-49e8-aab7-2c278dff5427",
                    "abstract": "This paper presents a novel statistical method for factor analysis of binary and count data which is closely related to a technique known as Latent Semantic Analysis. In contrast to the latter method which stems from linear algebra and performs a Singular Value Decomposition of co-occurrence tables, the proposed technique uses a generative latent class model to perform a probabilistic mixture decomposition. This results in a more principled approach with a solid foundation in statistical inference. More precisely, we propose to make use of a temperature controlled version of the Expectation Maximization algorithm for model fitting, which has shown excellent performance in practice. Probabilistic Latent Semantic Analysis has many applications, most prominently in information retrieval, natural language processing, machine learning from text, and in related areas. The paper presents perplexity results for different types of text and linguistic data collections and discusses an application in automated document indexing. The experiments indicate substantial and consistent improvements of the probabilistic method over standard Latent Semantic Analysis.",
                    "title": "Unsupervised learning by probabilistic latent semantic analysis",
                    "venue": "Machine Learning",
                    "year": 2001,
                    "__v": 2,
                    "citationCount": 1008,
                    "result": 5.1383884777073625
                },
                "a06e231e-3682-4270-b36a-397d119f504a": {
                    "authors": [
                        "David G. Lowe"
                    ],
                    "references": [
                        "01a0f825-a308-455b-93fc-e62defc0e3b0",
                        "035f8537-61a7-4c4f-b9fe-120f913a38b0",
                        "5ebbd1f5-dfe5-4eec-9883-b8b5efea366c",
                        "5f1992df-975f-49e7-bd88-aee0740317cf",
                        "6018a516-8149-4bce-bc33-5449d86e58c2",
                        "78dd7c1a-bc00-4993-bd41-8e5da9a7fe5b",
                        "899de8c7-9cd9-4dd5-82f1-ad9acb801f8e",
                        "a00704dc-a2fa-4267-b7a6-427167d99521",
                        "bb4963db-e1bf-43d9-91bd-62e9600938a4"
                    ],
                    "keyword": [
                        "features",
                        "object",
                        "image",
                        "recognition",
                        "modeled",
                        "local",
                        "invariant",
                        "achieved"
                    ],
                    "group": [],
                    "_id": "a06e231e-3682-4270-b36a-397d119f504a",
                    "abstract": "There is considerable evidence that object recognition in primates is based on the detection of local image features of intermediate complexity that are largely invariant to imaging transformations. A computer vision system has been developed that performs object recognition using features with similar properties. Invariance to image translation, scale and rotation is achieved by first selecting stable key points in scale space and performing feature detection only at these locations. The features measure local image gradients in a manner modeled on the response of complex cells in primary visual cortex, and thereby obtain partial invariance to illumination, affine change, and other local distortions. The features are used as input to a nearest-neighbor indexing method and Hough transform that identify candidate object matches. Final verification of each match is achieved by finding a best-fit solution for the unknown model parameters and integrating the features consistent with these parameter values. This verification procedure provides a model for the serial process of attention in human vision that integrates features belonging to a single object. Experimental results show that this approach can achieve rapid and robust object recognition in cluttered partially-occluded images.",
                    "title": "Towards a Computational Model for Object Recognition in IT Cortex",
                    "venue": "Lecture Notes in Computer Science",
                    "year": 2000,
                    "__v": 2,
                    "citationCount": 25,
                    "result": 3.677586826658034
                },
                "c14bcc73-3061-46a5-9b1e-648faf08f7cf": {
                    "authors": [
                        "Svetlana Lazebnik",
                        "Cordelia Schmid",
                        "Jean Ponce"
                    ],
                    "references": [
                        "01f443e7-ea4c-48a7-8081-745c3fa62769",
                        "07ccd481-b4ec-47eb-9634-92e64ba18a08",
                        "2d6c9f60-ea78-44a8-b5f9-6964575dd196",
                        "413cf1e4-b315-47c5-afbf-fe1c642870c8",
                        "6842d04f-2b92-4298-aee8-92babc53f7c4",
                        "7f86241f-b5c5-486a-9fcb-38f6a3435620",
                        "9f5f1500-0df7-4675-8290-b47979bcad38",
                        "b8a86432-fff7-474e-9d72-046c5189e6dc",
                        "b944f77f-113b-4a02-ae5e-d4a124b8fd5b",
                        "c455fb04-4566-4648-ad6f-3cf2245e507c",
                        "cf09783a-75d7-4d0f-9e3f-c39b39b27cf5",
                        "d7b1fba1-b5f8-4377-88a8-d2fc69f723b7",
                        "ec6d5904-331c-48d8-8f6b-f59f7d10bc04"
                    ],
                    "keyword": [
                        "texture",
                        "part",
                        "object",
                        "dictionary",
                        "represented",
                        "keypoints",
                        "framework",
                        "classes"
                    ],
                    "group": [],
                    "_id": "c14bcc73-3061-46a5-9b1e-648faf08f7cf",
                    "abstract": "This paper presents a probabilistic part-based approach for texture and object recognition. Textures are represented using a part dictionary found by quantizing the appearance of scale- or affine- invariant keypoints. Object classes are represented using a dictionary of composite semi-local parts, or groups of neighboring keypoints with stable and distinctive appearance and geometric layout. A discriminative maximum entropy framework is used to learn the posterior distribution of the class label given the occurrences of parts from the dictionary in the training set. Experiments on two texture and two object databases demonstrate the effectiveness of this framework for visual classification.",
                    "title": "A maximum entropy framework for part-based texture and object recognition",
                    "venue": "international conference on computer vision",
                    "year": 2005,
                    "__v": 2,
                    "citationCount": 94,
                    "result": 3.9684056483592083
                },
                "c3eee093-b3ff-47ae-a5ac-e005bb060e4a": {
                    "authors": [
                        "Pedro Quelhas",
                        "Florent Monay",
                        "J.-M. Odobez",
                        "Daniel Gatica-Perez",
                        "Tinne Tuytelaars",
                        "L. Van Gool"
                    ],
                    "references": [
                        "1ed2cc94-3d0b-4718-80b6-2528e814c921",
                        "21a8e8fd-0172-4e9a-8474-7024eb0bf979",
                        "26316adf-569e-49bc-a289-c1ba311624f6",
                        "2beaa150-6293-4f05-ba04-8e001993e766",
                        "5f70f18c-5f9c-442e-ae2c-ee6aadecab95",
                        "60e77fab-98d4-438b-a664-753b70e98709",
                        "6fe37c18-8dc5-4baa-b6e0-5546353907bb",
                        "750b0ac1-2ac9-4273-a9c8-baad11e26fcd",
                        "829f9b1f-d04f-49e8-aab7-2c278dff5427",
                        "8bc5f80f-af26-47b4-aa0a-aab3a2e6c503",
                        "904cbad5-94b6-4992-b1fa-4e68c56f18ab",
                        "b944f77f-113b-4a02-ae5e-d4a124b8fd5b",
                        "c455fb04-4566-4648-ad6f-3cf2245e507c",
                        "cd0d43d4-0be6-4458-a966-118fabbcc90f",
                        "ffa029cf-7240-4723-8339-51fac57f9f28"
                    ],
                    "keyword": [
                        "scenes",
                        "latent",
                        "image",
                        "classification",
                        "approach",
                        "visual",
                        "space",
                        "model",
                        "local",
                        "invariant"
                    ],
                    "group": [],
                    "_id": "c3eee093-b3ff-47ae-a5ac-e005bb060e4a",
                    "abstract": "We present a new approach to model visual scenes in image collections, based on local invariant features and probabilistic latent space models. Our formulation provides answers to three open questions:(l) whether the invariant local features are suitable for scene (rather than object) classification; (2) whether unsupennsed latent space models can be used for feature extraction in the classification task; and (3) whether the latent space formulation can discover visual co-occurrence patterns, motivating novel approaches for image organization and segmentation. Using a 9500-image dataset, our approach is validated on each of these issues. First, we show with extensive experiments on binary and multi-class scene classification tasks, that a bag-of-visterm representation, derived from local invariant descriptors, consistently outperforms state-of-the-art approaches. Second, we show that probabilistic latent semantic analysis (PLSA) generates a compact scene representation, discriminative for accurate classification, and significantly more robust when less training data are available. Third, we have exploited the ability of PLSA to automatically extract visually meaningful aspects, to propose new algorithms for aspect-based image ranking and context-sensitive image segmentation.",
                    "title": "Modeling scenes with local descriptors and latent aspects",
                    "venue": "international conference on computer vision",
                    "year": 2005,
                    "__v": 2,
                    "citationCount": 221,
                    "result": 9.312863684303313
                },
                "c455fb04-4566-4648-ad6f-3cf2245e507c": {
                    "authors": [
                        "Rob Fergus",
                        "Pietro Perona",
                        "Andrew Zisserman"
                    ],
                    "references": [
                        "2d6c9f60-ea78-44a8-b5f9-6964575dd196",
                        "473cf1a4-9f42-4e6d-b34f-77787f329079",
                        "509e1ae2-768b-4417-bebe-d90cf1e0fdae",
                        "613841ae-c925-4aee-9c2e-8675213e4bbf",
                        "bf664a72-1007-43e6-8dff-f1b0de9b5740",
                        "c591c440-b19b-4d7b-b067-cd8c366b7d6d",
                        "c7f93552-c1ef-4ae4-b1f5-2317e1c9d904",
                        "ccdefe89-9b16-4c22-8bb8-bd314ccad6e1",
                        "d5e5a24d-f80e-4f1a-b48b-22403b653276",
                        "d6e37fb1-5f7e-448e-847b-7d1f1271c574",
                        "d7b1fba1-b5f8-4377-88a8-d2fc69f723b7",
                        "df152036-9859-492f-998f-1ff9769b6d95",
                        "e649a9fd-f6d9-4aac-b428-29b82c20a484",
                        "ef35a024-f5f3-4a7b-b6f6-61d9167385e6",
                        "f111ff97-89a3-4df6-8f02-962d7b4fe985"
                    ],
                    "keyword": [
                        "object",
                        "models",
                        "scale",
                        "flexible",
                        "manner",
                        "learn",
                        "image",
                        "class"
                    ],
                    "group": [],
                    "_id": "c455fb04-4566-4648-ad6f-3cf2245e507c",
                    "abstract": "We present a method to learn and recognize object class models from unlabeled and unsegmented cluttered scenes in a scale invariant manner. Objects are modeled as flexible constellations of parts. A probabilistic representation is used for all aspects of the object: shape, appearance, occlusion and relative scale. An entropy-based feature detector is used to select regions and their scale within the image. In learning the parameters of the scale-invariant object model are estimated. This is done using expectation-maximization in a maximum-likelihood setting. In recognition, this model is used in a Bayesian manner to classify images. The flexible nature of the model is demonstrated by excellent results over a range of datasets including geometrically constrained classes (e.g. faces, cars) and flexible objects (such as animals).",
                    "title": "Object class recognition by unsupervised scale-invariant learning",
                    "venue": "computer vision and pattern recognition",
                    "year": 2003,
                    "__v": 2,
                    "citationCount": 1184,
                    "result": 2.43010878010878
                },
                "c9482f1f-6600-44a7-a69a-e63ef13cdff8": {
                    "authors": [
                        "Li Fei-Fei",
                        "Rob Fergus",
                        "Pietro Perona"
                    ],
                    "references": [
                        "2199c5a8-b004-4bcb-81c6-bb1568112077",
                        "222859e5-5135-4d8c-8bb3-8f8fbcc36fe4",
                        "6018a516-8149-4bce-bc33-5449d86e58c2",
                        "613841ae-c925-4aee-9c2e-8675213e4bbf",
                        "7f6e8f66-f378-445a-a322-f2d08287fbe3",
                        "c455fb04-4566-4648-ad6f-3cf2245e507c",
                        "ccdefe89-9b16-4c22-8bb8-bd314ccad6e1",
                        "e649a9fd-f6d9-4aac-b428-29b82c20a484",
                        "ef35a024-f5f3-4a7b-b6f6-61d9167385e6",
                        "fb244d98-60f6-40f8-8c42-a233dfa5843f"
                    ],
                    "keyword": [
                        "object",
                        "learning",
                        "incremental",
                        "categories",
                        "training",
                        "prior",
                        "method",
                        "information",
                        "images",
                        "bayesian"
                    ],
                    "group": [],
                    "_id": "c9482f1f-6600-44a7-a69a-e63ef13cdff8",
                    "abstract": "Current computational approaches to learning visual object categories require thousands of training images, are slow, cannot learn in an incremental manner and cannot incorporate prior information into the learning process. In addition, no algorithm presented in the literature has been tested on more than a handful of object categories. We present an method for learning object categories from just a few training images. It is quick and it uses prior information in a principled way. We test it on a dataset composed of images of objects belonging to 101 widely varied categories. Our proposed method is based on making use of prior information, assembled from (unrelated) object categories which were previously learnt. A generative probabilistic model is used, which represents the shape and appearance of a constellation of features belonging to the object. The parameters of the model are learnt incrementally in a Bayesian manner. Our incremental algorithm is compared experimentally to an earlier batch Bayesian algorithm, as well as to one based on maximum-likelihood. The incremental and batch versions have comparable classification performance on small training sets, but incremental learning is significantly faster, making real-time learning feasible. Both Bayesian methods outperform maximum likelihood on small training sets.",
                    "title": "Learning Generative Visual Models from Few Training Examples: An Incremental Bayesian Approach Tested on 101 Object Categories",
                    "venue": "computer vision and pattern recognition",
                    "year": 2004,
                    "__v": 2,
                    "citationCount": 1108,
                    "result": 7.709087429598265
                },
                "ea64f6ce-6ad4-4e2d-ad18-24c25ff99870": {
                    "authors": [
                        "Hao Zhang",
                        "Alexander C. Berg",
                        "Michael Maire",
                        "Jitendra Malik"
                    ],
                    "references": [
                        "090af1dd-85e1-49f1-ae85-9928df7f709f",
                        "17aaf448-d7d7-48fa-b536-876dc59c7edb",
                        "1f888552-7aec-43bc-80c7-60a791479e8a",
                        "20f52431-62f1-4670-ba81-d19ef3c04204",
                        "29b27984-ff06-4c52-a744-a205bad37fc4",
                        "32dee8bc-22e3-4db9-af2f-0b0c492a2da7",
                        "3843d2db-d96f-47be-8ece-fa9c1e87d1bc",
                        "6ad0e1b1-4a8d-4d9e-8404-6fb2a01194de",
                        "73fc2c1c-88a7-4ffe-afe6-618f22c57157",
                        "7dee8610-7878-451d-aa5c-30f315d8c3f9",
                        "8b2c0aff-4589-4e0f-aae4-4f84a4413406",
                        "8e4a459f-61ea-4355-803f-842f903c995b",
                        "90050143-bb76-4d04-9836-5f781699272e",
                        "9d0c1148-1d1f-4e00-9e52-69b2a8c48c01",
                        "ae3e7593-586f-495f-9416-4b50ed1fcd10",
                        "b4c5a572-c0a9-41e3-8782-9d4ee8105d81",
                        "b592576f-ff29-4a68-9b2f-8a8ad02e9c70",
                        "b72828e5-6b0f-430e-8461-f0e87851d958",
                        "b944f77f-113b-4a02-ae5e-d4a124b8fd5b",
                        "c9482f1f-6600-44a7-a69a-e63ef13cdff8",
                        "cdbd2ef9-d4b1-4dff-9037-3ea84627424d",
                        "cf2118d1-16a2-4cd2-b99e-df920cff971b",
                        "cf93558f-c1b2-4292-8284-1be8d4316af1",
                        "d0563309-0497-4bad-8abe-79f96a19a617",
                        "d7244347-76f9-4ff2-86c1-03798cd473f3",
                        "d8253317-f868-432f-bae4-633f767324db",
                        "e0ac4812-7729-4a2d-8a1f-74b1b7c8eb5d",
                        "fc4a70a7-80c5-43c8-a68f-0a72a46ecce8"
                    ],
                    "keyword": [
                        "vector",
                        "training",
                        "support",
                        "setting",
                        "neighbor",
                        "machines",
                        "distances",
                        "recognition"
                    ],
                    "group": [],
                    "_id": "ea64f6ce-6ad4-4e2d-ad18-24c25ff99870",
                    "abstract": "We consider visual category recognition in the framework of measuring similarities, or equivalently perceptual distances, to prototype examples of categories. This approach is quite flexible, and permits recognition based on color, texture, and particularly shape, in a homogeneous framework. While nearest neighbor classifiers are natural in this setting, they suffer from the problem of high variance (in bias-variance decomposition) in the case of limited sampling. Alternatively, one could use support vector machines but they involve time-consuming optimization and computation of pairwise distances. We propose a hybrid of these two methods which deals naturally with the multiclass setting, has reasonable computational complexity both in training and at run time, and yields excellent results in practice. The basic idea is to find close neighbors to a query sample and train a local support vector machine that preserves the distance function on the collection of neighbors. Our method can be applied to large, multiclass data sets for which it outperforms nearest neighbor and support vector machines, and remains efficient when the problem becomes intractable for support vector machines. A wide variety of distance functions can be used and our experiments show state-of-the-art performance on a number of benchmark data sets for shape and texture classification (MNIST, USPS, CUReT) and object recognition (Caltech- 101). On Caltech-101 we achieved a correct classification rate of 59.05%(±0.56%) at 15 training images per class, and 66.23%(±0.48%) at 30 training images.",
                    "title": "SVM-KNN: Discriminative Nearest Neighbor Classification for Visual Category Recognition",
                    "venue": "computer vision and pattern recognition",
                    "year": 2006,
                    "__v": 2,
                    "citationCount": 526,
                    "result": 4.744744668815875
                }
            }
        ],
        "_id": "e0ac4812-7729-4a2d-8a1f-74b1b7c8eb5d",
        "abstract": "This paper presents a method for recognizing scene categories based on approximate global geometric correspondence. This technique works by partitioning the image into increasingly fine sub-regions and computing histograms of local features found inside each sub-region. The resulting \"spatial pyramid\" is a simple and computationally efficient extension of an orderless bag-of-features image representation, and it shows significantly improved performance on challenging scene categorization tasks. Specifically, our proposed method exceeds the state of the art on the Caltech-101 database and achieves high accuracy on a large database of fifteen natural scene categories. The spatial pyramid framework also offers insights into the success of several recently proposed image descriptions, including Torralbas \"gist\" and Lowes SIFT descriptors.",
        "title": "Beyond Bags of Features: Spatial Pyramid Matching for Recognizing Natural Scene Categories",
        "venue": "computer vision and pattern recognition",
        "year": 2006,
        "__v": 3,
        "citationCount": 3815
    },
    {
        "authors": [
            "Sylvia Ratnasamy",
            "Paul Francis",
            "Mark Handley",
            "Richard M. Karp",
            "Scott Shenker"
        ],
        "references": [
            "00ade209-5974-42c1-9089-a3741481d9c7",
            "0695070f-320e-4d26-9c68-2c8faa20c944",
            "0a094924-1b25-43cc-ac8b-dd8cf90a8f78",
            "1545dfd3-2c25-4ff1-b43c-df4a2a501d06",
            "1cc64868-4f72-4939-aed4-fc8fb0b45118",
            "31c5e39a-3f24-4d20-bf8c-3d00036baf95",
            "39adcd6c-0b60-430c-99ab-21cd9e98b385",
            "42c70869-0dad-4629-93b5-a2d9e29071a7",
            "4743d708-b82d-42ec-adaa-a8bf2f23cc38",
            "483cb980-c968-48e6-b848-714ed2937f98",
            "48740ddd-afd1-4331-8af7-224ef5d19ed7",
            "4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4",
            "88c35cd8-dd49-44f8-9674-96974c8f3650",
            "c0ea675b-2479-48ae-817e-3ecedd175ecf",
            "c8771a57-de9c-44b7-966c-1ff156d3091f",
            "d06f8723-1b89-4684-99c9-c1045ddfb85c",
            "e4ee2d81-7629-4445-b4f3-55ef57bd42fd",
            "ec7d1720-3285-4729-b819-b4c58a826ec8",
            "f6fc4443-7a98-4f9f-92e8-e4e5d94521a7"
        ],
        "keyword": [
            "systems",
            "scalable",
            "hash",
            "functionality",
            "distributed",
            "valuable",
            "values",
            "tablelike",
            "tables",
            "software"
        ],
        "group": [
            {
                "4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4": {
                    "authors": [
                        "Ion Stoica",
                        "Robert Morris",
                        "David Liben-Nowell",
                        "David R. Karger",
                        "M. Frans Kaashoek",
                        "Frank Dabek",
                        "Hari Balakrishnan"
                    ],
                    "references": [
                        "1cc64868-4f72-4939-aed4-fc8fb0b45118",
                        "48740ddd-afd1-4331-8af7-224ef5d19ed7",
                        "59084791-6ebd-4d0d-8f93-2c1da8d47490",
                        "6aac8d9c-34bd-42d9-b887-b0a3bd697ee6",
                        "6eff83a4-db80-40ea-8c9f-8bda5f506c29",
                        "a369afee-a619-4e9a-9250-5fd2b06e8a05",
                        "aa89fd2a-319e-48b1-b0ab-099acbe37617",
                        "abf003a2-6485-41f0-a111-88b80412d539",
                        "b7d7ec53-f079-4bd7-a795-8b6fe77f2db6",
                        "b948f5db-4dc3-4151-a9bd-62a3f5be739e",
                        "c0ea675b-2479-48ae-817e-3ecedd175ecf",
                        "c37c70cb-3956-4249-934d-848845f2f444",
                        "e1263ada-afda-498c-a37d-9b545293118a",
                        "e4ee2d81-7629-4445-b4f3-55ef57bd42fd",
                        "ea44a1ae-ddfe-4694-8df1-0ec69182ec11",
                        "f14df1ed-e3e9-4348-9040-fc06e3411b95",
                        "f49921e2-fb25-48d1-aaf2-1afcfeb8b268",
                        "fad8fc34-ff78-45ac-bc30-ca9e4173740f"
                    ],
                    "keyword": [
                        "node",
                        "chord",
                        "key",
                        "data",
                        "system",
                        "stores",
                        "problem",
                        "maps",
                        "location",
                        "item"
                    ],
                    "group": [
                        null
                    ],
                    "_id": "4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4",
                    "abstract": "A fundamental problem that confronts peer-to-peer applications is the efficient location of the node that stores a desired data item. This paper presents  Chord , a distributed lookup protocol that addresses this problem. Chord provides support for just one operation: given a key, it maps the key onto a node. Data location can be easily implemented on top of Chord by associating a key with each data item, and storing the key/data pair at the node to which the key maps. Chord adapts efficiently as nodes join and leave the system, and can answer queries even if the system is continuously changing. Results from theoretical analysis and simulations show that Chord is scalable: Communication cost and the state maintained by each node scale logarithmically with the number of Chord nodes.",
                    "title": "Chord: a scalable peer-to-peer lookup protocol for Internet applications",
                    "venue": "IEEE\\/ACM Transactions on Networking",
                    "year": 2003,
                    "__v": 3,
                    "citationCount": 5975,
                    "result": 7.416329576855892
                },
                "88c35cd8-dd49-44f8-9674-96974c8f3650": {
                    "authors": [
                        "Ramón Cáceres",
                        "Nick G. Duffield",
                        "Joseph Horowitz",
                        "D. Towlsey",
                        "Tian Bu"
                    ],
                    "references": [
                        "125299a0-d010-4913-bdd8-690ea40a7cd5",
                        "1642f59c-10a1-40da-abb1-0934ef864108",
                        "4b5c9003-da3b-4a1c-9ddd-0262278668e5",
                        "640bf867-82af-4175-a880-11db6e9f4c49",
                        "bca24aff-d6ba-4f1c-b82a-ffbc52815148",
                        "d2b7db5d-bc47-48c7-a173-865fed9bff96",
                        "e4128b01-edcc-4749-b7f7-4a8798ae4f08"
                    ],
                    "keyword": [
                        "loss",
                        "probes",
                        "traffic",
                        "rates",
                        "network",
                        "multicast",
                        "infer",
                        "estimator",
                        "receivers",
                        "packet"
                    ],
                    "group": [],
                    "_id": "88c35cd8-dd49-44f8-9674-96974c8f3650",
                    "abstract": "We explore the use of end-to-end multicast traffic as measurement probes to infer network internal characteristics. We have developed in an earlier paper a maximum likelihood estimator for packet loss rates on individual links based on losses observed by multicast receivers. This technique exploits the inherent correlation between such observations to infer the performance of paths between branch points in the multicast tree spanning the probe source and its receivers. We evaluate through analysis and simulation the accuracy of our estimator under a variety of network conditions. In particular, we report on the error between inferred loss rates and actual loss rates as we vary the network topology, propagation delay, packet drop policy, background traffic mix, and probe traffic type. In all but one case, estimated losses and probe losses agree to within 2 percent on average. We feel this accuracy is enough to reliably identify congested links in a wide-area internetwork.",
                    "title": "Multicast-based inference of network-internal characteristics: accuracy of packet loss estimation",
                    "venue": "international conference on computer communications",
                    "year": 1999,
                    "__v": 1,
                    "citationCount": 58,
                    "result": 3.084107559107559
                },
                "c8771a57-de9c-44b7-966c-1ff156d3091f": {
                    "authors": [
                        "Ellen W. Zegura",
                        "Kenneth L. Calvert",
                        "Samrat Bhattacharjee"
                    ],
                    "references": [
                        "0718dc34-4b49-4b24-8a2e-b5cd0d9d82c6",
                        "0b8983cb-f319-4556-91e5-69410f8e6172",
                        "221a51ba-b64d-4bf4-b9b9-968b9d7bd99e",
                        "2c6bba4b-342e-4f90-b27b-35b1934d9186",
                        "386a49a9-d157-4e11-b4a7-18535c14cb94",
                        "4e91bf76-c262-4d42-b8e2-1a3de3c6cac6",
                        "597182f8-8afc-4f90-9aab-70b5c92607d0",
                        "79eab80b-9916-4045-96f1-eb077dddd14b",
                        "abfeee51-0e3a-43c2-b974-cc589c32a679"
                    ],
                    "keyword": [
                        "topologies",
                        "model",
                        "internetworks",
                        "graphs",
                        "generated",
                        "structure",
                        "real",
                        "properties",
                        "study",
                        "problems"
                    ],
                    "group": [],
                    "_id": "c8771a57-de9c-44b7-966c-1ff156d3091f",
                    "abstract": "Graphs are commonly used to model the structure of internetworks, for the study of problems ranging from routing to resource reservation. A variety of graph models are found in the literature, including regular topologies such as rings or stars, \"well-known\" topologies such as the original ARPAnet, and randomly generated topologies. Less common is any discussion of how closely these models correlate with real network topologies. We consider the problem of efficiently generating graph models that accurately reflect the topological properties of real internetworks. We compare the properties of graphs generated using various methods with those of real internets. We also propose efficient methods for generating topologies with particular properties, including a transit-stub model that correlates well with the internet structure. Improved models for the internetwork structure have the potential to impact the significance of simulation studies of internetworking solutions, providing a basis for the validity of the conclusions.",
                    "title": "How to model an internetwork",
                    "venue": "international conference on computer communications",
                    "year": 1996,
                    "__v": 2,
                    "citationCount": 929,
                    "result": 4.909420112051691
                },
                "d06f8723-1b89-4684-99c9-c1045ddfb85c": {
                    "authors": [
                        "Ion Stoica",
                        "Robert Morris",
                        "David R. Karger",
                        "M. Frans Kaashoek",
                        "Hari Balakrishnan"
                    ],
                    "references": [
                        "1c729f22-9928-4703-92a0-8819569a1bbb",
                        "1cc64868-4f72-4939-aed4-fc8fb0b45118",
                        "48740ddd-afd1-4331-8af7-224ef5d19ed7",
                        "4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4",
                        "59084791-6ebd-4d0d-8f93-2c1da8d47490",
                        "6500989e-b1e1-4b02-a921-21ec25685b73",
                        "6aac8d9c-34bd-42d9-b887-b0a3bd697ee6",
                        "6eff83a4-db80-40ea-8c9f-8bda5f506c29",
                        "7502e770-12f7-4fd1-8cd6-f54f456f7aa8",
                        "a1b950a0-345b-4471-ba60-872e4f8cc058",
                        "a369afee-a619-4e9a-9250-5fd2b06e8a05",
                        "aa89fd2a-319e-48b1-b0ab-099acbe37617",
                        "b7d7ec53-f079-4bd7-a795-8b6fe77f2db6",
                        "c0ea675b-2479-48ae-817e-3ecedd175ecf",
                        "c37c70cb-3956-4249-934d-848845f2f444",
                        "e1263ada-afda-498c-a37d-9b545293118a",
                        "e4ee2d81-7629-4445-b4f3-55ef57bd42fd"
                    ],
                    "keyword": [
                        "node",
                        "chord",
                        "key",
                        "item",
                        "data",
                        "system",
                        "stores",
                        "problem",
                        "maps",
                        "locate"
                    ],
                    "group": [],
                    "_id": "d06f8723-1b89-4684-99c9-c1045ddfb85c",
                    "abstract": "A fundamental problem that confronts peer-to-peer applications is to efficiently locate the node that stores a particular data item. This paper presents  Chord , a distributed lookup protocol that addresses this problem. Chord provides support for just one operation: given a key, it maps the key onto a node. Data location can be easily implemented on top of Chord by associating a key with each data item, and storing the key/data item pair at the node to which the key maps. Chord adapts efficiently as nodes join and leave the system, and can answer queries even if the system is continuously changing. Results from theoretical analysis, simulations, and experiments show that Chord is scalable, with communication cost and the state maintained by each node scaling logarithmically with the number of Chord nodes.",
                    "title": "Chord: A scalable peer-to-peer lookup service for internet applications",
                    "venue": "acm special interest group on data communication",
                    "year": 2001,
                    "__v": 2,
                    "citationCount": 2568,
                    "result": 7.965816931606405
                },
                "e4ee2d81-7629-4445-b4f3-55ef57bd42fd": {
                    "authors": [
                        "Jinyang Li",
                        "John Jannotti",
                        "Douglas S. J. De Couto",
                        "David R. Karger",
                        "Robert Morris"
                    ],
                    "references": [
                        "0d4d0363-07b5-43b6-976d-955e96044709",
                        "1545dfd3-2c25-4ff1-b43c-df4a2a501d06",
                        "39adcd6c-0b60-430c-99ab-21cd9e98b385",
                        "60fb0dc2-bde3-4714-948e-de0ed12ab460",
                        "6eff83a4-db80-40ea-8c9f-8bda5f506c29",
                        "7c9f8cd8-d0ef-4954-b4db-4a6c803459c2",
                        "83a2eb55-b330-4e0c-8dc9-05e9466d5028",
                        "9de43d04-c7fa-48a9-b092-67c2888745d4",
                        "c7b0d60b-9956-4254-b6d3-26fb1f8782bb",
                        "e3af190a-754d-415d-a32d-f1d9999c599f",
                        "ff4259bb-5b84-4f51-b975-146794715d22"
                    ],
                    "keyword": [
                        "node",
                        "location",
                        "gls",
                        "mobile",
                        "networks",
                        "servers",
                        "queries",
                        "predefined",
                        "geographic"
                    ],
                    "group": [],
                    "_id": "e4ee2d81-7629-4445-b4f3-55ef57bd42fd",
                    "abstract": "GLS is a new distributed location service which tracks mobile node locations. GLS combined with geographic forwarding allows the construction of ad hoc mobile networks that scale to a larger number of nodes than possible with previous work. GLS is decentralized and runs on the mobile nodes themselves, requiring no fixed infrastructure. Each mobile node periodically updates a small set of other nodes (its location servers) with its current location. A node sends its position updates to its location servers without knowing their actual identities, assisted by a predefined ordering of node identifiers and a predefined geographic hierarchy. Queries for a mobile node's location also use the predefined identifier ordering and spatial hierarchy to find a location server for that node.  Experiments using the  ns  simulator for up to 600 mobile nodes show that the storage and bandwidth requirements of GLS grow slowly with the size of the network. Furthermore, GLS tolerates node failures well: each failure has only a limited effect and query performance degrades gracefully as nodes fail and restart. The query performance of GLS is also relatively insensitive to node speeds. Simple geographic forwarding combined with GLS compares favorably with Dynamic Source Routing (DSR): in larger networks (over 200 nodes) our approach delivers more packets, but consumes fewer network resources.",
                    "title": "A scalable location service for geographic ad hoc routing",
                    "venue": "acm ieee international conference on mobile computing and networking",
                    "year": 2000,
                    "__v": 2,
                    "citationCount": 786,
                    "result": 3.242032528874634
                },
                "ec7d1720-3285-4729-b819-b4c58a826ec8": {
                    "authors": [
                        "Sylvia Ratnasamy",
                        "Mark Handley",
                        "Richard M. Karp",
                        "Scott Shenker"
                    ],
                    "references": [
                        "436b5fcd-6488-4a4c-b41a-85130718b39a",
                        "4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4",
                        "5de99dee-6647-4ebf-b20b-fe970cfd062b",
                        "b61d40f0-06b8-4779-8600-4884087348ca",
                        "c8771a57-de9c-44b7-966c-1ff156d3091f",
                        "d06f8723-1b89-4684-99c9-c1045ddfb85c",
                        "e1263ada-afda-498c-a37d-9b545293118a",
                        "f14df1ed-e3e9-4348-9040-fc06e3411b95"
                    ],
                    "keyword": [
                        "multicast",
                        "scheme",
                        "proposed",
                        "applicationlevel",
                        "solutions",
                        "service",
                        "scale",
                        "scalability",
                        "routing",
                        "restricting"
                    ],
                    "group": [],
                    "_id": "ec7d1720-3285-4729-b819-b4c58a826ec8",
                    "abstract": "Most currently proposed solutions to application-level multicast organise the group members into an application-level mesh over which a Distance-Vector routing protocol, or a similar algorithm, is used to construct source-rooted distribution trees. The use of a global routing protocol limits the scalability of these systems. Other proposed solutions that scale to larger numbers of receivers do so by restricting the multicast service model to be single-sourced. In this paper, we propose an application-level multicast scheme capable of scaling to large group sizes without restricting the service model to a single source. Our scheme builds on recent work on Content-Addressable Networks (CANs). Extending the CAN framework to support multicast comes at trivial additional cost and, because of the structured nature of CAN topologies, obviates the need for a multicast routingalg orithm. Given the deployment of a distributed infrastructure such as a CAN, we believe our CAN-based multicast scheme offers the dual advantages of simplicity and scalability.",
                    "title": "Application-Level Multicast Using Content-Addressable Networks",
                    "venue": "Lecture Notes in Computer Science",
                    "year": 2001,
                    "__v": 2,
                    "citationCount": 326,
                    "result": 9.206033995443741
                },
                "f6fc4443-7a98-4f9f-92e8-e4e5d94521a7": {
                    "authors": [
                        "Sally Floyd",
                        "Van Jacobson",
                        "Ching-gung Liu",
                        "Steven McCanne",
                        "Lixia Zhang"
                    ],
                    "references": [
                        "01ed65be-1f6f-4a2b-bd4d-640131a2013e",
                        "0695070f-320e-4d26-9c68-2c8faa20c944",
                        "080470a8-9512-435d-a715-9ab4060015b5",
                        "0ce4877b-6e18-455c-9ee5-7ca93715a88f",
                        "14dbcb0a-b6a3-4407-9a3c-0ce575e268c9",
                        "1bb1fc9b-7b67-44a2-85f7-b609aa9c9eee",
                        "314f5dde-7eef-42fa-9d17-da162e9b1efb",
                        "35d355ed-82de-455d-acd5-fb0e38ea1a56",
                        "4ae3f7cf-16ae-49eb-ac7a-348e013abddc",
                        "51b8dcd2-b450-4710-b177-a78bb286175a",
                        "53e7e67d-b015-43a7-b4e0-2c45776e10bf",
                        "54f7f3ef-3fd8-4b9a-aaea-e291a297b2c2",
                        "6f1bb20f-25f0-4d0b-a7a5-f31e3fa66bdd",
                        "90e6c852-a1c5-4023-a8be-11f214d729e4",
                        "a202d101-de4d-4072-9859-d7739d4c791b",
                        "c56e468c-21be-40f2-ab54-57fc34522629",
                        "d563bff2-b63b-470e-a53f-567f8927dbf4",
                        "ee025190-5303-4b3e-84b2-a17c88382472"
                    ],
                    "keyword": [
                        "reliable",
                        "multicast",
                        "algorithms",
                        "srm",
                        "sessions",
                        "model",
                        "framework",
                        "delivery",
                        "application",
                        "adaptive"
                    ],
                    "group": [],
                    "_id": "f6fc4443-7a98-4f9f-92e8-e4e5d94521a7",
                    "abstract": "This paper describes scalable reliable multicast (SRM), a reliable multicast framework for light-weight sessions and application level framing. The algorithms of this framework are efficient, robust, and scale well to both very large networks and very large sessions. The SRM framework has been prototyped in wb, a distributed whiteboard application, which has been used on a global scale with sessions ranging from a few to a few hundred participants. The paper describes the principles that have guided the SRM design, including the IP multicast group delivery model, an end-to-end, receiver-based model of reliability, and the application level framing protocol model. As with unicast communications, the performance of a reliable multicast delivery algorithm depends on the underlying topology and operational environment. We investigate that dependence via analysis and simulation, and demonstrate an adaptive algorithm that uses the results of previous loss recovery events to adapt the control parameters used for future loss recovery. With the adaptive algorithm, our reliable multicast delivery algorithm provides good performance over a wide range of underlying topologies.",
                    "title": "A reliable multicast framework for light-weight sessions and application level framing",
                    "venue": "IEEE\\/ACM Transactions on Networking",
                    "year": 1997,
                    "__v": 2,
                    "citationCount": 664,
                    "result": 6.069409039532879
                }
            }
        ],
        "_id": "e1263ada-afda-498c-a37d-9b545293118a",
        "abstract": "Hash tables - which map \"keys\" onto \"values\" - are an essential building block in modern software systems. We believe a similar functionality would be equally valuable to large distributed systems. In this paper, we introduce the concept of a Content-Addressable Network (CAN) as a distributed infrastructure that provides hash table-like functionality on Internet-like scales. The CAN is scalable, fault-tolerant and completely self-organizing, and we demonstrate its scalability, robustness and low-latency properties through simulation.",
        "title": "A scalable content-addressable network",
        "venue": "acm special interest group on data communication",
        "year": 2001,
        "__v": 3,
        "citationCount": 3635
    },
    {
        "authors": [
            "Timo Ojala",
            "Matti Pietikäinen",
            "Topi Mäenpää"
        ],
        "references": [
            "0647fc30-735a-4d45-bf63-433216d5a014",
            "087735a7-1cb9-4911-a88b-158cf3ebde87",
            "09346dc3-f4d0-43a4-8f0b-27e02bcd336e",
            "0af9a421-ca6a-4f1e-acef-d77082a7cf0c",
            "0da4dd98-2681-4d42-ae54-9347e8dfed97",
            "11eebfa1-436a-4203-a39a-0d1c02bda34f",
            "233a5884-312b-4003-855f-c75f3f7c90ea",
            "30614910-26a5-495c-8bb7-0f723c47db69",
            "3a770bd2-20c6-45e1-b98e-46d6f31f1966",
            "3c4e8d07-47e2-4942-8197-59b613634ce4",
            "4d92607c-d2ca-48fa-9a55-8e7eff5a71d3",
            "5ffd13e9-177c-45f9-8f77-40e6e8f8378d",
            "606f8ecd-75f5-40fa-a70d-d6665cd2990e",
            "70e86498-0a19-465c-8b73-49c2769b1a53",
            "746415d7-a412-4a66-8752-ce90b405fc94",
            "76d48657-1eba-43d5-a642-f6f553331633",
            "79aaae90-c329-4f9f-86fb-31ae2ea58ae8",
            "813a6153-f889-4801-ac2a-233be07e5df7",
            "8573e55d-619d-425c-bbdf-4a0dbfe8f862",
            "9270a9b5-940a-4394-814f-433c6440f286",
            "a8d582af-d7f0-4a20-aba5-5b49f43e990a",
            "b1fbed62-1a39-48d6-8eb5-ea103ad6423e",
            "b9d5d8e9-ea08-4a60-a1fe-2164382647b8",
            "ba03a3a9-4acc-4fdb-a95f-75c76861b620",
            "be4205fb-27a0-4449-9ba2-d311dfd393a2",
            "d6e78be6-6ad4-4ea2-8076-911d015644e3",
            "d6e93459-39bb-4c2a-8018-cf9437c0ea06",
            "d70539c8-d4d5-4d3d-8333-6e6b210ff641",
            "e7209bb1-d240-48c1-866a-3fdcce8fa558"
        ],
        "keyword": [
            "operator",
            "patterns",
            "local",
            "invariant",
            "texture",
            "rotation",
            "presents",
            "grayscale",
            "binary",
            "uniform"
        ],
        "group": [
            {
                "3a770bd2-20c6-45e1-b98e-46d6f31f1966": {
                    "authors": [
                        "Matti Pietikäinen",
                        "Timo Ojala",
                        "Zelin Xu"
                    ],
                    "references": [
                        "087735a7-1cb9-4911-a88b-158cf3ebde87",
                        "0af9a421-ca6a-4f1e-acef-d77082a7cf0c",
                        "3c4e8d07-47e2-4942-8197-59b613634ce4",
                        "4d92607c-d2ca-48fa-9a55-8e7eff5a71d3",
                        "606f8ecd-75f5-40fa-a70d-d6665cd2990e",
                        "70e86498-0a19-465c-8b73-49c2769b1a53",
                        "9270a9b5-940a-4394-814f-433c6440f286",
                        "bd6cbbaa-f2f2-49c1-b672-ecc9a1c626f9",
                        "d2930486-5812-4750-b650-dfd17d917226",
                        "e7209bb1-d240-48c1-866a-3fdcce8fa558"
                    ],
                    "keyword": [],
                    "group": [],
                    "_id": "3a770bd2-20c6-45e1-b98e-46d6f31f1966",
                    "abstract": "A distribution-based classification approach and a set of recently developed texture measures are applied to rotation-invariant texture classification. The performance is compared to that obtained with the well-known circular-symmetric autoregressive random field (CSAR) model approach. A difficult classification problem of 15 different Brodatz textures and seven rotation angles is used in experiments. The results show much better performance for our approach than for the CSAR features. A detailed analysis of the confusion matrices and the rotation angles of misclassified samples produces several interesting observations about the classification problem and the features used in this study.",
                    "title": "Rotation-invariant texture classification using feature distributions",
                    "venue": "Pattern Recognition",
                    "year": 2000,
                    "__v": 0,
                    "citationCount": 112,
                    "result": 2.7586206896551726
                },
                "4d92607c-d2ca-48fa-9a55-8e7eff5a71d3": {
                    "authors": [
                        "Larry S Davis"
                    ],
                    "references": [
                        "087735a7-1cb9-4911-a88b-158cf3ebde87",
                        "48c4df8b-249a-4ca2-bf93-4df44200b7a6",
                        "9cef868f-eb6d-4189-acd1-43eac87cf81e"
                    ],
                    "keyword": [
                        "texture",
                        "polarogram",
                        "sensitive",
                        "image",
                        "tool",
                        "statistic",
                        "samples",
                        "rotations",
                        "rise",
                        "polar"
                    ],
                    "group": [],
                    "_id": "4d92607c-d2ca-48fa-9a55-8e7eff5a71d3",
                    "abstract": "Abstract : This paper introduces a new tool for image texture analysis called a polarogram. A polarogram is a polar plot of an orientation sensitive texture statistic. Polarograms give rise to a class of texture descriptors which are sensitive to both texture coarseness and directionality, but yet which are invariant to rotations of the image textures. An experiment is described in which polarograms are applied to the classification of texture samples. (Author)",
                    "title": "Polarograms: a New Tool for Image Texture Analysis",
                    "venue": "Pattern Recognition",
                    "year": 1979,
                    "__v": 1,
                    "citationCount": 41,
                    "result": 6.199061913970638
                },
                "5ffd13e9-177c-45f9-8f77-40e6e8f8378d": {
                    "authors": [
                        "George M. Haley",
                        "B. S. Manjunath"
                    ],
                    "references": [
                        "0af9a421-ca6a-4f1e-acef-d77082a7cf0c",
                        "11c60938-c8ff-4efc-9651-6854bfb1a16e",
                        "1a040e34-192c-48da-89c4-a89f05cc6f9b",
                        "1c99f86a-da88-47ed-ab16-e8b3323749aa",
                        "31e350c1-0600-4d59-9171-d2085a17d7bd",
                        "3c4e8d07-47e2-4942-8197-59b613634ce4",
                        "3f0bc2c9-a5c2-4e4c-a4e9-7631e36bc6a3",
                        "553abe04-7a0d-4ebd-a46d-b2f1294c0737",
                        "606f8ecd-75f5-40fa-a70d-d6665cd2990e",
                        "7ccbdf09-a84e-4ad2-ab20-cb28b6c41155",
                        "8747f12d-32f3-4156-a0b9-ad8d8c8df8f5",
                        "ad1edc2a-8fd9-47a0-aa46-a8c856847b60",
                        "c54f5e9b-8ee1-4c6d-934f-84c1f2413015",
                        "db5e774e-4fdf-4823-8a41-cb4cebd0055c",
                        "f168ad6f-0085-4779-8ddb-4bdc2f5af9d2",
                        "f4e766ac-f68f-4829-a5f8-bc8751f57948",
                        "fc443443-416f-4fd5-ba46-17a06046711d"
                    ],
                    "keyword": [
                        "texture",
                        "sample",
                        "classification",
                        "wavelet",
                        "micromodel",
                        "microfeatures",
                        "macrofeatures",
                        "form",
                        "derived",
                        "based"
                    ],
                    "group": [],
                    "_id": "5ffd13e9-177c-45f9-8f77-40e6e8f8378d",
                    "abstract": "A method of rotation-invariant texture classification based on a complete space-frequency model is introduced. A polar, analytic form of a two-dimensional (2-D) Gabor wavelet is developed, and a multiresolution family of these wavelets is used to compute information-conserving microfeatures. From these microfeatures a micromodel, which characterizes spatially localized amplitude, frequency, and directional behavior of the texture, is formed. The essential characteristics of a texture sample, its macrofeatures, are derived from the estimated selected parameters of the micromodel. Classification of texture samples is based on the macromodel derived from a rotation invariant subset of macrofeatures. In experiments, comparatively high correct classification rates were obtained using large sample sets.",
                    "title": "Rotation-invariant texture classification using a complete space-frequency model",
                    "venue": "IEEE Transactions on Image Processing",
                    "year": 1999,
                    "__v": 2,
                    "citationCount": 110,
                    "result": 7.110885535410464
                },
                "606f8ecd-75f5-40fa-a70d-d6665cd2990e": {
                    "authors": [
                        "Fernand S. Cohen",
                        "Zhigang Fan",
                        "Maqbool A. Patel"
                    ],
                    "references": [
                        "044ccfaf-4ede-4da3-9fe9-ebd615c7b910",
                        "087735a7-1cb9-4911-a88b-158cf3ebde87",
                        "1325fe65-6240-4f2f-8f4a-7ca12035551b",
                        "1db7f15e-832c-4f79-8aeb-b7819954c72b",
                        "3c4e8d07-47e2-4942-8197-59b613634ce4",
                        "536bae3c-3a30-4855-ac10-411930bd11ad",
                        "623d2a5e-3e87-4c96-a86d-7d450bc10d06",
                        "90493f6a-3ecc-4ffa-82d1-02747c8659b9",
                        "9f886972-baca-422c-9a13-b1cf7cb95812",
                        "a8d1500f-25f3-4d36-8867-f0514e20cb65",
                        "bfe98bfe-da21-4711-9e85-f63271e49441",
                        "c54f5e9b-8ee1-4c6d-934f-84c1f2413015",
                        "db5e774e-4fdf-4823-8a41-cb4cebd0055c",
                        "f61355ef-468d-4fff-a018-65550189e509"
                    ],
                    "keyword": [
                        "textured",
                        "scale",
                        "rotation",
                        "image",
                        "function",
                        "likelihood",
                        "gmrf",
                        "parameters",
                        "transformation",
                        "test"
                    ],
                    "group": [],
                    "_id": "606f8ecd-75f5-40fa-a70d-d6665cd2990e",
                    "abstract": "Consideration is given to the problem of classifying a test textured image that is obtained from one of C possible parent texture classes, after possibly applying unknown rotation and scale changes to the parent texture. The training texture images (parent classes) are modeled by Gaussian Markov random fields (GMRFs). To classify a rotated and scaled test texture, the rotation and scale changes are incorporated in the texture model through an appropriate transformation of the power spectral density of the GMRF. For the rotated and scaled image, a bona fide likelihood function that shows the explicit dependence of the likelihood function on the GMRF parameters, as well as on the rotation and scale parameters, is derived. Although, in general, the scaled and/or rotated texture does not correspond to a finite-order GMRF, it is possible nonetheless to write down a likelihood function for the image data. The likelihood function of the discrete Fourier transform of the image data corresponds to that of a white nonstationary Gaussian random field, with the variance at each pixel (i,j) being a known function of the rotation, the scale, the GMRF model parameters, and (i,j). The variance is an explicit function of the appropriately sampled power spectral density of the GMRF. The estimation of the rotation and scale parameters is performed in the frequency domain by maximizing the likelihood function associated with the discrete Fourier transform of the image data. Cramer-Rao error bounds on the scale and rotation estimates are easily computed. A modified Bayes decision rule is used to classify a given test image into one of C possible texture classes. The classification power of the method is demonstrated through experimental results on natural textures from the Brodatz album. >",
                    "title": "Classification of rotated and scaled textured images using Gaussian Markov random field models",
                    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "year": 1991,
                    "__v": 1,
                    "citationCount": 136,
                    "result": 8.098217396223696
                },
                "70e86498-0a19-465c-8b73-49c2769b1a53": {
                    "authors": [
                        "Jianchang Mao",
                        "Anil K. Jain"
                    ],
                    "references": [
                        "021d51c9-a26d-4a5a-ac5f-5d1c4653c5fb",
                        "1017d9d4-9a4c-423d-ad40-6d9bebbd6b31",
                        "3c4e8d07-47e2-4942-8197-59b613634ce4",
                        "400c7d3d-a4e9-49a1-821c-3646904d44ed",
                        "575c97d4-2a2e-49cb-9319-df0dbe57ef36",
                        "6686d73f-897a-40b4-a548-d294438a03e8",
                        "66ce8563-5327-455e-afa5-941f663bfbde",
                        "69b6d290-efca-43dc-85b2-5b11f86c7ab7",
                        "9205abb2-a53a-4d16-b3d5-ebb3c6a6640b",
                        "93869064-218b-475d-909d-abf02329ba38",
                        "a741aea9-18f9-43a8-8f94-8050fb9f052d",
                        "c54f5e9b-8ee1-4c6d-934f-84c1f2413015",
                        "cd8df7ee-a457-47c4-bd7d-3f4187daaf10",
                        "d0b38dbb-37d1-4804-8a5d-f6fabb2078bb",
                        "d353984d-d376-43f1-ad08-0f3199f7b993",
                        "db5e774e-4fdf-4823-8a41-cb4cebd0055c",
                        "e2fe7a5c-3b21-4b4f-bacf-be28af75689f",
                        "ee3fa7f4-a88d-4b58-8ee8-843370ed51be",
                        "f4da7094-903c-47cd-b5ca-4a75af3fc416",
                        "f60b0079-9454-4cb5-8c7e-ea199e76d8bc",
                        "f61355ef-468d-4fff-a018-65550189e509"
                    ],
                    "keyword": [
                        "segmentation",
                        "texture",
                        "model",
                        "features",
                        "classification",
                        "spatial",
                        "sar",
                        "risar",
                        "present",
                        "multivariate"
                    ],
                    "group": [],
                    "_id": "70e86498-0a19-465c-8b73-49c2769b1a53",
                    "abstract": "We present a multiresolution simultaneous autoregressive (MR-SAR) model for texture classification and segmentation. First, a multivariate rotation-invariant SAR (RISAR) model is introduced which is based on the circular autoregressive (CAR) model. Experiments show that the multivariate RISAR model outperforms the CAR model in texture classification. Then, we demonstrate that integrating the information extracted from multiresolution SAR models gives much better performance than single resolution methods in both texture classification and texture segmentation. A quality measure to evaluate individual features for the purpose of segmentation is also presented. We employ the spatial coordinates of the pixels as two additional features to remove small speckles in the segmented image, and carefully examine the role that the spatial features play in texture segmentation. Two internal indices are introduced to evaluate the unsupervised segmentation and to find the “true” number of segments or clusters existing in the textured image.",
                    "title": "Texture classification and segmentation using multiresolution simultaneous autoregressive models",
                    "venue": "Pattern Recognition",
                    "year": 1992,
                    "__v": 1,
                    "citationCount": 273,
                    "result": 9.71093752545925
                },
                "746415d7-a412-4a66-8752-ce90b405fc94": {
                    "authors": [
                        "Robert Porter",
                        "Nishan Canagarajah"
                    ],
                    "references": [
                        "1c99f86a-da88-47ed-ab16-e8b3323749aa",
                        "3c4e8d07-47e2-4942-8197-59b613634ce4",
                        "70e86498-0a19-465c-8b73-49c2769b1a53",
                        "8b93e983-3647-4947-979d-edd1769100d8",
                        "afc23a7d-3f52-4cec-bdae-4aee9a413f61",
                        "f4e766ac-f68f-4829-a5f8-bc8751f57948",
                        "f5980f05-fb35-4667-880f-b59919426ab8"
                    ],
                    "keyword": [
                        "texture",
                        "schemes",
                        "rotation",
                        "image",
                        "high",
                        "features",
                        "existing",
                        "classification",
                        "analysis",
                        "required"
                    ],
                    "group": [],
                    "_id": "746415d7-a412-4a66-8752-ce90b405fc94",
                    "abstract": "The importance of texture analysis and classification in image processing is well known. However, many existing texture classification schemes suffer from a number of drawbacks. A large number of features are commonly used to represent each texture and an excessively large image area is often required for the texture analysis, both leading to high computational complexity. Furthermore, most existing schemes are highly orientation dependent and thus cannot correctly classify textures after rotation. In this paper, two novel feature extraction techniques for rotation invariant texture classification are presented. These schemes, using the wavelet transform and Gaussian Markov random field modelling, are shown to give a consistently high performance for rotated textures in the presence of noise. Moreover, they use just four features to represent each texture and require only a 16/spl times/16 image area for their analysis leading to a significantly lower computational complexity than most existing schemes.",
                    "title": "Robust rotation invariant texture classification",
                    "venue": "international conference on acoustics, speech, and signal processing",
                    "year": 1997,
                    "__v": 2,
                    "citationCount": 19,
                    "result": 7.3156289921956645
                },
                "76d48657-1eba-43d5-a642-f6f553331633": {
                    "authors": [
                        "Wen-Rong Wu",
                        "Shieh-Chung Wei"
                    ],
                    "references": [
                        "07a6d3a2-251e-4441-95c2-2e15ff0e62d4",
                        "087735a7-1cb9-4911-a88b-158cf3ebde87",
                        "0d66d358-49fa-4d9c-931e-98c828313246",
                        "1325fe65-6240-4f2f-8f4a-7ca12035551b",
                        "14928b47-1730-4a5f-a6c8-43399316abb7",
                        "1c99f86a-da88-47ed-ab16-e8b3323749aa",
                        "213c8623-c9c9-4c42-9582-4699e0d095c0",
                        "233a5884-312b-4003-855f-c75f3f7c90ea",
                        "26936fd1-612e-42d9-b565-d1cf8315bc3c",
                        "31e350c1-0600-4d59-9171-d2085a17d7bd",
                        "3c4e8d07-47e2-4942-8197-59b613634ce4",
                        "3c576bc2-bd42-4462-80d4-236467ec48b3",
                        "3da38560-7591-4522-b593-af5b128cc10b",
                        "48c4df8b-249a-4ca2-bf93-4df44200b7a6",
                        "536bae3c-3a30-4855-ac10-411930bd11ad",
                        "5ebc8117-0e62-4b17-8dd6-abf0248d07a9",
                        "606f8ecd-75f5-40fa-a70d-d6665cd2990e",
                        "623d2a5e-3e87-4c96-a86d-7d450bc10d06",
                        "6c407686-4fb2-4f0b-9ced-644903f3954e",
                        "8831d80b-0ec8-4d25-a609-7746251a0f54",
                        "9cef868f-eb6d-4189-acd1-43eac87cf81e",
                        "ae1545aa-e965-4400-8e66-a5c351c99c7c",
                        "ba1455c6-3b4b-4722-9cce-84be1cc242ad",
                        "c54f5e9b-8ee1-4c6d-934f-84c1f2413015",
                        "d37db9c2-96dc-4b09-99ec-c88e9e93c0be",
                        "dbdcd8a5-e3c2-44ec-8192-8322ca8569d4",
                        "dc27f317-43ac-4d17-a1ba-253a0432ce70",
                        "e50ac8be-f254-4c06-9c1c-0fba316ef3d1",
                        "f4e766ac-f68f-4829-a5f8-bc8751f57948",
                        "fc443443-416f-4fd5-ba46-17a06046711d"
                    ],
                    "keyword": [
                        "texture",
                        "classification",
                        "modeled",
                        "signals",
                        "matched",
                        "features",
                        "band"
                    ],
                    "group": [],
                    "_id": "76d48657-1eba-43d5-a642-f6f553331633",
                    "abstract": "This paper proposes a new texture classification algorithm that is invariant to rotation and gray-scale transformation. First, we convert two-dimensional (2-D) texture images to one-dimensional (1-D) signals by spiral resampling. Then, we use a quadrature mirror filter (QMF) bank to decompose sampled signals into subbands. In each band, we take high-order autocorrelation functions as features. Features in different bands, which form a vector sequence, are then modeled as a hidden Markov model (BMM). During classification, the unknown texture is matched against all the models and the best match is taken as the classification result. Simulations showed that the highest correct classification rate for 16 kinds of texture was 95.14%.",
                    "title": "Correction to \"Rotation And Gray-scale Transform-invariant Texture Classification Using Spiral Resampling, Subband Decomposition, And Hidden Markov Model\"",
                    "venue": "IEEE Transactions on Image Processing",
                    "year": 1996,
                    "__v": 2,
                    "citationCount": 59,
                    "result": 6.091864251189542
                },
                "79aaae90-c329-4f9f-86fb-31ae2ea58ae8": {
                    "authors": [
                        "Timo Ojala",
                        "Kimmo Valkealahti",
                        "Erkki Oja",
                        "Matti Pietikäinen"
                    ],
                    "references": [
                        "09346dc3-f4d0-43a4-8f0b-27e02bcd336e",
                        "48c4df8b-249a-4ca2-bf93-4df44200b7a6",
                        "536bae3c-3a30-4855-ac10-411930bd11ad",
                        "62a46780-e1d9-4186-babe-6179735d785e",
                        "8831d80b-0ec8-4d25-a609-7746251a0f54",
                        "9205abb2-a53a-4d16-b3d5-ebb3c6a6640b",
                        "9270a9b5-940a-4394-814f-433c6440f286",
                        "a6c602d7-fdfd-4d60-8e39-ebfbce63adc7",
                        "d3a2754c-cedf-44d2-93af-ca0c62d37606",
                        "fadad052-0cfd-4267-b4e0-5b9ae7c0916e"
                    ],
                    "keyword": [
                        "texture",
                        "graylevel",
                        "erences",
                        "di",
                        "approach",
                        "matrices",
                        "cooccurrence"
                    ],
                    "group": [],
                    "_id": "79aaae90-c329-4f9f-86fb-31ae2ea58ae8",
                    "abstract": "The statistics of gray-level di!erences have been successfully used in a number of texture analysis studies. In this paper we propose to use signed gray-level di!erences and their multidimensional distributions for texture description. The present approach has important advantages compared to earlier related approaches based on gray level cooccurrence matrices or histograms of absolute gray-level di!erences. Experiments with di$cult texture classi\"cation and supervised texture segmentation problems show that our approach provides a very good and robust performance in comparison with the mainstream paradigms such as cooccurrence matrices, Gaussian Markov random \"elds, or Gabor \"ltering. ( 2001 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.",
                    "title": "Texture discrimination with multidimensional distributions of signed gray-level differences",
                    "venue": "Pattern Recognition",
                    "year": 2001,
                    "__v": 2,
                    "citationCount": 90,
                    "result": 5.1479041130156755
                },
                "813a6153-f889-4801-ac2a-233be07e5df7": {
                    "authors": [
                        "Raghava Kondepudy",
                        "Glenn Healey"
                    ],
                    "references": [],
                    "keyword": [
                        "color",
                        "recognition",
                        "invariants",
                        "functions",
                        "dimensional",
                        "correlation",
                        "texture",
                        "image",
                        "transformations",
                        "surface"
                    ],
                    "group": [],
                    "_id": "813a6153-f889-4801-ac2a-233be07e5df7",
                    "abstract": "We introduce an image model for color texture based on spatial correlation functions defined both within and between color bands. We show that three dimensional geometric transformations of a surface in the scene produce corresponding transformations in these correlation functions. From this analysis, we derive invariants of color correlation functions that can be computed efficiently and used for geometry invariant recognition. We show experimentally that these invariants are effective for recognition in situations where neither color distributions nor gray scale texture are sufficient. Following recognition, the estimated color correlation functions can be used to recover the three dimensional location and orientation of surfaces. The color texture invariants can be used in the recognition of three dimensional objects, the segmentation of images of three dimensional scenes, and the searching of image databases. >",
                    "title": "Using moment invariants to analyze 3-D color textures",
                    "venue": "international conference on image processing",
                    "year": 1994,
                    "__v": 2,
                    "citationCount": 3,
                    "result": 8.36787395610925
                },
                "8573e55d-619d-425c-bbdf-4a0dbfe8f862": {
                    "authors": [
                        "Olivier Alata",
                        "Claude Cariou",
                        "Clarisse Ramananjarasoa",
                        "Mohamed Najim"
                    ],
                    "references": [
                        "61669bbc-06bd-4a50-a8ff-33fc60605d3b",
                        "79baa7b9-871a-4ce6-9977-ed9e537c935c",
                        "90d84122-cb64-4232-96c3-fdcc8187f151",
                        "a0affaec-fe08-468b-bf53-21d7b05c7cbb",
                        "b2b35b2e-b052-4370-ae2b-9f172855d48b",
                        "dcce8f96-338e-4d8d-8a18-9eecfa463b90",
                        "ebc930af-8ca8-4fa0-b215-52e0ce22a514"
                    ],
                    "keyword": [
                        "method",
                        "texture",
                        "hmhv",
                        "spectrum",
                        "set",
                        "parametric",
                        "image",
                        "hm",
                        "harmonic",
                        "estimation"
                    ],
                    "group": [],
                    "_id": "8573e55d-619d-425c-bbdf-4a0dbfe8f862",
                    "abstract": "In the framework of image modeling for texture analysis, we propose the combination of the new parametric 2-D spectrum estimation method called HMHV (harmonic mean horizontal vertical) and the Fourier-Mellin transform. This latter technique allows the calculation of a set of texture descriptors from a 2-D spectrum estimate which is invariant under rotation and scaling. A comparison of the HMHV and the \"standard\" parametric HM (harmonic mean) methods on synthetic and natural stochastic textures shows that the HMHV method presents almost no spurious peaks and is quite isotropic. By performing the classification of a set of 60 images divided in 12 texture classes, descriptors computed with the HMHV method provide better results than those computed with the HM method.",
                    "title": "Classification of rotated and scaled textures using HMHV spectrum estimation and the Fourier-Mellin transform",
                    "venue": "international conference on image processing",
                    "year": 1998,
                    "__v": 2,
                    "citationCount": 8,
                    "result": 4.044119442648855
                },
                "9270a9b5-940a-4394-814f-433c6440f286": {
                    "authors": [
                        "Timo Ojala",
                        "Matti Pietikäinen",
                        "David Harwood"
                    ],
                    "references": [
                        "48c4df8b-249a-4ca2-bf93-4df44200b7a6",
                        "66ef956f-ea06-4527-8cb1-a71a9e00f9b5",
                        "689ead95-6fb0-43d0-8c49-e255a20ae09d",
                        "8831d80b-0ec8-4d25-a609-7746251a0f54",
                        "9205abb2-a53a-4d16-b3d5-ebb3c6a6640b",
                        "b43507d2-72e1-4f55-ac87-72dd87e321ad",
                        "d2930486-5812-4750-b650-dfd17d917226"
                    ],
                    "keyword": [
                        "texture",
                        "successfully",
                        "sample",
                        "prototype",
                        "proposed",
                        "promising",
                        "performance",
                        "paper",
                        "method",
                        "measures"
                    ],
                    "group": [],
                    "_id": "9270a9b5-940a-4394-814f-433c6440f286",
                    "abstract": "This paper evaluates the performance both of some texture measures which have been successfully used in various applications and of some new promising approaches proposed recently. For classification a method based on Kullback discrimination of sample and prototype distributions is used. The classification results for single features with one-dimensional feature value distributions and for pairs of complementary features with two-dimensional distributions are presented",
                    "title": "A comparative study of texture measures with classification based on featured distributions",
                    "venue": "Pattern Recognition",
                    "year": 1996,
                    "__v": 1,
                    "citationCount": 1718,
                    "result": 5.633636298342182
                },
                "a8d582af-d7f0-4a20-aba5-5b49f43e990a": {
                    "authors": [
                        "Vidya Manian",
                        "Ramon E. Vasquez"
                    ],
                    "references": [],
                    "keyword": [
                        "basis",
                        "textured",
                        "scaled",
                        "rotated",
                        "orthonormal",
                        "orthogonal",
                        "haar",
                        "functions",
                        "daubechies"
                    ],
                    "group": [],
                    "_id": "a8d582af-d7f0-4a20-aba5-5b49f43e990a",
                    "abstract": "Abstract   Three classes of basis functions are considered for classifying scaled and rotated textured images. The first is the orthonormal, compactly supported Daubechies and the discrete Haar bases, the second is the biorthogonal basis and the third is the non orthogonal Gabor basis. Textures are scaled and rotated and the basis functions are used to expand them. Features are computed on a combination of inter-resolution coefficients. Experimental results show that the Daubechies orthonormal basis perform well in recognizing transformed textures, followed by the Haar basis. The concept of multiresolution representation and orthogonality are shown to be useful for invariant texture classificaiton.",
                    "title": "Scaled and rotated texture classification using a class of basis functions",
                    "venue": "Pattern Recognition",
                    "year": 1998,
                    "__v": 1,
                    "citationCount": 19,
                    "result": 6.282164730694144
                },
                "b1fbed62-1a39-48d6-8eb5-ea103ad6423e": {
                    "authors": [
                        "Terence Wang",
                        "Chin-Liang Wang"
                    ],
                    "references": [
                        "4f2fba01-40e4-4c51-8e01-c80230d002a6",
                        "7255724d-e135-426e-832a-bdd8f213ccf6",
                        "83701c14-7417-4831-9ba5-fd369d0afb14",
                        "b2a1686f-c3d6-4b70-85b8-73df44208e2a",
                        "f2b13ff5-001c-437b-91da-2f3fc2b944c2"
                    ],
                    "keyword": [
                        "algorithm",
                        "tdobsg",
                        "block",
                        "2d",
                        "tdoba",
                        "squares",
                        "optimum",
                        "filtering",
                        "factor",
                        "convergence"
                    ],
                    "group": [],
                    "_id": "b1fbed62-1a39-48d6-8eb5-ea103ad6423e",
                    "abstract": "This paper presents a new two-dimensional (2-D) optimum block stochastic gradient (TDOBSG) algorithm for 2-D adaptive finite impulse response (FIR) filtering. The TDOBSG algorithm employs a space-varying convergence factor for all the filter coefficients, where the convergence factor at each block iteration is optimized in a least squares sense that the squared norm of the a posteriori estimation error vector is minimized. It has the same order of computational complexity as another 2-D optimum block adaptive (TDOBA) algorithm. Computer simulations for image restoration show that the TDOBSG algorithm outperforms the TDOBA algorithm and other related algorithms in terms of objective and/or subjective measures.",
                    "title": "A new two-dimensional block adaptive FIR filtering algorithm and its application to image restoration",
                    "venue": "IEEE Transactions on Image Processing",
                    "year": 1998,
                    "__v": 2,
                    "citationCount": 18,
                    "result": 4.34313790784379
                },
                "b9d5d8e9-ea08-4a60-a1fe-2164382647b8": {
                    "authors": [
                        "Lizhi Wang",
                        "Glenn Healey"
                    ],
                    "references": [
                        "087735a7-1cb9-4911-a88b-158cf3ebde87",
                        "17a9bbe1-b8ce-43ef-9ab3-3b75c19139aa",
                        "33c61d43-6e1c-4e26-a723-c43ce64c1fbe",
                        "3c4e8d07-47e2-4942-8197-59b613634ce4",
                        "4c0ae3e7-45b4-441e-81b2-7b325af64e32",
                        "4d92607c-d2ca-48fa-9a55-8e7eff5a71d3",
                        "606f8ecd-75f5-40fa-a70d-d6665cd2990e",
                        "6f5a2d04-9370-4123-97a8-a5cdfef7a632",
                        "9cef868f-eb6d-4189-acd1-43eac87cf81e",
                        "c083f584-daa0-4058-9a89-6b03409acfef",
                        "d9b9f667-9d8a-4723-a6c4-c19b941acd46"
                    ],
                    "keyword": [
                        "illumination",
                        "correlation",
                        "color",
                        "transformation",
                        "texture",
                        "scale",
                        "linear",
                        "functions",
                        "algorithm",
                        "sensor"
                    ],
                    "group": [],
                    "_id": "b9d5d8e9-ea08-4a60-a1fe-2164382647b8",
                    "abstract": "We develop a method for recognizing color texture independent of rotation, scale, and illumination. Color texture is modeled using spatial correlation functions defined within and between sensor bands. Using a linear model for surface spectral reflectance with the same number of parameters as the number of sensor classes, we show that illumination and geometry changes in the scene correspond to a linear transformation of the correlation functions and a linear transformation of their coordinates. A several step algorithm that includes scale estimation and correlation moment computation is used to achieve the invariance. The key to the method is the new result that illumination, rotation, and scale changes in the scene correspond to a specific transformation of correlation function Zernike moment matrices. These matrices can be estimated from a color image. This relationship is used to derive an efficient algorithm for recognition. The algorithm is substantiated using classification results on over 200 images of color textures obtained under various illumination conditions and geometric configurations.",
                    "title": "Using Zernike moments for the illumination and geometry invariant classification of multispectral texture",
                    "venue": "IEEE Transactions on Image Processing",
                    "year": 1998,
                    "__v": 2,
                    "citationCount": 58,
                    "result": 11.030084235539555
                },
                "ba03a3a9-4acc-4fdb-a95f-75c76861b620": {
                    "authors": [
                        "Didier Coquin",
                        "Philippe Bolon",
                        "A. Onea"
                    ],
                    "references": [
                        "cd84aa5d-a982-4c0a-9b56-6c618a57264e",
                        "d1123c98-b7b6-4288-b055-756505058cbc",
                        "e3fca471-d952-49b6-a91a-e2578cdcc744",
                        "f41d8df9-41b4-427f-999c-4fdfe15641a0"
                    ],
                    "keyword": [
                        "operator",
                        "local",
                        "distance",
                        "sampled",
                        "nonstationary",
                        "adapted",
                        "version",
                        "measurement",
                        "images",
                        "grids"
                    ],
                    "group": [],
                    "_id": "ba03a3a9-4acc-4fdb-a95f-75c76861b620",
                    "abstract": "In this paper, a 3D nonstationary local distance operator is introduced. This kind of operator is adapted to the measurement of distances between objects sampled on nonuniform grids. This operator can be regarded as a nonstationary version of local distance operators adapted to parallelepipedic (noncubic) grids. The principle of coefficient computation and spatial adaptation are given. An application to dissimilarity measurement between color images is presented. We compare the nonstationary local distance operator with two stationary versions: 1) images are sampled with the lowest sampling step; and 2) the local operator is designed according to the average voxel size.",
                    "title": "3D nonstationary local distance operator",
                    "venue": "international conference on pattern recognition",
                    "year": 2000,
                    "__v": 2,
                    "citationCount": 2,
                    "result": 6.913128031239487
                },
                "d6e78be6-6ad4-4ea2-8076-911d015644e3": {
                    "authors": [
                        "Timo Ojala",
                        "Topi Mäenpää",
                        "Matti Pietikäinen",
                        "Jaakko Viertola",
                        "Juha Kyllönen",
                        "Sami Huovinen"
                    ],
                    "references": [
                        "09346dc3-f4d0-43a4-8f0b-27e02bcd336e",
                        "3a770bd2-20c6-45e1-b98e-46d6f31f1966",
                        "5854f8af-3e16-4956-b14f-6e015a5d3a18",
                        "5881c5b2-527b-48e5-a4d4-eaeeab3ca9cb",
                        "62a46780-e1d9-4186-babe-6179735d785e",
                        "71fbd945-fa91-4751-b212-a13e0940de3c",
                        "73499fd2-0b7f-453e-9797-22b092b85899",
                        "79aaae90-c329-4f9f-86fb-31ae2ea58ae8",
                        "800fb2d1-7075-47d1-8a9e-6c40867f6601",
                        "9270a9b5-940a-4394-814f-433c6440f286",
                        "982667e6-ac94-4b92-9326-41c6f2570e09",
                        "a6c602d7-fdfd-4d60-8e39-ebfbce63adc7",
                        "b43507d2-72e1-4f55-ac87-72dd87e321ad",
                        "bd6cbbaa-f2f2-49c1-b672-ecc9a1c626f9",
                        "e2204e92-e6dc-4884-9bbc-200029491fc7",
                        "fdb43c84-e9de-4ded-99dc-3c1917892d05"
                    ],
                    "keyword": [
                        "texture",
                        "framework",
                        "wide",
                        "results",
                        "problems",
                        "obtained",
                        "database",
                        "analysis",
                        "algorithms"
                    ],
                    "group": [],
                    "_id": "d6e78be6-6ad4-4ea2-8076-911d015644e3",
                    "abstract": "This paper presents the current status of a new initiative aimed at developing a versatile framework and image database for empirical evaluation of texture analysis algorithms. The proposed Outex framework contains a large collection of surface textures captured under different conditions, which facilitates construction of a wide range of texture analysis problems. The problems are encapsulated into test suites, for which baseline results obtained with algorithms from literature are provided. The rich functionality of the framework is demonstrated with examples in texture classification, segmentation and retrieval. The framework has a web site for public dissemination of the database and comparative results obtained by research groups world wide.",
                    "title": "Outex - new framework for empirical evaluation of texture analysis algorithms",
                    "venue": "international conference on pattern recognition",
                    "year": 2002,
                    "__v": 2,
                    "citationCount": 252,
                    "result": 6.821880519750704
                },
                "d70539c8-d4d5-4d3d-8333-6e6b210ff641": {
                    "authors": [
                        "Yue Wu",
                        "Yasuo Yoshida"
                    ],
                    "references": [
                        "3c4e8d07-47e2-4942-8197-59b613634ce4",
                        "606f8ecd-75f5-40fa-a70d-d6665cd2990e",
                        "87696fdc-3a34-4f55-a6b1-eac563a43d10",
                        "b2b35b2e-b052-4370-ae2b-9f172855d48b"
                    ],
                    "keyword": [
                        "texture",
                        "function",
                        "scaling",
                        "rotation",
                        "parameters",
                        "2d",
                        "representing",
                        "invariant",
                        "image",
                        "fields"
                    ],
                    "group": [],
                    "_id": "d70539c8-d4d5-4d3d-8333-6e6b210ff641",
                    "abstract": "This paper presents a new approach for texture classification using rotation and scaling invariant parameters. A test textured image can be correctly classified even if it is rotated and scaled. Based on a 2-D Wold-like decomposition of homogeneous random fields, the texture field can be decomposed into a deterministic component and an indeterministic component. The spectral density function (SDF) of the former is a sum of 1-D or 2-D delta functions. The 2-D autocorrelation function (ACF) of the latter is fitted to the assumed anisotropic ACF that has an elliptical contour. Invariant parameters applicable to the classification of rotated and scaled textured images can be estimated by combining the parameters representing the ellipse and those representing the delta functions. The effectiveness of this method is illustrated through experimental results on natural textures.",
                    "title": "An efficient method for rotation and scaling invariant texture classification",
                    "venue": "international conference on acoustics, speech, and signal processing",
                    "year": 1995,
                    "__v": 2,
                    "citationCount": 9,
                    "result": 8.82718748873868
                }
            }
        ],
        "_id": "e2204e92-e6dc-4884-9bbc-200029491fc7",
        "abstract": "Presents a theoretically very simple, yet efficient, multiresolution approach to gray-scale and rotation invariant texture classification based on local binary patterns and nonparametric discrimination of sample and prototype distributions. The method is based on recognizing that certain local binary patterns, termed \"uniform,\" are fundamental properties of local image texture and their occurrence histogram is proven to be a very powerful texture feature. We derive a generalized gray-scale and rotation invariant operator presentation that allows for detecting the \"uniform\" patterns for any quantization of the angular space and for any spatial resolution and presents a method for combining multiple operators for multiresolution analysis. The proposed approach is very robust in terms of gray-scale variations since the operator is, by definition, invariant against any monotonic transformation of the gray scale. Another advantage is computational simplicity as the operator can be realized with a few operations in a small neighborhood and a lookup table. Experimental results demonstrate that good discrimination can be achieved with the occurrence statistics of simple rotation invariant local binary patterns.",
        "title": "Multiresolution gray-scale and rotation invariant texture classification with local binary patterns",
        "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
        "year": 2002,
        "__v": 3,
        "citationCount": 3941
    },
    {
        "authors": [
            "Alex Krizhevsky",
            "Ilya Sutskever",
            "Geoffrey E. Hinton"
        ],
        "references": [
            "2b6a3d0f-368f-45bb-be23-4e82f62fbbf7",
            "2caf053c-09a4-4536-b303-6d4c834e429a",
            "2d94566b-ac2d-49b0-a867-2392c41a2172",
            "32a53bab-1ede-4869-98ad-d2ff0c1e3367",
            "4bbacb77-1097-4cc5-b001-6554ea01fb75",
            "657e0ce9-3a0c-4cc3-ac69-0f60aaf955f1",
            "73ec9d29-4fc5-4019-97d3-c496c8509f37",
            "820b9eee-e009-4dc1-b464-f5fd4485d6b3",
            "a21b42c9-dff1-4cf2-becd-0bc9f922ea72",
            "adea0a98-d74d-43be-a238-a1ef027c6a58",
            "bd62aacb-5037-43d3-926a-af4d38ec3bfc",
            "c700dc12-7eac-4091-8462-527773668dfa",
            "c9482f1f-6600-44a7-a69a-e63ef13cdff8",
            "ca250ca4-70fd-411f-8cc7-fb17be31cd9e",
            "f6bd8b64-684d-429a-aab5-8ff3a2c23cd6",
            "f7ac19b7-daaf-4dc1-bbb9-7f4ffd7385ba"
        ],
        "keyword": [
            "layers",
            "convolutional",
            "achieved",
            "trained",
            "top5",
            "test",
            "rates",
            "neurons",
            "neural",
            "network"
        ],
        "group": [
            {
                "4bbacb77-1097-4cc5-b001-6554ea01fb75": {
                    "authors": [
                        "Kevin Jarrett",
                        "Koray Kavukcuoglu",
                        "Marc’Aurelio Ranzato",
                        "Yann LeCun"
                    ],
                    "references": [
                        "04c47f14-8533-41ff-bafd-affc1eb52287",
                        "20f52431-62f1-4670-ba81-d19ef3c04204",
                        "2d700d61-baaf-401f-a9bf-00c62059c03e",
                        "32c1bdf2-cea7-4d60-8289-2207eaa41a77",
                        "3843d2db-d96f-47be-8ece-fa9c1e87d1bc",
                        "3871db29-4ce5-4ab0-a1fa-4bb93d04e88d",
                        "3c1f9893-1a32-4afb-9f40-5d4856b7f886",
                        "5ad47e8e-b112-480d-b8f3-3786fc2c0a5a",
                        "6996760a-97de-4ea0-9b33-dda325b252af",
                        "73ec9d29-4fc5-4019-97d3-c496c8509f37",
                        "7af6585a-b797-47ad-84f3-a8fec553f67a",
                        "7db5b031-03e2-4051-9049-e0cc7b0a4f11",
                        "820b9eee-e009-4dc1-b464-f5fd4485d6b3",
                        "924fe569-7b4c-4968-bcc9-35aa73dbb587",
                        "9517e823-1ee3-43f6-bd63-33d7b9a3caaf",
                        "ae4a15da-5aec-4876-bec6-7c8ce40761b1",
                        "b944f77f-113b-4a02-ae5e-d4a124b8fd5b",
                        "c9482f1f-6600-44a7-a69a-e63ef13cdff8",
                        "dd83785a-dd19-41e3-9b25-ebabbd48d336",
                        "de7e534b-6d80-46c7-bf2a-2b2b4112a42b",
                        "e0ac4812-7729-4a2d-8a1f-74b1b7c8eb5d",
                        "e752ace3-2161-4948-8443-d504de19c859",
                        "ea64f6ce-6ad4-4e2d-ad18-24c25ff99870",
                        "fd4c2dc1-317b-41f0-8469-2896b2768fbb",
                        "ff948282-ac63-40ea-821b-e32f748e1e3f"
                    ],
                    "keyword": [
                        "filter",
                        "stages",
                        "feature",
                        "systems",
                        "supervised",
                        "show",
                        "recognition",
                        "nonlinear",
                        "extraction",
                        "accuracy"
                    ],
                    "group": [],
                    "_id": "4bbacb77-1097-4cc5-b001-6554ea01fb75",
                    "abstract": "In many recent object recognition systems, feature extraction stages are generally composed of a filter bank, a non-linear transformation, and some sort of feature pooling layer. Most systems use only one stage of feature extraction in which the filters are hard-wired, or two stages where the filters in one or both stages are learned in supervised or unsupervised mode. This paper addresses three questions: 1. How does the non-linearities that follow the filter banks influence the recognition accuracy? 2. does learning the filter banks in an unsupervised or supervised manner improve the performance over random filters or hardwired filters? 3. Is there any advantage to using an architecture with two stages of feature extraction, rather than one? We show that using non-linearities that include rectification and local contrast normalization is the single most important ingredient for good accuracy on object recognition benchmarks. We show that two stages of feature extraction yield better accuracy than one. Most surprisingly, we show that a two-stage system with random filters can yield almost 63% recognition rate on Caltech-101, provided that the proper non-linearities and pooling layers are used. Finally, we show that with supervised refinement, the system achieves state-of-the-art performance on NORB dataset (5.6%) and unsupervised pre-training followed by supervised refinement produces good accuracy on Caltech-101 (≫ 65%), and the lowest known error rate on the undistorted, unprocessed MNIST dataset (0.53%).",
                    "title": "What is the best multi-stage architecture for object recognition?",
                    "venue": "international conference on computer vision",
                    "year": 2009,
                    "__v": 1,
                    "citationCount": 519,
                    "result": 8.393450993450996
                },
                "657e0ce9-3a0c-4cc3-ac69-0f60aaf955f1": {
                    "authors": [
                        "Yann LeCun",
                        "Koray Kavukcuoglu",
                        "Clement Farabet"
                    ],
                    "references": [
                        "09a3449b-e2c5-4b28-b26a-c4135f8309da",
                        "20f52431-62f1-4670-ba81-d19ef3c04204",
                        "2ba41db5-ac76-4805-a904-67ff0361f528",
                        "2d700d61-baaf-401f-a9bf-00c62059c03e",
                        "32c1bdf2-cea7-4d60-8289-2207eaa41a77",
                        "3400b9a0-70f1-4545-a5db-1c470dcd45e8",
                        "3843d2db-d96f-47be-8ece-fa9c1e87d1bc",
                        "3ec579e5-7f6c-43d0-a998-3dbacce74e0d",
                        "42354418-fffa-4f5c-99f5-edca6ae3b569",
                        "4bbacb77-1097-4cc5-b001-6554ea01fb75",
                        "526860a6-aea8-4f8d-b7f9-e01d3629a6a9",
                        "5b08cd47-f0e2-45d4-99a5-ac11c0b20228",
                        "6996760a-97de-4ea0-9b33-dda325b252af",
                        "6ce6c9e4-877f-4270-ac6d-afec0c522701",
                        "72c6c663-330b-400f-94f1-1abd68991fc2",
                        "73ec9d29-4fc5-4019-97d3-c496c8509f37",
                        "75883e63-4f9a-41c8-941f-5fbbc8943867",
                        "79f292f6-701c-4879-a960-a5082a77b348",
                        "7af6585a-b797-47ad-84f3-a8fec553f67a",
                        "7da18809-6301-4eca-8e71-f73b422fb739",
                        "91167093-f0bb-40a1-82c2-c0aec55fbb56",
                        "9517e823-1ee3-43f6-bd63-33d7b9a3caaf",
                        "adbdeaac-329c-4790-b1e0-2a9ea0a4c698",
                        "ae3e7593-586f-495f-9416-4b50ed1fcd10",
                        "b944f77f-113b-4a02-ae5e-d4a124b8fd5b",
                        "c4dc7b46-01d3-44f5-91ca-0cc063d38c8c",
                        "ca250ca4-70fd-411f-8cc7-fb17be31cd9e",
                        "d2de642b-7044-4d04-85ea-1e05eea964c6",
                        "dd83785a-dd19-41e3-9b25-ebabbd48d336",
                        "e0ac4812-7729-4a2d-8a1f-74b1b7c8eb5d",
                        "fb1e85b8-5ae8-4074-88cf-4e9270d625ff",
                        "fd4c2dc1-317b-41f0-8469-2896b2768fbb"
                    ],
                    "keyword": [
                        "learning",
                        "features",
                        "convnets",
                        "stage",
                        "visual",
                        "training",
                        "samples",
                        "require",
                        "perception",
                        "nonlinearities"
                    ],
                    "group": [],
                    "_id": "657e0ce9-3a0c-4cc3-ac69-0f60aaf955f1",
                    "abstract": "Intelligent tasks, such as visual perception, auditory perception, and language understanding require the construction of good internal representations of the world (or \"features\")? which must be invariant to irrelevant variations of the input while, preserving relevant information. A major question for Machine Learning is how to learn such good features automatically. Convolutional Networks (ConvNets) are a biologically-inspired trainable architecture that can learn invariant features. Each stage in a ConvNets is composed of a filter bank, some nonlinearities, and feature pooling layers. With multiple stages, a ConvNet can learn multi-level hierarchies of features. While ConvNets have been successfully deployed in many commercial applications from OCR to video surveillance, they require large amounts of labeled training samples. We describe new unsupervised learning algorithms, and new non-linear stages that allow ConvNets to be trained with very few labeled samples. Applications to visual object recognition and vision navigation for off-road mobile robots are described.",
                    "title": "Convolutional networks and applications in vision",
                    "venue": "international symposium on circuits and systems",
                    "year": 2010,
                    "__v": 1,
                    "citationCount": 216,
                    "result": 7.8561139995195735
                },
                "73ec9d29-4fc5-4019-97d3-c496c8509f37": {
                    "authors": [
                        "Honglak Lee",
                        "Roger B. Grosse",
                        "Rajesh Ranganath",
                        "Andrew Y. Ng"
                    ],
                    "references": [
                        "15c931f1-4acc-46c4-b691-af3c50b8f60b",
                        "20f52431-62f1-4670-ba81-d19ef3c04204",
                        "32c1bdf2-cea7-4d60-8289-2207eaa41a77",
                        "4453fa3b-308f-472a-be61-65d1ce5c3de2",
                        "52e6ed42-458b-4514-8ace-0bc8f504fc4e",
                        "5ad47e8e-b112-480d-b8f3-3786fc2c0a5a",
                        "5b35e6b8-3077-4ca4-aa34-5e211cace1b9",
                        "89f10062-acf1-4171-b882-f3222c3a357e",
                        "924fe569-7b4c-4968-bcc9-35aa73dbb587",
                        "ae3e7593-586f-495f-9416-4b50ed1fcd10",
                        "ae4a15da-5aec-4876-bec6-7c8ce40761b1",
                        "c9482f1f-6600-44a7-a69a-e63ef13cdff8",
                        "d0d13c7a-308c-4138-9802-8e7c0260bb90",
                        "e0ac4812-7729-4a2d-8a1f-74b1b7c8eb5d",
                        "ea64f6ce-6ad4-4e2d-ad18-24c25ff99870",
                        "ff948282-ac63-40ea-821b-e32f748e1e3f"
                    ],
                    "keyword": [
                        "models",
                        "images",
                        "probabilistic",
                        "hierarchical",
                        "visual",
                        "topdown",
                        "show",
                        "scaling",
                        "problem",
                        "performance"
                    ],
                    "group": [],
                    "_id": "73ec9d29-4fc5-4019-97d3-c496c8509f37",
                    "abstract": "There has been much interest in unsupervised learning of hierarchical generative models such as deep belief networks. Scaling such models to full-sized, high-dimensional images remains a difficult problem. To address this problem, we present the  convolutional deep belief network , a hierarchical generative model which scales to realistic image sizes. This model is translation-invariant and supports efficient bottom-up and top-down probabilistic inference. Key to our approach is  probabilistic max-pooling , a novel technique which shrinks the representations of higher layers in a probabilistically sound way. Our experiments show that the algorithm learns useful high-level visual features, such as object parts, from unlabeled images of objects and natural scenes. We demonstrate excellent performance on several visual recognition tasks and show that our model can perform hierarchical (bottom-up and top-down) inference over full-sized images.",
                    "title": "Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations",
                    "venue": "international conference on machine learning",
                    "year": 2009,
                    "__v": 2,
                    "citationCount": 698,
                    "result": 4.117957710093259
                },
                "820b9eee-e009-4dc1-b464-f5fd4485d6b3": {
                    "authors": [
                        "Yann LeCun",
                        "Fu Jie Huang",
                        "Léon Bottou"
                    ],
                    "references": [
                        "37031566-2033-44cb-a87e-91a9bb37996f",
                        "532dec4c-28bf-4ca8-aa3b-fc5b5b20bb2d",
                        "5ebbd1f5-dfe5-4eec-9883-b8b5efea366c",
                        "5f1992df-975f-49e7-bd88-aee0740317cf",
                        "5ffac6f9-2456-42cf-830c-9049ce37c899",
                        "8fc9506c-3603-4af2-b0c8-02b368863fcb",
                        "937cc256-e6e2-4bfa-928b-52f01cd416f4",
                        "98cfeac3-9abb-4f5b-9705-158c3b7b9d3a",
                        "ac938f78-f927-4d0b-ad55-466879fa129f",
                        "ae4917d5-94ec-40c1-973c-b91dc77fac5b",
                        "bb4963db-e1bf-43d9-91bd-62e9600938a4",
                        "c7f93552-c1ef-4ae4-b1f5-2317e1c9d904",
                        "d42f853d-12d7-416d-8b27-c314ef563eed",
                        "d6e37fb1-5f7e-448e-847b-7d1f1271c574",
                        "d7b1fba1-b5f8-4377-88a8-d2fc69f723b7",
                        "e649a9fd-f6d9-4aac-b428-29b82c20a484",
                        "f111ff97-89a3-4df6-8f02-962d7b4fe985",
                        "fd19cb48-3fd2-41ca-b044-67cb47218704"
                    ],
                    "keyword": [
                        "testing",
                        "objects",
                        "image",
                        "instances",
                        "convolutional",
                        "clutter",
                        "categories"
                    ],
                    "group": [],
                    "_id": "820b9eee-e009-4dc1-b464-f5fd4485d6b3",
                    "abstract": "We assess the applicability of several popular learning methods for the problem of recognizing generic visual categories with invariance to pose, lighting, and surrounding clutter. A large dataset comprising stereo image pairs of 50 uniform-colored toys under 36 azimuths, 9 elevations, and 6 lighting conditions was collected (for a total of 194,400 individual images). The objects were 10 instances of 5 generic categories: four-legged animals, human figures, airplanes, trucks, and cars. Five instances of each category were used for training, and the other five for testing. Low-resolution grayscale images of the objects with various amounts of variability and surrounding clutter were used for training and testing. Nearest neighbor methods, support vector machines, and convolutional networks, operating on raw pixels or on PCA-derived features were tested. Test error rates for unseen object instances placed on uniform backgrounds were around 13% for SVM and 7% for convolutional nets. On a segmentation/recognition task with highly cluttered images, SVM proved impractical, while convolutional nets yielded 16/7% error. A real-time version of the system was implemented that can detect and classify objects in natural scenes at around 10 frames per second.",
                    "title": "Learning methods for generic object recognition with invariance to pose and lighting",
                    "venue": "computer vision and pattern recognition",
                    "year": 2004,
                    "__v": 2,
                    "citationCount": 353,
                    "result": 5.268687684864156
                },
                "a21b42c9-dff1-4cf2-becd-0bc9f922ea72": {
                    "authors": [
                        "Nicolas Pinto",
                        "David Doukhan",
                        "James J. DiCarlo",
                        "David D. Cox"
                    ],
                    "references": [
                        "02ab1c1c-0b15-46eb-8a0d-300fb4164c24",
                        "29f2ddf1-90cb-4f20-a772-74eb7adcf417",
                        "3895c5fb-93ed-4dbd-93de-e8f9bff2840c",
                        "3faa5389-a69b-4470-b99b-1e3faec79b10",
                        "485e8957-eedd-4ef9-b68d-366aed343348",
                        "4fa6167f-3737-4793-a013-d1218ae53fa2",
                        "7af6585a-b797-47ad-84f3-a8fec553f67a",
                        "820b9eee-e009-4dc1-b464-f5fd4485d6b3",
                        "a4d9008a-d15b-4d87-a173-bef2f4b0d453",
                        "b8d1ab41-c327-42b3-9424-cc1dc694e8c5",
                        "b944f77f-113b-4a02-ae5e-d4a124b8fd5b",
                        "c29d0023-c23f-44d4-a733-a3d26dd3342c",
                        "c5360ce9-89ea-494f-b58e-59c76568823b",
                        "c7f1acbc-1e00-4ba5-bab6-e8464b3b4336",
                        "c9482f1f-6600-44a7-a69a-e63ef13cdff8",
                        "dab2a721-01df-4ca9-aaf7-c4f1f6192ec1",
                        "e0ac4812-7729-4a2d-8a1f-74b1b7c8eb5d",
                        "e7005d3a-7bbb-46f1-a84b-50d110ddee6e",
                        "e8fe573a-2572-49f3-b7d3-ea167b6ffa9d",
                        "f08b9763-4892-4718-9760-032ff7b041b7",
                        "f64c3789-7636-41a7-9b96-6e1978e2b1d4"
                    ],
                    "keyword": [
                        "parameters",
                        "models",
                        "approach",
                        "biological",
                        "vision",
                        "set",
                        "recognition",
                        "performance",
                        "object",
                        "instantiation"
                    ],
                    "group": [],
                    "_id": "a21b42c9-dff1-4cf2-becd-0bc9f922ea72",
                    "abstract": "While many models of biological object recognition share a common set of ‘‘broad-stroke’’ properties, the performance of any one model depends strongly on the choice of parameters in a particular instantiation of that model—e.g., the number of units per layer, the size of pooling kernels, exponents in normalization operations, etc. Since the number of such parameters (explicit or implicit) is typically large and the computational cost of evaluating one particular parameter set is high, the space of possible model instantiations goes largely unexplored. Thus, when a model fails to approach the abilities of biological visual systems, we are left uncertain whether this failure is because we are missing a fundamental idea or because the correct ‘‘parts’’ have not been tuned correctly, assembled at sufficient scale, or provided with enough training. Here, we present a high-throughput approach to the exploration of such parameter sets, leveraging recent advances in stream processing hardware (high-end NVIDIA graphic cards and the PlayStation 3’s IBM Cell Processor). In analogy to highthroughput screening approaches in molecular biology and genetics, we explored thousands of potential network architectures and parameter instantiations, screening those that show promising object recognition performance for further analysis. We show that this approach can yield significant, reproducible gains in performance across an array of basic object recognition tasks, consistently outperforming a variety of state-of-the-art purpose-built vision systems from the literature. As the scale of available computational power continues to expand, we argue that this approach has the potential to greatly accelerate progress in both artificial vision and our understanding of the computational underpinning of biological vision.",
                    "title": "A High-Throughput Screening Approach to Discovering Good Forms of Biologically Inspired Visual Representation",
                    "venue": "PLOS Computational Biology",
                    "year": 2009,
                    "__v": 2,
                    "citationCount": 82,
                    "result": 5.543477600830541
                },
                "adea0a98-d74d-43be-a238-a1ef027c6a58": {
                    "authors": [
                        "Jorge Sánchez",
                        "Florent Perronnin"
                    ],
                    "references": [
                        "04c47f14-8533-41ff-bafd-affc1eb52287",
                        "1680e45e-2dcd-4daa-b99f-d8daeaecdb69",
                        "1b40cd27-25d0-4c28-b406-ce88578beebb",
                        "2a3a6115-439a-48bf-9154-6175c0e0fe0b",
                        "2b6a3d0f-368f-45bb-be23-4e82f62fbbf7",
                        "306c53db-0ff2-4c38-92fc-6ed9e236e48d",
                        "3081c29b-8b78-46cd-b365-e8cb87b35597",
                        "59e5e0b0-db01-438e-8763-319477f9baf1",
                        "5a92cbaa-f7c5-433c-be83-f99d433fe876",
                        "5f290b18-d3c6-452d-966b-c8a11e88a5f6",
                        "6081e837-0af4-466c-8a80-7d78629c4f72",
                        "63692e82-1fd0-4caa-a0e4-188e9aa784e0",
                        "6dcb6528-aaae-4615-a46b-0aff15f63bae",
                        "6eef7a4b-cb7c-4e04-99c9-44092f30dd24",
                        "7cdd68ef-876b-4214-bd85-38dd01ac99c9",
                        "8174913d-2c94-4344-9fd5-383246be7cb3",
                        "8ecbb404-d99e-4991-bde0-9caa49f8a3e8",
                        "8fed7067-5f57-4f15-88cc-c948bcdd83f4",
                        "918ece8e-8a2f-4b8e-80bd-9927cff46641",
                        "999b9a1c-939e-4693-b896-37e0596c1d4b",
                        "a24e8c7a-41a9-494c-b446-c82b48617e9b",
                        "ac5e3fe4-3b1d-412d-a03b-3247d39f62d5",
                        "c61efabe-4f71-4d5c-a6cc-9e50be780411",
                        "d05a104c-6d43-451b-a2e2-7d065fe8bec4",
                        "d8c09afc-83dc-4600-b4ef-836e3f3928ec",
                        "e0296c28-35a4-41c1-9fd2-58e75d4819be",
                        "e0ac4812-7729-4a2d-8a1f-74b1b7c8eb5d",
                        "ef1ee55e-d2a3-4344-a4d7-aeed963c8d48",
                        "f00ec039-e6d1-45e2-a558-7f7c46872c3b",
                        "f540925f-40b4-449c-bc2b-60f968cd2f14",
                        "fbdfc1ca-09ef-47f8-a0d1-adaf626a8562",
                        "fc780759-4533-4b33-9774-746ca210842f"
                    ],
                    "keyword": [
                        "accuracy",
                        "signature",
                        "large",
                        "image",
                        "training",
                        "stateoftheart",
                        "report",
                        "dimensionality"
                    ],
                    "group": [],
                    "_id": "adea0a98-d74d-43be-a238-a1ef027c6a58",
                    "abstract": "We address image classification on a large-scale, i.e. when a large number of images and classes are involved. First, we study classification accuracy as a function of the image signature dimensionality and the training set size. We show experimentally that the larger the training set, the higher the impact of the dimensionality on the accuracy. In other words, high-dimensional signatures are important to obtain state-of-the-art results on large datasets. Second, we tackle the problem of data compression on very large signatures (on the order of 10 5  dimensions) using two lossy compression strategies: a dimensionality reduction technique known as the hash kernel and an encoding technique based on product quantizers. We explain how the gain in storage can be traded against a loss in accuracy and/or an increase in CPU cost. We report results on two large databases — ImageNet and a dataset of lM Flickr images — showing that we can reduce the storage of our signatures by a factor 64 to 128 with little loss in accuracy. Integrating the decompression in the classifier learning yields an efficient and scalable training algorithm. On ILSVRC2010 we report a 74.3% accuracy at top-5, which corresponds to a 2.5% absolute improvement with respect to the state-of-the-art. On a subset of 10K classes of ImageNet we report a top-1 accuracy of 16.7%, a relative improvement of 160% with respect to the state-of-the-art.",
                    "title": "High-dimensional signature compression for large-scale image classification",
                    "venue": "computer vision and pattern recognition",
                    "year": 2011,
                    "__v": 1,
                    "citationCount": 123,
                    "result": 4.680284890548047
                },
                "c9482f1f-6600-44a7-a69a-e63ef13cdff8": {
                    "authors": [
                        "Li Fei-Fei",
                        "Rob Fergus",
                        "Pietro Perona"
                    ],
                    "references": [
                        "2199c5a8-b004-4bcb-81c6-bb1568112077",
                        "222859e5-5135-4d8c-8bb3-8f8fbcc36fe4",
                        "6018a516-8149-4bce-bc33-5449d86e58c2",
                        "613841ae-c925-4aee-9c2e-8675213e4bbf",
                        "7f6e8f66-f378-445a-a322-f2d08287fbe3",
                        "c455fb04-4566-4648-ad6f-3cf2245e507c",
                        "ccdefe89-9b16-4c22-8bb8-bd314ccad6e1",
                        "e649a9fd-f6d9-4aac-b428-29b82c20a484",
                        "ef35a024-f5f3-4a7b-b6f6-61d9167385e6",
                        "fb244d98-60f6-40f8-8c42-a233dfa5843f"
                    ],
                    "keyword": [
                        "object",
                        "learning",
                        "incremental",
                        "categories",
                        "training",
                        "prior",
                        "method",
                        "information",
                        "images",
                        "bayesian"
                    ],
                    "group": [],
                    "_id": "c9482f1f-6600-44a7-a69a-e63ef13cdff8",
                    "abstract": "Current computational approaches to learning visual object categories require thousands of training images, are slow, cannot learn in an incremental manner and cannot incorporate prior information into the learning process. In addition, no algorithm presented in the literature has been tested on more than a handful of object categories. We present an method for learning object categories from just a few training images. It is quick and it uses prior information in a principled way. We test it on a dataset composed of images of objects belonging to 101 widely varied categories. Our proposed method is based on making use of prior information, assembled from (unrelated) object categories which were previously learnt. A generative probabilistic model is used, which represents the shape and appearance of a constellation of features belonging to the object. The parameters of the model are learnt incrementally in a Bayesian manner. Our incremental algorithm is compared experimentally to an earlier batch Bayesian algorithm, as well as to one based on maximum-likelihood. The incremental and batch versions have comparable classification performance on small training sets, but incremental learning is significantly faster, making real-time learning feasible. Both Bayesian methods outperform maximum likelihood on small training sets.",
                    "title": "Learning Generative Visual Models from Few Training Examples: An Incremental Bayesian Approach Tested on 101 Object Categories",
                    "venue": "computer vision and pattern recognition",
                    "year": 2004,
                    "__v": 2,
                    "citationCount": 1108,
                    "result": 5.004939504939506
                },
                "ca250ca4-70fd-411f-8cc7-fb17be31cd9e": {
                    "authors": [
                        "Patrice Y. Simard",
                        "David W. Steinkraus",
                        "John Platt"
                    ],
                    "references": [
                        "7b75127a-9fc0-4fa3-85dd-1e9744d3addb",
                        "d6104d9a-faaa-4db4-8c4e-748176157ef2",
                        "ec892eb8-6815-4ea3-b309-026f9202c256"
                    ],
                    "keyword": [
                        "networks",
                        "documents",
                        "set",
                        "neural",
                        "architecture",
                        "visual",
                        "training",
                        "simple",
                        "results",
                        "analysis"
                    ],
                    "group": [],
                    "_id": "ca250ca4-70fd-411f-8cc7-fb17be31cd9e",
                    "abstract": "Neural networks are a powerful technology forclassification of visual inputs arising from documents.However, there is a confusing plethora of different neuralnetwork methods that are used in the literature and inindustry. This paper describes a set of concrete bestpractices that document analysis researchers can use toget good results with neural networks. The mostimportant practice is getting a training set as large aspossible: we expand the training set by adding a newform of distorted data. The next most important practiceis that convolutional neural networks are better suited forvisual document tasks than fully connected networks. Wepropose that a simple \"do-it-yourself\" implementation ofconvolution with a flexible architecture is suitable formany visual document problems. This simpleconvolutional neural network does not require complexmethods, such as momentum, weight decay, structure-dependentlearning rates, averaging layers, tangent prop,or even finely-tuning the architecture. The end result is avery simple yet general architecture which can yieldstate-of-the-art performance for document analysis. Weillustrate our claims on the MNIST set of English digitimages.",
                    "title": "Best practices for convolutional neural networks applied to visual document analysis",
                    "venue": "international conference on document analysis and recognition",
                    "year": 2003,
                    "__v": 2,
                    "citationCount": 387,
                    "result": 6.900205753998324
                },
                "f6bd8b64-684d-429a-aab5-8ff3a2c23cd6": {
                    "authors": [
                        "Leo Breiman"
                    ],
                    "references": [
                        "0e9dc5ee-f078-4894-8f90-c3b1272da979",
                        "0f115eea-2272-431f-9f21-6d6789b2bbc9",
                        "17f811d8-8607-4270-bbec-1cc7883edd68",
                        "3704f939-09a2-4e9f-b851-1261bcd310df",
                        "3ae9664a-bf6f-45d2-852f-bba9b47e2b8a",
                        "504ab3f2-f826-411f-b3fd-02d2019c3844",
                        "5242f101-1511-4660-9a4c-4eb597aaa3c6",
                        "64abe8f5-cc63-4666-a4fe-d9c3c88db207",
                        "67046388-ae78-4aa4-ad8a-4f012858f6fb",
                        "7cd3d1bf-4df0-46c8-9e75-701534e5d93c",
                        "9e1ac4ec-85bf-4b41-b3f1-d12264b9352b",
                        "bd34fa58-2c96-4101-a068-2ef6368e2c6a",
                        "becc43bc-a7b6-46e1-817e-553c84a4a6dd",
                        "c88edc45-936d-4cda-9d12-1a7a21cdb651",
                        "d3b865bc-69e2-4426-9e7a-d01f0180a3ec",
                        "d9809d9a-ccf7-44a2-9073-3ed158f9057f",
                        "dc5dbb29-71b6-42e7-9e6b-8a1afdeeaee4",
                        "ebbbb0e3-5789-4dd0-b5f3-a911e59df314",
                        "f780a374-9a90-4ce3-951d-071db1e0ba9e",
                        "f98f3e2b-d93b-4c34-bb55-f2acc0cddab6",
                        "ffe77764-a254-4316-887e-c65bd4da6185"
                    ],
                    "keyword": [
                        "tree",
                        "forests",
                        "error",
                        "random",
                        "international",
                        "strength",
                        "split",
                        "number",
                        "generalization",
                        "features"
                    ],
                    "group": [
                        null
                    ],
                    "_id": "f6bd8b64-684d-429a-aab5-8ff3a2c23cd6",
                    "abstract": "Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund & R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, aaa, 148–156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.",
                    "title": "Random Forests",
                    "venue": "Machine Learning",
                    "year": 2001,
                    "__v": 2,
                    "citationCount": 7968,
                    "result": 6.481161989025767
                },
                "f7ac19b7-daaf-4dc1-bbb9-7f4ffd7385ba": {
                    "authors": [
                        "Srinivas C. Turaga",
                        "Joseph F. Murray",
                        "Viren Jain",
                        "Fabian Roth",
                        "Moritz Helmstaedter",
                        "Kevin L. Briggman",
                        "Winfried Denk",
                        "H. Sebastian Seung"
                    ],
                    "references": [
                        "03f3d290-78fb-4694-86ed-85acc48b0e79",
                        "05c86322-8109-4627-bddf-8d209db4aa83",
                        "11ed4e01-a5f5-471b-9a53-42650043269d",
                        "1c4b432d-a257-479a-8713-f9fe3d4f74fa",
                        "20c9c17e-7799-4588-95a6-c02bf8f31e23",
                        "243298e6-89e2-4291-a354-9764bd40a1a4",
                        "387c3cf9-cf56-4255-a772-e69e107f2105",
                        "3a450bcc-54d2-4787-9cad-d8eeef0067d4",
                        "45beeef2-a57d-436d-8fc4-56136234b4b9",
                        "463537e0-fa3e-485b-8cd2-4ae5dca7a6b3",
                        "4c437831-19d0-42cc-8f4d-874dd9e6676c",
                        "50deb9e0-e10b-40bd-a73f-c544285457e3",
                        "72c6c663-330b-400f-94f1-1abd68991fc2",
                        "773461d3-db93-4300-a052-83ba48cc0402",
                        "8b1f78ae-ecaf-4cc8-920e-3eee344102cf",
                        "ae3e7593-586f-495f-9416-4b50ed1fcd10",
                        "d2de642b-7044-4d04-85ea-1e05eea964c6",
                        "dc7dff25-79f6-4db5-9545-8577bc50c2f7"
                    ],
                    "keyword": [
                        "graph",
                        "affinity",
                        "image",
                        "algorithms",
                        "segmentation",
                        "partition",
                        "standard",
                        "show",
                        "learning",
                        "improves"
                    ],
                    "group": [],
                    "_id": "f7ac19b7-daaf-4dc1-bbb9-7f4ffd7385ba",
                    "abstract": "Many image segmentation algorithms first generate an affinity graph and then partition it. We present a machine learning approach to computing an affinity graph using a convolutional network (CN) trained using ground truth provided by human experts. The CN affinity graph can be paired with any standard partitioning algorithm and improves segmentation accuracy significantly compared to standard hand-designed affinity functions.#R##N##R##N#We apply our algorithm to the challenging 3D segmentation problem of reconstructing neuronal processes from volumetric electron microscopy (EM) and show that we are able to learn a good affinity graph directly from the raw EM images. Further, we show that our affinity graph improves the segmentation accuracy of both simple and sophisticated graph partitioning algorithms.#R##N##R##N#In contrast to previous work, we do not rely on prior knowledge in the form of hand-designed image features or image preprocessing. Thus, we expect our algorithm to generalize effectively to arbitrary image types.",
                    "title": "Convolutional networks can learn to generate affinity graphs for image segmentation",
                    "venue": "Neural Computation",
                    "year": 2010,
                    "__v": 2,
                    "citationCount": 76,
                    "result": 3.184571680095976
                }
            }
        ],
        "_id": "e2f7a74a-8430-4463-94ce-fe85dfd309f9",
        "abstract": "We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0% which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully-connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overriding in the fully-connected layers we employed a recently-developed regularization method called \"dropout\" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry.",
        "title": "ImageNet Classification with Deep Convolutional Neural Networks",
        "venue": "neural information processing systems",
        "year": 2012,
        "__v": 3,
        "citationCount": 5094
    },
    {
        "authors": [
            "Stephen P. Boyd",
            "Neal Parikh",
            "Eric Chu",
            "Borja Peleato",
            "Jonathan Eckstein"
        ],
        "references": [
            "01f025f9-3cc1-41d4-9424-363c290fe765",
            "02629ee1-0ac3-4f22-a725-f59e6b5e6170",
            "0435b723-134f-4036-ab7e-f3c21ce63e24",
            "0ab6d92b-44d2-44da-b029-39e138eb1216",
            "109367fa-db04-4db0-8777-d6ca7e9e78fd",
            "1112d936-cb10-4c0c-9eec-b4fd8f5a5c7f",
            "18cb68a7-8f1c-46f5-a854-7465070c1913",
            "19a42cd3-c8ae-4f71-8c8c-4eae6ca48345",
            "257b41f6-d411-4029-b551-4483e7c5cf3e",
            "26467b42-3e2f-4794-bbfa-6420a096257b",
            "2684fb9b-5b4d-400c-91fb-27fd5c083879",
            "2c58f129-ff63-4afe-ab63-b10d03da1779",
            "2ca8a212-1179-4f68-bc20-8f2d8848585a",
            "30577785-43de-4a11-b5f8-d460cd2944ec",
            "36430fd0-a383-4f6d-ae8a-6048eaf9fe08",
            "3a0a2f46-50e6-46c8-872e-35744fe66738",
            "3f90046c-1c24-4a11-abc5-831c4d30f660",
            "400299f5-6b73-4ea9-b1cc-c4460f8b60c4",
            "41fde063-16ea-4520-900d-3b935c8c53f0",
            "4773f066-c0ab-4ed4-9a02-7fe97871fea8",
            "4b94b764-ede9-42ab-97c2-43700b728d69",
            "5002dd27-9ce6-4abb-a3d0-2ac112f58c37",
            "5270bc6c-a24f-40d9-8d96-50c31f9d0bfb",
            "52981273-36dc-429f-a12d-bada6edee02e",
            "52e55346-2fb4-45a8-9e50-db06f3343982",
            "5b92842e-1023-4c80-99a2-23b15a78c58c",
            "5bbc1a90-621e-4b83-be68-d6fe2eb7c6c2",
            "5fa58e5b-3d77-4aee-905b-99aec0711748",
            "609d17f8-e650-4754-96eb-5c5a3769a50c",
            "6e1947dd-2997-481b-9726-2921960e677f",
            "71a18de9-e543-4337-ab7a-3db31d9f8c00",
            "7298a617-55f9-4bdb-be57-7e83349bb530",
            "74b9aa5f-e5e4-4789-a5ca-254030320eca",
            "7a7b52f0-82db-4e16-9df0-d3f5b5c7b5c5",
            "7b7510c9-1506-4153-b2df-6aa1242e22ef",
            "81a60c6f-2102-4b93-b991-00814ab480f4",
            "839e59b8-b356-4329-ba79-97f981cf6768",
            "860a3efc-800e-4e62-8200-7acf3f8d2b8d",
            "861e877e-3903-4aed-827a-5a501858f17b",
            "87b16469-4b10-41e5-8dfc-2381a6592bfb",
            "92a22c32-9559-496a-b35c-813407edd134",
            "94e82a1e-656e-45d6-8b4e-1315c2e94fba",
            "9b166075-5b89-4ec5-91db-47e5ca47c7ec",
            "9c7174a1-3c73-4a2e-a78b-b23816830420",
            "9e7f3a14-e586-4bad-aab9-0c36173e441d",
            "a012a24d-aa95-4049-b628-e606a0d007e9",
            "a06aef17-2b53-4dbd-ba4b-d15fdd44ba51",
            "a083a1b9-8dfb-45d6-99a9-fa30c4a6e9f5",
            "a53a3dda-b003-4d5c-96b1-e9afd8e35692",
            "a7b474ca-c1f6-45c6-bc77-534d90c30764",
            "aa70d058-ba2d-409f-a20e-fcf8239a069e",
            "ab0bfa8d-80b6-47ef-8a91-febce2ce65c5",
            "b18e236f-aa78-452c-a85a-240e5e5d69fb",
            "b220c1dd-7184-4e8b-a835-cce5504d95d1",
            "b22ae921-bc95-40ad-9a6e-af0d73790adc",
            "b2425f3b-5b13-483a-8fd1-fdf13fa238fd",
            "b8321e4f-ccae-433a-984e-7567535ff293",
            "b959ad94-9d47-418a-a145-e719bb379203",
            "bacedd4e-2e09-4ec8-8d9a-0f77e1e3816f",
            "bc40dd83-5f7a-435c-8275-73f36c3c6c49",
            "c18bd8c2-a8ab-431e-8d13-621efa0864de",
            "c9ef3dc8-4117-4dc4-8aa5-19d8af78766c",
            "d7b5aadf-ec30-4fb7-9224-7474169d3744",
            "db26488d-78be-44b1-a343-e896f43c5d29",
            "de4fea1d-2739-4e0f-b5a3-08f0df58d787",
            "e05c0e3a-edab-4cc4-af71-9ea53378e364",
            "e5b8523a-bc81-4389-8569-741e2c590dd3",
            "ea082c34-f979-4fdc-9e13-a74e93cadebc",
            "eb3c9554-d529-42df-ba9a-5665ffa2b2d1",
            "f3478418-696c-42da-a11d-a654e4aba79e",
            "f56b877b-4060-4754-b303-e8140968544c",
            "fa619312-6a30-40c5-bd8e-f09dffce0543",
            "fb0a382c-a1f1-4f0c-8e80-36fe5fbbfb86",
            "fbea2899-47c7-41de-b0e7-af93e8889537"
        ],
        "keyword": [
            "methods",
            "problems",
            "machine",
            "distributed",
            "statistics",
            "optimization",
            "learning",
            "algorithms"
        ],
        "group": [
            {
                "4b94b764-ede9-42ab-97c2-43700b728d69": {
                    "authors": [
                        "Henrik Ohlsson",
                        "Lennart Ljung",
                        "Stephen P. Boyd"
                    ],
                    "references": [
                        "27608262-e731-4ff7-8c0f-f9af55a7db4c",
                        "a53a3dda-b003-4d5c-96b1-e9afd8e35692",
                        "be85d125-170b-41b8-8182-4f5680ac30c2",
                        "c2a38919-b9ff-4d88-a5be-2a14cb608b06",
                        "f56b877b-4060-4754-b303-e8140968544c",
                        "fb3eeea2-1d83-4e4d-85d0-0c8a283a8ce1"
                    ],
                    "keyword": [
                        "parameters",
                        "segmentation",
                        "regularization",
                        "problem",
                        "formulated",
                        "constant",
                        "tuning",
                        "tradeoff",
                        "timevarying",
                        "time"
                    ],
                    "group": [],
                    "_id": "4b94b764-ede9-42ab-97c2-43700b728d69",
                    "abstract": "Segmentation of time-varying systems and signals into models whose parameters are piecewise constant in time is an important and well studied problem. Here it is formulated as a least-squares problem with sum-of-norms regularization over the state parameter jumps, a generalization of @?\"1-regularization. A nice property of the suggested formulation is that it only has one tuning parameter, the regularization constant which is used to trade-off fit and the number of segments.",
                    "title": "Brief paper: Segmentation of ARX-models using sum-of-norms regularization",
                    "venue": "Automatica",
                    "year": 2010,
                    "__v": 2,
                    "citationCount": 42,
                    "result": 6.969346036713783
                },
                "5002dd27-9ce6-4abb-a3d0-2ac112f58c37": {
                    "authors": [
                        "Sanjay Ghemawat",
                        "Howard Gobioff",
                        "Shun-Tak Leung"
                    ],
                    "references": [
                        "424dc19d-6ea3-4167-a3c9-86af30ccb38a",
                        "78001675-2215-4b4e-8a92-cd30f6409d70",
                        "7853ec59-161c-4a18-a36f-1fa4f3a97a86",
                        "7dfaeb99-65b2-4dc1-b03e-68489b29fb10",
                        "8ce5aa42-c9f7-4e6b-87cd-a4f2e13b4aa8",
                        "b4489ce3-343e-4540-a074-baccb5207bce",
                        "f1b8a32b-2629-476b-a0fe-07bd782d141c"
                    ],
                    "keyword": [
                        "system",
                        "file",
                        "designed",
                        "distributed",
                        "storage",
                        "large",
                        "applications"
                    ],
                    "group": [],
                    "_id": "5002dd27-9ce6-4abb-a3d0-2ac112f58c37",
                    "abstract": "We have designed and implemented the Google File System, a scalable distributed file system for large distributed data-intensive applications. It provides fault tolerance while running on inexpensive commodity hardware, and it delivers high aggregate performance to a large number of clients. While sharing many of the same goals as previous distributed file systems, our design has been driven by observations of our application workloads and technological environment, both current and anticipated, that reflect a marked departure from some earlier file system assumptions. This has led us to reexamine traditional choices and explore radically different design points. The file system has successfully met our storage needs. It is widely deployed within Google as the storage platform for the generation and processing of data used by our service as well as research and development efforts that require large data sets. The largest cluster to date provides hundreds of terabytes of storage across thousands of disks on over a thousand machines, and it is concurrently accessed by hundreds of clients. In this paper, we present file system interface extensions designed to support distributed applications, discuss many aspects of our design, and report measurements from both micro-benchmarks and real world use.",
                    "title": "The Google file system",
                    "venue": "symposium on operating systems principles",
                    "year": 2003,
                    "__v": 2,
                    "citationCount": 1985,
                    "result": 3.8005943746655824
                },
                "5270bc6c-a24f-40d9-8d96-50c31f9d0bfb": {
                    "authors": [
                        "Alekh Agarwal",
                        "Martin J. Wainwright",
                        "John C. Duchi"
                    ],
                    "references": [
                        "4a78d773-7703-4de6-9881-2bcef9e336ea",
                        "4fe5d18b-f2c5-4edd-8542-65dbbd05a75b",
                        "6bc414a1-3f2f-44de-913d-f2536d7eb0d3",
                        "79dc23f9-2514-4010-a875-8789d74555eb",
                        "860a3efc-800e-4e62-8200-7acf3f8d2b8d",
                        "8cc9ea80-563f-4e62-bda9-8ff6d71cf6ae",
                        "8e8cb2b4-799b-4348-8029-b91045fb659a",
                        "9c7174a1-3c73-4a2e-a78b-b23816830420",
                        "a6ffa92f-a61a-4e94-b63c-5036f7751aea",
                        "af342d20-c229-4e21-8b04-26a5af4c8ede",
                        "bb352f7c-946c-4518-9e58-820cbc146657",
                        "dadfa87e-535b-42fa-be7f-61d24458ede4"
                    ],
                    "keyword": [
                        "network",
                        "optimization",
                        "algorithms",
                        "sharp",
                        "local",
                        "functions",
                        "convergence",
                        "communication",
                        "bounds"
                    ],
                    "group": [],
                    "_id": "5270bc6c-a24f-40d9-8d96-50c31f9d0bfb",
                    "abstract": "The goal of decentralized optimization over a network is to optimize a global objective formed by a sum of local (possibly nonsmooth) convex functions using only local computation and communication. We develop and analyze distributed algorithms based on dual averaging of subgradients, and provide sharp bounds on their convergence rates as a function of the network size and topology. Our analysis clearly separates the convergence of the optimization algorithm itself from the effects of communication constraints arising from the network structure. We show that the number of iterations required by our algorithm scales inversely in the spectral gap of the network. The sharpness of this prediction is confirmed both by theoretical lower bounds and simulations for various networks.",
                    "title": "Distributed Dual Averaging In Networks",
                    "venue": "neural information processing systems",
                    "year": 2010,
                    "__v": 2,
                    "citationCount": 20,
                    "result": 5.185494103958904
                },
                "52981273-36dc-429f-a12d-bada6edee02e": {
                    "authors": [
                        "Martin J. Wainwright",
                        "Michael I. Jordan"
                    ],
                    "references": [
                        "02d3f186-8c49-449a-9ee4-e530c92b6f16",
                        "04716a7d-182f-4976-881f-4c550da15fba",
                        "0674f351-6c2f-49fb-b1aa-1343421c8964",
                        "072e48e7-9c93-4d36-bba6-127a62346f70",
                        "0852e77b-5dcd-4e10-804c-19f5087dc4d8",
                        "090a55a8-73b0-4f07-9467-fadeac63cc44",
                        "0a4f0020-c885-45ba-bbf8-ac29ba05d0e9",
                        "0bb0317b-f466-4f99-81f8-007ff466305a",
                        "0d1a2775-e9dc-4243-9702-9fd3ae342236",
                        "0e4a04de-f3f3-467d-a3bd-aaffd77e092a",
                        "0eb5d88d-960e-4c47-b9c5-40bb682e8166",
                        "152f4ef5-04dd-4ab4-9f9f-cca75185d3bf",
                        "1552a53d-6c82-4d57-ae26-e881e3f96a44",
                        "172f9f68-8417-43bb-8fe5-b377d569f6b6",
                        "18d45b46-bb52-4f37-8980-c46e29a35145",
                        "1c9e0295-e59f-41a2-b7ea-821efd4e65e9",
                        "1e8afa9e-4f00-4f5e-96c7-cf2cbeb80e10",
                        "2430ab7c-cec5-4cee-a05c-d34bc9eef826",
                        "24ea0e05-bd7a-48c9-9a98-d855445161b1",
                        "26635066-5a61-43b4-afe1-19432b1e2529",
                        "2908dc22-56ac-4215-9b03-6fa0a4ff89ab",
                        "29f196b0-3df4-43c9-bf33-6411f5adf879",
                        "2b7c6442-36d4-45bf-b73c-c07f05291703",
                        "2d021904-d1a1-489f-9c27-c2eb986eadce",
                        "2d0fa10a-491a-4083-81ff-5e788d7e2230",
                        "30b61522-5b29-4c65-a814-c68ec56a3401",
                        "3322da40-7067-4210-9e4b-d73d0de71523",
                        "352b467b-9720-4c03-bf0a-8fa27638120f",
                        "3659f2d5-bc81-467e-9488-34aff690bdc3",
                        "3d6e0282-bf21-4e8b-a1d6-c07a52688f18",
                        "3fe92f21-0114-47bb-9e02-566c10f67539",
                        "400d44a7-39be-4782-a000-36a3e8202ea5",
                        "407e5009-677d-4f6b-8788-26e9dddb914d",
                        "41270b80-f1b7-4721-bf76-e91b6f825864",
                        "4155451c-5eb5-42af-ac38-14a3195e869f",
                        "42a72901-f540-4c2d-a9bf-c10fd9faa00a",
                        "440ab2d5-3af6-4a67-9ddb-d1a7b6693063",
                        "4682bab4-4d89-43a7-9493-ad04f38e5e32",
                        "4d1c024f-848a-42b6-a0e5-4be6e09f60cc",
                        "51657f5d-8e60-4a5f-9797-d7bd64609284",
                        "52f4beb4-b9dd-422d-a88e-61c318c8e5d1",
                        "5b862059-9b3f-4c4e-91ae-c05a78a73fb8",
                        "5fd00f57-47b6-4775-8d34-069344c2ca60",
                        "6160bed5-2291-4af6-ad90-8f1ade4fa961",
                        "63b18851-8ddb-4750-af19-ea3bd3942f58",
                        "688a9110-7b34-4628-bc78-8fcc4bdd3010",
                        "6c6c0882-a3d9-4224-91ce-4cee8827c912",
                        "6e305c57-4baa-454f-a980-541cb871d743",
                        "6f9aeb94-bd72-4ac6-8ec4-4c3f98dcb993",
                        "7163a2a6-5de8-45f1-9d1a-1db21883a5a5",
                        "773edbd9-07a0-45b6-8747-04f928e2342c",
                        "7963ab0f-472d-47ec-a2d9-d21d72e390b2",
                        "7e5365be-bb99-4f86-9523-d7e6c56e86d9",
                        "7f869d2a-a8ad-403e-b031-b14058d032b4",
                        "821feac4-ac45-4fdf-b624-a5456706e038",
                        "8285b7c1-a2cd-4916-ad56-afc0eceeb815",
                        "83d61fde-ec1e-4675-924a-dbcb7231ab4d",
                        "84e6d1d0-dde4-492e-9cf4-fe4f3ce7f864",
                        "869007f7-ac7f-49dd-9d24-1859396fd4db",
                        "889d825a-2ac9-4ab8-bfff-5f3806a5b717",
                        "89eeb249-2af5-4b3b-8529-0b3d32393dd6",
                        "8c6298f3-6edb-4fbd-832a-11c8cb03d009",
                        "8c881b24-066e-4a16-957f-bf365b2780bf",
                        "8cea470a-9c6d-4137-8f4c-acda7e0d1904",
                        "8d09527f-b5ad-4902-ba34-5583f6759d3b",
                        "8d0c338e-1b11-4c91-9a0c-70022456613c",
                        "95c0933d-4dfd-4891-8a45-78d055313cbd",
                        "9616a989-d350-4bbc-95fc-da43ab672658",
                        "9671b795-a3be-4b98-bbc4-ced2f53994cd",
                        "96da39e0-2929-46e6-a87d-536608e3c7b7",
                        "97233a1c-326d-45da-abdf-06c8fb366ed2",
                        "9771fcb5-e9e8-4f6c-a49f-6887aa69599a",
                        "97ab981e-3738-4907-86a7-b04321c5e13c",
                        "9879290a-43a1-4268-982c-3b6863fa2d37",
                        "9d32a674-cd69-4f28-be68-b2a4fa6db086",
                        "9f1c57c9-ae6c-4e00-b3ee-10256adb3cb1",
                        "9ffac7fb-666f-4a98-a2a1-09334d05e814",
                        "a034a67b-7af7-4ed4-ae57-edb4ccb5075a",
                        "a2a38398-1a0f-4904-b826-e0d7a2710d8b",
                        "a4ffbcf0-fbd0-42d3-b60f-b1be256493dc",
                        "a5f4f8f7-0e36-4a42-a147-53252c7f1ce8",
                        "a66a3bdc-6625-4fab-ade4-5d72f61263a5",
                        "ae1bbc96-0803-4190-ac6c-a54624cf12ae",
                        "b01b0c90-45e5-40da-9993-2c07644b9c0a",
                        "b0b16a57-9f50-4578-95a6-73ead015cd80",
                        "b3d533e4-3021-4fc1-911c-e266c8a3bc20",
                        "b7d68ae9-233d-4ddd-9c1d-80eb63a43dd3",
                        "b809b2e3-b5be-447d-9847-cbde35375304",
                        "b8ce186d-3a45-4e8c-a5d8-524e16fc76b6",
                        "b959ad94-9d47-418a-a145-e719bb379203",
                        "ba56e820-31bd-46fd-93c1-91391aaba599",
                        "ba733803-6b30-4a2b-b76a-0bbe17baa2f0",
                        "bc95970b-34c5-4860-a832-41bc04a50889",
                        "bd3a3a31-46b2-420d-ba03-057ac8ead4b2",
                        "bd8c46c6-3635-407f-9bd1-b90bbba3d26d",
                        "be17d822-41dc-4bdd-ac04-bf3f42bf41a0",
                        "c1583154-cfbc-4303-8563-7a8603d72848",
                        "c3afdbe4-e7ff-4a63-9c40-444f7a678626",
                        "c54f5e9b-8ee1-4c6d-934f-84c1f2413015",
                        "c5b20e50-4fca-4c72-b532-345094d0dd19",
                        "d0ad8d69-b4fa-44ec-ae7b-2f36351becaf",
                        "d10a85a4-5ccc-4604-a291-82add5e72262",
                        "d3e00e7e-1c64-4d7a-b2b2-1ad98ba4c706",
                        "d65159fb-7da8-4951-863f-0e24b484b525",
                        "d6eac4fa-5a6e-4f72-93d4-0bb45f0188d2",
                        "d6ff89e7-6065-4090-8c82-4d4bab3ddda4",
                        "da3d4bc5-b3e5-42e2-ad2a-704cf9465833",
                        "db1984f8-fb09-48ac-97bd-9a6cf99603f4",
                        "dfd6d225-9a7b-459a-9575-5c1bf949b4bc",
                        "e0f03d8a-6641-4dc7-af7a-e89dbbaa7e3b",
                        "e22a2ee3-699c-4f1f-a11d-67a50ed00da0",
                        "e27fe383-0509-4a5f-b591-aa970c0d430d",
                        "eaea1ba1-b261-45af-8c94-6b4587c1284f",
                        "f28fe1e5-7094-4b11-8efc-12561a70fbc5",
                        "f2d7c3e6-416a-4af9-8d29-ce78161d9d01",
                        "f56dbdc3-f2ee-4a66-a3fb-df142f830dc5",
                        "f6024225-8136-4735-845d-9fa03c8ca880",
                        "f65eafab-1d85-4bf5-92f0-0eb640a64ce0",
                        "f76d6081-9b4e-4c7a-8fc2-1e361f1c8adc",
                        "f7cdf297-0d6e-4eb2-b120-3bab0c881264",
                        "f836297f-a750-4fa2-b80f-bc941a667a78",
                        "fb244d98-60f6-40f8-8c42-a233dfa5843f",
                        "fec3e964-bdbb-4c29-acf1-01d43f18c82e"
                    ],
                    "keyword": [
                        "statistical",
                        "variational",
                        "models",
                        "representations",
                        "problems",
                        "probability",
                        "methods",
                        "general",
                        "computational"
                    ],
                    "group": [],
                    "_id": "52981273-36dc-429f-a12d-bada6edee02e",
                    "abstract": "The formalism of probabilistic graphical models provides a unifying framework for capturing complex dependencies among random variables, and building large-scale multivariate statistical models. Graphical models have become a focus of research in many statistical, computational and mathematical fields, including bioinformatics, communication theory, statistical physics, combinatorial optimization, signal and image processing, information retrieval and statistical machine learning. Many problems that arise in specific instances — including the key problems of computing marginals and modes of probability distributions — are best studied in the general setting. Working with exponential family representations, and exploiting the conjugate duality between the cumulant function and the entropy for exponential families, we develop general variational representations of the problems of computing likelihoods, marginal probabilities and most probable configurations. We describe how a wide variety of algorithms — among them sum-product, cluster variational methods, expectation-propagation, mean field methods, max-product and linear programming relaxation, as well as conic programming relaxations — can all be understood in terms of exact or approximate forms of these variational representations. The variational approach provides a complementary alternative to Markov chain Monte Carlo as a general source of approximation methods for inference in large-scale statistical models.",
                    "title": "Graphical Models, Exponential Families, and Variational Inference",
                    "venue": "",
                    "year": 2008,
                    "__v": 2,
                    "citationCount": 1015,
                    "result": 7.4248781249043745
                },
                "52e55346-2fb4-45a8-9e50-db06f3343982": {
                    "authors": [
                        "Patrick L. Combettes",
                        "Valérie R. Wajs"
                    ],
                    "references": [
                        "039c3781-16d5-495c-8ce9-3509ee45bdcb",
                        "1241eb73-d134-48f7-abcd-73330d509605",
                        "1e46bd4c-ad0c-4742-b42c-b876161d9c97",
                        "30903582-5194-4053-ab76-aae6109401ac",
                        "31c883b9-75b1-4ea6-b9e2-776cc33a287f",
                        "414e6288-6ba5-47dc-bc8f-c5bb25e24978",
                        "593b32e9-7937-42f0-9e2f-2a8d909cb92b",
                        "76230717-9d67-455a-bc8b-11dd4a01af75",
                        "7c1241ea-33cf-4292-846d-95311b1623ea",
                        "95036700-fda4-42de-81af-bf7ec7f06932",
                        "9f0de2aa-7876-42cd-b5c6-263bfffdb9e8",
                        "a2b4e486-fe7e-417f-a79d-0d43cd4dbfd3",
                        "b5e502fe-aba4-4027-bc41-89a67760255e",
                        "ba36a239-93ab-430b-97d2-cd128ff0ccb2",
                        "c7e200d2-e084-4160-824c-5c578056b012",
                        "d07cee0a-6de6-45f9-af55-689c4ab6b92c",
                        "d11c6a56-fc23-4642-b394-99fd3aec953a",
                        "e150fc0f-42a7-4de9-a8f2-0b29d4304623",
                        "f97efc00-a307-4ec2-bf21-1f209584d342",
                        "fccf935e-ce98-4235-a0bc-50cb817a9e70"
                    ],
                    "keyword": [
                        "problems",
                        "results",
                        "operator",
                        "methods",
                        "generic",
                        "formulated",
                        "existence"
                    ],
                    "group": [],
                    "_id": "52e55346-2fb4-45a8-9e50-db06f3343982",
                    "abstract": "We show that various inverse problems in signal recovery can be formulated as the generic problem of minimizing the sum of two convex functions with certain regularity properties. This formulation makes it possible to derive existence, uniqueness, characterization, and stability results in a unified and standardized fashion for a large class of apparently disparate problems. Recent results on monotone operator splitting methods are applied to establish the convergence of a forward-backward algorithm to solve the generic problem. In turn, we recover, extend, and provide a simplified analysis for a variety of existing iterative methods. Applications to geometry/texture image decomposition schemes are also discussed. A novelty of our framework is to use extensively the notion of a proximity operator, which was introduced by Moreau in the 1960s.",
                    "title": "SIGNAL RECOVERY BY PROXIMAL FORWARD-BACKWARD SPLITTING ∗",
                    "venue": "Multiscale Modeling & Simulation",
                    "year": 2005,
                    "__v": 1,
                    "citationCount": 590,
                    "result": 4.533122020738121
                },
                "5b92842e-1023-4c80-99a2-23b15a78c58c": {
                    "authors": [
                        "Manya V. Afonso",
                        "José M. Bioucas-Dias",
                        "Mário A. T. Figueiredo"
                    ],
                    "references": [
                        "109367fa-db04-4db0-8777-d6ca7e9e78fd",
                        "1112d936-cb10-4c0c-9eec-b4fd8f5a5c7f",
                        "170f3ee6-769a-4e7e-acc2-5ceb02492e93",
                        "1cc8f484-eeac-462f-9dce-4b93a1942be0",
                        "2131c96b-7724-48f3-a53e-49c2d6e5065d",
                        "28e6e848-a661-40bd-8667-630e8575016a",
                        "31c883b9-75b1-4ea6-b9e2-776cc33a287f",
                        "3f90046c-1c24-4a11-abc5-831c4d30f660",
                        "4289bfe3-7305-41e5-a19d-8f0dd37e9892",
                        "4914ef63-62d1-458b-a9f7-56c78ca31e3d",
                        "4b00142e-0e50-4245-9094-8d0108a68582",
                        "52362b6a-44d0-43ed-857e-958820244f2f",
                        "52e55346-2fb4-45a8-9e50-db06f3343982",
                        "65447e66-f512-459b-9733-5bf40a537e24",
                        "6d263589-e3d5-45f8-8159-faff0f21c319",
                        "74b9aa5f-e5e4-4789-a5ca-254030320eca",
                        "7db1957b-66a4-439f-a9bd-ca89aea58642",
                        "a6afe815-62b7-4894-b996-c13cc4aebe69",
                        "b18e236f-aa78-452c-a85a-240e5e5d69fb",
                        "b8321e4f-ccae-433a-984e-7567535ff293",
                        "e43307d3-7ab9-4b31-b84d-c714f44bc9d2",
                        "e7af7694-28e7-4b6a-b23c-b7f4f8647ed2",
                        "eeb6ade1-11bd-4015-bf01-c259007c6a6f",
                        "f0c0249b-4cef-436c-904f-1d70ef15d300",
                        "f56b877b-4060-4754-b303-e8140968544c"
                    ],
                    "keyword": [
                        "propose",
                        "algorithm",
                        "problems",
                        "regularizer",
                        "image",
                        "sufficiently",
                        "show",
                        "reconstruction",
                        "observations",
                        "nonsmooth"
                    ],
                    "group": [],
                    "_id": "5b92842e-1023-4c80-99a2-23b15a78c58c",
                    "abstract": "We propose a new fast algorithm for solving one of the standard approaches to ill-posed linear inverse problems (IPLIP), where a (possibly nonsmooth) regularizer is minimized under the constraint that the solution explains the observations sufficiently well. Although the regularizer and constraint are usually convex, several particular features of these problems (huge dimensionality, nonsmoothness) preclude the use of off-the-shelf optimization tools and have stimulated a considerable amount of research. In this paper, we propose a new efficient algorithm to handle one class of constrained problems (often known as basis pursuit denoising) tailored to image recovery applications. The proposed algorithm, which belongs to the family of augmented Lagrangian methods, can be used to deal with a variety of imaging IPLIP, including deconvolution and reconstruction from compressive observations (such as MRI), using either total-variation or wavelet-based (or, more generally, frame-based) regularization. The proposed algorithm is an instance of the so-called alternating direction method of multipliers, for which convergence sufficient conditions are known; we show that these conditions are satisfied by the proposed algorithm. Experiments on a set of image restoration and reconstruction benchmark problems show that the proposed algorithm is a strong contender for the state-of-the-art.",
                    "title": "An Augmented Lagrangian Approach to the Constrained Optimization Formulation of Imaging Inverse Problems",
                    "venue": "IEEE Transactions on Image Processing",
                    "year": 2011,
                    "__v": 2,
                    "citationCount": 254,
                    "result": 6.689372242141795
                },
                "5bbc1a90-621e-4b83-be68-d6fe2eb7c6c2": {
                    "authors": [
                        "Gabriele Steidl",
                        "Tanja Teuber"
                    ],
                    "references": [
                        "02bfbbbb-2302-4952-8f9d-2860d36d7c62",
                        "02e9644c-45ca-4bf6-865b-5d3d2536e747",
                        "04f38cf3-16eb-405b-8fd0-3c7b5ca4ee6b",
                        "0d1b70bf-afa2-40a0-9fdc-2f389cc3487c",
                        "1964ac5a-8c1c-428f-9d07-97aa319dbece",
                        "1cc8f484-eeac-462f-9dce-4b93a1942be0",
                        "1e9dc3ef-4c20-47b9-8277-efd5b895183d",
                        "3d90055d-6a77-4b99-b2d1-9340d76cac21",
                        "3f90046c-1c24-4a11-abc5-831c4d30f660",
                        "43898afd-2192-4aa3-9c66-1e4b02f2a392",
                        "504fb96a-168b-4d5d-bf7a-e2fa16b16073",
                        "5d136308-0021-4a30-9926-942912666cb3",
                        "60b2f3d2-5796-436e-8336-c5d367cfb771",
                        "661fb6a5-76ec-4b75-bda8-5d60383c26e1",
                        "6ace9049-f111-4939-b2a5-56adbeb15539",
                        "6aebafce-f4c0-4a34-8a36-b9ede925fb8e",
                        "6c0f40ca-99ed-461a-ae23-3417a4736749",
                        "6c425b62-ed6e-4cb8-9091-e5d6e3899aa2",
                        "6d263589-e3d5-45f8-8159-faff0f21c319",
                        "732798c6-b42e-43f7-b4ff-f48077451d93",
                        "886fd9ac-a45f-40b1-af49-0aabbbc65181",
                        "9b166075-5b89-4ec5-91db-47e5ca47c7ec",
                        "9ba48547-e98c-43da-ad9b-910302e62a13",
                        "9ebe0155-6839-49bc-a71a-0aff2e694c75",
                        "a468f2d2-abf5-4566-a836-0c0b25ed8519",
                        "a4c6f436-a7a0-40b5-8a2c-fb2c1a3df2fc",
                        "a77c2879-23b2-476f-884d-20b591a20b1d",
                        "b8321e4f-ccae-433a-984e-7567535ff293",
                        "bcde1b1a-26b0-4782-a252-3af7d730e3df",
                        "cbf3652c-3d45-488c-9347-9408caec92fe",
                        "f0c0249b-4cef-436c-904f-1d70ef15d300"
                    ],
                    "keyword": [
                        "noise",
                        "variational",
                        "term",
                        "splitting",
                        "restoration",
                        "methods",
                        "idivergence",
                        "gamma",
                        "fitting",
                        "data"
                    ],
                    "group": [],
                    "_id": "5bbc1a90-621e-4b83-be68-d6fe2eb7c6c2",
                    "abstract": "In this paper, we consider a variational restoration model consisting of the I-divergence as data fitting term and the total variation semi-norm or nonlocal means as regularizer for removing multiplicative Gamma noise. Although the I-divergence is the typical data fitting term when dealing with Poisson noise we substantiate why it is also appropriate for cleaning Gamma noise. We propose to compute the minimizers of our restoration functionals by applying Douglas-Rachford splitting techniques, resp. alternating direction methods of multipliers. For a particular splitting, we present a semi-implicit scheme to solve the involved nonlinear systems of equations and prove its Q-linear convergence. Finally, we demonstrate the performance of our methods by numerical examples.",
                    "title": "Removing Multiplicative Noise by Douglas-Rachford Splitting Methods",
                    "venue": "Journal of Mathematical Imaging and Vision",
                    "year": 2010,
                    "__v": 1,
                    "citationCount": 79,
                    "result": 6.295889534279627
                },
                "609d17f8-e650-4754-96eb-5c5a3769a50c": {
                    "authors": [
                        "Yingyi Bu",
                        "Bill Howe",
                        "Magdalena Balazinska",
                        "Michael D. Ernst"
                    ],
                    "references": [
                        "0b2b5b0c-74d1-486b-88ae-7280fcd09c27",
                        "117d7c05-35c9-4745-bd6c-c745c35ec7eb",
                        "15d4f7fc-4199-4547-a34e-4d623416fc25",
                        "3e73340d-034b-4f84-bc93-b9f3d181a123",
                        "40fbb7d2-8060-4a9b-be69-1b168c3e2fba",
                        "8f9e92cf-f266-4e51-807f-c098a260a0dc",
                        "d71355af-17f4-438e-9b9f-f76cdf055630",
                        "fa619312-6a30-40c5-bd8e-f09dffce0543"
                    ],
                    "keyword": [
                        "haloop",
                        "data",
                        "applications",
                        "platforms",
                        "mapreduce",
                        "support",
                        "reduces",
                        "real",
                        "queries",
                        "programs"
                    ],
                    "group": [],
                    "_id": "609d17f8-e650-4754-96eb-5c5a3769a50c",
                    "abstract": "The growing demand for large-scale data mining and data analysis applications has led both industry and academia to design new types of highly scalable data-intensive computing platforms. MapReduce and Dryad are two popular platforms in which the dataflow takes the form of a directed acyclic graph of operators. These platforms lack built-in support for iterative programs, which arise naturally in many applications including data mining, web ranking, graph analysis, model fitting, and so on. This paper presents HaLoop, a modified version of the Hadoop MapReduce framework that is designed to serve these applications. HaLoop not only extends MapReduce with programming support for iterative applications, it also dramatically improves their efficiency by making the task scheduler loop-aware and by adding various caching mechanisms. We evaluated HaLoop on real queries and real datasets. Compared with Hadoop, on average, HaLoop reduces query runtimes by 1.85, and shuffles only 4% of the data between mappers and reducers.",
                    "title": "HaLoop: efficient iterative data processing on large clusters",
                    "venue": "very large data bases",
                    "year": 2010,
                    "__v": 1,
                    "citationCount": 315,
                    "result": 3.9585631347241255
                },
                "6e1947dd-2997-481b-9726-2921960e677f": {
                    "authors": [
                        "Jimmy J. Lin",
                        "Michael C. Schatz"
                    ],
                    "references": [
                        "2ef8d7bb-3451-49fe-ba1d-70dc6a9786ab",
                        "2f2a347d-cc88-483a-9723-7767c6046ee0",
                        "3260aa32-5e36-4e4c-9733-2656e475a87a",
                        "3815ecae-4044-4bcf-92e4-cc910289489b",
                        "5002dd27-9ce6-4abb-a3d0-2ac112f58c37",
                        "5757135f-8be1-4e31-b024-7c8dfe56b059",
                        "59af7e25-c0ee-4af5-acea-a58dfe4ccac4",
                        "64df1833-928f-443a-81e0-4ded006e1477",
                        "66d033c4-7d3c-4e06-8d5e-f1841d4d5c3b",
                        "6b7cb833-15a7-44b6-b488-94e3bb251e16",
                        "8f9e92cf-f266-4e51-807f-c098a260a0dc",
                        "92d18205-9a2f-422f-9fe4-4c90e16d1d9f",
                        "bef7bb6a-0193-47e2-97b5-61512ba0528b",
                        "c7e4e04b-45da-4bae-8c8a-d17ca0087361",
                        "def05aeb-0e78-4703-ab9d-3f6a57f83c81"
                    ],
                    "keyword": [
                        "graphs",
                        "web",
                        "patterns",
                        "pagerank",
                        "networks",
                        "mapreduce",
                        "large",
                        "edges",
                        "distributed",
                        "design"
                    ],
                    "group": [],
                    "_id": "6e1947dd-2997-481b-9726-2921960e677f",
                    "abstract": "Graphs are analyzed in many important contexts, including ranking search results based on the hyperlink structure of the world wide web, module detection of proteinprotein interaction networks, and privacy analysis of social networks. Many graphs of interest are difficult to analyze because of their large size, often spanning millions of vertices and billions of edges. As such, researchers have increasingly turned to distributed solutions. In particular, MapReduce has emerged as an enabling technology for large-scale graph processing. However, existing best practices for MapReduce graph algorithms have significant shortcomings that limit performance, especially with respect to partitioning, serializing, and distributing the graph. In this paper, we present three design patterns that address these issues and can be used to accelerate a large class of graph algorithms based on message passing, exemplified by PageRank. Experiments show that the application of our design patterns reduces the running time of PageRank on a web graph with 1.4 billion edges by 69%.",
                    "title": "Design patterns for efficient graph algorithms in MapReduce",
                    "venue": "mining and learning with graphs",
                    "year": 2010,
                    "__v": 1,
                    "citationCount": 85,
                    "result": 3.0922091412803483
                },
                "7298a617-55f9-4bdb-be57-7e83349bb530": {
                    "authors": [
                        "Hao Zhu",
                        "Alfonso Cano",
                        "Georgios B. Giannakis"
                    ],
                    "references": [
                        "2ca8a212-1179-4f68-bc20-8f2d8848585a",
                        "81a60c6f-2102-4b93-b991-00814ab480f4",
                        "848ad555-7a71-4695-bd6d-fe3743d43c9d",
                        "cb183c24-19cc-4498-b1bb-695f7fbb8736",
                        "cc530def-5371-452e-8c93-ae69e490be0f",
                        "d7b5aadf-ec30-4fb7-9224-7474169d3744",
                        "ea1d5c21-fba6-4fae-9fdc-ee7679ee46c9",
                        "ff2ae0dd-048c-4048-8d6f-dfa2382c396b"
                    ],
                    "keyword": [
                        "demodulation",
                        "distributed",
                        "sensor",
                        "algorithms",
                        "iteratively",
                        "error",
                        "performance"
                    ],
                    "group": [],
                    "_id": "7298a617-55f9-4bdb-be57-7e83349bb530",
                    "abstract": "This paper deals with distributed demodulation of space-time transmissions of a common message from a multi-antenna access point (AP) to a wireless sensor network. Based on local message exchanges with single-hop neighboring sensors, two algorithms are developed for distributed demodulation. In the first algorithm, sensors consent on the estimated symbols. By relaxing the finite-alphabet constraints on the symbols, the demodulation task is formulated as a distributed convex optimization problem that is solved iteratively using the method of multipliers. Distributed versions of the centralized zero-forcing (ZF) and minimum mean-square error (MMSE) demodulators follow as special cases. In the second algorithm, sensors iteratively reach consensus on the average (cross-) covariances of locally available per-sensor data vectors with the corresponding AP-to-sensor channel matrices, which constitute sufficient statistics for maximum likelihood demodulation. Distributed versions of the sphere decoding algorithm and the ZF/MMSE demodulators are also developed. These algorithms offer distinct merits in terms of error performance and resilience to non-ideal inter-sensor links. In both cases, the per-iteration error performance is analyzed, and the approximate number of iterations needed to attain a prescribed error rate are quantified. Simulated tests verify the analytical claims. Interestingly, only a few consensus iterations (roughly as many as the number of sensors), suffice for the distributed demodulators to approach the performance of their centralized counterparts.",
                    "title": "Distributed consensus-based demodulation: algorithms and error analysis",
                    "venue": "IEEE Transactions on Wireless Communications",
                    "year": 2010,
                    "__v": 2,
                    "citationCount": 23,
                    "result": 5.192236204465307
                },
                "74b9aa5f-e5e4-4789-a5ca-254030320eca": {
                    "authors": [
                        "Stephen Becker",
                        "J. Bobin",
                        "Emmanuel J. Candès"
                    ],
                    "references": [
                        "0a0ecabb-d669-4ffd-8441-3267d8d9c370",
                        "109367fa-db04-4db0-8777-d6ca7e9e78fd",
                        "1112d936-cb10-4c0c-9eec-b4fd8f5a5c7f",
                        "13e032c3-94bb-4e3e-abea-63934bf9715e",
                        "28e6e848-a661-40bd-8667-630e8575016a",
                        "31c883b9-75b1-4ea6-b9e2-776cc33a287f",
                        "3f90046c-1c24-4a11-abc5-831c4d30f660",
                        "4289bfe3-7305-41e5-a19d-8f0dd37e9892",
                        "509ba4be-958f-4496-afc2-bbd0e59b50c3",
                        "52e55346-2fb4-45a8-9e50-db06f3343982",
                        "71a18de9-e543-4337-ab7a-3db31d9f8c00",
                        "7292eb6c-3d6a-4a17-b837-c1d74e849044",
                        "7db1957b-66a4-439f-a9bd-ca89aea58642",
                        "821801cc-6928-44ea-997c-b9d5dfb60b8e",
                        "9b166075-5b89-4ec5-91db-47e5ca47c7ec",
                        "9beb72f3-d857-4a45-8291-e2361b7de8f9",
                        "a4c6f436-a7a0-40b5-8a2c-fb2c1a3df2fc",
                        "a53a3dda-b003-4d5c-96b1-e9afd8e35692",
                        "a6afe815-62b7-4894-b996-c13cc4aebe69",
                        "bd958d1d-2300-4c62-ad95-15c4d59df588",
                        "e6b4b4b8-6ed2-4be1-9463-dcd516752044",
                        "e7af7694-28e7-4b6a-b23c-b7f4f8647ed2",
                        "f0c0249b-4cef-436c-904f-1d70ef15d300",
                        "f56b877b-4060-4754-b303-e8140968544c"
                    ],
                    "keyword": [
                        "problems",
                        "sensing",
                        "reconstruction",
                        "algorithm",
                        "solving",
                        "signal",
                        "range",
                        "program",
                        "minimization",
                        "compressed"
                    ],
                    "group": [],
                    "_id": "74b9aa5f-e5e4-4789-a5ca-254030320eca",
                    "abstract": "Accurate signal recovery or image reconstruction from indirect and possibly undersampled data is a topic of considerable interest; for example, the literature in the recent field of compressed sensing is already quite immense. This paper applies a smoothing technique and an accelerated first-order algorithm, both from Nesterov [Math. Program. Ser. A, 103 (2005), pp. 127-152], and demonstrates that this approach is ideally suited for solving large-scale compressed sensing reconstruction problems as (1) it is computationally efficient, (2) it is accurate and returns solutions with several correct digits, (3) it is flexible and amenable to many kinds of reconstruction problems, and (4) it is robust in the sense that its excellent performance across a wide range of problems does not depend on the fine tuning of several parameters. Comprehensive numerical experiments on realistic signals exhibiting a large dynamic range show that this algorithm compares favorably with recently proposed state-of-the-art methods. We also apply the algorithm to solve other problems for which there are fewer alternatives, such as total-variation minimization and convex programs seeking to minimize the $\\ell_1$ norm of $Wx$ under constraints, in which $W$ is not diagonal. The code is available online as a free package in the MATLAB language.",
                    "title": "NESTA: A Fast and Accurate First-Order Method for Sparse Recovery",
                    "venue": "Siam Journal on Imaging Sciences",
                    "year": 2011,
                    "__v": 1,
                    "citationCount": 260,
                    "result": 7.228304921089952
                },
                "7a7b52f0-82db-4e16-9df0-d3f5b5c7b5c5": {
                    "authors": [
                        "Pedro A. Forero",
                        "Alfonso Cano",
                        "Georgios B. Giannakis"
                    ],
                    "references": [
                        "0c426c09-06f7-4427-95c7-21d181f764c7",
                        "16e72af5-d349-47f8-98db-19c870c7da35",
                        "1ab94a0d-992c-4001-93c6-70a4ac1251e8",
                        "2c1c7fb1-f6d6-4a5c-8aa6-3b6c550b4bd7",
                        "3808738a-4a0a-4586-858f-7c8b902482ea",
                        "38500fe9-7c31-4a6a-aa20-fc96325f2946",
                        "4ac215da-bb39-445c-9759-ebdb3faf472e",
                        "4b2f8b2f-13e1-49ec-992b-c0a6e309a747",
                        "7e60e052-c4ed-43e6-856f-2d28110678bb",
                        "7f0c5d44-512f-4945-8be8-e3a08647df3d",
                        "81a60c6f-2102-4b93-b991-00814ab480f4",
                        "83dfb6ca-659f-4f84-99fb-f11e16d88552",
                        "86f4a8cd-6950-4859-b208-4845d4797c09",
                        "95b79d07-9a9c-455b-8bca-c319cb627fed",
                        "99b7c24b-5497-4e2b-a2af-60d28855228f",
                        "a083a1b9-8dfb-45d6-99a9-fa30c4a6e9f5",
                        "a3c09cac-7e2e-4164-a338-39d6b40863a9",
                        "b3d38c4e-534f-48e1-a66d-1c1d9bbc4432",
                        "d46030de-64f6-4c74-9590-d84bce63e325",
                        "d56f9124-582d-4266-bec3-3c6f543cb9e8"
                    ],
                    "keyword": [
                        "train",
                        "nodes",
                        "distributed",
                        "communication",
                        "algorithms",
                        "set",
                        "processing",
                        "develops",
                        "data",
                        "centralized"
                    ],
                    "group": [],
                    "_id": "7a7b52f0-82db-4e16-9df0-d3f5b5c7b5c5",
                    "abstract": "This paper develops algorithms to train support vector machines when training data are distributed across different nodes, and their communication to a centralized processing unit is prohibited due to, for example, communication complexity, scalability, or privacy reasons. To accomplish this goal, the centralized linear SVM problem is cast as a set of decentralized convex optimization sub-problems (one per node) with consensus constraints on the wanted classifier parameters. Using the alternating direction method of multipliers, fully distributed training algorithms are obtained without exchanging training data among nodes. Different from existing incremental approaches, the overhead associated with inter-node communications is fixed and solely dependent on the network topology rather than the size of the training sets available per node. Important generalizations to train nonlinear SVMs in a distributed fashion are also developed along with sequential variants capable of online processing. Simulated tests illustrate the performance of the novel algorithms.",
                    "title": "Consensus-Based Distributed Support Vector Machines",
                    "venue": "Journal of Machine Learning Research",
                    "year": 2010,
                    "__v": 2,
                    "citationCount": 81,
                    "result": 6.284271264191173
                },
                "7b7510c9-1506-4153-b2df-6aa1242e22ef": {
                    "authors": [
                        "Kwangmoo Koh",
                        "Seung-Jean Kim",
                        "Stephen P. Boyd"
                    ],
                    "references": [
                        "0ed45fd4-4061-4da8-8336-b660c9fc4806",
                        "213f47bd-0cda-46c9-9741-e8e0cf51bccc",
                        "3bb12f05-eac9-4cb6-b17f-46c596577d65",
                        "3c878dd1-ba36-4065-9d07-8bda3896977d",
                        "4e5e46d1-6ade-4145-9e32-4904bd35a15f",
                        "634d3f58-79ee-4319-b122-63cb62146f53",
                        "752b99b8-077e-4310-a851-5b78d13aaf04",
                        "800c39c6-36d9-4e11-a337-c0b69c05e60d",
                        "951a9708-9bf2-4cbf-a3e1-5b8f89f8387b",
                        "adc31a96-1f8e-4793-8ee9-ecef04a16ac6",
                        "b7850d71-2cee-4c3b-9d53-216d63ca0515",
                        "c8896a36-2eac-4edc-8f42-7c281b2e6734",
                        "e824de4f-874c-4d8f-8246-af26ef67e276",
                        "eb957b6d-4f22-4f13-94cc-847210fad714",
                        "f25387ae-9025-409c-a8fd-a8a7c9cb23c6",
                        "f2c1bdc4-bfb6-4c97-8efd-04bc4937adca"
                    ],
                    "keyword": [
                        "problems",
                        "solving",
                        "method",
                        "feature",
                        "examples",
                        "thousand",
                        "tens",
                        "regularization",
                        "regression",
                        "pc"
                    ],
                    "group": [],
                    "_id": "7b7510c9-1506-4153-b2df-6aa1242e22ef",
                    "abstract": "Logistic regression with l1 regularization has been proposed as a promising method for feature selection in classification problems. In this paper we describe an efficient interior-point method for solving large-scale l1-regularized logistic regression problems. Small problems with up to a thousand or so features and examples can be solved in seconds on a PC; medium sized problems, with tens of thousands of features and examples, can be solved in tens of seconds (assuming some sparsity in the data). A variation on the basic method, that uses a preconditioned conjugate gradient method to compute the search step, can solve very large problems, with a million features and examples (e.g., the 20 Newsgroups data set), in a few minutes, on a PC. Using warm-start techniques, a good approximation of the entire regularization path can be computed much more efficiently than by solving a family of problems independently.",
                    "title": "An Interior-Point Method for Large-Scale l 1 -Regularized Logistic Regression",
                    "venue": "Journal of Machine Learning Research",
                    "year": 2007,
                    "__v": 1,
                    "citationCount": 198,
                    "result": 5.2309272568863365
                },
                "81a60c6f-2102-4b93-b991-00814ab480f4": {
                    "authors": [
                        "Hao Zhu",
                        "Georgios B. Giannakis",
                        "Alfonso Cano"
                    ],
                    "references": [
                        "2768199c-b9d6-4001-94d3-e6429c93bc5f",
                        "2ca8a212-1179-4f68-bc20-8f2d8848585a",
                        "521c76bb-713a-4db0-a543-6ef506f7b0d1",
                        "7163a2a6-5de8-45f1-9d1a-1db21883a5a5",
                        "d7b5aadf-ec30-4fb7-9224-7474169d3744",
                        "ea1d5c21-fba6-4fae-9fdc-ee7679ee46c9",
                        "f02e7866-3bf9-441c-9cd5-a059c7bb2638",
                        "f56dbdc3-f2ee-4a66-a3fb-df142f830dc5"
                    ],
                    "keyword": [
                        "decoding",
                        "sensor",
                        "iterative",
                        "perform",
                        "llrs",
                        "distributed",
                        "consensus",
                        "average",
                        "probability",
                        "links"
                    ],
                    "group": [],
                    "_id": "81a60c6f-2102-4b93-b991-00814ab480f4",
                    "abstract": "Average log-likelihood ratios (LLRs) constitute sufficient statistics for centralized maximum-likelihood block decoding as well as for  a   posteriori  probability evaluation which enables bit-wise (possibly iterative) decoding. By acquiring such average LLRs per sensor it becomes possible to perform these decoding tasks in a low-complexity  distributed  fashion using wireless sensor networks. At affordable communication overhead, the resultant distributed decoders rely on local message exchanges among single-hop neighboring sensors to achieve iteratively consensus on the average LLRs per sensor. Furthermore, the decoders exhibit robustness to non-ideal inter-sensor links affected by additive noise and random link failures. Pairwise error probability bounds benchmark the decoding performance as a function of the number of consensus iterations. Interestingly, simulated tests corroborating the analytical findings demonstrate that only a few consensus iterations suffice for the novel distributed decoders to approach the performance of their centralized counterparts.",
                    "title": "Distributed In-Network Channel Decoding",
                    "venue": "IEEE Transactions on Signal Processing",
                    "year": 2009,
                    "__v": 2,
                    "citationCount": 41,
                    "result": 4.193168149824496
                },
                "839e59b8-b356-4329-ba79-97f981cf6768": {
                    "authors": [
                        "Daniel D. Lee",
                        "H. Sebastian Seung"
                    ],
                    "references": [
                        "328aafa9-db5d-4ac4-9338-fe918ea60f42",
                        "5cd74e0b-f25c-4aaf-8327-7ec949c7d098",
                        "9707d672-9d01-4f8e-bfa0-028ed63f0837",
                        "b0217d71-3709-4ada-a5de-a78af1de2e02",
                        "cd17473b-9aec-4099-bf27-b116490b43ea"
                    ],
                    "keyword": [
                        "algorithms",
                        "factorization",
                        "convergence",
                        "shown",
                        "rescaled",
                        "nmf",
                        "multiplicative",
                        "minimize"
                    ],
                    "group": [],
                    "_id": "839e59b8-b356-4329-ba79-97f981cf6768",
                    "abstract": "Non-negative matrix factorization (NMF) has previously been shown to be a useful decomposition for multivariate data. Two different multiplicative algorithms for NMF are analyzed. They differ only slightly in the multiplicative factor used in the update rules. One algorithm can be shown to minimize the conventional least squares error while the other minimizes the generalized Kullback-Leibler divergence. The monotonic convergence of both algorithms can be proven using an auxiliary function analogous to that used for proving convergence of the Expectation-Maximization algorithm. The algorithms can also be interpreted as diagonally rescaled gradient descent, where the rescaling factor is optimally chosen to ensure convergence.",
                    "title": "Algorithms for Non-negative Matrix Factorization",
                    "venue": "neural information processing systems",
                    "year": 2001,
                    "__v": 2,
                    "citationCount": 2397,
                    "result": 4.678437780941484
                },
                "861e877e-3903-4aed-827a-5a501858f17b": {
                    "authors": [
                        "R. T. Rockafellar"
                    ],
                    "references": [
                        "732d70fd-372e-4100-94bd-6e2c3890e342",
                        "ea7809b4-357e-45aa-99a2-1174710909b3"
                    ],
                    "keyword": [
                        "algorithm",
                        "proximal",
                        "multipliers",
                        "method",
                        "theory",
                        "strong",
                        "standard",
                        "sort",
                        "solving",
                        "shown"
                    ],
                    "group": [],
                    "_id": "861e877e-3903-4aed-827a-5a501858f17b",
                    "abstract": "The theory of the proximal point algorithm for maximal monotone operators is applied to three algorithms for solving convex programs, one of which has not previously been formulated. Rate-of-convergence results for the “method of multipliers,” of the strong sort already known, are derived in a generalized form relevant also to problems beyond the compass of the standard second-order conditions for oplimality. The new algorithm, the “proximal method of multipliers,” is shown to have much the same convergence properties, but with some potential advantages.",
                    "title": "Augmented Lagrangians and Applications of the Proximal Point Algorithm in Convex Programming",
                    "venue": "Mathematics of Operations Research",
                    "year": 1976,
                    "__v": 2,
                    "citationCount": 238,
                    "result": 5.810185033404848
                },
                "87b16469-4b10-41e5-8dfc-2381a6592bfb": {
                    "authors": [
                        "Heinz H. Bauschke",
                        "Jonathan M. Borwein"
                    ],
                    "references": [
                        "039c3781-16d5-495c-8ce9-3509ee45bdcb",
                        "37dd6f1d-e2d7-425e-bb54-74fc065a5c41",
                        "53176414-fd39-4c63-addc-98e85ea3d9d5",
                        "7a3f78e9-10b1-4af5-a2e3-1f8a24604cae",
                        "90b4a555-4028-44c1-95ca-00324424d670",
                        "ad1a13e4-f8fe-44cd-abb5-f1cd799bee73",
                        "f7b8ecd4-0046-4609-a0d3-81ed6e3ea80d",
                        "fa11f0ce-ef2b-435c-846d-85842c5b5ab0",
                        "fde876f9-4b46-418d-b33c-922a29f7ad6b"
                    ],
                    "keyword": [
                        "generalize",
                        "broad",
                        "algorithms",
                        "utility",
                        "unify",
                        "tomography",
                        "systematic",
                        "spaces",
                        "solving",
                        "sciences"
                    ],
                    "group": [],
                    "_id": "87b16469-4b10-41e5-8dfc-2381a6592bfb",
                    "abstract": "Due to their extraordinary utility and broad applicability in many areas of classical mathematics and modern physical sciences (most notably, computerized tomography), algorithms for solving convex feasibility problems continue to receive great attention. To unify, generalize, and review some of these algorithms, a very broad and flexible framework is investigated. Several crucial new concepts which allow a systematic discussion of questions on behaviour in general Hilbert spaces and on the quality of convergence are brought out. Numerous examples are given.",
                    "title": "On Projection Algorithms for Solving Convex Feasibility Problems",
                    "venue": "Siam Review",
                    "year": 1996,
                    "__v": 1,
                    "citationCount": 290,
                    "result": 4.350472274543482
                },
                "92a22c32-9559-496a-b35c-813407edd134": {
                    "authors": [
                        "Jonathan Eckstein",
                        "B. F. Svaiter"
                    ],
                    "references": [
                        "0435b723-134f-4036-ab7e-f3c21ce63e24",
                        "202fdedc-8e8c-47e6-8bca-2a320f877b6d",
                        "87b16469-4b10-41e5-8dfc-2381a6592bfb",
                        "a012a24d-aa95-4049-b628-e606a0d007e9",
                        "b2425f3b-5b13-483a-8fd1-fdf13fa238fd",
                        "b8321e4f-ccae-433a-984e-7567535ff293"
                    ],
                    "keyword": [
                        "operators",
                        "n2",
                        "evaluating",
                        "vary",
                        "resolvent",
                        "projective",
                        "problem",
                        "prior",
                        "methods",
                        "iteration"
                    ],
                    "group": [],
                    "_id": "92a22c32-9559-496a-b35c-813407edd134",
                    "abstract": "We describe a general projective framework for finding a zero of the sum of $n$ maximal monotone operators over a real Hilbert space. Unlike prior methods for this problem, we neither assume $n=2$ nor first reduce the problem to the case $n=2$. Our analysis defines a closed convex extended solution set for which we can construct a separating hyperplane by individually evaluating the resolvent of each operator. At the cost of a single, computationally simple projection step, this framework gives rise to a family of splitting methods of unprecedented flexibility: numerous parameters, including the proximal stepsize, may vary by iteration and by operator. The order of operator evaluation may vary by iteration and may be either serial or parallel. The analysis essentially generalizes our prior results for the case $n=2$. We also include a relative error criterion for approximately evaluating resolvents, which was not present in our earlier work.",
                    "title": "General Projective Splitting Methods for Sums of Maximal Monotone Operators",
                    "venue": "Siam Journal on Control and Optimization",
                    "year": 2009,
                    "__v": 1,
                    "citationCount": 21,
                    "result": 6.560336182008008
                },
                "94e82a1e-656e-45d6-8b4e-1315c2e94fba": {
                    "authors": [
                        "Ioannis D. Schizas",
                        "Georgios B. Giannakis",
                        "Stergios I. Roumeliotis",
                        "Alejandro Ribeiro"
                    ],
                    "references": [
                        "0aed8a11-15e1-4915-9563-f672e773dac6",
                        "2768199c-b9d6-4001-94d3-e6429c93bc5f",
                        "2ca8a212-1179-4f68-bc20-8f2d8848585a",
                        "716fbc8b-74dc-4837-88f5-5f2c83e66c7e",
                        "839602ef-a406-4282-9aa2-29ef2231e281",
                        "8cc9ea80-563f-4e62-bda9-8ff6d71cf6ae",
                        "acf627e1-384b-4a35-acac-67ea223c0d33",
                        "b3b2c754-23c2-4f6d-aeea-b726976d2bfc",
                        "bae3c792-4ffa-4473-8675-f760a81044ba",
                        "bb352f7c-946c-4518-9e58-820cbc146657",
                        "cc259597-c637-451f-96ae-dd92d7f697c9",
                        "d63f6c2b-219a-4150-851a-1cbf744a7e61",
                        "d7b5aadf-ec30-4fb7-9224-7474169d3744"
                    ],
                    "keyword": [
                        "estimation",
                        "distributed",
                        "communicate"
                    ],
                    "group": [],
                    "_id": "94e82a1e-656e-45d6-8b4e-1315c2e94fba",
                    "abstract": "Distributed algorithms are developed for optimal estimation of stationary random signals and smoothing of (even nonstationary) dynamical processes based on generally correlated observations collected by ad hoc wireless sensor networks (WSNs). Maximum a posteriori (MAP) and linear minimum mean-square error (LMMSE) schemes, well appreciated for centralized estimation, are shown possible to reformulate for distributed operation through the iterative (alternating-direction) method of multipliers. Sensors communicate with single-hop neighbors their individual estimates as well as multipliers measuring how far local estimates are from consensus. When iterations reach consensus, the resultant distributed (D) MAP and LMMSE estimators converge to their centralized counterparts when inter-sensor communication links are ideal. The D-MAP estimators do not require the desired estimator to be expressible in closed form, the D-LMMSE ones are provably robust to communication or quantization noise and both are particularly simple to implement when the data model is linear-Gaussian. For decentralized tracking applications, distributed Kalman filtering and smoothing algorithms are derived for any-time MMSE optimal consensus-based state estimation using WSNs. Analysis and corroborating numerical examples demonstrate the merits of the novel distributed estimators.",
                    "title": "Consensus in Ad Hoc WSNs With Noisy Links—Part II: Distributed Estimation and Smoothing of Random Signals",
                    "venue": "IEEE Transactions on Signal Processing",
                    "year": 2008,
                    "__v": 1,
                    "citationCount": 88,
                    "result": 3.392512149478094
                },
                "9b166075-5b89-4ec5-91db-47e5ca47c7ec": {
                    "authors": [
                        "Tom Goldstein",
                        "Stanley Osher"
                    ],
                    "references": [
                        "2ad802e0-dfe8-401c-b42f-0cfc575a4801",
                        "3f90046c-1c24-4a11-abc5-831c4d30f660",
                        "509ba4be-958f-4496-afc2-bbd0e59b50c3",
                        "5c6cd648-83ab-41c1-9bb7-95d4040a412a",
                        "67f4c84e-a224-43e6-a81c-342c56c6d15b",
                        "6aebafce-f4c0-4a34-8a36-b9ede925fb8e",
                        "a53a3dda-b003-4d5c-96b1-e9afd8e35692",
                        "dba51c0d-9e96-49a4-a2bf-722fd03f6fa1",
                        "efa407cf-e88f-4de5-9d4a-c66b0802d5ea",
                        "f56b877b-4060-4754-b303-e8140968544c",
                        "fb3eb505-20cf-4163-b5f9-c95dae0ff98f"
                    ],
                    "keyword": [
                        "problems",
                        "techniques",
                        "solve",
                        "l1regularized",
                        "images",
                        "sensing",
                        "optimization",
                        "compressed",
                        "class",
                        "bregman"
                    ],
                    "group": [],
                    "_id": "9b166075-5b89-4ec5-91db-47e5ca47c7ec",
                    "abstract": "The class of L1-regularized optimization problems has received much attention recently because of the introduction of “compressed sensing,” which allows images and signals to be reconstructed from small amounts of data. Despite this recent attention, many L1-regularized problems still remain difficult to solve, or require techniques that are very problem-specific. In this paper, we show that Bregman iteration can be used to solve a wide variety of constrained optimization problems. Using this technique, we propose a “split Bregman” method, which can solve a very broad class of L1-regularized problems. We apply this technique to the Rudin-Osher-Fatemi functional for image denoising and to a compressed sensing problem that arises in magnetic resonance imaging.",
                    "title": "The Split Bregman Method for L1-Regularized Problems",
                    "venue": "Siam Journal on Imaging Sciences",
                    "year": 2009,
                    "__v": 2,
                    "citationCount": 869,
                    "result": 4.984241976919321
                },
                "9c7174a1-3c73-4a2e-a78b-b23816830420": {
                    "authors": [
                        "Angelia Nedic",
                        "Asuman E. Ozdaglar"
                    ],
                    "references": [
                        "0018ed74-be27-461d-9d42-ae05ec0f8bd3",
                        "13c9856f-e4f8-4c1c-b728-c8ccff9b7b4b",
                        "2768199c-b9d6-4001-94d3-e6429c93bc5f",
                        "4014a440-363a-4a73-b102-de8c45f1b06b",
                        "53b5788a-1b16-42ab-8502-070c17c4af18",
                        "860a3efc-800e-4e62-8200-7acf3f8d2b8d",
                        "8fd6531b-c809-4e63-895b-fb91be11759d",
                        "bca0bb44-aa53-4e36-bd83-e6570150e5c7",
                        "d340974e-775f-48f4-a83d-754e7d5b35db",
                        "dadfa87e-535b-42fa-be7f-61d24458ede4",
                        "ea1d5c21-fba6-4fae-9fdc-ee7679ee46c9",
                        "fc7e044a-e74a-40b5-958d-d7d3e6d2f847"
                    ],
                    "keyword": [
                        "agents",
                        "optimizing",
                        "method",
                        "convergence",
                        "subgradient",
                        "results",
                        "rate",
                        "objective",
                        "functions",
                        "distributed"
                    ],
                    "group": [],
                    "_id": "9c7174a1-3c73-4a2e-a78b-b23816830420",
                    "abstract": "We study a distributed computation model for optimizing a sum of convex objective functions corresponding to multiple agents. For solving this (not necessarily smooth) optimization problem, we consider a subgradient method that is distributed among the agents. The method involves every agent minimizing his/her own objective function while exchanging information locally with other agents in the network over a time-varying topology. We provide convergence results and convergence rate estimates for the subgradient method. Our convergence rate results explicitly characterize the tradeoff between a desired accuracy of the generated approximate optimal solutions and the number of iterations needed to achieve the accuracy.",
                    "title": "Distributed Subgradient Methods for Multi-Agent Optimization",
                    "venue": "IEEE Transactions on Automatic Control",
                    "year": 2009,
                    "__v": 1,
                    "citationCount": 527,
                    "result": 5.045605246379241
                },
                "9e7f3a14-e586-4bad-aab9-0c36173e441d": {
                    "authors": [
                        "Leslie G. Valiant"
                    ],
                    "references": [
                        "0df046c4-ec86-4010-ba2a-de94fc2f289d",
                        "1a4847f4-b1b0-4c9e-975f-64d1d5f431a4",
                        "29695034-3d53-42f9-a1e0-f3776f815277",
                        "3295d02a-ee89-4593-9689-4f21f47c226c",
                        "53cbd5d8-6219-48f6-bcb6-4d68158d9f41",
                        "67c269bd-76b2-4f69-a34d-055c873742f5",
                        "6f7fd60c-4775-40a5-94d0-6dc3ed6c0de1",
                        "74545c96-0833-4ef6-b239-6e50365e0c8a",
                        "7adb6c08-54e8-4b31-8965-a1817590477f",
                        "97771ada-e429-43be-b8b7-4db90a84e92a",
                        "98006e99-fc89-4eac-a0d4-e30c16a76587",
                        "9fc52d0d-7ce7-4c0d-9a61-3d93d5332479",
                        "abf003a2-6485-41f0-a111-88b80412d539",
                        "b7dad633-ef3a-4d51-a3b1-c27bab02f7f1",
                        "c52c9dc3-78d1-4782-b5f9-d65a545cdc64",
                        "cd6c7231-bb2c-4068-997c-b9a39991fd29"
                    ],
                    "keyword": [
                        "hardware",
                        "model",
                        "implemented",
                        "efficient",
                        "software",
                        "parallel",
                        "languages",
                        "highlevel",
                        "computation",
                        "bridge"
                    ],
                    "group": [],
                    "_id": "9e7f3a14-e586-4bad-aab9-0c36173e441d",
                    "abstract": "The success of the von Neumann model of sequential computation is attributable to the fact that it is an efficient bridge between software and hardware: high-level languages can be efficiently compiled on to this model; yet it can be effeciently implemented in hardware. The author argues that an analogous bridge between software and hardware in required for parallel computation if that is to become as widely used. This article introduces the bulk-synchronous parallel (BSP) model as a candidate for this role, and gives results quantifying its efficiency both in implementing high-level language features and algorithms, as well as in being implemented in hardware.",
                    "title": "A bridging model for parallel computation",
                    "venue": "Communications of The ACM",
                    "year": 1990,
                    "__v": 1,
                    "citationCount": 1549,
                    "result": 3.5459015185021374
                },
                "a012a24d-aa95-4049-b628-e606a0d007e9": {
                    "authors": [
                        "Jonathan Eckstein",
                        "Michael C. Ferris"
                    ],
                    "references": [
                        "0ab6d92b-44d2-44da-b029-39e138eb1216",
                        "40c1d1cd-3597-4d33-9741-1455378b7deb",
                        "824f6ee7-010a-48c9-8237-91a655c8ae19",
                        "8d3c217b-f72e-4dbe-8d24-b60d13064ce3",
                        "92d90be6-6f3e-4e3d-91f8-3495d8f72652",
                        "b8321e4f-ccae-433a-984e-7567535ff293",
                        "fecc9394-c6a5-4023-ab8e-23029138de77"
                    ],
                    "keyword": [
                        "splitting",
                        "operators",
                        "monotone",
                        "algorithms",
                        "affine",
                        "variational",
                        "special",
                        "results",
                        "problem",
                        "inequalities"
                    ],
                    "group": [],
                    "_id": "a012a24d-aa95-4049-b628-e606a0d007e9",
                    "abstract": "This article applies splitting techniques developed for set-valued maximal monotone operators to monotone affine variational inequalities, including, as a special case, the classical linear complementarity problem. We give a unified presentation of several splitting algorithms for monotone operators, and then apply these results to obtain two classes of algorithms for affine variational inequalities. The second class resembles classical matrix splitting, but has a novel \"under-relaxation\" step, and converges under more general conditions. In particular, the convergence proofs do not require the affine operator to be symmetric. We specialize our matrix-splitting-like method to discrete-time optimal control problems formulated as extended linear-quadratic programs in the manner advocated by Rockafellar and Wets. The result is a highly parallel algorithm, which we implement and test on the Connection Machine CM-5 computer family.",
                    "title": "Operator-Splitting Methods for Monotone Affine Variational Inequalities, with a Parallel Application to Optimal Control",
                    "venue": "Informs Journal on Computing",
                    "year": 1998,
                    "__v": 2,
                    "citationCount": 17,
                    "result": 6.592251376539301
                },
                "a06aef17-2b53-4dbd-ba4b-d15fdd44ba51": {
                    "authors": [
                        "Zhaosong Lu",
                        "Ting Kei Pong",
                        "Yong Zhang"
                    ],
                    "references": [
                        "14f5048e-d6ef-4f72-aa8a-9731386e688a",
                        "1d7626c6-6baa-4a80-98ce-7e996ead2bc7",
                        "222a6691-bab9-47ed-b96f-29b548152bf4",
                        "2d5e8c4c-8421-4d8b-b07e-0ffc7a60f544",
                        "4e517fa8-b591-4f4d-85f9-f2fa81e81984",
                        "5b92842e-1023-4c80-99a2-23b15a78c58c",
                        "6c259b28-876b-4c64-971a-677bbaeab2a6",
                        "81464590-4d68-4583-969f-8f0814b53088",
                        "b769d0a9-3824-4f46-b6f0-13fdd870ccc1",
                        "b8321e4f-ccae-433a-984e-7567535ff293",
                        "d1aafff0-1471-4ddc-9bb0-9a313bd8fbc1",
                        "e43307d3-7ab9-4b31-b84d-c714f44bc9d2",
                        "fb119fc6-1888-46f6-afa1-986818615b80",
                        "fe8f9b93-3674-44e0-bc45-e4042509cf96"
                    ],
                    "keyword": [
                        "method",
                        "proposed",
                        "compare",
                        "approach",
                        "zhang",
                        "time",
                        "terms",
                        "tao",
                        "subproblem",
                        "study"
                    ],
                    "group": [],
                    "_id": "a06aef17-2b53-4dbd-ba4b-d15fdd44ba51",
                    "abstract": "In this paper, we study the alternating direction method for finding the Dantzig selectors, which are first introduced in Candes and Tao (2007a). In particular, at each iteration we apply the nonmonotone gradient method proposed in Lu and Zhang (in press) to approximately solve one subproblem of this method. We compare our approach with a first-order method proposed in Becker et al. (2011). The computational results show that our approach usually outperforms that method in terms of CPU time while producing solutions of comparable quality.",
                    "title": "An alternating direction method for finding Dantzig selectors",
                    "venue": "Computational Statistics & Data Analysis",
                    "year": 2012,
                    "__v": 2,
                    "citationCount": 11,
                    "result": 5.272407838584309
                },
                "a53a3dda-b003-4d5c-96b1-e9afd8e35692": {
                    "authors": [
                        "Emmanuel J. Candès",
                        "Justin K. Romberg",
                        "Terence Tao"
                    ],
                    "references": [
                        "2d75f21b-8617-4c21-a1bf-467a82458459",
                        "4114181f-6f48-4cb6-b6d3-b337515d57f8",
                        "449bfdfc-f916-422c-ac0d-ebfdd2ab773a",
                        "53c1d13a-863d-4db2-bc77-bbc7f8a45fa8",
                        "5eb8608d-d0a1-4f14-af98-8a26bab51fae",
                        "7291a02d-1d94-48b7-a4e2-35406c0e52ad",
                        "87a4faed-c1a5-45c8-81eb-3bf19ae19011",
                        "d2104367-6389-4b06-8dbe-bab7e05b903b",
                        "f11bfae2-e272-4acc-b231-a9619f1e4d6c"
                    ],
                    "keyword": [
                        "spl",
                        "frequency",
                        "samples",
                        "reconstructing",
                        "spikes",
                        "set",
                        "problem",
                        "probability",
                        "omega",
                        "convex"
                    ],
                    "group": [
                        null
                    ],
                    "_id": "a53a3dda-b003-4d5c-96b1-e9afd8e35692",
                    "abstract": "This paper considers the model problem of reconstructing an object from incomplete frequency samples. Consider a discrete-time signal f/spl isin/C/sup N/ and a randomly chosen set of frequencies /spl Omega/. Is it possible to reconstruct f from the partial knowledge of its Fourier coefficients on the set /spl Omega/? A typical result of this paper is as follows. Suppose that f is a superposition of |T| spikes f(t)=/spl sigma//sub /spl tau//spl isin/T/f(/spl tau/)/spl delta/(t-/spl tau/) obeying |T|/spl les/C/sub M//spl middot/(log N)/sup -1/ /spl middot/ |/spl Omega/| for some constant C/sub M/>0. We do not know the locations of the spikes nor their amplitudes. Then with probability at least 1-O(N/sup -M/), f can be reconstructed exactly as the solution to the /spl lscr//sub 1/ minimization problem. In short, exact recovery may be obtained by solving a convex optimization problem. We give numerical values for C/sub M/ which depend on the desired probability of success. Our result may be interpreted as a novel kind of nonlinear sampling theorem. In effect, it says that any signal made out of |T| spikes may be recovered by convex programming from almost every set of frequencies of size O(|T|/spl middot/logN). Moreover, this is nearly optimal in the sense that any method succeeding with probability 1-O(N/sup -M/) would in general require a number of frequency samples at least proportional to |T|/spl middot/logN. The methodology extends to a variety of other situations and higher dimensions. For example, we show how one can reconstruct a piecewise constant (one- or two-dimensional) object from incomplete frequency samples - provided that the number of jumps (discontinuities) obeys the condition above - by minimizing other convex functionals such as the total variation of f.",
                    "title": "Robust uncertainty principles: exact signal reconstruction from highly incomplete frequency information",
                    "venue": "IEEE Transactions on Information Theory",
                    "year": 2006,
                    "__v": 3,
                    "citationCount": 3800,
                    "result": 3.2454807688385556
                },
                "aa70d058-ba2d-409f-a20e-fcf8239a069e": {
                    "authors": [
                        "Dong C. Liu",
                        "Jorge Nocedal"
                    ],
                    "references": [
                        "5a04ee0f-3d3d-4afe-89c1-57affdaa7b85",
                        "75a84b76-0bbb-416f-b4f9-0d6f8193572c",
                        "8a9696d0-371e-4d2e-9da6-19f544244aaa",
                        "8abc93cb-9bdb-4e0a-8632-ff130ef86ced",
                        "b4765cc2-d138-430a-b136-e186a8119eb0",
                        "bff6b5ca-510c-48c7-8e99-244b4fcd4b72",
                        "c4e5389e-3afe-4a13-8c19-ebb48164eb35",
                        "f905320e-6166-4e01-b93e-69e379fe4f0e"
                    ],
                    "keyword": [
                        "method",
                        "lbfgs",
                        "quasinewton",
                        "problems",
                        "convergence",
                        "study",
                        "steps",
                        "show",
                        "scale",
                        "performance"
                    ],
                    "group": [],
                    "_id": "aa70d058-ba2d-409f-a20e-fcf8239a069e",
                    "abstract": "We study the numerical performance of a limited memory quasi-Newton method for large scale optimization, which we call the L-BFGS method. We compare its performance with that of the method developed by Buckley and LeNir (1985), which combines cycles of BFGS steps and conjugate direction steps. Our numerical tests indicate that the L-BFGS method is faster than the method of Buckley and LeNir, and is better able to use additional storage to accelerate convergence. We show that the L-BFGS method can be greatly accelerated by means of a simple scaling. We then compare the L-BFGS method with the partitioned quasi-Newton method of Griewank and Toint (1982a). The results show that, for some problems, the partitioned quasi-Newton method is clearly superior to the L-BFGS method. However we find that for other problems the L-BFGS method is very competitive due to its low iteration cost. We also study the convergence properties of the L-BFGS method, and prove global convergence on uniformly convex problems.",
                    "title": "On the limited memory BFGS method for large scale optimization",
                    "venue": "Mathematical Programming",
                    "year": 1989,
                    "__v": 1,
                    "citationCount": 1189,
                    "result": 4.584160077968129
                },
                "ab0bfa8d-80b6-47ef-8a91-febce2ce65c5": {
                    "authors": [
                        "David L. Donoho"
                    ],
                    "references": [
                        "28b8d07b-a802-4e3a-9dfb-2735d0ef7dfb",
                        "b172a91e-42cf-4e43-a6f3-e4101943786f",
                        "bd5acb06-2698-4ce9-a0ae-cbd687e03278"
                    ],
                    "keyword": [
                        "smooth",
                        "estimator",
                        "wavelet",
                        "results",
                        "reconstructing",
                        "measures",
                        "fspl",
                        "circsub"
                    ],
                    "group": [],
                    "_id": "ab0bfa8d-80b6-47ef-8a91-febce2ce65c5",
                    "abstract": "Donoho and Johnstone (1994) proposed a method for reconstructing an unknown function f on [0,1] from noisy data d/sub i/=f(t/sub i/)+/spl sigma/z/sub i/, i=0, ..., n-1,t/sub i/=i/n, where the z/sub i/ are independent and identically distributed standard Gaussian random variables. The reconstruction f/spl circ/*/sub n/ is defined in the wavelet domain by translating all the empirical wavelet coefficients of d toward 0 by an amount /spl sigma//spl middot//spl radic/(2log (n)/n). The authors prove two results about this type of estimator. [Smooth]: with high probability f/spl circ/*/sub n/ is at least as smooth as f, in any of a wide variety of smoothness measures. [Adapt]: the estimator comes nearly as close in mean square to f as any measurable estimator can come, uniformly over balls in each of two broad scales of smoothness classes. These two properties are unprecedented in several ways. The present proof of these results develops new facts about abstract statistical inference and its connection with an optimal recovery model. >",
                    "title": "De-noising by soft-thresholding",
                    "venue": "IEEE Transactions on Information Theory",
                    "year": 1995,
                    "__v": 2,
                    "citationCount": 1733,
                    "result": 3.0970779418753573
                },
                "b18e236f-aa78-452c-a85a-240e5e5d69fb": {
                    "authors": [
                        "Mário A. T. Figueiredo",
                        "José M. Bioucas-Dias"
                    ],
                    "references": [
                        "057eb4c8-0ec4-4156-b95a-e67b9df63e6b",
                        "06dd6b12-c373-4509-9139-8e5987d5c25c",
                        "109367fa-db04-4db0-8777-d6ca7e9e78fd",
                        "1654714d-fd37-42e4-a64b-141c193b720e",
                        "1cc8f484-eeac-462f-9dce-4b93a1942be0",
                        "28e6e848-a661-40bd-8667-630e8575016a",
                        "2ad802e0-dfe8-401c-b42f-0cfc575a4801",
                        "30fa5223-a13d-429d-99fa-4428199d581d",
                        "31c883b9-75b1-4ea6-b9e2-776cc33a287f",
                        "366d79b2-b969-48d6-b565-4b6dc1e2f454",
                        "3f90046c-1c24-4a11-abc5-831c4d30f660",
                        "4289bfe3-7305-41e5-a19d-8f0dd37e9892",
                        "43898afd-2192-4aa3-9c66-1e4b02f2a392",
                        "46ed61d9-3fba-46e9-a5b8-47fe0b5abc8a",
                        "52e55346-2fb4-45a8-9e50-db06f3343982",
                        "5bbc1a90-621e-4b83-be68-d6fe2eb7c6c2",
                        "64fde789-e378-4f98-a3f1-08d81c60b0de",
                        "6d263589-e3d5-45f8-8159-faff0f21c319",
                        "7165eacb-22a8-469d-a987-172ead716fd5",
                        "7db1957b-66a4-439f-a9bd-ca89aea58642",
                        "844e8374-b6cf-40f5-8c8a-75788ee2ac76",
                        "9b166075-5b89-4ec5-91db-47e5ca47c7ec",
                        "a166d6dd-2e69-4e98-aed6-fa8286f59785",
                        "a6afe815-62b7-4894-b996-c13cc4aebe69",
                        "abcdb492-bf0a-47ac-9c4b-e4889235a05a",
                        "b8321e4f-ccae-433a-984e-7567535ff293",
                        "c531f74c-0a7c-4a26-8ab7-fd63ca32dcde",
                        "cf1185ea-c464-4ee9-b6fa-ced4ece47a4b",
                        "dc5ed054-0c63-473e-9996-3c91daeca369",
                        "e150fc0f-42a7-4de9-a8f2-0b29d4304623"
                    ],
                    "keyword": [
                        "regularizers",
                        "problem",
                        "restoring",
                        "optimization",
                        "method",
                        "images",
                        "framebased",
                        "analysis",
                        "alternating"
                    ],
                    "group": [],
                    "_id": "b18e236f-aa78-452c-a85a-240e5e5d69fb",
                    "abstract": "Much research has been devoted to the problem of restoring Poissonian images, namely for medical and astronomical applications. However, the restoration of these images using state-of-the-art regularizers (such as those based upon multiscale representations or total variation) is still an active research area, since the associated optimization problems are quite challenging. In this paper, we propose an approach to deconvolving Poissonian images, which is based upon an alternating direction optimization method. The standard regularization [or maximum a posteriori (MAP)] restoration criterion, which combines the Poisson log-likelihood with a (nonsmooth) convex regularizer (log-prior), leads to hard optimization problems: the log-likelihood is nonquadratic and nonseparable, the regularizer is nonsmooth, and there is a nonnegativity constraint. Using standard convex analysis tools, we present sufficient conditions for existence and uniqueness of solutions of these optimization problems, for several types of regularizers: total-variation, frame-based analysis, and frame-based synthesis. We attack these problems with an instance of the alternating direction method of multipliers (ADMM), which belongs to the family of augmented Lagrangian algorithms. We study sufficient conditions for convergence and show that these are satisfied, either under total-variation or frame-based (analysis and synthesis) regularization. The resulting algorithms are shown to outperform alternative state-of-the-art methods, both in terms of speed and restoration accuracy.",
                    "title": "Restoration of Poissonian Images Using Alternating Direction Optimization",
                    "venue": "IEEE Transactions on Image Processing",
                    "year": 2010,
                    "__v": 2,
                    "citationCount": 127,
                    "result": 7.618896017657628
                },
                "b220c1dd-7184-4e8b-a835-cce5504d95d1": {
                    "authors": [
                        "Zhaosong Lu"
                    ],
                    "references": [
                        "0e91e850-9657-41ca-9007-41f5a5fa14f4",
                        "2d5e8c4c-8421-4d8b-b07e-0ffc7a60f544",
                        "3fb686f8-168e-40b8-8b9e-0997c0202143",
                        "489b5715-2976-4a07-8eb7-fee0e4d9e301",
                        "9d32a674-cd69-4f28-be68-b2a4fa6db086",
                        "f0c0249b-4cef-436c-904f-1d70ef15d300",
                        "facef596-4c0e-491d-a8ae-d6bde5f8cdc5"
                    ],
                    "keyword": [
                        "smooth",
                        "approach",
                        "problems",
                        "pp",
                        "nesterov's",
                        "methods",
                        "substantially",
                        "outperformed",
                        "optimization"
                    ],
                    "group": [],
                    "_id": "b220c1dd-7184-4e8b-a835-cce5504d95d1",
                    "abstract": "In this paper we first study a smooth optimization approach for solving a class of nonsmooth strictly concave maximization problems whose objective functions admit smooth convex minimization reformulations. In particular, we apply Nesterov's smooth optimization technique [Y. E. Nesterov, Dokl. Akad. Nauk SSSR, 269 (1983), pp. 543-547; Y. E. Nesterov, Math. Programming, 103 (2005), pp. 127-152] to their dual counterparts that are smooth convex problems. It is shown that the resulting approach has ${\\cal O}(1/{\\sqrt{\\epsilon}})$ iteration complexity for finding an $\\epsilon$-optimal solution to both primal and dual problems. We then discuss the application of this approach to sparse covariance selection that is approximately solved as an $l_1$-norm penalized maximum likelihood estimation problem, and also propose a variant of this approach which has substantially outperformed the latter one in our computational experiments. We finally compare the performance of these approaches with other first-order methods, namely, Nesterov's ${\\cal O}(1/\\epsilon)$ smooth approximation scheme and block-coordinate descent method studied in [A. d'Aspremont, O. Banerjee, and L. El Ghaoui, SIAM J. Matrix Anal. Appl., 30 (2008), pp. 56-66; J. Friedman, T. Hastie, and R. Tibshirani, Biostatistics, 9 (2008), pp. 432-441] for sparse covariance selection on a set of randomly generated instances. It shows that our smooth optimization approach substantially outperforms the first method above, and moreover, its variant substantially outperforms both methods above.",
                    "title": "Smooth Optimization Approach for Sparse Covariance Selection",
                    "venue": "Siam Journal on Optimization",
                    "year": 2008,
                    "__v": 1,
                    "citationCount": 40,
                    "result": 6.166184397406636
                },
                "b22ae921-bc95-40ad-9a6e-af0d73790adc": {
                    "authors": [
                        "Katya Scheinberg",
                        "Shiqian Ma",
                        "Donald Goldfarb"
                    ],
                    "references": [
                        "109367fa-db04-4db0-8777-d6ca7e9e78fd",
                        "2d773039-c390-4450-bb12-d56eaa4343ae",
                        "5ab1529e-c6f9-4fa9-a461-9294e5639748",
                        "5fa58e5b-3d77-4aee-905b-99aec0711748",
                        "9d32a674-cd69-4f28-be68-b2a4fa6db086",
                        "add4c404-c9fe-42fe-8042-2c23ea1ec69d",
                        "b220c1dd-7184-4e8b-a835-cce5504d95d1",
                        "b959ad94-9d47-418a-a145-e719bb379203",
                        "ed3293b7-e9f2-4726-a1f0-8cf065ee49d2",
                        "f0c0249b-4cef-436c-904f-1d70ef15d300",
                        "f4510189-871d-42d8-b680-69b56c96632c"
                    ],
                    "keyword": [
                        "algorithm",
                        "structure",
                        "solving",
                        "solutions",
                        "problem",
                        "matrix",
                        "learning",
                        "iteration",
                        "inverse",
                        "gaussian"
                    ],
                    "group": [],
                    "_id": "b22ae921-bc95-40ad-9a6e-af0d73790adc",
                    "abstract": "Gaussian graphical models are of great interest in statistical learning. Because the conditional independencies between different nodes correspond to zero entries in the inverse covariance matrix of the Gaussian distribution, one can learn the structure of the graph by estimating a sparse inverse covariance matrix from sample data, by solving a convex maximum likelihood problem with an l1-regularization term. In this paper, we propose a first-order method based on an alternating linearization technique that exploits the problem's special structure; in particular, the subproblems solved in each iteration have closed-form solutions. Moreover, our algorithm obtains an e-optimal solution in O(1/e) iterations. Numerical experiments on both synthetic and real data from gene association networks show that a practical version of this algorithm outperforms other competitive algorithms.",
                    "title": "Sparse Inverse Covariance Selection via Alternating Linearization Methods",
                    "venue": "neural information processing systems",
                    "year": 2010,
                    "__v": 2,
                    "citationCount": 62,
                    "result": 7.532904411619583
                },
                "b2425f3b-5b13-483a-8fd1-fdf13fa238fd": {
                    "authors": [
                        "Paul Tseng"
                    ],
                    "references": [],
                    "keyword": [
                        "method",
                        "monotone",
                        "mappings",
                        "variational",
                        "step",
                        "modification",
                        "inequalities",
                        "convex",
                        "converge",
                        "sum"
                    ],
                    "group": [],
                    "_id": "b2425f3b-5b13-483a-8fd1-fdf13fa238fd",
                    "abstract": "We consider the forward-backward splitting method for finding a zero of the sum of two maximal monotone mappings. This method is known to converge when the inverse of the forward mapping is strongly monotone. We propose a modification to this method, in the spirit of the extragradient method for monotone variational inequalities, under which the method converges assuming only the forward mapping is (Lipschitz) continuous on some closed convex subset of its domain. The modification entails an additional forward step and a projection step at each iteration. Applications of the modified method to decomposition in convex programming and monotone variational inequalities are discussed.",
                    "title": "A Modified Forward-Backward Splitting Method for Maximal Monotone Mappings",
                    "venue": "Siam Journal on Control and Optimization",
                    "year": 2000,
                    "__v": 1,
                    "citationCount": 94,
                    "result": 5.254269904502102
                },
                "b8321e4f-ccae-433a-984e-7567535ff293": {
                    "authors": [
                        "Jonathan Eckstein",
                        "Dimitri P. Bertsekas"
                    ],
                    "references": [
                        "0ab6d92b-44d2-44da-b029-39e138eb1216",
                        "2c58f129-ff63-4afe-ab63-b10d03da1779",
                        "732d70fd-372e-4100-94bd-6e2c3890e342",
                        "861e877e-3903-4aed-827a-5a501858f17b"
                    ],
                    "keyword": [
                        "operator",
                        "algorithm",
                        "proximal",
                        "programming",
                        "point",
                        "method",
                        "generalization",
                        "convex",
                        "splitting",
                        "special"
                    ],
                    "group": [],
                    "_id": "b8321e4f-ccae-433a-984e-7567535ff293",
                    "abstract": "This paper shows, by means of an operator called asplitting operator, that the Douglas—Rachford splitting method for finding a zero of the sum of two monotone operators is a special case of the proximal point algorithm. Therefore, applications of Douglas—Rachford splitting, such as the alternating direction method of multipliers for convex programming decomposition, are also special cases of the proximal point algorithm. This observation allows the unification and generalization of a variety of convex programming algorithms. By introducing a modified version of the proximal point algorithm, we derive a new,generalized alternating direction method of multipliers for convex programming. Advances of this sort illustrate the power and generality gained by adopting monotone operator theory as a conceptual framework.",
                    "title": "On the Douglas-Rachford splitting method and the proximal point algorithm for maximal monotone operators",
                    "venue": "Mathematical Programming",
                    "year": 1992,
                    "__v": 1,
                    "citationCount": 611,
                    "result": 6.759441316175062
                },
                "b959ad94-9d47-418a-a145-e719bb379203": {
                    "authors": [
                        "Onureena Banerjee",
                        "Laurent El Ghaoui",
                        "Alexandre d'Aspremont"
                    ],
                    "references": [
                        "05b7b300-610a-4c07-89db-afdb355fef65",
                        "3fb686f8-168e-40b8-8b9e-0997c0202143",
                        "869007f7-ac7f-49dd-9d24-1859396fd4db",
                        "f0c0249b-4cef-436c-904f-1d70ef15d300"
                    ],
                    "keyword": [
                        "problem",
                        "algorithms",
                        "solve",
                        "methods",
                        "sparse",
                        "point",
                        "nodes",
                        "maximum",
                        "log",
                        "likelihood"
                    ],
                    "group": [],
                    "_id": "b959ad94-9d47-418a-a145-e719bb379203",
                    "abstract": "We consider the problem of estimating the parameters of a Gaussian or binary distribution in such a way that the resulting undirected graphical model is sparse. Our approach is to solve a maximum likelihood problem with an added l1-norm penalty term. The problem as formulated is convex but the memory requirements and complexity of existing interior point methods are prohibitive for problems with more than tens of nodes. We present two new algorithms for solving problems with at least a thousand nodes in the Gaussian case. Our first algorithm uses block coordinate descent, and can be interpreted as recursive l1-norm penalized regression. Our second algorithm, based on Nesterov's first order method, yields a complexity estimate with a better dependence on problem size than existing interior point methods. Using a log determinant relaxation of the log partition function (Wainwright and Jordan, 2006), we show that these same algorithms can be used to solve an approximate sparse maximum likelihood problem for the binary case. We test our algorithms on synthetic data, as well as on gene expression and senate voting records data.",
                    "title": "Model Selection Through Sparse Maximum Likelihood Estimation for Multivariate Gaussian or Binary Data",
                    "venue": "Journal of Machine Learning Research",
                    "year": 2008,
                    "__v": 2,
                    "citationCount": 290,
                    "result": 4.873318142126192
                },
                "bacedd4e-2e09-4ec8-8d9a-0f77e1e3816f": {
                    "authors": [
                        "Gonzalo Mateos",
                        "Juan Andres Bazerque",
                        "Georgios B. Giannakis"
                    ],
                    "references": [
                        "2c80dcc7-3637-4885-939b-cd144b8035a4",
                        "2ca8a212-1179-4f68-bc20-8f2d8848585a",
                        "3093ce56-f1c7-43ca-8ff6-082ba0ca9f92",
                        "5269cce8-bbc4-4c54-b040-3f9cfd95a702",
                        "7a7b52f0-82db-4e16-9df0-d3f5b5c7b5c5",
                        "81a60c6f-2102-4b93-b991-00814ab480f4",
                        "99b7c24b-5497-4e2b-a2af-60d28855228f",
                        "9a2f5ef0-d32b-4d16-aaf2-6ff778ae17c2",
                        "9b166075-5b89-4ec5-91db-47e5ca47c7ec",
                        "9c7174a1-3c73-4a2e-a78b-b23816830420",
                        "c74e5d58-1493-4fa8-a092-abc20c7c7fab",
                        "d7b5aadf-ec30-4fb7-9224-7474169d3744",
                        "d9162547-fd7f-4605-855d-0a3173c4b08e",
                        "dadfa87e-535b-42fa-be7f-61d24458ede4",
                        "e0280877-486b-4c83-b7cb-fa67d7270c1f",
                        "ea1d5c21-fba6-4fae-9fdc-ee7679ee46c9",
                        "f3267c01-b670-4b7a-a3a5-79088c0d90ab"
                    ],
                    "keyword": [
                        "lasso",
                        "estimation",
                        "communication",
                        "distributed",
                        "data"
                    ],
                    "group": [],
                    "_id": "bacedd4e-2e09-4ec8-8d9a-0f77e1e3816f",
                    "abstract": "The Lasso is a popular technique for joint estimation and continuous variable selection, especially well-suited for sparse and possibly under-determined linear regression problems. This paper develops algorithms to estimate the regression coefficients via Lasso when the training data are distributed across different agents, and their communication to a central processing unit is prohibited for e.g., communication cost or privacy reasons. A motivating application is explored in the context of wireless communications, whereby sensing cognitive radios collaborate to estimate the radio-frequency power spectrum density. Attaining different tradeoffs between complexity and convergence speed, three novel algorithms are obtained after reformulating the Lasso into a separable form, which is iteratively minimized using the alternating-direction method of multipliers so as to gain the desired degree of parallelization. Interestingly, the per agent estimate updates are given by simple soft-thresholding operations, and inter-agent communication overhead remains at affordable level. Without exchanging elements from the different training sets, the local estimates consent to the global Lasso solution, i.e., the fit that would be obtained if the entire data set were centrally available. Numerical experiments with both simulated and real data demonstrate the merits of the proposed distributed schemes, corroborating their convergence and global optimality. The ideas in this paper can be easily extended for the purpose of fitting related models in a distributed fashion, including the adaptive Lasso, elastic net, fused Lasso and nonnegative garrote.",
                    "title": "Distributed Sparse Linear Regression",
                    "venue": "IEEE Transactions on Signal Processing",
                    "year": 2010,
                    "__v": 1,
                    "citationCount": 129,
                    "result": 4.624635226923556
                },
                "bc40dd83-5f7a-435c-8275-73f36c3c6c49": {
                    "authors": [
                        "Jonathan Eckstein"
                    ],
                    "references": [
                        "06d1d07b-4a24-428f-8320-8e6b9dbdea4d",
                        "23e8b37f-31c6-4ac9-a327-872cca4c74d4",
                        "36430fd0-a383-4f6d-ae8a-6048eaf9fe08",
                        "3a0a2f46-50e6-46c8-872e-35744fe66738",
                        "499c5045-9557-4b03-8293-2a248cb486ba",
                        "58bb064c-f360-4cf7-ad56-e911e4ba28f2",
                        "6794e1a8-849d-41f4-af5a-1b3d262ed196",
                        "6f992c5b-c541-4c9e-953e-d89f2a2cafb7",
                        "7b23688a-96a2-4be4-b424-1f87de29de38",
                        "861e877e-3903-4aed-827a-5a501858f17b",
                        "e5092856-14e2-401b-bf5d-7b790094dc69"
                    ],
                    "keyword": [
                        "methods",
                        "programming",
                        "lagrangian",
                        "iterate",
                        "convex",
                        "augmented",
                        "results",
                        "required",
                        "multipliers",
                        "including"
                    ],
                    "group": [],
                    "_id": "bc40dd83-5f7a-435c-8275-73f36c3c6c49",
                    "abstract": "This paper demonstrates that for generalized methods of multipliers for convex programming based on Bregman distance kernels – including the classical quadratic method of multipliers – the minimization of the augmented Lagrangian can be truncated using a simple, generally implementable stopping criterion based only on the norms of the primal iterate and the gradient (or a subgradient) of the augmented Lagrangian at that iterate. Previous results in this and related areas have required conditions that are much harder to verify, such as e-optimality with respect to the augmented Lagrangian, or strong conditions on the convex program to be solved. Here, only existence of a KKT pair is required, and the convergence properties of the exact form of the method are preserved. The key new element in the analysis is the use of a full conjugate duality framework, as opposed to mainly examining the action of the method on the standard dual function of the convex program. An existence result for the iterates, stronger than those possible for the exact form of the algorithm, is also included.",
                    "title": "A practical general approximation criterion for methods of multipliers based on Bregman distances",
                    "venue": "Mathematical Programming",
                    "year": 2003,
                    "__v": 1,
                    "citationCount": 4,
                    "result": 4.192741392431795
                },
                "f56b877b-4060-4754-b303-e8140968544c": {
                    "authors": [
                        "David L. Donoho"
                    ],
                    "references": [
                        "036a19f8-fdca-4e84-a237-e54f2108dcb4",
                        "05c85ace-c998-47cd-a285-f6ecfd72004d",
                        "0bb77e7f-bfc4-4d0d-873a-3d6d3c28b316",
                        "0ed39048-dd26-467a-bcd5-7017fcccddb5",
                        "225591b8-1c1a-4854-81d4-5b5f364c20a9",
                        "2862ec34-58f4-41c0-8790-1740130f1814",
                        "2a15f947-2402-4979-94b8-53de9ceef26e",
                        "3d414a5e-b97a-498e-8a75-920997235c6b",
                        "3dd913b8-e22d-434e-9015-bf68fbbb7bef",
                        "3ddea798-1e4f-408a-86db-a611c7bbcdcf",
                        "449bfdfc-f916-422c-ac0d-ebfdd2ab773a",
                        "4c9f2bac-2f23-4170-a0f1-a3001f63a7b9",
                        "5eb8608d-d0a1-4f14-af98-8a26bab51fae",
                        "71a18de9-e543-4337-ab7a-3db31d9f8c00",
                        "7291a02d-1d94-48b7-a4e2-35406c0e52ad",
                        "834863b2-34f0-40dc-b4d2-f4189eaa262a",
                        "87a4faed-c1a5-45c8-81eb-3bf19ae19011",
                        "8dd4158a-bbc4-40cf-a4d5-14e0fe630387",
                        "9b021b12-2e59-42bc-9e29-86e480e652b7",
                        "9e65914c-bfef-45e7-9fd7-85c39ed13ac4",
                        "a53a3dda-b003-4d5c-96b1-e9afd8e35692",
                        "adc31a96-1f8e-4793-8ee9-ecef04a16ac6",
                        "ae4ab999-5078-4348-9a3d-94c019952bcc",
                        "aecf8a08-eff7-4182-8bbb-a7b29de2f281",
                        "bb3c38fa-c2b0-4d4f-8c9d-ca1884343474",
                        "c380b798-6583-4821-9613-0a9731b1ced1",
                        "c9bf7235-7aad-4e6d-a9a6-e4a6bbddc327",
                        "ca546a51-ffda-46b1-b783-ff512ec9c4bd",
                        "cd9bd50b-d672-43a9-b0c2-0b332cf0b88e",
                        "d2104367-6389-4b06-8dbe-bab7e05b903b",
                        "d6457de8-9f03-4671-91da-f557a0ec20e0",
                        "defc112d-f91d-4b34-9d44-bd7f702c2391",
                        "f11bfae2-e272-4acc-b231-a9619f1e4d6c",
                        "ff44599f-5e74-4d9b-94d3-286592973471"
                    ],
                    "keyword": [
                        "measure",
                        "reconstruct",
                        "nwidths",
                        "nonadaptive",
                        "linear",
                        "coefficients"
                    ],
                    "group": [
                        null
                    ],
                    "_id": "f56b877b-4060-4754-b303-e8140968544c",
                    "abstract": "Suppose x is an unknown vector in Ropf m  (a digital image or signal); we plan to measure n general linear functionals of x and then reconstruct. If x is known to be compressible by transform coding with a known transform, and we reconstruct via the nonlinear procedure defined here, the number of measurements n can be dramatically smaller than the size m. Thus, certain natural classes of images with m pixels need only n=O(m 1/4 log 5/2 (m)) nonadaptive nonpixel samples for faithful recovery, as opposed to the usual m pixel samples. More specifically, suppose x has a sparse representation in some orthonormal basis (e.g., wavelet, Fourier) or tight frame (e.g., curvelet, Gabor)-so the coefficients belong to an lscr p  ball for 0 2  error O(N 1/2-1 p/). It is possible to design n=O(Nlog(m)) nonadaptive measurements allowing reconstruction with accuracy comparable to that attainable with direct knowledge of the N most important coefficients. Moreover, a good approximation to those N important coefficients is extracted from the n measurements by solving a linear program-Basis Pursuit in signal processing. The nonadaptive measurements have the character of \"random\" linear combinations of basis/frame elements. Our results use the notions of optimal recovery, of n-widths, and information-based complexity. We estimate the Gel'fand n-widths of lscr p  balls in high-dimensional Euclidean space in the case 0<ples1, and give a criterion identifying near- optimal subspaces for Gel'fand n-widths. We show that \"most\" subspaces are near-optimal, and show that convex optimization (Basis Pursuit) is a near-optimal way to extract information derived from these near-optimal subspaces",
                    "title": "Compressed sensing",
                    "venue": "IEEE Transactions on Information Theory",
                    "year": 2006,
                    "__v": 3,
                    "citationCount": 6079,
                    "result": 2.6458981511613087
                },
                "fa619312-6a30-40c5-bd8e-f09dffce0543": {
                    "authors": [
                        "Grzegorz Malewicz",
                        "Matthew H. Austern",
                        "Aart J. C. Bik",
                        "James C. Dehnert",
                        "Ilan Horn",
                        "Naty Leiser",
                        "Grzegorz Czajkowski"
                    ],
                    "references": [
                        "0718dc34-4b49-4b24-8a2e-b5cd0d9d82c6",
                        "0b174274-d6e9-4199-b768-cde485917802",
                        "0b2b5b0c-74d1-486b-88ae-7280fcd09c27",
                        "117d7c05-35c9-4745-bd6c-c745c35ec7eb",
                        "11aac7ac-6da0-49fb-ab45-a3ad89a01eef",
                        "1c2e1643-4a7e-45c9-bba7-6af345191e86",
                        "1d57daa8-7fa0-42f3-9f00-d5b9356ffdf9",
                        "2d46f44d-5e8d-4a4a-9935-49b5a6a4a99a",
                        "409159cc-0393-4021-99ee-654018eb0fa4",
                        "45e02742-bb34-436b-b7b5-875d5f01c0e9",
                        "5002dd27-9ce6-4abb-a3d0-2ac112f58c37",
                        "5081ba39-ed0e-42a5-ab93-924b341f40c9",
                        "5481c31d-a562-46a9-ad5b-c5cad52a468e",
                        "551a4f50-593e-4708-a485-d50b6e4bb877",
                        "6cfadeac-6b9f-4f96-b36a-bc512153ffe0",
                        "7d012f5a-8baa-4d1e-8a04-1b7d824cce0f",
                        "96d97669-95ba-4cbc-9b69-b7cc5a1c4763",
                        "99c38516-e79c-4b98-86ef-571ca361bc8d",
                        "9e7f3a14-e586-4bad-aab9-0c36173e441d",
                        "a0ee3102-b11e-467e-be7b-1b2691d9bc7e",
                        "a6b8a65c-076b-4858-854c-f0e984d15564",
                        "ace2d178-68ed-4ecf-a058-8a18cdd55fcd",
                        "b827788f-1745-4a96-a46b-f2b43d27c1e5",
                        "c7e4e04b-45da-4bae-8c8a-d17ca0087361",
                        "ca1d3032-e288-42f1-9228-f95da0535c0c",
                        "d619d941-098d-4fda-80bc-729745ad3090",
                        "d73ec1ba-382a-40cf-86ab-785a450d372d",
                        "e8a213a4-a353-479c-a216-43169ff21e3b",
                        "f4ba186b-c705-4fe8-ad1c-35a8c6f19028",
                        "f72e8d03-14b0-4282-917f-60bf818c56a5",
                        "fc478323-7142-4f81-8a7f-657860f33e1d"
                    ],
                    "keyword": [
                        "graphs",
                        "programs",
                        "expressed",
                        "computing",
                        "vertices",
                        "processing",
                        "model",
                        "messages",
                        "large",
                        "iterations"
                    ],
                    "group": [],
                    "_id": "fa619312-6a30-40c5-bd8e-f09dffce0543",
                    "abstract": "Many practical computing problems concern large graphs. Standard examples include the Web graph and various social networks. The scale of these graphs - in some cases billions of vertices, trillions of edges - poses challenges to their efficient processing. In this paper we present a computational model suitable for this task. Programs are expressed as a sequence of iterations, in each of which a vertex can receive messages sent in the previous iteration, send messages to other vertices, and modify its own state and that of its outgoing edges or mutate graph topology. This vertex-centric approach is flexible enough to express a broad set of algorithms. The model has been designed for efficient, scalable and fault-tolerant implementation on clusters of thousands of commodity computers, and its implied synchronicity makes reasoning about programs easier. Distribution-related details are hidden behind an abstract API. The result is a framework for processing large graphs that is expressive and easy to program.",
                    "title": "Pregel: a system for large-scale graph processing",
                    "venue": "international conference on management of data",
                    "year": 2010,
                    "__v": 2,
                    "citationCount": 1167,
                    "result": 4.18053655197618
                },
                "fb0a382c-a1f1-4f0c-8e80-36fe5fbbfb86": {
                    "authors": [
                        "Matei Zaharia",
                        "N. M. Mosharaf Kabir Chowdhury",
                        "Michael J. Franklin",
                        "Scott Shenker",
                        "Ion Stoica"
                    ],
                    "references": [
                        "01c92637-18cc-4d81-8a61-8c53e14ec3ec",
                        "0b2b5b0c-74d1-486b-88ae-7280fcd09c27",
                        "117d7c05-35c9-4745-bd6c-c745c35ec7eb",
                        "15d4f7fc-4199-4547-a34e-4d623416fc25",
                        "1c2e1643-4a7e-45c9-bba7-6af345191e86",
                        "2f2a347d-cc88-483a-9723-7767c6046ee0",
                        "3bc3b806-e51f-4110-818a-8fb9ea196b44",
                        "3fab2153-d83b-447d-bdfd-59855c8701ad",
                        "73b01626-f296-4e16-a097-f69179864aef",
                        "7e182520-45bd-491b-855c-31aceef3d6f7",
                        "8ae8d596-9bba-4bb2-9da7-2138b050e176",
                        "95c4210b-0fde-42b7-b24d-4ba0d1da412f",
                        "976688c4-9532-42f2-b5a8-8d6800d9991b",
                        "becb67c1-ddca-492b-b8c7-adb96f03da44",
                        "c5e9ece5-db9b-4914-a6e5-e9bf821f4dc7",
                        "cd34a690-50bf-481f-8b31-d06e5ebbd3d2",
                        "db4e226a-5dd9-44d4-bac3-3ba3594ca4d7",
                        "e428d749-c2f1-41da-a00e-ef44850bf4c3",
                        "f01c3967-b176-4738-bc8a-6545552170e4"
                    ],
                    "keyword": [
                        "applications",
                        "spark",
                        "machine",
                        "data",
                        "set",
                        "partitioned",
                        "mapreduce",
                        "learning",
                        "iterative",
                        "interactive"
                    ],
                    "group": [],
                    "_id": "fb0a382c-a1f1-4f0c-8e80-36fe5fbbfb86",
                    "abstract": "MapReduce and its variants have been highly successful in implementing large-scale data-intensive applications on commodity clusters. However, most of these systems are built around an acyclic data flow model that is not suitable for other popular applications. This paper focuses on one such class of applications: those that reuse a working set of data across multiple parallel operations. This includes many iterative machine learning algorithms, as well as interactive data analysis tools. We propose a new framework called Spark that supports these applications while retaining the scalability and fault tolerance of MapReduce. To achieve these goals, Spark introduces an abstraction called resilient distributed datasets (RDDs). An RDD is a read-only collection of objects partitioned across a set of machines that can be rebuilt if a partition is lost. Spark can outperform Hadoop by 10x in iterative machine learning jobs, and can be used to interactively query a 39 GB dataset with sub-second response time.",
                    "title": "Spark: cluster computing with working sets",
                    "venue": "ieee international conference on cloud computing technology and science",
                    "year": 2010,
                    "__v": 2,
                    "citationCount": 990,
                    "result": 6.791611888283714
                }
            }
        ],
        "_id": "e537d143-155e-4ca0-8ae8-66b777a77fea",
        "abstract": "Many problems of recent interest in statistics and machine learning can be posed in the framework of convex optimization. Due to the explosion in size and complexity of modern datasets, it is increasingly important to be able to solve problems with a very large number of features or training examples. As a result, both the decentralized collection or storage of these datasets as well as accompanying distributed solution methods are either necessary or at least highly desirable. In this review, we argue that the alternating direction method of multipliers is well suited to distributed convex optimization, and in particular to large-scale problems arising in statistics, machine learning, and related areas. The method was developed in the 1970s, with roots in the 1950s, and is equivalent or closely related to many other algorithms, such as dual decomposition, the method of multipliers, Douglas–Rachford splitting, Spingarn's method of partial inverses, Dykstra's alternating projections, Bregman iterative algorithms for l1 problems, proximal methods, and others. After briefly surveying the theory and history of the algorithm, we discuss applications to a wide variety of statistical and machine learning problems of recent interest, including the lasso, sparse logistic regression, basis pursuit, covariance selection, support vector machines, and many others. We also discuss general distributed optimization, extensions to the nonconvex setting, and efficient implementation, including some details on distributed MPI and Hadoop MapReduce implementations.",
        "title": "Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers",
        "venue": "",
        "year": 2011,
        "__v": 2,
        "citationCount": 2516
    },
    {
        "authors": [
            "Paul A. Viola",
            "Michael J. Jones"
        ],
        "references": [
            "13cd743f-beb9-43a1-8e08-2ef08f0d8b3f",
            "17f811d8-8607-4270-bbec-1cc7883edd68",
            "310cbba4-d88d-4bf4-a4f2-738f91b5f8c8",
            "36800655-b2ff-4eb7-9070-c6be304c4baa",
            "43530fe4-10a9-4ddf-b61d-8844f0ff3f04",
            "5ffac6f9-2456-42cf-830c-9049ce37c899",
            "6d121e97-e351-4cf9-8c44-d7ab3ce9d9fe",
            "9fa55b0f-eaa6-4c59-b6e5-77e5f1a406f0",
            "c7f93552-c1ef-4ae4-b1f5-2317e1c9d904",
            "d5e5a24d-f80e-4f1a-b48b-22403b653276",
            "d6e37fb1-5f7e-448e-847b-7d1f1271c574",
            "db26488d-78be-44b1-a343-e896f43c5d29",
            "f1bd37c4-d033-4cd1-af44-4df9f11c71e4",
            "f4642ffc-3571-4d02-8b94-142f2448023a"
        ],
        "keyword": [
            "images",
            "detection",
            "regions",
            "object",
            "yields",
            "visual",
            "system",
            "rates",
            "quickly",
            "previous"
        ],
        "group": [
            {
                "5ffac6f9-2456-42cf-830c-9049ce37c899": {
                    "authors": [
                        "Edgar Osuna",
                        "Robert M. Freund",
                        "Federico Girosit"
                    ],
                    "references": [
                        "0150e8cd-09bc-4991-92b4-454fe4b0bfac",
                        "50dd56db-151d-4d62-8576-65f0ef6f381b",
                        "648675c6-6ea7-4fa5-a91d-9d3156d09692",
                        "a689c833-ccce-475c-87af-526da83ebb29",
                        "d42f853d-12d7-416d-8b27-c314ef563eed",
                        "d46e68dc-dbb7-4296-8f40-f3c513b432bc",
                        "d5e5a24d-f80e-4f1a-b48b-22403b653276",
                        "eb2dc957-4aae-4d39-a99d-8adab1effb39",
                        "f006e236-59ad-4647-a59f-4f46dc2c85be"
                    ],
                    "keyword": [
                        "data",
                        "svm",
                        "problem",
                        "optimization",
                        "training",
                        "sets",
                        "quadratic",
                        "present",
                        "points",
                        "iterative"
                    ],
                    "group": [],
                    "_id": "5ffac6f9-2456-42cf-830c-9049ce37c899",
                    "abstract": "We investigate the application of Support Vector Machines (SVMs) in computer vision. SVM is a learning technique developed by V. Vapnik and his team (AT&T Bell Labs., 1985) that can be seen as a new method for training polynomial, neural network, or Radial Basis Functions classifiers. The decision surfaces are found by solving a linearly constrained quadratic programming problem. This optimization problem is challenging because the quadratic form is completely dense and the memory requirements grow with the square of the number of data points. We present a decomposition algorithm that guarantees global optimality, and can be used to train SVM's over very large data sets. The main idea behind the decomposition is the iterative solution of sub-problems and the evaluation of optimality conditions which are used both to generate improved iterative values, and also establish the stopping criteria for the algorithm. We present experimental results of our implementation of SVM, and demonstrate the feasibility of our approach on a face detection problem that involves a data set of 50,000 data points.",
                    "title": "Training support vector machines: an application to face detection",
                    "venue": "computer vision and pattern recognition",
                    "year": 1997,
                    "__v": 2,
                    "citationCount": 975,
                    "result": 5.459563999811678
                },
                "6d121e97-e351-4cf9-8c44-d7ab3ce9d9fe": {
                    "authors": [
                        "Laurent Itti",
                        "Christof Koch",
                        "Ernst Niebur"
                    ],
                    "references": [
                        "f0d33a06-24c8-42c5-a8e9-839ea9891157",
                        "f4642ffc-3571-4d02-8b94-142f2448023a"
                    ],
                    "keyword": [
                        "system",
                        "visual",
                        "selects",
                        "saliency",
                        "locations",
                        "understanding",
                        "topographical",
                        "single",
                        "scene",
                        "rapidly"
                    ],
                    "group": [],
                    "_id": "6d121e97-e351-4cf9-8c44-d7ab3ce9d9fe",
                    "abstract": "A visual attention system, inspired by the behavior and the neuronal architecture of the early primate visual system, is presented. Multiscale image features are combined into a single topographical saliency map. A dynamical neural network then selects attended locations in order of decreasing saliency. The system breaks down the complex problem of scene understanding by rapidly selecting, in a computationally efficient manner, conspicuous locations to be analyzed in detail.",
                    "title": "A model of saliency-based visual attention for rapid scene analysis",
                    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "year": 1998,
                    "__v": 2,
                    "citationCount": 3535,
                    "result": 6.463166245519187
                },
                "9fa55b0f-eaa6-4c59-b6e5-77e5f1a406f0": {
                    "authors": [
                        "Franklin C. Crow"
                    ],
                    "references": [
                        "023ba930-7460-4044-98b9-f49a14423f8d",
                        "24170cb6-386a-4beb-bdbd-633643045a04",
                        "47cadce1-29d8-4a65-8d19-5d7acd50d366",
                        "6038a4bb-7978-4fac-9751-c929871d2fe4",
                        "9ecac0ea-d548-4b3d-b77d-bed14dc8c030"
                    ],
                    "keyword": [
                        "technique",
                        "texture",
                        "tables",
                        "function",
                        "costs",
                        "computations",
                        "yield",
                        "values",
                        "tractable",
                        "texturemap"
                    ],
                    "group": [],
                    "_id": "9fa55b0f-eaa6-4c59-b6e5-77e5f1a406f0",
                    "abstract": "Texture-map computations can be made tractable through use of precalculated tables which allow computational costs independent of the texture density. The first example of this technique, the “mip” map, uses a set of tables containing successively lower-resolution representations filtered down from the discrete texture function. An alternative method using a single table of values representing the integral over the texture function rather than the function itself may yield superior results at similar cost. The necessary algorithms to support the new technique are explained. Finally, the cost and performance of the new technique is compared to previous techniques.",
                    "title": "Summed-area tables for texture mapping",
                    "venue": "international conference on computer graphics and interactive techniques",
                    "year": 1984,
                    "__v": 2,
                    "citationCount": 488,
                    "result": 7.33559515819578
                },
                "c7f93552-c1ef-4ae4-b1f5-2317e1c9d904": {
                    "authors": [
                        "Henry Schneiderman",
                        "Takeo Kanade"
                    ],
                    "references": [
                        "310cbba4-d88d-4bf4-a4f2-738f91b5f8c8",
                        "4a29b56b-b74e-4945-9017-61a7ab844fd9",
                        "8f6a657e-e387-4572-bb88-91aee042e8da",
                        "96d6d9b9-6d69-4c9a-b3f5-c8083966d55c",
                        "bb83383f-0de9-408b-9ba2-aa902c63f14a",
                        "d5e5a24d-f80e-4f1a-b48b-22403b653276",
                        "d6e37fb1-5f7e-448e-847b-7d1f1271c574",
                        "db26488d-78be-44b1-a343-e896f43c5d29",
                        "ed59a2e5-7330-4e07-9edf-cc80872135d0"
                    ],
                    "keyword": [
                        "statistical",
                        "represent",
                        "object",
                        "histograms",
                        "detection",
                        "wide",
                        "reliably",
                        "method",
                        "algorithm",
                        "wavelet"
                    ],
                    "group": [],
                    "_id": "c7f93552-c1ef-4ae4-b1f5-2317e1c9d904",
                    "abstract": "In this paper, we describe a statistical method for 3D object detection. We represent the statistics of both object appearance and \"non-object\" appearance using a product of histograms. Each histogram represents the joint statistics of a subset of wavelet coefficients and their position on the object. Our approach is to use many such histograms representing a wide variety of visual attributes. Using this method, we have developed the first algorithm that can reliably detect human faces with out-of-plane rotation and the first algorithm that can reliably detect passenger cars over a wide range of viewpoints.",
                    "title": "A statistical method for 3D object detection applied to faces and cars",
                    "venue": "computer vision and pattern recognition",
                    "year": 2000,
                    "__v": 2,
                    "citationCount": 525,
                    "result": 9.592055167055172
                },
                "d5e5a24d-f80e-4f1a-b48b-22403b653276": {
                    "authors": [
                        "Kah Kay Sung",
                        "Tomaso Poggio"
                    ],
                    "references": [
                        "17bb9954-1e92-4f77-b952-8f99153aba0c",
                        "1e4f4b5c-55e0-4d5b-b7cc-9e7fada3e341",
                        "3b3d7569-08b1-4017-9910-2a017a00e43e",
                        "3e7823cd-cff6-43b3-8df8-990f5525eb50",
                        "64fa74e8-db02-4190-87d7-bf23e9859a7c",
                        "85114f9d-70a8-4940-83aa-af504b75acf8",
                        "9499c3b8-c1f9-4d80-9cfb-c0b9b26b2511"
                    ],
                    "keyword": [
                        "models",
                        "faces",
                        "vector",
                        "locating",
                        "image",
                        "human",
                        "feature",
                        "difference",
                        "patterns",
                        "nonface"
                    ],
                    "group": [],
                    "_id": "d5e5a24d-f80e-4f1a-b48b-22403b653276",
                    "abstract": "We present an example-based learning approach for locating vertical frontal views of human faces in complex scenes. The technique models the distribution of human face patterns by means of a few view-based \"face\" and \"nonface\" model clusters. At each image location, a difference feature vector is computed between the local image pattern and the distribution-based model. A trained classifier determines, based on the difference feature vector measurements, whether or not a human face exists at the current image location. We show empirically that the distance metric we adopt for computing difference feature vectors, and the \"nonface\" clusters we include in our distribution-based model, are both critical for the success of our system.",
                    "title": "Example-based learning for view-based human face detection",
                    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "year": 1998,
                    "__v": 2,
                    "citationCount": 802,
                    "result": 4.865875790875791
                },
                "d6e37fb1-5f7e-448e-847b-7d1f1271c574": {
                    "authors": [
                        "Henry A. Rowley",
                        "Shumeet Baluja",
                        "Takeo Kanade"
                    ],
                    "references": [
                        "0150e8cd-09bc-4991-92b4-454fe4b0bfac",
                        "0b4c0d6f-58fd-4704-98af-8c12de196ede",
                        "168d7a6e-46b3-41b6-8776-3890b23b6b1c",
                        "1863ec2a-4485-4bf6-80c4-6dfce4a8d627",
                        "1c940510-5473-4e01-9c7c-bce8e006134a",
                        "1d1fe6e4-bf7f-4785-893a-04156d3cfa6a",
                        "2a08b967-f90e-43d5-860e-d07ef09431c2",
                        "40f728c0-55b3-423b-aff5-a9b3ff27b7d5",
                        "47e8badc-7db1-4e43-99e7-6fea4a6d65e3",
                        "49b0495d-2caa-4dbf-b1ab-6f9695b8bd72",
                        "59242d60-5827-412a-ab6c-69ba14fa3b6a",
                        "5ffac6f9-2456-42cf-830c-9049ce37c899",
                        "6ca64ec6-3080-42c1-8970-33677cb1e3f1",
                        "772654a7-a951-4327-aca5-ba5da8dfec7c",
                        "79bd9613-8976-41a1-b0b7-133b80b8477e",
                        "88b9bcca-fb07-4eb3-8dba-d5a06741c360",
                        "91979159-37d8-410f-a245-a33ef80a092b",
                        "9499c3b8-c1f9-4d80-9cfb-c0b9b26b2511",
                        "98df207d-2dfc-4365-846a-c875a2a3a59e",
                        "ac0fee21-9f70-4e21-8536-5c9b5d3dc420",
                        "ae3e7593-586f-495f-9416-4b50ed1fcd10",
                        "cdbb7784-a0c2-4b40-bd6d-d14fc14651a7",
                        "ce9c0c07-83af-4fb7-9491-38255660025c",
                        "d42f853d-12d7-416d-8b27-c314ef563eed",
                        "e29cd2ee-bb3e-4c90-a085-ebd358cd4757",
                        "e41b2fd1-c576-453e-9a22-9b0eeafe308c",
                        "e9f4315c-139f-400c-b6e5-1e5cb369191d",
                        "eb2dc957-4aae-4d39-a99d-8adab1effb39",
                        "eca46fc4-e594-461f-83b8-aa5247e440ca",
                        "f3eb4ac3-9302-42aa-be89-7cf746f286fd",
                        "fe966e48-ad81-4d33-af4f-b9e2509b64ed"
                    ],
                    "keyword": [
                        "face",
                        "training",
                        "system",
                        "detection",
                        "present",
                        "network",
                        "image",
                        "examples",
                        "windows",
                        "performance"
                    ],
                    "group": [],
                    "_id": "d6e37fb1-5f7e-448e-847b-7d1f1271c574",
                    "abstract": "We present a neural network-based upright frontal face detection system. A retinally connected neural network examines small windows of an image and decides whether each window contains a face. The system arbitrates between multiple networks to improve performance over a single network. We present a straightforward procedure for aligning positive face examples for training. To collect negative examples, we use a bootstrap algorithm, which adds false detections into the training set as training progresses. This eliminates the difficult task of manually selecting nonface training examples, which must be chosen to span the entire space of nonface images. Simple heuristics, such as using the fact that faces rarely overlap in images, can further improve the accuracy. Comparisons with several other state-of-the-art face detection systems are presented, showing that our system has comparable performance in terms of detection and false-positive rates.",
                    "title": "Neural network-based face detection",
                    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "year": 1998,
                    "__v": 2,
                    "citationCount": 1384,
                    "result": 6.68916638916639
                },
                "f1bd37c4-d033-4cd1-af44-4df9f11c71e4": {
                    "authors": [
                        "F. Fleuret",
                        "Donald Geman"
                    ],
                    "references": [
                        "2958fc5c-15e8-45e7-8da8-d2e0fa46f0c7",
                        "5242f101-1511-4660-9a4c-4eb597aaa3c6",
                        "55fa440a-2b98-4e8e-bb45-fa09598b4eca",
                        "5ffac6f9-2456-42cf-830c-9049ce37c899",
                        "613841ae-c925-4aee-9c2e-8675213e4bbf",
                        "64fa74e8-db02-4190-87d7-bf23e9859a7c",
                        "6610284f-1f5a-4460-95d6-b0ad690e171d",
                        "6da113cb-3257-4014-990b-2ebbb7d998f2",
                        "757078f8-0e20-4c8b-a907-5d068db66fc4",
                        "762c9918-e579-42ef-80e5-4e464870a017",
                        "b85ac095-a9f2-4954-b2bf-f53fde98958c",
                        "bcc5343a-dee5-4e42-bd84-6700cbab125e",
                        "bec76d54-02fb-4e7e-8a9c-c058f780194d",
                        "cd9494ab-fbd2-401d-8afe-376c0bd24c80",
                        "d5e5a24d-f80e-4f1a-b48b-22403b653276",
                        "d6e37fb1-5f7e-448e-847b-7d1f1271c574",
                        "ea294286-3cc2-4979-a22b-2fbb78c2ef18"
                    ],
                    "keyword": [],
                    "group": [],
                    "_id": "f1bd37c4-d033-4cd1-af44-4df9f11c71e4",
                    "abstract": "We study visual selection: Detect and roughly localize all instances of a generic object class, such as a face, in a greyscale scene, measuring performance in terms of computation and false alarms. Our approach is sequential testing which is coarse-to-fine in both in the exploration of poses and the representation of objects. All the tests are binary and indicate the presence or absence of loose spatial arrangements of oriented edge fragments. Starting from training examples, we recursively find larger and larger arrangements which are “decomposable,” which implies the probability of an arrangement appearing on an object decays slowly with its size. Detection means finding a sufficient number of arrangements of each size along a decreasing sequence of pose cells. At the beginning, the tests are simple and universal, accommodating many poses simultaneously, but the false alarm rate is relatively high. Eventually, the tests are more discriminating, but also more complex and dedicated to specific poses. As a result, the spatial distribution of processing is highly skewed and detection is rapid, but at the expense of (isolated) false alarms which, presumably, could be eliminated with localized, more intensive, processing.",
                    "title": "Coarse-to-Fine Face Detection",
                    "venue": "International Journal of Computer Vision",
                    "year": 2001,
                    "__v": 0,
                    "citationCount": 131,
                    "result": 2.142857142857143
                }
            }
        ],
        "_id": "e649a9fd-f6d9-4aac-b428-29b82c20a484",
        "abstract": "This paper describes a machine learning approach for visual object detection which is capable of processing images extremely rapidly and achieving high detection rates. This work is distinguished by three key contributions. The first is the introduction of a new image representation called the \"integral image\" which allows the features used by our detector to be computed very quickly. The second is a learning algorithm, based on AdaBoost, which selects a small number of critical visual features from a larger set and yields extremely efficient classifiers. The third contribution is a method for combining increasingly more complex classifiers in a \"cascade\" which allows background regions of the image to be quickly discarded while spending more computation on promising object-like regions. The cascade can be viewed as an object specific focus-of-attention mechanism which unlike previous approaches provides statistical guarantees that discarded regions are unlikely to contain the object of interest. In the domain of face detection the system yields detection rates comparable to the best previous systems. Used in real-time applications, the detector runs at 15 frames per second without resorting to image differencing or skin color detection.",
        "title": "Rapid object detection using a boosted cascade of simple features",
        "venue": "computer vision and pattern recognition",
        "year": 2001,
        "__v": 3,
        "citationCount": 5200
    },
    {
        "authors": [
            "Ali Jadbabaie",
            "Jie Lin",
            "A.S. Morse"
        ],
        "references": [
            "aeabc622-720d-44d0-888c-787e7d377f54",
            "b6a0562d-91b9-4b65-a395-0e705e24f3ba",
            "cf772fd2-26e1-49d5-b59c-5854b276ab0d",
            "ee265d03-1a69-4425-b248-bd68bc9ed6e0"
        ],
        "keyword": [
            "headings",
            "agents",
            "vicsek",
            "neighbors",
            "model",
            "system",
            "rule",
            "results",
            "paper",
            "nearest"
        ],
        "group": [
            {
                "aeabc622-720d-44d0-888c-787e7d377f54": {
                    "authors": [
                        "Jaydev P. Desai",
                        "James P. Ostrowski",
                        "R. Vijay Kumar"
                    ],
                    "references": [
                        "05dc7361-18e9-42d3-8948-f49f7017a3ef",
                        "09dab3e4-6328-4370-a3ec-ed7ebf44405d",
                        "0cb61dc0-15c5-4592-a5fb-fd76d75f03ac",
                        "4e86ab99-7537-44aa-8446-f256922c934d",
                        "a3338531-6699-4121-a1fd-27a6b4a91028",
                        "b227829b-f971-48a9-92a1-65e31a217918"
                    ],
                    "keyword": [
                        "robots",
                        "formation",
                        "graph",
                        "describes",
                        "control",
                        "team",
                        "position",
                        "variables",
                        "triple",
                        "transitions"
                    ],
                    "group": [],
                    "_id": "aeabc622-720d-44d0-888c-787e7d377f54",
                    "abstract": "This paper addresses the control of a team of nonholonomic mobile robots navigating in a terrain with obstacles while maintaining a desired formation and changing formations when required, using graph theory. We model the team as a triple, (g, r, H), consisting of a group element g that describes the gross position of the lead robot, a set of shape variables r that describe the relative positions of robots, and a control graph H that describes the behaviors of the robots in the formation. Our framework enables the representation and enumeration of possible control graphs and the coordination of transitions between any two formations.",
                    "title": "Modeling and control of formations of nonholonomic mobile robots",
                    "venue": "international conference on robotics and automation",
                    "year": 2001,
                    "__v": 2,
                    "citationCount": 348,
                    "result": 3.0774753024753023
                },
                "b6a0562d-91b9-4b65-a395-0e705e24f3ba": {
                    "authors": [
                        "Craig W. Reynolds"
                    ],
                    "references": [
                        "0017a0a1-1988-41f4-84ae-831abc9d288d",
                        "031c805d-9b01-4359-82d9-62efb0125ed2",
                        "50689679-8346-48f2-8d70-4dfd29f8b470",
                        "65ade230-c556-4520-acfa-fa4d40e06f84",
                        "7cea31dc-2409-4487-aaf0-7e168a85235a",
                        "bb951809-08f1-4c31-a396-a2645a10def4",
                        "c89c5eee-93f3-47e8-bf8d-3c716cb36d88",
                        "cc2e8e22-90ad-449a-82b6-98277575425c",
                        "daef850c-4981-4eb3-8ec3-f50ae45fff46"
                    ],
                    "keyword": [
                        "simulation",
                        "birds",
                        "motion",
                        "flock",
                        "behavioral",
                        "animals",
                        "aggregate",
                        "particle",
                        "natural",
                        "individually"
                    ],
                    "group": [],
                    "_id": "b6a0562d-91b9-4b65-a395-0e705e24f3ba",
                    "abstract": "The aggregate motion of a flock of birds, a herd of land animals, or a school of fish is a beautiful and familiar part of the natural world. But this type of complex motion is rarely seen in computer animation. This paper explores an approach based on simulation as an alternative to scripting the paths of each bird individually. The simulated flock is an elaboration of a particle systems, with the simulated birds being the particles. The aggregate motion of the simulated flock is created by a distributed behavioral model much like that at work in a natural flock; the birds choose their own course. Each simulated bird is implemented as an independent actor that navigates according to its local perception of the dynamic environment, the laws of simulated physics that rule its motion, and a set of behaviors programmed into it by the \"animator.\" The aggregate motion of the simulated flock is the result of the dense interaction of the relatively simple behaviors of the individual simulated birds.",
                    "title": "Flocks, herds and schools: A distributed behavioral model",
                    "venue": "international conference on computer graphics and interactive techniques",
                    "year": 1987,
                    "__v": 2,
                    "citationCount": 2128,
                    "result": 2.425686241862712
                },
                "cf772fd2-26e1-49d5-b59c-5854b276ab0d": {
                    "authors": [
                        "Yang Liu",
                        "Kevin M. Passino",
                        "Marios M. Polycarpou"
                    ],
                    "references": [
                        "47aa8f65-89ee-425a-a10f-ea923b73db63",
                        "675525e3-866a-4414-b4f6-4a77bfcc4054",
                        "b6a0562d-91b9-4b65-a395-0e705e24f3ba",
                        "baf403cc-eaa6-4aa3-8a43-50d63ab45774",
                        "dba09d73-450f-4780-8b27-0b0eea033856"
                    ],
                    "keyword": [
                        "swarm",
                        "vehicles",
                        "stability",
                        "sensors",
                        "robots",
                        "provide",
                        "position",
                        "occurs",
                        "groups",
                        "coordinated"
                    ],
                    "group": [],
                    "_id": "cf772fd2-26e1-49d5-b59c-5854b276ab0d",
                    "abstract": "Coordinated dynamical swarm behavior occurs when certain types of animals forage for food or try to avoid predators. Analogous behaviors can occur in engineering systems such as in groups of autonomous mobile robots or air vehicles. In this paper we characterize swarm \"cohesiveness\" as a stability property and provide conditions under which convergence can be achieved for an asynchronous swarm with swarm members that have proximity sensors and neighbor position sensors that only provide delayed position information. Such stability analysis is fundamental to understand the coordination mechanisms for groups of autonomous vehicles or robots where inter-member communication channels are less than perfect.",
                    "title": "Stability analysis of one-dimensional asynchronous swarms",
                    "venue": "american control conference",
                    "year": 2001,
                    "__v": 2,
                    "citationCount": 7,
                    "result": 5.871480153833095
                },
                "ee265d03-1a69-4425-b248-bd68bc9ed6e0": {
                    "authors": [
                        "Petter Ögren",
                        "Magnus Egerstedt",
                        "Xiaoming Hu"
                    ],
                    "references": [
                        "05dc7361-18e9-42d3-8948-f49f7017a3ef",
                        "435d486d-ddea-4938-8bc4-297067c11dda",
                        "4e86ab99-7537-44aa-8446-f256922c934d",
                        "85e69023-a620-4e24-9a19-0791b8b33b11"
                    ],
                    "keyword": [
                        "robots",
                        "problem",
                        "lyapunov",
                        "functions",
                        "formation",
                        "control",
                        "velocity",
                        "time",
                        "theorems",
                        "task"
                    ],
                    "group": [],
                    "_id": "ee265d03-1a69-4425-b248-bd68bc9ed6e0",
                    "abstract": "In this paper, the multiagent coordination problem is studied. This problem is addressed for a class of robots for which control Lyapunov functions can be found. The main result is a suite of theorems about formation maintenance, task completion time, and formation velocity. It is also shown how to moderate the requirement that, for each individual robot, there exists a control Lyapunov function. An example is provided that illustrates the soundness of the method.",
                    "title": "A control Lyapunov function approach to multiagent coordination",
                    "venue": "international conference on robotics and automation",
                    "year": 2002,
                    "__v": 2,
                    "citationCount": 128,
                    "result": 2.3607087357087355
                }
            }
        ],
        "_id": "ea1d5c21-fba6-4fae-9fdc-ee7679ee46c9",
        "abstract": "In a recent Physical Review Letters article, Vicsek et al. propose a simple but compelling discrete-time model of n autonomous agents (i.e., points or particles) all moving in the plane with the same speed but with different headings. Each agent's heading is updated using a local rule based on the average of its own heading plus the headings of its \"neighbors.\" In their paper, Vicsek et al. provide simulation results which demonstrate that the nearest neighbor rule they are studying can cause all agents to eventually move in the same direction despite the absence of centralized coordination and despite the fact that each agent's set of nearest neighbors change with time as the system evolves. This paper provides a theoretical explanation for this observed behavior. In addition, convergence results are derived for several other similarly inspired models. The Vicsek model proves to be a graphic example of a switched linear system which is stable, but for which there does not exist a common quadratic Lyapunov function.",
        "title": "Coordination of groups of mobile autonomous agents using nearest neighbor rules",
        "venue": "IEEE Transactions on Automatic Control",
        "year": 2003,
        "__v": 2,
        "citationCount": 2265
    },
    {
        "authors": [
            "Andrew Y. Ng",
            "Michael I. Jordan",
            "Yair Weiss"
        ],
        "references": [
            "52b8747c-6eef-43bc-8e11-aa3c4aae1111",
            "5c89ee50-d7f5-4cd6-8eed-19a08efd6f90",
            "75d0cdfa-44cd-4fc3-ae56-72e982cb383b",
            "94898e1d-1e50-41ab-9dcc-2c2e030cddd0",
            "98cfeac3-9abb-4f5b-9705-158c3b7b9d3a",
            "d78003db-ad8a-48d2-be57-1c50e95cef72",
            "fbb1d0f0-290f-490d-baab-63d29bc5f794"
        ],
        "keyword": [
            "clustering",
            "algorithms",
            "spectral",
            "eigenvectors",
            "wide",
            "variety",
            "unresolved",
            "tools",
            "theory",
            "surprisingly"
        ],
        "group": [
            {
                "52b8747c-6eef-43bc-8e11-aa3c4aae1111": {
                    "authors": [
                        "Charles J. Alpert",
                        "So-Zen Yao"
                    ],
                    "references": [
                        "1a72a4c9-b314-4ef4-9dfb-6b8213091aa8",
                        "2850b715-0f22-444c-a1cb-07c0df652140",
                        "63ec4f55-8f3b-431e-88e5-87c04caa7e9f",
                        "68fa35f1-e8ee-493b-be2f-c2e00dd54db0",
                        "6f7517aa-b3dd-4289-a44e-42cec8ef0370",
                        "c8c88c99-84c5-4988-bfa4-72f03bd8a74f",
                        "cdcfb25d-fe03-4e27-b35c-334b705b3564",
                        "d2c126a7-4d95-4031-b089-f290811aa4c9",
                        "f91c810e-0d12-4541-85b3-d76c2aa5566d"
                    ],
                    "keyword": [
                        "partitioning",
                        "vector",
                        "heuristically",
                        "graph's",
                        "eigenvectors",
                        "ordering"
                    ],
                    "group": [],
                    "_id": "52b8747c-6eef-43bc-8e11-aa3c4aae1111",
                    "abstract": "A spectral partitioning method uses the eigenvectors of a graph's adjacency or Laplacian matrix to construct a geometric representation (e.g., a linear ordering) which is then heuristically partitioned. We map each graph vertex to a vector in d-dimensional space, where d is the number of eigenvectors, such that these vectors constitute an instance of the vector partitioning problem. When all the eigenvectors are used, graph partitioning exactly reduces to vector partitioning. This result motivates a simple ordering heuristic that can be used to yield high-quality 2-way and multi-way partitionings. Our experiments suggest the vector partitioning perspective opens the door to new and effective heuristics.",
                    "title": "Spectral Partitioning: The More Eigenvectors, The Better",
                    "venue": "design automation conference",
                    "year": 1995,
                    "__v": 2,
                    "citationCount": 86,
                    "result": 6.877893852008806
                },
                "5c89ee50-d7f5-4cd6-8eed-19a08efd6f90": {
                    "authors": [
                        "Nello Cristianini",
                        "John Shawe-Taylor",
                        "Jaz S. Kandola"
                    ],
                    "references": [
                        "9c2ed18d-2a96-48f2-ab3c-49b67a88f218"
                    ],
                    "keyword": [
                        "optimize",
                        "labeled",
                        "functions",
                        "cost",
                        "algorithms",
                        "unsupervised",
                        "resulting",
                        "related",
                        "problem",
                        "paper"
                    ],
                    "group": [],
                    "_id": "5c89ee50-d7f5-4cd6-8eed-19a08efd6f90",
                    "abstract": "In this paper we introduce new algorithms for unsupervised learning based on the use of a kernel matrix. All the information required by such algorithms is contained in the eigenvectors of the matrix or of closely related matrices. We use two different but related cost functions, the Alignment and the 'cut cost'. The first one is discussed in a companion paper [3], the second one is based on graph theoretic concepts. Both functions measure the level of clustering of a labeled dataset, or the correlation between data clusters and labels. We state the problem of unsupervised learning as assigning labels so as to optimize these cost functions. We show how the optimal solution can be approximated by slightly relaxing the corresponding optimization problem, and how this corresponds to using eigenvector information. The resulting simple algorithms are tested on real world data with positive results.",
                    "title": "Spectral Kernel Methods for Clustering",
                    "venue": "neural information processing systems",
                    "year": 2002,
                    "__v": 2,
                    "citationCount": 32,
                    "result": 4.744020676605815
                },
                "75d0cdfa-44cd-4fc3-ae56-72e982cb383b": {
                    "authors": [
                        "Ravi Kannan",
                        "Santosh Vempala",
                        "Andre Mia Veta"
                    ],
                    "references": [
                        "52b8747c-6eef-43bc-8e11-aa3c4aae1111",
                        "63139dcf-11e2-4b8e-bcbd-ebd1f0511389",
                        "6c4b0829-01d8-407a-8cab-53cd38080c2f",
                        "70c53433-0357-4957-9089-6e59a06282c3",
                        "7ec5f06e-2fe3-495a-84a0-94fcfe08bb7b",
                        "93b14f9a-884c-441a-b91d-66a659248c0d",
                        "9438a773-c15c-4ef2-a97c-54f643ce6082",
                        "b613fdc9-9f3c-484c-aac3-2d55eadf7cbb",
                        "c19c233b-6b1d-40a9-b553-a6efbe11932c",
                        "c4d758e3-eadb-4d0f-828f-323ff3a1dd8c",
                        "d78003db-ad8a-48d2-be57-1c50e95cef72",
                        "d7953b97-e51b-45e2-b0f7-5e2eed1f9bd3",
                        "e1ebee81-dfa4-4fe0-b0e1-c00df9ada4d4",
                        "ecefe0b5-db61-490b-8a4b-56abf2a8e5ab",
                        "fec44afc-ba10-4d57-a898-4208e83890eb"
                    ],
                    "keyword": [
                        "clustering",
                        "spectral",
                        "quality",
                        "measure",
                        "guarantees",
                        "algorithm",
                        "worstcase",
                        "worst",
                        "simple",
                        "shown"
                    ],
                    "group": [],
                    "_id": "75d0cdfa-44cd-4fc3-ae56-72e982cb383b",
                    "abstract": "We propose a new measure for assessing the quality of a clustering. A simple heuristic is shown to give worst-case guarantees under the new measure. Then we present two results regarding the quality of the clustering found by a popular spectral algorithm. One proffers worst case guarantees whilst the other shows that if there exists a \"good\" clustering then the spectral algorithm will find one close to it.",
                    "title": "On clusterings-good, bad and spectral",
                    "venue": "foundations of computer science",
                    "year": 2000,
                    "__v": 2,
                    "citationCount": 172,
                    "result": 10.559652430472866
                },
                "94898e1d-1e50-41ab-9dcc-2c2e030cddd0": {
                    "authors": [
                        "Bernhard Schölkopf",
                        "Alexander J. Smola",
                        "Klaus-Robert Müller"
                    ],
                    "references": [
                        "29e06cb4-0ae3-4c7b-863a-d63ced9b1fa2",
                        "50dd56db-151d-4d62-8576-65f0ef6f381b",
                        "7b57db11-7c4d-4d1e-aa62-3a5d7d1f7987",
                        "7c016469-519e-4f34-9655-cf37f116942b",
                        "7d575c42-b8c4-43fe-bf75-842cfe0a3fe3",
                        "85114f9d-70a8-4940-83aa-af504b75acf8",
                        "87969fc2-8332-4ee5-b6b0-e1b26d01ebd4",
                        "a8693e98-1ed1-457b-a9fa-0f03395ce3fe",
                        "ae3e7593-586f-495f-9416-4b50ed1fcd10",
                        "aec3237b-b440-4d97-91a7-f57c249f82d6",
                        "b33eea94-414c-4232-a1b8-1ffc687c1d61",
                        "d46e68dc-dbb7-4296-8f40-f3c513b432bc",
                        "db84fccc-eb21-4b65-9ea5-7be175c6fc24",
                        "f006e236-59ad-4647-a59f-4f46dc2c85be",
                        "f15b056f-a577-4391-9724-a5be885e2bd2"
                    ],
                    "keyword": [
                        "spaces",
                        "principal",
                        "nonlinear",
                        "method",
                        "feature",
                        "component",
                        "16",
                        "results",
                        "related",
                        "recognition"
                    ],
                    "group": [],
                    "_id": "94898e1d-1e50-41ab-9dcc-2c2e030cddd0",
                    "abstract": "A new method for performing a nonlinear form of principal component analysis is proposed. By the use of integral operator kernel functions, one can efficiently compute principal components in high-dimensional feature spaces, related to input space by some nonlinear map—for instance, the space of all possible five-pixel products in 16 × 16 images. We give the derivation of the method and present experimental results on polynomial feature extraction for pattern recognition.",
                    "title": "Nonlinear component analysis as a kernel eigenvalue problem",
                    "venue": "Neural Computation",
                    "year": 1998,
                    "__v": 2,
                    "citationCount": 2527,
                    "result": 3.826503424336241
                },
                "98cfeac3-9abb-4f5b-9705-158c3b7b9d3a": {
                    "authors": [
                        "Jitendra Malik",
                        "Serge J. Belongie",
                        "Thomas K. Leung",
                        "Jianbo Shi"
                    ],
                    "references": [
                        "0ab71a43-a7d8-437c-83e0-6caf7523235f",
                        "0e0cb734-b4cd-483b-9c14-1ac6bae3313d",
                        "25b0c9f9-0c8a-4f2a-b075-90d339b6faa3",
                        "2a6b7b7a-a43b-4390-8601-e0165ec2f2cc",
                        "37ea1824-917d-4fff-b057-6baaa3da5eb4",
                        "4b230d75-936c-4a3f-9c1c-725bfd52ac51",
                        "57e35e32-f009-4b9b-bfb2-3747eac40b72",
                        "5b255d3a-5639-41cf-886b-8377bea8193f",
                        "6088acf8-dc40-4054-91c1-15c6ca7db4b0",
                        "613ccc65-c740-48c2-bc5a-a40201830c00",
                        "6cd1fccd-865f-4d54-b037-d622dbcfaf00",
                        "6fd932e6-412c-46a6-a623-1e582e0a04e4",
                        "805dd061-a59c-4599-a019-090d2ceb64f8",
                        "9438a773-c15c-4ef2-a97c-54f643ce6082",
                        "9c4bc7e5-5ab3-4561-96d5-e8d857860257",
                        "9d083ab3-6b3f-4746-a8ca-15aaba4eb400",
                        "d5deb58f-4ff6-49f7-a610-00cd35fdde28",
                        "d61e46ec-1332-4e40-a442-9e036507775a",
                        "d78003db-ad8a-48d2-be57-1c50e95cef72"
                    ],
                    "keyword": [
                        "texture",
                        "regions",
                        "images",
                        "cues",
                        "contour",
                        "pixel",
                        "partitioning",
                        "framework",
                        "coherent",
                        "brightness"
                    ],
                    "group": [],
                    "_id": "98cfeac3-9abb-4f5b-9705-158c3b7b9d3a",
                    "abstract": "This paper provides an algorithm for partitioning grayscale images into disjoint regions of coherent brightness and texture. Natural images contain both textured and untextured regions, so the cues of contour and texture differences are exploited simultaneously. Contours are treated in the intervening contour framework, while texture is analyzed using textons. Each of these cues has a domain of applicability, so to facilitate cue combination we introduce a gating operator based on the texturedness of the neighborhood at a pixel. Having obtained a local measure of how likely two nearby pixels are to belong to the same region, we use the spectral graph theoretic framework of normalized cuts to find partitions of the image into regions of coherent texture and brightness. Experimental results on a wide range of images are shown.",
                    "title": "Contour and Texture Analysis for Image Segmentation",
                    "venue": "International Journal of Computer Vision",
                    "year": 2001,
                    "__v": 2,
                    "citationCount": 484,
                    "result": 5.120035803549735
                },
                "d78003db-ad8a-48d2-be57-1c50e95cef72": {
                    "authors": [
                        "Yair Weiss"
                    ],
                    "references": [
                        "2e1d6310-46b9-400f-bfe4-9de099193cd1",
                        "6e184d1b-925b-4918-b354-a2647e8fd945",
                        "8742180d-2a83-478a-b5d2-43a52423d1fe",
                        "9438a773-c15c-4ef2-a97c-54f643ce6082",
                        "bf709674-bab3-478a-ae07-e4f85c500ec7"
                    ],
                    "keyword": [
                        "algorithms",
                        "segmentation",
                        "eigenvectors",
                        "understood",
                        "simple",
                        "results",
                        "performance",
                        "methods",
                        "images",
                        "grouping"
                    ],
                    "group": [],
                    "_id": "d78003db-ad8a-48d2-be57-1c50e95cef72",
                    "abstract": "Automatic grouping and segmentation of images remains a challenging problem in computer vision. Recently, a number of authors have demonstrated good performance on this task using methods that are based on eigenvectors of the affinity matrix. These approaches are extremely attractive in that they are based on simple eigendecomposition algorithms whose stability is well understood. Nevertheless, the use of eigendecompositions in the context of segmentation is far from well understood. In this paper we give a unified treatment of these algorithms, and show the close connections between them while highlighting their distinguishing features. We then prove results on eigenvectors of block matrices that allow us to analyze the performance of these algorithms in simple grouping settings. Finally, we use our analysis to motivate a variation on the existing methods that combines aspects from different eigenvector segmentation algorithms. We illustrate our analysis with results on real and synthetic images.",
                    "title": "Segmentation using eigenvectors: a unifying view",
                    "venue": "international conference on computer vision",
                    "year": 1999,
                    "__v": 2,
                    "citationCount": 341,
                    "result": 6.92227175988786
                },
                "fbb1d0f0-290f-490d-baab-63d29bc5f794": {
                    "authors": [
                        "Marina Meila",
                        "Jianbo Shi"
                    ],
                    "references": [
                        "0cdb081e-f2db-49d9-8c65-45cbcc948265",
                        "2256cad0-cf03-42da-bcf3-4a89be0ebf8e",
                        "6e184d1b-925b-4918-b354-a2647e8fd945",
                        "75d0cdfa-44cd-4fc3-ae56-72e982cb383b",
                        "98cfeac3-9abb-4f5b-9705-158c3b7b9d3a",
                        "d78003db-ad8a-48d2-be57-1c50e95cef72"
                    ],
                    "keyword": [
                        "similarities",
                        "methods",
                        "walk",
                        "segmentation",
                        "interpret",
                        "framework",
                        "view",
                        "transition",
                        "study",
                        "spectral"
                    ],
                    "group": [],
                    "_id": "fbb1d0f0-290f-490d-baab-63d29bc5f794",
                    "abstract": "We present a new view of image segmentation by pairwise similarities. We interpret the similarities as edge flows in a Markov random walk and study the eigenvalues and eigenvectors of the walk's transition matrix. This interpretation shows that spectral methods for clustering and segmentation have a probabilistic foundation. In particular, we prove that the Normalized Cut method arises naturally from our framework. Finally, the framework provides a principled method for learning the similarity function as a combination of features.",
                    "title": "Learning Segmentation by Random Walks",
                    "venue": "neural information processing systems",
                    "year": 2001,
                    "__v": 2,
                    "citationCount": 145,
                    "result": 9.783593848531929
                }
            }
        ],
        "_id": "ea8cd3d8-17ae-4a1e-8f83-1609469087af",
        "abstract": "Despite many empirical successes of spectral clustering methods— algorithms that cluster points using eigenvectors of matrices derived from the data—there are several unresolved issues. First. there are a wide variety of algorithms that use the eigenvectors in slightly different ways. Second, many of these algorithms have no proof that they will actually compute a reasonable clustering. In this paper, we present a simple spectral clustering algorithm that can be implemented using a few lines of Matlab. Using tools from matrix perturbation theory, we analyze the algorithm, and give conditions under which it can be expected to do well. We also show surprisingly good experimental results on a number of challenging clustering problems.",
        "title": "On Spectral Clustering: Analysis and an algorithm",
        "venue": "neural information processing systems",
        "year": 2002,
        "__v": 2,
        "citationCount": 2537
    },
    {
        "authors": [
            "Bo Pang",
            "Lillian Lee",
            "Shivakumar Vaithyanathan"
        ],
        "references": [
            "01f443e7-ea4c-48a7-8081-745c3fa62769",
            "21421f14-af9c-4c95-9aad-b7bece9fb7d9",
            "23b2db98-6897-497b-8b90-67b591016a5e",
            "3b20d6fb-4f2c-4eab-b5a3-82746b83f1f1",
            "43bcc79f-1316-4a3c-81ba-69e6c3afbcbb",
            "691983e4-67cb-4456-9462-42b22c620c64",
            "75ec0b95-65c5-48c9-ae1b-a44c6c378bec",
            "90ca3ecc-702a-45ab-af75-8c5851ce7bb9",
            "96d6d9b9-6d69-4c9a-b3f5-c8083966d55c",
            "a4830914-2189-4c4b-bfa4-adc5b45b7c23",
            "ab339474-ea21-443b-893f-96ae09e65a2e",
            "c75c7b08-7264-4daa-a133-59bea66db0c7",
            "c7ce0fc7-4d38-4355-aa19-ab35527d2519",
            "cf111a55-139a-4108-bf05-a8e25ec7874f",
            "ddef8d03-46e5-4df7-ac2d-ce48d54ba742",
            "e1f8e6f0-eee8-4e01-ace1-cbc47ac3880a",
            "ed8013b0-9bdd-4bc6-b31a-70fca6d15aa9"
        ],
        "keyword": [
            "sentiment",
            "machine",
            "classification",
            "review",
            "problem",
            "learning",
            "vector",
            "traditional",
            "topicbased",
            "topic"
        ],
        "group": [
            {
                "21421f14-af9c-4c95-9aad-b7bece9fb7d9": {
                    "authors": [
                        "Vasileios Hatzivassiloglou",
                        "Kathleen McKeown"
                    ],
                    "references": [
                        "0c35895c-9f13-4678-80f3-9310652446e0",
                        "1f4e9897-ec06-42e7-a70f-c77fc7484395",
                        "558dee29-ba49-4949-bbb8-ac8bb76541fd",
                        "69df0789-a06f-4166-9c34-93047de2673d",
                        "85dced95-605b-495d-9009-3465a1d487cc",
                        "bf6f26d3-1796-4152-85ac-d5922698d8d3",
                        "f9759d6e-a74f-4d6c-ae70-ffe454771288"
                    ],
                    "keyword": [
                        "adjectives",
                        "orientation",
                        "constraints",
                        "conjunctions",
                        "positive",
                        "negative",
                        "corpus",
                        "conjoined"
                    ],
                    "group": [],
                    "_id": "21421f14-af9c-4c95-9aad-b7bece9fb7d9",
                    "abstract": "We identify and validate from a large corpus constraints from conjunctions on the positive or negative semantic orientation of the conjoined adjectives. A log-linear regression model uses these constraints to predict whether conjoined adjectives are of same or different orientations, achieving 82% accuracy in this task when each conjunction is considered independently. Combining the constraints across many adjectives, a clustering algorithm separates the adjectives into groups of different orientations, and finally, adjectives are labeled positive or negative. Evaluations on real data and simulation experiments indicate high levels of performance: classification precision is more than 90% for adjectives that occur in a modest number of conjunctions in the corpus.",
                    "title": "Predicting the Semantic Orientation of Adjectives",
                    "venue": "meeting of the association for computational linguistics",
                    "year": 1997,
                    "__v": 2,
                    "citationCount": 663,
                    "result": 6.052003330869933
                },
                "90ca3ecc-702a-45ab-af75-8c5851ce7bb9": {
                    "authors": [
                        "Jussi Karlgren",
                        "Douglas R. Cutting"
                    ],
                    "references": [
                        "0c35895c-9f13-4678-80f3-9310652446e0",
                        "407ceb18-464f-4ab3-b731-68f7681fb26d",
                        "a05838da-089f-4be8-a169-b0223ae4f0ac",
                        "af23f3f8-6377-4848-b925-6355712cb35f"
                    ],
                    "keyword": [
                        "texts",
                        "discriminant",
                        "parameters",
                        "number",
                        "information",
                        "genre",
                        "corpus",
                        "application",
                        "analysis",
                        "weighted"
                    ],
                    "group": [],
                    "_id": "90ca3ecc-702a-45ab-af75-8c5851ce7bb9",
                    "abstract": "A simple method for categorizing texts into pre-determined text genre categories using the statistical standard technique of discriminant analysis is demonstrated with application to the Brown corpus. Discriminant analysis makes it possible use a large number of parameters that may be specific for a certain corpus or information stream, and combine them into a small number of functions, with the parameters weighted on basis of how useful they are for discriminating text genres. An application to information retrieval is discussed.",
                    "title": "Recognizing text genres with simple metrics using discriminant analysis",
                    "venue": "international conference on computational linguistics",
                    "year": 1994,
                    "__v": 1,
                    "citationCount": 106,
                    "result": 4.467742031976788
                },
                "96d6d9b9-6d69-4c9a-b3f5-c8083966d55c": {
                    "authors": [
                        "Pedro M. Domingos",
                        "Michael J. Pazzani"
                    ],
                    "references": [
                        "29a79d67-73a4-4990-9880-f9cc5b56c6f2",
                        "340c101a-7317-4ba9-b642-a91eb2e456a7",
                        "3a90b5d2-3377-4ffa-9545-9ef332679370",
                        "3b2d19a3-29b8-4983-832a-08e489f13f38",
                        "47b2f222-c6c2-4cb2-9aa0-07e7f7b8fea4",
                        "485598b2-ed73-4670-a44d-b0844f923fa4",
                        "4935259d-fca4-454d-9128-6dfed1c72357",
                        "4ca9b504-fdf7-4963-89a1-170608086f35",
                        "60ac157b-ad14-49c3-a901-6673c71cdb9d",
                        "62549bc2-e0b3-46e8-8d32-390dded105d5",
                        "7f60f284-50e8-4bf3-92c5-db7ef4975434",
                        "86dafb65-1d2e-42d9-8982-4d520b6da774",
                        "9d391f89-9fbd-438a-bbba-57f8fe085e0c",
                        "ac28de8d-4445-4d2d-a134-7f0e835ebca9",
                        "ad4af6f6-2bb4-47c5-9e26-e3877f28b4d8",
                        "cda06ad5-1cad-4bb7-834f-cd5693ad277a",
                        "d5f75cb3-4d88-4471-af2e-d1d4a3dc14fa",
                        "d6f92f3a-fff7-4312-be70-72f61e92913d",
                        "df1f94be-7bf8-4696-b0b5-42a02e06275c",
                        "e1662082-8ddd-4df1-90a9-c1f30382b3d0",
                        "ed748247-965b-4857-a004-7531209fa975",
                        "f76331c6-7be5-4f61-bbb1-25ea462536e6",
                        "f9de53f4-b2fe-46eb-888d-7497862b5354",
                        "fa70488d-1d06-4967-8c8e-c678cf1052c8"
                    ],
                    "keyword": [
                        "optimal",
                        "classifier",
                        "bayesian",
                        "attributes",
                        "showing",
                        "independent",
                        "domains",
                        "assumption",
                        "article"
                    ],
                    "group": [],
                    "_id": "96d6d9b9-6d69-4c9a-b3f5-c8083966d55c",
                    "abstract": "The simple Bayesian classifier is known to be optimal when attributes are independent given the class, but the question of whether other sufficient conditions for its optimality exist has so far not been explored. Empirical results showing that it performs surprisingly well in many domains containing clear attribute dependences suggest that the answer to this question may be positive. This article shows that, although the Bayesian classifier‘s probability estimates are only optimal under quadratic loss if the independence assumption holds, the classifier itself can be optimal under zero-one loss (misclassification rate) even when this assumption is violated by a wide margin. The region of quadratic-loss optimality of the Bayesian classifier is in fact a second-order infinitesimal fraction of the region of zero-one optimality. This implies that the Bayesian classifier has a much greater range of applicability than previously thought. For example, in this article it is shown to be optimal for learning conjunctions and disjunctions, even though they violate the independence assumption. Further, studies in artificial domains show that it will often outperform more powerful classifiers for common training set sizes and numbers of attributes, even if its bias is a priori much less appropriate to the domain. This article‘s results also imply that detecting attribute dependence is not necessarily the best way to extend the Bayesian classifier, and this is also verified empirically.",
                    "title": "On the Optimality of the Simple Bayesian Classifier under Zero-One Loss",
                    "venue": "Machine Learning",
                    "year": 1997,
                    "__v": 2,
                    "citationCount": 1021,
                    "result": 6.380432458838032
                },
                "a4830914-2189-4c4b-bfa4-adc5b45b7c23": {
                    "authors": [
                        "Ted Pedersen"
                    ],
                    "references": [
                        "01b26291-a389-40b7-a3a9-53f38a3884ec",
                        "12c253c7-3370-4e51-9661-08387e32ba34",
                        "132dec8f-a17d-437a-af24-0074c4b454e4",
                        "25ba4997-7f75-4ea3-97ed-85fb0b13d70d",
                        "26d386eb-ef6b-409e-88b2-3bf50eef4ce6",
                        "44880061-3ec8-4779-b394-156d6a9e3245",
                        "46b72748-859f-41ca-8679-2c6430de8f76",
                        "7a10be82-6113-4f60-9e37-f35f2d9423c5",
                        "a2017f4a-cff4-4d0e-addc-5bd21c122b44",
                        "aa9af505-b437-4081-ba4a-97f0355a7f9e",
                        "bd4b835e-9b9d-45ae-aeba-ed27d06b7f3a",
                        "ca46649f-54c3-4138-ac4b-abd784e99f0d",
                        "cd062a74-6824-4d7a-ac17-6939d41a520c",
                        "d5bb0ee8-60da-462c-af12-406e978cfb36",
                        "fac7f7cc-ab0d-48ec-9488-79dbc19380cc"
                    ],
                    "keyword": [
                        "word",
                        "sense",
                        "results",
                        "disambiguation",
                        "approach",
                        "accurate",
                        "36",
                        "tree",
                        "senseval",
                        "sensetagged"
                    ],
                    "group": [],
                    "_id": "a4830914-2189-4c4b-bfa4-adc5b45b7c23",
                    "abstract": "This paper presents a corpus-based approach to word sense disambiguation where a decision tree assigns a sense to an ambiguous word based on the bigrams that occur nearby. This approach is evaluated using the sense-tagged corpora from the 1998 SENSEVAL word sense disambiguation exercise. It is more accurate than the average results reported for 30 of 36 words, and is more accurate than the best results for 19 of 36 words.",
                    "title": "A decision tree of bigrams is an accurate predictor of word sense",
                    "venue": "north american chapter of the association for computational linguistics",
                    "year": 2001,
                    "__v": 1,
                    "citationCount": 53,
                    "result": 4.169207070953604
                },
                "ab339474-ea21-443b-893f-96ae09e65a2e": {
                    "authors": [
                        "Brett L. Kessler",
                        "Geoffrey Nunberg",
                        "Hinrich Schütze"
                    ],
                    "references": [
                        "7870231d-c710-4aa1-9ad3-ae121e3b488e",
                        "90ca3ecc-702a-45ab-af75-8c5851ce7bb9"
                    ],
                    "keyword": [
                        "genre",
                        "surface",
                        "structural",
                        "detection",
                        "cues",
                        "based",
                        "users",
                        "topical",
                        "theory",
                        "text"
                    ],
                    "group": [],
                    "_id": "ab339474-ea21-443b-893f-96ae09e65a2e",
                    "abstract": "As the text databases available to users become larger and more heterogeneous, genre becomes increasingly important for computational linguistics as a complement to topical and structural principles of classification. We propose a theory of genres as bundles of facets, which correlate with various surface cues, and argue that genre detection based on surface cues is as successful as detection based on deeper structural properties.",
                    "title": "Automatic Detection of Text Genre",
                    "venue": "meeting of the association for computational linguistics",
                    "year": 1997,
                    "__v": 2,
                    "citationCount": 158,
                    "result": 5.925066385283103
                },
                "c75c7b08-7264-4daa-a133-59bea66db0c7": {
                    "authors": [
                        "Peter D. Turney"
                    ],
                    "references": [
                        "21421f14-af9c-4c95-9aad-b7bece9fb7d9",
                        "4299e3db-c1dd-486a-9ff2-7f5b5f8aa402",
                        "43bcc79f-1316-4a3c-81ba-69e6c3afbcbb",
                        "691983e4-67cb-4456-9462-42b22c620c64",
                        "aab1a31b-5b8b-42af-8300-f1da4dc67827",
                        "adaaafab-aa7a-4b1e-842d-e29c8c2f049b",
                        "d5bb0ee8-60da-462c-af12-406e978cfb36",
                        "d72e4002-82ec-483a-b381-9fc4dc56186b",
                        "f998a503-422a-46ef-adf3-8c23579d7be5"
                    ],
                    "keyword": [
                        "reviews",
                        "phrases",
                        "semantic",
                        "orientation",
                        "recommended",
                        "average",
                        "word",
                        "thumbs",
                        "positive",
                        "paper"
                    ],
                    "group": [],
                    "_id": "c75c7b08-7264-4daa-a133-59bea66db0c7",
                    "abstract": "This paper presents a simple unsupervised learning algorithm for classifying reviews as recommended (thumbs up) or not recommended (thumbs down). The classification of a review is predicted by the average semantic orientation of the phrases in the review that contain adjectives or adverbs. A phrase has a positive semantic orientation when it has good associations (e.g., \"subtle nuances\") and a negative semantic orientation when it has bad associations (e.g., \"very cavalier\"). In this paper, the semantic orientation of a phrase is calculated as the mutual information between the given phrase and the word \"excellent\" minus the mutual information between the given phrase and the word \"poor\". A review is classified as recommended if the average semantic orientation of its phrases is positive. The algorithm achieves an average accuracy of 74% when evaluated on 410 reviews from Epinions, sampled from four different domains (reviews of automobiles, banks, movies, and travel destinations). The accuracy ranges from 84% for automobile reviews to 66% for movie reviews.",
                    "title": "Thumbs Up or Thumbs Down? Semantic Orientation Applied to Unsupervised Classification of Reviews",
                    "venue": "meeting of the association for computational linguistics",
                    "year": 2002,
                    "__v": 2,
                    "citationCount": 1549,
                    "result": 7.904831740401804
                },
                "cf111a55-139a-4108-bf05-a8e25ec7874f": {
                    "authors": [
                        "Aidan Finn",
                        "Nicholas Kushmerick",
                        "Barry Smyth"
                    ],
                    "references": [
                        "96dbd157-1e72-475a-a7c2-1cdd394ec24e",
                        "aab1a31b-5b8b-42af-8300-f1da4dc67827",
                        "f998a503-422a-46ef-adf3-8c23579d7be5"
                    ],
                    "keyword": [
                        "documents",
                        "genre",
                        "words",
                        "transfer",
                        "traditional",
                        "techniques",
                        "partofspeech",
                        "identify",
                        "domain",
                        "corpus"
                    ],
                    "group": [],
                    "_id": "cf111a55-139a-4108-bf05-a8e25ec7874f",
                    "abstract": "The World Wide Web is a vast repository of information, but the sheer volume makes it difficult to identify useful documents. We identify document genre is an important factor in retrieving useful documents and focus on the novel document genre dimension of subjectivity. We investigate three approaches to automatically classifying documents by genre: traditional bag of words techniques, part-of-speech statistics, and hand-crafted shallow linguistic features. We are particularly interested in domain transfer: how well the learned classifiers generalize from the training corpus to a new document corpus. Our experiments demonstrate that the part-of-speech approach is better than traditional bag of words techniques, particularly in the domain transfer conditions.",
                    "title": "Genre Classification and Domain Transfer for Information Filtering",
                    "venue": "european conference on information retrieval",
                    "year": 2002,
                    "__v": 2,
                    "citationCount": 31,
                    "result": 5.154617973671682
                },
                "ddef8d03-46e5-4df7-ac2d-ce48d54ba742": {
                    "authors": [
                        "Peter D. Turney",
                        "Michael L. Littman"
                    ],
                    "references": [
                        "21421f14-af9c-4c95-9aad-b7bece9fb7d9",
                        "691983e4-67cb-4456-9462-42b22c620c64",
                        "adaaafab-aa7a-4b1e-842d-e29c8c2f049b"
                    ],
                    "keyword": [
                        "semantic",
                        "orientation",
                        "word",
                        "algorithm",
                        "web",
                        "tested",
                        "search",
                        "results",
                        "positive",
                        "negative"
                    ],
                    "group": [],
                    "_id": "ddef8d03-46e5-4df7-ac2d-ce48d54ba742",
                    "abstract": "The evaluative character of a word is called its semantic orientation. A positive semantic orientation implies desirability (e.g., \"honest\", \"intrepid\") and a negative semantic orientation implies undesirability (e.g., \"disturbing\", \"superfluous\"). This paper introduces a simple algorithm for unsupervised learning of semantic orientation from extremely large corpora. The method involves issuing queries to a Web search engine and using pointwise mutual information to analyse the results. The algorithm is empirically evaluated using a training corpus of approximately one hundred billion words  the subset of the Web that is indexed by the chosen search engine. Tested with 3,596 words (1,614 positive and 1,982 negative), the algorithm attains an accuracy of 80%. The 3,596 test words include adjectives, adverbs, nouns, and verbs. The accuracy is comparable with the results achieved by Hatzivassiloglou and McKeown (1997), using a complex four-stage supervised learning algorithm that is restricted to determining the semantic orientation of adjectives.",
                    "title": "Unsupervised Learning of Semantic Orientation from a Hundred-Billion-Word Corpus",
                    "venue": "arXiv: Learning",
                    "year": 2002,
                    "__v": 2,
                    "citationCount": 115,
                    "result": 7.1508400664410905
                },
                "e1f8e6f0-eee8-4e01-ace1-cbc47ac3880a": {
                    "authors": [
                        "Stanley F. Chen",
                        "Ronald Rosenfeld"
                    ],
                    "references": [
                        "01f443e7-ea4c-48a7-8081-745c3fa62769",
                        "05d0ec98-5acc-4675-b1eb-59a960f106e3",
                        "067692a8-da25-4aab-844b-8c164ecdd3e1",
                        "10b46196-2b40-45f6-8c27-89ac24eec0ac",
                        "14020884-6a3f-437e-96d5-78d5dcedabc7",
                        "40c1f32d-2e92-4172-a714-db0efed14973",
                        "484ecdde-3961-4046-a762-b591f133f64b",
                        "5424b7dc-4d34-4e0b-9a70-7a3ee4c3e1f4",
                        "7cb50dfa-2730-47a8-b5e2-e47ecf736f9f",
                        "80fa2024-e935-44a6-8e36-39af74a76dfe",
                        "9735980d-18cd-475d-8605-23b493d4e406",
                        "b4b9fe07-c87d-439c-801b-3b5a3c2689aa",
                        "d87e3fe9-3ed2-4356-87a8-b9b4e44c72af"
                    ],
                    "keyword": [
                        "smoothing",
                        "modeling",
                        "methods",
                        "performance",
                        "ngram",
                        "previous",
                        "work",
                        "training",
                        "ml",
                        "maximum"
                    ],
                    "group": [],
                    "_id": "e1f8e6f0-eee8-4e01-ace1-cbc47ac3880a",
                    "abstract": "In certain contexts, maximum entropy (ME) modeling can be viewed as maximum likelihood (ML) training for exponential models, and like other ML methods is prone to overfitting of training data. Several smoothing methods for ME models have been proposed to address this problem, but previous results do not make it clear how these smoothing methods compare with smoothing methods for other types of related models. In this work, we survey previous work in ME smoothing and compare the performance of several of these algorithms with conventional techniques for smoothing n-gram language models. Because of the mature body of research in n-gram model smoothing and the close connection between ME and conventional n-gram models, this domain is well-suited to gauge the performance of ME smoothing methods. Over a large number of data sets, we find that fuzzy ME smoothing performs as well as or better than all other algorithms under consideration. We contrast this method with previous n-gram smoothing methods to explain its superior performance.",
                    "title": "A survey of smoothing techniques for ME models",
                    "venue": "IEEE Transactions on Speech and Audio Processing",
                    "year": 2000,
                    "__v": 2,
                    "citationCount": 108,
                    "result": 4.554771209182974
                }
            }
        ],
        "_id": "ed543a19-85d9-427a-a2d3-88e7c59a100e",
        "abstract": "We consider the problem of classifying documents not by topic, but by overall sentiment, e.g., determining whether a review is positive or negative. Using movie reviews as data, we find that standard machine learning techniques definitively outperform human-produced baselines. However, the three machine learning methods we employed (Naive Bayes, maximum entropy classification, and support vector machines) do not perform as well on sentiment classification as on traditional topic-based categorization. We conclude by examining factors that make the sentiment classification problem more challenging.",
        "title": "Thumbs up? Sentiment Classification using Machine Learning Techniques",
        "venue": "empirical methods in natural language processing",
        "year": 2002,
        "__v": 2,
        "citationCount": 2142
    },
    {
        "authors": [
            "Antony I. T. Rowstron",
            "Peter Druschel"
        ],
        "references": [
            "0f290b24-96ae-48f7-9304-9209bba8db17",
            "1cc64868-4f72-4939-aed4-fc8fb0b45118",
            "309f5d34-0bb0-4ffc-aa87-fdffb67dddf6",
            "39adcd6c-0b60-430c-99ab-21cd9e98b385",
            "40fb7878-7a6e-4fc1-af74-a73c1261c20b",
            "42c70869-0dad-4629-93b5-a2d9e29071a7",
            "48740ddd-afd1-4331-8af7-224ef5d19ed7",
            "4ae3d80b-ce75-4c33-8abb-c5358ec01a6d",
            "4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4",
            "4ff9d356-904f-4ad9-835a-bc3ccf6febd9",
            "5e354aca-2d93-43f7-8e80-6bc4eb96e7d9",
            "5e43bfa1-e1fa-428f-847f-b1b575380d14",
            "6500989e-b1e1-4b02-a921-21ec25685b73",
            "747c0c4a-1e59-4af3-a9a6-ad0d081a49ce",
            "b7d7ec53-f079-4bd7-a795-8b6fe77f2db6",
            "c0ea675b-2479-48ae-817e-3ecedd175ecf",
            "c8771a57-de9c-44b7-966c-1ff156d3091f",
            "d81c71d5-dd57-46e3-92e0-daf7a7bbb065",
            "e1263ada-afda-498c-a37d-9b545293118a",
            "e4ee2d81-7629-4445-b4f3-55ef57bd42fd",
            "eb02194b-fa72-4f3e-a259-1dd36cd4839d"
        ],
        "keyword": [
            "nodes",
            "pastry",
            "network",
            "routing",
            "scalable",
            "nodeid",
            "message",
            "failures"
        ],
        "group": [
            {
                "4ae3d80b-ce75-4c33-8abb-c5358ec01a6d": {
                    "authors": [
                        "Mark A. Sheldon",
                        "Andrzej Duda",
                        "Ron Weiss",
                        "David K. Gifford"
                    ],
                    "references": [
                        "02473f4a-3389-4f97-84c6-5f01056f3f64",
                        "47bc0f75-4181-4619-b2ff-126d7f549997",
                        "93f501e9-78e2-41a1-ab3e-d7923995967c",
                        "a7a68181-8dc4-4ccc-9d4d-85b69bb8a0da",
                        "f03189d2-f31d-4488-8ba0-1dbf299083c2"
                    ],
                    "keyword": [
                        "query",
                        "refinement",
                        "routing",
                        "wais",
                        "discover",
                        "user",
                        "system",
                        "servers",
                        "result",
                        "resource"
                    ],
                    "group": [],
                    "_id": "4ae3d80b-ce75-4c33-8abb-c5358ec01a6d",
                    "abstract": "Abstract   We have built an HTTP based resource discovery system called  Discover  that provides a single point of access to over 500 WAIS servers. Discover provides two key services:  query refinement  and  query routing . Query refinement helps a user improve a query fragment to describe the user's interests more precisely. Once a query has been refined and describes a manageable result set, query routing automatically forwards the query to the WAIS servers that contain relevant documents. Abbreviated descriptions of WAIS sites called  content labels  are used by the query refinement and query routing algorithms. Our experimental results suggest that query refinement in conjunction with the query routing provides an effective way to discover resources in a large universe of documents. Our experience with query refinement has convinced us that the expansion of query fragments is essential in helping one use a large, dynamically changing, heterogenous distributed information system.",
                    "title": "Discover: a resource discovery system based on content routing",
                    "venue": "international world wide web conferences",
                    "year": 1995,
                    "__v": 1,
                    "citationCount": 26,
                    "result": 3.9455350205350204
                },
                "4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4": {
                    "authors": [
                        "Ion Stoica",
                        "Robert Morris",
                        "David Liben-Nowell",
                        "David R. Karger",
                        "M. Frans Kaashoek",
                        "Frank Dabek",
                        "Hari Balakrishnan"
                    ],
                    "references": [
                        "1cc64868-4f72-4939-aed4-fc8fb0b45118",
                        "48740ddd-afd1-4331-8af7-224ef5d19ed7",
                        "59084791-6ebd-4d0d-8f93-2c1da8d47490",
                        "6aac8d9c-34bd-42d9-b887-b0a3bd697ee6",
                        "6eff83a4-db80-40ea-8c9f-8bda5f506c29",
                        "a369afee-a619-4e9a-9250-5fd2b06e8a05",
                        "aa89fd2a-319e-48b1-b0ab-099acbe37617",
                        "abf003a2-6485-41f0-a111-88b80412d539",
                        "b7d7ec53-f079-4bd7-a795-8b6fe77f2db6",
                        "b948f5db-4dc3-4151-a9bd-62a3f5be739e",
                        "c0ea675b-2479-48ae-817e-3ecedd175ecf",
                        "c37c70cb-3956-4249-934d-848845f2f444",
                        "e1263ada-afda-498c-a37d-9b545293118a",
                        "e4ee2d81-7629-4445-b4f3-55ef57bd42fd",
                        "ea44a1ae-ddfe-4694-8df1-0ec69182ec11",
                        "f14df1ed-e3e9-4348-9040-fc06e3411b95",
                        "f49921e2-fb25-48d1-aaf2-1afcfeb8b268",
                        "fad8fc34-ff78-45ac-bc30-ca9e4173740f"
                    ],
                    "keyword": [
                        "node",
                        "chord",
                        "key",
                        "data",
                        "system",
                        "stores",
                        "problem",
                        "maps",
                        "location",
                        "item"
                    ],
                    "group": [
                        null
                    ],
                    "_id": "4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4",
                    "abstract": "A fundamental problem that confronts peer-to-peer applications is the efficient location of the node that stores a desired data item. This paper presents  Chord , a distributed lookup protocol that addresses this problem. Chord provides support for just one operation: given a key, it maps the key onto a node. Data location can be easily implemented on top of Chord by associating a key with each data item, and storing the key/data pair at the node to which the key maps. Chord adapts efficiently as nodes join and leave the system, and can answer queries even if the system is continuously changing. Results from theoretical analysis and simulations show that Chord is scalable: Communication cost and the state maintained by each node scale logarithmically with the number of Chord nodes.",
                    "title": "Chord: a scalable peer-to-peer lookup protocol for Internet applications",
                    "venue": "IEEE\\/ACM Transactions on Networking",
                    "year": 2003,
                    "__v": 3,
                    "citationCount": 5975,
                    "result": 6.754539904539904
                },
                "4ff9d356-904f-4ad9-835a-bc3ccf6febd9": {
                    "authors": [
                        "Jussi Kangasharju",
                        "Keith W. Ross",
                        "J. Roberts"
                    ],
                    "references": [
                        "0466ce5c-a113-469a-828f-238f7e29e715",
                        "32f3c88f-0652-4224-9ff0-24885073857e",
                        "6aa34646-964f-4a2c-b5e5-e745d3eba40a"
                    ],
                    "keyword": [
                        "web",
                        "server",
                        "page",
                        "schemes",
                        "objects",
                        "distribution",
                        "clients",
                        "single",
                        "replicated",
                        "redirection"
                    ],
                    "group": [],
                    "_id": "4ff9d356-904f-4ad9-835a-bc3ccf6febd9",
                    "abstract": "Content distribution on the Web is moving from an architecture where objects are placed on a single, designated server to an architecture where objects are replicated on geographically distributed servers and clients transparently access a nearby copy of an object. In this paper we study how the different redirection schemes used in modern content distribution networks affect the user-perceived performance in normal Web page viewing. Using both simulations and experiments with real Web servers we show that redirection schemes that require clients to retrieve different parts of a Web page from different servers yield sub-optional performance compared to schemes where a client accesses only one server for all the parts of a Web page. This implies that when replicating Web pages, we should treat the whole page (HTML and images) as a single entity.",
                    "title": "Performance evaluation of redirection schemes in content distribution networks",
                    "venue": "Computer Communications",
                    "year": 2001,
                    "__v": 1,
                    "citationCount": 43,
                    "result": 3.043714292243704
                },
                "5e354aca-2d93-43f7-8e80-6bc4eb96e7d9": {
                    "authors": [
                        "Antony I. T. Rowstron",
                        "Peter Druschel"
                    ],
                    "references": [
                        "0f290b24-96ae-48f7-9304-9209bba8db17",
                        "152b8a68-f115-4173-a262-45aa2c9046b5",
                        "1c729f22-9928-4703-92a0-8819569a1bbb",
                        "1cc64868-4f72-4939-aed4-fc8fb0b45118",
                        "36f0f3cb-6b32-4284-8e08-0972ee67074f",
                        "40fb7878-7a6e-4fc1-af74-a73c1261c20b",
                        "42c70869-0dad-4629-93b5-a2d9e29071a7",
                        "48740ddd-afd1-4331-8af7-224ef5d19ed7",
                        "4ae3d80b-ce75-4c33-8abb-c5358ec01a6d",
                        "4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4",
                        "4f60dbc7-9647-4b91-b96f-9f77d07fea7c",
                        "4ff9d356-904f-4ad9-835a-bc3ccf6febd9",
                        "5e43bfa1-e1fa-428f-847f-b1b575380d14",
                        "5fa79bc6-4203-442f-a3e8-99abe8bd542a",
                        "6500989e-b1e1-4b02-a921-21ec25685b73",
                        "747c0c4a-1e59-4af3-a9a6-ad0d081a49ce",
                        "78001675-2215-4b4e-8a92-cd30f6409d70",
                        "9f65fe84-a2e3-420a-8fe4-7253e4605422",
                        "b7d7ec53-f079-4bd7-a795-8b6fe77f2db6",
                        "c0ea675b-2479-48ae-817e-3ecedd175ecf",
                        "d06f8723-1b89-4684-99c9-c1045ddfb85c",
                        "d81c71d5-dd57-46e3-92e0-daf7a7bbb065",
                        "e1263ada-afda-498c-a37d-9b545293118a",
                        "e4ee2d81-7629-4445-b4f3-55ef57bd42fd",
                        "eb02194b-fa72-4f3e-a259-1dd36cd4839d",
                        "f14df1ed-e3e9-4348-9040-fc06e3411b95"
                    ],
                    "keyword": [
                        "file",
                        "storage",
                        "nodes",
                        "caching",
                        "balances",
                        "utility",
                        "system",
                        "store",
                        "queries",
                        "popular"
                    ],
                    "group": [],
                    "_id": "5e354aca-2d93-43f7-8e80-6bc4eb96e7d9",
                    "abstract": "This paper presents and evaluates the storage management and caching in PAST, a large-scale peer-to-peer persistent storage utility. PAST is based on a self-organizing, Internet-based overlay network of storage nodes that cooperatively route file queries, store multiple replicas of files, and cache additional copies of popular files.In the PAST system, storage nodes and files are each assigned uniformly distributed identifiers, and replicas of a file are stored at nodes whose identifier matches most closely the file's identifier. This statistical assignment of files to storage nodes approximately balances the number of files stored on each node. However, non-uniform storage node capacities and file sizes require more explicit storage load balancing to permit graceful behavior under high global storage utilization; likewise, non-uniform popularity of files requires caching to minimize fetch distance and to balance the query load.We present and evaluate PAST, with an emphasis on its storage management and caching system. Extensive trace-driven experiments show that the system minimizes fetch distance, that it balances the query load for popular files, and that it displays graceful degradation of performance as the global storage utilization increases beyond 95%.",
                    "title": "Storage management and caching in PAST, a large-scale, persistent peer-to-peer storage utility",
                    "venue": "symposium on operating systems principles",
                    "year": 2001,
                    "__v": 2,
                    "citationCount": 657,
                    "result": 14.442535242535243
                },
                "6500989e-b1e1-4b02-a921-21ec25685b73": {
                    "authors": [
                        "William Adjie-Winoto",
                        "Elliot Schwartz",
                        "Hari Balakrishnan",
                        "Jeremy Lilley"
                    ],
                    "references": [
                        "00ade209-5974-42c1-9089-a3741481d9c7",
                        "1ece4859-34df-4469-bec1-5a6f3d26e8a4",
                        "2915a22c-b1dd-46e9-9082-40793a90abf9",
                        "2b7c69f7-54ce-4a5c-825f-1cb4fd1ea531",
                        "2d8951cc-a672-4a18-b12a-a50df100bcff",
                        "31c5e39a-3f24-4d20-bf8c-3d00036baf95",
                        "49c6311d-6f49-4df2-a2df-96887974ea00",
                        "4ae3d80b-ce75-4c33-8abb-c5358ec01a6d",
                        "59084791-6ebd-4d0d-8f93-2c1da8d47490",
                        "6a9c2062-e8eb-4584-8d40-35f8ed4e40d2",
                        "747c0c4a-1e59-4af3-a9a6-ad0d081a49ce",
                        "7c9f8cd8-d0ef-4954-b4db-4a6c803459c2",
                        "86104574-7932-4182-81f6-355252072a23",
                        "93f501e9-78e2-41a1-ab3e-d7923995967c",
                        "9b65b2b8-9750-48b5-8f3c-790a85a0de96",
                        "9e063b41-0ada-4db8-8846-6e5153a0de55",
                        "a511dcd6-cade-4dc0-aaf4-695df83487db",
                        "b045be7b-3691-41ca-ae2f-00b2dbaa1733",
                        "c2ae33d8-85e5-4d1d-8f17-b71a210b4546",
                        "de0be766-5520-44e1-804b-e65d134cfb46",
                        "e1c7443f-fbc7-4edc-919b-8f3bd2c1a34c"
                    ],
                    "keyword": [
                        "implementation",
                        "system",
                        "service",
                        "performance",
                        "describe",
                        "presents",
                        "networks",
                        "mobile",
                        "late",
                        "language"
                    ],
                    "group": [],
                    "_id": "6500989e-b1e1-4b02-a921-21ec25685b73",
                    "abstract": "This paper presents the design and implementation of the Intentional Naming System (INS), a resource discovery and service location system for dynamic and mobile networks of devices and computers. Such environments require a naming system that is (i) expressive, to describe and make requests based on specific properties of services, (ii) responsive, to track changes due to mobility and performance, (iii) robust, to handle failures, and (iv) easily configurable. INS uses a simple language based on attributes and values for its names. Applications use the language to describe what they are looking for (i.e., their  intent ), not where to find things (i.e., not hostnames). INS implements a  late binding  mechanism that integrates name resolution and message routing, enabling clients to continue communicating with end-nodes even if the name-to-address mappings change while a session is in progress. INS resolvers self-configure to form an application-level overlay network, which they use to discover new services, perform late binding, and maintain weak consistency of names using soft-state name exchanges and updates. We analyze the performance of the INS algorithms and protocols, present measurements of a Java-based implementation, and describe three applications we have implemented that demonstrate the feasibility and utility of INS.",
                    "title": "The design and implementation of an intentional naming system",
                    "venue": "symposium on operating systems principles",
                    "year": 1999,
                    "__v": 2,
                    "citationCount": 325,
                    "result": 5.239955220218378
                },
                "747c0c4a-1e59-4af3-a9a6-ad0d081a49ce": {
                    "authors": [
                        "Butler W. Lampson"
                    ],
                    "references": [
                        "648ef0af-051c-4d25-b7a9-a7dc92e05f22",
                        "6baaa322-2882-4164-a5f6-50277fd58173",
                        "9b65b2b8-9750-48b5-8f3c-790a85a0de96"
                    ],
                    "keyword": [
                        "service",
                        "global",
                        "distributed",
                        "addressing",
                        "world",
                        "wide",
                        "trust",
                        "system",
                        "string",
                        "size"
                    ],
                    "group": [],
                    "_id": "747c0c4a-1e59-4af3-a9a6-ad0d081a49ce",
                    "abstract": "A name service maps a name of an individual, organization or facility into a set of labeled properties, each of which is a string. It is the basis for resource location, mail addressing, and authentication in a distributed computing system. The global name service described here is meant to do this for billions of names distributed throughout the world. It addresses the problems of high availability, large size, continuing evolution, fault isolation and lack of global trust. The non-deterministic behavior of the service is specified rather precisely to allow a wide range of client and server implementations.",
                    "title": "Designing a global name service",
                    "venue": "principles of distributed computing",
                    "year": 1986,
                    "__v": 2,
                    "citationCount": 86,
                    "result": 4.0893079143079145
                },
                "b7d7ec53-f079-4bd7-a795-8b6fe77f2db6": {
                    "authors": [
                        "Frank Dabek",
                        "M. Frans Kaashoek",
                        "David R. Karger",
                        "Robert Morris",
                        "Ion Stoica"
                    ],
                    "references": [
                        "1c729f22-9928-4703-92a0-8819569a1bbb",
                        "1cc64868-4f72-4939-aed4-fc8fb0b45118",
                        "1dda408f-2203-4793-bfa8-2fab15bce7cf",
                        "48740ddd-afd1-4331-8af7-224ef5d19ed7",
                        "4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4",
                        "5e354aca-2d93-43f7-8e80-6bc4eb96e7d9",
                        "5fa0709f-7330-417f-8da7-3ab31d91da5b",
                        "6eff83a4-db80-40ea-8c9f-8bda5f506c29",
                        "786e7d9f-6e9a-47e5-8482-7ee37809b922",
                        "9f65fe84-a2e3-420a-8fe4-7253e4605422",
                        "a369afee-a619-4e9a-9250-5fd2b06e8a05",
                        "b1ab8eee-7043-4f04-b440-5765752d4845",
                        "b90c5640-8e10-4f65-9193-c28af80f45e2",
                        "bd61df44-c80e-406c-8c4e-9c13635ce4f5",
                        "c0ea675b-2479-48ae-817e-3ecedd175ecf",
                        "cb0dcdc4-3c84-4301-891b-42535ac74f8c",
                        "cf67f4c1-ff76-4210-ba80-0356733c5be7",
                        "e1263ada-afda-498c-a37d-9b545293118a",
                        "f14df1ed-e3e9-4348-9040-fc06e3411b95"
                    ],
                    "keyword": [
                        "cfs",
                        "servers",
                        "system",
                        "block",
                        "file",
                        "dhash",
                        "storage",
                        "robustness"
                    ],
                    "group": [],
                    "_id": "b7d7ec53-f079-4bd7-a795-8b6fe77f2db6",
                    "abstract": "The Cooperative File System (CFS) is a new peer-to-peer read-only storage system that provides provable guarantees for the efficiency, robustness, and load-balance of file storage and retrieval. CFS does this with a completely decentralized architecture that can scale to large systems. CFS servers provide a distributed hash table (DHash) for block storage. CFS clients interpret DHash blocks as a file system. DHash distributes and caches blocks at a fine granularity to achieve load balance, uses replication for robustness, and decreases latency with server selection. DHash finds blocks using the Chord location protocol, which operates in time logarithmic in the number of servers.CFS is implemented using the SFS file system toolkit and runs on Linux, OpenBSD, and FreeBSD. Experience on a globally deployed prototype shows that CFS delivers data to clients as fast as FTP. Controlled tests show that CFS is scalable: with 4,096 servers, looking up a block of data involves contacting only seven servers. The tests also demonstrate nearly perfect robustness and unimpaired performance even when as many as half the servers fail.",
                    "title": "Wide-area cooperative storage with CFS",
                    "venue": "symposium on operating systems principles",
                    "year": 2001,
                    "__v": 2,
                    "citationCount": 784,
                    "result": 5.498038073038073
                },
                "c8771a57-de9c-44b7-966c-1ff156d3091f": {
                    "authors": [
                        "Ellen W. Zegura",
                        "Kenneth L. Calvert",
                        "Samrat Bhattacharjee"
                    ],
                    "references": [
                        "0718dc34-4b49-4b24-8a2e-b5cd0d9d82c6",
                        "0b8983cb-f319-4556-91e5-69410f8e6172",
                        "221a51ba-b64d-4bf4-b9b9-968b9d7bd99e",
                        "2c6bba4b-342e-4f90-b27b-35b1934d9186",
                        "386a49a9-d157-4e11-b4a7-18535c14cb94",
                        "4e91bf76-c262-4d42-b8e2-1a3de3c6cac6",
                        "597182f8-8afc-4f90-9aab-70b5c92607d0",
                        "79eab80b-9916-4045-96f1-eb077dddd14b",
                        "abfeee51-0e3a-43c2-b974-cc589c32a679"
                    ],
                    "keyword": [
                        "topologies",
                        "model",
                        "internetworks",
                        "graphs",
                        "generated",
                        "structure",
                        "real",
                        "properties",
                        "study",
                        "problems"
                    ],
                    "group": [],
                    "_id": "c8771a57-de9c-44b7-966c-1ff156d3091f",
                    "abstract": "Graphs are commonly used to model the structure of internetworks, for the study of problems ranging from routing to resource reservation. A variety of graph models are found in the literature, including regular topologies such as rings or stars, \"well-known\" topologies such as the original ARPAnet, and randomly generated topologies. Less common is any discussion of how closely these models correlate with real network topologies. We consider the problem of efficiently generating graph models that accurately reflect the topological properties of real internetworks. We compare the properties of graphs generated using various methods with those of real internets. We also propose efficient methods for generating topologies with particular properties, including a transit-stub model that correlates well with the internet structure. Improved models for the internetwork structure have the potential to impact the significance of simulation studies of internetworking solutions, providing a basis for the validity of the conclusions.",
                    "title": "How to model an internetwork",
                    "venue": "international conference on computer communications",
                    "year": 1996,
                    "__v": 2,
                    "citationCount": 929,
                    "result": 4.735103785103785
                },
                "e1263ada-afda-498c-a37d-9b545293118a": {
                    "authors": [
                        "Sylvia Ratnasamy",
                        "Paul Francis",
                        "Mark Handley",
                        "Richard M. Karp",
                        "Scott Shenker"
                    ],
                    "references": [
                        "00ade209-5974-42c1-9089-a3741481d9c7",
                        "0695070f-320e-4d26-9c68-2c8faa20c944",
                        "0a094924-1b25-43cc-ac8b-dd8cf90a8f78",
                        "1545dfd3-2c25-4ff1-b43c-df4a2a501d06",
                        "1cc64868-4f72-4939-aed4-fc8fb0b45118",
                        "31c5e39a-3f24-4d20-bf8c-3d00036baf95",
                        "39adcd6c-0b60-430c-99ab-21cd9e98b385",
                        "42c70869-0dad-4629-93b5-a2d9e29071a7",
                        "4743d708-b82d-42ec-adaa-a8bf2f23cc38",
                        "483cb980-c968-48e6-b848-714ed2937f98",
                        "48740ddd-afd1-4331-8af7-224ef5d19ed7",
                        "4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4",
                        "88c35cd8-dd49-44f8-9674-96974c8f3650",
                        "c0ea675b-2479-48ae-817e-3ecedd175ecf",
                        "c8771a57-de9c-44b7-966c-1ff156d3091f",
                        "d06f8723-1b89-4684-99c9-c1045ddfb85c",
                        "e4ee2d81-7629-4445-b4f3-55ef57bd42fd",
                        "ec7d1720-3285-4729-b819-b4c58a826ec8",
                        "f6fc4443-7a98-4f9f-92e8-e4e5d94521a7"
                    ],
                    "keyword": [
                        "systems",
                        "scalable",
                        "hash",
                        "functionality",
                        "distributed",
                        "valuable",
                        "values",
                        "tablelike",
                        "tables",
                        "software"
                    ],
                    "group": [
                        null
                    ],
                    "_id": "e1263ada-afda-498c-a37d-9b545293118a",
                    "abstract": "Hash tables - which map \"keys\" onto \"values\" - are an essential building block in modern software systems. We believe a similar functionality would be equally valuable to large distributed systems. In this paper, we introduce the concept of a Content-Addressable Network (CAN) as a distributed infrastructure that provides hash table-like functionality on Internet-like scales. The CAN is scalable, fault-tolerant and completely self-organizing, and we demonstrate its scalability, robustness and low-latency properties through simulation.",
                    "title": "A scalable content-addressable network",
                    "venue": "acm special interest group on data communication",
                    "year": 2001,
                    "__v": 3,
                    "citationCount": 3635,
                    "result": 9.235119412750992
                },
                "e4ee2d81-7629-4445-b4f3-55ef57bd42fd": {
                    "authors": [
                        "Jinyang Li",
                        "John Jannotti",
                        "Douglas S. J. De Couto",
                        "David R. Karger",
                        "Robert Morris"
                    ],
                    "references": [
                        "0d4d0363-07b5-43b6-976d-955e96044709",
                        "1545dfd3-2c25-4ff1-b43c-df4a2a501d06",
                        "39adcd6c-0b60-430c-99ab-21cd9e98b385",
                        "60fb0dc2-bde3-4714-948e-de0ed12ab460",
                        "6eff83a4-db80-40ea-8c9f-8bda5f506c29",
                        "7c9f8cd8-d0ef-4954-b4db-4a6c803459c2",
                        "83a2eb55-b330-4e0c-8dc9-05e9466d5028",
                        "9de43d04-c7fa-48a9-b092-67c2888745d4",
                        "c7b0d60b-9956-4254-b6d3-26fb1f8782bb",
                        "e3af190a-754d-415d-a32d-f1d9999c599f",
                        "ff4259bb-5b84-4f51-b975-146794715d22"
                    ],
                    "keyword": [
                        "node",
                        "location",
                        "gls",
                        "mobile",
                        "networks",
                        "servers",
                        "queries",
                        "predefined",
                        "geographic"
                    ],
                    "group": [],
                    "_id": "e4ee2d81-7629-4445-b4f3-55ef57bd42fd",
                    "abstract": "GLS is a new distributed location service which tracks mobile node locations. GLS combined with geographic forwarding allows the construction of ad hoc mobile networks that scale to a larger number of nodes than possible with previous work. GLS is decentralized and runs on the mobile nodes themselves, requiring no fixed infrastructure. Each mobile node periodically updates a small set of other nodes (its location servers) with its current location. A node sends its position updates to its location servers without knowing their actual identities, assisted by a predefined ordering of node identifiers and a predefined geographic hierarchy. Queries for a mobile node's location also use the predefined identifier ordering and spatial hierarchy to find a location server for that node.  Experiments using the  ns  simulator for up to 600 mobile nodes show that the storage and bandwidth requirements of GLS grow slowly with the size of the network. Furthermore, GLS tolerates node failures well: each failure has only a limited effect and query performance degrades gracefully as nodes fail and restart. The query performance of GLS is also relatively insensitive to node speeds. Simple geographic forwarding combined with GLS compares favorably with Dynamic Source Routing (DSR): in larger networks (over 200 nodes) our approach delivers more packets, but consumes fewer network resources.",
                    "title": "A scalable location service for geographic ad hoc routing",
                    "venue": "acm ieee international conference on mobile computing and networking",
                    "year": 2000,
                    "__v": 2,
                    "citationCount": 786,
                    "result": 4.978663003663004
                },
                "eb02194b-fa72-4f3e-a259-1dd36cd4839d": {
                    "authors": [
                        "Peter Druschel",
                        "Antony I. T. Rowstron"
                    ],
                    "references": [
                        "1cc64868-4f72-4939-aed4-fc8fb0b45118",
                        "42c70869-0dad-4629-93b5-a2d9e29071a7",
                        "48740ddd-afd1-4331-8af7-224ef5d19ed7",
                        "4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4",
                        "5e354aca-2d93-43f7-8e80-6bc4eb96e7d9",
                        "9ba85cd6-22c7-487d-828d-5d8c092d1280",
                        "ad88020d-b7d4-40c7-adae-1014e51f3a2f",
                        "c0ea675b-2479-48ae-817e-3ecedd175ecf",
                        "e1263ada-afda-498c-a37d-9b545293118a",
                        "f14df1ed-e3e9-4348-9040-fc06e3411b95"
                    ],
                    "keyword": [],
                    "group": [],
                    "_id": "eb02194b-fa72-4f3e-a259-1dd36cd4839d",
                    "abstract": "This paper sketches the design of PAST, a large-scale, Internet-based, global storage utility that provides scalability, high availability, persistence and security. PAST is a peer-to-peer Internet application and is entirely self-organizing. PAST nodes serve as access points for clients, participate in the routing of client requests, and contribute storage to the system. Nodes are not trusted, they may join the system at any time and may silently leave the system without warning. Yet, the system is able to provide strong assurances, efficient storage access, load balancing and scalability. Among the most interesting aspects of PAST's design are (1) the Pastry location and routing scheme, which reliably and efficiently routes client requests among the PAST nodes, has good network locality properties and automatically resolves node failures and node additions; (2) the use of randomization to ensure diversity in the set of nodes that store a file's replicas and to provide load balancing; and (3) the optional use of smartcards, which are held by each PAST user and issued by a third party called a broker The smartcards support a quota system that balances supply and demand of storage in the system.",
                    "title": "PAST: a large-scale, persistent peer-to-peer storage utility",
                    "venue": "ieee international conference on requirements engineering",
                    "year": 2001,
                    "__v": 0,
                    "citationCount": 247,
                    "result": 3.333333333333333
                }
            }
        ],
        "_id": "f14df1ed-e3e9-4348-9040-fc06e3411b95",
        "abstract": "This paper presents the design and evaluation of Pastry, a scalable, distributed object location and routing substrate for wide-area peer-to-peer ap- plications. Pastry performs application-level routing and object location in a po- tentially very large overlay network of nodes connected via the Internet. It can be used to support a variety of peer-to-peer applications, including global data storage, data sharing, group communication and naming. Each node in the Pastry network has a unique identifier (nodeId). When presented with a message and a key, a Pastry node efficiently routes the message to the node with a nodeId that is numerically closest to the key, among all currently live Pastry nodes. Each Pastry node keeps track of its immediate neighbors in the nodeId space, and notifies applications of new node arrivals, node failures and recoveries. Pastry takes into account network locality; it seeks to minimize the distance messages travel, according to a to scalar proximity metric like the number of IP routing hops. Pastry is completely decentralized, scalable, and self-organizing; it automatically adapts to the arrival, departure and failure of nodes. Experimental results obtained with a prototype implementation on an emulated network of up to 100,000 nodes confirm Pastry's scalability and efficiency, its ability to self-organize and adapt to node failures, and its good network locality properties.",
        "title": "Pastry: Scalable, Decentralized Object Location, and Routing for Large-Scale Peer-to-Peer Systems",
        "venue": "Lecture Notes in Computer Science",
        "year": 2001,
        "__v": 3,
        "citationCount": 4022
    },
    {
        "authors": [
            "Pedro F. Felzenszwalb",
            "Ross B. Girshick",
            "David A. McAllester",
            "Deva Ramanan"
        ],
        "references": [
            "0149d4d7-6775-4387-9098-d02ddb7dbc58",
            "0d21b163-cce6-4dc5-bb12-1f6c7e709436",
            "0ea0c1c5-e42b-4843-90b7-3cef138e4327",
            "13d83701-8e72-482a-882e-fc1450146d6e",
            "1ed718cd-ab43-47e4-a97f-e68d0f7fb216",
            "202da7f7-a7fc-4026-b535-b2c938c5567a",
            "21094c3c-478e-4d91-8ae6-9ff240ebfc6f",
            "2be85cbb-5df3-42f0-99db-3bb427412cea",
            "325664f0-77db-4ab7-8e85-1f79e70df4cf",
            "3c49df6f-3b50-450f-aa93-4c715cfd05af",
            "3dedfe96-bf8c-47fb-ad4e-075e54b48ec6",
            "43530fe4-10a9-4ddf-b61d-8844f0ff3f04",
            "52dbf565-81ab-439e-a9af-6c4d6ae302f8",
            "648675c6-6ea7-4fa5-a91d-9d3156d09692",
            "64fa74e8-db02-4190-87d7-bf23e9859a7c",
            "651454cb-eb8b-4f08-8f7a-b40f6b55b998",
            "67f92163-023b-4655-8abe-acf23dc38aea",
            "7f367932-20d6-425d-b207-9869b1c277cf",
            "81eec382-cc0a-4381-91df-a90054925734",
            "83c737b8-e084-4766-ba6e-131e6a1c017c",
            "8b8a2247-bd77-4736-b493-449734f56b9a",
            "9f84e529-87a3-42f1-9d63-9af710f40925",
            "a5254ae0-1ce1-4390-b9f8-8d5a3dcb1e62",
            "a96a19b9-2924-4231-9da7-ad1860d23480",
            "ab2669d7-eed4-41db-abe8-46d91db31747",
            "b944f77f-113b-4a02-ae5e-d4a124b8fd5b",
            "bf03f268-de9d-4a80-aee1-200990056503",
            "c455fb04-4566-4648-ad6f-3cf2245e507c",
            "c7f93552-c1ef-4ae4-b1f5-2317e1c9d904",
            "d5e5a24d-f80e-4f1a-b48b-22403b653276",
            "dd83785a-dd19-41e3-9b25-ebabbd48d336",
            "e44ae1a0-12a2-4838-a42f-fdade39c81a5",
            "eb017324-3c9c-4ffb-b5bd-81833b925af6",
            "ed835ca3-7120-4646-afaf-20c04a57c698",
            "ef35a024-f5f3-4a7b-b6f6-61d9167385e6",
            "f111ff97-89a3-4df6-8f02-962d7b4fe985",
            "fc780759-4533-4b33-9774-746ca210842f"
        ],
        "keyword": [
            "latent",
            "svm",
            "object",
            "training",
            "system",
            "examples",
            "variable",
            "positive",
            "pascal",
            "part"
        ],
        "group": [
            {
                "3dedfe96-bf8c-47fb-ad4e-075e54b48ec6": {
                    "authors": [
                        "Bastian Leibe",
                        "Ales Leonardis",
                        "Bernt Schiele"
                    ],
                    "references": [
                        "0289a1a7-579b-42a8-8795-45bb59850e67",
                        "05c99d31-32c1-431d-99ce-0dfcd6ca805c",
                        "0aae4e44-abdb-4948-9462-61f6e52162ba",
                        "16340e43-b1cd-4c5f-8b9a-44384a0a6123",
                        "177b7083-bfca-472b-833a-515f1ad77735",
                        "1b2ca840-c231-4d15-b1d5-09fd8d61400c",
                        "20f52431-62f1-4670-ba81-d19ef3c04204",
                        "21094c3c-478e-4d91-8ae6-9ff240ebfc6f",
                        "21a8e8fd-0172-4e9a-8474-7024eb0bf979",
                        "21c67dad-f0eb-4479-afe7-fdf4a71eef01",
                        "229c6b00-6eaf-4302-b843-09167f8082c5",
                        "2d6c9f60-ea78-44a8-b5f9-6964575dd196",
                        "307b5053-ee01-4dc6-8969-7efa7379e416",
                        "34758e0a-3def-447b-9c5e-e82a206426b5",
                        "34ab16ee-97db-4520-992e-f92aca3386d8",
                        "473cf1a4-9f42-4e6d-b34f-77787f329079",
                        "49e8d454-99f4-4cde-9ff8-6f50c33eaa48",
                        "526860a6-aea8-4f8d-b7f9-e01d3629a6a9",
                        "54a5822c-e405-44ad-84e3-cea51e7349c2",
                        "552d8ea6-1cb0-44db-ba2c-eec5016ef5df",
                        "5ea6e082-6427-4ac3-ac85-95f9232c8213",
                        "6018a516-8149-4bce-bc33-5449d86e58c2",
                        "60285266-7da2-474e-b05a-b380c836f665",
                        "64fa74e8-db02-4190-87d7-bf23e9859a7c",
                        "8028b8ab-06c2-41f8-b833-88ba9248fd15",
                        "81eec382-cc0a-4381-91df-a90054925734",
                        "853b29ea-c6d1-497e-bad3-b608d370e7e2",
                        "873c9c21-6bfd-484c-95ed-c4831ec8e00a",
                        "8b8a2247-bd77-4736-b493-449734f56b9a",
                        "8d8e7d51-3223-4776-bf6a-40306774b8a1",
                        "9298ec73-f02d-4ee5-9fab-1ac3f188a910",
                        "9438a773-c15c-4ef2-a97c-54f643ce6082",
                        "98cfeac3-9abb-4f5b-9705-158c3b7b9d3a",
                        "a74b3c2b-0710-4648-afb1-298f23b47030",
                        "b29cb808-1f59-40e9-8afa-26a3701b6284",
                        "b592576f-ff29-4a68-9b2f-8a8ad02e9c70",
                        "b944f77f-113b-4a02-ae5e-d4a124b8fd5b",
                        "bdd58d4a-2e0e-4fb2-8049-cfa50dda7b0d",
                        "c455fb04-4566-4648-ad6f-3cf2245e507c",
                        "c591c440-b19b-4d7b-b067-cd8c366b7d6d",
                        "c69bfded-9ea9-4a1c-84f9-1e230e30ceed",
                        "c8f80ea6-4602-458c-9a70-daf1c646c89b",
                        "cb66e49d-077b-4adf-873c-2bc39f78fca6",
                        "cf545f57-5abd-4a15-888f-a674b99391ed",
                        "d486ab6f-98b8-46a1-8ae2-521ebd7391d6",
                        "d4d98193-fa86-445e-a140-959c646323a7",
                        "d6e37fb1-5f7e-448e-847b-7d1f1271c574",
                        "dd83785a-dd19-41e3-9b25-ebabbd48d336",
                        "e1f2a353-af70-48c2-aba6-a0e0a71fdffc",
                        "e46bb6ea-7b67-4edf-8cd4-a51ce64cff19",
                        "ed8a9624-3abe-4b5e-bffe-5b3ecc34e841",
                        "ee9b186c-b7f0-4323-8f28-a55bbbd62b71",
                        "ef35a024-f5f3-4a7b-b6f6-61d9167385e6",
                        "f111ff97-89a3-4df6-8f02-962d7b4fe985",
                        "f200d16f-8e1a-4a51-be50-4eeaafbb4a2f",
                        "fc4a70a7-80c5-43c8-a68f-0a72a46ecce8",
                        "fc780759-4533-4b33-9774-746ca210842f",
                        "ff0d990e-90f3-4973-8541-5f7e595710aa"
                    ],
                    "keyword": [],
                    "group": [],
                    "_id": "3dedfe96-bf8c-47fb-ad4e-075e54b48ec6",
                    "abstract": "This paper presents a novel method for detecting and localizing objects of a visual category in cluttered real-world scenes. Our approach considers object categorization and figure-ground segmentation as two interleaved processes that closely collaborate towards a common goal. As shown in our work, the tight coupling between those two processes allows them to benefit from each other and improve the combined performance. #R##N##R##N#The core part of our approach is a highly flexible learned representation for object shape that can combine the information observed on different training examples in a probabilistic extension of the Generalized Hough Transform. The resulting approach can detect categorical objects in novel images and automatically infer a probabilistic segmentation from the recognition result. This segmentation is then in turn used to again improve recognition by allowing the system to focus its efforts on object pixels and to discard misleading influences from the background. Moreover, the information from where in the image a hypothesis draws its support is employed in an MDL based hypothesis verification stage to resolve ambiguities between overlapping hypotheses and factor out the effects of partial occlusion. #R##N##R##N#An extensive evaluation on several large data sets shows that the proposed system is applicable to a range of different object categories, including both rigid and articulated objects. In addition, its flexible representation allows it to achieve competitive object detection performance already from training sets that are between one and two orders of magnitude smaller than those used in comparable systems.",
                    "title": "Robust Object Detection with Interleaved Categorization and Segmentation",
                    "venue": "International Journal of Computer Vision",
                    "year": 2008,
                    "__v": 0,
                    "citationCount": 501,
                    "result": 2.7027027027027026
                },
                "52dbf565-81ab-439e-a9af-6c4d6ae302f8": {
                    "authors": [
                        "Pedro F. Felzenszwalb",
                        "David A. McAllester",
                        "Deva Ramanan"
                    ],
                    "references": [
                        "0149d4d7-6775-4387-9098-d02ddb7dbc58",
                        "0d21b163-cce6-4dc5-bb12-1f6c7e709436",
                        "13d83701-8e72-482a-882e-fc1450146d6e",
                        "202da7f7-a7fc-4026-b535-b2c938c5567a",
                        "3c49df6f-3b50-450f-aa93-4c715cfd05af",
                        "651454cb-eb8b-4f08-8f7a-b40f6b55b998",
                        "67f92163-023b-4655-8abe-acf23dc38aea",
                        "6f6fe122-6003-498c-a584-b27b3f7a6be3",
                        "81eec382-cc0a-4381-91df-a90054925734",
                        "83c737b8-e084-4766-ba6e-131e6a1c017c",
                        "8f5cecf7-c1dc-4400-8af3-739409424dac",
                        "9f84e529-87a3-42f1-9d63-9af710f40925",
                        "c455fb04-4566-4648-ad6f-3cf2245e507c",
                        "c45e6f71-1ad4-4971-b22f-12f3af34379f",
                        "dbc47800-7dc3-46da-94d3-70120f07f13a",
                        "dd83785a-dd19-41e3-9b25-ebabbd48d336",
                        "ed8a9624-3abe-4b5e-bffe-5b3ecc34e841",
                        "ef35a024-f5f3-4a7b-b6f6-61d9167385e6",
                        "fc780759-4533-4b33-9774-746ca210842f"
                    ],
                    "keyword": [
                        "latent",
                        "trained",
                        "model",
                        "system",
                        "svm",
                        "part",
                        "deformable",
                        "challenge",
                        "relies",
                        "problem"
                    ],
                    "group": [],
                    "_id": "52dbf565-81ab-439e-a9af-6c4d6ae302f8",
                    "abstract": "This paper describes a discriminatively trained, multiscale, deformable part model for object detection. Our system achieves a two-fold improvement in average precision over the best performance in the 2006 PASCAL person detection challenge. It also outperforms the best results in the 2007 challenge in ten out of twenty categories. The system relies heavily on deformable parts. While deformable part models have become quite popular, their value had not been demonstrated on difficult benchmarks such as the PASCAL challenge. Our system also relies heavily on new methods for discriminative training. We combine a margin-sensitive approach for data mining hard negative examples with a formalism we call latent SVM. A latent SVM, like a hidden CRF, leads to a non-convex training problem. However, a latent SVM is semi-convex and the training problem becomes convex once latent information is specified for the positive examples. We believe that our training methods will eventually make possible the effective use of more latent information such as hierarchical (grammar) models and models involving latent three dimensional pose.",
                    "title": "A discriminatively trained, multiscale, deformable part model",
                    "venue": "computer vision and pattern recognition",
                    "year": 2008,
                    "__v": 2,
                    "citationCount": 916,
                    "result": 11.4487021987022
                },
                "648675c6-6ea7-4fa5-a91d-9d3156d09692": {
                    "authors": [
                        "Henry A. Rowley",
                        "Shumeet Baluja",
                        "Takeo Kanade"
                    ],
                    "references": [
                        "33d74862-6527-4c30-be0c-95226a3f8a3a",
                        "49b0495d-2caa-4dbf-b1ab-6f9695b8bd72",
                        "ae3e7593-586f-495f-9416-4b50ed1fcd10",
                        "be3dc921-98bb-4c9a-999c-0d9ef826dd56",
                        "d5e5a24d-f80e-4f1a-b48b-22403b653276",
                        "eb2dc957-4aae-4d39-a99d-8adab1effb39"
                    ],
                    "keyword": [
                        "training",
                        "system",
                        "detection",
                        "network",
                        "face",
                        "windows",
                        "present",
                        "performance",
                        "nonface",
                        "neural"
                    ],
                    "group": [],
                    "_id": "648675c6-6ea7-4fa5-a91d-9d3156d09692",
                    "abstract": "We present a neural network-based face detection system. A retinally connected neural network examines small windows of an image, and decides whether each window contains a face. The system arbitrates between multiple networks to improve performance over a single network. We use a bootstrap algorithm for training, which adds false detections into the training set as training progresses. This eliminates the difficult task of manually selecting non-face training examples, which must be chosen to span the entire space of non-face images. Comparisons with another state-of-the-art face detection system are presented; our system has better performance in terms of detection and false-positive rates.",
                    "title": "Human Face Detection in Visual Scenes",
                    "venue": "neural information processing systems",
                    "year": 1996,
                    "__v": 2,
                    "citationCount": 162,
                    "result": 4.256983556983557
                },
                "64fa74e8-db02-4190-87d7-bf23e9859a7c": {
                    "authors": [
                        "Alan L. Yuille",
                        "D. S. Cohen",
                        "Peter W. Hallinan"
                    ],
                    "references": [
                        "1c63e1d5-b963-455b-829d-e4f3eb63a36a",
                        "26be7564-13c5-4650-aa82-5d06540cef84",
                        "9f84e529-87a3-42f1-9d63-9af710f40925",
                        "e9d5e8a5-de36-4615-a5c8-7cdabf75486e"
                    ],
                    "keyword": [
                        "templates",
                        "image",
                        "features",
                        "deformable",
                        "values",
                        "parameter",
                        "method",
                        "function",
                        "eye",
                        "energy"
                    ],
                    "group": [],
                    "_id": "64fa74e8-db02-4190-87d7-bf23e9859a7c",
                    "abstract": "A method for detecting and describing the features of faces using deformable templates is described. The feature of interest, an eye for example, is described by a parameterized template. An energy function is defined which links edges, peaks, and valleys in the image intensity to corresponding properties of the template. The template then interacts dynamically with the image, by altering its parameter values to minimize the energy function, thereby deforming itself to find the best fit. The final parameter values can be used as descriptors for the features. This method is demonstrated by showing deformable templates detecting eyes and mouths in real images. >",
                    "title": "Feature extraction from faces using deformable templates",
                    "venue": "computer vision and pattern recognition",
                    "year": 1989,
                    "__v": 2,
                    "citationCount": 716,
                    "result": 4.517056817056816
                },
                "651454cb-eb8b-4f08-8f7a-b40f6b55b998": {
                    "authors": [
                        "Pedro F. Felzenszwalb",
                        "David A. McAllester"
                    ],
                    "references": [
                        "0a540da8-1c50-4255-b1bb-6775f860fbd2",
                        "12933647-4280-4bda-8a63-aebb93cc8144",
                        "179075b2-c3df-4921-99f2-0747b26ba0be",
                        "1a1c954b-b21a-4ece-a07d-072d3ec07aa7",
                        "21ef532b-de84-4465-bb41-85546f137592",
                        "26054cad-cbdc-423c-b8f9-d719cd975efb",
                        "3cc7d99b-2563-47ab-a83a-3555a2bf2736",
                        "59391763-c3a6-4564-bce9-4340811f3d2f",
                        "67f92163-023b-4655-8abe-acf23dc38aea",
                        "6fd932e6-412c-46a6-a623-1e582e0a04e4",
                        "797eb766-6198-4551-bd09-46411fc5df0b",
                        "7e3122e5-fd6f-4292-80f5-99e1969ac5e0",
                        "7f8979b8-ebaf-4128-b130-777fe9fc4469",
                        "83359201-f6d5-4572-97df-c06380267aa1",
                        "bc95970b-34c5-4860-a832-41bc04a50889",
                        "bc9f2a40-8a93-48c7-a3ca-51a5ebdd92cb",
                        "bdd72f1c-6df6-4069-bb3a-40a82dfc9065",
                        "d5725e0f-2253-48de-b5f5-e8648f144bf4",
                        "d7aa5356-a059-4044-9b18-fef9d72dfeea",
                        "e4a2c293-6276-4fbd-ac6e-406ad2e028d8",
                        "e7c36fb4-67b6-443b-9df2-d5f7d79c46d2",
                        "ee000702-8768-4f0a-ac7a-9b627841441b",
                        "f780f31c-4ffe-4150-9452-299e4bc143d5"
                    ],
                    "keyword": [
                        "problem",
                        "search",
                        "derivation",
                        "algorithm",
                        "lightest",
                        "generalize",
                        "set",
                        "processing",
                        "images",
                        "computing"
                    ],
                    "group": [],
                    "_id": "651454cb-eb8b-4f08-8f7a-b40f6b55b998",
                    "abstract": "We consider the problem of computing a lightest derivation of a global structure using a set of weighted rules. A large variety of inference problems in AI can be formulated in this framework. We generalize A* search and heuristics derived from abstractions to a broad class of lightest derivation problems. We also describe a new algorithm that searches for lightest derivations using a hierarchy of abstractions. Our generalization of A* gives a new algorithm for searching AND/OR graphs in a bottom-up fashion.#R##N##R##N#We discuss how the algorithms described here provide a general architecture for addressing the pipeline problem -- the problem of passing information back and forth between various stages of processing in a perceptual system. We consider examples in computer vision and natural language processing. We apply the hierarchical search algorithm to the problem of estimating the boundaries of convex objects in grayscale images and compare it to other search methods. A second set of experiments demonstrate the use of a new compositional model for finding salient curves in images.",
                    "title": "The generalized A* architecture",
                    "venue": "Journal of Artificial Intelligence Research",
                    "year": 2007,
                    "__v": 2,
                    "citationCount": 39,
                    "result": 4.829053154053154
                },
                "67f92163-023b-4655-8abe-acf23dc38aea": {
                    "authors": [
                        "Ya Jin",
                        "Stuart Geman"
                    ],
                    "references": [
                        "0d21b163-cce6-4dc5-bb12-1f6c7e709436",
                        "3c49df6f-3b50-450f-aa93-4c715cfd05af",
                        "6018a516-8149-4bce-bc33-5449d86e58c2",
                        "6068418b-4c47-42b0-b3bf-1b854549dc9b",
                        "62f3bf9a-662e-40f8-bc26-7cc356562e8c",
                        "7876d86f-e782-4ca6-9504-5f347d1c388f",
                        "7ac78dd3-def4-4236-9a1e-628e84d80c2c",
                        "c591c440-b19b-4d7b-b067-cd8c366b7d6d",
                        "cb731238-55b6-4404-a8d7-2b386fae4623",
                        "da4534a6-897c-4431-89ef-cd326bfaf9a8",
                        "e9d32426-c3a6-41b0-be95-43e999c9022e",
                        "fc4a70a7-80c5-43c8-a68f-0a72a46ecce8"
                    ],
                    "keyword": [
                        "plates",
                        "systems",
                        "machine",
                        "grammar",
                        "composition",
                        "reading",
                        "probabilistic",
                        "nonmarkovian",
                        "network",
                        "multiple"
                    ],
                    "group": [],
                    "_id": "67f92163-023b-4655-8abe-acf23dc38aea",
                    "abstract": "It is widely conjectured that the excellent ROC performance of biological vision systems is due in large part to the exploitation of context at each of many levels in a part/whole hierarchy. We propose a mathematical framework (a \"composition machine\") for constructing probabilistic hierarchical image models, designed to accommodate arbitrary contextual relationships, and we build a demonstration system for reading Massachusetts license plates in an image set collected at Logan Airport. The demonstration system detects and correctly reads more than 98% of the plates, with a negligible rate of false detection. Unlike a formal grammar, the architecture of a composition machine does not exclude the sharing of sub-parts among multiple entities, and does not limit interpretations to single trees (e.g. a scene can have multiple license plates, or no plates at all). In this sense, the architecture is more like a general Bayesian network than a formal grammar. On the other hand, unlike a Bayesian network, the distribution is non-Markovian, and therefore more like a probabilistic context-sensitive grammar. The conceptualization and construction of a composition machine is facilitated by its formulation as the result of a series of non-Markovian perturbations of a \"Markov backbone.\"",
                    "title": "Context and Hierarchy in a Probabilistic Image Model",
                    "venue": "computer vision and pattern recognition",
                    "year": 2006,
                    "__v": 2,
                    "citationCount": 85,
                    "result": 5.998292832967756
                },
                "7f367932-20d6-425d-b207-9869b1c277cf": {
                    "authors": [
                        "Elliot Joel Bernstein",
                        "Yali Amit"
                    ],
                    "references": [
                        "43530fe4-10a9-4ddf-b61d-8844f0ff3f04",
                        "492d8a17-94b7-4467-b879-4714585aca57",
                        "5ea6e082-6427-4ac3-ac85-95f9232c8213",
                        "613841ae-c925-4aee-9c2e-8675213e4bbf",
                        "8b8a2247-bd77-4736-b493-449734f56b9a",
                        "b944f77f-113b-4a02-ae5e-d4a124b8fd5b",
                        "c1569952-27a7-42dc-8e4c-f396d061ac31",
                        "d5e01b64-7902-4df0-a768-43c2a8e1739e",
                        "d6f07d85-fb52-4a11-84c5-65afe9b54434",
                        "eefeca44-4dc8-45c8-8ba7-45bbd350bc4e"
                    ],
                    "keyword": [
                        "classes",
                        "trained",
                        "models",
                        "features",
                        "classification",
                        "simple",
                        "set",
                        "local",
                        "data",
                        "binary"
                    ],
                    "group": [],
                    "_id": "7f367932-20d6-425d-b207-9869b1c277cf",
                    "abstract": "We propose using simple mixture models to define a set of mid-level binary local features based on binary oriented edge input. The features capture natural local structures in the data and yield very high classification rates when used with a variety of classifiers trained on small training sets, exhibiting robustness to degradation with clutter. Of particular interest is the use of the features as variables in simple statistical models for the objects thus enabling likelihood based classification. Pre-training decision boundaries between classes, a necessary component of non-parametric techniques, are thus avoided. Class models are trained separately with no need to access data of other classes. Experimental results are presented for handwritten character recognition, classification of deformed BTEX symbols involving hundreds of classes, and side view car detection.",
                    "title": "Part-based statistical models for object classification and detection",
                    "venue": "computer vision and pattern recognition",
                    "year": 2005,
                    "__v": 2,
                    "citationCount": 17,
                    "result": 5.008757308757308
                },
                "81eec382-cc0a-4381-91df-a90054925734": {
                    "authors": [
                        "Pedro F. Felzenszwalb",
                        "Daniel P. Huttenlocher"
                    ],
                    "references": [
                        "04d8a9cb-a14d-4ccf-8b19-da1327e86b91",
                        "0684a9f8-cf32-4161-ac7b-fb45a6c1329b",
                        "17aaf918-52ec-4b30-baf1-b067b4fc8e74",
                        "2b75e1ce-cd61-4c39-8260-b51e4136ed34",
                        "36800655-b2ff-4eb7-9070-c6be304c4baa",
                        "37032748-43bb-410a-8349-d2808bb6f7fa",
                        "3bb5658b-131c-4072-9f9c-5f18a8272054",
                        "46da0145-fc17-4096-9624-4828cb32e116",
                        "47e8badc-7db1-4e43-99e7-6fea4a6d65e3",
                        "4adf54c9-f808-4988-ad8a-bf9cc87c6668",
                        "5ebbd1f5-dfe5-4eec-9883-b8b5efea366c",
                        "613841ae-c925-4aee-9c2e-8675213e4bbf",
                        "6e8cc926-79a1-4676-a2bd-f9d49f3144cf",
                        "6f6fe122-6003-498c-a584-b27b3f7a6be3",
                        "79359cb0-3770-480a-943b-fabb0f8da236",
                        "7f3d9495-7b9e-44ad-a36b-61b8bd7e0e43",
                        "87c6d06a-66ed-4867-b789-2d114525063c",
                        "896bcce8-1847-4c92-b488-38f54240e790",
                        "9f1c57c9-ae6c-4e00-b3ee-10256adb3cb1",
                        "9f84e529-87a3-42f1-9d63-9af710f40925",
                        "b5e72744-0105-48bf-95ea-753f52280f48",
                        "c2dd1e3a-e1d4-456c-b1b8-6ddc2d66f1ee",
                        "caeecc11-ec92-47d8-b112-c43b88dd4491",
                        "cd84aa5d-a982-4c0a-9b56-6c618a57264e",
                        "d3e00e7e-1c64-4d7a-b2b2-1ad98ba4c706",
                        "d5f8e154-e8c9-45e8-a3a0-fd705f00ced4",
                        "d9752a5a-1603-45cc-9a21-7997750d429f",
                        "ebfca554-7a3c-4597-954b-07336a2e3030",
                        "ef35a024-f5f3-4a7b-b6f6-61d9167385e6",
                        "f3d57b86-0677-4dd8-bbf5-52efaeed9a82"
                    ],
                    "keyword": [
                        "modeling",
                        "objects",
                        "represent",
                        "problems",
                        "parts",
                        "structure",
                        "recognition",
                        "present",
                        "pictorial",
                        "learning"
                    ],
                    "group": [],
                    "_id": "81eec382-cc0a-4381-91df-a90054925734",
                    "abstract": "In this paper we present a computationally efficient framework for part-based modeling and recognition of objects. Our work is motivated by the pictorial structure models introduced by Fischler and Elschlager. The basic idea is to represent an object by a collection of parts arranged in a deformable configuration. The appearance of each part is modeled separately, and the deformable configuration is represented by spring-like connections between pairs of parts. These models allow for qualitative descriptions of visual appearance, and are suitable for generic recognition problems. We address the problem of using pictorial structure models to find instances of an object in an image as well as the problem of learning an object model from training examples, presenting efficient algorithms in both cases. We demonstrate the techniques by learning models that represent faces and human bodies and using the resulting models to locate the corresponding objects in novel images.",
                    "title": "Pictorial Structures for Object Recognition",
                    "venue": "International Journal of Computer Vision",
                    "year": 2005,
                    "__v": 1,
                    "citationCount": 1148,
                    "result": 7.27574389927331
                },
                "83c737b8-e084-4766-ba6e-131e6a1c017c": {
                    "authors": [
                        "Mark Everingham",
                        "Luc J. Van Gool",
                        "Christopher K. I. Williams",
                        "John Winn",
                        "Andrew Zisserman"
                    ],
                    "references": [
                        "08877f4f-6266-44d8-83d6-6fa9070e0729",
                        "1f520d1a-5870-477d-85d7-0f50be690ea7",
                        "1f556c88-b553-4c75-b243-92d8200f8149",
                        "23120ec2-cd0d-48ed-abef-567a3f9ea103",
                        "319f5c0d-b3f1-4f4e-a553-03c887f50e3c",
                        "32a53bab-1ede-4869-98ad-d2ff0c1e3367",
                        "364d2f61-6575-464a-9be2-1138b3b64c4a",
                        "3ac62b27-10f6-41a7-9489-20c68399d826",
                        "433969bb-d29f-4cac-83a5-ccfb5c6c7b4e",
                        "470a4f23-7661-44a2-b1fe-a370995631d1",
                        "52b16eb0-053c-42d3-9713-d4b631dac23a",
                        "52dbf565-81ab-439e-a9af-6c4d6ae302f8",
                        "61447020-9a4b-4742-affd-fb5cde9d84ae",
                        "7af6585a-b797-47ad-84f3-a8fec553f67a",
                        "80c70167-d4e9-46e5-aeb9-a2d91df48db1",
                        "86ba72ef-465f-44dc-8068-cdd6a64f0b40",
                        "8b8a2247-bd77-4736-b493-449734f56b9a",
                        "98801e79-fc9d-4c6a-a383-10e937c9d008",
                        "99a51496-fcec-4bf4-aa14-0f548bc20a57",
                        "9aea2ad1-64c1-4e32-b991-1333e5b60a13",
                        "a1e856ee-3e21-4efd-bc25-86201dd71737",
                        "a96a19b9-2924-4231-9da7-ad1860d23480",
                        "aa767a83-de19-4421-bfb4-f63808992758",
                        "ac5e3fe4-3b1d-412d-a03b-3247d39f62d5",
                        "ad4f81d3-cba5-4db2-9044-93962e883865",
                        "b3e241a6-126f-40fb-a063-8ed7d0223a3c",
                        "b624c279-af53-46e8-97ef-cc7e8a1c2d55",
                        "b944f77f-113b-4a02-ae5e-d4a124b8fd5b",
                        "c0a960bd-3739-41ed-9b84-f1e12f28795d",
                        "c31657cb-cc9b-4947-b9dd-5a40de643bbe",
                        "c70a5a06-395e-452e-bec8-01807cf4be7e",
                        "c7ffa962-3c2c-4298-b32a-745510e8ef9f",
                        "cb5e3b2d-a97e-461f-b99e-d4593d0ef2d7",
                        "cfbc794e-0fa7-4d5b-be73-f5f03c5a1f9d",
                        "d5e01b64-7902-4df0-a768-43c2a8e1739e",
                        "d8da60d2-11fb-4c95-ad08-d077828e994d",
                        "dc2c4901-c7cd-405f-b549-fad267d3f5bd",
                        "dd83785a-dd19-41e3-9b25-ebabbd48d336",
                        "e0ac4812-7729-4a2d-8a1f-74b1b7c8eb5d",
                        "e75d8e62-a86d-4241-953f-1b315005d920",
                        "e8736260-dc56-4097-a88c-24c9e189e91c",
                        "e88433aa-0835-4c0e-88d0-1165ab4ac4f8",
                        "eba773db-f6b9-4fb3-9112-61cd10e0c754",
                        "ed835ca3-7120-4646-afaf-20c04a57c698",
                        "ee9b186c-b7f0-4323-8f28-a55bbbd62b71",
                        "fc780759-4533-4b33-9774-746ca210842f",
                        "ffa31d0c-ff37-4bf3-b213-6d8a968e6636",
                        "ffc56f7f-1295-4647-a1f7-e44ea58f93f2"
                    ],
                    "keyword": [
                        "object",
                        "methods",
                        "evaluation",
                        "detection",
                        "dataset",
                        "challenge",
                        "visual",
                        "standard",
                        "procedures",
                        "paper"
                    ],
                    "group": [],
                    "_id": "83c737b8-e084-4766-ba6e-131e6a1c017c",
                    "abstract": "The Pascal Visual Object Classes (VOC) challenge is a benchmark in visual object category recognition and detection, providing the vision and machine learning communities with a standard dataset of images and annotation, and standard evaluation procedures. Organised annually from 2005 to present, the challenge and its associated dataset has become accepted as the benchmark for object detection.#R##N##R##N#This paper describes the dataset and evaluation procedure. We review the state-of-the-art in evaluated methods for both classification and detection, analyse whether the methods are statistically different, what they are learning from the images (e.g. the object or its context), and what the methods find easy or confuse. The paper concludes with lessons learnt in the three year history of the challenge, and proposes directions for future improvement and extension.",
                    "title": "The Pascal Visual Object Classes (VOC) Challenge",
                    "venue": "International Journal of Computer Vision",
                    "year": 2010,
                    "__v": 1,
                    "citationCount": 2425,
                    "result": 6.590113115113115
                },
                "8b8a2247-bd77-4736-b493-449734f56b9a": {
                    "authors": [
                        "Paul A. Viola",
                        "Michael J. Jones"
                    ],
                    "references": [
                        "13cd743f-beb9-43a1-8e08-2ef08f0d8b3f",
                        "17f811d8-8607-4270-bbec-1cc7883edd68",
                        "245e4043-ccdb-457a-9be1-e120c7a94753",
                        "310cbba4-d88d-4bf4-a4f2-738f91b5f8c8",
                        "36800655-b2ff-4eb7-9070-c6be304c4baa",
                        "43530fe4-10a9-4ddf-b61d-8844f0ff3f04",
                        "55fa440a-2b98-4e8e-bb45-fa09598b4eca",
                        "5ffac6f9-2456-42cf-830c-9049ce37c899",
                        "613841ae-c925-4aee-9c2e-8675213e4bbf",
                        "62d0a064-3808-4bc0-99bd-f007359ce651",
                        "6d121e97-e351-4cf9-8c44-d7ab3ce9d9fe",
                        "8f6a657e-e387-4572-bb88-91aee042e8da",
                        "9fa55b0f-eaa6-4c59-b6e5-77e5f1a406f0",
                        "b49c1e2b-0cd0-4950-a724-00c698e5b49d",
                        "c7f93552-c1ef-4ae4-b1f5-2317e1c9d904",
                        "d5e5a24d-f80e-4f1a-b48b-22403b653276",
                        "d6e37fb1-5f7e-448e-847b-7d1f1271c574",
                        "db26488d-78be-44b1-a343-e896f43c5d29",
                        "f1bd37c4-d033-4cd1-af44-4df9f11c71e4",
                        "f4642ffc-3571-4d02-8b94-142f2448023a"
                    ],
                    "keyword": [
                        "detection",
                        "images",
                        "face",
                        "features",
                        "system",
                        "set",
                        "regions",
                        "quickly",
                        "contributions",
                        "computed"
                    ],
                    "group": [
                        null
                    ],
                    "_id": "8b8a2247-bd77-4736-b493-449734f56b9a",
                    "abstract": "This paper describes a face detection framework that is capable of processing images extremely rapidly while achieving high detection rates. There are three key contributions. The first is the introduction of a new image representation called the “Integral Image” which allows the features used by our detector to be computed very quickly. The second is a simple and efficient classifier which is built using the AdaBoost learning algorithm (Freund and Schapire, 1995) to select a small number of critical visual features from a very large set of potential features. The third contribution is a method for combining classifiers in a “cascade” which allows background regions of the image to be quickly discarded while spending more computation on promising face-like regions. A set of experiments in the domain of face detection is presented. The system yields face detection performance comparable to the best previous systems (Sung and Poggio, 1998; Rowley et al., 1998; Schneiderman and Kanade, 2000; Roth et al., 2000). Implemented on a conventional desktop, face detection proceeds at 15 frames per second.",
                    "title": "Robust real-time face detection",
                    "venue": "international conference on computer vision",
                    "year": 2001,
                    "__v": 3,
                    "citationCount": 4436,
                    "result": 4.145346244417451
                },
                "9f84e529-87a3-42f1-9d63-9af710f40925": {
                    "authors": [
                        "Martin A. Fischler",
                        "Robert A. Elschlager"
                    ],
                    "references": [
                        "0f8d373b-1312-44fd-97c4-a9926ebb29cc",
                        "469db401-52b5-4183-913d-a10e45bb8af2",
                        "7dac4219-13e1-4000-9c51-108613ffa362",
                        "7db93c71-06a6-4d4f-b893-ec4db1872974"
                    ],
                    "keyword": [
                        "problem",
                        "object",
                        "description",
                        "visual",
                        "specification",
                        "solution",
                        "scheme",
                        "primary",
                        "photograph",
                        "part"
                    ],
                    "group": [],
                    "_id": "9f84e529-87a3-42f1-9d63-9af710f40925",
                    "abstract": "The primary problem dealt with in this paper is the following. Given some description of a visual object, find that object in an actual photograph. Part of the solution to this problem is the specification of a descriptive scheme, and a metric on which to base the decision of \"goodness\" of matching or detection.",
                    "title": "The Representation and Matching of Pictorial Structures",
                    "venue": "IEEE Transactions on Computers",
                    "year": 1973,
                    "__v": 1,
                    "citationCount": 560,
                    "result": 5.6174253421157445
                },
                "a5254ae0-1ce1-4390-b9f8-8d5a3dcb1e62": {
                    "authors": [
                        "Yan Ke",
                        "Rahul Sukthankar"
                    ],
                    "references": [
                        "28005624-c0e8-4c62-b585-6e362c3dc8d5",
                        "34758e0a-3def-447b-9c5e-e82a206426b5",
                        "36800655-b2ff-4eb7-9070-c6be304c4baa",
                        "509e1ae2-768b-4417-bebe-d90cf1e0fdae",
                        "6018a516-8149-4bce-bc33-5449d86e58c2",
                        "608a581a-0e03-435a-9067-c0e0982567af",
                        "6fe37c18-8dc5-4baa-b6e0-5546353907bb",
                        "7ab7b36d-baae-4b21-89fc-69389fcabc44",
                        "aec2ffaf-e691-4884-9304-7d7e14733b2e",
                        "b944f77f-113b-4a02-ae5e-d4a124b8fd5b",
                        "c455fb04-4566-4648-ad6f-3cf2245e507c",
                        "d7b1fba1-b5f8-4377-88a8-d2fc69f723b7"
                    ],
                    "keyword": [
                        "image",
                        "sift",
                        "descriptor",
                        "local",
                        "results",
                        "representation",
                        "gradient",
                        "feature",
                        "deformations",
                        "component"
                    ],
                    "group": [],
                    "_id": "a5254ae0-1ce1-4390-b9f8-8d5a3dcb1e62",
                    "abstract": "Stable local feature detection and representation is a fundamental component of many image registration and object recognition algorithms. Mikolajczyk and Schmid (June 2003) recently evaluated a variety of approaches and identified the SIFT [D. G. Lowe, 1999] algorithm as being the most resistant to common image deformations. This paper examines (and improves upon) the local image descriptor used by SIFT. Like SIFT, our descriptors encode the salient aspects of the image gradient in the feature point's neighborhood; however, instead of using SIFT's smoothed weighted histograms, we apply principal components analysis (PCA) to the normalized gradient patch. Our experiments demonstrate that the PCA-based local descriptors are more distinctive, more robust to image deformations, and more compact than the standard SIFT representation. We also present results showing that using these descriptors in an image retrieval application results in increased accuracy and faster matching.",
                    "title": "PCA-SIFT: a more distinctive representation for local image descriptors",
                    "venue": "computer vision and pattern recognition",
                    "year": 2004,
                    "__v": 2,
                    "citationCount": 1138,
                    "result": 3.7335003585003586
                },
                "a96a19b9-2924-4231-9da7-ad1860d23480": {
                    "authors": [
                        "Derek Hoiem",
                        "Alexei A. Efros",
                        "Martial Hebert"
                    ],
                    "references": [
                        "00da6a0e-aa5d-4f92-b3a0-21c976e11330",
                        "2c5f401d-b50c-4697-aef6-2ff7caed3b72",
                        "32a53bab-1ede-4869-98ad-d2ff0c1e3367",
                        "33ef0eb5-c4b5-4810-b528-74b4605efc52",
                        "40bbddd1-5e44-4372-9fe4-27fd7d6aafd7",
                        "5057898e-bc25-4969-a4b4-881ba80d6783",
                        "57b3e9a4-5b74-4397-9ee3-00d7df58a771",
                        "5ad7276f-f084-4a24-8187-57873f008c82",
                        "5f70f18c-5f9c-442e-ae2c-ee6aadecab95",
                        "68bd97cf-3d10-4382-a690-3649a2b695c1",
                        "6f5f8d69-4439-4080-b2ce-b1da049b11c3",
                        "74cfc504-79ca-454f-b8ed-86eced93f44a",
                        "82d0ec51-e40e-4602-b969-fc0b44464ac3",
                        "8341f8ac-a713-45b9-845c-c32abe2fca00",
                        "85415160-c71b-49de-b62a-7cf8ee2a60a8",
                        "8b8a2247-bd77-4736-b493-449734f56b9a",
                        "c92c2419-c837-4e80-8890-ac92d8d0cb3e",
                        "d3e00e7e-1c64-4d7a-b2b2-1ad98ba4c706",
                        "dd83785a-dd19-41e3-9b25-ebabbd48d336",
                        "e05a6676-6e91-466e-b705-19e19b66e5a2",
                        "e4f59ab1-c7e5-4734-a310-c85fa75f26a5"
                    ],
                    "keyword": [
                        "object",
                        "image",
                        "world",
                        "understanding",
                        "surface",
                        "scales",
                        "probabilistic",
                        "modeling",
                        "locations",
                        "geometry"
                    ],
                    "group": [],
                    "_id": "a96a19b9-2924-4231-9da7-ad1860d23480",
                    "abstract": "Image understanding requires not only individually estimating elements of the visual world but also capturing the interplay among them. In this paper, we provide a framework for placing local object detection in the context of the overall 3D scene by modeling the interdependence of objects, surface orientations, and camera viewpoint. Most object detection methods consider all scales and locations in the image as equally likely. We show that with probabilistic estimates of 3D geometry, both in terms of surfaces and world coordinates, we can put objects into perspective and model the scale and location variance in the image. Our approach reflects the cyclical nature of the problem by allowing probabilistic object hypotheses to refine geometry and vice-versa. Our framework allows painless substitution of almost any object detector and is easily extended to include other aspects of image understanding. Our results confirm the benefits of our integrated approach.",
                    "title": "Putting Objects in Perspective",
                    "venue": "computer vision and pattern recognition",
                    "year": 2006,
                    "__v": 2,
                    "citationCount": 483,
                    "result": 4.284131418187146
                },
                "ab2669d7-eed4-41db-abe8-46d91db31747": {
                    "authors": [
                        "James M. Coughlan",
                        "Alan L. Yuille",
                        "Camper English",
                        "Daniel Snow"
                    ],
                    "references": [
                        "0d66d358-49fa-4d9c-931e-98c828313246",
                        "34758e0a-3def-447b-9c5e-e82a206426b5",
                        "3a0388e4-4d17-4fd2-9de3-26cba5f4c9a9",
                        "4238fd4a-fd80-43db-a1d7-ee32846851d9",
                        "58b05db1-a51a-4165-bf3f-4fbd8b218b1e",
                        "6610284f-1f5a-4460-95d6-b0ad690e171d",
                        "6b7fbc4d-d0e8-4c2b-8c91-c51d9820dc1e",
                        "6da113cb-3257-4014-990b-2ebbb7d998f2",
                        "7bdecab6-2761-4b4d-8a0b-f1b7b1732068",
                        "893791c5-4414-4db6-a307-472768e36e3b",
                        "9f84e529-87a3-42f1-9d63-9af710f40925",
                        "a88b2e20-8fc6-430d-8ab1-aab1d07e7fab",
                        "b20fb115-14dc-4edd-b312-73a7ff53aedf",
                        "b39299a5-6c2f-4be9-842d-0433262505ad",
                        "d44e71a4-553f-4aba-a0fb-dbc022d152fa",
                        "d7cb4d76-5e54-42f2-b49d-8801c0a72f11",
                        "e47ff468-de7a-457a-bb93-cf1b71a32846"
                    ],
                    "keyword": [
                        "hand",
                        "template",
                        "image",
                        "deformable",
                        "user",
                        "translation",
                        "techniques",
                        "significant",
                        "shape",
                        "rotationinvariant"
                    ],
                    "group": [],
                    "_id": "ab2669d7-eed4-41db-abe8-46d91db31747",
                    "abstract": "A novel deformable template is presented which detects the boundary of an open hand in a grayscale image without initialization by the user. A dynamic programming algorithm enhanced by pruning techniques finds the hand contour in the image in as little as 19 s on a Pentium 150 MHz. The template is translation- and rotation-invariant and accomodates shape deformation, significant occlusion and background clutter, and the presence of multiple hands.",
                    "title": "Efficient Deformable Template Detection and Localization without User Initialization",
                    "venue": "Computer Vision and Image Understanding",
                    "year": 2000,
                    "__v": 1,
                    "citationCount": 61,
                    "result": 4.593892945885139
                },
                "b944f77f-113b-4a02-ae5e-d4a124b8fd5b": {
                    "authors": [
                        "David G. Lowe"
                    ],
                    "references": [
                        "00a4e16f-6b65-4ad2-bedc-b19d9cbc2cfe",
                        "01a0f825-a308-455b-93fc-e62defc0e3b0",
                        "035f8537-61a7-4c4f-b9fe-120f913a38b0",
                        "03a42efa-a19c-4b19-a881-9c7ff63865ce",
                        "05c3e696-6add-4b0d-b867-e6f1c98deb9b",
                        "2fa2e5ba-11d3-4691-91e1-807b8ef7d8a5",
                        "32d9eaee-c68f-4479-aa67-837d3cc91a05",
                        "34758e0a-3def-447b-9c5e-e82a206426b5",
                        "5437c0a0-8f20-49c3-86e5-9d860f3e4f04",
                        "5dcd5949-faa9-4af3-8c6f-b285dd3b6566",
                        "5f1992df-975f-49e7-bd88-aee0740317cf",
                        "5f84f09f-7644-447c-89e1-8dc9ee334197",
                        "6018a516-8149-4bce-bc33-5449d86e58c2",
                        "60285266-7da2-474e-b05a-b380c836f665",
                        "768eea6d-8e82-4bbf-8bdd-1f2338ded29f",
                        "791e9257-d7a0-41fe-b471-bde48f3c4a04",
                        "7ab7b36d-baae-4b21-89fc-69389fcabc44",
                        "7b3f5f5b-a965-4656-9a6f-2f9740625176",
                        "899de8c7-9cd9-4dd5-82f1-ad9acb801f8e",
                        "a00704dc-a2fa-4267-b7a6-427167d99521",
                        "a0fa7ae2-61e5-48a9-be10-86440416129f",
                        "a748e0f4-ee6f-41ad-a2a5-1a5a6751086d",
                        "b3e60214-b54c-4e8f-9315-a6975c760f4c",
                        "b4685927-0ad9-466b-b2c6-2e1764475726",
                        "c455fb04-4566-4648-ad6f-3cf2245e507c",
                        "ccdefe89-9b16-4c22-8bb8-bd314ccad6e1",
                        "d20995f6-529c-41c6-b75e-a169b005fb5c",
                        "d9b9f667-9d8a-4723-a6c4-c19b941acd46",
                        "df9fe96c-752e-49be-a8c4-8b098ab51e22",
                        "ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d",
                        "f6272ea9-0360-47ed-90a5-651ea958143f"
                    ],
                    "keyword": [
                        "features",
                        "object",
                        "matching",
                        "recognition",
                        "perform",
                        "images",
                        "single",
                        "robust",
                        "paper",
                        "invariant"
                    ],
                    "group": [
                        null
                    ],
                    "_id": "b944f77f-113b-4a02-ae5e-d4a124b8fd5b",
                    "abstract": "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance.",
                    "title": "Distinctive Image Features from Scale-Invariant Keypoints",
                    "venue": "International Journal of Computer Vision",
                    "year": 2004,
                    "__v": 3,
                    "citationCount": 16229,
                    "result": 5.428717052246464
                },
                "bf03f268-de9d-4a80-aee1-200990056503": {
                    "authors": [
                        "Timothy F. Cootes",
                        "G. Edwards",
                        "Christopher J. Taylor"
                    ],
                    "references": [
                        "13c491a8-d910-4451-9cc9-fe4a8033976b",
                        "1b2ca840-c231-4d15-b1d5-09fd8d61400c",
                        "1ba94a3f-ba8a-4aff-8151-3a855803711c",
                        "1d150ea3-d6c0-4c75-822f-433639a7dbcc",
                        "45521624-faa8-4fed-a2e1-fdcdf96a7c56",
                        "504af9f2-1981-4066-b835-1b69f6536b0f",
                        "700061b6-54a5-4f50-a1ef-1d8de3015c43",
                        "7cdaaa8a-8ddc-4ccd-89b0-d85ff20c41b7",
                        "923f5d0a-23a3-4fb1-bee7-ec72122709a4",
                        "9a342fc2-984f-443e-9597-99b3432afbd0",
                        "ae66f3ec-b67d-4193-bb89-a19576fe3eb2",
                        "ae9fd662-5816-4bc6-8cdf-390d15c2d6f2",
                        "f6f9c3fa-6575-4408-ac39-3c7431c5a818"
                    ],
                    "keyword": [
                        "models",
                        "set",
                        "parameters",
                        "matching",
                        "learned",
                        "images",
                        "variation",
                        "training",
                        "statistical",
                        "shape"
                    ],
                    "group": [],
                    "_id": "bf03f268-de9d-4a80-aee1-200990056503",
                    "abstract": "We describe a new method of matching statistical models of appearance to images. A set of model parameters control modes of shape and gray-level variation learned from a training set. We construct an efficient iterative matching algorithm by learning the relationship between perturbations in the model parameters and the induced image errors.",
                    "title": "Active appearance models",
                    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "year": 2001,
                    "__v": 2,
                    "citationCount": 2362,
                    "result": 5.0930244592009295
                },
                "c455fb04-4566-4648-ad6f-3cf2245e507c": {
                    "authors": [
                        "Rob Fergus",
                        "Pietro Perona",
                        "Andrew Zisserman"
                    ],
                    "references": [
                        "2d6c9f60-ea78-44a8-b5f9-6964575dd196",
                        "473cf1a4-9f42-4e6d-b34f-77787f329079",
                        "509e1ae2-768b-4417-bebe-d90cf1e0fdae",
                        "613841ae-c925-4aee-9c2e-8675213e4bbf",
                        "bf664a72-1007-43e6-8dff-f1b0de9b5740",
                        "c591c440-b19b-4d7b-b067-cd8c366b7d6d",
                        "c7f93552-c1ef-4ae4-b1f5-2317e1c9d904",
                        "ccdefe89-9b16-4c22-8bb8-bd314ccad6e1",
                        "d5e5a24d-f80e-4f1a-b48b-22403b653276",
                        "d6e37fb1-5f7e-448e-847b-7d1f1271c574",
                        "d7b1fba1-b5f8-4377-88a8-d2fc69f723b7",
                        "df152036-9859-492f-998f-1ff9769b6d95",
                        "e649a9fd-f6d9-4aac-b428-29b82c20a484",
                        "ef35a024-f5f3-4a7b-b6f6-61d9167385e6",
                        "f111ff97-89a3-4df6-8f02-962d7b4fe985"
                    ],
                    "keyword": [
                        "object",
                        "models",
                        "scale",
                        "flexible",
                        "manner",
                        "learn",
                        "image",
                        "class"
                    ],
                    "group": [],
                    "_id": "c455fb04-4566-4648-ad6f-3cf2245e507c",
                    "abstract": "We present a method to learn and recognize object class models from unlabeled and unsegmented cluttered scenes in a scale invariant manner. Objects are modeled as flexible constellations of parts. A probabilistic representation is used for all aspects of the object: shape, appearance, occlusion and relative scale. An entropy-based feature detector is used to select regions and their scale within the image. In learning the parameters of the scale-invariant object model are estimated. This is done using expectation-maximization in a maximum-likelihood setting. In recognition, this model is used in a Bayesian manner to classify images. The flexible nature of the model is demonstrated by excellent results over a range of datasets including geometrically constrained classes (e.g. faces, cars) and flexible objects (such as animals).",
                    "title": "Object class recognition by unsupervised scale-invariant learning",
                    "venue": "computer vision and pattern recognition",
                    "year": 2003,
                    "__v": 2,
                    "citationCount": 1184,
                    "result": 4.958425958425959
                },
                "c7f93552-c1ef-4ae4-b1f5-2317e1c9d904": {
                    "authors": [
                        "Henry Schneiderman",
                        "Takeo Kanade"
                    ],
                    "references": [
                        "310cbba4-d88d-4bf4-a4f2-738f91b5f8c8",
                        "4a29b56b-b74e-4945-9017-61a7ab844fd9",
                        "8f6a657e-e387-4572-bb88-91aee042e8da",
                        "96d6d9b9-6d69-4c9a-b3f5-c8083966d55c",
                        "bb83383f-0de9-408b-9ba2-aa902c63f14a",
                        "d5e5a24d-f80e-4f1a-b48b-22403b653276",
                        "d6e37fb1-5f7e-448e-847b-7d1f1271c574",
                        "db26488d-78be-44b1-a343-e896f43c5d29",
                        "ed59a2e5-7330-4e07-9edf-cc80872135d0"
                    ],
                    "keyword": [
                        "statistical",
                        "represent",
                        "object",
                        "histograms",
                        "detection",
                        "wide",
                        "reliably",
                        "method",
                        "algorithm",
                        "wavelet"
                    ],
                    "group": [],
                    "_id": "c7f93552-c1ef-4ae4-b1f5-2317e1c9d904",
                    "abstract": "In this paper, we describe a statistical method for 3D object detection. We represent the statistics of both object appearance and \"non-object\" appearance using a product of histograms. Each histogram represents the joint statistics of a subset of wavelet coefficients and their position on the object. Our approach is to use many such histograms representing a wide variety of visual attributes. Using this method, we have developed the first algorithm that can reliably detect human faces with out-of-plane rotation and the first algorithm that can reliably detect passenger cars over a wide range of viewpoints.",
                    "title": "A statistical method for 3D object detection applied to faces and cars",
                    "venue": "computer vision and pattern recognition",
                    "year": 2000,
                    "__v": 2,
                    "citationCount": 525,
                    "result": 4.814474105650576
                },
                "d5e5a24d-f80e-4f1a-b48b-22403b653276": {
                    "authors": [
                        "Kah Kay Sung",
                        "Tomaso Poggio"
                    ],
                    "references": [
                        "17bb9954-1e92-4f77-b952-8f99153aba0c",
                        "1e4f4b5c-55e0-4d5b-b7cc-9e7fada3e341",
                        "3b3d7569-08b1-4017-9910-2a017a00e43e",
                        "3e7823cd-cff6-43b3-8df8-990f5525eb50",
                        "64fa74e8-db02-4190-87d7-bf23e9859a7c",
                        "85114f9d-70a8-4940-83aa-af504b75acf8",
                        "9499c3b8-c1f9-4d80-9cfb-c0b9b26b2511"
                    ],
                    "keyword": [
                        "models",
                        "faces",
                        "vector",
                        "locating",
                        "image",
                        "human",
                        "feature",
                        "difference",
                        "patterns",
                        "nonface"
                    ],
                    "group": [],
                    "_id": "d5e5a24d-f80e-4f1a-b48b-22403b653276",
                    "abstract": "We present an example-based learning approach for locating vertical frontal views of human faces in complex scenes. The technique models the distribution of human face patterns by means of a few view-based \"face\" and \"nonface\" model clusters. At each image location, a difference feature vector is computed between the local image pattern and the distribution-based model. A trained classifier determines, based on the difference feature vector measurements, whether or not a human face exists at the current image location. We show empirically that the distance metric we adopt for computing difference feature vectors, and the \"nonface\" clusters we include in our distribution-based model, are both critical for the success of our system.",
                    "title": "Example-based learning for view-based human face detection",
                    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "year": 1998,
                    "__v": 2,
                    "citationCount": 802,
                    "result": 2.9720018720018717
                },
                "dd83785a-dd19-41e3-9b25-ebabbd48d336": {
                    "authors": [
                        "Navneet Dalal",
                        "Bill Triggs"
                    ],
                    "references": [
                        "04d8a9cb-a14d-4ccf-8b19-da1327e86b91",
                        "3e812129-beeb-415e-b6f7-ae255695cec7",
                        "6f6fe122-6003-498c-a584-b27b3f7a6be3",
                        "8d8e7d51-3223-4776-bf6a-40306774b8a1",
                        "8fc9506c-3603-4af2-b0c8-02b368863fcb",
                        "a5254ae0-1ce1-4390-b9f8-8d5a3dcb1e62",
                        "b944f77f-113b-4a02-ae5e-d4a124b8fd5b",
                        "bdd58d4a-2e0e-4fb2-8049-cfa50dda7b0d",
                        "cb66e49d-077b-4adf-873c-2bc39f78fca6",
                        "ed8a9624-3abe-4b5e-bffe-5b3ecc34e841",
                        "f200d16f-8e1a-4a51-be50-4eeaafbb4a2f",
                        "f3959783-a9aa-48a2-9fcc-978879de365e",
                        "ff0d990e-90f3-4973-8541-5f7e595710aa",
                        "ffa029cf-7240-4723-8339-51fac57f9f28"
                    ],
                    "keyword": [
                        "human",
                        "gradient",
                        "descriptors",
                        "study",
                        "sets",
                        "oriented",
                        "feature",
                        "existing",
                        "detection",
                        "binning"
                    ],
                    "group": [
                        null
                    ],
                    "_id": "dd83785a-dd19-41e3-9b25-ebabbd48d336",
                    "abstract": "We study the question of feature sets for robust visual object recognition; adopting linear SVM based human detection as a test case. After reviewing existing edge and gradient based descriptors, we show experimentally that grids of histograms of oriented gradient (HOG) descriptors significantly outperform existing feature sets for human detection. We study the influence of each stage of the computation on performance, concluding that fine-scale gradients, fine orientation binning, relatively coarse spatial binning, and high-quality local contrast normalization in overlapping descriptor blocks are all important for good results. The new approach gives near-perfect separation on the original MIT pedestrian database, so we introduce a more challenging dataset containing over 1800 annotated human images with a large range of pose variations and backgrounds.",
                    "title": "Histograms of oriented gradients for human detection",
                    "venue": "computer vision and pattern recognition",
                    "year": 2005,
                    "__v": 3,
                    "citationCount": 8477,
                    "result": 4.701120483473424
                },
                "eb017324-3c9c-4ffb-b5bd-81833b925af6": {
                    "authors": [
                        "Cha Zhang",
                        "John Platt",
                        "Paul A. Viola"
                    ],
                    "references": [
                        "307db816-5b31-4902-b554-29597320719d",
                        "37bfba44-965a-40df-871e-5aea3eb4fefa",
                        "4194632e-b625-438f-a92c-5f0b903d47d3",
                        "5f1992df-975f-49e7-bd88-aee0740317cf",
                        "6c9c72bd-936a-42b8-8b9e-29c59696db44",
                        "852d4703-36db-4c8c-814c-6cd2273b536b",
                        "8b8a2247-bd77-4736-b493-449734f56b9a",
                        "9fbcf820-45ff-4d75-ac39-a0dbdab3f0ca",
                        "c3fd25c3-e5c6-48e1-ba24-2f13d15f9ffe",
                        "c455fb04-4566-4648-ad6f-3cf2245e507c",
                        "e7e0773a-55f7-4d5f-87d0-f8728308f40b",
                        "fb1e85b8-5ae8-4074-88cf-4e9270d625ff"
                    ],
                    "keyword": [
                        "object",
                        "milboost",
                        "training",
                        "detection",
                        "violajones",
                        "show",
                        "set",
                        "rate",
                        "locations",
                        "learning"
                    ],
                    "group": [],
                    "_id": "eb017324-3c9c-4ffb-b5bd-81833b925af6",
                    "abstract": "A good image object detection algorithm is accurate, fast, and does not require exact locations of objects in a training set. We can create such an object detector by taking the architecture of the Viola-Jones detector cascade and training it with a new variant of boosting that we call MIL-Boost. MILBoost uses cost functions from the Multiple Instance Learning literature combined with the AnyBoost framework. We adapt the feature selection criterion of MILBoost to optimize the performance of the Viola-Jones cascade. Experiments show that the detection rate is up to 1.6 times better using MILBoost. This increased detection rate shows the advantage of simultaneously learning the locations and scales of the objects in the training set along with the parameters of the classifier.",
                    "title": "Multiple Instance Boosting for Object Detection",
                    "venue": "neural information processing systems",
                    "year": 2006,
                    "__v": 2,
                    "citationCount": 336,
                    "result": 6.314807939807942
                },
                "ed835ca3-7120-4646-afaf-20c04a57c698": {
                    "authors": [
                        "Antonio Torralba"
                    ],
                    "references": [
                        "09c5663f-0e10-42dd-8a06-de98eb6283d0",
                        "0f58e2da-b7b7-47a8-93e1-29ac58631f34",
                        "1ed2cc94-3d0b-4718-80b6-2528e814c921",
                        "3754cd3d-1c71-44d4-ade9-916b9c21ab92",
                        "45b5946e-2dad-4318-9f98-ceb44af530d7",
                        "4a29b56b-b74e-4945-9017-61a7ab844fd9",
                        "5ad7276f-f084-4a24-8187-57873f008c82",
                        "65a76574-1ea8-4b1d-8d29-efe42d06446c",
                        "6c2f97e5-a9f8-4953-9fd1-8e188c0d9302",
                        "6d121e97-e351-4cf9-8c44-d7ab3ce9d9fe",
                        "6e8cc926-79a1-4676-a2bd-f9d49f3144cf",
                        "82d0ec51-e40e-4602-b969-fc0b44464ac3",
                        "895baf65-af49-4daa-bbda-93ab87096ff1",
                        "899de8c7-9cd9-4dd5-82f1-ad9acb801f8e",
                        "92f1db41-9ed7-4384-9635-134797661240",
                        "94ce3d32-4057-4002-a3ef-6f87b0582802",
                        "9bd24114-921d-4869-ba66-48e4afef2303",
                        "a15cddb4-131e-4c80-ac81-e67febff8f4a",
                        "a8c1aa3c-b6e3-4295-92db-edb8d364a93f",
                        "ab3afb93-8ca0-4556-ae60-11199dc263c2",
                        "c027a810-02a3-415b-83ad-e48144273475",
                        "d6e37fb1-5f7e-448e-847b-7d1f1271c574",
                        "eebe49e1-42f0-43b8-b5ec-cfaaaf3b90e1",
                        "ef35a024-f5f3-4a7b-b6f6-61d9167385e6",
                        "f4642ffc-3571-4d02-8b94-142f2448023a",
                        "ff0d990e-90f3-4973-8541-5f7e595710aa"
                    ],
                    "keyword": [
                        "object's",
                        "scenes",
                        "context",
                        "realworld"
                    ],
                    "group": [],
                    "_id": "ed835ca3-7120-4646-afaf-20c04a57c698",
                    "abstract": "There is general consensus that context can be a rich source of information about an object's identity, location and scale. In fact, the structure of many real-world scenes is governed by strong configurational rules akin to those that apply to a single object. Here we introduce a simple framework for modeling the relationship between context and object properties based on the correlation between the statistics of low-level features across the entire scene and the objects that it contains. The resulting scheme serves as an effective procedure for object priming, context driven focus of attention and automatic scale-selection on real-world scenes.",
                    "title": "Contextual Priming for Object Detection",
                    "venue": "International Journal of Computer Vision",
                    "year": 2003,
                    "__v": 1,
                    "citationCount": 361,
                    "result": 2.5234171234171234
                },
                "f111ff97-89a3-4df6-8f02-962d7b4fe985": {
                    "authors": [
                        "Markus Weber",
                        "Max Welling",
                        "Pietro Perona"
                    ],
                    "references": [
                        "00909251-9935-44f3-94a1-629023b5015b",
                        "45521624-faa8-4fed-a2e1-fdcdf96a7c56",
                        "47e8badc-7db1-4e43-99e7-6fea4a6d65e3",
                        "a1f1edad-49c5-46f6-a3db-8bbe9e6613b9",
                        "b889d6ec-330d-406f-87b6-ea34804fadfd",
                        "ccdefe89-9b16-4c22-8bb8-bd314ccad6e1",
                        "ef35a024-f5f3-4a7b-b6f6-61d9167385e6"
                    ],
                    "keyword": [
                        "object",
                        "models",
                        "classes",
                        "training",
                        "represent",
                        "method",
                        "learn",
                        "views",
                        "set",
                        "parts"
                    ],
                    "group": [],
                    "_id": "f111ff97-89a3-4df6-8f02-962d7b4fe985",
                    "abstract": "We propose a method to learn heterogeneous models of object classes for visual recognition. The training images contain a preponderance of clutter and learning is unsupervised. Our models represent objects as probabilistic constellations of rigid parts (features). The variability within a class is represented by a join probability density function on the shape of the constellation and the appearance of the parts. Our method automatically identifies distinctive features in the training set. The set of model parameters is then learned using expectation maximization. When trained on different, unlabeled and unsegmented views of a class of objects, each component of the mixture model can adapt to represent a subset of the views. Similarly, different component models can also \"specialize\" on sub-classes of an object class. Experiments on images of human heads, leaves from different species of trees, and motor-cars demonstrate that the method works well over a wide variety of objects.",
                    "title": "Towards automatic discovery of object categories",
                    "venue": "computer vision and pattern recognition",
                    "year": 2000,
                    "__v": 2,
                    "citationCount": 111,
                    "result": 5.32113052113052
                },
                "fc780759-4533-4b33-9774-746ca210842f": {
                    "authors": [
                        "Jianguo Zhang",
                        "Marcin Marszalek",
                        "Svetlana Lazebnik",
                        "Cordelia Schmid"
                    ],
                    "references": [
                        "03f3d290-78fb-4694-86ed-85acc48b0e79",
                        "090af1dd-85e1-49f1-ae85-9928df7f709f",
                        "0d68cae7-51b5-41e9-b66a-01254a8022a3",
                        "1f556c88-b553-4c75-b243-92d8200f8149",
                        "21a8e8fd-0172-4e9a-8474-7024eb0bf979",
                        "26316adf-569e-49bc-a289-c1ba311624f6",
                        "2d6c9f60-ea78-44a8-b5f9-6964575dd196",
                        "354d0df4-594b-4672-bdba-4a4a9310d04d",
                        "37031566-2033-44cb-a87e-91a9bb37996f",
                        "4fddea17-773c-4d66-a8a4-ce4a1d939151",
                        "532dec4c-28bf-4ca8-aa3b-fc5b5b20bb2d",
                        "606f8ecd-75f5-40fa-a70d-d6665cd2990e",
                        "62a46780-e1d9-4186-babe-6179735d785e",
                        "6692d3e1-f6a0-48c0-8733-7b1f72587fd0",
                        "6842d04f-2b92-4298-aee8-92babc53f7c4",
                        "6ed8bba0-4960-4c10-8dfc-b7705bb6c158",
                        "70e86498-0a19-465c-8b73-49c2769b1a53",
                        "71a81f33-5958-4066-990c-39feafe3ed9c",
                        "72c27d5a-23c5-4d1b-a000-280b87b368ee",
                        "758978d8-5908-4afc-8d47-0309601427e3",
                        "8028b8ab-06c2-41f8-b833-88ba9248fd15",
                        "805dd061-a59c-4599-a019-090d2ceb64f8",
                        "81eec382-cc0a-4381-91df-a90054925734",
                        "827ea34a-8b5f-4e39-bf91-361e8dce0d04",
                        "8d8e7d51-3223-4776-bf6a-40306774b8a1",
                        "9f84e529-87a3-42f1-9d63-9af710f40925",
                        "a075f8b3-9c5a-4e43-a72a-8e41e82855a6",
                        "a083a1b9-8dfb-45d6-99a9-fa30c4a6e9f5",
                        "acaea615-8ac3-42b4-a737-28fdce1a8da6",
                        "ae4a15da-5aec-4876-bec6-7c8ce40761b1",
                        "b944f77f-113b-4a02-ae5e-d4a124b8fd5b",
                        "b9c9a059-d63a-4abe-9403-449f2352391a",
                        "bac97ced-fab8-4545-9b91-870dfc6f4bdf",
                        "c3eee093-b3ff-47ae-a5ac-e005bb060e4a",
                        "c455fb04-4566-4648-ad6f-3cf2245e507c",
                        "c9482f1f-6600-44a7-a69a-e63ef13cdff8",
                        "cf09783a-75d7-4d0f-9e3f-c39b39b27cf5",
                        "d1cad764-0045-4592-b8f6-7b879f6bc56a",
                        "d7b1fba1-b5f8-4377-88a8-d2fc69f723b7",
                        "dc45e731-69f8-4829-ac34-97ae79f9a55a",
                        "e46b1853-c375-4277-afa5-6d1278b90736",
                        "e5f122f3-dd0f-4317-9ac2-2a4baa08ba01",
                        "ee9b186c-b7f0-4323-8f28-a55bbbd62b71",
                        "ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d",
                        "f111ff97-89a3-4df6-8f02-962d7b4fe985",
                        "fb5b7aa5-5d68-45b9-be8b-36d217d940d7",
                        "ffa029cf-7240-4723-8339-51fac57f9f28"
                    ],
                    "keyword": [
                        "object",
                        "image",
                        "texture",
                        "recognition",
                        "performance",
                        "local",
                        "features",
                        "evaluation",
                        "distributions",
                        "databases"
                    ],
                    "group": [],
                    "_id": "fc780759-4533-4b33-9774-746ca210842f",
                    "abstract": "Recently, methods based on local image features have shown promise for texture and object recognition tasks. This paper presents a large-scale evaluation of an approach that represents images as distributions (signatures or histograms) of features extracted from a sparse set of keypoint locations and learns a Support Vector Machine classifier with kernels based on two effective measures for comparing distributions, the Earth Mover's Distance and the ?2 distance. We first evaluate the performance of our approach with different keypoint detectors and descriptors, as well as different kernels and classifiers. We then conduct a comparative evaluation with several state-of-the-art recognition methods on four texture and five object databases. On most of these databases, our implementation exceeds the best reported results and achieves comparable performance on the rest. Finally, we investigate the influence of background correlations on recognition performance via extensive tests on the PASCAL database, for which ground-truth object localization information is available. Our experiments demonstrate that image representations based on distributions of local features are surprisingly effective for classification of texture and object images under challenging real-world conditions, including significant intra-class variations and substantial background clutter.",
                    "title": "Local Features and Kernels for Classification of Texture and Object Categories: A Comprehensive Study",
                    "venue": "International Journal of Computer Vision",
                    "year": 2007,
                    "__v": 2,
                    "citationCount": 1010,
                    "result": 5.652586425187044
                }
            }
        ],
        "_id": "f2d49150-35de-4fd5-ac46-eb071d1cc73e",
        "abstract": "We describe an object detection system based on mixtures of multiscale deformable part models. Our system is able to represent highly variable object classes and achieves state-of-the-art results in the PASCAL object detection challenges. While deformable part models have become quite popular, their value had not been demonstrated on difficult benchmarks such as the PASCAL data sets. Our system relies on new methods for discriminative training with partially labeled data. We combine a margin-sensitive approach for data-mining hard negative examples with a formalism we call latent SVM. A latent SVM is a reformulation of MI--SVM in terms of latent variables. A latent SVM is semiconvex, and the training problem becomes convex once latent information is specified for the positive examples. This leads to an iterative training algorithm that alternates between fixing latent values for positive examples and optimizing the latent SVM objective function.",
        "title": "Object Detection with Discriminatively Trained Part-Based Models",
        "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
        "year": 2010,
        "__v": 3,
        "citationCount": 3149
    },
    {
        "authors": [
            "Ian F. Akyildiz",
            "Weilian Su",
            "Yogesh Sankarasubramaniam",
            "Erdal Cayirci"
        ],
        "references": [
            "05e77df0-5ecd-435f-943d-9a5be09e969d",
            "05fb3436-276f-43ca-979b-0a3323240c19",
            "0f1d0353-2c63-49e9-b29c-4d258cf2a445",
            "10f58ff9-c14e-4bf5-9c44-0a3f14626d3f",
            "2088d2fd-d0ed-477f-b350-5d342624e91e",
            "23dd7fc0-1ebd-43ce-ab3e-43896512c209",
            "282f60bc-e000-420c-b8f7-6d52d645e2b9",
            "28f9f004-7356-4bb4-85e1-275330adeb32",
            "30e4f067-742f-4ad5-b8b0-66d3e8b6303f",
            "32b7988a-f873-44c9-bacb-0d660fe12f01",
            "35f43b14-7174-4eb7-ab99-ce32d08af1a4",
            "3657876a-6f24-47e3-bbba-62e4b3f7ab05",
            "38f54b84-5272-43df-8cde-a3e755b17dee",
            "3939cb96-d8c8-4ec4-8102-bbce2976aeee",
            "436c164e-783e-46c1-a03c-4c7473c8c2df",
            "47cc806c-a905-4355-9bfa-d1a49bf7034b",
            "4ac80067-bbea-4eaf-8b7a-89c97db7ecfe",
            "4ce4d734-c29c-4097-9ca9-314feaccc642",
            "553db688-bb98-4ed0-a2a4-42f1e5678559",
            "55a6413a-4a9c-4e8d-957b-8c1a4e5d5f0b",
            "653c2aa8-cf50-451c-8877-f397ffd07fb5",
            "6b527e7d-50c4-42f5-b3d2-b688d23b8138",
            "73574f5f-bf4f-44fb-b13f-d5eaa8c96619",
            "776f8406-6b10-4397-a1b6-5c8b9b0e1927",
            "81074e3c-5e19-4dd5-9b64-52e97111b919",
            "84dc5aaa-7b2c-4f15-97f4-aa867b4328e2",
            "869b266e-e607-4f60-92d8-d8726d0c97da",
            "8828d2f5-0b50-4715-863d-66c787fc40e0",
            "97612810-668b-4ed2-87d8-38eada1f6377",
            "988d1185-0dd2-4da9-9f47-2be897e90836",
            "9b531247-bb38-4d26-94e8-dab8c453e3ca",
            "9e063b41-0ada-4db8-8846-6e5153a0de55",
            "9e52b6a5-e70c-437f-a30d-8d544132c939",
            "9eafc226-1312-41de-a492-2835f4d04b13",
            "a0d62424-8f60-46e7-aa92-4fd3c26f472e",
            "afc06b7c-7fb3-4f88-942b-3076ed77920e",
            "b2ccb628-0c27-48cf-8b5e-291ab25b9117",
            "b7c9f36d-9c92-4a6d-a3d8-3d81d5c839de",
            "ba0c3ecd-ee31-400a-9125-b1df96a998a6",
            "bd9d3ea6-7749-4f91-bee0-1a953d6d1eb9",
            "c4ebd69b-bb41-4715-bed3-9ea35e246db0",
            "cabe73d6-d410-47fc-8604-02ec6d37b57c",
            "d844e86f-758a-4c98-b896-1a972a90df97",
            "dfc9f1b0-a952-42e2-bc5e-c5d78c053d2d",
            "e4ae164f-53b7-4a17-a850-bcd5ed2308e0",
            "e9b312ab-fead-4b3f-a5a6-bf19e6b50fab",
            "f699578c-c859-4e95-9e8c-5a56629a3a09",
            "f8ece2c5-c8b1-4a1e-8528-c09357ec23a4",
            "fdc216a2-018d-467f-b463-5c051c352111"
        ],
        "keyword": [
            "sensor",
            "networks",
            "explored",
            "communications",
            "wireless",
            "viable",
            "technology",
            "tasks",
            "systems",
            "sensing"
        ],
        "group": [
            {
                "05fb3436-276f-43ca-979b-0a3323240c19": {
                    "authors": [
                        "Ya Xu",
                        "John S. Heidemann",
                        "Deborah Estrin"
                    ],
                    "references": [],
                    "keyword": [
                        "gaf",
                        "nodes",
                        "energy",
                        "routing",
                        "fidelity",
                        "simulate",
                        "networks",
                        "lifetime",
                        "increases",
                        "hoc"
                    ],
                    "group": [],
                    "_id": "05fb3436-276f-43ca-979b-0a3323240c19",
                    "abstract": "We introduce a geographical adaptive fidelity (GAF) algorithm that reduces energy consumption in ad hoc wireless networks. GAF conserves energy by identifying nodes that are equivalent from a routing perspective and turning off unnecessary nodes, keeping a constant level of routing fidelity. GAF moderates this policy using application- and system-level information; nodes that source or sink data remain on and intermediate nodes monitor and balance energy use. GAF is independent of the underlying ad hoc routing protocol; we simulate GAF over unmodified AODV and DSR. Analysis and simulation studies of GAF show that it can consume 40% to 60% less energy than an unmodified ad hoc routing protocol. Moreover, simulations of GAF suggest that network lifetime increases proportionally to node density; in one example, a four-fold increase in node density leads to network lifetime increase for 3 to 6 times (depending on the mobility pattern). More generally, GAF is an example of adaptive fidelity, a technique proposed for extending the lifetime of self-configuring systems by exploiting redundancy to conserve energy while maintaining application fidelity.",
                    "title": "Geography-informed Energy Conservation for Ad Hoc Routing",
                    "venue": "",
                    "year": 2001,
                    "__v": 2,
                    "citationCount": 991,
                    "result": 4.981578509210087
                },
                "4ce4d734-c29c-4097-9ca9-314feaccc642": {
                    "authors": [
                        "Tomasz Imielinski",
                        "Samir Goel"
                    ],
                    "references": [
                        "027291a7-a3fd-4ab0-a81c-6e350f989cc5"
                    ],
                    "keyword": [
                        "dataspace",
                        "network",
                        "queried",
                        "objects",
                        "monitored",
                        "local",
                        "geographically",
                        "addressed"
                    ],
                    "group": [],
                    "_id": "4ce4d734-c29c-4097-9ca9-314feaccc642",
                    "abstract": "We introduce a new conception of three-dimensional DataSpace, which is physical space enhanced by connectivity to the network. DataSpace is addressed geographically as opposed to the current logical addressing scheme of the Internet. Here, a local area network is replaced by a room, a street, a mountaintop, and so on. Billions of objects populate DataSpace, each aware of its own geographic location. These objects move through DataSpace, and produce and locally store their own data. They can be selectively queried, monitored, and controlled based on their properties. We propose two architectures for DataSpace. We describe mechanisms to use the network as a DataSpace engine in order to perform querying and monitoring operation in a highly scalable way.",
                    "title": "DataSpace: querying and monitoring deeply networked collections in physical space",
                    "venue": "IEEE Personal Communications",
                    "year": 2000,
                    "__v": 2,
                    "citationCount": 37,
                    "result": 4.6469177880942585
                },
                "553db688-bb98-4ed0-a2a4-42f1e5678559": {
                    "authors": [
                        "Ajay V. Bakre",
                        "B. R. Badrinath"
                    ],
                    "references": [
                        "02df8f8c-ddff-4412-b212-7d41e9af7a2e",
                        "0b648474-ee09-4bfe-9eb8-62018d7595ad",
                        "0ce74249-8be4-45f5-96de-c5fb2c69c2e9",
                        "17f9698e-02de-4248-b2b8-9bc3c2ccfaff",
                        "22cf117e-17a7-44ab-b502-11389ffbbaa8",
                        "2eb01c13-2c0c-4ae5-83e8-3b2033848374",
                        "6a9c2062-e8eb-4584-8d40-35f8ed4e40d2",
                        "9ed8e875-ca35-4c39-b6e1-35e9802f3933",
                        "ee4aae5e-a7fe-4521-b3f9-280d3abeb745",
                        "f1bfc5c7-e5bb-4958-828d-c523c5e075aa",
                        "fd85eee7-2f63-476b-917a-d7087733f922"
                    ],
                    "keyword": [
                        "mobile",
                        "hosts",
                        "wireless",
                        "itcp",
                        "fixed",
                        "transport",
                        "network",
                        "link",
                        "layer",
                        "unreliable"
                    ],
                    "group": [],
                    "_id": "553db688-bb98-4ed0-a2a4-42f1e5678559",
                    "abstract": "IP based solutions to accommodate mobile hosts within existing internetworks do not address the distinctive features of wireless mobile computing. IP-based transport protocols thus suffer from poor performance when a mobile host communicates with a host on the fixed network. This is caused by frequent disruptions in network layer connectivity due to i) mobility and ii) unreliable nature of the wireless link. We describe I-TCP, which is an indirect transport layer protocol for mobile hosts. I-TCP utilizes the resources of Mobility Support Routers (MSRs) to provide transport layer communication between mobile hosts and hosts on the fixed network. With I-TCP, the problems related to mobility and unreliability of wireless link are handled entirely within the wireless link; the TCP/IP software on the fixed hosts is not modified. Using I-TCP on our testbed, the throughput between a fixed host and a mobile host improved substantially in comparison to regular TCP.",
                    "title": "I-TCP: indirect TCP for mobile hosts",
                    "venue": "international conference on distributed computing systems",
                    "year": 1995,
                    "__v": 2,
                    "citationCount": 518,
                    "result": 5.513764013764015
                },
                "6b527e7d-50c4-42f5-b3d2-b688d23b8138": {
                    "authors": [
                        "Eugene Shih",
                        "SeongHwan Cho",
                        "Nathan Ickes",
                        "Rex Min",
                        "Amit Sinha",
                        "Alice Wang",
                        "Anantha P. Chandrakasan"
                    ],
                    "references": [
                        "0b9c4010-5c06-4bd0-bbdb-b4b9b1319937",
                        "0f1d0353-2c63-49e9-b29c-4d258cf2a445",
                        "1081ae4c-2a85-4b47-a903-b5518ee62334",
                        "23dd7fc0-1ebd-43ce-ab3e-43896512c209",
                        "28f9f004-7356-4bb4-85e1-275330adeb32",
                        "38f54b84-5272-43df-8cde-a3e755b17dee",
                        "3939cb96-d8c8-4ec4-8102-bbce2976aeee",
                        "4934742a-77f3-41c6-a7da-99aea0eecfb3",
                        "4ac80067-bbea-4eaf-8b7a-89c97db7ecfe",
                        "776f8406-6b10-4397-a1b6-5c8b9b0e1927",
                        "869b266e-e607-4f60-92d8-d8726d0c97da",
                        "90b80d6a-d4e1-445a-a42e-cf37ccc650b7",
                        "9e063b41-0ada-4db8-8846-6e5153a0de55",
                        "afc06b7c-7fb3-4f88-942b-3076ed77920e",
                        "ba0c3ecd-ee31-400a-9125-b1df96a998a6",
                        "bd9d3ea6-7749-4f91-bee0-1a953d6d1eb9",
                        "c4ebd69b-bb41-4715-bed3-9ea35e246db0",
                        "d837e24c-026d-4dcd-91b7-21e7364d863d",
                        "d844e86f-758a-4c98-b896-1a972a90df97",
                        "e4b25d27-0214-4921-a88d-b2c8b37d3515",
                        "ee1062a6-21fd-4ce8-9dde-60f37a92a26c"
                    ],
                    "keyword": [
                        "networks",
                        "design",
                        "applications",
                        "wireless",
                        "protocols",
                        "physical",
                        "microsensors",
                        "layer",
                        "hardware",
                        "challenges"
                    ],
                    "group": [],
                    "_id": "6b527e7d-50c4-42f5-b3d2-b688d23b8138",
                    "abstract": "The potential for collaborative, robust networks of microsensors has attracted a great deal of research attention. For the most part, this is due to the compelling applications that will be enabled once wireless microsensor networks are in place; location-sensing, environmental sensing, medical monitoring and similar applications are all gaining interest. However, wireless microsensor networks pose numerous design challenges. For applications requiring long-term, robust sensing, such as military reconnaissance, one important challenge is to design sensor networks that have long system lifetimes. This challenge is especially difficult due to the energy-constrained nature of the devices. In order to design networks that have extremely long lifetimes, we propose a physical layer driven approach to designing protocols and algorithms. We first present a hardware model for our wireless sensor node and then introduce the design of physical layer aware protocols, algorithms, and applications that minimize energy consumption of the system. Our approach prescribes methods that can be used at all levels of the hierarchy to take advantage of the underlying hardware. We also show how to reduce energy consumption of non-ideal hardware through physical layer aware algorithms and protocols.",
                    "title": "Physical layer driven protocol and algorithm design for energy-efficient wireless sensor networks",
                    "venue": "acm ieee international conference on mobile computing and networking",
                    "year": 2001,
                    "__v": 2,
                    "citationCount": 378,
                    "result": 10.230198886081238
                },
                "73574f5f-bf4f-44fb-b13f-d5eaa8c96619": {
                    "authors": [
                        "Alec Woo",
                        "David E. Culler"
                    ],
                    "references": [
                        "0b93552e-74e8-483f-82cb-5c04e1cd9232",
                        "10f58ff9-c14e-4bf5-9c44-0a3f14626d3f",
                        "1dd8c68d-3b20-4171-9245-3a12c64c2838",
                        "3804c050-c207-4072-8077-f61297d009aa",
                        "38f54b84-5272-43df-8cde-a3e755b17dee",
                        "6858fa05-89cf-48b9-ab78-507b868de4bd",
                        "686b1f97-3cb7-47a6-bbd2-e8ba891dc1b5"
                    ],
                    "keyword": [
                        "networks",
                        "energy",
                        "control",
                        "sensor",
                        "regime",
                        "media",
                        "goals",
                        "fair",
                        "efficient",
                        "computation"
                    ],
                    "group": [],
                    "_id": "73574f5f-bf4f-44fb-b13f-d5eaa8c96619",
                    "abstract": "We study the problem of media access control in the novel regime of sensor networks, where unique application behavior and tight constraints in computation power, storage, energy resources, and radio technology have shaped this design space to be very different from that found in traditional mobile computing regime. Media access control in sensor networks must not only be energy efficient but should also allow fair bandwidth allocation to the infrastructure for all nodes in a multihop network. We propose an adaptive rate control mechanism aiming to support these two goals and find that such a scheme is most effective in achieving our fairness goal while being energy efficient for both low and high duty cycle of network traffic.",
                    "title": "A transmission control scheme for media access in sensor networks",
                    "venue": "acm ieee international conference on mobile computing and networking",
                    "year": 2001,
                    "__v": 1,
                    "citationCount": 445,
                    "result": 6.918517289618957
                },
                "776f8406-6b10-4397-a1b6-5c8b9b0e1927": {
                    "authors": [
                        "B. Narendran",
                        "James Sienicki",
                        "Shalini Yajnik",
                        "Prathima Agrawal"
                    ],
                    "references": [
                        "a18a352c-df54-494b-b5db-1bbe7637f046"
                    ],
                    "keyword": [
                        "power",
                        "control",
                        "systems",
                        "algorithm",
                        "user",
                        "unified",
                        "mobile",
                        "error"
                    ],
                    "group": [],
                    "_id": "776f8406-6b10-4397-a1b6-5c8b9b0e1927",
                    "abstract": "We study the performance of a unified power control and forward error correction control algorithm for mobile radio systems that attempts to maximize system capacity and minimize transmitter power utilization while satisfying user defined quality of service constraints. The algorithm is distributed, with each individual transmitter-receiver pair determining its own operating point with respect to power and error control parameters. Simulation results from a cellular system with mobile users show that this unified algorithm outperforms the schemes that use power control alone.",
                    "title": "Evaluation of an adaptive power and error control algorithm for wireless systems",
                    "venue": "international conference on communications",
                    "year": 1997,
                    "__v": 2,
                    "citationCount": 16,
                    "result": 3.6868257473520636
                },
                "81074e3c-5e19-4dd5-9b64-52e97111b919": {
                    "authors": [
                        "Irfan A. Essa"
                    ],
                    "references": [
                        "09c5663f-0e10-42dd-8a06-de98eb6283d0",
                        "309aa6fc-9044-4961-aeb1-c0018878d233",
                        "3bc63ea2-cdce-47ff-bb35-ef34a3fd3e81",
                        "7f7fd004-7853-4c6c-b120-e9a9b9ea4821",
                        "99ccc33c-b6ff-4d4f-8aa0-a5d063b6314a",
                        "b7b6250a-2ae7-42cb-aa70-425eead247a5",
                        "da19c758-4c30-472b-91e4-3ef0c4b8270f",
                        "da3364d5-34e0-4565-b2f9-aa9c7c700d91",
                        "de127c5a-26a8-4756-82cb-f223ba82b5d6"
                    ],
                    "keyword": [
                        "sense",
                        "environments",
                        "support",
                        "infrastructure",
                        "development",
                        "computing",
                        "awareness",
                        "ubiquitous",
                        "transmission",
                        "technology"
                    ],
                    "group": [],
                    "_id": "81074e3c-5e19-4dd5-9b64-52e97111b919",
                    "abstract": "As computing technology continues to become increasingly pervasive and ubiquitous, we envision the development of environments that can sense what we are doing and support our daily activities. In this article, we outline our efforts toward building such environments and discuss the importance of a sensing and signal-understanding infrastructure that leads to awareness of what is happening in an environment and how it can best be supported. Such an infrastructure supports both high- and low-end data transmission and processing, while allowing for detailed interpretation, modeling and recognition from sensed information. We are currently prototyping several aware environments to aid in the development and study of such sensing and computation in real-world settings.",
                    "title": "Ubiquitous sensing for smart and aware environments",
                    "venue": "IEEE Personal Communications",
                    "year": 2000,
                    "__v": 2,
                    "citationCount": 41,
                    "result": 7.077516798646831
                },
                "84dc5aaa-7b2c-4f15-97f4-aa867b4328e2": {
                    "authors": [
                        "Alberto E. Cerpa",
                        "Jeremy Elson",
                        "Deborah Estrin",
                        "Lewis Girod",
                        "Michael Hamilton",
                        "Jerry Zhao"
                    ],
                    "references": [
                        "0b34e114-4034-4efb-8163-9426229ba711",
                        "0d4d0363-07b5-43b6-976d-955e96044709",
                        "4ac80067-bbea-4eaf-8b7a-89c97db7ecfe",
                        "4dbbb936-3108-4096-826a-c6488f635a31",
                        "55a6413a-4a9c-4e8d-957b-8c1a4e5d5f0b",
                        "83a2eb55-b330-4e0c-8dc9-05e9466d5028",
                        "89253643-14dd-4793-b95a-a54bc59e72ff",
                        "9e063b41-0ada-4db8-8846-6e5153a0de55",
                        "afc06b7c-7fb3-4f88-942b-3076ed77920e",
                        "fab6340c-b4eb-4988-b77a-719bce44f145"
                    ],
                    "keyword": [
                        "systems",
                        "data",
                        "sensors",
                        "applications",
                        "wireless",
                        "nodes",
                        "networks",
                        "monitoring",
                        "architectures"
                    ],
                    "group": [],
                    "_id": "84dc5aaa-7b2c-4f15-97f4-aa867b4328e2",
                    "abstract": "As new fabrication and integration technologies reduce the cost and size of micro-sensors and wireless interfaces, it becomes feasible to deploy densely distributed wireless networks of sensors and actuators. These systems promise to revolutionize biological, earth, and environmental monitoring applications, providing data at granularities unrealizable by other means. In addition to the challenges of miniaturization, new system architectures and new network algorithms must be developed to transform the vast quantity of raw sensor data into a manageable stream of high-level data. To address this, we propose a tiered system architecture in which data collected at numerous, inexpensive sensor nodes is filtered by local processing on its way through to larger, more capable and more expensive nodes.We briefly describe Habitat monitoring as our motivating application and introduce initial system building blocks designed to support this application. The remainder of the paper presents details of our experimental platform.",
                    "title": "Habitat monitoring: application driver for wireless communications technology",
                    "venue": "acm special interest group on data communication",
                    "year": 2001,
                    "__v": 2,
                    "citationCount": 411,
                    "result": 9.809999025987526
                },
                "8828d2f5-0b50-4715-863d-66c787fc40e0": {
                    "authors": [
                        "Adrian Perrig",
                        "Robert Szewczyk",
                        "Victor Wen",
                        "David E. Culler",
                        "J. D. Tygar"
                    ],
                    "references": [
                        "09756c4e-2414-4dd1-8e35-c1410d3511b6",
                        "0ab8c0f9-fdba-428d-81a3-da79d759598e",
                        "0b868c0b-2b01-4732-abfb-06a8773783cb",
                        "0d4d0363-07b5-43b6-976d-955e96044709",
                        "0e1c9c62-343a-447a-9b47-9b3012656cdb",
                        "1dd8c68d-3b20-4171-9245-3a12c64c2838",
                        "28fa59f0-eca3-4c79-a2e8-2a60a9180b1c",
                        "2ee9a087-6188-4ebd-95b9-6561cba0584c",
                        "2f814545-7696-433e-b8fd-e680a9cc5a1f",
                        "31c5e39a-3f24-4d20-bf8c-3d00036baf95",
                        "3fb43b00-905c-4a08-934d-198ea4eb66c3",
                        "48a829fd-7c8f-4bb7-b481-ae23d55570a2",
                        "4c4597ec-30be-4738-b3d6-95dda4722250",
                        "51da4901-311e-46ba-a066-0656779980c6",
                        "59054202-3dbe-424a-bd0a-b70986faf2ed",
                        "5fd22977-137c-4b3b-904c-f05e02f4fb31",
                        "60fb0dc2-bde3-4714-948e-de0ed12ab460",
                        "668f4a29-4f19-4f95-8051-ad912a1b7de9",
                        "6b2923c7-0b03-4070-be88-9214369dfd53",
                        "745f0f29-0489-4906-b625-fd0efa9f85aa",
                        "83a2eb55-b330-4e0c-8dc9-05e9466d5028",
                        "a76086c3-fd36-4c8d-8a98-619ac62a3d5c",
                        "b68fc787-7817-421e-8e66-8a98ab9db1ad",
                        "bdd9387e-ed5f-4208-acd2-37e2e033827c",
                        "bf2e4bc7-c465-43c7-85ca-80cd98efe735",
                        "ca394e6a-59e0-466c-a66a-d976555db689",
                        "cd7b4b1f-8614-4fab-8c33-a89394f0d6f9",
                        "d782ce32-3afb-4683-a07b-2e68cd540c6a",
                        "f7268eda-b392-44cd-bcd8-134cbb9032ff"
                    ],
                    "keyword": [
                        "security",
                        "protocol",
                        "networks",
                        "data",
                        "suite",
                        "sensor",
                        "building",
                        "authentication",
                        "tesla",
                        "snep"
                    ],
                    "group": [],
                    "_id": "8828d2f5-0b50-4715-863d-66c787fc40e0",
                    "abstract": "As sensor networks edge closer towards wide-spread deployment, security issues become a central concern. So far, much research has focused on making sensor networks feasible and useful, and has not concentrated on security.  We present a suite of security building blocks optimized for resource-constrained environments and wireless communication. SPINS has two secure building blocks: SNEP and μTESLA SNEP provides the following important baseline security primitives: Data confidentiality, two-party data authentication, and data freshness. A particularly hard problem is to provide efficient broadcast authentication, which is an important mechanism for sensor networks. μTESLA is a new protocol which provides authenticated broadcast for severely resource-constrained environments. We implemented the above protocols, and show that they are practical even on minimal hardware: the performance of the protocol suite easily matches the data rate of our network. Additionally, we demonstrate that the suite can be used for building higher level protocols.",
                    "title": "SPINS: security protocols for sensor networks",
                    "venue": "acm ieee international conference on mobile computing and networking",
                    "year": 2001,
                    "__v": 1,
                    "citationCount": 1514,
                    "result": 6.6375836152151955
                },
                "97612810-668b-4ed2-87d8-38eada1f6377": {
                    "authors": [
                        "Yu-Chee Tseng",
                        "Shih-Lin Wu",
                        "Chih-Yu Lin",
                        "Jang-Ping Sheu"
                    ],
                    "references": [
                        "05e77df0-5ecd-435f-943d-9a5be09e969d",
                        "0d5d6c89-52f5-4353-b8f7-be8e58633b60",
                        "185dfc84-5463-4022-b36f-7e95073d5042",
                        "1cac3872-1a0d-4a21-a7ce-084f3ad63692",
                        "21d4ab31-90aa-474e-8c27-ca6f85a9ce76",
                        "277cd65c-dcb3-4347-835b-e058f2e057f1",
                        "5e3d00a5-22c5-4708-bc3e-70b59f0c9067",
                        "73aa328e-83a1-4ccd-a60a-02d07df09db2",
                        "7b625230-914e-46e9-b9a9-4fc881ae3842",
                        "a527b427-de51-4ef4-8ae7-057ca81901d3",
                        "a6e8d7c2-13dd-4093-bf5f-aa8f130f9151",
                        "cfbb611c-c0c1-4023-a09e-1a3c0ddf7911",
                        "da931260-00e6-400b-ba90-d1fb00690031",
                        "e4242955-c64f-4276-b020-ee7835a70d30",
                        "ec96c8dd-83d0-48f1-ab6c-91ff74d069a9"
                    ],
                    "keyword": [
                        "control",
                        "power",
                        "mobile",
                        "protocols",
                        "medium",
                        "manet",
                        "hosts",
                        "channels",
                        "required",
                        "networks"
                    ],
                    "group": [],
                    "_id": "97612810-668b-4ed2-87d8-38eada1f6377",
                    "abstract": "In a mobile ad-hoc networks (MANET), one essential issue is medium access control (MAC) which addresses how to utilize the radio spectrum efficiently and to resolve potential contention and collision among mobile hosts on using the medium. Existing work is dedicated to using multiple channels and power control to improve the performance of MANET. We investigate the possibility of bringing the concepts of power control and multi-channel medium access together in the MAC design problem in a MANET. Existing protocols only address one of these issues independently. The proposed protocol is characterized by the following features: it follows an \"on-demand\" style to assign channels to mobile hosts; the number of channels required is independent of the network topology and degree; it flexibly adapts to host mobility; no form of clock synchronization is required; and power control is used to exploit frequency reuse. Power control may also extend battery life and reduce signal interference, both of which are important in wireless communication. Through simulations, we demonstrate the advantage of our new protocol.",
                    "title": "A multi-channel MAC protocol with power control for multi-hop mobile ad hoc networks",
                    "venue": "international conference on distributed computing systems",
                    "year": 2001,
                    "__v": 2,
                    "citationCount": 29,
                    "result": 4.331280981292037
                },
                "988d1185-0dd2-4da9-9f47-2be897e90836": {
                    "authors": [
                        "Chavalit Srisathapornphat",
                        "Chaiporn Jaikaeo",
                        "Chien-Chung Shen"
                    ],
                    "references": [
                        "0098ce89-9e58-4d21-8dc6-cd84ec17dd37",
                        "9e063b41-0ada-4db8-8846-6e5153a0de55",
                        "f8ece2c5-c8b1-4a1e-8528-c09357ec23a4"
                    ],
                    "keyword": [
                        "sensor",
                        "networked",
                        "sina",
                        "programmable",
                        "information",
                        "tasks",
                        "queried",
                        "nodes",
                        "facilitated"
                    ],
                    "group": [],
                    "_id": "988d1185-0dd2-4da9-9f47-2be897e90836",
                    "abstract": "The advent of technology has facilitated the development of networked systems of extremely small, low-power devices that combine programmable general-purpose computing with multiple sensing and wireless communication capability. This networked system of programmable sensor nodes, which together form a sensor network, poses unique challenges on how information collected by, and stored within, the sensor network could be queried and accessed, and how concurrent sensing tasks could be executed internally and programmed by external users. In this paper, we describe SINA (Sensor Information Networking Architecture), which facilitates the querying, monitoring and tasking of sensor networks. We model a sensor network as a collection of massively distributed objects, and SINA plays the role of middleware that facilitates the adaptive organization of sensor information. The SINA kernel provides a set of configuration and communication primitives that enable the scalable, robust and energy-efficient organization of, and interactions among, sensor objects. On top of the SINA kernel is a programmable substrate that follows the spreadsheet paradigm and provides mechanisms to create associations among sensor nodes. Users then access information within a sensor network using declarative queries and perform tasks using programmable scripts. Issues concerning interworking between stationary sensor networks and mobile nodes are also addressed.",
                    "title": "Sensor Information Networking Architecture",
                    "venue": "",
                    "year": 2000,
                    "__v": 2,
                    "citationCount": 35,
                    "result": 7.822970055186946
                },
                "9b531247-bb38-4d26-94e8-dab8c453e3ca": {
                    "authors": [
                        "Li Li",
                        "Joseph Y. Halpern"
                    ],
                    "references": [
                        "0d4d0363-07b5-43b6-976d-955e96044709",
                        "1545dfd3-2c25-4ff1-b43c-df4a2a501d06",
                        "23dd7fc0-1ebd-43ce-ab3e-43896512c209",
                        "afd4c865-5c81-424b-82c3-1dcb6150ea6d",
                        "c8771a57-de9c-44b7-966c-1ff156d3091f",
                        "d7124e3a-a4cd-4a58-ba02-f77c773458ea",
                        "e3af190a-754d-415d-a32d-f1d9999c599f"
                    ],
                    "keyword": [
                        "protocol",
                        "computes",
                        "subnetwork",
                        "network",
                        "upsi",
                        "spl",
                        "path",
                        "minimumenergy",
                        "communication"
                    ],
                    "group": [],
                    "_id": "9b531247-bb38-4d26-94e8-dab8c453e3ca",
                    "abstract": "We propose a protocol that, given a communication network, computes a subnetwork such that, for every pair (u, /spl upsi/) of nodes connected in the original network, there is a a minimum-energy path between u and /spl upsi/ in the subnetwork (where a minimum-energy path is one that allows messages to be transmitted with a minimum use of energy). The network computed by our protocol is in general a subnetwork of the one computed by the protocol given by Rodoplu and Meng (see IEEE J. Selected Areas in Communications, vol.17, no.8, p.1333-44, 1999). Moreover, our protocol is computationally simpler. We demonstrate the performance improvements obtained by using the subnetwork computed by our protocol through simulation.",
                    "title": "Minimum-energy mobile wireless networks revisited",
                    "venue": "international conference on communications",
                    "year": 2001,
                    "__v": 2,
                    "citationCount": 148,
                    "result": 5.557198309577789
                },
                "9e52b6a5-e70c-437f-a30d-8d544132c939": {
                    "authors": [
                        "Charles Chien",
                        "Igor Elgorriaga",
                        "C. McConaghy"
                    ],
                    "references": [],
                    "keyword": [
                        "sensor",
                        "power",
                        "implementation",
                        "wireless",
                        "technologies",
                        "networks",
                        "modem",
                        "extended",
                        "easily",
                        "dissipating"
                    ],
                    "group": [],
                    "_id": "9e52b6a5-e70c-437f-a30d-8d544132c939",
                    "abstract": "Emerging CMOS and MEMS technologies enable the implementation of a large number of wireless distributed microsensors that can be easily and rapidly deployed to form highly redundant, self-configuring, and ad hoc sensor networks. To facilitate ease of deployment, these sensors should operate on battery for extended periods of time. A particular challenge in maintaining extended battery lifetime lies in achieving communications with low power. This paper presents a direct-sequence spread-spectrum modem architecture that provides robust communications for wireless sensor networks while dissipating very low power. The modem architecture has been verified in an FPGA implementation that dissipates only 33 mW for both transmission and reception. The implementation can be easily mapped to an ASIC technology with an estimated power performance of less than 1 row.",
                    "title": "Low-power direct-sequence spread-spectrum modem architecture for distributed wireless sensor networks",
                    "venue": "international symposium on low power electronics and design",
                    "year": 2001,
                    "__v": 2,
                    "citationCount": 14,
                    "result": 9.144395742753527
                },
                "a0d62424-8f60-46e7-aa92-4fd3c26f472e": {
                    "authors": [
                        "Chien-Chung Shen",
                        "Chavalit Srisathapornphat",
                        "Chaiporn Jaikaeo"
                    ],
                    "references": [
                        "47cc806c-a905-4355-9bfa-d1a49bf7034b",
                        "4ce4d734-c29c-4097-9ca9-314feaccc642",
                        "6825e7be-db72-4377-a599-6667ef0bd553",
                        "cabe73d6-d410-47fc-8604-02ec6d37b57c",
                        "f8ece2c5-c8b1-4a1e-8528-c09357ec23a4",
                        "fdc216a2-018d-467f-b463-5c051c352111",
                        "ffe96fe5-5423-42f6-8368-81da1c43766a"
                    ],
                    "keyword": [
                        "sensor",
                        "networking",
                        "sina",
                        "tasking",
                        "querying",
                        "objects",
                        "nodes",
                        "information",
                        "execution",
                        "environment"
                    ],
                    "group": [],
                    "_id": "a0d62424-8f60-46e7-aa92-4fd3c26f472e",
                    "abstract": "This article introduces a sensor information networking architecture, called SINA, that facilitates querying, monitoring, and tasking of sensor networks. SINA serves the role of middleware that abstracts a network of sensor nodes as a collection of massively distributed objects. SINA's execution environment provides a set of configuration and communication primitives that enable scalable and energy-efficient organization of and interactions among sensor objects. On top the execution environment is a programmable substrate that provides mechanisms to create associations and coordinate activities among sensor nodes. Users then access information within a sensor network using declarative queries, or perform tasks using programming script.",
                    "title": "Sensor information networking architecture and applications",
                    "venue": "IEEE Personal Communications",
                    "year": 2001,
                    "__v": 2,
                    "citationCount": 196,
                    "result": 8.423717180193249
                },
                "afc06b7c-7fb3-4f88-942b-3076ed77920e": {
                    "authors": [
                        "Chalermek Intanagonwiwat",
                        "Ramesh Govindan",
                        "Deborah Estrin"
                    ],
                    "references": [
                        "027291a7-a3fd-4ab0-a81c-6e350f989cc5",
                        "19bb3151-ecc6-47d3-a639-476590858f2b",
                        "4f60dbc7-9647-4b91-b96f-9f77d07fea7c",
                        "55a6413a-4a9c-4e8d-957b-8c1a4e5d5f0b",
                        "6500989e-b1e1-4b02-a921-21ec25685b73",
                        "7c9f8cd8-d0ef-4954-b4db-4a6c803459c2",
                        "83a2eb55-b330-4e0c-8dc9-05e9466d5028",
                        "b46af373-5147-4193-9c1d-70adb1f5a527",
                        "cae1e692-9d2c-48ca-80da-956c63397390",
                        "d563bff2-b63b-470e-a53f-567f8927dbf4",
                        "dc0c4146-bf52-4584-85d9-1ea648aecc14",
                        "f8ece2c5-c8b1-4a1e-8528-c09357ec23a4"
                    ],
                    "keyword": [
                        "directed",
                        "diffusion",
                        "nodes",
                        "networks",
                        "sensing",
                        "explore",
                        "enable",
                        "data",
                        "coordinate",
                        "communication"
                    ],
                    "group": [],
                    "_id": "afc06b7c-7fb3-4f88-942b-3076ed77920e",
                    "abstract": "Advances in processor, memory and radio technology will enable small and cheap nodes capable of sensing, communication and computation. Networks of such nodes can coordinate to perform distributed sensing of environmental phenomena. In this paper, we explore the  directed diffusion  paradigm for such coordination. Directed diffusion is datacentric in that all communication is for named data. All nodes in a directed diffusion-based network are application-aware. This enables diffusion to achieve energy savings by selecting empirically good paths and by caching and processing data in-network. We explore and evaluate the use of directed diffusion for a simple remote-surveillance sensor network.",
                    "title": "Directed diffusion: a scalable and robust communication paradigm for sensor networks",
                    "venue": "acm ieee international conference on mobile computing and networking",
                    "year": 2000,
                    "__v": 2,
                    "citationCount": 2463,
                    "result": 10.212068336842771
                },
                "b2ccb628-0c27-48cf-8b5e-291ab25b9117": {
                    "authors": [
                        "Amit Sinha",
                        "Anantha P. Chandrakasan"
                    ],
                    "references": [
                        "55b61c03-4f91-4f1a-8395-ab99ec10f0bb",
                        "5767d589-8def-481b-bf46-4ad7484a8bbc",
                        "d1c0391c-b34d-4082-b3f1-220eb727e692",
                        "d844e86f-758a-4c98-b896-1a972a90df97"
                    ],
                    "keyword": [
                        "power",
                        "transition",
                        "system",
                        "state",
                        "sleepstate",
                        "management",
                        "energy",
                        "dpm",
                        "wake",
                        "sleep"
                    ],
                    "group": [],
                    "_id": "b2ccb628-0c27-48cf-8b5e-291ab25b9117",
                    "abstract": "We propose an OS-directed power management technique to improve the energy efficiency of sensor nodes. Dynamic power management (DPM) is an effective tool in reducing system power consumption without significantly degrading performance. The basic idea is to shut down devices when not needed and wake them up when necessary. DPM, in general, is not a trivial problem. If the energy and performance overheads in sleep-state transition were negligible, then a simple greedy algorithm that makes the system enter the deepest sleep state when idling would be perfect. However, in reality, sleep-state transitioning has the overhead of storing processor state and turning off power. Waking up also takes a finite amount of time. Therefore, implementing the correct policy for sleep-state transitioning is critical for DPM success. It is argued that power-aware methodology uses an embedded microoperating system to reduce node energy consumption by exploiting both sleep state and active power management.",
                    "title": "Dynamic power management in wireless sensor networks",
                    "venue": "IEEE Design & Test of Computers",
                    "year": 2001,
                    "__v": 1,
                    "citationCount": 242,
                    "result": 5.34597944072734
                },
                "ba0c3ecd-ee31-400a-9125-b1df96a998a6": {
                    "authors": [
                        "Paul Lettieri",
                        "Mani B. Srivastava"
                    ],
                    "references": [
                        "5bb54ec7-3954-43a7-b008-92ad0f43063f",
                        "655eacc0-ab6d-49a5-a262-07dd38c3b609",
                        "66c490f1-f6c9-4742-b9a8-acd5ccc504af",
                        "6d6ad30a-396a-4cc1-b62d-7cb7c4d79b42"
                    ],
                    "keyword": [
                        "adaptive",
                        "links",
                        "frame",
                        "channel",
                        "layer",
                        "control",
                        "wireless",
                        "radio",
                        "error"
                    ],
                    "group": [],
                    "_id": "ba0c3ecd-ee31-400a-9125-b1df96a998a6",
                    "abstract": "Wireless network links are characterized by rapidly time varying channel conditions and battery energy limitations at the wireless mobile user nodes. Therefore static link control techniques that make sense in comparatively well behaved wired links do not necessarily apply to wireless links. New adaptive link layer control techniques are needed to provide robust and energy efficient operation even in the presence of orders of magnitude variations in bit error rates and other radio channel conditions. For example, research has advocated adaptive link layer techniques such as adaptive error control, channel state dependent protocols, and variable spreading gain. We explore dynamic sizing of the MAC layer frame, the atomic unit that is sent through the radio channel. A trade-off exists between the desire to reduce the header and physical layer overhead by making frames large, and the need to reduce frame error rates in the noisy channel by using small frame lengths. Clearly the optimum depends on the channel conditions. Through analysis supported by physical measurements with Lucent's WaveLAN radio we show that adaptive sizing of the MAC layer frame in the presence of varying channel noise indeed has a large impact on the user seen throughput (goodput). In addition, we show how that adaptive frame length control can be exploited to improve the energy efficiency for a desired level of goodput, and to extend the usable radio range with graceful throughput degradation. We describe the implementation of the adaptive MAC frame length control mechanism in combination with adaptive hybrid FEC/ARQ error control in a reconfigurable wireless link layer packet processing architecture for a low-power adaptive wireless multimedia node.",
                    "title": "Adaptive frame length control for improving wireless link throughput, range, and energy efficiency",
                    "venue": "international conference on computer communications",
                    "year": 1998,
                    "__v": 2,
                    "citationCount": 130,
                    "result": 3.5297329261725547
                },
                "bd9d3ea6-7749-4f91-bee0-1a953d6d1eb9": {
                    "authors": [
                        "Michele Zorzi",
                        "Ramesh R. Rao"
                    ],
                    "references": [
                        "6528fe84-c7b2-4fbc-a72c-e73d4705fd36",
                        "8484e412-7fcc-4707-93e4-f79940c2c383",
                        "869b266e-e607-4f60-92d8-d8726d0c97da",
                        "f7a10d8a-280b-4462-82ee-5c04556942f6"
                    ],
                    "keyword": [
                        "energy",
                        "channel",
                        "transmissions",
                        "model",
                        "battery",
                        "sources",
                        "slight",
                        "scheme",
                        "lead",
                        "errors"
                    ],
                    "group": [],
                    "_id": "bd9d3ea6-7749-4f91-bee0-1a953d6d1eb9",
                    "abstract": "We consider the problem of communications over a wireless channel in support of data transmissions from the perspective of small portable devices that must rely on limited battery energy. We model the channel outages as statistically correlated errors. Classic ARQ strategies are found to lead to a considerable waste of energy, due to the large number of transmissions. The use of finite energy sources in the face of dependent channel errors leads to new protocol design criteria. As an example, a simple probing scheme, which slows down the transmission rate when the channel is impaired, is show? to be more energy efficient, with a slight loss in throughput. A modified scheme that yields slightly better performance but requires some additional complexity is also studied. Some references on the modeling of battery cells are discussed to highlight the fact that battery charge capacity is strongly influenced by the available \"relaxation time\" between current pulses. A formal approach that can track complex models for power sources, including dynamic charge recovery, is also developed.",
                    "title": "Error control and energy consumption in communications for nomadic computing",
                    "venue": "IEEE Transactions on Computers",
                    "year": 1997,
                    "__v": 2,
                    "citationCount": 105,
                    "result": 4.252336037347093
                },
                "c4ebd69b-bb41-4715-bed3-9ea35e246db0": {
                    "authors": [
                        "Mark Weiser",
                        "Brent B. Welch",
                        "Alan J. Demers",
                        "Scott Shenker"
                    ],
                    "references": [
                        "3b33321f-99d3-48ae-9548-424791878c60",
                        "9ada4e4d-dfeb-4ed6-b7b7-1e9464a771b3",
                        "b27c3adc-4ac3-4461-91b3-d96facf9961a",
                        "c1a4415a-3629-475f-b073-5f602a13440c",
                        "c94251ca-b695-4c29-bfe4-6537a7d6d0bc"
                    ],
                    "keyword": [
                        "reducing",
                        "energy",
                        "systems",
                        "method",
                        "speed",
                        "clock",
                        "performance",
                        "operated",
                        "mipj",
                        "cpu"
                    ],
                    "group": [],
                    "_id": "c4ebd69b-bb41-4715-bed3-9ea35e246db0",
                    "abstract": "The energy usage of computer systems is becoming more important, especially for battery operated systems. Displays, disks, and cpus, in that order, use the most energy. Reducing the energy used by displays and disks has been studied elsewhere; this paper considers a new method for reducing the energy used by the cpu. We introduce a new metric for cpu energy performance, millions-of-instructions-per-joule (MIPJ). We examine a class of methods to reduce MIPJ that are characterized by dynamic control of system clock speed by the operating system scheduler. Reducing clock speed alone does not reduce MIPJ, since to do the same work the system must run longer. However, a number of methods are available for reducing energy with reduced clock-speed, such as reducing the voltage [Chandrakasan et al 1992][Horowitz 1993] or using reversible [Younis and Knight 1993] or adiabatic logic [Athas et al 1994].   What are the right scheduling algorithms for taking advantage of reduced clock-speed, especially in the presence of applications demanding ever more instructions-per-second? We consider several methods for varying the clock speed dynamically under control of the operating system, and examine the performance of these methods against workstation traces. The primary result is that by adjusting the clock speed at a fine grain, substantial CPU energy can be saved with a limited impact on performance.",
                    "title": "Scheduling for reduced CPU energy",
                    "venue": "operating systems design and implementation",
                    "year": 1994,
                    "__v": 2,
                    "citationCount": 576,
                    "result": 4.135418992771934
                },
                "cabe73d6-d410-47fc-8604-02ec6d37b57c": {
                    "authors": [
                        "Philippe Bonnet",
                        "Johannes Gehrke",
                        "Praveen Seshadri"
                    ],
                    "references": [
                        "21f5c29b-c0b8-4e29-b3e8-e6b80050c8ec",
                        "2d4188c8-a722-40fe-b630-7bc3549cc551",
                        "428592e3-854b-43e5-8ca8-87f10d466772",
                        "55a6413a-4a9c-4e8d-957b-8c1a4e5d5f0b",
                        "57cf1661-41a8-4e28-8143-342ad165cf55",
                        "5fb4c1bd-f557-44f0-8b74-600d16a2dffb",
                        "6350cbd7-e913-40b8-8513-553ee2a72f1e",
                        "690245db-d49a-4e00-8759-575f000d6204",
                        "90a28006-66ed-4230-99db-d183ded403c5",
                        "9e063b41-0ada-4db8-8846-6e5153a0de55",
                        "e0dcf271-d2c1-4625-9128-7368e846735f"
                    ],
                    "keyword": [
                        "devices",
                        "systems",
                        "query",
                        "large",
                        "data",
                        "techniques",
                        "networks",
                        "distributed",
                        "database",
                        "communication"
                    ],
                    "group": [],
                    "_id": "cabe73d6-d410-47fc-8604-02ec6d37b57c",
                    "abstract": "In the next decade, millions of sensors and small-scale mobile devices will integrate processors, memory, and communication capabilities. Networks of devices will be widely deployed for monitoring applications. In these new applications, users need to query very large collections of devices in an ad hoc manner. Most existing systems rely on a centralized system for collecting device data. These systems lack flexibility because data is extracted in a predefined way. Also, they do not scale to a large number of devices because large volumes of raw data are transferred. In our new concept of a device database system, distributed query execution techniques are applied to leverage the computing capabilities of devices, and to reduce communication. We define an abstraction that allows us to represent a device network as a database and we describe how distributed query processing techniques are applied in this new context.",
                    "title": "Querying the physical world",
                    "venue": "IEEE Personal Communications",
                    "year": 2000,
                    "__v": 2,
                    "citationCount": 180,
                    "result": 7.061893305475791
                },
                "dfc9f1b0-a952-42e2-bc5e-c5d78c053d2d": {
                    "authors": [
                        "Katayoun Sohrabi",
                        "Gao J",
                        "Vishal Ailawadhi",
                        "Gregory J. Pottie"
                    ],
                    "references": [
                        "082fd26c-ab26-42a9-8a94-eb7ed3a48a08",
                        "2fad490e-f39a-4224-ab8c-709a259c8c34",
                        "38f54b84-5272-43df-8cde-a3e755b17dee",
                        "47cc806c-a905-4355-9bfa-d1a49bf7034b",
                        "4a2c9915-0d26-4989-8285-6cff0d03f0ad",
                        "4f60dbc7-9647-4b91-b96f-9f77d07fea7c",
                        "55a6413a-4a9c-4e8d-957b-8c1a4e5d5f0b",
                        "5eed21bf-bb54-4245-b2b1-979734b1d786",
                        "5fec7385-fd12-43d7-af67-a0ce07fb8c33",
                        "c460a595-161b-47c9-941c-fa4e3009c275",
                        "dd0886de-d9f0-4463-b5b3-536f00c21a6d",
                        "ef4e6127-1de5-4998-a80c-571c606860a9"
                    ],
                    "keyword": [
                        "nodes",
                        "wireless",
                        "support",
                        "suite",
                        "subset",
                        "subnetworks",
                        "static",
                        "slow",
                        "signal",
                        "set"
                    ],
                    "group": [],
                    "_id": "dfc9f1b0-a952-42e2-bc5e-c5d78c053d2d",
                    "abstract": "We present a suite of algorithms for self-organization of wireless sensor networks in which there is a scalably large number of mainly static nodes with highly constrained energy resources. The protocols further support slow mobility by a subset of the nodes, energy-efficient routing, and formation of ad hoc subnetworks for carrying out cooperative signal processing functions among a set of the nodes.",
                    "title": "Protocols for self-organization of a wireless sensor network",
                    "venue": "IEEE Personal Communications",
                    "year": 2000,
                    "__v": 2,
                    "citationCount": 729,
                    "result": 6.910436575562628
                },
                "f699578c-c859-4e95-9e8c-5a56629a3a09": {
                    "authors": [
                        "Sasha Slijepcevic",
                        "Miodrag Potkonjak"
                    ],
                    "references": [
                        "23dd7fc0-1ebd-43ce-ab3e-43896512c209",
                        "24ac0bb6-6350-4e3e-81a5-4f680e03ab68",
                        "47cc806c-a905-4355-9bfa-d1a49bf7034b",
                        "4ac80067-bbea-4eaf-8b7a-89c97db7ecfe",
                        "55a6413a-4a9c-4e8d-957b-8c1a4e5d5f0b",
                        "5fd22977-137c-4b3b-904c-f05e02f4fb31",
                        "75d3c418-05b0-4927-8c72-2e0fa9b5b640",
                        "7d7f640e-caff-4334-afe1-34ca5729b242",
                        "9e063b41-0ada-4db8-8846-6e5153a0de55"
                    ],
                    "keyword": [
                        "nodes",
                        "sensor",
                        "networks",
                        "sets",
                        "number",
                        "monitoring",
                        "energy",
                        "deployment",
                        "activating",
                        "save"
                    ],
                    "group": [],
                    "_id": "f699578c-c859-4e95-9e8c-5a56629a3a09",
                    "abstract": "Wireless sensor networks have emerged recently as an effective way of monitoring remote or inhospitable physical environments. One of the major challenges in devising such networks lies in the constrained energy and computational resources available to sensor nodes. These constraints must be taken into account at all levels of the system hierarchy. The deployment of sensor nodes is the first step in establishing a sensor network. Since sensor networks contain a large number of sensor nodes, the nodes must be deployed in clusters, where the location of each particular node cannot be fully guaranteed a priori. Therefore, the number of nodes that must be deployed in order to completely cover the whole monitored area is often higher than if a deterministic procedure were used. In networks with stochastically placed nodes, activating only the necessary number of sensor nodes at any particular moment can save energy. We introduce a heuristic that selects mutually exclusive sets of sensor nodes, where the members of each of those sets together completely cover the monitored area. The intervals of activity are the same for all sets, and only one of the sets is active at any time. The experimental results demonstrate that by using only a subset of sensor nodes at each moment, we achieve a significant energy savings while fully preserving coverage.",
                    "title": "Power efficient organization of wireless sensor networks",
                    "venue": "international conference on communications",
                    "year": 2001,
                    "__v": 2,
                    "citationCount": 462,
                    "result": 8.128006120863263
                }
            }
        ],
        "_id": "f3267c01-b670-4b7a-a3a5-79088c0d90ab",
        "abstract": "This paper describes the concept of sensor networks which has been made viable by the convergence of micro-electro-mechanical systems technology, wireless communications and digital electronics. First, the sensing tasks and the potential sensor networks applications are explored, and a review of factors influencing the design of sensor networks is provided. Then, the communication architecture for sensor networks is outlined, and the algorithms and protocols developed for each layer in the literature are explored. Open research issues for the realization of sensor networks are also discussed.",
        "title": "Wireless sensor networks: a survey",
        "venue": "Computer Networks",
        "year": 2002,
        "__v": 3,
        "citationCount": 5060
    },
    {
        "authors": [
            "Maurice Clerc",
            "James Kennedy"
        ],
        "references": [],
        "keyword": [
            "particle",
            "view",
            "swarm",
            "algorithm",
            "time",
            "system",
            "optimal",
            "finding"
        ],
        "group": [
            null
        ],
        "_id": "f5cc526f-6cd4-401e-aac1-416ac15aa146",
        "abstract": "The particle swarm is an algorithm for finding optimal regions of complex search spaces through the interaction of individuals in a population of particles. This paper analyzes a particle's trajectory as it moves in discrete time (the algebraic view), then progresses to the view of it in continuous time (the analytical view). A five-dimensional depiction is developed, which describes the system completely. These analyses lead to a generalized model of the algorithm, containing a set of coefficients to control the system's convergence tendencies. Some results of the particle swarm optimizer, implementing modifications derived from the analysis, suggest methods for altering the original algorithm in ways that eliminate problems and increase the ability of the particle swarm to find optima of some well-studied test functions.",
        "title": "The particle swarm - explosion, stability, and convergence in a multidimensional complex space",
        "venue": "IEEE Transactions on Evolutionary Computation",
        "year": 2002,
        "__v": 2,
        "citationCount": 2113
    },
    {
        "authors": [
            "Gediminas Adomavicius",
            "Alexander Tuzhilin"
        ],
        "references": [
            "05234ed3-29a1-4a96-970c-44ebdf1a2fe6",
            "05f5fba9-e7ca-4c46-be79-df57944a8b41",
            "06f4b95e-9242-4408-b9cc-114357d88fe7",
            "09880ee2-8770-4f53-96d0-90eaa4d3133d",
            "0ad38f3e-8131-4287-9e62-2b2ae77f47f7",
            "0e00f9b2-a002-465a-baa8-e167aa0fbeac",
            "0ea745c7-58b2-48e8-9115-42e9b0d20f2a",
            "1406f119-82cd-4cbb-9231-f885212a724e",
            "1a9d8939-2919-4d50-8f2b-12b4aeb25aa1",
            "1b7418af-1aba-4090-bad4-0dd0e900f5aa",
            "238bfbbc-91cc-407b-8f37-b7942b09410a",
            "23f66d97-4abf-479f-8af5-ec833d850a24",
            "290e0375-d2ad-4bec-a94f-f05e1580125b",
            "2d741908-7f21-4984-89b3-53e34ebbd3e7",
            "2e34c4e7-7c2a-4172-af48-f32834865655",
            "312e54ca-e7e9-4129-99f4-36f3aeff827e",
            "3730ca24-81f0-456e-a7f3-5c0987e05147",
            "38332469-d318-4976-a49e-9613695cac08",
            "3cf667e4-b285-48e6-9816-085ce9c56f8c",
            "44e91111-b413-4143-85a9-81872a97fa9d",
            "47197c38-6c68-4fb5-9dd3-5b083262bd22",
            "48632bf4-3e9f-4e98-b8f6-c08aaf7f2b58",
            "48a1dbbd-b496-4b37-b3ba-db144c654d23",
            "57bd2d58-8b2c-4783-9bd0-445de23e5e76",
            "5d134b15-3e3f-402e-a4cd-d5022aef1305",
            "5ee83a3b-d5f8-4532-97dd-c0579bed0d17",
            "60c814e2-c4d1-47d7-9a5a-68f4141505ae",
            "67fa583a-da81-4338-8349-e9a7f19f6fe2",
            "694f475e-f6c4-4105-b645-84c7d592db30",
            "6a6d14f3-83d4-4df4-bd27-94455c216c4f",
            "6acfaeb4-5d94-4245-9a0a-dd0e8de54c6c",
            "6b700ee7-1b54-4aa7-8cdb-d6a9a08592aa",
            "7b960c31-7b3c-456f-9352-80380e2be085",
            "7f2e92f7-6a67-491c-9546-cfd9b8a3b348",
            "7f2f7b7d-3e6c-4196-9056-a943b3e96c2f",
            "812c314c-9742-46fa-b1e8-5c7d640f1322",
            "822235e6-6abe-442b-b761-b51795df418a",
            "8735c7ea-f5c6-4310-b250-bc0d1bf5e834",
            "8afd1b1d-7e34-43ac-8f93-654be568e61c",
            "8c3149bc-5c9e-44bc-a58a-1ce8d92208d5",
            "8ca1fc15-957a-4b80-9988-3c8cae85a4f6",
            "8de6e50f-dde3-40ad-99fa-83fcbce40b76",
            "92bd56e3-08b9-4c30-8539-5a8b8c042933",
            "962a941e-d2b0-4ba7-8698-0257b7ebe695",
            "98b23182-8f51-428a-a4af-a91d280471ca",
            "9a7e4c43-690d-432d-b9a5-b519bf377646",
            "9ad74e9b-de27-4f5a-8108-08043eb6d544",
            "9ae0142d-b12f-42b1-ac48-d655fdec233f",
            "9b602954-f960-46fe-87ae-41f06c486efc",
            "a214c450-50cc-4210-acd9-480a2a7e8eb4",
            "a3d4a2d1-d9dd-4f4d-9d8e-bcc056135d21",
            "a69adad1-7efb-4204-93de-97aaeed2424a",
            "b3321db8-4600-4969-ae23-336c36669dae",
            "b9009e04-394c-4bcb-ab04-adc4365e0fe1",
            "b919b53b-591a-4046-bda3-fe16340939d5",
            "bc288dd8-9104-456a-9edf-f0526b0f8633",
            "c12af7c5-ea9e-41b8-8d0a-eab301f8d270",
            "c69ef004-087e-486c-97c9-9b4587d0b10a",
            "c7ce0fc7-4d38-4355-aa19-ab35527d2519",
            "cb512b89-7b86-4565-92c7-81599f1b1ca2",
            "d1fcfcd1-faa8-4ba3-a0d2-50fb53a9f47f",
            "d3c5fc62-2f5b-4ab2-a321-564ef9232643",
            "d3ec5b39-7147-440d-82b0-4c4d05e671c9",
            "d4e20fdf-beec-410c-a9b4-1ded047b320b",
            "e09ac4da-c7fb-4a9d-9c77-cc41c6f74621",
            "e5e1e41c-774c-4bb4-a087-bcd02fd37b0f",
            "ed4c0d5d-5152-4915-b9bd-d0bd25f82674",
            "f782a72e-eeca-4757-ace9-670012f961a8",
            "f9571f5e-7bf7-427f-a512-b6979338ff31",
            "fada1cc8-d343-45fb-9040-22795f1ca833",
            "fe7f2770-ddca-4716-a7d9-545e68f691fe"
        ],
        "keyword": [
            "recommender",
            "systems",
            "paper",
            "methods",
            "improve",
            "extensions",
            "describes",
            "current",
            "applicable"
        ],
        "group": [
            {
                "0ea745c7-58b2-48e8-9115-42e9b0d20f2a": {
                    "authors": [
                        "Jonathan L. Herlocker",
                        "Joseph A. Konstan",
                        "Loren G. Terveen",
                        "John Riedl"
                    ],
                    "references": [
                        "05f5fba9-e7ca-4c46-be79-df57944a8b41",
                        "126f597c-4efc-49f4-9758-086b767f9fe3",
                        "1406f119-82cd-4cbb-9231-f885212a724e",
                        "2ac8fe14-27ce-4e39-b256-08fd95887484",
                        "30119eca-9d54-4d87-88b0-04cadda25ea0",
                        "312e54ca-e7e9-4129-99f4-36f3aeff827e",
                        "3f8e14d5-4655-4c61-8636-99eb5cc99411",
                        "44e91111-b413-4143-85a9-81872a97fa9d",
                        "454b7a62-ff47-4263-822b-2a1a938b489f",
                        "464c5e0a-2de4-4aa6-a0f6-56cb5ef6740d",
                        "48632bf4-3e9f-4e98-b8f6-c08aaf7f2b58",
                        "48a1dbbd-b496-4b37-b3ba-db144c654d23",
                        "4a2b8b20-c8bc-4e0a-b7db-9dec439951d5",
                        "5ee83a3b-d5f8-4532-97dd-c0579bed0d17",
                        "60c814e2-c4d1-47d7-9a5a-68f4141505ae",
                        "694f475e-f6c4-4105-b645-84c7d592db30",
                        "749790a4-8bdf-4ad8-8ae9-9e9e8f57a898",
                        "78113af6-9abc-46e5-bb78-80049f5770b5",
                        "7d15ffdf-ec35-4498-b794-c186147b39eb",
                        "7f2f7b7d-3e6c-4196-9056-a943b3e96c2f",
                        "812c314c-9742-46fa-b1e8-5c7d640f1322",
                        "822235e6-6abe-442b-b761-b51795df418a",
                        "93fbc138-713f-402a-a554-89f111ddfcd8",
                        "9863baf6-d69f-495a-8d5a-71442adea84e",
                        "98b23182-8f51-428a-a4af-a91d280471ca",
                        "9ae0142d-b12f-42b1-ac48-d655fdec233f",
                        "a04df34d-8c30-4d8a-89fc-781660703e95",
                        "bb237c57-3c58-492f-af1e-3e19a35115a6",
                        "c69ef004-087e-486c-97c9-9b4587d0b10a",
                        "ca25acbc-7ec2-453c-911f-077a06d76ebf",
                        "cff1b7c3-dc60-4ac0-a016-0e4b5070310a",
                        "d1fcfcd1-faa8-4ba3-a0d2-50fb53a9f47f",
                        "d69f9422-3d82-4095-aa7c-b7f3513778ba",
                        "daca38ab-f534-42d6-956c-130a321cd40d",
                        "df338255-a225-4c0e-931d-4a011d141184",
                        "e5e1e41c-774c-4bb4-a087-bcd02fd37b0f",
                        "e9f47fc0-2e5e-4d5f-a7a9-3650e65a1722",
                        "ed4c0d5d-5152-4915-b9bd-d0bd25f82674",
                        "f454a778-621e-4e96-8501-7d72fb0d6103",
                        "f68eb690-34df-4271-acc4-802cb273de83"
                    ],
                    "keyword": [],
                    "group": [],
                    "_id": "0ea745c7-58b2-48e8-9115-42e9b0d20f2a",
                    "abstract": "Recommender systems have been evaluated in many, often incomparable, ways. In this article, we review the key decisions in evaluating collaborative filtering recommender systems: the user tasks being evaluated, the types of analysis and datasets being used, the ways in which prediction quality is measured, the evaluation of prediction attributes other than quality, and the user-based evaluation of the system as a whole. In addition to reviewing the evaluation strategies used by prior researchers, we present empirical results from the analysis of various accuracy metrics on one content domain where all the tested metrics collapsed roughly into three equivalence classes. Metrics within each equivalency class were strongly correlated, while metrics from different equivalency classes were uncorrelated.",
                    "title": "Evaluating collaborative filtering recommender systems",
                    "venue": "ACM Transactions on Information Systems",
                    "year": 2004,
                    "__v": 0,
                    "citationCount": 1987,
                    "result": 2.535211267605634
                },
                "38332469-d318-4976-a49e-9613695cac08": {
                    "authors": [
                        "Gediminas Adomavicius",
                        "Ramesh Sankaranarayanan",
                        "Shahana Sen",
                        "Alexander Tuzhilin"
                    ],
                    "references": [
                        "1406f119-82cd-4cbb-9231-f885212a724e",
                        "15fa2620-5dc8-4d32-97a7-294afe3c61c3",
                        "1b7418af-1aba-4090-bad4-0dd0e900f5aa",
                        "1f6caa35-3d3f-481f-a820-a5d6e6b130d1",
                        "312e54ca-e7e9-4129-99f4-36f3aeff827e",
                        "3730ca24-81f0-456e-a7f3-5c0987e05147",
                        "44e91111-b413-4143-85a9-81872a97fa9d",
                        "47d1e055-7dc7-44ee-8a02-c33aaf7e23a3",
                        "48a1dbbd-b496-4b37-b3ba-db144c654d23",
                        "57bd2d58-8b2c-4783-9bd0-445de23e5e76",
                        "5ee83a3b-d5f8-4532-97dd-c0579bed0d17",
                        "60c814e2-c4d1-47d7-9a5a-68f4141505ae",
                        "67fa583a-da81-4338-8349-e9a7f19f6fe2",
                        "6a6d14f3-83d4-4df4-bd27-94455c216c4f",
                        "6c2fee35-a596-416a-bd8a-a7966324f71e",
                        "6c871065-76b8-44f3-97d5-ac3bce951421",
                        "7b960c31-7b3c-456f-9352-80380e2be085",
                        "812c314c-9742-46fa-b1e8-5c7d640f1322",
                        "8a8e532b-9b51-4ef3-b2ec-69b05191f758",
                        "8afd1b1d-7e34-43ac-8f93-654be568e61c",
                        "8c3149bc-5c9e-44bc-a58a-1ce8d92208d5",
                        "8ca1fc15-957a-4b80-9988-3c8cae85a4f6",
                        "9751ec02-fb0a-4b00-8296-dacb01928335",
                        "98b23182-8f51-428a-a4af-a91d280471ca",
                        "9ae0142d-b12f-42b1-ac48-d655fdec233f",
                        "a214c450-50cc-4210-acd9-480a2a7e8eb4",
                        "bc288dd8-9104-456a-9edf-f0526b0f8633",
                        "bdf2f8ec-db4e-41b9-996e-4299685b33b0",
                        "c69ef004-087e-486c-97c9-9b4587d0b10a",
                        "c7ce0fc7-4d38-4355-aa19-ab35527d2519",
                        "cb512b89-7b86-4565-92c7-81599f1b1ca2",
                        "d3c5fc62-2f5b-4ab2-a321-564ef9232643",
                        "e5e1e41c-774c-4bb4-a087-bcd02fd37b0f",
                        "ed4c0d5d-5152-4915-b9bd-d0bd25f82674",
                        "f1788b85-208f-41aa-a66f-f44220a6a5da",
                        "f782a72e-eeca-4757-ace9-670012f961a8"
                    ],
                    "keyword": [],
                    "group": [],
                    "_id": "38332469-d318-4976-a49e-9613695cac08",
                    "abstract": "The article presents a multidimensional (MD) approach to recommender systems that can provide recommendations based on additional contextual information besides the typical information on users and items used in most of the current recommender systems. This approach supports multiple dimensions, profiling information, and hierarchical aggregation of recommendations. The article also presents a multidimensional rating estimation method capable of selecting two-dimensional segments of ratings pertinent to the recommendation context and applying standard collaborative filtering or other traditional two-dimensional rating estimation techniques to these segments. A comparison of the multidimensional and two-dimensional rating estimation approaches is made, and the tradeoffs between the two are studied. Moreover, the article introduces a combined rating estimation method, which identifies the situations where the MD approach outperforms the standard two-dimensional approach and uses the MD approach in those situations and the standard two-dimensional approach elsewhere. Finally, the article presents a pilot empirical study of the combined approach, using a multidimensional movie recommender system that was developed for implementing this approach and testing its performance.",
                    "title": "Incorporating contextual information in recommender systems using a multidimensional approach",
                    "venue": "ACM Transactions on Information Systems",
                    "year": 2005,
                    "__v": 0,
                    "citationCount": 431,
                    "result": 3.8028169014084505
                },
                "5d134b15-3e3f-402e-a4cd-d5022aef1305": {
                    "authors": [
                        "Yi Zhang",
                        "James P. Callan"
                    ],
                    "references": [
                        "024f3c6f-aff6-4027-835b-b9aef5550af4",
                        "050f3d56-45c0-4c32-86fb-db2fe9b5fb88",
                        "06f1575a-c67e-47bc-a442-0980a147ab0b",
                        "0895c22d-37c5-4c8f-9202-a32ebd2cb0c0",
                        "1f54b4c0-e85f-40bf-a3fe-2fd708c71064",
                        "34fb014b-1029-4565-a7b8-4a4813bb9063",
                        "4bf13cbb-9026-4e4a-90da-64104415c0b3",
                        "4cf5423f-5c84-4012-b9dd-ea6265753326",
                        "52013347-5248-4031-b297-18f028b9af12",
                        "721edbab-399c-4aed-bd0a-4b0a8bdf304e",
                        "9519ccab-8cda-40ff-bd55-b61857c27b56",
                        "d1a51572-839b-4ae1-97c3-ad045ea6425a",
                        "fada1cc8-d343-45fb-9040-22795f1ca833",
                        "fc07a7a7-7c7d-4c5b-90f3-3cd89ff91f70"
                    ],
                    "keyword": [
                        "relevant",
                        "document",
                        "thresholds",
                        "score",
                        "information",
                        "filtering",
                        "distributions",
                        "dissemination",
                        "based",
                        "parameters"
                    ],
                    "group": [],
                    "_id": "5d134b15-3e3f-402e-a4cd-d5022aef1305",
                    "abstract": "Information filtering systems based on statistical retrieval models usually compute a numeric score indicating how well each document matches each profile.  Documents with scores above profile-specific dissemination thresholds are delivered.  An optimal dissemination threshold is one that maximizes a given utility function based on the distributions of the scores of relevant and non-relevant documents.  The parameters of the distribution can be estimated using relevance information, but relevance information obtained while filtering is biased . This paper presents a new method of adjusting dissemination thresholds that explicitly models and compensates for this bias.  The new algorithm, which is based on the Maximum Likelihood principle, jointly estimates the parameters of the density distributions for relevant and non-relevant documents and the ratio of the relevant document in the corpus. Experiments with TREC-8 and TREC-9 Filtering Track data demonstrate the effectiveness of the algorithm.",
                    "title": "Maximum likelihood estimation for filtering thresholds",
                    "venue": "international acm sigir conference on research and development in information retrieval",
                    "year": 2001,
                    "__v": 1,
                    "citationCount": 52,
                    "result": 5.877038400656113
                },
                "5ee83a3b-d5f8-4532-97dd-c0579bed0d17": {
                    "authors": [
                        "Chumki Basu",
                        "Haym Hirsh",
                        "William W. Cohen"
                    ],
                    "references": [
                        "1b7418af-1aba-4090-bad4-0dd0e900f5aa",
                        "2245205b-0f95-4dca-aa7c-e5eb5271536b",
                        "4a48d1c0-8255-49d4-8800-66fa0cf7560d",
                        "60c814e2-c4d1-47d7-9a5a-68f4141505ae",
                        "812c314c-9742-46fa-b1e8-5c7d640f1322",
                        "9ae0142d-b12f-42b1-ac48-d655fdec233f",
                        "d5f75cb3-4d88-4471-af2e-d1d4a3dc14fa",
                        "d8ddd4ae-16ab-4702-b4f5-65aff0e33533"
                    ],
                    "keyword": [
                        "user",
                        "artifacts",
                        "recommendation",
                        "movie",
                        "methods",
                        "ratings",
                        "information",
                        "predict",
                        "collect"
                    ],
                    "group": [],
                    "_id": "5ee83a3b-d5f8-4532-97dd-c0579bed0d17",
                    "abstract": "Recommendation systems make suggestions about artifacts to a user. For instance, they may predict whether a user would be interested in seeing a particular movie. Social recomendation methods collect ratings of artifacts from many individuals, and use nearest-neighbor techniques to make recommendations to a user concerning new artifacts. However, these methods do not use the significant amount of other information that is often available about the nature of each artifact - such as cast lists o r movie reviews, for example. This paper presents an inductive learning approach to recommendation that is able to use both ratings information and other forms of information about each artifact in predicting user preferences. We show that our method outperforms an existing social-filtering method in the domain of movie recommendations on a dataset of more than 45,000 movie ratings collected from a community of over 250 users.",
                    "title": "Recommendation as classification: using social and content-based information in recommendation",
                    "venue": "national conference on artificial intelligence",
                    "year": 1998,
                    "__v": 2,
                    "citationCount": 431,
                    "result": 4.79763595736458
                },
                "67fa583a-da81-4338-8349-e9a7f19f6fe2": {
                    "authors": [
                        "Jonathan L. Herlocker",
                        "Joseph A. Konstan"
                    ],
                    "references": [
                        "1406f119-82cd-4cbb-9231-f885212a724e",
                        "312e54ca-e7e9-4129-99f4-36f3aeff827e",
                        "3f8e14d5-4655-4c61-8636-99eb5cc99411",
                        "41350086-4320-45bb-a93c-be68975bfff5",
                        "44e91111-b413-4143-85a9-81872a97fa9d",
                        "60c814e2-c4d1-47d7-9a5a-68f4141505ae",
                        "694f475e-f6c4-4105-b645-84c7d592db30",
                        "7d15ffdf-ec35-4498-b794-c186147b39eb",
                        "812c314c-9742-46fa-b1e8-5c7d640f1322",
                        "822235e6-6abe-442b-b761-b51795df418a",
                        "c69ef004-087e-486c-97c9-9b4587d0b10a",
                        "d2f431da-276b-4ded-866a-e55cdd68125f",
                        "ed4c0d5d-5152-4915-b9bd-d0bd25f82674"
                    ],
                    "keyword": [
                        "recommender",
                        "user",
                        "approach",
                        "validated",
                        "type",
                        "technique",
                        "taskfocused",
                        "task",
                        "system",
                        "studies"
                    ],
                    "group": [],
                    "_id": "67fa583a-da81-4338-8349-e9a7f19f6fe2",
                    "abstract": "A technique that correlates database items to a task adds content-independent context to a recommender system based solely on user interest ratings. In this article, we present a task-focused approach to recommendation that is entirely independent of the type of content involved. The approach leverages robust, high-performance, commercial software. We have implemented it in a live movie recommendation site and validated it with empirical results from user studies.",
                    "title": "Content-independent task-focused recommendation",
                    "venue": "IEEE Internet Computing",
                    "year": 2001,
                    "__v": 1,
                    "citationCount": 61,
                    "result": 6.702860695218868
                },
                "6a6d14f3-83d4-4df4-bd27-94455c216c4f": {
                    "authors": [
                        "Raymond J. Mooney",
                        "Loriene Roy"
                    ],
                    "references": [
                        "01e036ec-11c7-4251-98cc-13d11b59d0f0",
                        "05f5fba9-e7ca-4c46-be79-df57944a8b41",
                        "1b7418af-1aba-4090-bad4-0dd0e900f5aa",
                        "2245205b-0f95-4dca-aa7c-e5eb5271536b",
                        "25f9dfdb-4cb7-4dd2-9b42-90992fd5d8b8",
                        "32fbde18-d4c1-48e6-93f0-1e6b03d3df0c",
                        "3f394e9d-c50a-4505-9b76-458f5e8be345",
                        "4a48d1c0-8255-49d4-8800-66fa0cf7560d",
                        "514444a0-7178-4d68-9914-fd018d94fa16",
                        "5465d7f9-4818-4f79-a434-73907d7ae423",
                        "5ee83a3b-d5f8-4532-97dd-c0579bed0d17",
                        "62549bc2-e0b3-46e8-8d32-390dded105d5",
                        "6619a06e-4a3d-4b27-8cf7-5fedb33d0c60",
                        "694f475e-f6c4-4105-b645-84c7d592db30",
                        "8fcbc406-5e4c-4e21-8dff-564714afefa3",
                        "9142bfbf-8ab9-411c-887a-22dfe941bef6",
                        "92d0da63-d882-4d22-b5d2-5c41306bda51",
                        "9ae0142d-b12f-42b1-ac48-d655fdec233f",
                        "9f4995af-e704-48ab-8717-6972a3d4455b",
                        "a66c42ad-8392-48dc-8347-24a208f99bda",
                        "b9009e04-394c-4bcb-ab04-adc4365e0fe1",
                        "c69ef004-087e-486c-97c9-9b4587d0b10a",
                        "d5f75cb3-4d88-4471-af2e-d1d4a3dc14fa",
                        "e5e1e41c-774c-4bb4-a087-bcd02fd37b0f",
                        "e95d5929-3b53-4016-8de6-8b60e4e15ce2",
                        "eae52d2c-81f9-4638-ad81-8f33f42ec23e"
                    ],
                    "keyword": [
                        "recommender",
                        "user's",
                        "systems",
                        "information",
                        "suggestions",
                        "previous",
                        "methods",
                        "item",
                        "contentbased",
                        "based"
                    ],
                    "group": [],
                    "_id": "6a6d14f3-83d4-4df4-bd27-94455c216c4f",
                    "abstract": "Recommender systems improve access to relevant products and information by making personalized suggestions based on previous examples of a user's likes and dislikes.  Most existing recommender systems use collaborative filtering methods that base recommendations on other users' preferences. By contrast,content-based methods use information about an item itself to make suggestions.This approach has the advantage of being able to recommend previously unrated items to users with unique interests and to provide explanations for its recommendations. We describe a content-based book recommending system that utilizes information extraction and a machine-learning algorithm for text categorization.  Initial experimental results demonstrate that this approach can produce accurate recommendations.",
                    "title": "Content-based book recommending using learning for text categorization",
                    "venue": "arXiv: Digital Libraries",
                    "year": 2000,
                    "__v": 2,
                    "citationCount": 466,
                    "result": 8.242175609290685
                },
                "6acfaeb4-5d94-4245-9a0a-dd0e8de54c6c": {
                    "authors": [
                        "Thomas Hofmann"
                    ],
                    "references": [
                        "05f5fba9-e7ca-4c46-be79-df57944a8b41",
                        "28903e7b-aa3b-4840-b634-916029ed6c77",
                        "312e54ca-e7e9-4129-99f4-36f3aeff827e",
                        "44e91111-b413-4143-85a9-81872a97fa9d",
                        "57bd2d58-8b2c-4783-9bd0-445de23e5e76",
                        "5ee83a3b-d5f8-4532-97dd-c0579bed0d17",
                        "60c814e2-c4d1-47d7-9a5a-68f4141505ae",
                        "829f9b1f-d04f-49e8-aab7-2c278dff5427",
                        "8fda5d41-ef91-4e72-848f-7da042d1f9aa",
                        "93fbc138-713f-402a-a554-89f111ddfcd8",
                        "c69ef004-087e-486c-97c9-9b4587d0b10a",
                        "d3bb20b9-6528-40a4-8867-29535b3b5806",
                        "ed4c0d5d-5152-4915-b9bd-d0bd25f82674",
                        "f55154df-99c2-4b26-8fd4-3106e74f9016"
                    ],
                    "keyword": [
                        "user",
                        "ratings",
                        "community",
                        "probabilistic",
                        "preferences",
                        "normalized",
                        "models",
                        "interests",
                        "groups",
                        "filtering"
                    ],
                    "group": [],
                    "_id": "6acfaeb4-5d94-4245-9a0a-dd0e8de54c6c",
                    "abstract": "Collaborative filtering aims at learning predictive models of user preferences, interests or behavior from community data, i.e. a database of available user preferences. In this paper, we describe a new model-based algorithm designed for this task, which is based on a generalization of probabilistic latent semantic analysis to continuous-valued response variables. More specifically, we assume that the observed user ratings can be modeled as a mixture of user communities or interest groups, where users may participate probabilistically in one or more groups. Each community is characterized by a Gaussian distribution on the normalized ratings for each item. The normalization of ratings is performed in a user-specific manner to account for variations in absolute shift and variance of ratings. Experiments on the EachMovie data set show that the proposed approach compares favorably with other collaborative filtering techniques.",
                    "title": "Collaborative filtering via gaussian probabilistic latent semantic analysis",
                    "venue": "international acm sigir conference on research and development in information retrieval",
                    "year": 2003,
                    "__v": 1,
                    "citationCount": 166,
                    "result": 6.181106827711065
                },
                "6b700ee7-1b54-4aa7-8cdb-d6a9a08592aa": {
                    "authors": [
                        "Saharon Rosset",
                        "Einat Neumann",
                        "Uri Eick",
                        "Nurit Vatnik",
                        "Yizhak Idan"
                    ],
                    "references": [
                        "230b2bd7-f0f7-43e4-8209-4cd240c56ebf",
                        "3927ca90-eaa7-497c-8b55-8d6fd15a805a",
                        "644665f9-aad6-423a-9c4c-dcd70f2fbedf",
                        "ddd164f3-42dd-4aae-b551-dcc83c7acee3",
                        "f0864e26-24f3-4f4e-8675-636d5da983b9"
                    ],
                    "keyword": [
                        "retention",
                        "problem",
                        "present",
                        "lifetime",
                        "estimating",
                        "effect",
                        "discuss",
                        "customer",
                        "business",
                        "approach"
                    ],
                    "group": [],
                    "_id": "6b700ee7-1b54-4aa7-8cdb-d6a9a08592aa",
                    "abstract": "We present and discuss the important business problem of estimating the effect of retention efforts on the Lifetime Value of a customer in the Telecommunications industry. We discuss the components of this problem, in particular customer value and length of service (or tenure) modeling, and present a novel segment-based approach, motivated by the segment-level view marketing analysts usually employ. We then describe how we build on this approach to estimate the effects of retention on Lifetime Value. Our solution has been successfully implemented in Amdocs' Business Insight (BI) platform, and we illustrate its usefulness in real-world scenarios.",
                    "title": "Customer lifetime value modeling and its use for customer retention planning",
                    "venue": "knowledge discovery and data mining",
                    "year": 2002,
                    "__v": 1,
                    "citationCount": 22,
                    "result": 6.89211801270625
                },
                "7b960c31-7b3c-456f-9352-80380e2be085": {
                    "authors": [
                        "Alper K. Caglayan",
                        "Magnus Snorrason",
                        "Jennifer Jacoby",
                        "James Mazzu",
                        "Robin Jones",
                        "K. Krishna Kumar"
                    ],
                    "references": [
                        "2e37a399-5479-44f4-90c3-16417ffc78e4",
                        "36d1c00d-02b3-49e7-91e6-9d71ee026eaf",
                        "84fb4839-2869-4beb-8527-f4d0abed6eb7",
                        "cc98dd2e-d37b-473c-a81a-e25fa9c58ef6"
                    ],
                    "keyword": [
                        "learning",
                        "agent",
                        "design",
                        "sesame",
                        "open",
                        "feedback",
                        "development",
                        "customer"
                    ],
                    "group": [],
                    "_id": "7b960c31-7b3c-456f-9352-80380e2be085",
                    "abstract": "Open Sesame! 1.0-released in 1993-was the world's first commercial user interface learning agent. The development of this agent involved a number of decisions about basic design issues that had not been previously addressed, including the expected types of agents and the preferred form and frequency of interaction. In the 2 years after shipping Open Sesame! 1.0, we have compiled a rich database of customer feedback. Many of our design choices have been validated by the general approval of our customers, while some were not received as favorably. Thanks to the overwhelming amount of feedback, we were able to substantially improve the design for Open Sesame! 2.0 and develop a cross-platform learning engine-Learn Sesame-that can be used to add learning agent functionality to any third-party application. In this article, we present a summary of the lessons learned from customer feedback, an outline of resulting design changes, the details of the developed learning agent engine, and planned research.",
                    "title": "Learn sesame a learning agent engine",
                    "venue": "Applied Artificial Intelligence",
                    "year": 1997,
                    "__v": 2,
                    "citationCount": 16,
                    "result": 4.715705166866157
                },
                "7f2f7b7d-3e6c-4196-9056-a943b3e96c2f": {
                    "authors": [
                        "Bradley N. Miller",
                        "Istvan Albert",
                        "Shyong K. Lam",
                        "Joseph A. Konstan",
                        "John Riedl"
                    ],
                    "references": [
                        "312e54ca-e7e9-4129-99f4-36f3aeff827e",
                        "3cf667e4-b285-48e6-9816-085ce9c56f8c",
                        "3f8e14d5-4655-4c61-8636-99eb5cc99411",
                        "41350086-4320-45bb-a93c-be68975bfff5",
                        "44e91111-b413-4143-85a9-81872a97fa9d",
                        "60c814e2-c4d1-47d7-9a5a-68f4141505ae",
                        "73e642f0-e13c-424b-82b9-1a9fc43175fe",
                        "9ae0142d-b12f-42b1-ac48-d655fdec233f",
                        "e99d0ff7-cc76-486c-be38-dd406525b579",
                        "ed4c0d5d-5152-4915-b9bd-d0bd25f82674"
                    ],
                    "keyword": [
                        "recommender",
                        "systems",
                        "shop",
                        "people",
                        "movie",
                        "wireless",
                        "users",
                        "stores",
                        "service",
                        "select"
                    ],
                    "group": [],
                    "_id": "7f2f7b7d-3e6c-4196-9056-a943b3e96c2f",
                    "abstract": "Recommender systems have changed the way people shop online. Recommender systems on wireless mobile devices may have the same impact on the way people shop in stores. We present our experience with implementing a recommender system on a PDA that is occasionally connected to the network. This interface helps users of the MovieLens movie recommendation service select movies to rent, buy, or see while away from their computer. The results of a nine month field study show that although there are several challenges to overcome, mobile recommender systems have the potential to provide value to their users today",
                    "title": "MovieLens unplugged: experiences with an occasionally connected recommender system",
                    "venue": "intelligent user interfaces",
                    "year": 2003,
                    "__v": 1,
                    "citationCount": 221,
                    "result": 6.950817247090087
                },
                "822235e6-6abe-442b-b761-b51795df418a": {
                    "authors": [
                        "Jonathan L. Herlocker",
                        "Joseph A. Konstan",
                        "John Riedl"
                    ],
                    "references": [
                        "44e91111-b413-4143-85a9-81872a97fa9d",
                        "60c814e2-c4d1-47d7-9a5a-68f4141505ae",
                        "812c314c-9742-46fa-b1e8-5c7d640f1322",
                        "c69ef004-087e-486c-97c9-9b4587d0b10a",
                        "e4d735f6-1ae7-4b7d-a6d8-be379fa19432",
                        "ed4c0d5d-5152-4915-b9bd-d0bd25f82674"
                    ],
                    "keyword": [
                        "explanations",
                        "systems",
                        "recommender",
                        "providing",
                        "present",
                        "person's",
                        "acf",
                        "user's",
                        "transparency",
                        "recorded"
                    ],
                    "group": [],
                    "_id": "822235e6-6abe-442b-b761-b51795df418a",
                    "abstract": "Automated collaborative filtering (ACF) systems predict a person's affinity for items or information by connecting that person's recorded interests with the recorded interests of a community of people and sharing ratings between like-minded persons. However, current recommender systems are black boxes, providing no transparency into the working of the recommendation. Explanations provide that transparency, exposing the reasoning and data behind a recommendation. In this paper, we address explanation interfaces for ACF systems - how they should be implemented and why they should be implemented. To explore how, we present a model for explanations based on the user's conceptual model of the recommendation process. We then present experimental results demonstrating what components of an  explanation are the most compelling. To address why, we present experimental evidence that shows that providing explanations can improve the acceptance of ACF systems. We also describe some initial explorations into measuring how explanations can improve the filtering performance of users.",
                    "title": "Explaining collaborative filtering recommendations",
                    "venue": "conference on computer supported cooperative work",
                    "year": 2000,
                    "__v": 2,
                    "citationCount": 481,
                    "result": 8.171929010683211
                },
                "8735c7ea-f5c6-4310-b250-bc0d1bf5e834": {
                    "authors": [
                        "David Cohn",
                        "Zoubin Ghahramani",
                        "Michael I. Jordan"
                    ],
                    "references": [
                        "24e0770e-66a5-476e-979e-d8a670be4058",
                        "41cb9a4d-09fa-4163-89d3-5630e792148c",
                        "468f2f4c-76b4-4769-b168-1f4990a165d7",
                        "6ce645b9-765d-4660-9df1-5d6ac65040b5",
                        "7b613c31-1174-4d22-8cf7-1807d85fa9c3",
                        "9340b059-91ef-4c27-8e05-df59a65a610b",
                        "b77c1eb9-deab-4828-8c8e-912740a4e6bf",
                        "b9009e04-394c-4bcb-ab04-adc4365e0fe1",
                        "cf444464-cd42-4545-b3ee-bcf09a1a9503",
                        "d3e00e7e-1c64-4d7a-b2b2-1ad98ba4c706",
                        "da4534a6-897c-4431-89ef-cd326bfaf9a8",
                        "edd4e4ab-3154-437a-a96c-f2fdb709c12d",
                        "f8b2045f-195e-420f-9516-df72eeb7df74"
                    ],
                    "keyword": [
                        "techniques",
                        "select",
                        "optimal",
                        "data",
                        "weighted",
                        "training",
                        "regression",
                        "neural",
                        "networks",
                        "mixtures"
                    ],
                    "group": [],
                    "_id": "8735c7ea-f5c6-4310-b250-bc0d1bf5e834",
                    "abstract": "For many types of machine learning algorithms, one can compute the statistically \"optimal\" way to select training data. In this paper, we review how optimal data selection techniques have been used with feedforward neural networks. We then show how the same principles may be used to select data for two alternative, statistically-based learning architectures: mixtures of Gaussians and locally weighted regression. While the techniques for neural networks are computationally expensive and approximate, the techniques for mixtures of Gaussians and locally weighted regression are both efficient and accurate. Empirically, we observe that the optimality criterion sharply decreases the number of training examples the learner needs in order to achieve good performance.",
                    "title": "Active learning with statistical models",
                    "venue": "Journal of Artificial Intelligence Research",
                    "year": 1996,
                    "__v": 1,
                    "citationCount": 672,
                    "result": 3.0388169471869815
                },
                "8ca1fc15-957a-4b80-9988-3c8cae85a4f6": {
                    "authors": [
                        "Michael J. Pazzani"
                    ],
                    "references": [
                        "290e0375-d2ad-4bec-a94f-f05e1580125b",
                        "2fb1b055-2eb3-4016-92e5-41e882d8bf57",
                        "328e6d1a-73c4-48da-ac29-d671a581cf86",
                        "60c814e2-c4d1-47d7-9a5a-68f4141505ae",
                        "99586b3c-4b95-41a3-adb9-0853ffd9727d",
                        "9ae0142d-b12f-42b1-ac48-d655fdec233f",
                        "ac14afe6-de4d-4056-b2ac-0f6e36f369a2",
                        "b49c1e2b-0cd0-4950-a724-00c698e5b49d",
                        "bb74ee29-c9bd-4ed8-978c-295045e24594",
                        "c69ef004-087e-486c-97c9-9b4587d0b10a",
                        "cd17473b-9aec-4099-bf27-b116490b43ea",
                        "dddfbe50-c5c7-4fe7-8f92-02e8f10db47f",
                        "e5e1e41c-774c-4bb4-a087-bcd02fd37b0f",
                        "e9a10bb1-bcd7-48c4-af6b-df754852d14c",
                        "ec4af381-2284-441e-8ca2-1a9e27d2cccd"
                    ],
                    "keyword": [
                        "pages",
                        "user",
                        "information",
                        "recommending",
                        "ratings",
                        "approach",
                        "types",
                        "sources",
                        "discuss",
                        "describe"
                    ],
                    "group": [],
                    "_id": "8ca1fc15-957a-4b80-9988-3c8cae85a4f6",
                    "abstract": "We discuss learning a profile of user interests for recommending information sources such as Web pages or news articles. We describe the types of information available to determine whether to recommend a particular page to a particular user. This information includes the content of the page, the ratings of the user on other pages and the contents of these pages, the ratings given to that page by other users and the ratings of these other users on other pages and demographic information about users. We describe how each type of information may be used individually and then discuss an approach to combining recommendations from multiple sources. We illustrate each approach and the combined approach in the context of recommending restaurants.",
                    "title": "A Framework for Collaborative, Content-Based and Demographic Filtering",
                    "venue": "Artificial Intelligence Review",
                    "year": 1999,
                    "__v": 2,
                    "citationCount": 493,
                    "result": 5.812029879886244
                },
                "8de6e50f-dde3-40ad-99fa-83fcbce40b76": {
                    "authors": [
                        "Guy Shani",
                        "David Heckerman",
                        "Ronen I. Brafman"
                    ],
                    "references": [
                        "03a1edee-e68f-441d-ac9f-fdadcfa300c1",
                        "07ccd481-b4ec-47eb-9634-92e64ba18a08",
                        "148b71b5-e230-45c4-ad11-9e6df508343f",
                        "288106a6-f48d-44c2-98fb-bd4c257d6ff5",
                        "2e005016-6a16-436b-9db4-f7c6da10089e",
                        "312e54ca-e7e9-4129-99f4-36f3aeff827e",
                        "3f8e14d5-4655-4c61-8636-99eb5cc99411",
                        "41350086-4320-45bb-a93c-be68975bfff5",
                        "41de0c82-c218-4c6c-a326-df6ca6173f8b",
                        "41e7c40d-5250-47e3-bb57-720bc30cbdca",
                        "5a92ee72-2713-4004-8644-2ec6d9061a77",
                        "694f475e-f6c4-4105-b645-84c7d592db30",
                        "6a6d14f3-83d4-4df4-bd27-94455c216c4f",
                        "84091ff6-5edd-4dd3-9201-1e391b0d9cc7",
                        "93fbc138-713f-402a-a554-89f111ddfcd8",
                        "adced26f-f053-4073-b712-cedf066de916",
                        "b3321db8-4600-4969-ae23-336c36669dae",
                        "c69ef004-087e-486c-97c9-9b4587d0b10a",
                        "d02f1291-ed4a-48fc-8c69-c72850dae7b4",
                        "d4b91c05-0fa3-4aef-b0c1-b4f696544ee2",
                        "d77bb2de-8e9e-4f30-82a5-9604016070fb",
                        "e0f3a738-4ab2-40d1-ba44-506d81c1d230",
                        "e1f53f93-f8fc-45e9-9e7f-b2d68554cabb"
                    ],
                    "keyword": [
                        "recommender",
                        "systems",
                        "model",
                        "commercial",
                        "problem",
                        "prediction",
                        "view",
                        "site",
                        "process",
                        "mdps"
                    ],
                    "group": [],
                    "_id": "8de6e50f-dde3-40ad-99fa-83fcbce40b76",
                    "abstract": "Typical recommender systems adopt a static view of the recommendation process and treat it as a prediction problem. We argue that it is more appropriate to view the problem of generating recommendations as a sequential optimization problem and, consequently, that Markov decision processes (MDPs) provide a more appropriate model for recommender systems. MDPs introduce two benefits: they take into account the long-term effects of each recommendation and the expected value of each recommendation. To succeed in practice, an MDP-based recommender system must employ a strong initial model, must be solvable quickly, and should not consume too much memory. In this paper, we describe our particular MDP model, its initialization using a predictive model, the solution and update algorithm, and its actual performance on a commercial site. We also describe the particular predictive model we used which outperforms previous models. Our system is one of a small number of commercially deployed recommender systems. As far as we know, it is the first to report experimental analysis conducted on a real commercial site. These results validate the commercial value of recommender systems, and in particular, of our MDP-based approach.",
                    "title": "An MDP-Based Recommender System",
                    "venue": "Journal of Machine Learning Research",
                    "year": 2005,
                    "__v": 2,
                    "citationCount": 136,
                    "result": 7.3984850397934165
                },
                "92bd56e3-08b9-4c30-8539-5a8b8c042933": {
                    "authors": [
                        "Kai Yu",
                        "Anton Schwaighofer",
                        "Volker Tresp",
                        "Xiaowei Xu",
                        "Hans-Peter Kriegel"
                    ],
                    "references": [
                        "01ceeabc-308b-4b98-9424-eb36293d799d",
                        "30119eca-9d54-4d87-88b0-04cadda25ea0",
                        "312e54ca-e7e9-4129-99f4-36f3aeff827e",
                        "3f8e14d5-4655-4c61-8636-99eb5cc99411",
                        "48632bf4-3e9f-4e98-b8f6-c08aaf7f2b58",
                        "48a1dbbd-b496-4b37-b3ba-db144c654d23",
                        "5ee83a3b-d5f8-4532-97dd-c0579bed0d17",
                        "60c814e2-c4d1-47d7-9a5a-68f4141505ae",
                        "694f475e-f6c4-4105-b645-84c7d592db30",
                        "6a6d14f3-83d4-4df4-bd27-94455c216c4f",
                        "7b1f7bf8-a1dc-4f2c-8983-86b836ebc17c",
                        "812c314c-9742-46fa-b1e8-5c7d640f1322",
                        "822235e6-6abe-442b-b761-b51795df418a",
                        "8fda5d41-ef91-4e72-848f-7da042d1f9aa",
                        "93fbc138-713f-402a-a554-89f111ddfcd8",
                        "98b23182-8f51-428a-a4af-a91d280471ca",
                        "9ae0142d-b12f-42b1-ac48-d655fdec233f",
                        "bb471afa-e600-483d-92a5-7a36c9135155",
                        "c69ef004-087e-486c-97c9-9b4587d0b10a",
                        "e5e1e41c-774c-4bb4-a087-bcd02fd37b0f",
                        "ed4c0d5d-5152-4915-b9bd-d0bd25f82674"
                    ],
                    "keyword": [
                        "user",
                        "memorybased",
                        "framework",
                        "cf",
                        "probabilistic",
                        "systems",
                        "recommender",
                        "problems",
                        "pmcf",
                        "active"
                    ],
                    "group": [],
                    "_id": "92bd56e3-08b9-4c30-8539-5a8b8c042933",
                    "abstract": "Memory-based collaborative filtering (CF) has been studied extensively in the literature and has proven to be successful in various types of personalized recommender systems. In this paper, we develop a probabilistic framework for memory-based CF (PMCF). While this framework has clear links with classical memory-based CF, it allows us to find principled solutions to known problems of CF-based recommender systems. In particular, we show that a probabilistic active learning method can be used to actively query the user, thereby solving the \"new user problem.\" Furthermore, the probabilistic framework allows us to reduce the computational cost of memory-based CF by working on a carefully selected subset of user profiles, while retaining high accuracy. We report experimental results based on two real-world data sets, which demonstrate that our proposed PMCF framework allows an accurate and efficient prediction of user preferences.",
                    "title": "Probabilistic memory-based collaborative filtering",
                    "venue": "IEEE Transactions on Knowledge and Data Engineering",
                    "year": 2004,
                    "__v": 2,
                    "citationCount": 92,
                    "result": 7.5491748408909265
                },
                "962a941e-d2b0-4ba7-8698-0257b7ebe695": {
                    "authors": [
                        "Stuart E. Middleton",
                        "Nigel Shadbolt",
                        "David De Roure"
                    ],
                    "references": [
                        "0895c22d-37c5-4c8f-9202-a32ebd2cb0c0",
                        "1700b9f8-b8f4-4b6d-85a3-15f9225cc9c7",
                        "1b7418af-1aba-4090-bad4-0dd0e900f5aa",
                        "282525d0-6520-489f-aed2-db0f4aa17277",
                        "3236e2cd-79d5-4a52-aaf8-87a5432ecd7a",
                        "3704f939-09a2-4e9f-b851-1261bcd310df",
                        "3cf667e4-b285-48e6-9816-085ce9c56f8c",
                        "44e91111-b413-4143-85a9-81872a97fa9d",
                        "48632bf4-3e9f-4e98-b8f6-c08aaf7f2b58",
                        "4adb467d-dacf-4019-b0d5-28ce1f323cf4",
                        "4aee70a1-6e49-4427-a6ee-150f1ec4e151",
                        "6119b461-7a82-44c1-9e2f-63c3f725b8af",
                        "9ae0142d-b12f-42b1-ac48-d655fdec233f",
                        "ac237969-3fd5-4303-83b7-a67e02afe976",
                        "c0af1514-af65-4d85-af68-de3409fc6532",
                        "cb512b89-7b86-4565-92c7-81599f1b1ca2",
                        "d1fcfcd1-faa8-4ba3-a0d2-50fb53a9f47f",
                        "dfb8a5e6-8046-4dcf-b6f3-be079bd26a8b",
                        "ee746464-b6d4-47c6-afbb-8b8e0faa0bcd",
                        "f0e17923-e4a0-48d1-967c-97313383df1b",
                        "f5a0ca62-6167-4647-b5a8-43c7e20210bc",
                        "fe440a55-22a7-4627-b12c-d14b2b637160"
                    ],
                    "keyword": [
                        "profiling",
                        "recommender",
                        "ontological",
                        "systems",
                        "papers",
                        "user",
                        "research",
                        "approach",
                        "visualization",
                        "topic"
                    ],
                    "group": [],
                    "_id": "962a941e-d2b0-4ba7-8698-0257b7ebe695",
                    "abstract": "We explore a novel ontological approach to user profiling within recommender systems, working on the problem of recommending on-line academic research papers. Our two experimental systems, Quickstep and Foxtrot, create user profiles from unobtrusively monitored behaviour and relevance feedback, representing the profiles in terms of a research paper topic ontology. A novel profile visualization approach is taken to acquire profile feedback. Research papers are classified using ontological classes and collaborative recommendation algorithms used to recommend papers seen by similar people on their current topics of interest. Two small-scale experiments, with 24 subjects over 3 months, and a large-scale experiment, with 260 subjects over an academic year, are conducted to evaluate different aspects of our approach. Ontological inference is shown to improve user profiling, external ontological knowledge used to successfully bootstrap a recommender system and profile visualization employed to improve profiling accuracy. The overall performance of our ontological recommender systems are also presented and favourably compared to other systems in the literature.",
                    "title": "Ontological user profiling in recommender systems",
                    "venue": "ACM Transactions on Information Systems",
                    "year": 2004,
                    "__v": 1,
                    "citationCount": 290,
                    "result": 7.886168336089846
                },
                "9b602954-f960-46fe-87ae-41f06c486efc": {
                    "authors": [
                        "Mukund Deshpande",
                        "George Karypis"
                    ],
                    "references": [
                        "05f5fba9-e7ca-4c46-be79-df57944a8b41",
                        "11c3cd75-00cf-45ef-9efc-ad503b531e48",
                        "1406f119-82cd-4cbb-9231-f885212a724e",
                        "312e54ca-e7e9-4129-99f4-36f3aeff827e",
                        "33d6dabd-c086-4a6e-939a-c322b6ada724",
                        "34b7e270-80d7-46d5-a6f1-e50087a8d045",
                        "3f8e14d5-4655-4c61-8636-99eb5cc99411",
                        "41350086-4320-45bb-a93c-be68975bfff5",
                        "41e7c40d-5250-47e3-bb57-720bc30cbdca",
                        "44e91111-b413-4143-85a9-81872a97fa9d",
                        "5ee83a3b-d5f8-4532-97dd-c0579bed0d17",
                        "60c814e2-c4d1-47d7-9a5a-68f4141505ae",
                        "694f475e-f6c4-4105-b645-84c7d592db30",
                        "6e425bce-a497-4c63-9eb0-b038e660a54f",
                        "812c314c-9742-46fa-b1e8-5c7d640f1322",
                        "929abc46-4b62-459b-a972-caa1d09e0fcc",
                        "93fbc138-713f-402a-a554-89f111ddfcd8",
                        "98b23182-8f51-428a-a4af-a91d280471ca",
                        "9ae0142d-b12f-42b1-ac48-d655fdec233f",
                        "c4710c73-497d-44f0-ae10-64613eca18d4",
                        "c69ef004-087e-486c-97c9-9b4587d0b10a",
                        "c7ce0fc7-4d38-4355-aa19-ab35527d2519",
                        "cbc55d1f-5b03-4102-a37d-2608e100ff47",
                        "e3a14094-d98f-425a-a764-ca44f297489c",
                        "e5e1e41c-774c-4bb4-a087-bcd02fd37b0f",
                        "ecd6a845-8439-49b0-abe8-f71fff81da23",
                        "ed4c0d5d-5152-4915-b9bd-d0bd25f82674"
                    ],
                    "keyword": [
                        "recommender",
                        "items",
                        "systems",
                        "similarities",
                        "computational",
                        "methods",
                        "algorithms"
                    ],
                    "group": [],
                    "_id": "9b602954-f960-46fe-87ae-41f06c486efc",
                    "abstract": "The explosive growth of the world-wide-web and the emergence of e-commerce has led to the development of  recommender systems ---a personalized information filtering technology used to identify a set of items that will be of interest to a certain user. User-based collaborative filtering is the most successful technology for building recommender systems to date and is extensively used in many commercial recommender systems. Unfortunately, the computational complexity of these methods grows linearly with the number of customers, which in typical commercial applications can be several millions. To address these scalability concerns model-based recommendation techniques have been developed. These techniques analyze the user--item matrix to discover relations between the different items and use these relations to compute the list of recommendations.In this article, we present one such class of model-based recommendation algorithms that first determines the similarities between the various items and then uses them to identify the set of items to be recommended. The key steps in this class of algorithms are (i) the method used to compute the similarity between the items, and (ii) the method used to combine these similarities in order to compute the similarity between a  basket  of items and a candidate recommender item. Our experimental evaluation on eight real datasets shows that these  item-based  algorithms are up to two orders of magnitude faster than the traditional user-neighborhood based recommender systems and provide recommendations with comparable or better quality.",
                    "title": "Item-based top- N recommendation algorithms",
                    "venue": "ACM Transactions on Information Systems",
                    "year": 2004,
                    "__v": 2,
                    "citationCount": 723,
                    "result": 8.014134468466652
                },
                "a69adad1-7efb-4204-93de-97aaeed2424a": {
                    "authors": [
                        "Thomas Hofmann"
                    ],
                    "references": [
                        "05f5fba9-e7ca-4c46-be79-df57944a8b41",
                        "28903e7b-aa3b-4840-b634-916029ed6c77",
                        "290e0375-d2ad-4bec-a94f-f05e1580125b",
                        "44e91111-b413-4143-85a9-81872a97fa9d",
                        "48a1dbbd-b496-4b37-b3ba-db144c654d23",
                        "57bd2d58-8b2c-4783-9bd0-445de23e5e76",
                        "5ee83a3b-d5f8-4532-97dd-c0579bed0d17",
                        "60c814e2-c4d1-47d7-9a5a-68f4141505ae",
                        "69df0789-a06f-4166-9c34-93047de2673d",
                        "829f9b1f-d04f-49e8-aab7-2c278dff5427",
                        "8dd4158a-bbc4-40cf-a4d5-14e0fe630387",
                        "8fda5d41-ef91-4e72-848f-7da042d1f9aa",
                        "93fbc138-713f-402a-a554-89f111ddfcd8",
                        "98b23182-8f51-428a-a4af-a91d280471ca",
                        "ac14afe6-de4d-4056-b2ac-0f6e36f369a2",
                        "c69ef004-087e-486c-97c9-9b4587d0b10a",
                        "d3bb20b9-6528-40a4-8867-29535b3b5806",
                        "ed4c0d5d-5152-4915-b9bd-d0bd25f82674",
                        "f55154df-99c2-4b26-8fd4-3106e74f9016"
                    ],
                    "keyword": [
                        "user",
                        "models",
                        "variables",
                        "technique",
                        "preferences",
                        "predictive",
                        "methods",
                        "interests",
                        "community",
                        "algorithms"
                    ],
                    "group": [],
                    "_id": "a69adad1-7efb-4204-93de-97aaeed2424a",
                    "abstract": "Collaborative filtering aims at learning predictive models of user preferences, interests or behavior from community data, that is, a database of available user preferences. In this article, we describe a new family of model-based algorithms designed for this task. These algorithms rely on a statistical modelling technique that introduces latent class variables in a mixture model setting to discover user communities and prototypical interest profiles. We investigate several variations to deal with discrete and continuous response variables as well as with different objective functions. The main advantages of this technique over standard memory-based methods are higher accuracy, constant time prediction, and an explicit and compact model representation. The latter can also be used to mine for user communitites. The experimental evaluation shows that substantial improvements in accucracy over existing methods and published results can be obtained.",
                    "title": "Latent semantic models for collaborative filtering",
                    "venue": "ACM Transactions on Information Systems",
                    "year": 2004,
                    "__v": 1,
                    "citationCount": 601,
                    "result": 7.987782560879188
                },
                "b9009e04-394c-4bcb-ab04-adc4365e0fe1": {
                    "authors": [
                        "David Cohn",
                        "Les E. Atlas",
                        "Richard E. Ladner"
                    ],
                    "references": [
                        "1b341afb-5b02-487e-90d0-05d53ab473f5",
                        "1ded326a-8835-4fad-892d-3c9a61b4a04f",
                        "25891440-431f-4e1c-9e82-27e41a1498c2",
                        "312febf5-4f84-4af6-9a3e-0f4516cf6946",
                        "3fff50e3-6a11-415b-8c8d-6f2c651f658d",
                        "41cb9a4d-09fa-4163-89d3-5630e792148c",
                        "5899eb6c-2e22-4d79-a2be-15fe67911177",
                        "617ef83b-22c1-4c25-ada8-a5854d8a61d8",
                        "6f0ca85c-0b7f-4e29-8e36-4a9ec51d82d6",
                        "9601c322-4fbc-4af2-ab8d-5f9fab957b88",
                        "c61bad33-aa9f-4a6e-ab8b-8e7eaa835492",
                        "d50e6e96-3419-43fe-92fd-862b2b3cea7a",
                        "e1d4d2dc-35dc-46d9-9773-a3964a3d831c",
                        "ea294286-3cc2-4979-a22b-2fbb78c2ef18",
                        "ea98bd3b-fe01-4584-b5bc-4b7eacf78d47"
                    ],
                    "keyword": [
                        "learning",
                        "examples",
                        "domain",
                        "active",
                        "selective",
                        "sampling",
                        "receives",
                        "part",
                        "information",
                        "implemented"
                    ],
                    "group": [],
                    "_id": "b9009e04-394c-4bcb-ab04-adc4365e0fe1",
                    "abstract": "Active learning differs from “learning from examples” in that the learning algorithm assumes at least some control over what part of the input domain it receives information about. In some situations, active learning is provably more powerful than learning from examples alone, giving better generalization for a fixed number of training examples.#R##N##R##N#In this article, we consider the problem of learning a binary concept in the absence of noise. We describe a formalism for active concept learning called selective sampling and show how it may be approximately implemented by a neural network. In selective sampling, a learner receives distribution information from the environment and queries an oracle on parts of the domain it considers “useful.” We test our implementation, called an SG-network, on three domains and observe significant improvement in generalization.",
                    "title": "Improving Generalization with Active Learning",
                    "venue": "Machine Learning",
                    "year": 1994,
                    "__v": 2,
                    "citationCount": 534,
                    "result": 4.546405460724346
                },
                "b919b53b-591a-4046-bda3-fe16340939d5": {
                    "authors": [
                        "Benjamin M. Marlin"
                    ],
                    "references": [
                        "114b51fc-d122-48ce-a6ce-80c62a282ae9",
                        "48a1dbbd-b496-4b37-b3ba-db144c654d23",
                        "8db65cd7-266f-4700-95a4-f91f947403c6",
                        "c19e94a6-b1dc-4f54-8dd2-1935aa7e7cf9",
                        "c69ef004-087e-486c-97c9-9b4587d0b10a",
                        "d3bb20b9-6528-40a4-8867-29535b3b5806"
                    ],
                    "keyword": [
                        "user",
                        "model",
                        "rating",
                        "urp",
                        "item",
                        "generative",
                        "attitudes",
                        "variable",
                        "selecting",
                        "profile"
                    ],
                    "group": [],
                    "_id": "b919b53b-591a-4046-bda3-fe16340939d5",
                    "abstract": "In this paper we present a generative latent variable model for rating-based collaborative filtering called the User Rating Profile model (URP). The generative process which underlies URP is designed to produce complete user rating profiles, an assignment of one rating to each item for each user. Our model represents each user as a mixture of user attitudes, and the mixing proportions are distributed according to a Dirichlet random variable. The rating for each item is generated by selecting a user attitude for the item, and then selecting a rating according to the preference pattern associated with that attitude. URP is related to several models including a multinomial mixture model, the aspect model [7], and LDA [1], but has clear advantages over each.",
                    "title": "Modeling User Rating Profiles For Collaborative Filtering",
                    "venue": "neural information processing systems",
                    "year": 2004,
                    "__v": 2,
                    "citationCount": 119,
                    "result": 4.398905029499587
                },
                "c69ef004-087e-486c-97c9-9b4587d0b10a": {
                    "authors": [
                        "Paul Resnick",
                        "Neophytos Iacovou",
                        "Mitesh Suchak",
                        "Peter Bergstrom",
                        "John Riedl"
                    ],
                    "references": [
                        "05f5fba9-e7ca-4c46-be79-df57944a8b41",
                        "1ce7a9a3-91c4-45d6-984a-e1d240fd81aa",
                        "23f66d97-4abf-479f-8af5-ec833d850a24",
                        "2e37a399-5479-44f4-90c3-16417ffc78e4",
                        "8fd9aa19-5b11-48a2-a8dc-4cc75c36d8eb",
                        "982a382c-bd5e-40fc-89ed-0734e2fae945",
                        "9b356229-f03a-467a-b9ce-6f586e33d61d",
                        "ac14afe6-de4d-4056-b2ac-0f6e36f369a2",
                        "b3593e4a-622e-49eb-b375-6ce650003a05",
                        "eae52d2c-81f9-4638-ad81-8f33f42ec23e"
                    ],
                    "keyword": [
                        "rate",
                        "people",
                        "scores",
                        "predicted",
                        "articles",
                        "users",
                        "servers",
                        "news",
                        "filters",
                        "developed"
                    ],
                    "group": [],
                    "_id": "c69ef004-087e-486c-97c9-9b4587d0b10a",
                    "abstract": "Collaborative filters help people make choices based on the opinions of other people. GroupLens is a system for collaborative filtering of netnews, to help people find articles they will like in the huge stream of available articles. News reader clients display predicted scores and make it easy for users to rate articles after they read them. Rating servers, called Better Bit Bureaus, gather and disseminate the ratings. The rating servers predict scores based on the heuristic that people who agreed in the past will probably agree again. Users can protect their privacy by entering ratings under pseudonyms, without reducing the effectiveness of the score prediction. The entire architecture is open: alternative software for news clients and Better Bit Bureaus can be developed  independently and can interoperate with the components we have developed.",
                    "title": "GroupLens: an open architecture for collaborative filtering of netnews",
                    "venue": "conference on computer supported cooperative work",
                    "year": 1994,
                    "__v": 2,
                    "citationCount": 2083,
                    "result": 5.148161414669285
                },
                "d1fcfcd1-faa8-4ba3-a0d2-50fb53a9f47f": {
                    "authors": [
                        "Andrew I. Schein",
                        "Alexandrin Popescul",
                        "Lyle H. Ungar",
                        "David M. Pennock"
                    ],
                    "references": [
                        "05234ed3-29a1-4a96-970c-44ebdf1a2fe6",
                        "28903e7b-aa3b-4840-b634-916029ed6c77",
                        "290e0375-d2ad-4bec-a94f-f05e1580125b",
                        "30119eca-9d54-4d87-88b0-04cadda25ea0",
                        "312e54ca-e7e9-4129-99f4-36f3aeff827e",
                        "3f8e14d5-4655-4c61-8636-99eb5cc99411",
                        "44e91111-b413-4143-85a9-81872a97fa9d",
                        "5ee83a3b-d5f8-4532-97dd-c0579bed0d17",
                        "60c814e2-c4d1-47d7-9a5a-68f4141505ae",
                        "694f475e-f6c4-4105-b645-84c7d592db30",
                        "6a6d14f3-83d4-4df4-bd27-94455c216c4f",
                        "812c314c-9742-46fa-b1e8-5c7d640f1322",
                        "8c3149bc-5c9e-44bc-a58a-1ce8d92208d5",
                        "8fb19592-ccce-4deb-a158-45dd7bba6d5a",
                        "8fda5d41-ef91-4e72-848f-7da042d1f9aa",
                        "98b23182-8f51-428a-a4af-a91d280471ca",
                        "b99db203-5c26-4182-bdc1-df188456f9f9",
                        "c69ef004-087e-486c-97c9-9b4587d0b10a",
                        "e5e1e41c-774c-4bb4-a087-bcd02fd37b0f",
                        "e75d8e62-a86d-4241-953f-1b315005d920",
                        "ed4c0d5d-5152-4915-b9bd-d0bd25f82674"
                    ],
                    "keyword": [
                        "recommending",
                        "testing",
                        "performance",
                        "method",
                        "items",
                        "data",
                        "combines",
                        "coldstart",
                        "benchmark"
                    ],
                    "group": [],
                    "_id": "d1fcfcd1-faa8-4ba3-a0d2-50fb53a9f47f",
                    "abstract": "We have developed a method for recommending items that combines content and collaborative data under a single probabilistic framework. We benchmark our algorithm against a naive Bayes classifier on the   cold-start  problem, where we wish to recommend items that no one in the community has yet rated. We systematically explore three testing methodologies using a publicly available data set, and explain how these methods apply to specific real-world applications. We advocate heuristic recommenders when benchmarking to give competent baseline performance. We introduce a new performance metric, the CROC curve, and demonstrate empirically that the various components of our testing strategy combine to obtain deeper understanding of the performance characteristics of recommender systems. Though the emphasis of our testing is on  cold-start  recommending, our methods for recommending and evaluation are general.",
                    "title": "Methods and metrics for cold-start recommendations",
                    "venue": "international acm sigir conference on research and development in information retrieval",
                    "year": 2002,
                    "__v": 2,
                    "citationCount": 538,
                    "result": 7.240253576396908
                },
                "d3ec5b39-7147-440d-82b0-4c4d05e671c9": {
                    "authors": [
                        "Greg Linden",
                        "Brent Smith",
                        "Jeremy C. York"
                    ],
                    "references": [
                        "312e54ca-e7e9-4129-99f4-36f3aeff827e",
                        "3f8e14d5-4655-4c61-8636-99eb5cc99411",
                        "48a1dbbd-b496-4b37-b3ba-db144c654d23",
                        "98b23182-8f51-428a-a4af-a91d280471ca",
                        "9ae0142d-b12f-42b1-ac48-d655fdec233f",
                        "a8ac113b-d9d1-4083-accd-85a17751a944",
                        "b3321db8-4600-4969-ae23-336c36669dae",
                        "c69ef004-087e-486c-97c9-9b4587d0b10a"
                    ],
                    "keyword": [
                        "recommendation",
                        "customer's",
                        "algorithms",
                        "items",
                        "interests",
                        "filtering",
                        "collaborative",
                        "traditional",
                        "store",
                        "scales"
                    ],
                    "group": [],
                    "_id": "d3ec5b39-7147-440d-82b0-4c4d05e671c9",
                    "abstract": "Recommendation algorithms are best known for their use on e-commerce Web sites, where they use input about a customer's interests to generate a list of recommended items. Many applications use only the items that customers purchase and explicitly rate to represent their interests, but they can also use other attributes, including items viewed, demographic data, subject interests, and favorite artists. At Amazon.com, we use recommendation algorithms to personalize the online store for each customer. The store radically changes based on customer interests, showing programming titles to a software engineer and baby toys to a new mother. There are three common approaches to solving the recommendation problem: traditional collaborative filtering, cluster models, and search-based methods. Here, we compare these methods with our algorithm, which we call item-to-item collaborative filtering. Unlike traditional collaborative filtering, our algorithm's online computation scales independently of the number of customers and number of items in the product catalog. Our algorithm produces recommendations in real-time, scales to massive data sets, and generates high quality recommendations.",
                    "title": "Amazon.com recommendations: item-to-item collaborative filtering",
                    "venue": "IEEE Internet Computing",
                    "year": 2003,
                    "__v": 2,
                    "citationCount": 1446,
                    "result": 7.647329697637397
                },
                "f782a72e-eeca-4757-ace9-670012f961a8": {
                    "authors": [
                        "Zan Huang",
                        "Hsinchun Chen",
                        "Daniel Dajun Zeng"
                    ],
                    "references": [
                        "04427dfc-6714-4008-98f3-b5507018ead0",
                        "1406f119-82cd-4cbb-9231-f885212a724e",
                        "1d33c6e4-1baf-4ef3-8068-b626a6ad5a49",
                        "28617842-e696-4a7c-8a9c-e4dcf09f3759",
                        "2c2dbdbf-d6db-4019-94a4-4084337eb6e0",
                        "312e54ca-e7e9-4129-99f4-36f3aeff827e",
                        "3f8e14d5-4655-4c61-8636-99eb5cc99411",
                        "41350086-4320-45bb-a93c-be68975bfff5",
                        "44e91111-b413-4143-85a9-81872a97fa9d",
                        "48a1dbbd-b496-4b37-b3ba-db144c654d23",
                        "5aa0fb6f-0b06-48df-8cf2-ee180c85c738",
                        "5ee83a3b-d5f8-4532-97dd-c0579bed0d17",
                        "60c814e2-c4d1-47d7-9a5a-68f4141505ae",
                        "60ef3852-fa16-44bf-9434-9909268ba5d8",
                        "694f475e-f6c4-4105-b645-84c7d592db30",
                        "6e425bce-a497-4c63-9eb0-b038e660a54f",
                        "7c4dfd37-fa37-4a43-a3e1-898b98e0b48d",
                        "7d15ffdf-ec35-4498-b794-c186147b39eb",
                        "812c314c-9742-46fa-b1e8-5c7d640f1322",
                        "8aa326d5-2a3d-4c30-8d56-06bb275f079c",
                        "8ca1fc15-957a-4b80-9988-3c8cae85a4f6",
                        "8f6cafa9-28c3-424e-87bd-c28c8e57a44f",
                        "98b23182-8f51-428a-a4af-a91d280471ca",
                        "9ae0142d-b12f-42b1-ac48-d655fdec233f",
                        "abe38dcd-53ce-48b3-8e3d-4702ddd4e4c0",
                        "b3321db8-4600-4969-ae23-336c36669dae",
                        "bb471afa-e600-483d-92a5-7a36c9135155",
                        "bed2c8c8-1dc3-4631-b8e2-746ba766a9ae",
                        "c69ef004-087e-486c-97c9-9b4587d0b10a",
                        "c7ce0fc7-4d38-4355-aa19-ab35527d2519",
                        "d16cb7ae-ae7c-4b37-8667-93a57b025d5a",
                        "d1fcfcd1-faa8-4ba3-a0d2-50fb53a9f47f",
                        "dacf855f-a7d2-42bf-89a7-fabe9b003150",
                        "e5e1e41c-774c-4bb4-a087-bcd02fd37b0f"
                    ],
                    "keyword": [
                        "approach",
                        "algorithms",
                        "recommender",
                        "consumers",
                        "associative",
                        "transitive",
                        "transactions",
                        "spreading",
                        "problem",
                        "filtering"
                    ],
                    "group": [],
                    "_id": "f782a72e-eeca-4757-ace9-670012f961a8",
                    "abstract": "Recommender systems are being widely applied in many application settings to suggest products, services, and information items to potential consumers. Collaborative filtering, the most successful recommendation approach, makes recommendations based on past transactions and feedback from consumers sharing similar interests. A major problem limiting the usefulness of collaborative filtering is the sparsity problem, which refers to a situation in which transactional or feedback data is sparse and insufficient to identify similarities in consumer interests. In this article, we propose to deal with this sparsity problem by applying an associative retrieval framework and related spreading activation algorithms to explore transitive associations among consumers through their past transactions and feedback. Such transitive associations are a valuable source of information to help infer consumer interests and can be explored to deal with the sparsity problem. To evaluate the effectiveness of our approach, we have conducted an experimental study using a data set from an online bookstore. We experimented with three spreading activation algorithms including a constrained Leaky Capacitor algorithm, a branch-and-bound serial symbolic search algorithm, and a Hopfield net parallel relaxation search algorithm. These algorithms were compared with several collaborative filtering approaches that do not consider the transitive associations: a simple graph search approach, two variations of the user-based approach, and an item-based approach. Our experimental results indicate that spreading activation-based approaches significantly outperformed the other collaborative filtering methods as measured by recommendation precision, recall, the F-measure, and the rank score. We also observed the over-activation effect of the spreading activation approach, that is, incorporating transitive associations with past transactional data that is not sparse may \"dilute\" the data used to infer user preferences and lead to degradation in recommendation performance.",
                    "title": "Applying associative retrieval techniques to alleviate the sparsity problem in collaborative filtering",
                    "venue": "ACM Transactions on Information Systems",
                    "year": 2004,
                    "__v": 2,
                    "citationCount": 249,
                    "result": 8.69705761263451
                },
                "f9571f5e-7bf7-427f-a512-b6979338ff31": {
                    "authors": [
                        "Luo Si",
                        "Rong Jin"
                    ],
                    "references": [
                        "312e54ca-e7e9-4129-99f4-36f3aeff827e",
                        "5ee83a3b-d5f8-4532-97dd-c0579bed0d17",
                        "8fda5d41-ef91-4e72-848f-7da042d1f9aa",
                        "c69ef004-087e-486c-97c9-9b4587d0b10a"
                    ],
                    "keyword": [
                        "users",
                        "items",
                        "filtering",
                        "collaborative",
                        "algorithms",
                        "rate",
                        "model",
                        "fmm",
                        "clustering"
                    ],
                    "group": [],
                    "_id": "f9571f5e-7bf7-427f-a512-b6979338ff31",
                    "abstract": "This paper presents a flexible mixture model (FMM) for collaborative filtering. FMM extends existing partitioning/clustering algorithms for collaborative filtering by clustering both users and items together simultaneously without assuming that each user and item should only belong to a single cluster. Furthermore, with the introduction of 'preference' nodes, the proposed framework is able to explicitly model how users rate items, which can vary dramatically, even among the users with similar tastes on items. Empirical study over two datasets of movie ratings has shown that our new algorithm outperforms five other collaborative filtering algorithms substantially.",
                    "title": "Flexible mixture model for collaborative filtering",
                    "venue": "international conference on machine learning",
                    "year": 2003,
                    "__v": 2,
                    "citationCount": 154,
                    "result": 4.733706023599408
                },
                "fe7f2770-ddca-4716-a7d9-545e68f691fe": {
                    "authors": [
                        "Dmitry Pavlov",
                        "David M. Pennock"
                    ],
                    "references": [
                        "00b25862-c833-4b20-b80f-a8d84cd14156",
                        "05234ed3-29a1-4a96-970c-44ebdf1a2fe6",
                        "111a25a1-44ca-44fb-bca8-51e8157463d3",
                        "2e34c4e7-7c2a-4172-af48-f32834865655",
                        "312e54ca-e7e9-4129-99f4-36f3aeff827e",
                        "3f8e14d5-4655-4c61-8636-99eb5cc99411",
                        "60c814e2-c4d1-47d7-9a5a-68f4141505ae",
                        "884ad41b-521b-4866-a2cb-fd3869ed5089",
                        "8de6e50f-dde3-40ad-99fa-83fcbce40b76",
                        "8fda5d41-ef91-4e72-848f-7da042d1f9aa",
                        "93fbc138-713f-402a-a554-89f111ddfcd8",
                        "b14af934-664f-44da-ac26-1d516d55d32e",
                        "c4972241-6660-4937-9e87-066e79a27d34",
                        "c69ef004-087e-486c-97c9-9b4587d0b10a"
                    ],
                    "keyword": [
                        "recommendations",
                        "user's",
                        "maxent",
                        "data",
                        "clustering",
                        "show",
                        "researchindex",
                        "nature",
                        "dynamic",
                        "documents"
                    ],
                    "group": [],
                    "_id": "fe7f2770-ddca-4716-a7d9-545e68f691fe",
                    "abstract": "We develop a maximum entropy (maxent) approach to generating recommendations in the context of a user's current navigation stream, suitable for environments where data is sparse, high-dimensional, and dynamic— conditions typical of many recommendation applications. We address sparsity and dimensionality reduction by first clustering items based on user access patterns so as to attempt to minimize the apriori probability that recommendations will cross cluster boundaries and then recommending only within clusters. We address the inherent dynamic nature of the problem by explicitly modeling the data as a time series; we show how this representational expressivity fits naturally into a maxent framework. We conduct experiments on data from ResearchIndex, a popular online repository of over 470,000 computer science documents. We show that our maxent formulation outperforms several competing algorithms in offline tests simulating the recommendation of documents to ResearchIndex users.",
                    "title": "A Maximum Entropy Approach to Collaborative Filtering in Dynamic, Sparse, High-Dimensional Domains",
                    "venue": "neural information processing systems",
                    "year": 2003,
                    "__v": 2,
                    "citationCount": 53,
                    "result": 6.352379303959047
                }
            }
        ],
        "_id": "feddae21-3c05-4743-80fa-b8e101f1b93f",
        "abstract": "This paper presents an overview of the field of recommender systems and describes the current generation of recommendation methods that are usually classified into the following three main categories: content-based, collaborative, and hybrid recommendation approaches. This paper also describes various limitations of current recommendation methods and discusses possible extensions that can improve recommendation capabilities and make recommender systems applicable to an even broader range of applications. These extensions include, among others, an improvement of understanding of users and items, incorporation of the contextual information into the recommendation process, support for multicriteria ratings, and a provision of more flexible and less intrusive types of recommendations.",
        "title": "Toward the next generation of recommender systems: a survey of the state-of-the-art and possible extensions",
        "venue": "IEEE Transactions on Knowledge and Data Engineering",
        "year": 2005,
        "__v": 3,
        "citationCount": 3038
    },
    {
        "authors": [
            "Krystian Mikolajczyk",
            "Cordelia Schmid"
        ],
        "references": [
            "00a4e16f-6b65-4ad2-bedc-b19d9cbc2cfe",
            "09346dc3-f4d0-43a4-8f0b-27e02bcd336e",
            "0aae4e44-abdb-4948-9462-61f6e52162ba",
            "0d287faa-99bb-42df-98a7-24fcd601b9a4",
            "19195bc1-7aff-4dd3-91cc-25402c343a19",
            "21a8e8fd-0172-4e9a-8474-7024eb0bf979",
            "21c67dad-f0eb-4479-afe7-fdf4a71eef01",
            "2d6c9f60-ea78-44a8-b5f9-6964575dd196",
            "33711daf-2a44-4f42-8466-c7801f29959b",
            "34758e0a-3def-447b-9c5e-e82a206426b5",
            "36800655-b2ff-4eb7-9070-c6be304c4baa",
            "37031566-2033-44cb-a87e-91a9bb37996f",
            "3b744649-d7a0-46c3-b242-9e0060d8ecfa",
            "4e58f9b5-8562-4f17-830f-f055449867fc",
            "509e1ae2-768b-4417-bebe-d90cf1e0fdae",
            "5149d3c0-5ac9-47ba-9fb0-3d2ef757b0e8",
            "568f1994-f91e-413e-92fd-87dbbb9642a8",
            "5f1992df-975f-49e7-bd88-aee0740317cf",
            "6018a516-8149-4bce-bc33-5449d86e58c2",
            "60285266-7da2-474e-b05a-b380c836f665",
            "608a581a-0e03-435a-9067-c0e0982567af",
            "683dd26d-5c59-4feb-9fbd-2bcf3cc1942f",
            "6fe37c18-8dc5-4baa-b6e0-5546353907bb",
            "72c27d5a-23c5-4d1b-a000-280b87b368ee",
            "7ab7b36d-baae-4b21-89fc-69389fcabc44",
            "853b29ea-c6d1-497e-bad3-b608d370e7e2",
            "a5254ae0-1ce1-4390-b9f8-8d5a3dcb1e62",
            "a8c6ead3-d61a-4f6a-a702-08743f19eec9",
            "b4685927-0ad9-466b-b2c6-2e1764475726",
            "b592576f-ff29-4a68-9b2f-8a8ad02e9c70",
            "b944f77f-113b-4a02-ae5e-d4a124b8fd5b",
            "c455fb04-4566-4648-ad6f-3cf2245e507c",
            "e2204e92-e6dc-4884-9bbc-200029491fc7",
            "e927dff1-6ed4-45fd-8852-eb804e11e665",
            "ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d",
            "fc9638b8-572c-4b23-aab2-92e2dd3b79f8",
            "ffa029cf-7240-4723-8339-51fac57f9f28"
        ],
        "keyword": [
            "descriptors",
            "regions",
            "performance",
            "interest",
            "detector",
            "filters",
            "al"
        ],
        "group": [
            {
                "21a8e8fd-0172-4e9a-8474-7024eb0bf979": {
                    "authors": [
                        "Andreas Opelt",
                        "Michael Fussenegger",
                        "Axel Pinz",
                        "Peter Auer"
                    ],
                    "references": [
                        "01a03531-eb3c-4b9e-a41f-2ef531e3cac2",
                        "2d6c9f60-ea78-44a8-b5f9-6964575dd196",
                        "33711daf-2a44-4f42-8466-c7801f29959b",
                        "34758e0a-3def-447b-9c5e-e82a206426b5",
                        "36800655-b2ff-4eb7-9070-c6be304c4baa",
                        "3ba1e680-b3cc-40e6-bc90-2af6c781f9bc",
                        "49e8d454-99f4-4cde-9ff8-6f50c33eaa48",
                        "509e1ae2-768b-4417-bebe-d90cf1e0fdae",
                        "5f1992df-975f-49e7-bd88-aee0740317cf",
                        "6018a516-8149-4bce-bc33-5449d86e58c2",
                        "608a581a-0e03-435a-9067-c0e0982567af",
                        "6fe37c18-8dc5-4baa-b6e0-5546353907bb",
                        "733eea21-9c61-4935-8ffd-5b8e56dd947d",
                        "84ba5bee-f8ac-4c66-8e81-858a888be0b8",
                        "8d8e7d51-3223-4776-bf6a-40306774b8a1",
                        "90ebc6d7-108e-4698-a147-76ac4e67c036",
                        "c455fb04-4566-4648-ad6f-3cf2245e507c",
                        "ccdefe89-9b16-4c22-8bb8-bd314ccad6e1",
                        "d7b1fba1-b5f8-4377-88a8-d2fc69f723b7",
                        "da8cc675-ae9d-40a0-abe2-f08e7df3fc3a",
                        "e649a9fd-f6d9-4aac-b428-29b82c20a484",
                        "ed8a9624-3abe-4b5e-bffe-5b3ecc34e841",
                        "ee554ae0-03a8-4976-9d09-0d2a885d79d6",
                        "ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d"
                    ],
                    "keyword": [],
                    "group": [],
                    "_id": "21a8e8fd-0172-4e9a-8474-7024eb0bf979",
                    "abstract": "In this paper we describe the first stage of a new learning system for object detection and recognition. For our system we propose Boosting (5) as the underlying learning technique. This allows the use of very diverse sets of visual features in the learning process within a com- mon framework: Boosting — together with a weak hypotheses finder — may choose very inhomogeneous features as most relevant for combina- tion into a final hypothesis. As another advantage the weak hypotheses finder may search the weak hypotheses space without explicit calculation of all available hypotheses, reducing computation time. This contrasts the related work of Agarwal and Roth (1) where Winnow was used as learning algorithm and all weak hypotheses were calculated explicitly. In our first empirical evaluation we use four types of local descriptors: two basic ones consisting of a set of grayvalues and intensity moments and two high level descriptors: moment invariants (8) and SIFTs (12). The descriptors are calculated from local patches detected by an inter- est point operator. The weak hypotheses finder selects one of the local patches and one type of local descriptor and efficiently searches for the most discriminative similarity threshold. This differs from other work on Boosting for object recognition where simple rectangular hypotheses (22) or complex classifiers (20) have been used. In relatively simple images, where the objects are prominent, our approach yields results comparable to the state-of-the-art (3). But we also obtain very good results on more complex images, where the objects are located in arbitrary positions, poses, and scales in the images. These results indicate that our flexible approach, which also allows the inclusion of features from segmented re- gions and even spatial relationships, leads us a significant step towards generic object recognition.",
                    "title": "Weak Hypotheses and Boosting for Generic Object Detection and Recognition",
                    "venue": "european conference on computer vision",
                    "year": 2004,
                    "__v": 0,
                    "citationCount": 150,
                    "result": 2.9729729729729732
                },
                "21c67dad-f0eb-4479-afe7-fdf4a71eef01": {
                    "authors": [
                        "Krystian Mikolajczyk",
                        "Tinne Tuytelaars",
                        "C. Schmid",
                        "Andrew Zisserman",
                        "Jir i Matas",
                        "Frederik Schaffalitzky",
                        "Timor Kadir",
                        "L. Van Gool"
                    ],
                    "references": [
                        "085204a8-62ca-4a3c-8098-4f75d62d1ae4",
                        "0aae4e44-abdb-4948-9462-61f6e52162ba",
                        "0bc5747a-2caf-4996-a55b-6ec5e7273636",
                        "0d287faa-99bb-42df-98a7-24fcd601b9a4",
                        "1dc84769-ff4c-4de6-a1c9-8d3af9299701",
                        "21a8e8fd-0172-4e9a-8474-7024eb0bf979",
                        "2beaa150-6293-4f05-ba04-8e001993e766",
                        "2d6c9f60-ea78-44a8-b5f9-6964575dd196",
                        "2dfac644-329c-46f4-a508-749ccb2d7c85",
                        "34758e0a-3def-447b-9c5e-e82a206426b5",
                        "4e58f9b5-8562-4f17-830f-f055449867fc",
                        "50212652-4999-4f13-82d6-a37eb2862a73",
                        "509e1ae2-768b-4417-bebe-d90cf1e0fdae",
                        "5149d3c0-5ac9-47ba-9fb0-3d2ef757b0e8",
                        "5172d9aa-41cc-40dc-949a-cde3d9f05f31",
                        "5f1992df-975f-49e7-bd88-aee0740317cf",
                        "6018a516-8149-4bce-bc33-5449d86e58c2",
                        "60285266-7da2-474e-b05a-b380c836f665",
                        "6842d04f-2b92-4298-aee8-92babc53f7c4",
                        "6fe37c18-8dc5-4baa-b6e0-5546353907bb",
                        "7283fa2b-1f6a-4138-a3da-4bf69809a1a9",
                        "776d4b4d-d49f-439f-9db5-7c5c3ce68db3",
                        "7ab7b36d-baae-4b21-89fc-69389fcabc44",
                        "8ab773a4-49b4-4755-a070-4ab1b1710690",
                        "8d8e7d51-3223-4776-bf6a-40306774b8a1",
                        "9b480902-c7fd-4d9f-ac9c-3c2fe3aa9c2c",
                        "a0be9da4-c423-4f87-a387-822fe304aa03",
                        "ab7b7857-e48d-4b94-8bfa-bc9ed61d5853",
                        "b25e7392-e9f9-4600-8ab0-a76252f1633a",
                        "b3e60214-b54c-4e8f-9315-a6975c760f4c",
                        "b944f77f-113b-4a02-ae5e-d4a124b8fd5b",
                        "b9e63aeb-aa46-40a0-9b06-01e2270cea70",
                        "c455fb04-4566-4648-ad6f-3cf2245e507c",
                        "cf9198ae-7e03-401f-a52b-94689ba30a36",
                        "ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d",
                        "fc9638b8-572c-4b23-aab2-92e2dd3b79f8",
                        "ffa029cf-7240-4723-8339-51fac57f9f28"
                    ],
                    "keyword": [],
                    "group": [],
                    "_id": "21c67dad-f0eb-4479-afe7-fdf4a71eef01",
                    "abstract": "The paper gives a snapshot of the state of the art in affine covariant region detectors, and compares their performance on a set of test images under varying imaging conditions. Six types of detectors are included: detectors based on affine normalization around Harris (Mikolajczyk and Schmid, 2002; Schaffalitzky and Zisserman, 2002) and Hessian points (Mikolajczyk and Schmid, 2002), a detector of `maximally stable extremal regions', proposed by Matas et al. (2002); an edge-based region detector (Tuytelaars and Van Gool, 1999) and a detector based on intensity extrema (Tuytelaars and Van Gool, 2000), and a detector of `salient regions', proposed by Kadir, Zisserman and Brady (2004). The performance is measured against changes in viewpoint, scale, illumination, defocus and image compression.#R##N##R##N#The objective of this paper is also to establish a reference test set of images and performance software, so that future detectors can be evaluated in the same framework.",
                    "title": "A Comparison of Affine Region Detectors",
                    "venue": "International Journal of Computer Vision",
                    "year": 2005,
                    "__v": 0,
                    "citationCount": 1317,
                    "result": 4.864864864864865
                },
                "4e58f9b5-8562-4f17-830f-f055449867fc": {
                    "authors": [
                        "Svetlana Lazebnik",
                        "Cordelia Schmid",
                        "Jean Ponce"
                    ],
                    "references": [
                        "02415fa8-1b54-4448-8220-7ef932a458f5",
                        "0d287faa-99bb-42df-98a7-24fcd601b9a4",
                        "0d68cae7-51b5-41e9-b66a-01254a8022a3",
                        "2d6c9f60-ea78-44a8-b5f9-6964575dd196",
                        "354d0df4-594b-4672-bdba-4a4a9310d04d",
                        "509e1ae2-768b-4417-bebe-d90cf1e0fdae",
                        "627c74ef-59d8-43b5-a68d-e60e4ac75c0a",
                        "70e86498-0a19-465c-8b73-49c2769b1a53",
                        "8bfee4b9-77a4-45f1-997d-32ee6fa1c99b",
                        "98cfeac3-9abb-4f5b-9705-158c3b7b9d3a",
                        "a3659c1d-edb1-4c48-9d00-5e15072c952b",
                        "bb472b8e-3004-49f4-9362-47aa6c75ab9b",
                        "bf664a72-1007-43e6-8dff-f1b0de9b5740",
                        "e86ce68d-0d77-4f44-a212-518e7d8f394b",
                        "ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d",
                        "f3f1d5e7-ead9-43cd-a210-fbed039d66b1"
                    ],
                    "keyword": [
                        "texture",
                        "viewpoint",
                        "surfaces",
                        "representation",
                        "images",
                        "extraction"
                    ],
                    "group": [],
                    "_id": "4e58f9b5-8562-4f17-830f-f055449867fc",
                    "abstract": "This paper introduces a texture representation suitable for recognizing images of textured surfaces under a wide range of transformations, including viewpoint changes and nonrigid deformations. At the feature extraction stage, a sparse set of affine-invariant local patches is extracted from the image. This spatial selection process permits the computation of characteristic scale and neighborhood shape for every texture element. The proposed texture representation is evaluated in retrieval and classification tasks using the entire Brodatz database and a collection of photographs of textured surfaces taken from different viewpoints.",
                    "title": "A sparse texture representation using affine-invariant regions",
                    "venue": "computer vision and pattern recognition",
                    "year": 2003,
                    "__v": 2,
                    "citationCount": 72,
                    "result": 4.166163857370615
                },
                "509e1ae2-768b-4417-bebe-d90cf1e0fdae": {
                    "authors": [
                        "Krystian Mikolajczyk",
                        "Cordelia Schmid"
                    ],
                    "references": [
                        "1c016f4a-20fb-44b5-84ad-96c10cb8e61b",
                        "1dc84769-ff4c-4de6-a1c9-8d3af9299701",
                        "2beaa150-6293-4f05-ba04-8e001993e766",
                        "2d6c9f60-ea78-44a8-b5f9-6964575dd196",
                        "2fa2e5ba-11d3-4691-91e1-807b8ef7d8a5",
                        "36800655-b2ff-4eb7-9070-c6be304c4baa",
                        "457f15ab-c8e1-461d-b768-e044d88f1917",
                        "5c179e67-426d-402e-bfbf-1893059ab7cf",
                        "5f1992df-975f-49e7-bd88-aee0740317cf",
                        "6018a516-8149-4bce-bc33-5449d86e58c2",
                        "6b98de8f-f857-417c-9667-de061bd05872",
                        "7a9f04e3-2883-4204-8fb3-7db1ce5ddc09",
                        "a0be9da4-c423-4f87-a387-822fe304aa03"
                    ],
                    "keyword": [
                        "scale",
                        "points",
                        "invariant",
                        "results",
                        "method",
                        "local",
                        "interest",
                        "image",
                        "select",
                        "rotation"
                    ],
                    "group": [],
                    "_id": "509e1ae2-768b-4417-bebe-d90cf1e0fdae",
                    "abstract": "This paper presents a new method for detecting scale invariant interest points. The method is based on two recent results on scale space: (1) Interest points can be adapted to scale and give repeatable results (geometrically stable). (2) Local extrema over scale of normalized derivatives indicate the presence of characteristic local structures. Our method first computes a multi-scale representation for the Harris interest point detector. We then select points at which a local measure (the Laplacian) is maximal over scales. This allows a selection of distinctive points for which the characteristic scale is known. These points are invariant to scale, rotation and translation as well as robust to illumination changes and limited changes of viewpoint. For indexing, the image is characterized by a set of scale invariant points; the scale associated with each point allows the computation of a scale invariant descriptor. Our descriptors are, in addition, invariant to image rotation, of affine illumination changes and robust to small perspective deformations. Experimental results for indexing show an excellent performance up to a scale factor of 4 for a database with more than 5000 images.",
                    "title": "Indexing based on scale invariant interest points",
                    "venue": "international conference on computer vision",
                    "year": 2001,
                    "__v": 2,
                    "citationCount": 444,
                    "result": 6.402425259778202
                },
                "5149d3c0-5ac9-47ba-9fb0-3d2ef757b0e8": {
                    "authors": [
                        "Tinne Tuytelaars",
                        "Luc J. Van Gool"
                    ],
                    "references": [
                        "1dc84769-ff4c-4de6-a1c9-8d3af9299701",
                        "2733a789-f151-4385-9eea-a57a96a38e96",
                        "2beaa150-6293-4f05-ba04-8e001993e766",
                        "4e7159fd-ca32-4dcd-953b-5e36a3bc9af4",
                        "6018a516-8149-4bce-bc33-5449d86e58c2",
                        "a748e0f4-ee6f-41ad-a2a5-1a5a6751086d",
                        "b23fd9d6-c390-4157-9c0f-3522a30749a8",
                        "bac97ced-fab8-4545-9b91-870dfc6f4bdf",
                        "beb947f3-b954-4bb9-8379-e33474f07c6d",
                        "ebfca554-7a3c-4597-954b-07336a2e3030"
                    ],
                    "keyword": [
                        "regions",
                        "invariant",
                        "image",
                        "system",
                        "match",
                        "correspondences",
                        "edges",
                        "corners",
                        "combination",
                        "changing"
                    ],
                    "group": [],
                    "_id": "5149d3c0-5ac9-47ba-9fb0-3d2ef757b0e8",
                    "abstract": "‘Invariant regions’ are image patches that automatically deform with changing viewpoint as to keep on covering identical physical parts of a scene. Such regions are then described by a set of invariant features, which makes it relatively easy to match them between views and under changing illumination. In previous work, we have presented invariant regions that are based on a combination of corners and edges. The application discussed then was image database retrieval. Here, an alternative method for extracting (affinely) invariant regions is given, that does not depend on the presence of edges or corners in the image but is purely intensity-based. Also, we demonstrate the use of such regions for another application, which is wide baseline stereo matching. As a matter of fact, the goal is to build an opportunistic system that exploits several types of invariant regions as it sees fit. This yields more correspondences and a system that can deal with a wider range of images. To increase the robustness of the system even further, two semi-local constraints on combinations of region correspondences are derived (one geometric, the other photometric). They allow to test the consistency of correspondences and hence to reject falsely matched regions.",
                    "title": "Wide Baseline Stereo Matching based on Local, Affinely Invariant Regions",
                    "venue": "british machine vision conference",
                    "year": 2000,
                    "__v": 1,
                    "citationCount": 206,
                    "result": 6.209188541541483
                },
                "568f1994-f91e-413e-92fd-87dbbb9642a8": {
                    "authors": [
                        "Stephen Se",
                        "David G. Lowe",
                        "James J. Little"
                    ],
                    "references": [
                        "0168d149-3c91-446e-9bc0-4ad62727b3c7",
                        "03a42efa-a19c-4b19-a881-9c7ff63865ce",
                        "55b4d6cc-785d-490c-a190-b6c0520dc670",
                        "5fda5f10-7c36-497e-b8b9-31e3a13daf6a",
                        "6018a516-8149-4bce-bc33-5449d86e58c2",
                        "743c8f36-b01c-475f-9e19-b3b93ede843d",
                        "7c2fcbda-4c70-4258-a325-499aaa9f6814",
                        "a7011f5e-9bd7-485c-ac98-708545f2d546",
                        "b0c58756-9975-4c4e-8671-12902204b0ef",
                        "ebfca554-7a3c-4597-954b-07336a2e3030",
                        "f2582897-9648-41b5-bb2e-882503f6fbe0"
                    ],
                    "keyword": [
                        "alignment",
                        "submaps",
                        "map",
                        "landmarks",
                        "global",
                        "3d",
                        "pairwise",
                        "minimization",
                        "data",
                        "consistent"
                    ],
                    "group": [],
                    "_id": "568f1994-f91e-413e-92fd-87dbbb9642a8",
                    "abstract": "We consider the problem of creating a consistent alignment of multiple 3D submaps containing distinctive visual landmarks in an unmodified environment. An efficient map alignment algorithm based on landmark specificity is proposed to align submaps. This is followed by a global minimization using the close-the-loop constraint. Landmark uncertainty is taken into account in the pairwise alignment and the global minimization process. Experiments show that the pairwise alignment of submaps with backward correction produces a consistent global 3D map. Our vision-based mapping approach using sparse 3D data is different from other existing approaches which use dense 2D range data from laser or sonar rangefinders.",
                    "title": "Vision-based mapping with backward correction",
                    "venue": "intelligent robots and systems",
                    "year": 2002,
                    "__v": 2,
                    "citationCount": 17,
                    "result": 2.719453276806218
                },
                "5f1992df-975f-49e7-bd88-aee0740317cf": {
                    "authors": [
                        "Cordelia Schmid",
                        "Roger Mohr"
                    ],
                    "references": [
                        "00909251-9935-44f3-94a1-629023b5015b",
                        "2fa2e5ba-11d3-4691-91e1-807b8ef7d8a5",
                        "34758e0a-3def-447b-9c5e-e82a206426b5",
                        "3bb5658b-131c-4072-9f9c-5f18a8272054",
                        "46da0145-fc17-4096-9624-4828cb32e116",
                        "4ea088d2-1d7e-433e-87ca-f31ad9b1e322",
                        "5dcd5949-faa9-4af3-8c6f-b285dd3b6566",
                        "5ebbd1f5-dfe5-4eec-9883-b8b5efea366c",
                        "643913d9-b72a-4ee3-9c3f-63c1249e9a3c",
                        "774c108a-4002-4123-861f-edd3b7ccb0e7",
                        "79bd9613-8976-41a1-b0b7-133b80b8477e",
                        "7a624075-0930-4956-8d8c-2910a80bdbca",
                        "7d5e97d2-5ebe-4be2-ac67-3c15fcde2c8d",
                        "8ec028ec-a8d0-4963-9e6f-231f0d6104ed",
                        "92551b72-99c5-4882-801c-a419e4eb705e",
                        "a8c76816-3583-47e8-98e1-18db34cb5b67",
                        "c083f584-daa0-4058-9a89-6b03409acfef",
                        "c38cebd1-1503-4321-ab02-28712487b9d3",
                        "c39c2ff9-1401-474d-917e-3776f528b204",
                        "d9b9f667-9d8a-4723-a6c4-c19b941acd46",
                        "dda837ee-640b-48b1-bb19-a00c5894f003"
                    ],
                    "keyword": [
                        "retrieving",
                        "images",
                        "databases",
                        "voting",
                        "visibility",
                        "transformations",
                        "small",
                        "similarity",
                        "show",
                        "semilocal"
                    ],
                    "group": [],
                    "_id": "5f1992df-975f-49e7-bd88-aee0740317cf",
                    "abstract": "This paper addresses the problem of retrieving images from large image databases. The method is based on local grayvalue invariants which are computed at automatically detected interest points. A voting algorithm and semilocal constraints make retrieval possible. Indexing allows for efficient retrieval from a database of more than 1,000 images. Experimental results show correct retrieval in the case of partial visibility, similarity transformations, extraneous features, and small perspective deformations.",
                    "title": "Local grayvalue invariants for image retrieval",
                    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "year": 1997,
                    "__v": 2,
                    "citationCount": 720,
                    "result": 3.903415633678791
                },
                "6018a516-8149-4bce-bc33-5449d86e58c2": {
                    "authors": [
                        "David G. Lowe"
                    ],
                    "references": [
                        "01a0f825-a308-455b-93fc-e62defc0e3b0",
                        "035f8537-61a7-4c4f-b9fe-120f913a38b0",
                        "5dcd5949-faa9-4af3-8c6f-b285dd3b6566",
                        "5ebbd1f5-dfe5-4eec-9883-b8b5efea366c",
                        "5f1992df-975f-49e7-bd88-aee0740317cf",
                        "78dd7c1a-bc00-4993-bd41-8e5da9a7fe5b",
                        "8678514b-e795-4972-b891-c0d31d0d46cf",
                        "899de8c7-9cd9-4dd5-82f1-ad9acb801f8e",
                        "92551b72-99c5-4882-801c-a419e4eb705e",
                        "a00704dc-a2fa-4267-b7a6-427167d99521",
                        "caeecc11-ec92-47d8-b112-c43b88dd4491",
                        "e46bb6ea-7b67-4edf-8cd4-a51ce64cff19",
                        "ee11b7f0-4aeb-4e0f-a808-2126f1590163"
                    ],
                    "keyword": [
                        "image",
                        "object",
                        "features",
                        "scaling",
                        "recognition",
                        "partially",
                        "multiple",
                        "matches",
                        "local",
                        "keys"
                    ],
                    "group": [],
                    "_id": "6018a516-8149-4bce-bc33-5449d86e58c2",
                    "abstract": "An object recognition system has been developed that uses a new class of local image features. The features are invariant to image scaling, translation, and rotation, and partially invariant to illumination changes and affine or 3D projection. These features share similar properties with neurons in inferior temporal cortex that are used for object recognition in primate vision. Features are efficiently detected through a staged filtering approach that identifies stable points in scale space. Image keys are created that allow for local geometric deformations by representing blurred image gradients in multiple orientation planes and at multiple scales. The keys are used as input to a nearest neighbor indexing method that identifies candidate object matches. Final verification of each match is achieved by finding a low residual least squares solution for the unknown model parameters. Experimental results show that robust object recognition can be achieved in cluttered partially occluded images with a computation time of under 2 seconds.",
                    "title": "Object recognition from local scale-invariant features",
                    "venue": "international conference on computer vision",
                    "year": 1999,
                    "__v": 2,
                    "citationCount": 4272,
                    "result": 3.7760843907902726
                },
                "60285266-7da2-474e-b05a-b380c836f665": {
                    "authors": [
                        "Jiri Matas",
                        "Ondrej Chum",
                        "M. Urban",
                        "Tomas Pajdla"
                    ],
                    "references": [
                        "1dc84769-ff4c-4de6-a1c9-8d3af9299701",
                        "2beaa150-6293-4f05-ba04-8e001993e766",
                        "509e1ae2-768b-4417-bebe-d90cf1e0fdae",
                        "5f1992df-975f-49e7-bd88-aee0740317cf",
                        "5fadd790-4d5c-4a63-9d0c-39661713cf69",
                        "6018a516-8149-4bce-bc33-5449d86e58c2",
                        "63dbad19-24d8-4646-8e6a-65d85a5c2af3",
                        "7a9f04e3-2883-4204-8fb3-7db1ce5ddc09",
                        "7ab7b36d-baae-4b21-89fc-69389fcabc44",
                        "8f9d2434-c08a-43e5-8152-d41f2784ddc2",
                        "a0be9da4-c423-4f87-a387-822fe304aa03",
                        "beb947f3-b954-4bb9-8379-e33474f07c6d",
                        "ceb9e934-951e-47d6-a256-9ed1bb44b4b6",
                        "e86ce68d-0d77-4f44-a212-518e7d8f394b",
                        "ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d"
                    ],
                    "keyword": [
                        "regions",
                        "images",
                        "extremal",
                        "correspondences",
                        "robust",
                        "problem",
                        "mser",
                        "measure",
                        "invariant",
                        "establishing"
                    ],
                    "group": [],
                    "_id": "60285266-7da2-474e-b05a-b380c836f665",
                    "abstract": "The wide-baseline stereo problem, i.e. the problem of establishing correspondences between a pair of images taken from different viewpoints is studied.#R##N##R##N#A new set of image elements that are put into correspondence, the so called extremal regions, is introduced. Extremal regions possess highly desirable properties: the set is closed under (1) continuous (and thus projective) transformation of image coordinates and (2) monotonic transformation of image intensities. An efficient (near linear complexity) and practically fast detection algorithm (near frame rate) is presented for an affinely invariant stable subset of extremal regions, the maximally stable extremal regions (MSER).#R##N##R##N#A new robust similarity measure for establishing tentative correspondences is proposed. The robustness ensures that invariants from multiple measurement regions (regions obtained by invariant constructions from extremal regions), some that are significantly larger (and hence discriminative) than the MSERs, may be used to establish tentative correspondences.#R##N##R##N#The high utility of MSERs, multiple measurement regions and the robust metric is demonstrated in wide-baseline experiments on image pairs from both indoor and outdoor scenes. Significant change of scale (3.5×), illumination conditions, out-of-plane rotation, occlusion, locally anisotropic scale change and 3D translation of the viewpoint are all present in the test problems. Good estimates of epipolar geometry (average distance from corresponding points to the epipolar line below 0.09 of the inter-pixel distance) are obtained.",
                    "title": "Robust wide-baseline stereo from maximally stable extremal regions",
                    "venue": "Image and Vision Computing",
                    "year": 2004,
                    "__v": 2,
                    "citationCount": 1575,
                    "result": 6.664541755718226
                },
                "6fe37c18-8dc5-4baa-b6e0-5546353907bb": {
                    "authors": [
                        "Krystian Mikolajczyk",
                        "Cordelia Schmid"
                    ],
                    "references": [
                        "00a4e16f-6b65-4ad2-bedc-b19d9cbc2cfe",
                        "09346dc3-f4d0-43a4-8f0b-27e02bcd336e",
                        "0aae4e44-abdb-4948-9462-61f6e52162ba",
                        "0d287faa-99bb-42df-98a7-24fcd601b9a4",
                        "19195bc1-7aff-4dd3-91cc-25402c343a19",
                        "21a8e8fd-0172-4e9a-8474-7024eb0bf979",
                        "21c67dad-f0eb-4479-afe7-fdf4a71eef01",
                        "2d6c9f60-ea78-44a8-b5f9-6964575dd196",
                        "33711daf-2a44-4f42-8466-c7801f29959b",
                        "34758e0a-3def-447b-9c5e-e82a206426b5",
                        "36800655-b2ff-4eb7-9070-c6be304c4baa",
                        "509e1ae2-768b-4417-bebe-d90cf1e0fdae",
                        "5149d3c0-5ac9-47ba-9fb0-3d2ef757b0e8",
                        "5f1992df-975f-49e7-bd88-aee0740317cf",
                        "6018a516-8149-4bce-bc33-5449d86e58c2",
                        "60285266-7da2-474e-b05a-b380c836f665",
                        "608a581a-0e03-435a-9067-c0e0982567af",
                        "683dd26d-5c59-4feb-9fbd-2bcf3cc1942f",
                        "853b29ea-c6d1-497e-bad3-b608d370e7e2",
                        "a5254ae0-1ce1-4390-b9f8-8d5a3dcb1e62",
                        "b4685927-0ad9-466b-b2c6-2e1764475726",
                        "b592576f-ff29-4a68-9b2f-8a8ad02e9c70",
                        "b944f77f-113b-4a02-ae5e-d4a124b8fd5b",
                        "c455fb04-4566-4648-ad6f-3cf2245e507c",
                        "e2204e92-e6dc-4884-9bbc-200029491fc7",
                        "e927dff1-6ed4-45fd-8852-eb804e11e665",
                        "ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d",
                        "fc9638b8-572c-4b23-aab2-92e2dd3b79f8"
                    ],
                    "keyword": [
                        "descriptors",
                        "point",
                        "performance",
                        "interest",
                        "filters",
                        "detector",
                        "van",
                        "steerable",
                        "sift",
                        "rate"
                    ],
                    "group": [],
                    "_id": "6fe37c18-8dc5-4baa-b6e0-5546353907bb",
                    "abstract": "In this paper we compare the performance of interest point descriptors. Many different descriptors have been proposed in the literature. However, it is unclear which descriptors are more appropriate and how their performance depends on the interest point detector. The descriptors should be distinctive and at the same time robust to changes in viewing conditions as well as to errors of the point detector. Our evaluation uses as criterion detection rate with respect to false positive rate and is carried out for different image transformations. We compare SIFT descriptors (Lowe, 1999), steerable filters (Freeman and Adelson, 1991), differential invariants (Koenderink ad van Doorn, 1987), complex filters (Schaffalitzky and Zisserman, 2002), moment invariants (Van Gool et al., 1996) and cross-correlation for different types of interest points. In this evaluation, we observe that the ranking of the descriptors does not depend on the point detector and that SIFT descriptors perform best. Steerable filters come second ; they can be considered a good choice given the low dimensionality.",
                    "title": "A performance evaluation of local descriptors",
                    "venue": "computer vision and pattern recognition",
                    "year": 2003,
                    "__v": 2,
                    "citationCount": 683,
                    "result": 18.124653618771266
                },
                "72c27d5a-23c5-4d1b-a000-280b87b368ee": {
                    "authors": [
                        "Manik Varma",
                        "Andrew Zisserman"
                    ],
                    "references": [
                        "090af1dd-85e1-49f1-ae85-9928df7f709f",
                        "15b97643-1763-4c9b-bfd5-873f62e1ad88",
                        "1ddcd105-153a-4613-9e4f-d1891c8dab3b",
                        "354d0df4-594b-4672-bdba-4a4a9310d04d",
                        "3945aa17-369f-4f16-83b8-41b14b31ac0d",
                        "442895c4-93e2-4dea-afb7-4be44eaded41",
                        "45844786-21d5-4c3b-b1a6-494fbcc3cbe4",
                        "68d734f8-c860-43a0-9c2b-182e8a40e50d",
                        "797bd062-91e8-46a2-8d74-e20b1acae0f9",
                        "98df207d-2dfc-4365-846a-c875a2a3a59e",
                        "b8a86432-fff7-474e-9d72-046c5189e6dc",
                        "bf664a72-1007-43e6-8dff-f1b0de9b5740",
                        "dc45e731-69f8-4829-ac34-97ae79f9a55a"
                    ],
                    "keyword": [
                        "texture",
                        "classified",
                        "images",
                        "filter",
                        "classification",
                        "banks",
                        "representation",
                        "neighborhoods",
                        "large",
                        "joint"
                    ],
                    "group": [],
                    "_id": "72c27d5a-23c5-4d1b-a000-280b87b368ee",
                    "abstract": "We question the role that large scale filter banks have traditionally played in texture classification. It is demonstrated that textures can be classified using the joint distribution of intensity values over extremely compact neighborhoods (starting from as small as 3 /spl times/ 3 pixels square), and that this outperforms classification using filter banks with large support. We develop a novel texton based representation, which is suited to modeling this joint neighborhood distribution for MRFs. The representation is learnt from training images, and then used to classify novel images (with unknown viewpoint and lighting) into texture classes. The power of the method is demonstrated by classifying over 2800 images of all 61 textures present in the Columbia-Utrecht database. The classification performance surpasses that of recent state-of-the-art filter bank based classifiers such as Leung & Malik, Cula & Dana, and Varma & Zisserman.",
                    "title": "Texture classification: are filter banks necessary?",
                    "venue": "computer vision and pattern recognition",
                    "year": 2003,
                    "__v": 2,
                    "citationCount": 234,
                    "result": 4.71607301927668
                },
                "853b29ea-c6d1-497e-bad3-b608d370e7e2": {
                    "authors": [
                        "Bastian Leibe",
                        "Bernt Schiele"
                    ],
                    "references": [
                        "229c6b00-6eaf-4302-b843-09167f8082c5",
                        "34758e0a-3def-447b-9c5e-e82a206426b5",
                        "37031566-2033-44cb-a87e-91a9bb37996f",
                        "6018a516-8149-4bce-bc33-5449d86e58c2",
                        "64fa74e8-db02-4190-87d7-bf23e9859a7c",
                        "9298ec73-f02d-4ee5-9fab-1ac3f188a910",
                        "9438a773-c15c-4ef2-a97c-54f643ce6082",
                        "98cfeac3-9abb-4f5b-9705-158c3b7b9d3a",
                        "c591c440-b19b-4d7b-b067-cd8c366b7d6d",
                        "d7b1fba1-b5f8-4377-88a8-d2fc69f723b7",
                        "e46bb6ea-7b67-4edf-8cd4-a51ce64cff19"
                    ],
                    "keyword": [
                        "segmentation",
                        "object",
                        "recognition",
                        "process",
                        "method",
                        "knowledge",
                        "figureground",
                        "category",
                        "categorization",
                        "approach"
                    ],
                    "group": [],
                    "_id": "853b29ea-c6d1-497e-bad3-b608d370e7e2",
                    "abstract": "Historically, figure-ground segmentation has been seen as an important and even necessary precursor for object recognition. In that context, segmentation is mostly defined as a data driven, that is bottom-up, process. As for humans object recognition and segmentation are heavily intertwined processes, it has been argued that top-down knowledge from object recognition can and should be used for guiding the segmentation process. In this paper, we present a method for the categorization of unfamiliar objects in difficult real-world scenes. The method generates object hypotheses without prior segmentation that can be used to obtain a category-specific figure-ground segmentation. In particular, the proposed approach uses a probabilistic formulation to incorporate knowledge about the recognized category as well as the supporting information in the image to segment the object from the background. This segmentation can then be used for hypothesis verification, to further improve recognition performance. Experimental results show the capacity of the approach to categorize and segment object categories as diverse as cars and cows.",
                    "title": "Interleaved Object Categorization and Segmentation",
                    "venue": "british machine vision conference",
                    "year": 2003,
                    "__v": 2,
                    "citationCount": 147,
                    "result": 5.206535708174556
                },
                "a5254ae0-1ce1-4390-b9f8-8d5a3dcb1e62": {
                    "authors": [
                        "Yan Ke",
                        "Rahul Sukthankar"
                    ],
                    "references": [
                        "28005624-c0e8-4c62-b585-6e362c3dc8d5",
                        "34758e0a-3def-447b-9c5e-e82a206426b5",
                        "36800655-b2ff-4eb7-9070-c6be304c4baa",
                        "509e1ae2-768b-4417-bebe-d90cf1e0fdae",
                        "6018a516-8149-4bce-bc33-5449d86e58c2",
                        "608a581a-0e03-435a-9067-c0e0982567af",
                        "6fe37c18-8dc5-4baa-b6e0-5546353907bb",
                        "7ab7b36d-baae-4b21-89fc-69389fcabc44",
                        "aec2ffaf-e691-4884-9304-7d7e14733b2e",
                        "b944f77f-113b-4a02-ae5e-d4a124b8fd5b",
                        "c455fb04-4566-4648-ad6f-3cf2245e507c",
                        "d7b1fba1-b5f8-4377-88a8-d2fc69f723b7"
                    ],
                    "keyword": [
                        "image",
                        "sift",
                        "descriptor",
                        "local",
                        "results",
                        "representation",
                        "gradient",
                        "feature",
                        "deformations",
                        "component"
                    ],
                    "group": [],
                    "_id": "a5254ae0-1ce1-4390-b9f8-8d5a3dcb1e62",
                    "abstract": "Stable local feature detection and representation is a fundamental component of many image registration and object recognition algorithms. Mikolajczyk and Schmid (June 2003) recently evaluated a variety of approaches and identified the SIFT [D. G. Lowe, 1999] algorithm as being the most resistant to common image deformations. This paper examines (and improves upon) the local image descriptor used by SIFT. Like SIFT, our descriptors encode the salient aspects of the image gradient in the feature point's neighborhood; however, instead of using SIFT's smoothed weighted histograms, we apply principal components analysis (PCA) to the normalized gradient patch. Our experiments demonstrate that the PCA-based local descriptors are more distinctive, more robust to image deformations, and more compact than the standard SIFT representation. We also present results showing that using these descriptors in an image retrieval application results in increased accuracy and faster matching.",
                    "title": "PCA-SIFT: a more distinctive representation for local image descriptors",
                    "venue": "computer vision and pattern recognition",
                    "year": 2004,
                    "__v": 2,
                    "citationCount": 1138,
                    "result": 7.882845200367748
                },
                "a8c6ead3-d61a-4f6a-a702-08743f19eec9": {
                    "authors": [
                        "Andrew Edie Johnson",
                        "Martial Hebert"
                    ],
                    "references": [
                        "36dd023a-14a7-479a-89c6-26d731dc5ae3",
                        "4b222616-1498-4af3-98d5-695f25e8d513",
                        "4becfab5-4039-4416-a602-5aeeb743ce60",
                        "602adc87-d33c-498b-8b5d-bea1224d0383",
                        "88521079-bcc0-4cd2-8a15-36add320a399",
                        "9460db78-bb00-420d-b159-299ae393858d",
                        "952c0c92-8cdd-4fc3-a2ad-4601ec80b127",
                        "a0d113be-5fb9-4b5b-866b-fe6900c307f1",
                        "a7a01782-8e14-4dd6-9336-60718abbfc0b",
                        "c33a51f5-0450-4172-bce8-a7a29a50b858",
                        "c39c2ff9-1401-474d-917e-3776f528b204",
                        "d57a30b0-c76d-406b-ae07-6a64ecfd5192",
                        "dfe377d1-9e27-4538-a69f-a802ead9f650",
                        "e65ca26e-ef3c-4875-b573-eda8cc7ae814",
                        "f19a8253-22d8-4574-9ddc-5e36000088fb",
                        "f876c897-0d05-4342-bf8a-0c7efdeca74e"
                    ],
                    "keyword": [
                        "point",
                        "objects",
                        "images",
                        "surface",
                        "scenes",
                        "oriented",
                        "results",
                        "recognition",
                        "parameters",
                        "descriptive"
                    ],
                    "group": [],
                    "_id": "a8c6ead3-d61a-4f6a-a702-08743f19eec9",
                    "abstract": "We present an approach to recognition of complex objects in cluttered 3-D scenes that does not require feature extraction or segmentation. Our object representation comprises descriptive images associated with each oriented point on the surface of an object. Using a single point basis constructed from an oriented point, the position of other points on the surface of the object can be described by two parameters. The accumulation of these parameters for many points on the surface of the object results in an image at each oriented point. These images, localized descriptions of the global shape of the object, are invariant to rigid transformations. Through correlation of images, point correspondences between a model and scene data are established and then grouped using geometric consistency. The effectiveness of our algorithm is demonstrated with results showing recognition of complex objects in cluttered scenes with occlusion.",
                    "title": "Recognizing objects by matching oriented points",
                    "venue": "computer vision and pattern recognition",
                    "year": 1997,
                    "__v": 2,
                    "citationCount": 60,
                    "result": 6.421684765183216
                },
                "b4685927-0ad9-466b-b2c6-2e1764475726": {
                    "authors": [
                        "Stephen Se",
                        "David G. Lowe",
                        "James J. Little"
                    ],
                    "references": [
                        "03a42efa-a19c-4b19-a881-9c7ff63865ce",
                        "202795f4-2db3-4b1b-9e81-01b7094d9f1f",
                        "34758e0a-3def-447b-9c5e-e82a206426b5",
                        "3936de47-94f1-4aa1-9e67-db8ccb8965f1",
                        "5a73ebfb-0c9b-4c63-9ccf-14720c815bfa",
                        "5d5a4e5f-da6e-42cd-b955-f2693926b9a6",
                        "6018a516-8149-4bce-bc33-5449d86e58c2",
                        "66322b0e-b724-483a-bd26-b5b55d6315e2",
                        "760bd9a4-ca62-420e-af44-bb2408e9ff5e",
                        "7f7dec03-1d9d-442b-ab89-7a90c3e1316e",
                        "a115b797-205c-43d6-a1cf-f1fc76c37641",
                        "b0c58756-9975-4c4e-8671-12902204b0ef",
                        "ebfca554-7a3c-4597-954b-07336a2e3030"
                    ],
                    "keyword": [
                        "localize",
                        "global",
                        "robot",
                        "ransac",
                        "matching",
                        "map",
                        "landmarks",
                        "frame",
                        "approach",
                        "achieved"
                    ],
                    "group": [],
                    "_id": "b4685927-0ad9-466b-b2c6-2e1764475726",
                    "abstract": "We have previously developed a mobile robot system which uses scale invariant visual landmarks to localize and simultaneously build a 3D map of the environment In this paper, we look at global localization, also known as the kidnapped robot problem, where the robot localizes itself globally, without any prior location estimate. This is achieved by matching distinctive landmarks in the current frame to a database map. A Hough transform approach and a random sample consensus (RANSAC) approach for global localization are compared, showing that RANSAC is much more efficient. Moreover, robust global localization can be achieved by matching a small sub-map of the local region built from multiple frames.",
                    "title": "Global localization using distinctive visual features",
                    "venue": "intelligent robots and systems",
                    "year": 2002,
                    "__v": 2,
                    "citationCount": 74,
                    "result": 2.0884184795949503
                },
                "b592576f-ff29-4a68-9b2f-8a8ad02e9c70": {
                    "authors": [
                        "Serge J. Belongie",
                        "Jitendra Malik",
                        "Jan Puzicha"
                    ],
                    "references": [
                        "00909251-9935-44f3-94a1-629023b5015b",
                        "042d18d1-aed3-4a9d-ba8b-fb7f3e14f568",
                        "0fc7a847-923c-4742-9b05-2b46eda24b2e",
                        "110d4ac1-9abd-4678-882c-56933790933c",
                        "13cd743f-beb9-43a1-8e08-2ef08f0d8b3f",
                        "1e4f4b5c-55e0-4d5b-b7cc-9e7fada3e341",
                        "1ef607fe-5348-4658-8964-25a57fc49270",
                        "23c61d04-333b-42c1-b8f8-a93cc33f4411",
                        "24187b9b-fe6b-484d-9a0e-0b849362fa18",
                        "25b0c9f9-0c8a-4f2a-b075-90d339b6faa3",
                        "2a082569-b03f-474a-8e45-dfd713557277",
                        "2ae7a9b5-6231-45ca-9813-afc3a6b5f5ff",
                        "31d3bf4a-4175-414e-84c4-0eb8e42fc66e",
                        "37032748-43bb-410a-8349-d2808bb6f7fa",
                        "4a29b56b-b74e-4945-9017-61a7ab844fd9",
                        "50dd56db-151d-4d62-8576-65f0ef6f381b",
                        "59ade036-678c-42ad-bce8-7aa9301103e1",
                        "5ae4ef7f-b13a-4e78-8afd-1e2d22259b87",
                        "5ebbd1f5-dfe5-4eec-9883-b8b5efea366c",
                        "5f1992df-975f-49e7-bd88-aee0740317cf",
                        "6018a516-8149-4bce-bc33-5449d86e58c2",
                        "6d86ad90-fe62-40e5-b917-7e3f31350523",
                        "772654a7-a951-4327-aca5-ba5da8dfec7c",
                        "88f85c71-d474-4d12-9c74-43ac3b7c7ee6",
                        "8fc9506c-3603-4af2-b0c8-02b368863fcb",
                        "923f5d0a-23a3-4fb1-bee7-ec72122709a4",
                        "932ef745-7197-4b00-bcd4-781bd048938f",
                        "9f84e529-87a3-42f1-9d63-9af710f40925",
                        "a8c6ead3-d61a-4f6a-a702-08743f19eec9",
                        "bf1d8c69-aefb-4a7a-8b02-f815b754833c",
                        "d5f8e154-e8c9-45e8-a3a0-fd705f00ced4",
                        "d6104d9a-faaa-4db4-8c4e-748176157ef2",
                        "d9752a5a-1603-45cc-9a21-7997750d429f",
                        "f1268507-d7ad-40be-a33a-083131f0ca8c",
                        "f3959783-a9aa-48a2-9fcc-978879de365e"
                    ],
                    "keyword": [
                        "shapes",
                        "points",
                        "similarity",
                        "correspondences",
                        "transform",
                        "solving",
                        "problem",
                        "measuring",
                        "context",
                        "aligning"
                    ],
                    "group": [],
                    "_id": "b592576f-ff29-4a68-9b2f-8a8ad02e9c70",
                    "abstract": "We present a novel approach to measuring similarity between shapes and exploit it for object recognition. In our framework, the measurement of similarity is preceded by: (1) solving for correspondences between points on the two shapes; (2) using the correspondences to estimate an aligning transform. In order to solve the correspondence problem, we attach a descriptor, the shape context, to each point. The shape context at a reference point captures the distribution of the remaining points relative to it, thus offering a globally discriminative characterization. Corresponding points on two similar shapes will have similar shape contexts, enabling us to solve for correspondences as an optimal assignment problem. Given the point correspondences, we estimate the transformation that best aligns the two shapes; regularized thin-plate splines provide a flexible class of transformation maps for this purpose. The dissimilarity between the two shapes is computed as a sum of matching errors between corresponding points, together with a term measuring the magnitude of the aligning transform. We treat recognition in a nearest-neighbor classification framework as the problem of finding the stored prototype shape that is maximally similar to that in the image. Results are presented for silhouettes, trademarks, handwritten digits, and the COIL data set.",
                    "title": "Shape matching and object recognition using shape contexts",
                    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "year": 2002,
                    "__v": 1,
                    "citationCount": 2839,
                    "result": 5.314791917423496
                },
                "b944f77f-113b-4a02-ae5e-d4a124b8fd5b": {
                    "authors": [
                        "David G. Lowe"
                    ],
                    "references": [
                        "00a4e16f-6b65-4ad2-bedc-b19d9cbc2cfe",
                        "01a0f825-a308-455b-93fc-e62defc0e3b0",
                        "035f8537-61a7-4c4f-b9fe-120f913a38b0",
                        "03a42efa-a19c-4b19-a881-9c7ff63865ce",
                        "05c3e696-6add-4b0d-b867-e6f1c98deb9b",
                        "2fa2e5ba-11d3-4691-91e1-807b8ef7d8a5",
                        "32d9eaee-c68f-4479-aa67-837d3cc91a05",
                        "34758e0a-3def-447b-9c5e-e82a206426b5",
                        "5437c0a0-8f20-49c3-86e5-9d860f3e4f04",
                        "5dcd5949-faa9-4af3-8c6f-b285dd3b6566",
                        "5f1992df-975f-49e7-bd88-aee0740317cf",
                        "5f84f09f-7644-447c-89e1-8dc9ee334197",
                        "6018a516-8149-4bce-bc33-5449d86e58c2",
                        "60285266-7da2-474e-b05a-b380c836f665",
                        "768eea6d-8e82-4bbf-8bdd-1f2338ded29f",
                        "791e9257-d7a0-41fe-b471-bde48f3c4a04",
                        "7ab7b36d-baae-4b21-89fc-69389fcabc44",
                        "7b3f5f5b-a965-4656-9a6f-2f9740625176",
                        "899de8c7-9cd9-4dd5-82f1-ad9acb801f8e",
                        "a00704dc-a2fa-4267-b7a6-427167d99521",
                        "a0fa7ae2-61e5-48a9-be10-86440416129f",
                        "a748e0f4-ee6f-41ad-a2a5-1a5a6751086d",
                        "b3e60214-b54c-4e8f-9315-a6975c760f4c",
                        "b4685927-0ad9-466b-b2c6-2e1764475726",
                        "c455fb04-4566-4648-ad6f-3cf2245e507c",
                        "ccdefe89-9b16-4c22-8bb8-bd314ccad6e1",
                        "d20995f6-529c-41c6-b75e-a169b005fb5c",
                        "d9b9f667-9d8a-4723-a6c4-c19b941acd46",
                        "df9fe96c-752e-49be-a8c4-8b098ab51e22",
                        "ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d",
                        "f6272ea9-0360-47ed-90a5-651ea958143f"
                    ],
                    "keyword": [
                        "features",
                        "object",
                        "matching",
                        "recognition",
                        "perform",
                        "images",
                        "single",
                        "robust",
                        "paper",
                        "invariant"
                    ],
                    "group": [
                        null
                    ],
                    "_id": "b944f77f-113b-4a02-ae5e-d4a124b8fd5b",
                    "abstract": "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance.",
                    "title": "Distinctive Image Features from Scale-Invariant Keypoints",
                    "venue": "International Journal of Computer Vision",
                    "year": 2004,
                    "__v": 3,
                    "citationCount": 16229,
                    "result": 7.466218580924463
                },
                "c455fb04-4566-4648-ad6f-3cf2245e507c": {
                    "authors": [
                        "Rob Fergus",
                        "Pietro Perona",
                        "Andrew Zisserman"
                    ],
                    "references": [
                        "2d6c9f60-ea78-44a8-b5f9-6964575dd196",
                        "473cf1a4-9f42-4e6d-b34f-77787f329079",
                        "509e1ae2-768b-4417-bebe-d90cf1e0fdae",
                        "613841ae-c925-4aee-9c2e-8675213e4bbf",
                        "bf664a72-1007-43e6-8dff-f1b0de9b5740",
                        "c591c440-b19b-4d7b-b067-cd8c366b7d6d",
                        "c7f93552-c1ef-4ae4-b1f5-2317e1c9d904",
                        "ccdefe89-9b16-4c22-8bb8-bd314ccad6e1",
                        "d5e5a24d-f80e-4f1a-b48b-22403b653276",
                        "d6e37fb1-5f7e-448e-847b-7d1f1271c574",
                        "d7b1fba1-b5f8-4377-88a8-d2fc69f723b7",
                        "df152036-9859-492f-998f-1ff9769b6d95",
                        "e649a9fd-f6d9-4aac-b428-29b82c20a484",
                        "ef35a024-f5f3-4a7b-b6f6-61d9167385e6",
                        "f111ff97-89a3-4df6-8f02-962d7b4fe985"
                    ],
                    "keyword": [
                        "object",
                        "models",
                        "scale",
                        "flexible",
                        "manner",
                        "learn",
                        "image",
                        "class"
                    ],
                    "group": [],
                    "_id": "c455fb04-4566-4648-ad6f-3cf2245e507c",
                    "abstract": "We present a method to learn and recognize object class models from unlabeled and unsegmented cluttered scenes in a scale invariant manner. Objects are modeled as flexible constellations of parts. A probabilistic representation is used for all aspects of the object: shape, appearance, occlusion and relative scale. An entropy-based feature detector is used to select regions and their scale within the image. In learning the parameters of the scale-invariant object model are estimated. This is done using expectation-maximization in a maximum-likelihood setting. In recognition, this model is used in a Bayesian manner to classify images. The flexible nature of the model is demonstrated by excellent results over a range of datasets including geometrically constrained classes (e.g. faces, cars) and flexible objects (such as animals).",
                    "title": "Object class recognition by unsupervised scale-invariant learning",
                    "venue": "computer vision and pattern recognition",
                    "year": 2003,
                    "__v": 2,
                    "citationCount": 1184,
                    "result": 2.608073008073008
                },
                "e2204e92-e6dc-4884-9bbc-200029491fc7": {
                    "authors": [
                        "Timo Ojala",
                        "Matti Pietikäinen",
                        "Topi Mäenpää"
                    ],
                    "references": [
                        "0647fc30-735a-4d45-bf63-433216d5a014",
                        "087735a7-1cb9-4911-a88b-158cf3ebde87",
                        "09346dc3-f4d0-43a4-8f0b-27e02bcd336e",
                        "0af9a421-ca6a-4f1e-acef-d77082a7cf0c",
                        "0da4dd98-2681-4d42-ae54-9347e8dfed97",
                        "11eebfa1-436a-4203-a39a-0d1c02bda34f",
                        "233a5884-312b-4003-855f-c75f3f7c90ea",
                        "30614910-26a5-495c-8bb7-0f723c47db69",
                        "3a770bd2-20c6-45e1-b98e-46d6f31f1966",
                        "3c4e8d07-47e2-4942-8197-59b613634ce4",
                        "4d92607c-d2ca-48fa-9a55-8e7eff5a71d3",
                        "5ffd13e9-177c-45f9-8f77-40e6e8f8378d",
                        "606f8ecd-75f5-40fa-a70d-d6665cd2990e",
                        "70e86498-0a19-465c-8b73-49c2769b1a53",
                        "746415d7-a412-4a66-8752-ce90b405fc94",
                        "76d48657-1eba-43d5-a642-f6f553331633",
                        "79aaae90-c329-4f9f-86fb-31ae2ea58ae8",
                        "813a6153-f889-4801-ac2a-233be07e5df7",
                        "8573e55d-619d-425c-bbdf-4a0dbfe8f862",
                        "9270a9b5-940a-4394-814f-433c6440f286",
                        "a8d582af-d7f0-4a20-aba5-5b49f43e990a",
                        "b1fbed62-1a39-48d6-8eb5-ea103ad6423e",
                        "b9d5d8e9-ea08-4a60-a1fe-2164382647b8",
                        "ba03a3a9-4acc-4fdb-a95f-75c76861b620",
                        "be4205fb-27a0-4449-9ba2-d311dfd393a2",
                        "d6e78be6-6ad4-4ea2-8076-911d015644e3",
                        "d6e93459-39bb-4c2a-8018-cf9437c0ea06",
                        "d70539c8-d4d5-4d3d-8333-6e6b210ff641",
                        "e7209bb1-d240-48c1-866a-3fdcce8fa558"
                    ],
                    "keyword": [
                        "operator",
                        "patterns",
                        "local",
                        "invariant",
                        "texture",
                        "rotation",
                        "presents",
                        "grayscale",
                        "binary",
                        "uniform"
                    ],
                    "group": [
                        null
                    ],
                    "_id": "e2204e92-e6dc-4884-9bbc-200029491fc7",
                    "abstract": "Presents a theoretically very simple, yet efficient, multiresolution approach to gray-scale and rotation invariant texture classification based on local binary patterns and nonparametric discrimination of sample and prototype distributions. The method is based on recognizing that certain local binary patterns, termed \"uniform,\" are fundamental properties of local image texture and their occurrence histogram is proven to be a very powerful texture feature. We derive a generalized gray-scale and rotation invariant operator presentation that allows for detecting the \"uniform\" patterns for any quantization of the angular space and for any spatial resolution and presents a method for combining multiple operators for multiresolution analysis. The proposed approach is very robust in terms of gray-scale variations since the operator is, by definition, invariant against any monotonic transformation of the gray scale. Another advantage is computational simplicity as the operator can be realized with a few operations in a small neighborhood and a lookup table. Experimental results demonstrate that good discrimination can be achieved with the occurrence statistics of simple rotation invariant local binary patterns.",
                    "title": "Multiresolution gray-scale and rotation invariant texture classification with local binary patterns",
                    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "year": 2002,
                    "__v": 3,
                    "citationCount": 3941,
                    "result": 6.294043882279178
                },
                "ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d": {
                    "authors": [
                        "Krystian Mikolajczyk",
                        "Cordelia Schmid"
                    ],
                    "references": [
                        "0d287faa-99bb-42df-98a7-24fcd601b9a4",
                        "1c016f4a-20fb-44b5-84ad-96c10cb8e61b",
                        "1dc84769-ff4c-4de6-a1c9-8d3af9299701",
                        "2d6c9f60-ea78-44a8-b5f9-6964575dd196",
                        "34758e0a-3def-447b-9c5e-e82a206426b5",
                        "36800655-b2ff-4eb7-9070-c6be304c4baa",
                        "509e1ae2-768b-4417-bebe-d90cf1e0fdae",
                        "5149d3c0-5ac9-47ba-9fb0-3d2ef757b0e8",
                        "5f1992df-975f-49e7-bd88-aee0740317cf",
                        "6018a516-8149-4bce-bc33-5449d86e58c2",
                        "7a9f04e3-2883-4204-8fb3-7db1ce5ddc09",
                        "a0be9da4-c423-4f87-a387-822fe304aa03",
                        "cc6caca8-1564-4cf8-88a3-f0733c46e0dd",
                        "e86ce68d-0d77-4f44-a212-518e7d8f394b"
                    ],
                    "keyword": [],
                    "group": [],
                    "_id": "ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d",
                    "abstract": "This paper presents a novel approach for detecting affine invariant interest points. Our method can deal with significant affine transformations including large scale changes. Such transformations introduce significant changes in the point location as well as in the scale and the shape of the neighbourhood of an interest point. Our approach allows to solve for these problems simultaneously. It is based on three key ideas : 1) The second moment matrix computed in a point can be used to normalize a region in an affine invariant way (skew and stretch). 2) The scale of the local structure is indicated by local extrema of normalized derivatives over scale. 3) An affine-adapted Harris detector determines the location of interest points. A multi-scale version of this detector is used for initialization. An iterative algorithm then modifies location, scale and neighbourhood of each point and converges to affine invariant points. For matching and recognition, the image is characterized by a set of affine invariant points; the affine transformation associated with each point allows the computation of an affine invariant descriptor which is also invariant to affine illumination changes. A quantitative comparison of our detector with existing ones shows a significant improvement in the presence of large affine deformations. Experimental results for wide baseline matching show an excellent performance in the presence of large perspective transformations including significant scale changes. Results for recognition are very good for a database with more than 5000 images.",
                    "title": "An Affine Invariant Interest Point Detector",
                    "venue": "european conference on computer vision",
                    "year": 2002,
                    "__v": 0,
                    "citationCount": 560,
                    "result": 2.1621621621621623
                },
                "ffa029cf-7240-4723-8339-51fac57f9f28": {
                    "authors": [
                        "Krystian Mikolajczyk",
                        "Cordelia Schmid"
                    ],
                    "references": [
                        "0d287faa-99bb-42df-98a7-24fcd601b9a4",
                        "1c016f4a-20fb-44b5-84ad-96c10cb8e61b",
                        "2beaa150-6293-4f05-ba04-8e001993e766",
                        "2d6c9f60-ea78-44a8-b5f9-6964575dd196",
                        "33711daf-2a44-4f42-8466-c7801f29959b",
                        "34758e0a-3def-447b-9c5e-e82a206426b5",
                        "36800655-b2ff-4eb7-9070-c6be304c4baa",
                        "457f15ab-c8e1-461d-b768-e044d88f1917",
                        "473cf1a4-9f42-4e6d-b34f-77787f329079",
                        "509e1ae2-768b-4417-bebe-d90cf1e0fdae",
                        "5149d3c0-5ac9-47ba-9fb0-3d2ef757b0e8",
                        "58d0cc4d-9deb-4188-98d2-7ca475ca7221",
                        "5f1992df-975f-49e7-bd88-aee0740317cf",
                        "5f84f09f-7644-447c-89e1-8dc9ee334197",
                        "6018a516-8149-4bce-bc33-5449d86e58c2",
                        "60285266-7da2-474e-b05a-b380c836f665",
                        "643913d9-b72a-4ee3-9c3f-63c1249e9a3c",
                        "64ea9dde-3bd8-4868-9c0b-f15556e67ad5",
                        "7283fa2b-1f6a-4138-a3da-4bf69809a1a9",
                        "79050acb-3012-4d4b-af60-66040a28043d",
                        "7a9f04e3-2883-4204-8fb3-7db1ce5ddc09",
                        "7ab7b36d-baae-4b21-89fc-69389fcabc44",
                        "899de8c7-9cd9-4dd5-82f1-ad9acb801f8e",
                        "8ab773a4-49b4-4755-a070-4ab1b1710690",
                        "a00704dc-a2fa-4267-b7a6-427167d99521",
                        "a0be9da4-c423-4f87-a387-822fe304aa03",
                        "a72802aa-e1ab-4f52-bae8-703d68f9b220",
                        "b3e60214-b54c-4e8f-9315-a6975c760f4c",
                        "c591c440-b19b-4d7b-b067-cd8c366b7d6d",
                        "cc6caca8-1564-4cf8-88a3-f0733c46e0dd",
                        "d4e9734a-a4e7-4c19-be20-c32f55d4d26f",
                        "e86ce68d-0d77-4f44-a212-518e7d8f394b",
                        "eeb31134-612a-42bf-a6c2-8b7d7c17e694",
                        "ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d"
                    ],
                    "keyword": [
                        "scale",
                        "points",
                        "invariant",
                        "affine",
                        "detectors",
                        "neighborhood",
                        "transformations",
                        "shape",
                        "results",
                        "region"
                    ],
                    "group": [],
                    "_id": "ffa029cf-7240-4723-8339-51fac57f9f28",
                    "abstract": "In this paper we propose a novel approach for detecting interest points invariant to scale and affine transformations. Our scale and affine invariant detectors are based on the following recent results: (1) Interest points extracted with the Harris detector can be adapted to affine transformations and give repeatable results (geometrically stable). (2) The characteristic scale of a local structure is indicated by a local extremum over scale of normalized derivatives (the Laplacian). (3) The affine shape of a point neighborhood is estimated based on the second moment matrix.#R##N##R##N#Our scale invariant detector computes a multi-scale representation for the Harris interest point detector and then selects points at which a local measure (the Laplacian) is maximal over scales. This provides a set of distinctive points which are invariant to scale, rotation and translation as well as robust to illumination changes and limited changes of viewpoint. The characteristic scale determines a scale invariant region for each point. We extend the scale invariant detector to affine invariance by estimating the affine shape of a point neighborhood. An iterative algorithm modifies location, scale and neighborhood of each point and converges to affine invariant points. This method can deal with significant affine transformations including large scale changes. The characteristic scale and the affine shape of neighborhood determine an affine invariant region for each point.#R##N##R##N#We present a comparative evaluation of different detectors and show that our approach provides better results than existing methods. The performance of our detector is also confirmed by excellent matching resultss the image is described by a set of scale/affine invariant descriptors computed on the regions associated with our points.",
                    "title": "Scale & Affine Invariant Interest Point Detectors",
                    "venue": "International Journal of Computer Vision",
                    "year": 2004,
                    "__v": 2,
                    "citationCount": 1525,
                    "result": 10.046209721209722
                }
            }
        ],
        "_id": "8d8e7d51-3223-4776-bf6a-40306774b8a1",
        "abstract": "In this paper, we compare the performance of descriptors computed for local interest regions, as, for example, extracted by the Harris-Affine detector [Mikolajczyk, K and Schmid, C, 2004]. Many different descriptors have been proposed in the literature. It is unclear which descriptors are more appropriate and how their performance depends on the interest region detector. The descriptors should be distinctive and at the same time robust to changes in viewing conditions as well as to errors of the detector. Our evaluation uses as criterion recall with respect to precision and is carried out for different image transformations. We compare shape context [Belongie, S, et al., April 2002], steerable filters [Freeman, W and Adelson, E, Setp. 1991], PCA-SIFT [Ke, Y and Sukthankar, R, 2004], differential invariants [Koenderink, J and van Doorn, A, 1987], spin images [Lazebnik, S, et al., 2003], SIFT [Lowe, D. G., 1999], complex filters [Schaffalitzky, F and Zisserman, A, 2002], moment invariants [Van Gool, L, et al., 1996], and cross-correlation for different types of interest regions. We also propose an extension of the SIFT descriptor and show that it outperforms the original method. Furthermore, we observe that the ranking of the descriptors is mostly independent of the interest region detector and that the SIFT-based descriptors perform best. Moments and steerable filters show the best performance among the low dimensional descriptors.",
        "title": "A performance evaluation of local descriptors",
        "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
        "year": 2005,
        "__v": 2,
        "citationCount": 2762
    },
    {
        "authors": [
            "David L. Donoho"
        ],
        "references": [
            "036a19f8-fdca-4e84-a237-e54f2108dcb4",
            "05c85ace-c998-47cd-a285-f6ecfd72004d",
            "0bb77e7f-bfc4-4d0d-873a-3d6d3c28b316",
            "0ed39048-dd26-467a-bcd5-7017fcccddb5",
            "225591b8-1c1a-4854-81d4-5b5f364c20a9",
            "2862ec34-58f4-41c0-8790-1740130f1814",
            "2a15f947-2402-4979-94b8-53de9ceef26e",
            "3d414a5e-b97a-498e-8a75-920997235c6b",
            "3dd913b8-e22d-434e-9015-bf68fbbb7bef",
            "3ddea798-1e4f-408a-86db-a611c7bbcdcf",
            "449bfdfc-f916-422c-ac0d-ebfdd2ab773a",
            "4c9f2bac-2f23-4170-a0f1-a3001f63a7b9",
            "5eb8608d-d0a1-4f14-af98-8a26bab51fae",
            "71a18de9-e543-4337-ab7a-3db31d9f8c00",
            "7291a02d-1d94-48b7-a4e2-35406c0e52ad",
            "834863b2-34f0-40dc-b4d2-f4189eaa262a",
            "87a4faed-c1a5-45c8-81eb-3bf19ae19011",
            "8dd4158a-bbc4-40cf-a4d5-14e0fe630387",
            "9b021b12-2e59-42bc-9e29-86e480e652b7",
            "9e65914c-bfef-45e7-9fd7-85c39ed13ac4",
            "a53a3dda-b003-4d5c-96b1-e9afd8e35692",
            "adc31a96-1f8e-4793-8ee9-ecef04a16ac6",
            "ae4ab999-5078-4348-9a3d-94c019952bcc",
            "aecf8a08-eff7-4182-8bbb-a7b29de2f281",
            "bb3c38fa-c2b0-4d4f-8c9d-ca1884343474",
            "c380b798-6583-4821-9613-0a9731b1ced1",
            "c9bf7235-7aad-4e6d-a9a6-e4a6bbddc327",
            "ca546a51-ffda-46b1-b783-ff512ec9c4bd",
            "cd9bd50b-d672-43a9-b0c2-0b332cf0b88e",
            "d2104367-6389-4b06-8dbe-bab7e05b903b",
            "d6457de8-9f03-4671-91da-f557a0ec20e0",
            "defc112d-f91d-4b34-9d44-bd7f702c2391",
            "f11bfae2-e272-4acc-b231-a9619f1e4d6c",
            "ff44599f-5e74-4d9b-94d3-286592973471"
        ],
        "keyword": [
            "measure",
            "reconstruct",
            "nwidths",
            "nonadaptive",
            "linear",
            "coefficients"
        ],
        "group": [
            {
                "71a18de9-e543-4337-ab7a-3db31d9f8c00": {
                    "authors": [
                        "Emmanuel J. Candès",
                        "Terence Tao"
                    ],
                    "references": [
                        "036a19f8-fdca-4e84-a237-e54f2108dcb4",
                        "2d75f21b-8617-4c21-a1bf-467a82458459",
                        "5eb8608d-d0a1-4f14-af98-8a26bab51fae",
                        "6ff01654-66d1-49c7-b526-1c8ed7fa893a",
                        "87a4faed-c1a5-45c8-81eb-3bf19ae19011",
                        "9b021b12-2e59-42bc-9e29-86e480e652b7",
                        "a53a3dda-b003-4d5c-96b1-e9afd8e35692",
                        "c385db5b-803b-4d88-b756-f7cc417bbfb0",
                        "d84405a3-88f2-4f71-8575-d16f3c8d4ca1",
                        "e33adb02-12d9-47b9-af5e-b9a79070a920",
                        "f56b877b-4060-4754-b303-e8140968544c"
                    ],
                    "keyword": [
                        "measurements",
                        "vector",
                        "suppose",
                        "random",
                        "obeys"
                    ],
                    "group": [],
                    "_id": "71a18de9-e543-4337-ab7a-3db31d9f8c00",
                    "abstract": "Suppose we are given a vector f in a class FsubeRopf N  , e.g., a class of digital signals or digital images. How many linear measurements do we need to make about f to be able to recover f to within precision epsi in the Euclidean (lscr 2 ) metric? This paper shows that if the objects of interest are sparse in a fixed basis or compressible, then it is possible to reconstruct f to within very high accuracy from a small number of random measurements by solving a simple linear program. More precisely, suppose that the nth largest entry of the vector |f| (or of its coefficients in a fixed basis) obeys |f| (n) lesRmiddotn -1 p/, where R>0 and p>0. Suppose that we take measurements y k =langf #  ,X k rang,k=1,...,K, where the X k  are N-dimensional Gaussian vectors with independent standard normal entries. Then for each f obeying the decay estimate above for some 0 t , defined as the solution to the constraints y k =langf #  ,X k rang with minimal lscr 1  norm, obeys parf-f # par lscr2 lesC p  middotRmiddot(K/logN) -r , r=1/p-1/2. There is a sense in which this result is optimal; it is generally impossible to obtain a higher accuracy from any set of K measurements whatsoever. The methodology extends to various other random measurement ensembles; for example, we show that similar results hold if one observes a few randomly sampled Fourier coefficients of f. In fact, the results are quite general and require only two hypotheses on the measurement ensemble which are detailed",
                    "title": "Near-Optimal Signal Recovery From Random Projections: Universal Encoding Strategies?",
                    "venue": "IEEE Transactions on Information Theory",
                    "year": 2006,
                    "__v": 1,
                    "citationCount": 1928,
                    "result": 3.236102622867329
                },
                "7291a02d-1d94-48b7-a4e2-35406c0e52ad": {
                    "authors": [
                        "Ping Feng",
                        "Yoram Bresler"
                    ],
                    "references": [
                        "627ff7f2-4db7-4db3-900a-38458d20ef6d",
                        "9964c906-b6bf-45de-8827-467114ee5493",
                        "c2edcc45-5cbc-403c-85c2-a125e7d80572"
                    ],
                    "keyword": [
                        "sampling",
                        "reconstruction",
                        "pattern",
                        "universal",
                        "spectral",
                        "signals",
                        "criterion",
                        "wellconditioned",
                        "support",
                        "shown"
                    ],
                    "group": [],
                    "_id": "7291a02d-1d94-48b7-a4e2-35406c0e52ad",
                    "abstract": "We propose a universal sampling pattern and corresponding reconstruction algorithms that guarantee well-conditioned reconstruction of all multiband signals with a given spectral occupancy bound without prior knowledge of the spectral support. It is shown that such a universal sampling pattern can asymptotically achieve the Nyquist-Landau (1957) minimal sampling rate. Also, the new design method replaces the nonaliasing or packability criterion for a reconstructive sampling pattern with a more lenient criterion, allowing reconstruction of signals aliased by sampling.",
                    "title": "Spectrum-blind minimum-rate sampling and reconstruction of multiband signals",
                    "venue": "international conference on acoustics speech and signal processing",
                    "year": 1996,
                    "__v": 2,
                    "citationCount": 118,
                    "result": 3.173056864240739
                },
                "834863b2-34f0-40dc-b4d2-f4189eaa262a": {
                    "authors": [
                        "Matthew S. Crouse",
                        "Robert D. Nowak",
                        "Richard G. Baraniuk"
                    ],
                    "references": [
                        "150dc0fb-e43d-4b43-bf6e-3eb9bee90660",
                        "3b939907-d596-4223-b1f2-b54a8e259d0d",
                        "3d1f5985-fe85-4e7f-92bc-fae84c785cab",
                        "42123575-fbfc-4bce-9a44-77838a00aa98",
                        "4eedf5e2-76a5-4c8c-b07e-e6318b825961",
                        "50f451e0-a314-478e-a92a-e0df1dca880d",
                        "59135305-4445-4506-8aad-52b0de9ca850",
                        "6ce99a8e-5efb-405d-afe3-d309d0e093e9",
                        "7d603a61-5361-4bd1-9c45-e0b32fe37037",
                        "970dc42b-a6e7-441a-ab94-d645d54f36b2",
                        "ad3a4ba4-5b88-4d61-9ba5-263cda996e9c",
                        "aecf8a08-eff7-4182-8bbb-a7b29de2f281",
                        "b55670f3-3025-457e-9bd8-06930a1b3e74",
                        "bd5acb06-2698-4ce9-a0ae-cbd687e03278",
                        "c0c6c887-c30a-4e7a-82c7-57da507b4606",
                        "d3e00e7e-1c64-4d7a-b2b2-1ad98ba4c706",
                        "de3c309f-3c75-41aa-aee9-44a598eafdcf"
                    ],
                    "keyword": [
                        "signal",
                        "model",
                        "statistical",
                        "hmms",
                        "waveletdomain",
                        "develop",
                        "detection",
                        "wavelet",
                        "realworld",
                        "processing"
                    ],
                    "group": [],
                    "_id": "834863b2-34f0-40dc-b4d2-f4189eaa262a",
                    "abstract": "Wavelet-based statistical signal processing techniques such as denoising and detection typically model the wavelet coefficients as independent or jointly Gaussian. These models are unrealistic for many real-world signals. We develop a new framework for statistical signal processing based on wavelet-domain hidden Markov models (HMMs) that concisely models the statistical dependencies and non-Gaussian statistics encountered in real-world signals. Wavelet-domain HMMs are designed with the intrinsic properties of the wavelet transform in mind and provide powerful, yet tractable, probabilistic signal models. Efficient expectation maximization algorithms are developed for fitting the HMMs to observational signal data. The new framework is suitable for a wide range of applications, including signal estimation, detection, classification, prediction, and even synthesis. To demonstrate the utility of wavelet-domain HMMs, we develop novel algorithms for signal denoising, classification, and detection.",
                    "title": "Wavelet-based statistical signal processing using hidden Markov models",
                    "venue": "IEEE Transactions on Signal Processing",
                    "year": 1998,
                    "__v": 2,
                    "citationCount": 620,
                    "result": 2.430329474447121
                },
                "87a4faed-c1a5-45c8-81eb-3bf19ae19011": {
                    "authors": [
                        "Rémi Gribonval",
                        "Morten Nielsen"
                    ],
                    "references": [
                        "4114181f-6f48-4cb6-b6d3-b337515d57f8",
                        "f11bfae2-e272-4acc-b231-a9619f1e4d6c"
                    ],
                    "keyword": [
                        "dictionaries",
                        "sparse",
                        "rsup",
                        "representations",
                        "union",
                        "signals",
                        "result",
                        "redundant",
                        "problem",
                        "orthonormal"
                    ],
                    "group": [],
                    "_id": "87a4faed-c1a5-45c8-81eb-3bf19ae19011",
                    "abstract": "The purpose of this correspondence is to generalize a result by Donoho and Huo and Elad and Bruckstein on sparse representations of signals in a union of two orthonormal bases for R/sup N/. We consider general (redundant) dictionaries for R/sup N/, and derive sufficient conditions for having unique sparse representations of signals in such dictionaries. The special case where the dictionary is given by the union of L/spl ges/2 orthonormal bases for R/sup N/ is studied in more detail. In particular, it is proved that the result of Donoho and Huo, concerning the replacement of the /spl lscr//sup 0/ optimization problem with a linear programming problem when searching for sparse representations, has an analog for dictionaries that may be highly redundant.",
                    "title": "Sparse representations in unions of bases",
                    "venue": "IEEE Transactions on Information Theory",
                    "year": 2003,
                    "__v": 2,
                    "citationCount": 284,
                    "result": 3.979041699614455
                },
                "9e65914c-bfef-45e7-9fd7-85c39ed13ac4": {
                    "authors": [
                        "Berwin A. Turlach",
                        "W. N. Venables",
                        "Stephen J. Wright"
                    ],
                    "references": [
                        "1b41a403-68bf-4486-bcfa-9e06abd63c28",
                        "3bb12f05-eac9-4cb6-b17f-46c596577d65",
                        "ef187358-8753-42e6-8fc5-ced3770e71b1"
                    ],
                    "keyword": [
                        "response",
                        "wavelengths",
                        "variables",
                        "suitable",
                        "subset",
                        "selecting",
                        "propose",
                        "method",
                        "case",
                        "aim"
                    ],
                    "group": [],
                    "_id": "9e65914c-bfef-45e7-9fd7-85c39ed13ac4",
                    "abstract": "We propose a new method for selecting a common subset of explanatory variables where the aim is to model several response variables. The idea is a natural extension of the LASSO technique proposed by Tibshirani (1996) and is based on the (joint) residual sum of squares while constraining the parameter estimates to lie within a suitable polyhedral region. The properties of the resulting convex programming problem are analyzed for the special case of an orthonormal design. For the general case, we develop an efficient interior point algorithm. The method is illustrated on a dataset with infrared spectrometry measurements on 14 qualitatively different but correlated responses using 770 wavelengths. The aim is to select a subset of the wavelengths suitable for use as predictors for as many of the responses as possible.",
                    "title": "Simultaneous Variable Selection",
                    "venue": "Technometrics",
                    "year": 2005,
                    "__v": 1,
                    "citationCount": 129,
                    "result": 2.6322210469269294
                },
                "a53a3dda-b003-4d5c-96b1-e9afd8e35692": {
                    "authors": [
                        "Emmanuel J. Candès",
                        "Justin K. Romberg",
                        "Terence Tao"
                    ],
                    "references": [
                        "2d75f21b-8617-4c21-a1bf-467a82458459",
                        "4114181f-6f48-4cb6-b6d3-b337515d57f8",
                        "449bfdfc-f916-422c-ac0d-ebfdd2ab773a",
                        "53c1d13a-863d-4db2-bc77-bbc7f8a45fa8",
                        "5eb8608d-d0a1-4f14-af98-8a26bab51fae",
                        "7291a02d-1d94-48b7-a4e2-35406c0e52ad",
                        "87a4faed-c1a5-45c8-81eb-3bf19ae19011",
                        "d2104367-6389-4b06-8dbe-bab7e05b903b",
                        "f11bfae2-e272-4acc-b231-a9619f1e4d6c"
                    ],
                    "keyword": [
                        "spl",
                        "frequency",
                        "samples",
                        "reconstructing",
                        "spikes",
                        "set",
                        "problem",
                        "probability",
                        "omega",
                        "convex"
                    ],
                    "group": [
                        null
                    ],
                    "_id": "a53a3dda-b003-4d5c-96b1-e9afd8e35692",
                    "abstract": "This paper considers the model problem of reconstructing an object from incomplete frequency samples. Consider a discrete-time signal f/spl isin/C/sup N/ and a randomly chosen set of frequencies /spl Omega/. Is it possible to reconstruct f from the partial knowledge of its Fourier coefficients on the set /spl Omega/? A typical result of this paper is as follows. Suppose that f is a superposition of |T| spikes f(t)=/spl sigma//sub /spl tau//spl isin/T/f(/spl tau/)/spl delta/(t-/spl tau/) obeying |T|/spl les/C/sub M//spl middot/(log N)/sup -1/ /spl middot/ |/spl Omega/| for some constant C/sub M/>0. We do not know the locations of the spikes nor their amplitudes. Then with probability at least 1-O(N/sup -M/), f can be reconstructed exactly as the solution to the /spl lscr//sub 1/ minimization problem. In short, exact recovery may be obtained by solving a convex optimization problem. We give numerical values for C/sub M/ which depend on the desired probability of success. Our result may be interpreted as a novel kind of nonlinear sampling theorem. In effect, it says that any signal made out of |T| spikes may be recovered by convex programming from almost every set of frequencies of size O(|T|/spl middot/logN). Moreover, this is nearly optimal in the sense that any method succeeding with probability 1-O(N/sup -M/) would in general require a number of frequency samples at least proportional to |T|/spl middot/logN. The methodology extends to a variety of other situations and higher dimensions. For example, we show how one can reconstruct a piecewise constant (one- or two-dimensional) object from incomplete frequency samples - provided that the number of jumps (discontinuities) obeys the condition above - by minimizing other convex functionals such as the total variation of f.",
                    "title": "Robust uncertainty principles: exact signal reconstruction from highly incomplete frequency information",
                    "venue": "IEEE Transactions on Information Theory",
                    "year": 2006,
                    "__v": 3,
                    "citationCount": 3800,
                    "result": 4.458789824091345
                },
                "adc31a96-1f8e-4793-8ee9-ecef04a16ac6": {
                    "authors": [
                        "Joel A. Tropp"
                    ],
                    "references": [
                        "02c194c5-2cb7-4d5e-9087-0437d297c33a",
                        "05c85ace-c998-47cd-a285-f6ecfd72004d",
                        "15e40102-1512-4446-9850-c8102506cbd4",
                        "1f34ec95-b00a-4c16-8e2f-1c5eff3836e2",
                        "29f196b0-3df4-43c9-bf33-6411f5adf879",
                        "35dd7a70-c187-4e3a-bee2-adb8d5c79d63",
                        "4114181f-6f48-4cb6-b6d3-b337515d57f8",
                        "449bfdfc-f916-422c-ac0d-ebfdd2ab773a",
                        "4f81a8e2-e4ca-4718-a2a2-05d18b1494e6",
                        "71a18de9-e543-4337-ab7a-3db31d9f8c00",
                        "87a4faed-c1a5-45c8-81eb-3bf19ae19011",
                        "8ca757a9-67be-4cfe-a7ec-be0d1ba5e8d5",
                        "91669e14-0ea5-4ba9-b396-b37e9abf3c67",
                        "9ec51dea-b1bb-49cc-9e36-9a13dfcadd52",
                        "af3dcf0c-6e6f-4190-a9d6-9a9d2551e378",
                        "b0afa6ff-6528-4701-800b-5dc0b5411b0c",
                        "c0edb280-44eb-4fba-8c4f-b905838d8eab",
                        "c4f2911b-627d-4278-a485-179c66ffef60",
                        "cb4fbf1c-02e4-4ca9-995d-29f5282fdb4a",
                        "cf20b5a0-152c-43ca-878e-91aab42400cf",
                        "d6457de8-9f03-4671-91da-f557a0ec20e0",
                        "d84405a3-88f2-4f71-8575-d16f3c8d4ca1",
                        "defc112d-f91d-4b34-9d44-bd7f702c2391",
                        "eacf08f1-1e8b-44ee-90b5-234724ae8355",
                        "f11bfae2-e272-4acc-b231-a9619f1e4d6c",
                        "fb8dc2b8-753f-4f2d-a9a8-a9c0f320e125"
                    ],
                    "keyword": [
                        "signals",
                        "paper",
                        "convex",
                        "relaxation",
                        "problem",
                        "studies",
                        "solve",
                        "linear",
                        "elementary",
                        "combination"
                    ],
                    "group": [],
                    "_id": "adc31a96-1f8e-4793-8ee9-ecef04a16ac6",
                    "abstract": "This paper studies a difficult and fundamental problem that arises throughout electrical engineering, applied mathematics, and statistics. Suppose that one forms a short linear combination of elementary signals drawn from a large, fixed collection. Given an observation of the linear combination that has been contaminated with additive noise, the goal is to identify which elementary signals participated and to approximate their coefficients. Although many algorithms have been proposed, there is little theory which guarantees that these algorithms can accurately and efficiently solve the problem. This paper studies a method called convex relaxation, which attempts to recover the ideal sparse signal by solving a convex program. This approach is powerful because the optimization can be completed in polynomial time with standard scientific software. The paper provides general conditions which ensure that convex relaxation succeeds. As evidence of the broad impact of these results, the paper describes how convex relaxation can be used for several concrete signal recovery problems. It also describes applications to channel coding, linear regression, and numerical analysis",
                    "title": "Just relax: convex programming methods for identifying sparse signals in noise",
                    "venue": "IEEE Transactions on Information Theory",
                    "year": 2006,
                    "__v": 2,
                    "citationCount": 454,
                    "result": 6.3114842587752795
                },
                "ae4ab999-5078-4348-9a3d-94c019952bcc": {
                    "authors": [
                        "Erich Novak"
                    ],
                    "references": [
                        "01656028-7c15-4246-9bdc-7907a25d2307",
                        "074cbf42-32ba-490f-989e-1af8e28fe45b",
                        "113c4ac3-fb84-488d-acaf-56c43cc3021c",
                        "1337d11c-9d91-4051-8a77-e9f5c122d4b5",
                        "1d926648-4a3a-4c00-9974-53a724bced4e",
                        "20165917-cebd-4548-997c-04213de9d665",
                        "22154610-d934-46ba-ae34-bd94658520d7",
                        "2699d05d-e9d5-49f3-b613-23e5b00c5a71",
                        "2f4e30ae-475c-40ae-9d5f-1dacd44c5bde",
                        "3242ca99-48b9-4c43-9909-8c3647781777",
                        "3cf43d2f-3df3-4a14-bba6-fb4a609822ce",
                        "49d6171d-97d9-4524-a2a7-0f9d5b9b2a2a",
                        "4c73043f-5305-4622-9e0a-90f044df0c8f",
                        "579fafc2-4afa-4310-aeb8-5eda6a377f0f",
                        "5ebbbe0c-c5b4-46ac-9575-4376f5c08581",
                        "61105e75-fc50-43f3-8db1-7c02a7682133",
                        "70320a0f-e63a-421a-ac6c-afa8a3b140b8",
                        "72fc16ed-9090-45f7-860b-7b4b2fb17d09",
                        "7ca70d8c-87f9-4909-83cf-26db7105ee72",
                        "89ad9cd1-9680-41c7-981d-ab082309489c",
                        "a67ac3b9-5541-4011-aaac-2a8e4addad0c",
                        "b70ccd00-4795-4f16-88ed-2a29b6fa382e",
                        "b8037bb4-4220-4106-8bb5-0f64c59c5f89",
                        "bab365ff-8370-4dec-8b8a-5c73d923da04",
                        "c0e77685-9026-4e63-a77f-6f5e6b0fb94c",
                        "cd9bd50b-d672-43a9-b0c2-0b332cf0b88e",
                        "de65b551-ff96-4ba9-81f9-2a0dfa9fcf24",
                        "fef6d5dd-55d0-4083-89fa-84eb3a2d57f1"
                    ],
                    "keyword": [
                        "methods",
                        "adaptive",
                        "nonadaptive",
                        "results",
                        "problem",
                        "bounds",
                        "assumptions",
                        "answer",
                        "wellchosen",
                        "turns"
                    ],
                    "group": [],
                    "_id": "ae4ab999-5078-4348-9a3d-94c019952bcc",
                    "abstract": "Abstract   Optimal error bounds for adaptive and nonadaptive numerical methods are compared. Since the class of adaptive methods is much larger, a well-chosen adaptive method might seem to be better than any nonadaptive method. Nevertheless there are several results saying that under natural assumptions adaptive methods are not better than nonadaptive ones. There are also other results, however, saying that adaptive methods can be significantly better than nonadaptive ones as well as bounds on how much better they can be. It turns out that the answer to the “adaption problem” depends very much on what is known a priori about the problem in question; even a seemingly small change of the assumptions can lead to a different answer.",
                    "title": "On the power of adaption",
                    "venue": "Journal of Complexity",
                    "year": 1996,
                    "__v": 1,
                    "citationCount": 19,
                    "result": 4.4531512605042005
                },
                "aecf8a08-eff7-4182-8bbb-a7b29de2f281": {
                    "authors": [
                        "Jerome M. Shapiro"
                    ],
                    "references": [
                        "011ac5b7-efca-4771-aca8-c16af5f31143",
                        "3f0bc2c9-a5c2-4e4c-a4e9-7631e36bc6a3",
                        "7ccbdf09-a84e-4ad2-ab20-cb28b6c41155",
                        "87624da4-289a-4c42-92a0-c239a103b029",
                        "8d611b4b-5120-494f-b5bd-d234be570072",
                        "8eaaee11-fdcc-479e-adcf-9ef720a18cbf",
                        "a6656b9e-ac90-42eb-8b65-9bd78b66f1f2",
                        "b9c3ab48-c632-4ec2-9e03-72c00b2d21ed",
                        "cb17c20e-e335-43dc-b2ae-350e43b74faa",
                        "d846cbd5-1ce3-40c0-b528-3669185e3c6c",
                        "eb42fb1b-ebb9-4b7f-abd2-6ef09becd655",
                        "ee3fa7f4-a88d-4b58-8ee8-843370ed51be",
                        "fd9761a2-c929-4912-b36c-6954ac9cb60b",
                        "ffe19a00-434e-4208-b764-27ce16f1b83e"
                    ],
                    "keyword": [
                        "image",
                        "bits",
                        "stream",
                        "embedded",
                        "algorithm",
                        "compression",
                        "code",
                        "produce",
                        "ezw",
                        "encoder"
                    ],
                    "group": [],
                    "_id": "aecf8a08-eff7-4182-8bbb-a7b29de2f281",
                    "abstract": "The embedded zerotree wavelet algorithm (EZW) is a simple, yet remarkably effective, image compression algorithm, having the property that the bits in the bit stream are generated in order of importance, yielding a fully embedded code. The embedded code represents a sequence of binary decisions that distinguish an image from the \"null\" image. Using an embedded coding algorithm, an encoder can terminate the encoding at any point thereby allowing a target rate or target distortion metric to be met exactly. Also, given a bit stream, the decoder can cease decoding at any point in the bit stream and still produce exactly the same image that would have been encoded at the bit rate corresponding to the truncated bit stream. In addition to producing a fully embedded bit stream, the EZW consistently produces compression results that are competitive with virtually all known compression algorithms on standard test images. Yet this performance is achieved with a technique that requires absolutely no training, no pre-stored tables or codebooks, and requires no prior knowledge of the image source. The EZW algorithm is based on four key concepts: (1) a discrete wavelet transform or hierarchical subband decomposition, (2) prediction of the absence of significant information across scales by exploiting the self-similarity inherent in images, (3) entropy-coded successive-approximation quantization, and (4) universal lossless data compression which is achieved via adaptive arithmetic coding. >",
                    "title": "Embedded image coding using zerotrees of wavelet coefficients",
                    "venue": "IEEE Transactions on Signal Processing",
                    "year": 1993,
                    "__v": 1,
                    "citationCount": 1846,
                    "result": 2.6515861589391005
                },
                "bb3c38fa-c2b0-4d4f-8c9d-ca1884343474": {
                    "authors": [
                        "S. Mallat",
                        "Zhifeng Zhang"
                    ],
                    "references": [
                        "3f0bc2c9-a5c2-4e4c-a4e9-7631e36bc6a3",
                        "cb17c20e-e335-43dc-b2ae-350e43b74faa"
                    ],
                    "keyword": [
                        "signal",
                        "matching",
                        "pursuit",
                        "dictionary",
                        "waveforms",
                        "timefrequency",
                        "structures",
                        "selected",
                        "functions",
                        "expansion"
                    ],
                    "group": [],
                    "_id": "bb3c38fa-c2b0-4d4f-8c9d-ca1884343474",
                    "abstract": "The authors introduce an algorithm, called matching pursuit, that decomposes any signal into a linear expansion of waveforms that are selected from a redundant dictionary of functions. These waveforms are chosen in order to best match the signal structures. Matching pursuits are general procedures to compute adaptive signal representations. With a dictionary of Gabor functions a matching pursuit defines an adaptive time-frequency transform. They derive a signal energy distribution in the time-frequency plane, which does not include interference terms, unlike Wigner and Cohen class distributions. A matching pursuit isolates the signal structures that are coherent with respect to a given dictionary. An application to pattern extraction from noisy signals is described. They compare a matching pursuit decomposition with a signal expansion over an optimized wavepacket orthonormal basis, selected with the algorithm of Coifman and Wickerhauser see (IEEE Trans. Informat. Theory, vol. 38, Mar. 1992). >",
                    "title": "Matching pursuits with time-frequency dictionaries",
                    "venue": "IEEE Transactions on Signal Processing",
                    "year": 1993,
                    "__v": 2,
                    "citationCount": 2385,
                    "result": 4.219262602759708
                },
                "c380b798-6583-4821-9613-0a9731b1ced1": {
                    "authors": [
                        "Ronald A. DeVore",
                        "Vladimir N. Temlyakov"
                    ],
                    "references": [
                        "3cc2c3e4-c2c1-4593-a006-814c26fa3857",
                        "eb5bfcb8-7dd1-4fef-93de-7351e27dfade"
                    ],
                    "keyword": [
                        "greedy",
                        "algorithms",
                        "function",
                        "estimates",
                        "approximation",
                        "relaxed",
                        "rate",
                        "pure",
                        "orthogonal",
                        "discussed"
                    ],
                    "group": [],
                    "_id": "c380b798-6583-4821-9613-0a9731b1ced1",
                    "abstract": "Estimates are given for the rate of approximation of a function by means of greedy algorithms. The estimates apply to approximation from an arbitrary dictionary of functions. Three greedy algorithms are discussed: the Pure Greedy Algorithm, an Orthogonal Greedy Algorithm, and a Relaxed Greedy Algorithm.",
                    "title": "Some remarks on greedy algorithms",
                    "venue": "Advances in Computational Mathematics",
                    "year": 1996,
                    "__v": 2,
                    "citationCount": 93,
                    "result": 2.84401174161236
                },
                "c9bf7235-7aad-4e6d-a9a6-e4a6bbddc327": {
                    "authors": [
                        "Ronald A. DeVore"
                    ],
                    "references": [
                        "6ff01654-66d1-49c7-b526-1c8ed7fa893a",
                        "f56b877b-4060-4754-b303-e8140968544c"
                    ],
                    "keyword": [
                        "constructions",
                        "samples",
                        "signal",
                        "performance",
                        "matrices",
                        "deterministic",
                        "widths",
                        "sensing",
                        "randomization",
                        "purely"
                    ],
                    "group": [],
                    "_id": "c9bf7235-7aad-4e6d-a9a6-e4a6bbddc327",
                    "abstract": "Compressed sensing is a new area of signal processing. Its goal is to minimize the number of samples that need to be taken from a signal for faithful reconstruction. The performance of compressed sensing on signal classes is directly related to Gelfand widths. Similar to the deeper constructions of optimal subspaces in Gelfand widths, most sampling algorithms are based on randomization. However, for possible circuit implementation, it is important to understand what can be done with purely deterministic sampling. In this note, we show how to construct sampling matrices using finite fields. One such construction gives cyclic matrices which are interesting for circuit implementation. While the guaranteed performance of these deterministic constructions is not comparable to the random constructions, these matrices have the best known performance for purely deterministic constructions.",
                    "title": "Deterministic constructions of compressed sensing matrices",
                    "venue": "Journal of Complexity",
                    "year": 2007,
                    "__v": 2,
                    "citationCount": 178,
                    "result": 3.8478138159084443
                },
                "ca546a51-ffda-46b1-b783-ff512ec9c4bd": {
                    "authors": [
                        "Nick G. Kingsbury",
                        "Tanya H. Reeves"
                    ],
                    "references": [],
                    "keyword": [
                        "transforms",
                        "coefficients",
                        "wavelet",
                        "set",
                        "nonlinear",
                        "domain",
                        "code"
                    ],
                    "group": [],
                    "_id": "ca546a51-ffda-46b1-b783-ff512ec9c4bd",
                    "abstract": "Overcomplete transforms, such as the Dual-Tree Complex Wavelet Transform, can offer more flexible signal representations than critically-sampled transforms such as the Discrete Wavelet Transform. However the process of selecting the optimal set of coefficients to code is much more difficult because many different sets of transform coefficients can represent the same decoded image. We show that large numbers of transform coefficients can be set to zero without much reconstruction quality loss by forcing compensatory changes in the remaining coefficients. We develop a system for achieving these coding aims of coefficient elimination and compensation, based on iterative projection of signals between the image domain and transform domain with a non-linear process (e.g.~centre-clipping or quantization) applied in the transform domain. The convergence properties of such non-linear feedback loops are discussed and several types of non-linearity are proposed and analyzed. The compression performance of the overcomplete scheme is compared with that of the standard Discrete Wavelet Transform, both objectively and subjectively, and is found to offer advantages of up to 0.65 dB in PSNR and significant reduction in visibility of some types of coding artifacts.© (2003) COPYRIGHT SPIE--The International Society for Optical Engineering. Downloading of the abstract is permitted for personal use only.",
                    "title": "Iterative image coding with overcomplete Complex Wavelet transforms",
                    "venue": "visual communications and image processing",
                    "year": 2003,
                    "__v": 2,
                    "citationCount": 11,
                    "result": 3.172888953152111
                },
                "d2104367-6389-4b06-8dbe-bab7e05b903b": {
                    "authors": [
                        "Martin Vetterli",
                        "Pina Marziliano",
                        "Thierry Blu"
                    ],
                    "references": [
                        "3c262768-4473-4806-b3f6-ba919d438471",
                        "57efc18d-3b8d-4fe0-b9c0-c19518159042",
                        "609eb56f-2252-48a8-9d53-7ec9a6172eb3",
                        "70694f68-0ecd-47ea-9f61-f464c0ef7a97",
                        "f8e77898-9f6b-4d14-9b14-06dc94ff0094"
                    ],
                    "keyword": [
                        "signals",
                        "sampled",
                        "kernel",
                        "innovation",
                        "show",
                        "rate",
                        "splines",
                        "reconstructed",
                        "finite",
                        "diracs"
                    ],
                    "group": [],
                    "_id": "d2104367-6389-4b06-8dbe-bab7e05b903b",
                    "abstract": "The authors consider classes of signals that have a finite number of degrees of freedom per unit of time and call this number the rate of innovation. Examples of signals with a finite rate of innovation include streams of Diracs (e.g., the Poisson process), nonuniform splines, and piecewise polynomials. Even though these signals are not bandlimited, we show that they can be sampled uniformly at (or above) the rate of innovation using an appropriate kernel and then be perfectly reconstructed. Thus, we prove sampling theorems for classes of signals and kernels that generalize the classic \"bandlimited and sinc kernel\" case. In particular, we show how to sample and reconstruct periodic and finite-length streams of Diracs, nonuniform splines, and piecewise polynomials using sinc and Gaussian kernels. For infinite-length signals with finite local rate of innovation, we show local sampling and reconstruction based on spline kernels. The key in all constructions is to identify the innovative part of a signal (e.g., time instants and weights of Diracs) using an annihilating or locator filter: a device well known in spectral analysis and error-correction coding. This leads to standard computational procedures for solving the sampling problem, which we show through experimental results. Applications of these new sampling results can be found in signal processing, communications systems, and biological systems.",
                    "title": "Sampling signals with finite rate of innovation",
                    "venue": "IEEE Transactions on Signal Processing",
                    "year": 2002,
                    "__v": 2,
                    "citationCount": 349,
                    "result": 2.9574319527408774
                },
                "defc112d-f91d-4b34-9d44-bd7f702c2391": {
                    "authors": [
                        "Shane F. Cotter",
                        "Bhaskar D. Rao",
                        "Kjersti Engan",
                        "Kenneth Kreutz-Delgado"
                    ],
                    "references": [
                        "00d121fe-1ac4-4e6a-9c51-f8360a4672d0",
                        "02c194c5-2cb7-4d5e-9087-0437d297c33a",
                        "0a2fba85-4491-44c3-b0f2-eb7e75656e97",
                        "0cee98b5-312a-4e98-b1e4-77fd412387e5",
                        "2411cbe1-2c0b-4059-a267-54020d8a57f5",
                        "2cc55e7d-66d9-41de-9fcf-8794bc6358e0",
                        "2d931da4-1abd-4ded-83d2-cfc1103ea038",
                        "41f33b32-2a7b-4b18-8181-97a2b9afc6ac",
                        "52cd5e3b-2e51-47b6-83c3-dcce8e63aea5",
                        "54147af2-42ad-4cf3-83eb-78d781dbfb8a",
                        "592f4278-aa82-4c43-9026-c4e180500dcb",
                        "64d9843a-b7dc-409a-9500-e6000b40db77",
                        "786422ee-1cb2-423e-9637-76f148eed2e7",
                        "840084bf-e24b-4dc8-9801-4ee80edeff17",
                        "87a4faed-c1a5-45c8-81eb-3bf19ae19011",
                        "89e35dca-e435-434b-8c47-bb7064a307eb",
                        "8a3de8c3-c8d9-4f23-974a-62966eb5964d",
                        "9ec51dea-b1bb-49cc-9e36-9a13dfcadd52",
                        "bb3c38fa-c2b0-4d4f-8c9d-ca1884343474",
                        "bd91c3d4-f7db-498f-b5ea-0dd2f9e55038",
                        "be6ee99e-8d06-4b9a-af9a-39f5ed8725fd",
                        "c0fba0f5-76d1-402f-909a-868291247426",
                        "c87c6650-2835-4f03-adf9-1ae58f51b254",
                        "d7d9ffa7-de47-46e6-b272-ebb28b6ea603",
                        "ebb65244-786b-40db-96d6-f8ae4da4651a",
                        "f11bfae2-e272-4acc-b231-a9619f1e4d6c",
                        "f4bd6520-1046-48b5-993a-98a38c25172c",
                        "f7d16f47-63d0-47d9-ae1c-e90e9ef0e804"
                    ],
                    "keyword": [
                        "measurement",
                        "multiple",
                        "vectors",
                        "solutions",
                        "problem",
                        "algorithms",
                        "utility",
                        "underdetermined",
                        "system",
                        "studied"
                    ],
                    "group": [],
                    "_id": "defc112d-f91d-4b34-9d44-bd7f702c2391",
                    "abstract": "We address the problem of finding sparse solutions to an underdetermined system of equations when there are multiple measurement vectors having the same, but unknown, sparsity structure. The single measurement sparse solution problem has been extensively studied in the past. Although known to be NP-hard, many single-measurement suboptimal algorithms have been formulated that have found utility in many different applications. Here, we consider in depth the extension of two classes of algorithms-Matching Pursuit (MP) and FOCal Underdetermined System Solver (FOCUSS)-to the multiple measurement case so that they may be used in applications such as neuromagnetic imaging, where multiple measurement vectors are available, and solutions with a common sparsity structure must be computed. Cost functions appropriate to the multiple measurement problem are developed, and algorithms are derived based on their minimization. A simulation study is conducted on a test-case dictionary to show how the utilization of more than one measurement vector improves the performance of the MP and FOCUSS classes of algorithm, and their performances are compared.",
                    "title": "Sparse solutions to linear inverse problems with multiple measurement vectors",
                    "venue": "IEEE Transactions on Signal Processing",
                    "year": 2005,
                    "__v": 2,
                    "citationCount": 442,
                    "result": 4.01991219135182
                },
                "f11bfae2-e272-4acc-b231-a9619f1e4d6c": {
                    "authors": [
                        "Michael Elad",
                        "Alfred M. Bruckstein"
                    ],
                    "references": [
                        "bb3c38fa-c2b0-4d4f-8c9d-ca1884343474",
                        "de4fea1d-2739-4e0f-b5a3-08f0df58d787"
                    ],
                    "keyword": [
                        "representations",
                        "vectors",
                        "uniqueness",
                        "sparse",
                        "result",
                        "pairs",
                        "orthonormal",
                        "bases",
                        "uncertainty",
                        "stronger"
                    ],
                    "group": [],
                    "_id": "f11bfae2-e272-4acc-b231-a9619f1e4d6c",
                    "abstract": "An elementary proof of a basic uncertainty principle concerning pairs of representations of R/sup N/ vectors in different orthonormal bases is provided. The result, slightly stronger than stated before, has a direct impact on the uniqueness property of the sparse representation of such vectors using pairs of orthonormal bases as overcomplete dictionaries. The main contribution in this paper is the improvement of an important result due to Donoho and Huo (2001) concerning the replacement of the l/sub 0/ optimization problem by a linear programming (LP) minimization when searching for the unique sparse representation.",
                    "title": "A generalized uncertainty principle and sparse representation in pairs of bases",
                    "venue": "IEEE Transactions on Information Theory",
                    "year": 2002,
                    "__v": 2,
                    "citationCount": 187,
                    "result": 3.6097708174178766
                }
            }
        ],
        "_id": "f56b877b-4060-4754-b303-e8140968544c",
        "abstract": "Suppose x is an unknown vector in Ropf m  (a digital image or signal); we plan to measure n general linear functionals of x and then reconstruct. If x is known to be compressible by transform coding with a known transform, and we reconstruct via the nonlinear procedure defined here, the number of measurements n can be dramatically smaller than the size m. Thus, certain natural classes of images with m pixels need only n=O(m 1/4 log 5/2 (m)) nonadaptive nonpixel samples for faithful recovery, as opposed to the usual m pixel samples. More specifically, suppose x has a sparse representation in some orthonormal basis (e.g., wavelet, Fourier) or tight frame (e.g., curvelet, Gabor)-so the coefficients belong to an lscr p  ball for 0 2  error O(N 1/2-1 p/). It is possible to design n=O(Nlog(m)) nonadaptive measurements allowing reconstruction with accuracy comparable to that attainable with direct knowledge of the N most important coefficients. Moreover, a good approximation to those N important coefficients is extracted from the n measurements by solving a linear program-Basis Pursuit in signal processing. The nonadaptive measurements have the character of \"random\" linear combinations of basis/frame elements. Our results use the notions of optimal recovery, of n-widths, and information-based complexity. We estimate the Gel'fand n-widths of lscr p  balls in high-dimensional Euclidean space in the case 0<ples1, and give a criterion identifying near- optimal subspaces for Gel'fand n-widths. We show that \"most\" subspaces are near-optimal, and show that convex optimization (Basis Pursuit) is a near-optimal way to extract information derived from these near-optimal subspaces",
        "title": "Compressed sensing",
        "venue": "IEEE Transactions on Information Theory",
        "year": 2006,
        "__v": 3,
        "citationCount": 6079
    },
    {
        "authors": [
            "Edmund M. Clarke",
            "Bernd-Holger Schlingloff"
        ],
        "references": [
            "031623d1-c0a0-4766-80eb-6842c6c2c3de",
            "036c1775-3f28-40b5-b67c-947debc8ff7a",
            "041b94e4-f12f-439f-a1a3-016a38548455",
            "04cb2cd3-1d26-4bca-902c-68f22facb84e",
            "0bc91cdf-6602-4b6e-b753-60297dd20f0d",
            "0d4cc186-9c63-429b-85e4-83b606481524",
            "0d740fe0-27b0-416f-b77b-c18169a53735",
            "0d860ba7-8967-4b78-8236-3c3f10b5fa66",
            "0ed8c347-0774-4a51-9d64-47b847d8897a",
            "10e8157e-963a-44e8-b4f6-f2cf054da376",
            "17a0d36a-8e95-49eb-8c0f-9f02bd2cdf88",
            "1859d24d-bbbe-4412-b407-59e1f1f44f25",
            "1c81fdcb-be83-4f02-a69d-86372afa828a",
            "1e62a293-dabe-47a5-bf82-24263ba97bc8",
            "1eb621bf-d554-429d-92e3-c50b4dcedfda",
            "22469495-2007-4480-8405-54101eefd366",
            "24903b34-eb6e-4b71-b354-b67d04d93822",
            "25a1fb95-d983-4379-9265-d02df7c805f4",
            "25d20461-5c89-4aee-9758-fa49a27c9acd",
            "29798dd2-bb98-47c2-b159-6d6dd9cb39ce",
            "2bb33756-67db-4329-8c0d-f3c5fdab2367",
            "2c7c1ecb-e09b-42f6-855b-ac3184356727",
            "2db89dc9-8302-4d71-b197-2ff3531185ab",
            "32f95722-0762-4661-9cc1-cc3d00af2ae9",
            "33bf2bc8-d459-4677-ab6e-c3aa781812d0",
            "383495e3-5d5e-4a00-ba12-2dcff9ab570e",
            "3863f02c-96e5-4830-bcc3-60a1c8218f2e",
            "3922dd79-4ffe-42f5-a88e-0372385e3801",
            "3af1387d-3cc8-4a33-bc2c-b92080dd9e34",
            "3cc4cf06-ef60-49ce-ac94-33ed62cf6fd3",
            "3e43b919-e77a-4d69-b267-fb7299a32495",
            "3e5d18f4-a087-4eda-9d3f-96ae80cfd094",
            "42864c94-1428-4f59-987a-a12aaaaf8014",
            "43235550-631d-4ed6-8ccf-86159a74206d",
            "450986a6-370b-4598-910e-802d4f90c04f",
            "472a2408-6d77-41d4-91f9-a4121814a441",
            "4814eca2-167a-48bd-a7e6-60150e7a54e3",
            "48978913-7441-4636-8352-75a7bc484d23",
            "49716cea-567f-429f-bda6-4e43c97ce499",
            "4ae1d627-8bd4-4f50-85f2-1b8e242f50de",
            "4d023b6d-a6fe-4a0e-b148-4cfe2c352270",
            "4efa3e92-a485-4d25-8eb9-93f012d7aed5",
            "5376f94d-6ba7-487c-ada2-e7f621c0ed50",
            "5a11bdba-a1e0-4fa3-b721-28881da79107",
            "5b52619b-b806-45ee-ae99-d08a69a8dd92",
            "5e03c8e0-f95c-4885-9839-cc9725ef9b15",
            "5fa3d032-bed9-415e-98ed-d725e1df5b62",
            "5fd2c45b-9be0-4805-a635-c23a04cf1f66",
            "60938b9d-4a77-42eb-95dd-ae64c93620e6",
            "62422955-6a62-4898-bede-a2fc7927bfa5",
            "635e2014-6579-4acf-9737-49593bc74701",
            "646977ea-5bcb-4e0c-8eeb-5a25f02df5f2",
            "6739cb71-6293-40a9-9742-6d4e864a7038",
            "6d9ec6da-c869-4ce1-8d97-853ddcebfb50",
            "709e4691-a28f-4677-a418-124eae69d7d8",
            "73d04fdc-7dbb-4621-bfd4-81dffb2a2f8b",
            "758cf7ad-c8bc-4e8c-b60f-60dd444ab5e9",
            "77d2ea65-9174-464d-a871-60b33377035c",
            "77e8f723-88ab-42ef-84e2-6b8b4f3b012a",
            "7875ba51-0438-46d5-bc04-d0278f5e0fca",
            "7b24d601-faf9-40b7-b18a-aaba822e243a",
            "7b3c0ff0-951d-4433-b495-328b0fadb801",
            "81541435-ee9c-4e08-a47c-76e93e1697d0",
            "82afb34a-cb4f-42e2-9438-fe181fcd5445",
            "83fa4cb3-9d63-4045-bfc2-06bfa8eec305",
            "8508a58e-67dd-4815-8b48-c48366a9d379",
            "866836f2-26cb-4a58-b0ed-dc58419c839a",
            "86718b68-beb2-4201-8bce-845a80302bd2",
            "8a2553f5-2018-403d-b0f3-9bda808737d6",
            "8bc1f31b-8589-4fe9-b3b2-0b3da2da7640",
            "8d1688b3-232b-4c48-80f6-d7f5e1b732d8",
            "8d6dc616-8728-49a3-8962-71a2530d16bc",
            "8d8ae06a-54a1-4175-82f9-7cd7d7f88900",
            "8e739a3f-55da-4977-ac9c-ec9e7524b5f4",
            "90571887-c29a-4df4-aded-087323d7b34b",
            "932c5ac3-1cfb-401f-8f7e-593262f39d7e",
            "93ea1246-9a3c-436e-8071-230e8623a930",
            "968b0d9a-519f-4fff-b4d2-030150473330",
            "97a7eecc-5a96-4d72-93bb-adbea9d8ba3f",
            "9851dbde-517e-4101-ba57-d90d9d6cae61",
            "9a4984f9-27d4-47eb-8bc8-0469bf540f94",
            "9d3fac2f-2734-45d3-99f1-3dc2398b88a2",
            "9dacfb52-eebb-4a91-ae67-5fdffbfeee7f",
            "a662a4e7-415e-417e-8a8f-fe085d7e487f",
            "b3d9b852-7a2b-4f2d-90f4-67b8274a3317",
            "b581d1fb-024c-43eb-80d8-ee7f4a0aaf52",
            "b5bc2106-f964-4808-9a3c-ba219e72d0ce",
            "b5fbaa5e-8016-4b7a-8ca0-b9d2359c97fc",
            "bb0e84e2-2fb1-4db1-8a85-ec338c32bd4b",
            "bd03422b-5f39-4d6c-814d-36d6e344a0d1",
            "bf12376d-27fb-4d07-9d43-3be5ddc2b9f7",
            "c1102d81-fb2c-4701-94c6-47feea928648",
            "c18eb103-3eea-4ee6-946e-95af3ad83a6d",
            "c231c6d9-02d8-4e31-ae79-8b97d8df44a8",
            "c685cb4c-ac72-4215-a865-760effb5a4fa",
            "c881cfae-fbc0-42f8-995f-df85fbf891be",
            "cb3cec59-ff10-4070-bda4-b440614d59b7",
            "ccf4e53c-87d9-4066-b6d0-e090af6bbae3",
            "cdda251e-24ae-4621-a85d-1ff865a1adae",
            "d0a712d2-8fdf-4345-9d21-bc067a4fc55f",
            "d39c9630-607d-48da-ae71-efdef3d7f129",
            "d9e3358b-6050-47bb-9633-4be8fb0c1618",
            "e2f00686-d81e-4d69-b5e3-88a9d8d2e7f9",
            "e5bb6591-252b-4ee7-9324-63646a90bf78",
            "e5f1be72-0eea-4650-b3d2-7a3201156554",
            "e8f9dee8-e8a1-4c17-82f1-34e432ce7cae",
            "eac1c0cb-beaa-46f9-ac77-56961ddf420a",
            "f025a6c0-83f7-4367-b864-b03bc6231799",
            "f5f1b6cd-64e7-428f-bd7a-90c92ed50bde",
            "fa1837c5-23ac-45a4-a4b0-47aa3da60df2"
        ],
        "keyword": [],
        "group": [],
        "_id": "c00bbb49-6e29-4103-8883-55acd23c248b",
        "title": "Model checking",
        "venue": "",
        "year": 2001,
        "abstract": "",
        "__v": 0,
        "citationCount": 4313
    },
    {
        "authors": [
            "Leo Breiman"
        ],
        "references": [
            "0e9dc5ee-f078-4894-8f90-c3b1272da979",
            "0f115eea-2272-431f-9f21-6d6789b2bbc9",
            "17f811d8-8607-4270-bbec-1cc7883edd68",
            "3704f939-09a2-4e9f-b851-1261bcd310df",
            "3ae9664a-bf6f-45d2-852f-bba9b47e2b8a",
            "504ab3f2-f826-411f-b3fd-02d2019c3844",
            "5242f101-1511-4660-9a4c-4eb597aaa3c6",
            "64abe8f5-cc63-4666-a4fe-d9c3c88db207",
            "67046388-ae78-4aa4-ad8a-4f012858f6fb",
            "7cd3d1bf-4df0-46c8-9e75-701534e5d93c",
            "9e1ac4ec-85bf-4b41-b3f1-d12264b9352b",
            "bd34fa58-2c96-4101-a068-2ef6368e2c6a",
            "becc43bc-a7b6-46e1-817e-553c84a4a6dd",
            "c88edc45-936d-4cda-9d12-1a7a21cdb651",
            "d3b865bc-69e2-4426-9e7a-d01f0180a3ec",
            "d9809d9a-ccf7-44a2-9073-3ed158f9057f",
            "dc5dbb29-71b6-42e7-9e6b-8a1afdeeaee4",
            "ebbbb0e3-5789-4dd0-b5f3-a911e59df314",
            "f780a374-9a90-4ce3-951d-071db1e0ba9e",
            "f98f3e2b-d93b-4c34-bb55-f2acc0cddab6",
            "ffe77764-a254-4316-887e-c65bd4da6185"
        ],
        "keyword": [
            "tree",
            "forests",
            "error",
            "random",
            "international",
            "strength",
            "split",
            "number",
            "generalization",
            "features"
        ],
        "group": [
            {
                "504ab3f2-f826-411f-b3fd-02d2019c3844": {
                    "authors": [
                        "Giorgio Giacinto",
                        "Fabio Roli"
                    ],
                    "references": [
                        "0813ad74-7670-4761-8699-59f5c25dfa9b",
                        "0f115eea-2272-431f-9f21-6d6789b2bbc9",
                        "1017d9d4-9a4c-423d-ad40-6d9bebbd6b31",
                        "78ad74ce-af25-4b0f-85da-2e7d852964e9",
                        "7cd3d1bf-4df0-46c8-9e75-701534e5d93c",
                        "84806dbe-fa0e-47c0-b1f2-00fb2eed25a7",
                        "b11d7f27-90e2-4c44-b94c-ce3f95bc0ac6",
                        "b7c2a37b-4274-46e5-896a-c44479c9a105",
                        "d130ecec-e5cf-4f59-b4f8-1cbda4b0c307",
                        "e62ff43e-b9cf-4db3-91ad-8e1e74384a7c",
                        "e6b6e8f4-3c7d-4435-8ca9-192c3a76cdf8",
                        "fe2bc8c5-302f-4572-ab96-4b22178178b4",
                        "fe3df661-e3d8-4057-9c87-84198ef53604",
                        "ff309f0f-ef0d-4379-8050-2e3cfd104860"
                    ],
                    "keyword": [
                        "classifier",
                        "systems",
                        "multiple",
                        "design",
                        "approach",
                        "proposed",
                        "accurate",
                        "showed",
                        "set",
                        "method"
                    ],
                    "group": [],
                    "_id": "504ab3f2-f826-411f-b3fd-02d2019c3844",
                    "abstract": "Multiple classifier systems (MCSs) based on the combination of outputs of a set of different classifiers have been proposed in the field of pattern recognition as a method for the development of high performance classification systems. Previous work clearly showed that multiple classifier systems are effective only if the classifiers forming them are accurate and make different errors. Therefore, the fundamental need for methods aimed to design “accurate and diverse” classifiers is currently acknowledged. In this paper, an approach to the automatic design of multiple classifier systems is proposed. Given an initial large set of classifiers, our approach is aimed at selecting the subset made up of the most accurate and diverse classifiers. A proof of the optimality of the proposed design approach is given. Reported results on the classification of multisensor remote sensing images show that this approach allows the design of effective multiple classifier systems.",
                    "title": "An approach to the automatic design of multiple classifier systems",
                    "venue": "machine learning and data mining in pattern recognition",
                    "year": 2001,
                    "__v": 1,
                    "citationCount": 83,
                    "result": 3.9956318535265902
                },
                "5242f101-1511-4660-9a4c-4eb597aaa3c6": {
                    "authors": [
                        "Yali Amit",
                        "Donald Geman"
                    ],
                    "references": [
                        "0f115eea-2272-431f-9f21-6d6789b2bbc9",
                        "13cd743f-beb9-43a1-8e08-2ef08f0d8b3f",
                        "1fe05e50-846a-4c19-bece-273985edb5f9",
                        "2214c39d-cd92-4125-b75f-d0c4616d378c",
                        "2958fc5c-15e8-45e7-8da8-d2e0fa46f0c7",
                        "29a79d67-73a4-4990-9880-f9cc5b56c6f2",
                        "32f9a283-def8-4fb1-958e-df425f170d03",
                        "3e297ee7-9858-44c7-a16e-37d6044e32ec",
                        "49a8f365-8245-4e84-8234-9493c2db38b0",
                        "814d8f95-6905-4344-b1db-834362e229fb",
                        "975d3963-b61f-46f8-ada8-8ac721734f75",
                        "9bc25dd2-fb5c-47dd-9edb-e1721029ac58",
                        "b49c1e2b-0cd0-4950-a724-00c698e5b49d",
                        "c4dc7b46-01d3-44f5-91ca-0cc063d38c8c",
                        "ce7a2e20-e615-4192-b4be-7ff2c53ef697",
                        "da4534a6-897c-4431-89ef-cd326bfaf9a8",
                        "db0f6e4e-b264-4386-bab5-9b32ffa4a4f6",
                        "e97694f9-509a-419d-9a4d-fa1b00b7d3b7",
                        "ea294286-3cc2-4979-a22b-2fbb78c2ef18",
                        "f00fc370-0854-4967-bc6a-83b6c49da8bf"
                    ],
                    "keyword": [
                        "queries",
                        "tree",
                        "shape",
                        "features",
                        "information",
                        "classifier",
                        "based"
                    ],
                    "group": [],
                    "_id": "5242f101-1511-4660-9a4c-4eb597aaa3c6",
                    "abstract": "We explore a new approach to shape recognition based on a virtually infinite family of binary features (queries) of the image data, designed to accommodate prior information about shape invariance and regularity. Each query corresponds to a spatial arrangement of several local topographic codes (or tags), which are in themselves too primitive and common to be informative about shape. All the discriminating power derives from relative angles and distances among the tags. The important attributes of the queries are a natural partial ordering corresponding to increasing structure and complexity; semi-invariance, meaning that most shapes of a given class will answer the same way to two queries that are successive in the ordering; and stability, since the queries are not based on distinguished points and substructures. No classifier based on the full feature set can be evaluated, and it is impossible to determine a priori which arrangements are informative. Our approach is to select informative features and build tree classifiers at the same time by inductive learning. In effect, each tree provides an approximation to the full posterior where the features chosen depend on the branch that is traversed. Due to the number and nature of the queries, standard decision tree construction based on a fixed-length feature vector is not feasible. Instead we entertain only a small random sample of queries at each node, constrain their complexity to increase with tree depth, and grow multiple trees. The terminal nodes are labeled by estimates of the corresponding posterior distribution over shape classes. An image is classified by sending it down every tree and aggregating the resulting distributions. The method is applied to classifying handwritten digits and synthetic linear and nonlinear deformations of three hundred L AT E X symbols. Stateof-the-art error rates are achieved on the National Institute of Standards and Technology database of digits. The principal goal of the experiments on L AT E X symbols is to analyze invariance, generalization error and related issues, and a comparison with artificial neural networks methods is presented in this context.",
                    "title": "Shape quantization and recognition with randomized trees",
                    "venue": "Neural Computation",
                    "year": 1997,
                    "__v": 2,
                    "citationCount": 332,
                    "result": 6.868656804226868
                },
                "64abe8f5-cc63-4666-a4fe-d9c3c88db207": {
                    "authors": [
                        "Bruce Rosen"
                    ],
                    "references": [
                        "08ae786f-e6b6-4417-ac45-dc1577e02ba0",
                        "2f5adf78-25e5-42e4-9a6c-435617f57387",
                        "6c68311c-2745-446f-9c09-df4632392a78",
                        "d44f2bdb-efce-4435-91e3-e7d8b6972604",
                        "d7a2e7a3-af93-4da2-9fea-33de924c0391",
                        "da4534a6-897c-4431-89ef-cd326bfaf9a8",
                        "e57d5178-eb38-4375-90ef-e9286d033c86"
                    ],
                    "keyword": [
                        "network",
                        "training",
                        "individual",
                        "'ensemble'",
                        "decorrelation",
                        "results",
                        "output",
                        "nns",
                        "linear",
                        "function"
                    ],
                    "group": [],
                    "_id": "64abe8f5-cc63-4666-a4fe-d9c3c88db207",
                    "abstract": "We describe a decorrelation network training method for improving the quality of regression learning in 'ensemble' neural networks NNs that are composed of linear combinations of individual NNs. In this method, individual networks are trained by backpropogation not only to reproduce a desired output, but also to have their errors linearly decorrelated with the other networks. Outputs from the individual networks are then linearly combined to produce the output of the ensemble network. We demonstrate the performances of decorrelated network training on learning the 'three-parity' logic function, a noisy sine function and a one-dimensional non-linear function, and compare the results with the ensemble networks composed of independently trained individual networks without decorrelation training . Empirical results show than when individual networks are forced to be decorrelated with one another the resulting ensemble NNs have lower mean squared errors than the ensemble networks having independently trained i...",
                    "title": "Ensemble Learning Using Decorrelated Neural Networks",
                    "venue": "Connection Science",
                    "year": 1996,
                    "__v": 1,
                    "citationCount": 110,
                    "result": 6.215569282798385
                },
                "67046388-ae78-4aa4-ad8a-4f012858f6fb": {
                    "authors": [
                        "Ludmila I. Kuncheva",
                        "James C. Bezdek",
                        "Robert P. W. Duin"
                    ],
                    "references": [
                        "380e23c7-5122-4f33-81ae-0242742150a9",
                        "434a52fb-6f63-453d-a035-534a8aa6ae30",
                        "46510028-2e6e-4ac6-a306-b63fdac85019",
                        "5206bed9-d48d-44ab-b0cd-4731dfe5679c",
                        "6679e3d1-e19f-4a48-8a86-8538631e364e",
                        "702936e6-7107-428b-b3ca-2bc64e785519",
                        "7d1ebe05-c398-4d42-878f-a318fc5a0f57",
                        "98ba2286-da81-41ca-9050-ede2e94e550d",
                        "9e1ac4ec-85bf-4b41-b3f1-d12264b9352b",
                        "b889d6ec-330d-406f-87b6-ea34804fadfd",
                        "c3b374ba-8057-4dce-8510-cc83c5be2e00",
                        "cdef6e1d-a973-49dc-9548-147c231c061f",
                        "d130ecec-e5cf-4f59-b4f8-1cbda4b0c307",
                        "d3b865bc-69e2-4426-9e7a-d01f0180a3ec",
                        "d44f2bdb-efce-4435-91e3-e7d8b6972604",
                        "e62ff43e-b9cf-4db3-91ad-8e1e74384a7c",
                        "ea3e7ab3-e7c2-4007-93db-5c459bf3f42e",
                        "ebbbb0e3-5789-4dd0-b5f3-a911e59df314",
                        "f780a374-9a90-4ce3-951d-071db1e0ba9e",
                        "ffe77764-a254-4316-887e-c65bd4da6185"
                    ],
                    "keyword": [
                        "classifier",
                        "templates",
                        "set",
                        "rules",
                        "fusion",
                        "decision",
                        "similarity",
                        "measure",
                        "combination",
                        "class"
                    ],
                    "group": [],
                    "_id": "67046388-ae78-4aa4-ad8a-4f012858f6fb",
                    "abstract": "Multiple classifier fusion may generate more accurate classification than each of the constituent classifiers. Fusion is often based on fixed combination rules like the product and average. Only under strict probabilistic conditions can these rules be justified. We present here a simple rule for adapting the class combiner to the application.  c  decision templates (one per class) are estimated with the same training set that is used for the set of classifiers. These templates are then matched to the decision profile of new incoming objects by some similarity measure. We compare 11 versions of our model with 14 other techniques for classifier fusion on the Satimage and Phoneme datasets from the database ELENA. Our results show that decision templates based on  integral  type measures of similarity are superior to the other schemes on both data sets.",
                    "title": "Decision templates for multiple classifier fusion: an experimental comparison",
                    "venue": "Pattern Recognition",
                    "year": 2001,
                    "__v": 1,
                    "citationCount": 413,
                    "result": 7.420806288729292
                },
                "7cd3d1bf-4df0-46c8-9e75-701534e5d93c": {
                    "authors": [
                        "David W. Opitz",
                        "Jude W. Shavlik"
                    ],
                    "references": [
                        "0e19f258-9fed-4e5c-ae34-83be9cccae31",
                        "1d48d76c-e82c-4ba5-a354-5db0b1ce05da",
                        "1defeff4-5a9b-491d-84b0-30b990d6c121",
                        "3213ae6b-6091-41e6-9a25-5eeb48600d90",
                        "4e80450b-37ed-440c-87cc-d17d27e0d892",
                        "5206bed9-d48d-44ab-b0cd-4731dfe5679c",
                        "6565053d-ddb6-4e27-967a-ea8f8021df4b",
                        "6a6b9aa6-683f-4c7c-b06e-9c3018d10fd3",
                        "6c68311c-2745-446f-9c09-df4632392a78",
                        "84806dbe-fa0e-47c0-b1f2-00fb2eed25a7",
                        "b889d6ec-330d-406f-87b6-ea34804fadfd",
                        "db26488d-78be-44b1-a343-e896f43c5d29",
                        "f5769af3-dc6c-4a61-8b2c-7972719db66f",
                        "fc603eb6-d237-4584-842c-c80805f31370"
                    ],
                    "keyword": [
                        "set",
                        "network",
                        "addemup",
                        "trained",
                        "highly",
                        "ensemble",
                        "creating",
                        "accurate",
                        "technique",
                        "show"
                    ],
                    "group": [],
                    "_id": "7cd3d1bf-4df0-46c8-9e75-701534e5d93c",
                    "abstract": "A neural network NN ensemble is a very successful technique where the outputs of a set of separately trained NNs are combined to form one unified prediction. An effective ensemble should consist of a set of networks that are not only highly correct, but ones that make their errors on different parts of the input space as well; however, most existing techniques only indirectly address the problem of creating such a set. We present an algorithm called ADDEMUP that uses genetic algorithms to search explicitly for a highly diverse set of accurate trained networks. ADDEMUP works by first creating an initial population, then uses genetic operators to create new networks continually, keeping the set of networks that are highly accurate while disagreeing with each other as much as possible. Experiments on four real-world domains show that ADDEMUP is able to generate a set of trained networks that is more accurate than several existing ensemble approaches. Experiments also show ADDEMUP is able to incorporate prior...",
                    "title": "Actively Searching for an Effective Neural Network Ensemble",
                    "venue": "Connection Science",
                    "year": 1996,
                    "__v": 1,
                    "citationCount": 124,
                    "result": 4.30780622885886
                },
                "9e1ac4ec-85bf-4b41-b3f1-d12264b9352b": {
                    "authors": [
                        "Ethem Alpaydin",
                        "Michael I. Jordan"
                    ],
                    "references": [
                        "b4c5a572-c0a9-41e3-8782-9d4ee8105d81",
                        "b889d6ec-330d-406f-87b6-ea34804fadfd",
                        "d4f3fc71-3e7b-4044-81c9-42096677fa79",
                        "e3dc812e-78dd-41a6-b87b-756e5a40cb46",
                        "ec0c146d-ff15-4f73-8ea1-55268340ab42",
                        "fc95b916-1e4d-4c45-862c-dd34a49e64ad"
                    ],
                    "keyword": [
                        "local",
                        "models",
                        "perceptrons",
                        "learning",
                        "cooperative",
                        "competitive",
                        "position",
                        "linear",
                        "generalization",
                        "function"
                    ],
                    "group": [],
                    "_id": "9e1ac4ec-85bf-4b41-b3f1-d12264b9352b",
                    "abstract": "A structure composed of local linear perceptrons for approximating global class discriminants is investigated. Such local linear models may be combined in a cooperative or competitive way. In the cooperative model, a weighted sum of the outputs of the local perceptrons is computed where the weight is a function of the distance between the input and the position of the local perceptron. In the competitive model, the cost function dictates a mixture model where only one of the local perceptrons give output. Learning of the local models' positions and the linear mappings they implement are coupled and both supervised. We show that this is preferable to the uncoupled case where the positions are trained in an unsupervised manner before the separate, supervised training of mappings. We use goodness criteria based on the cross-entropy and give learning equations for both the cooperative and competitive cases. The coupled and uncoupled versions of cooperative and competitive approaches are compared among themselves and with multilayer perceptrons of sigmoidal hidden units and radial basis functions (RBFs) of Gaussian units on the application of recognition of handwritten digits. The criteria of comparison are the generalization accuracy, learning time, and the number of free parameters. We conclude that even on such a high-dimensional problem, such local models are promising. They generalize much better than RBF's and use much less memory. When compared with multilayer perceptrons, we note that local models learn much faster and generalize as well and sometimes better with comparable number of parameters.",
                    "title": "Local linear perceptrons for classification",
                    "venue": "IEEE Transactions on Neural Networks",
                    "year": 1996,
                    "__v": 2,
                    "citationCount": 30,
                    "result": 7.6666116732013885
                },
                "becc43bc-a7b6-46e1-817e-553c84a4a6dd": {
                    "authors": [
                        "E. Bauer",
                        "Ron Kohavi"
                    ],
                    "references": [
                        "056e5059-9864-479b-8a2a-fb1cd3d2dd32",
                        "0587052d-9988-4c3f-8f82-3ffcf8da7c86",
                        "0f115eea-2272-431f-9f21-6d6789b2bbc9",
                        "17f811d8-8607-4270-bbec-1cc7883edd68",
                        "1d48d76c-e82c-4ba5-a354-5db0b1ce05da",
                        "28e70562-4760-4398-bbf3-04ecbcb2aca3",
                        "29a79d67-73a4-4990-9880-f9cc5b56c6f2",
                        "36313bb8-e0c2-4900-a399-3e772f9f51dc",
                        "3704f939-09a2-4e9f-b851-1261bcd310df",
                        "3a90b5d2-3377-4ffa-9545-9ef332679370",
                        "485598b2-ed73-4670-a44d-b0844f923fa4",
                        "62549bc2-e0b3-46e8-8d32-390dded105d5",
                        "66edaccf-b610-4e24-8576-04843d5c8386",
                        "7a10be82-6113-4f60-9e37-f35f2d9423c5",
                        "80ee4343-400a-48cc-b6b8-d66ad6ebb235",
                        "96d6d9b9-6d69-4c9a-b3f5-c8083966d55c",
                        "99f94622-f108-48a6-ae73-a2e39755698b",
                        "9d76dda0-0008-4ea3-b2b2-286ced3ab43d",
                        "c634b735-0df2-45a5-b1c0-92780dd5d088",
                        "cf740e2c-f5bf-4e0c-8375-2948d6dff2c7",
                        "d20df5c3-667b-42d4-a128-d5f0b649cc32",
                        "da4534a6-897c-4431-89ef-cd326bfaf9a8",
                        "db26488d-78be-44b1-a343-e896f43c5d29",
                        "db6f22d3-b01b-4d3d-999b-14fe80b7bbb7",
                        "e1662082-8ddd-4df1-90a9-c1f30382b3d0",
                        "e5519055-460a-4547-952b-d51cdc9202d4",
                        "e56921ad-e4e0-45e1-bd62-8da8a6db4a66",
                        "e8ad6740-ba4d-40d9-a5e0-2dc67157f0fd",
                        "ebb6a16c-1963-4bb4-927b-7f4756da1b25",
                        "ecbdb6b6-635d-4f79-be35-0200b5407a56",
                        "fc603eb6-d237-4584-842c-c80805f31370",
                        "fcb41378-32f7-4aab-8458-fc5a99d74f92"
                    ],
                    "keyword": [
                        "methods",
                        "error",
                        "adaboost",
                        "voting",
                        "variants",
                        "variance",
                        "show",
                        "algorithms"
                    ],
                    "group": [],
                    "_id": "becc43bc-a7b6-46e1-817e-553c84a4a6dd",
                    "abstract": "Methods for voting classification algorithms, such as Bagging and AdaBoost, have been shown to be very successful in improving the accuracy of certain classifiers for artificial and real-world datasets. We review these algorithms and describe a large empirical study comparing several variants in conjunction with a decision tree inducer (three variants) and a Naive-Bayes inducer. The purpose of the study is to improve our understanding of why and when these algorithms, which use perturbation, reweighting, and combination techniques, affect classification error. We provide a bias and variance decomposition of the error to show how different methods and variants influence these two terms. This allowed us to determine that Bagging reduced variance of unstable methods, while boosting methods (AdaBoost and Arc-x4) reduced both the bias and variance of unstable methods but increased the variance for Naive-Bayes, which was very stable. We observed that Arc-x4 behaves differently than AdaBoost if reweighting is used instead of resampling, indicating a fundamental difference. Voting variants, some of which are introduced in this paper, include: pruning versus no pruning, use of probabilistic estimates, weight perturbations (Wagging), and backfitting of data. We found that Bagging improves when probabilistic estimates in conjunction with no-pruning are used, as well as when the data was backfit. We measure tree sizes and show an interesting positive correlation between the increase in the average tree size in AdaBoost trials and its success in reducing the error. We compare the mean-squared error of voting methods to non-voting methods and show that the voting methods lead to large and significant reductions in the mean-squared errors. Practical problems that arise in implementing boosting algorithms are explored, including numerical instabilities and underflows. We use scatterplots that graphically show how AdaBoost reweights instances, emphasizing not only “hard” areas but also outliers and noise.",
                    "title": "An Empirical Comparison of Voting Classification Algorithms: Bagging, Boosting, and Variants",
                    "venue": "Machine Learning",
                    "year": 1999,
                    "__v": 2,
                    "citationCount": 914,
                    "result": 5.401677527838518
                },
                "d3b865bc-69e2-4426-9e7a-d01f0180a3ec": {
                    "authors": [
                        "Sung-Bae Cho",
                        "Jin H. Kim"
                    ],
                    "references": [
                        "12bef5ff-7027-43ce-a43e-afe0e722ff4b",
                        "20fb61d7-108f-4045-a45f-1c7db93c3476",
                        "4e631ef0-fad7-4dc0-901a-29af722c2169",
                        "84806dbe-fa0e-47c0-b1f2-00fb2eed25a7",
                        "b889d6ec-330d-406f-87b6-ea34804fadfd",
                        "bbfb243c-49ba-435a-8386-cfa9b0472a7a",
                        "c3b374ba-8057-4dce-8510-cc83c5be2e00",
                        "e62ff43e-b9cf-4db3-91ad-8e1e74384a7c"
                    ],
                    "keyword": [
                        "networks",
                        "neural",
                        "combining",
                        "technique",
                        "proposed",
                        "method",
                        "fuzzy"
                    ],
                    "group": [],
                    "_id": "d3b865bc-69e2-4426-9e7a-d01f0180a3ec",
                    "abstract": "In the area of artificial neural networks, the concept of combining multiple networks has been proposed as a new direction for the development of highly reliable neural network systems. The authors propose a method for multinetwork combination based on the fuzzy integral. This technique nonlinearly combines objective evidence, in the form of a fuzzy membership function, with subjective evaluation of the worth of the individual neural networks with respect to the decision. The experimental results with the recognition problem of on-line handwriting characters confirm the superiority of the presented method to the other voting techniques. >",
                    "title": "Combining multiple neural networks by fuzzy integral for robust classification",
                    "venue": "systems man and cybernetics",
                    "year": 1995,
                    "__v": 2,
                    "citationCount": 130,
                    "result": 2.2428218839983547
                },
                "d9809d9a-ccf7-44a2-9073-3ed158f9057f": {
                    "authors": [
                        "Ludmila I. Kuncheva"
                    ],
                    "references": [
                        "168f05e4-d428-4184-bfd5-e53bfd6644c4",
                        "30a94f8b-fbd3-4446-ac08-c5efd3406107",
                        "67046388-ae78-4aa4-ad8a-4f012858f6fb",
                        "6d15cd37-496d-44e1-8bfb-004621255173",
                        "705fd8bf-b2b5-4419-8206-236ba232aa8b",
                        "78ad74ce-af25-4b0f-85da-2e7d852964e9",
                        "d130ecec-e5cf-4f59-b4f8-1cbda4b0c307"
                    ],
                    "keyword": [
                        "estimating",
                        "classes",
                        "vote",
                        "uniform",
                        "spl",
                        "space",
                        "single",
                        "probability",
                        "posterior",
                        "point"
                    ],
                    "group": [],
                    "_id": "d9809d9a-ccf7-44a2-9073-3ed158f9057f",
                    "abstract": "We look at a single point in feature space, two classes, and L classifiers estimating the posterior probability for class /spl omega//sub 1/. Assuming that the estimates are independent and identically distributed (normal or uniform), we give formulas for the classification error for the following fusion methods: average, minimum, maximum, median, majority vote, and oracle.",
                    "title": "A theoretical study on six classifier fusion strategies",
                    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "year": 2002,
                    "__v": 2,
                    "citationCount": 273,
                    "result": 6.060780736739816
                },
                "f780a374-9a90-4ce3-951d-071db1e0ba9e": {
                    "authors": [
                        "Keung-Chi Ng",
                        "Bruce Abramson"
                    ],
                    "references": [
                        "3ad14896-9d69-4e65-8d9e-270f137093df",
                        "a5adfa76-d545-437a-ab47-44959a0256ae"
                    ],
                    "keyword": [
                        "opinions",
                        "contributors",
                        "size",
                        "oracle",
                        "diagnoses",
                        "perturbing",
                        "panel",
                        "generate",
                        "functions",
                        "decision"
                    ],
                    "group": [],
                    "_id": "f780a374-9a90-4ce3-951d-071db1e0ba9e",
                    "abstract": "Consensus diagnoses arise when several experts contribute their opinions about the relative merits of a series of competing hypothesis, and a single decision maker combines their responses and makes a decision without further discussion among the contributors. Consensus diagnoses were simulated by allowing an oracle to generate 'opinions' based on universal background knowledge and all available information about the specific problem being diagnosed. Contributors' opinions were generated by perturbing the oracle's opinion; the size of the perturbation depended on the contributor's degree of expertise. Several different aggregation functions were then used to reclaim the oracle's opinion from those of the contributors. The performance of these functions was compared as panel size and hypothesis-set size varied from two to ten. Comparative and individual analyses indicated that for panels assembled under circumstances similar to those of this study, small, simple methods work best. >",
                    "title": "Consensus diagnosis: a simulation study",
                    "venue": "systems man and cybernetics",
                    "year": 1992,
                    "__v": 2,
                    "citationCount": 32,
                    "result": 6.400180223151012
                }
            }
        ],
        "_id": "f6bd8b64-684d-429a-aab5-8ff3a2c23cd6",
        "abstract": "Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund & R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, aaa, 148–156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.",
        "title": "Random Forests",
        "venue": "Machine Learning",
        "year": 2001,
        "__v": 2,
        "citationCount": 7968
    },
    {
        "authors": [
            "J.N. Laneman",
            "Gregory W. Wornell"
        ],
        "references": [
            "064005b0-00e1-40c6-888b-a5c7314b6c68",
            "2659531e-eb9d-4dd5-b46f-10f66a4819c6",
            "324c0cc6-829c-4b4f-8ef4-5f2d9b34bf58",
            "48a5daf3-5217-4b07-8f66-82dd2934cba6",
            "720f59d2-acc3-4d5a-91c2-258d137d9647",
            "89925ea3-ffcc-406f-9b38-432275ce2bd9",
            "efcbfcea-e8b0-4ca9-a883-92f42f862307"
        ],
        "keyword": [
            "terminals",
            "protocols",
            "relay",
            "coded",
            "transmission",
            "spacetime",
            "diversity",
            "destination",
            "cooperative",
            "spatial"
        ],
        "group": [
            {
                "064005b0-00e1-40c6-888b-a5c7314b6c68": {
                    "authors": [
                        "Michael Gastpar",
                        "Martin Vetterli"
                    ],
                    "references": [
                        "748a2ab3-8b5f-4d0a-9e2d-af685089843a",
                        "89925ea3-ffcc-406f-9b38-432275ce2bd9",
                        "8cc9ea80-563f-4e62-bda9-8ff6d71cf6ae",
                        "b5741c8a-84a5-4b8d-9e5e-29d97732b48f",
                        "efcbfcea-e8b0-4ca9-a883-92f42f862307"
                    ],
                    "keyword": [],
                    "group": [],
                    "_id": "064005b0-00e1-40c6-888b-a5c7314b6c68",
                    "abstract": "Gupta and Kumar (see IEEE Transactions an Information Theory, vol.46, no.2, p.388-404, 2000) determined the capacity of wireless networks under certain assumptions, among them point-to-point coding, which excludes for example multi-access and broadcast codes. We consider essentially the same physical model of a wireless network under a different traffic pattern, namely the relay traffic pattern, but we allow for arbitrarily complex network coding. In our model, there is only one active source/destination pair, while all other nodes assist this transmission. We show code constructions leading to achievable rates and derive upper bounds from the max-flow min-cut theorem. It is shown that lower and upper bounds meet asymptotically as the number of nodes in the network goes to infinity, thus proving that the capacity of the wireless network with n nodes under the relay traffic pattern behaves like log n bits per second. This demonstrates also that network coding is essential: under the point-to-point coding assumption considered by Gupta et al., the achievable rate is constant, independent of the number of nodes. Moreover, the result of this paper has implications' and extensions to fading channels and to sensor networks.",
                    "title": "On the capacity of wireless networks: the relay case",
                    "venue": "international conference on computer communications",
                    "year": 2002,
                    "__v": 0,
                    "citationCount": 246,
                    "result": 2.8571428571428568
                },
                "48a5daf3-5217-4b07-8f66-82dd2934cba6": {
                    "authors": [
                        "Babak Hassibi",
                        "Bertrand M. Hochwald"
                    ],
                    "references": [
                        "03eca440-3c16-4758-9706-c853469f7d71",
                        "18c098e6-53d8-46a6-a5df-ec51e2c2336f",
                        "1ea643f1-3820-4ca3-9297-9ac9ee3c6be6",
                        "25d7ce16-e254-4d4c-97f4-1b575c0d3e24",
                        "2659531e-eb9d-4dd5-b46f-10f66a4819c6",
                        "2a69f973-4ad7-4d6c-bd17-27c13e58768c",
                        "2cf70f2e-9996-477e-9ba1-d02ec769c507",
                        "324c0cc6-829c-4b4f-8ef4-5f2d9b34bf58",
                        "4eec044b-7d46-4ebd-b387-4adca987ad43",
                        "748a2ab3-8b5f-4d0a-9e2d-af685089843a",
                        "7e78d227-bc04-4fa3-a38b-079ca5f71368",
                        "85bd9cc6-e41a-4fd4-8f3b-e776329efc4b",
                        "9b17227e-8fa9-4c0e-8487-4b05df9064eb",
                        "b99e567e-a281-41cb-a6ec-de5d0ec08063",
                        "cab91964-4e8d-4211-8d32-455cfd690b60",
                        "ebac2b26-3187-4435-88a2-049cb5463806",
                        "fbc50327-e90c-4509-a450-b9942f5b20d4"
                    ],
                    "keyword": [],
                    "group": [],
                    "_id": "48a5daf3-5217-4b07-8f66-82dd2934cba6",
                    "abstract": "Multiple-antenna systems that operate at high rates require simple yet effective space-time transmission schemes to handle the large traffic volume in real time. At rates of tens of bits per second per hertz, Vertical Bell Labs Layered Space-Time (V-BLAST), where every antenna transmits its own independent substream of data, has been shown to have good performance and simple encoding and decoding. Yet V-BLAST suffers from its inability to work with fewer receive antennas than transmit antennas-this deficiency is especially important for modern cellular systems, where a base station typically has more antennas than the mobile handsets. Furthermore, because V-BLAST transmits independent data streams on its antennas there is no built-in spatial coding to guard against deep fades from any given transmit antenna. On the other hand, there are many previously proposed space-time codes that have good fading resistance and simple decoding, but these codes generally have poor performance at high data rates or with many antennas. We propose a high-rate coding scheme that can handle any configuration of transmit and receive antennas and that subsumes both V-BLAST and many proposed space-time block codes as special cases. The scheme transmits substreams of data in linear combinations over space and time. The codes are designed to optimize the mutual information between the transmitted and received signals. Because of their linear structure, the codes retain the decoding simplicity of V-BLAST, and because of their information-theoretic optimality, they possess many coding advantages. We give examples of the codes and show that their performance is generally superior to earlier proposed methods over a wide range of rates and signal-to-noise ratios (SNRs).",
                    "title": "High-rate codes that are linear in space and time",
                    "venue": "IEEE Transactions on Information Theory",
                    "year": 2002,
                    "__v": 0,
                    "citationCount": 669,
                    "result": 2.8571428571428568
                },
                "720f59d2-acc3-4d5a-91c2-258d137d9647": {
                    "authors": [
                        "Lizhong Zheng",
                        "David Tse"
                    ],
                    "references": [
                        "03eca440-3c16-4758-9706-c853469f7d71",
                        "25d7ce16-e254-4d4c-97f4-1b575c0d3e24",
                        "2659531e-eb9d-4dd5-b46f-10f66a4819c6",
                        "324c0cc6-829c-4b4f-8ef4-5f2d9b34bf58",
                        "48a5daf3-5217-4b07-8f66-82dd2934cba6",
                        "748a2ab3-8b5f-4d0a-9e2d-af685089843a"
                    ],
                    "keyword": [
                        "tradeoff",
                        "scheme",
                        "multiple",
                        "channel",
                        "antennas",
                        "wireless",
                        "view",
                        "types",
                        "systems",
                        "simultaneously"
                    ],
                    "group": [],
                    "_id": "720f59d2-acc3-4d5a-91c2-258d137d9647",
                    "abstract": "Multiple antennas can be used for increasing the amount of diversity or the number of degrees of freedom in wireless communication systems. We propose the point of view that both types of gains can be simultaneously obtained for a given multiple-antenna channel, but there is a fundamental tradeoff between how much of each any coding scheme can get. For the richly scattered Rayleigh-fading channel, we give a simple characterization of the optimal tradeoff curve and use it to evaluate the performance of existing multiple antenna schemes.",
                    "title": "Diversity and multiplexing: a fundamental tradeoff in multiple-antenna channels",
                    "venue": "IEEE Transactions on Information Theory",
                    "year": 2003,
                    "__v": 2,
                    "citationCount": 1901,
                    "result": 8.084215947451241
                },
                "89925ea3-ffcc-406f-9b38-432275ce2bd9": {
                    "authors": [
                        "Piyush Gupta",
                        "P. Kumar"
                    ],
                    "references": [
                        "0c17b2f6-8003-44db-a49c-ee1e68638231",
                        "222e8196-b98b-47bc-a679-641bbf57b770",
                        "330841ef-6d92-4fe7-aebe-c8e7abaf9cd2",
                        "3b94e4f8-7325-456d-b51f-baf4b34cbd1e",
                        "52787900-26ba-4272-9e1f-42d9fd36943b",
                        "748a2ab3-8b5f-4d0a-9e2d-af685089843a",
                        "8cc9ea80-563f-4e62-bda9-8ff6d71cf6ae",
                        "b3d3944e-b2c0-4a5c-84ae-dd2da4c72459",
                        "e2bff54f-096f-43b2-9a40-8adf76b9435f",
                        "efcbfcea-e8b0-4ca9-a883-92f42f862307",
                        "f1b53f72-b185-4e4e-9b75-ebc637857809",
                        "f478067d-8d6a-433b-88c6-99806dcd81ee"
                    ],
                    "keyword": [
                        "networks",
                        "scheme",
                        "propose",
                        "channel",
                        "region",
                        "capacities"
                    ],
                    "group": [],
                    "_id": "89925ea3-ffcc-406f-9b38-432275ce2bd9",
                    "abstract": "We study communication networks of arbitrary size and topology and communicating over a general vector discrete memoryless channel (DMC). We propose an information-theoretic constructive scheme for obtaining an achievable rate region in such networks. Many well-known capacity-defining achievable rate regions can be derived as special cases of the proposed scheme. A few such examples are the physically degraded and reversely degraded relay channels, the Gaussian multiple-access channel, and the Gaussian broadcast channel. The proposed scheme also leads to inner bounds for the multicast and allcast capacities. Applying the proposed scheme to a specific wireless network of n nodes located in a region of unit area, we show that a transport capacity of /spl Theta/(n) bit-meters per second (bit-meters/s) is feasible in a certain family of networks, as compared to the best possible transport capacity of /spl Theta/(/spl radic/n) bit-meters/s in Gupta et al. (2000), where the receiver capabilities were limited. Even though the improvement is shown for a specific class of networks, a clear implication is that designing and employing more sophisticated multiuser coding schemes can provide sizable gains in at least some large wireless networks.",
                    "title": "Towards an information theory of large networks: an achievable rate region",
                    "venue": "international symposium on information theory",
                    "year": 2001,
                    "__v": 2,
                    "citationCount": 211,
                    "result": 4.2360455248226145
                },
                "efcbfcea-e8b0-4ca9-a883-92f42f862307": {
                    "authors": [
                        "Thomas M. Cover",
                        "Abbas El Gamal"
                    ],
                    "references": [
                        "0c17b2f6-8003-44db-a49c-ee1e68638231",
                        "6b638ffe-e01f-498a-a381-7fe9e33e3698",
                        "848461ba-2db6-47b3-9bdc-e9e40d882aea",
                        "850e2885-2353-4f5f-b1fd-632c68317493",
                        "c885e4cf-37b0-43ea-b2a2-c836eddeff8a",
                        "ea3d8027-171a-4c25-9186-f1d85d374081"
                    ],
                    "keyword": [
                        "relay",
                        "channel",
                        "x2",
                        "y1",
                        "y1x2",
                        "x2y",
                        "min",
                        "ix1",
                        "capacity"
                    ],
                    "group": [],
                    "_id": "efcbfcea-e8b0-4ca9-a883-92f42f862307",
                    "abstract": "A relay channel consists of an input x_{l} , a relay output y_{1} , a channel output y , and a relay sender x_{2} (whose transmission is allowed to depend on the past symbols y_{1} . The dependence of the received symbols upon the inputs is given by p(y,y_{1}|x_{1},x_{2}) . The channel is assumed to be memoryless. In this paper the following capacity theorems are proved. 1)If y is a degraded form of y_{1} , then C \\: = \\: \\max \\!_{p(x_{1},x_{2})} \\min \\,{I(X_{1},X_{2};Y), I(X_{1}; Y_{1}|X_{2})} . 2)If y_{1} is a degraded form of y , then C \\: = \\: \\max \\!_{p(x_{1})} \\max_{x_{2}} I(X_{1};Y|x_{2}) . 3)If p(y,y_{1}|x_{1},x_{2}) is an arbitrary relay channel with feedback from (y,y_{1}) to both x_{1} \\and x_{2} , then C\\: = \\: \\max_{p(x_{1},x_{2})} \\min \\,{I(X_{1},X_{2};Y),I \\,(X_{1};Y,Y_{1}|X_{2})} . 4)For a general relay channel, C \\: \\leq \\: \\max_{p(x_{1},x_{2})} \\min \\,{I \\,(X_{1}, X_{2};Y),I(X_{1};Y,Y_{1}|X_{2}) . Superposition block Markov encoding is used to show achievability of C , and converses are established. The capacities of the Gaussian relay channel and certain discrete relay channels are evaluated. Finally, an achievable lower bound to the capacity of the general relay channel is established.",
                    "title": "Capacity theorems for the relay channel",
                    "venue": "IEEE Transactions on Information Theory",
                    "year": 1979,
                    "__v": 2,
                    "citationCount": 2061,
                    "result": 2.7253393665158367
                }
            }
        ],
        "_id": "7ae0e791-2e2b-4504-a2fe-caa9b0589c44",
        "abstract": "We develop and analyze space-time coded cooperative diversity protocols for combating multipath fading across multiple protocol layers in a wireless network. The protocols exploit spatial diversity available among a collection of distributed terminals that relay messages for one another in such a manner that the destination terminal can average the fading, even though it is unknown a priori which terminals will be involved. In particular, a source initiates transmission to its destination, and many relays potentially receive the transmission. Those terminals that can fully decode the transmission utilize a space-time code to cooperatively relay to the destination. We demonstrate that these protocols achieve full spatial diversity in the number of cooperating terminals, not just the number of decoding relays, and can be used effectively for higher spectral efficiencies than repetition-based schemes. We discuss issues related to space-time code design for these protocols, emphasizing codes that readily allow for appealing distributed versions.",
        "title": "Distributed space-time-coded protocols for exploiting cooperative diversity in wireless networks",
        "venue": "IEEE Transactions on Information Theory",
        "year": 2003,
        "__v": 1,
        "citationCount": 2191
    },
    {
        "authors": [
            "Mark Everingham",
            "Luc J. Van Gool",
            "Christopher K. I. Williams",
            "John Winn",
            "Andrew Zisserman"
        ],
        "references": [
            "08877f4f-6266-44d8-83d6-6fa9070e0729",
            "1f520d1a-5870-477d-85d7-0f50be690ea7",
            "1f556c88-b553-4c75-b243-92d8200f8149",
            "23120ec2-cd0d-48ed-abef-567a3f9ea103",
            "319f5c0d-b3f1-4f4e-a553-03c887f50e3c",
            "32a53bab-1ede-4869-98ad-d2ff0c1e3367",
            "364d2f61-6575-464a-9be2-1138b3b64c4a",
            "3ac62b27-10f6-41a7-9489-20c68399d826",
            "433969bb-d29f-4cac-83a5-ccfb5c6c7b4e",
            "470a4f23-7661-44a2-b1fe-a370995631d1",
            "52b16eb0-053c-42d3-9713-d4b631dac23a",
            "52dbf565-81ab-439e-a9af-6c4d6ae302f8",
            "61447020-9a4b-4742-affd-fb5cde9d84ae",
            "7af6585a-b797-47ad-84f3-a8fec553f67a",
            "80c70167-d4e9-46e5-aeb9-a2d91df48db1",
            "86ba72ef-465f-44dc-8068-cdd6a64f0b40",
            "8b8a2247-bd77-4736-b493-449734f56b9a",
            "98801e79-fc9d-4c6a-a383-10e937c9d008",
            "99a51496-fcec-4bf4-aa14-0f548bc20a57",
            "9aea2ad1-64c1-4e32-b991-1333e5b60a13",
            "a1e856ee-3e21-4efd-bc25-86201dd71737",
            "a96a19b9-2924-4231-9da7-ad1860d23480",
            "aa767a83-de19-4421-bfb4-f63808992758",
            "ac5e3fe4-3b1d-412d-a03b-3247d39f62d5",
            "ad4f81d3-cba5-4db2-9044-93962e883865",
            "b3e241a6-126f-40fb-a063-8ed7d0223a3c",
            "b624c279-af53-46e8-97ef-cc7e8a1c2d55",
            "b944f77f-113b-4a02-ae5e-d4a124b8fd5b",
            "c0a960bd-3739-41ed-9b84-f1e12f28795d",
            "c31657cb-cc9b-4947-b9dd-5a40de643bbe",
            "c70a5a06-395e-452e-bec8-01807cf4be7e",
            "c7ffa962-3c2c-4298-b32a-745510e8ef9f",
            "cb5e3b2d-a97e-461f-b99e-d4593d0ef2d7",
            "cfbc794e-0fa7-4d5b-be73-f5f03c5a1f9d",
            "d5e01b64-7902-4df0-a768-43c2a8e1739e",
            "d8da60d2-11fb-4c95-ad08-d077828e994d",
            "dc2c4901-c7cd-405f-b549-fad267d3f5bd",
            "dd83785a-dd19-41e3-9b25-ebabbd48d336",
            "e0ac4812-7729-4a2d-8a1f-74b1b7c8eb5d",
            "e75d8e62-a86d-4241-953f-1b315005d920",
            "e8736260-dc56-4097-a88c-24c9e189e91c",
            "e88433aa-0835-4c0e-88d0-1165ab4ac4f8",
            "eba773db-f6b9-4fb3-9112-61cd10e0c754",
            "ed835ca3-7120-4646-afaf-20c04a57c698",
            "ee9b186c-b7f0-4323-8f28-a55bbbd62b71",
            "fc780759-4533-4b33-9774-746ca210842f",
            "ffa31d0c-ff37-4bf3-b213-6d8a968e6636",
            "ffc56f7f-1295-4647-a1f7-e44ea58f93f2"
        ],
        "keyword": [
            "object",
            "methods",
            "evaluation",
            "detection",
            "dataset",
            "challenge",
            "visual",
            "standard",
            "procedures",
            "paper"
        ],
        "group": [
            {
                "52b16eb0-053c-42d3-9713-d4b631dac23a": {
                    "authors": [
                        "Ondrej Chum",
                        "Andrew Zisserman"
                    ],
                    "references": [
                        "16f04f94-f300-4806-bcc5-ee2cb628e5a7",
                        "1f556c88-b553-4c75-b243-92d8200f8149",
                        "21094c3c-478e-4d91-8ae6-9ff240ebfc6f",
                        "306cd2d8-9cde-40bb-a2c8-b9196c453b97",
                        "4be30a9d-647a-4b97-815e-e6e8a7fe6e82",
                        "54f4f826-441a-40d1-9860-4d0d27c11867",
                        "5d7a9371-b15a-4635-b92b-46a8a31c214c",
                        "6018a516-8149-4bce-bc33-5449d86e58c2",
                        "81f384cb-72e0-4e86-8df2-582b17864c6e",
                        "94c8a558-ef68-4796-91aa-827901e2fde3",
                        "a74b3c2b-0710-4648-afb1-298f23b47030",
                        "c17b4778-a9d9-4213-8967-c5e8ed708ea0",
                        "c455fb04-4566-4648-ad6f-3cf2245e507c",
                        "d486ab6f-98b8-46a1-8ae2-521ebd7391d6",
                        "dd83785a-dd19-41e3-9b25-ebabbd48d336",
                        "e0ac4812-7729-4a2d-8a1f-74b1b7c8eb5d",
                        "ea64f6ce-6ad4-4e2d-ad18-24c25ff99870"
                    ],
                    "keyword": [
                        "training",
                        "objective",
                        "model",
                        "images",
                        "class",
                        "visual",
                        "set",
                        "test",
                        "requiring",
                        "region"
                    ],
                    "group": [],
                    "_id": "52b16eb0-053c-42d3-9713-d4b631dac23a",
                    "abstract": "We introduce an exemplar model that can learn and generate a region of interest around class instances in a training set, given only a set of images containing the visual class. The model is scale and translation invariant. In the training phase, image regions that optimize an objective function are automatically located in the training images, without requiring any user annotation such as bounding boxes. The objective function measures visual similarity between training image pairs, using the spatial distribution of both appearance patches and edges. The optimization is initialized using discriminative features. The model enables the detection (localization) of multiple instances of the object class in test images, and can be used as a precursor to training other visual models that require bounding box annotation. The detection performance of the model is assessed on the PASCAL Visual Object Classes Challenge 2006 test set. For a number of object classes the performance far exceeds the current state of the art of fully supervised methods.",
                    "title": "An Exemplar Model for Learning Object Classes",
                    "venue": "computer vision and pattern recognition",
                    "year": 2007,
                    "__v": 2,
                    "citationCount": 161,
                    "result": 6.80053720789015
                },
                "52dbf565-81ab-439e-a9af-6c4d6ae302f8": {
                    "authors": [
                        "Pedro F. Felzenszwalb",
                        "David A. McAllester",
                        "Deva Ramanan"
                    ],
                    "references": [
                        "0149d4d7-6775-4387-9098-d02ddb7dbc58",
                        "0d21b163-cce6-4dc5-bb12-1f6c7e709436",
                        "13d83701-8e72-482a-882e-fc1450146d6e",
                        "202da7f7-a7fc-4026-b535-b2c938c5567a",
                        "3c49df6f-3b50-450f-aa93-4c715cfd05af",
                        "651454cb-eb8b-4f08-8f7a-b40f6b55b998",
                        "67f92163-023b-4655-8abe-acf23dc38aea",
                        "6f6fe122-6003-498c-a584-b27b3f7a6be3",
                        "81eec382-cc0a-4381-91df-a90054925734",
                        "83c737b8-e084-4766-ba6e-131e6a1c017c",
                        "8f5cecf7-c1dc-4400-8af3-739409424dac",
                        "9f84e529-87a3-42f1-9d63-9af710f40925",
                        "c455fb04-4566-4648-ad6f-3cf2245e507c",
                        "c45e6f71-1ad4-4971-b22f-12f3af34379f",
                        "dbc47800-7dc3-46da-94d3-70120f07f13a",
                        "dd83785a-dd19-41e3-9b25-ebabbd48d336",
                        "ed8a9624-3abe-4b5e-bffe-5b3ecc34e841",
                        "ef35a024-f5f3-4a7b-b6f6-61d9167385e6",
                        "fc780759-4533-4b33-9774-746ca210842f"
                    ],
                    "keyword": [
                        "latent",
                        "trained",
                        "model",
                        "system",
                        "svm",
                        "part",
                        "deformable",
                        "challenge",
                        "relies",
                        "problem"
                    ],
                    "group": [],
                    "_id": "52dbf565-81ab-439e-a9af-6c4d6ae302f8",
                    "abstract": "This paper describes a discriminatively trained, multiscale, deformable part model for object detection. Our system achieves a two-fold improvement in average precision over the best performance in the 2006 PASCAL person detection challenge. It also outperforms the best results in the 2007 challenge in ten out of twenty categories. The system relies heavily on deformable parts. While deformable part models have become quite popular, their value had not been demonstrated on difficult benchmarks such as the PASCAL challenge. Our system also relies heavily on new methods for discriminative training. We combine a margin-sensitive approach for data mining hard negative examples with a formalism we call latent SVM. A latent SVM, like a hidden CRF, leads to a non-convex training problem. However, a latent SVM is semi-convex and the training problem becomes convex once latent information is specified for the positive examples. We believe that our training methods will eventually make possible the effective use of more latent information such as hierarchical (grammar) models and models involving latent three dimensional pose.",
                    "title": "A discriminatively trained, multiscale, deformable part model",
                    "venue": "computer vision and pattern recognition",
                    "year": 2008,
                    "__v": 2,
                    "citationCount": 916,
                    "result": 4.7391050126344245
                },
                "7af6585a-b797-47ad-84f3-a8fec553f67a": {
                    "authors": [
                        "Nicolas Pinto",
                        "David D. Cox",
                        "James J. DiCarlo"
                    ],
                    "references": [
                        "17aaf448-d7d7-48fa-b536-876dc59c7edb",
                        "20f52431-62f1-4670-ba81-d19ef3c04204",
                        "32a53bab-1ede-4869-98ad-d2ff0c1e3367",
                        "55e72675-ff9a-46fc-b7c8-859c6db0d258",
                        "5ad47e8e-b112-480d-b8f3-3786fc2c0a5a",
                        "820b9eee-e009-4dc1-b464-f5fd4485d6b3",
                        "a4d9008a-d15b-4d87-a173-bef2f4b0d453",
                        "b944f77f-113b-4a02-ae5e-d4a124b8fd5b",
                        "c1b6b493-01ef-420f-be44-7bacfe34e846",
                        "c9482f1f-6600-44a7-a69a-e63ef13cdff8",
                        "ccdefe89-9b16-4c22-8bb8-bd314ccad6e1",
                        "dab2a721-01df-4ca9-aaf7-c4f1f6192ec1",
                        "e0ac4812-7729-4a2d-8a1f-74b1b7c8eb5d",
                        "e39d264d-1b9d-438a-a36b-81e133006b0f",
                        "ea64f6ce-6ad4-4e2d-ad18-24c25ff99870"
                    ],
                    "keyword": [
                        "images",
                        "natural",
                        "test",
                        "recognition",
                        "progress",
                        "object",
                        "models",
                        "show"
                    ],
                    "group": [],
                    "_id": "7af6585a-b797-47ad-84f3-a8fec553f67a",
                    "abstract": "Progress in understanding the brain mechanisms underlying vision requires the construction of computational models that not only emulate the brain's anatomy and physiology, but ultimately match its performance on visual tasks. In recent years, “natural” images have become popular in the study of vision and have been used to show apparently impressive progress in building such models. Here, we challenge the use of uncontrolled “natural” images in guiding that progress. In particular, we show that a simple V1-like model—a neuroscientist's “null” model, which should perform poorly at real-world visual object recognition tasks—outperforms state-of-the-art object recognition systems (biologically inspired and otherwise) on a standard, ostensibly natural image recognition test. As a counterpoint, we designed a “simpler” recognition test to better span the real-world variation in object pose, position, and scale, and we show that this test correctly exposes the inadequacy of the V1-like model. Taken together, these results demonstrate that tests based on uncontrolled natural images can be seriously misleading, potentially guiding progress in the wrong direction. Instead, we reexamine what it means for images to be natural and argue for a renewed focus on the core problem of object recognition—real-world image variation.",
                    "title": "Why is real-world visual object recognition hard?",
                    "venue": "PLOS Computational Biology",
                    "year": 2008,
                    "__v": 1,
                    "citationCount": 171,
                    "result": 5.725939411465728
                },
                "80c70167-d4e9-46e5-aeb9-a2d91df48db1": {
                    "authors": [
                        "Seyed Mohammadali Eslami",
                        "Christopher K. I. Williams"
                    ],
                    "references": [
                        "1e4f4b5c-55e0-4d5b-b7cc-9e7fada3e341",
                        "3e219b07-c272-4e1f-95bc-bb12fa57aff5",
                        "47e3a0fe-b2ad-495b-bfaa-ac0e4c723b8e",
                        "5ffadf36-4496-4be6-b8a8-828fa37f7757",
                        "6745f93c-bec1-4c70-aa5b-3fa565daa16a",
                        "80938b79-9126-40fc-8559-9753267a289e",
                        "81f384cb-72e0-4e86-8df2-582b17864c6e",
                        "859aa9d3-2e96-440b-87b9-32319e115cbc",
                        "871a5bd7-653f-4642-aacf-f50c71f6246e",
                        "89f10062-acf1-4171-b882-f3222c3a357e",
                        "8dffe72a-5e95-42ce-9878-4b6fd4f15d20",
                        "9e1e5288-5535-4753-90a8-8ce6595266f2",
                        "9f84e529-87a3-42f1-9d63-9af710f40925",
                        "bb38f1ba-9459-443f-a289-49ffd4277f7f",
                        "bf03f268-de9d-4a80-aee1-200990056503",
                        "c455fb04-4566-4648-ad6f-3cf2245e507c",
                        "c6f6c303-03c3-4775-ad87-545f0758ed46",
                        "c9482f1f-6600-44a7-a69a-e63ef13cdff8",
                        "d4d98193-fa86-445e-a140-959c646323a7",
                        "d62268eb-4a8f-4ca7-abb7-fe518745c7d6",
                        "dc450afe-d272-4900-940c-8055d8a4eb4b",
                        "fc256ee2-74d0-465d-9dc4-5cb3f7a4879d"
                    ],
                    "keyword": [
                        "shapes",
                        "representations",
                        "object",
                        "model",
                        "datasets",
                        "variability",
                        "learning",
                        "fsa",
                        "factored"
                    ],
                    "group": [],
                    "_id": "80c70167-d4e9-46e5-aeb9-a2d91df48db1",
                    "abstract": "We present a novel generative framework for learning parts-based representations of object classes. Our model, Factored Shapes and Appearances (FSA), employs a highly factored representation to reason about appearance and shape variability across datasets of images. We propose Markov Chain Monte Carlo sampling schemes for efficient inference and learning, and evaluate the model on a number of datasets. Here we consider datasets that exhibit large amounts of variability, both in the shapes of objects in the scene, and in their appearances. We show that the FSA model extracts meaningful parts from training data, and that its parameters and representation can be used to perform a range of tasks, including object parsing, segmentation and fine-grained categorisation.",
                    "title": "Factored Shapes and Appearances for Parts-based Object Understanding",
                    "venue": "british machine vision conference",
                    "year": 2011,
                    "__v": 2,
                    "citationCount": 142,
                    "result": 6.586481548767859
                },
                "86ba72ef-465f-44dc-8068-cdd6a64f0b40": {
                    "authors": [
                        "Erik B. Sudderth",
                        "Antonio Torralba",
                        "William T. Freeman",
                        "Alan S. Willsky"
                    ],
                    "references": [
                        "00da6a0e-aa5d-4f92-b3a0-21c976e11330",
                        "1f530e4a-3e5b-4805-8110-0a08b6e34daa",
                        "26316adf-569e-49bc-a289-c1ba311624f6",
                        "327d0f9c-712e-48b5-a95b-602476e52c4f",
                        "32a53bab-1ede-4869-98ad-d2ff0c1e3367",
                        "413a4059-597f-4c9e-81e5-a9f35ffea422",
                        "499cc537-1061-4ccf-a508-229711a2f837",
                        "5d986892-456b-4b2e-9742-7b281b12620b",
                        "5e14ceb5-b390-4e43-8633-712cd9e7b33d",
                        "60285266-7da2-474e-b05a-b380c836f665",
                        "62f3bf9a-662e-40f8-bc26-7cc356562e8c",
                        "67f92163-023b-4655-8abe-acf23dc38aea",
                        "7aa3fb64-6ed5-4a29-aff7-f1180e259f79",
                        "7f6e8f66-f378-445a-a322-f2d08287fbe3",
                        "80fe1831-1c36-4c07-b4cc-3c1fce0fe075",
                        "820b9eee-e009-4dc1-b464-f5fd4485d6b3",
                        "84681b94-f21c-449a-9de4-ccc3b7ac27d7",
                        "8b8a2247-bd77-4736-b493-449734f56b9a",
                        "8bc5f80f-af26-47b4-aa0a-aab3a2e6c503",
                        "8d8e7d51-3223-4776-bf6a-40306774b8a1",
                        "94a26b29-62ba-47f0-9aa6-957e8a4c9d9c",
                        "9f84e529-87a3-42f1-9d63-9af710f40925",
                        "b592576f-ff29-4a68-9b2f-8a8ad02e9c70",
                        "b944f77f-113b-4a02-ae5e-d4a124b8fd5b",
                        "bf8efeb3-b93b-4d15-b99e-1c07516ee87c",
                        "c591c440-b19b-4d7b-b067-cd8c366b7d6d",
                        "c9409f7a-10f5-4271-aa39-5238cdafd05e",
                        "c9482f1f-6600-44a7-a69a-e63ef13cdff8",
                        "ccdefe89-9b16-4c22-8bb8-bd314ccad6e1",
                        "d7244347-76f9-4ff2-86c1-03798cd473f3",
                        "e05a6676-6e91-466e-b705-19e19b66e5a2",
                        "e2b15895-4fe8-4952-bfc4-30ceca2366e8",
                        "e9d32426-c3a6-41b0-be95-43e999c9022e",
                        "ed835ca3-7120-4646-afaf-20c04a57c698",
                        "efc03a99-91de-4c6d-9cc4-4c2813668fc7",
                        "fc4a70a7-80c5-43c8-a68f-0a72a46ecce8",
                        "ffa029cf-7240-4723-8339-51fac57f9f28",
                        "ffa31d0c-ff37-4bf3-b213-6d8a968e6636"
                    ],
                    "keyword": [
                        "objects",
                        "scenes",
                        "models",
                        "parts",
                        "transformations",
                        "processes",
                        "learning",
                        "images",
                        "dirichlet",
                        "develop"
                    ],
                    "group": [],
                    "_id": "86ba72ef-465f-44dc-8068-cdd6a64f0b40",
                    "abstract": "We develop hierarchical, probabilistic models for objects, the parts composing them, and the visual scenes surrounding them. Our approach couples topic models originally developed for text analysis with spatial transformations, and thus consistently accounts for geometric constraints. By building integrated scene models, we may discover contextual relationships, and better exploit partially labeled training images. We first consider images of isolated objects, and show that sharing parts among object categories improves detection accuracy when learning from few examples. Turning to multiple object scenes, we propose nonparametric models which use Dirichlet processes to automatically learn the number of parts underlying each object category, and objects composing each scene. The resulting transformed Dirichlet process (TDP) leads to Monte Carlo algorithms which simultaneously segment and recognize objects in street and office scenes.",
                    "title": "Describing Visual Scenes Using Transformed Objects and Parts",
                    "venue": "International Journal of Computer Vision",
                    "year": 2008,
                    "__v": 1,
                    "citationCount": 93,
                    "result": 6.633530578543366
                },
                "8b8a2247-bd77-4736-b493-449734f56b9a": {
                    "authors": [
                        "Paul A. Viola",
                        "Michael J. Jones"
                    ],
                    "references": [
                        "13cd743f-beb9-43a1-8e08-2ef08f0d8b3f",
                        "17f811d8-8607-4270-bbec-1cc7883edd68",
                        "245e4043-ccdb-457a-9be1-e120c7a94753",
                        "310cbba4-d88d-4bf4-a4f2-738f91b5f8c8",
                        "36800655-b2ff-4eb7-9070-c6be304c4baa",
                        "43530fe4-10a9-4ddf-b61d-8844f0ff3f04",
                        "55fa440a-2b98-4e8e-bb45-fa09598b4eca",
                        "5ffac6f9-2456-42cf-830c-9049ce37c899",
                        "613841ae-c925-4aee-9c2e-8675213e4bbf",
                        "62d0a064-3808-4bc0-99bd-f007359ce651",
                        "6d121e97-e351-4cf9-8c44-d7ab3ce9d9fe",
                        "8f6a657e-e387-4572-bb88-91aee042e8da",
                        "9fa55b0f-eaa6-4c59-b6e5-77e5f1a406f0",
                        "b49c1e2b-0cd0-4950-a724-00c698e5b49d",
                        "c7f93552-c1ef-4ae4-b1f5-2317e1c9d904",
                        "d5e5a24d-f80e-4f1a-b48b-22403b653276",
                        "d6e37fb1-5f7e-448e-847b-7d1f1271c574",
                        "db26488d-78be-44b1-a343-e896f43c5d29",
                        "f1bd37c4-d033-4cd1-af44-4df9f11c71e4",
                        "f4642ffc-3571-4d02-8b94-142f2448023a"
                    ],
                    "keyword": [
                        "detection",
                        "images",
                        "face",
                        "features",
                        "system",
                        "set",
                        "regions",
                        "quickly",
                        "contributions",
                        "computed"
                    ],
                    "group": [
                        null
                    ],
                    "_id": "8b8a2247-bd77-4736-b493-449734f56b9a",
                    "abstract": "This paper describes a face detection framework that is capable of processing images extremely rapidly while achieving high detection rates. There are three key contributions. The first is the introduction of a new image representation called the “Integral Image” which allows the features used by our detector to be computed very quickly. The second is a simple and efficient classifier which is built using the AdaBoost learning algorithm (Freund and Schapire, 1995) to select a small number of critical visual features from a very large set of potential features. The third contribution is a method for combining classifiers in a “cascade” which allows background regions of the image to be quickly discarded while spending more computation on promising face-like regions. A set of experiments in the domain of face detection is presented. The system yields face detection performance comparable to the best previous systems (Sung and Poggio, 1998; Rowley et al., 1998; Schneiderman and Kanade, 2000; Roth et al., 2000). Implemented on a conventional desktop, face detection proceeds at 15 frames per second.",
                    "title": "Robust real-time face detection",
                    "venue": "international conference on computer vision",
                    "year": 2001,
                    "__v": 3,
                    "citationCount": 4436,
                    "result": 5.863838612368026
                },
                "98801e79-fc9d-4c6a-a383-10e937c9d008": {
                    "authors": [
                        "Luis von Ahn",
                        "Laura Dabbish"
                    ],
                    "references": [
                        "2abf79b0-be53-4978-a81e-bf05f9d7a638",
                        "4fb6d9a0-f461-4603-ac8c-0109b0a70ec3",
                        "cb5e3b2d-a97e-461f-b99e-d4593d0ef2d7",
                        "d5321e41-3281-4557-ac5a-5c0389818822",
                        "d8b8efc0-4de2-47e0-b05b-5959b61090a5",
                        "ed8a9624-3abe-4b5e-bffe-5b3ecc34e841"
                    ],
                    "keyword": [
                        "images",
                        "game",
                        "labels",
                        "work",
                        "web",
                        "valuable",
                        "system",
                        "providing",
                        "play",
                        "people"
                    ],
                    "group": [],
                    "_id": "98801e79-fc9d-4c6a-a383-10e937c9d008",
                    "abstract": "We introduce a new interactive system: a game that is fun and can be used to create valuable output. When people play the game they help determine the contents of images by providing meaningful labels for them. If the game is played as much as popular online games, we estimate that most images on the Web can be labeled in a few months. Having proper labels associated with each image on the Web would allow for more accurate image search, improve the accessibility of sites (by providing descriptions of images to visually impaired individuals), and help users block inappropriate images. Our system makes a significant contribution because of its valuable output and because of the way it addresses the image-labeling problem. Rather than using computer vision techniques, which don't work well enough, we encourage people to do the work by taking advantage of their desire to be entertained.",
                    "title": "Labeling images with a computer game",
                    "venue": "human factors in computing systems",
                    "year": 2004,
                    "__v": 2,
                    "citationCount": 967,
                    "result": 3.0379803203332614
                },
                "a96a19b9-2924-4231-9da7-ad1860d23480": {
                    "authors": [
                        "Derek Hoiem",
                        "Alexei A. Efros",
                        "Martial Hebert"
                    ],
                    "references": [
                        "00da6a0e-aa5d-4f92-b3a0-21c976e11330",
                        "2c5f401d-b50c-4697-aef6-2ff7caed3b72",
                        "32a53bab-1ede-4869-98ad-d2ff0c1e3367",
                        "33ef0eb5-c4b5-4810-b528-74b4605efc52",
                        "40bbddd1-5e44-4372-9fe4-27fd7d6aafd7",
                        "5057898e-bc25-4969-a4b4-881ba80d6783",
                        "57b3e9a4-5b74-4397-9ee3-00d7df58a771",
                        "5ad7276f-f084-4a24-8187-57873f008c82",
                        "5f70f18c-5f9c-442e-ae2c-ee6aadecab95",
                        "68bd97cf-3d10-4382-a690-3649a2b695c1",
                        "6f5f8d69-4439-4080-b2ce-b1da049b11c3",
                        "74cfc504-79ca-454f-b8ed-86eced93f44a",
                        "82d0ec51-e40e-4602-b969-fc0b44464ac3",
                        "8341f8ac-a713-45b9-845c-c32abe2fca00",
                        "85415160-c71b-49de-b62a-7cf8ee2a60a8",
                        "8b8a2247-bd77-4736-b493-449734f56b9a",
                        "c92c2419-c837-4e80-8890-ac92d8d0cb3e",
                        "d3e00e7e-1c64-4d7a-b2b2-1ad98ba4c706",
                        "dd83785a-dd19-41e3-9b25-ebabbd48d336",
                        "e05a6676-6e91-466e-b705-19e19b66e5a2",
                        "e4f59ab1-c7e5-4734-a310-c85fa75f26a5"
                    ],
                    "keyword": [
                        "object",
                        "image",
                        "world",
                        "understanding",
                        "surface",
                        "scales",
                        "probabilistic",
                        "modeling",
                        "locations",
                        "geometry"
                    ],
                    "group": [],
                    "_id": "a96a19b9-2924-4231-9da7-ad1860d23480",
                    "abstract": "Image understanding requires not only individually estimating elements of the visual world but also capturing the interplay among them. In this paper, we provide a framework for placing local object detection in the context of the overall 3D scene by modeling the interdependence of objects, surface orientations, and camera viewpoint. Most object detection methods consider all scales and locations in the image as equally likely. We show that with probabilistic estimates of 3D geometry, both in terms of surfaces and world coordinates, we can put objects into perspective and model the scale and location variance in the image. Our approach reflects the cyclical nature of the problem by allowing probabilistic object hypotheses to refine geometry and vice-versa. Our framework allows painless substitution of almost any object detector and is easily extended to include other aspects of image understanding. Our results confirm the benefits of our integrated approach.",
                    "title": "Putting Objects in Perspective",
                    "venue": "computer vision and pattern recognition",
                    "year": 2006,
                    "__v": 2,
                    "citationCount": 483,
                    "result": 7.179496105889294
                },
                "ac5e3fe4-3b1d-412d-a03b-3247d39f62d5": {
                    "authors": [
                        "Florent Perronnin",
                        "Christopher R. Dance"
                    ],
                    "references": [
                        "4adf6a1e-3672-45f4-970f-08752797e37b",
                        "8d6ce1fa-f13c-4b8d-9c55-1d46364fb5d0",
                        "98916c1f-4030-4ac0-a186-2e2e60188701",
                        "b7850d71-2cee-4c3b-9d53-216d63ca0515",
                        "b944f77f-113b-4a02-ae5e-d4a124b8fd5b",
                        "b9c9a059-d63a-4abe-9403-449f2352391a",
                        "d770d0c0-c792-42ee-a340-3a98fe34a060",
                        "d8253317-f868-432f-bae4-633f767324db",
                        "ec8c9e00-d026-4d33-b102-ffd5389234cd"
                    ],
                    "keyword": [
                        "model",
                        "image",
                        "generative",
                        "databases",
                        "vocabulary",
                        "training",
                        "signal",
                        "set",
                        "performance",
                        "kernel"
                    ],
                    "group": [],
                    "_id": "ac5e3fe4-3b1d-412d-a03b-3247d39f62d5",
                    "abstract": "Within the field of pattern classification, the Fisher kernel is a powerful framework which combines the strengths of generative and discriminative approaches. The idea is to characterize a signal with a gradient vector derived from a generative probability model and to subsequently feed this representation to a discriminative classifier. We propose to apply this framework to image categorization where the input signals are images and where the underlying generative model is a visual vocabulary: a Gaussian mixture model which approximates the distribution of low-level features in images. We show that Fisher kernels can actually be understood as an extension of the popular bag-of-visterms. Our approach demonstrates excellent performance on two challenging databases: an in-house database of 19 object/scene categories and the recently released VOC 2006 database. It is also very practical: it has low computational needs both at training and test time and vocabularies trained on one set of categories can be applied to another set without any significant loss in performance.",
                    "title": "Fisher Kernels on Visual Vocabularies for Image Categorization",
                    "venue": "computer vision and pattern recognition",
                    "year": 2007,
                    "__v": 2,
                    "citationCount": 580,
                    "result": 5.367250516940918
                },
                "ad4f81d3-cba5-4db2-9044-93962e883865": {
                    "authors": [
                        "Rob Fergus",
                        "Pietro Perona",
                        "Andrew Zisserman"
                    ],
                    "references": [
                        "0ca9c674-29f9-48e5-a4bd-9e30f16f70c7",
                        "21094c3c-478e-4d91-8ae6-9ff240ebfc6f",
                        "21a8e8fd-0172-4e9a-8474-7024eb0bf979",
                        "2d6c9f60-ea78-44a8-b5f9-6964575dd196",
                        "32d69633-581f-4460-b272-49937d4a3550",
                        "3c49df6f-3b50-450f-aa93-4c715cfd05af",
                        "473cf1a4-9f42-4e6d-b34f-77787f329079",
                        "509e1ae2-768b-4417-bebe-d90cf1e0fdae",
                        "5a0fc7dd-52bf-420d-9620-f5013330dac5",
                        "5e029b9f-871f-4d45-b869-fc5d7376fa55",
                        "613841ae-c925-4aee-9c2e-8675213e4bbf",
                        "81eec382-cc0a-4381-91df-a90054925734",
                        "820b9eee-e009-4dc1-b464-f5fd4485d6b3",
                        "9f5f1500-0df7-4675-8290-b47979bcad38",
                        "a5254ae0-1ce1-4390-b9f8-8d5a3dcb1e62",
                        "a74b3c2b-0710-4648-afb1-298f23b47030",
                        "bf664a72-1007-43e6-8dff-f1b0de9b5740",
                        "c32b12e9-a542-458d-8611-4a22e5193730",
                        "c455fb04-4566-4648-ad6f-3cf2245e507c",
                        "c591c440-b19b-4d7b-b067-cd8c366b7d6d",
                        "caeecc11-ec92-47d8-b112-c43b88dd4491",
                        "ccdefe89-9b16-4c22-8bb8-bd314ccad6e1",
                        "d5e5a24d-f80e-4f1a-b48b-22403b653276",
                        "d6e37fb1-5f7e-448e-847b-7d1f1271c574",
                        "d7b1fba1-b5f8-4377-88a8-d2fc69f723b7",
                        "e649a9fd-f6d9-4aac-b428-29b82c20a484",
                        "ef35a024-f5f3-4a7b-b6f6-61d9167385e6",
                        "f111ff97-89a3-4df6-8f02-962d7b4fe985",
                        "fc4a70a7-80c5-43c8-a68f-0a72a46ecce8"
                    ],
                    "keyword": [
                        "categories",
                        "models",
                        "parts",
                        "object",
                        "training",
                        "likelihood",
                        "learning",
                        "images",
                        "generated",
                        "flexible"
                    ],
                    "group": [],
                    "_id": "ad4f81d3-cba5-4db2-9044-93962e883865",
                    "abstract": "We investigate a method for learning object categories in a weakly supervised manner. Given a set of images known to contain the target category from a similar viewpoint, learning is translation and scale-invariant; does not require alignment or correspondence between the training images, and is robust to clutter and occlusion. Category models are probabilistic constellations of parts, and their parameters are estimated by maximizing the likelihood of the training data. The appearance of the parts, as well as their mutual position, relative scale and probability of detection are explicitly described in the model. Recognition takes place in two stages. First, a feature-finder identifies promising locations for the model\"s parts. Second, the category model is used to compare the likelihood that the observed features are generated by the category model, or are generated by background clutter. The flexible nature of the model is demonstrated by results over six diverse object categories including geometrically constrained categories (e.g. faces, cars) and flexible objects (such as animals).",
                    "title": "Weakly Supervised Scale-Invariant Learning of Models for Visual Recognition",
                    "venue": "International Journal of Computer Vision",
                    "year": 2007,
                    "__v": 1,
                    "citationCount": 128,
                    "result": 4.707755806285218
                },
                "b3e241a6-126f-40fb-a063-8ed7d0223a3c": {
                    "authors": [
                        "Alexander Sorokin",
                        "David A. Forsyth"
                    ],
                    "references": [
                        "0e581f6f-d4f0-4b26-86f8-a94e94347eb3",
                        "22b6367e-032f-41fd-b1eb-f7f0827f2dfc",
                        "32a53bab-1ede-4869-98ad-d2ff0c1e3367",
                        "3f01f87d-9567-4d09-92cb-437d554dfa64",
                        "433969bb-d29f-4cac-83a5-ccfb5c6c7b4e",
                        "50deb9e0-e10b-40bd-a73f-c544285457e3",
                        "51f1493d-ce3b-4589-8373-55940026fecd",
                        "56f4b72a-ec39-47ac-8220-899296e7fb18",
                        "57e35e32-f009-4b9b-bfb2-3747eac40b72",
                        "5ae925f5-b38f-417b-90c3-b696e5bab998",
                        "5ea6e082-6427-4ac3-ac85-95f9232c8213",
                        "83c737b8-e084-4766-ba6e-131e6a1c017c",
                        "98801e79-fc9d-4c6a-a383-10e937c9d008",
                        "c8cc88b8-d971-49e9-8810-e784c856872f",
                        "dd83785a-dd19-41e3-9b25-ebabbd48d336",
                        "de7686aa-6d09-4f1f-90a3-ba7815808e1d",
                        "e39d264d-1b9d-438a-a36b-81e133006b0f",
                        "ff0d990e-90f3-4973-8541-5f7e595710aa"
                    ],
                    "keyword": [
                        "annotation",
                        "produced",
                        "describe",
                        "turk",
                        "task",
                        "strategies",
                        "show",
                        "results",
                        "quickly",
                        "quality"
                    ],
                    "group": [],
                    "_id": "b3e241a6-126f-40fb-a063-8ed7d0223a3c",
                    "abstract": "We show how to outsource data annotation to Amazon Mechanical Turk. Doing so has produced annotations in quite large numbers relatively cheaply. The quality is good, and can be checked and controlled. Annotations are produced quickly. We describe results for several different annotation problems. We describe some strategies for determining when the task is well specified and properly priced.",
                    "title": "Utility data annotation with Amazon Mechanical Turk",
                    "venue": "computer vision and pattern recognition",
                    "year": 2008,
                    "__v": 2,
                    "citationCount": 244,
                    "result": 6.037746077451959
                },
                "b944f77f-113b-4a02-ae5e-d4a124b8fd5b": {
                    "authors": [
                        "David G. Lowe"
                    ],
                    "references": [
                        "00a4e16f-6b65-4ad2-bedc-b19d9cbc2cfe",
                        "01a0f825-a308-455b-93fc-e62defc0e3b0",
                        "035f8537-61a7-4c4f-b9fe-120f913a38b0",
                        "03a42efa-a19c-4b19-a881-9c7ff63865ce",
                        "05c3e696-6add-4b0d-b867-e6f1c98deb9b",
                        "2fa2e5ba-11d3-4691-91e1-807b8ef7d8a5",
                        "32d9eaee-c68f-4479-aa67-837d3cc91a05",
                        "34758e0a-3def-447b-9c5e-e82a206426b5",
                        "5437c0a0-8f20-49c3-86e5-9d860f3e4f04",
                        "5dcd5949-faa9-4af3-8c6f-b285dd3b6566",
                        "5f1992df-975f-49e7-bd88-aee0740317cf",
                        "5f84f09f-7644-447c-89e1-8dc9ee334197",
                        "6018a516-8149-4bce-bc33-5449d86e58c2",
                        "60285266-7da2-474e-b05a-b380c836f665",
                        "768eea6d-8e82-4bbf-8bdd-1f2338ded29f",
                        "791e9257-d7a0-41fe-b471-bde48f3c4a04",
                        "7ab7b36d-baae-4b21-89fc-69389fcabc44",
                        "7b3f5f5b-a965-4656-9a6f-2f9740625176",
                        "899de8c7-9cd9-4dd5-82f1-ad9acb801f8e",
                        "a00704dc-a2fa-4267-b7a6-427167d99521",
                        "a0fa7ae2-61e5-48a9-be10-86440416129f",
                        "a748e0f4-ee6f-41ad-a2a5-1a5a6751086d",
                        "b3e60214-b54c-4e8f-9315-a6975c760f4c",
                        "b4685927-0ad9-466b-b2c6-2e1764475726",
                        "c455fb04-4566-4648-ad6f-3cf2245e507c",
                        "ccdefe89-9b16-4c22-8bb8-bd314ccad6e1",
                        "d20995f6-529c-41c6-b75e-a169b005fb5c",
                        "d9b9f667-9d8a-4723-a6c4-c19b941acd46",
                        "df9fe96c-752e-49be-a8c4-8b098ab51e22",
                        "ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d",
                        "f6272ea9-0360-47ed-90a5-651ea958143f"
                    ],
                    "keyword": [
                        "features",
                        "object",
                        "matching",
                        "recognition",
                        "perform",
                        "images",
                        "single",
                        "robust",
                        "paper",
                        "invariant"
                    ],
                    "group": [
                        null
                    ],
                    "_id": "b944f77f-113b-4a02-ae5e-d4a124b8fd5b",
                    "abstract": "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance.",
                    "title": "Distinctive Image Features from Scale-Invariant Keypoints",
                    "venue": "International Journal of Computer Vision",
                    "year": 2004,
                    "__v": 3,
                    "citationCount": 16229,
                    "result": 6.404114830817619
                },
                "c70a5a06-395e-452e-bec8-01807cf4be7e": {
                    "authors": [
                        "Xiaobing Liu",
                        "Dong Wang",
                        "Jianmin Li",
                        "Bo Zhang"
                    ],
                    "references": [
                        "1258bf08-888b-4454-8f45-cefef43bb5d1",
                        "290e0375-d2ad-4bec-a94f-f05e1580125b",
                        "319f5c0d-b3f1-4f4e-a553-03c887f50e3c",
                        "36d4ef32-d65f-43c2-a895-50598c8cd902",
                        "46242d38-c986-430d-ae17-81369cfa6c8d",
                        "8f5cecf7-c1dc-4400-8af3-739409424dac",
                        "ae4a15da-5aec-4876-bec6-7c8ce40761b1",
                        "b624c279-af53-46e8-97ef-cc7e8a1c2d55",
                        "b944f77f-113b-4a02-ae5e-d4a124b8fd5b",
                        "c14bcc73-3061-46a5-9b1e-648faf08f7cf",
                        "c455fb04-4566-4648-ad6f-3cf2245e507c",
                        "c9482f1f-6600-44a7-a69a-e63ef13cdff8",
                        "e0ac4812-7729-4a2d-8a1f-74b1b7c8eb5d",
                        "ee7d45f5-2a83-4a93-b31c-f1145ca0e906",
                        "f225f439-4389-4312-a503-f8c1b0aa02de",
                        "fc780759-4533-4b33-9774-746ca210842f"
                    ],
                    "keyword": [
                        "spatial",
                        "match",
                        "feature",
                        "kernel",
                        "video",
                        "representation",
                        "pyramid",
                        "histogram",
                        "fesco",
                        "achieve"
                    ],
                    "group": [],
                    "_id": "c70a5a06-395e-452e-bec8-01807cf4be7e",
                    "abstract": "In this paper, we are motivated to augment the holistic histogram representation with implicit spatial constrains. To be more concrete, we aim at finding a good match function for the problem of object/scene categorization which considers the spatial constraints against heavy clutter and occlusion. Our solution is a partial match kernel under the histogram representation which varies simultaneously at both the feature and spatial resolutions, named as the Feature and Spatial Covariant (FESCO) kernel. Both the FESCO kernel and its late fusion alternative achieve better match accuracy than Spatial Pyramid Match [13] and Pyramid Match [11]. We also apply the keypoint features to video indexing. And on a large scale TRECVID data sets of over 300 hours videos, to our best knowledge, this approach achieves the state-of-the-art result for a single feature.",
                    "title": "The feature and spatial covariant kernel: adding implicit spatial constraints to histogram",
                    "venue": "conference on image and video retrieval",
                    "year": 2007,
                    "__v": 2,
                    "citationCount": 9,
                    "result": 6.124478007372745
                },
                "cfbc794e-0fa7-4d5b-be73-f5f03c5a1f9d": {
                    "authors": [
                        "Julian Stoettinger",
                        "Allan Hanbury",
                        "Nicu Sebe",
                        "Th. Gevers"
                    ],
                    "references": [
                        "175af12a-353e-4202-9a7c-949fb260a3b0",
                        "21c67dad-f0eb-4479-afe7-fdf4a71eef01",
                        "2d6c9f60-ea78-44a8-b5f9-6964575dd196",
                        "34758e0a-3def-447b-9c5e-e82a206426b5",
                        "53242913-3362-4355-a081-f4b53b4e9641",
                        "5f1992df-975f-49e7-bd88-aee0740317cf",
                        "7a9f04e3-2883-4204-8fb3-7db1ce5ddc09",
                        "a7c7aa39-cef0-4b9c-b8a0-e7b5329cba68",
                        "bbcb470e-b2b8-46bc-ac4e-108268f07e8a",
                        "ec216f37-258a-4422-8cf4-6e0cb84f3513",
                        "ffa029cf-7240-4723-8339-51fac57f9f28"
                    ],
                    "keyword": [
                        "colour",
                        "information",
                        "point",
                        "methods",
                        "interest",
                        "image",
                        "tasks",
                        "scale",
                        "salient",
                        "retrieval"
                    ],
                    "group": [],
                    "_id": "cfbc794e-0fa7-4d5b-be73-f5f03c5a1f9d",
                    "abstract": "In image retrieval scenarios, many methods use interest point detection at an early stage to find regions in which descriptors are calculated. Finding salient locations in image data is crucial for these tasks. Observing that most current methods use only the luminance information of the images, we investigate the use of colour information in interest point detection. A way to use multi-channel information in the Harris corner detector is explored and different colour spaces are evaluated. To determine the characteristic scale of an interest point, a new colour scale selection method is presented. We show that using colour information and boosting salient colours results in improved performance in retrieval tasks.",
                    "title": "Do Colour Interest Points Improve Image Retrieval",
                    "venue": "international conference on image processing",
                    "year": 2007,
                    "__v": 2,
                    "citationCount": 8,
                    "result": 6.258676608908806
                },
                "d5e01b64-7902-4df0-a768-43c2a8e1739e": {
                    "authors": [
                        "Antonio Torralba",
                        "Kevin P. Murphy",
                        "William T. Freeman"
                    ],
                    "references": [
                        "0ab71a43-a7d8-437c-83e0-6caf7523235f",
                        "0ca9c674-29f9-48e5-a4bd-9e30f16f70c7",
                        "12fa9885-b0a9-4ea3-a0de-e020c333c3f0",
                        "32a53bab-1ede-4869-98ad-d2ff0c1e3367",
                        "37031566-2033-44cb-a87e-91a9bb37996f",
                        "5ea6e082-6427-4ac3-ac85-95f9232c8213",
                        "5ebbd1f5-dfe5-4eec-9883-b8b5efea366c",
                        "6018a516-8149-4bce-bc33-5449d86e58c2",
                        "685b313d-8a77-481e-9456-e405a1d29549",
                        "739659a7-5aa8-49de-8cbc-f7d9c3b405e7",
                        "7f367932-20d6-425d-b207-9869b1c277cf",
                        "81eec382-cc0a-4381-91df-a90054925734",
                        "820b9eee-e009-4dc1-b464-f5fd4485d6b3",
                        "8b8a2247-bd77-4736-b493-449734f56b9a",
                        "b84edc2c-53ca-4757-8994-fded2d0e50b1",
                        "bb4963db-e1bf-43d9-91bd-62e9600938a4",
                        "c455fb04-4566-4648-ad6f-3cf2245e507c",
                        "c7f93552-c1ef-4ae4-b1f5-2317e1c9d904",
                        "c91c50ec-4906-4748-96a8-f5868bdaa7c6",
                        "ca756b69-343b-4363-a9b7-7046fe3fe7d7",
                        "e05a6676-6e91-466e-b705-19e19b66e5a2",
                        "ed835ca3-7120-4646-afaf-20c04a57c698",
                        "edd1b75d-513f-4c77-a586-ed1da21207af",
                        "ee554ae0-03a8-4976-9d09-0d2a885d79d6",
                        "ee9b186c-b7f0-4323-8f28-a55bbbd62b71",
                        "f00fc370-0854-4967-bc6a-83b6c49da8bf",
                        "fc4a70a7-80c5-43c8-a68f-0a72a46ecce8",
                        "ff0d990e-90f3-4973-8541-5f7e595710aa"
                    ],
                    "keyword": [
                        "features",
                        "classes",
                        "training",
                        "require",
                        "number",
                        "scales",
                        "computation",
                        "complexity",
                        "classifiers",
                        "sample"
                    ],
                    "group": [],
                    "_id": "d5e01b64-7902-4df0-a768-43c2a8e1739e",
                    "abstract": "We consider the problem of detecting a large number of different classes of objects in cluttered scenes. Traditional approaches require applying a battery of different classifiers to the image, at multiple locations and scales. This can be slow and can require a lot of training data since each classifier requires the computation of many different image features. In particular, for independently trained detectors, the (runtime) computational complexity and the (training-time) sample complexity scale linearly with the number of classes to be detected. We present a multitask learning procedure, based on boosted decision stumps, that reduces the computational and sample complexity by finding common features that can be shared across the classes (and/or views). The detectors for each class are trained jointly, rather than independently. For a given performance level, the total number of features required and, therefore, the runtime cost of the classifier, is observed to scale approximately logarithmically with the number of classes. The features selected by joint training are generic edge-like features, whereas the features chosen by training each class separately tend to be more object-specific. The generic features generalize better and considerably reduce the computational cost of multiclass object detection",
                    "title": "Sharing Visual Features for Multiclass and Multiview Object Detection",
                    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "year": 2007,
                    "__v": 2,
                    "citationCount": 379,
                    "result": 4.897525015404272
                },
                "dc2c4901-c7cd-405f-b549-fad267d3f5bd": {
                    "authors": [
                        "Vittorio Ferrari",
                        "Loïc Février",
                        "Frédéric Jurie",
                        "Cordelia Schmid"
                    ],
                    "references": [
                        "0356c68a-a89c-414f-94c9-14d5e08d14c5",
                        "0aae4e44-abdb-4948-9462-61f6e52162ba",
                        "126263a9-f4df-4361-8395-29cad95702aa",
                        "2a6b7b7a-a43b-4390-8601-e0165ec2f2cc",
                        "30b466e4-594d-4199-9ae4-c083b3cae02d",
                        "509e1ae2-768b-4417-bebe-d90cf1e0fdae",
                        "50deb9e0-e10b-40bd-a73f-c544285457e3",
                        "5d7a9371-b15a-4635-b92b-46a8a31c214c",
                        "613bfe0e-b8bc-4cd1-a7b5-1563c78c983d",
                        "6421b691-4ea2-4b53-9705-64cd5ca65d7d",
                        "6449f7ba-5b0e-4560-94b4-47757a5f24af",
                        "6fd932e6-412c-46a6-a623-1e582e0a04e4",
                        "78dd7c1a-bc00-4993-bd41-8e5da9a7fe5b",
                        "8fd827e4-e11b-4fea-bdfb-690d453e6ee1",
                        "9f5f1500-0df7-4675-8290-b47979bcad38",
                        "ae4a15da-5aec-4876-bec6-7c8ce40761b1",
                        "b2823eb1-e628-48fd-8bb7-95504a20f054",
                        "b944f77f-113b-4a02-ae5e-d4a124b8fd5b",
                        "b9c9a059-d63a-4abe-9403-449f2352391a",
                        "c455fb04-4566-4648-ad6f-3cf2245e507c",
                        "c9482f1f-6600-44a7-a69a-e63ef13cdff8",
                        "d4d98193-fa86-445e-a140-959c646323a7",
                        "d77c3e72-3e01-4bc8-a1ab-1953aa96c534",
                        "dd83785a-dd19-41e3-9b25-ebabbd48d336",
                        "df152036-9859-492f-998f-1ff9769b6d95",
                        "e0ac4812-7729-4a2d-8a1f-74b1b7c8eb5d",
                        "e649a9fd-f6d9-4aac-b428-29b82c20a484",
                        "eaaecdfe-4671-4c23-a334-db237b02d3a5",
                        "fc780759-4533-4b33-9774-746ca210842f"
                    ],
                    "keyword": [
                        "kas",
                        "object",
                        "detection",
                        "class"
                    ],
                    "group": [],
                    "_id": "dc2c4901-c7cd-405f-b549-fad267d3f5bd",
                    "abstract": "We present a family of scale-invariant local shape features formed by chains of k connected roughly straight contour segments (kAS), and their use for object class detection. kAS are able to cleanly encode pure fragments of an object boundary without including nearby clutter. Moreover, they offer an attractive compromise between information content and repeatability and encompass a wide variety of local shape structures. We also define a translation and scale invariant descriptor encoding the geometric configuration of the segments within a kAS, making kAS easy to reuse in other frameworks, for example, as a replacement or addition to interest points (IPs). Software for detecting and describing kAS is released at http://lear.inrialpes.fr/software. We demonstrate the high performance of kAS within a simple but powerful sliding-window object detection scheme. Through extensive evaluations, involving eight diverse object classes and more than 1,400 images, we (1) study the evolution of performance as the degree of feature complexity k varies and determine the best degree, (2) show that kAS substantially outperform IPs for detecting shape-based classes, and (3) compare our object detector to the recent state-of-the-art system by Dalal and Triggs (2005).",
                    "title": "Groups of Adjacent Contour Segments for Object Detection",
                    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "year": 2008,
                    "__v": 1,
                    "citationCount": 290,
                    "result": 4.5373734109028225
                },
                "dd83785a-dd19-41e3-9b25-ebabbd48d336": {
                    "authors": [
                        "Navneet Dalal",
                        "Bill Triggs"
                    ],
                    "references": [
                        "04d8a9cb-a14d-4ccf-8b19-da1327e86b91",
                        "3e812129-beeb-415e-b6f7-ae255695cec7",
                        "6f6fe122-6003-498c-a584-b27b3f7a6be3",
                        "8d8e7d51-3223-4776-bf6a-40306774b8a1",
                        "8fc9506c-3603-4af2-b0c8-02b368863fcb",
                        "a5254ae0-1ce1-4390-b9f8-8d5a3dcb1e62",
                        "b944f77f-113b-4a02-ae5e-d4a124b8fd5b",
                        "bdd58d4a-2e0e-4fb2-8049-cfa50dda7b0d",
                        "cb66e49d-077b-4adf-873c-2bc39f78fca6",
                        "ed8a9624-3abe-4b5e-bffe-5b3ecc34e841",
                        "f200d16f-8e1a-4a51-be50-4eeaafbb4a2f",
                        "f3959783-a9aa-48a2-9fcc-978879de365e",
                        "ff0d990e-90f3-4973-8541-5f7e595710aa",
                        "ffa029cf-7240-4723-8339-51fac57f9f28"
                    ],
                    "keyword": [
                        "human",
                        "gradient",
                        "descriptors",
                        "study",
                        "sets",
                        "oriented",
                        "feature",
                        "existing",
                        "detection",
                        "binning"
                    ],
                    "group": [
                        null
                    ],
                    "_id": "dd83785a-dd19-41e3-9b25-ebabbd48d336",
                    "abstract": "We study the question of feature sets for robust visual object recognition; adopting linear SVM based human detection as a test case. After reviewing existing edge and gradient based descriptors, we show experimentally that grids of histograms of oriented gradient (HOG) descriptors significantly outperform existing feature sets for human detection. We study the influence of each stage of the computation on performance, concluding that fine-scale gradients, fine orientation binning, relatively coarse spatial binning, and high-quality local contrast normalization in overlapping descriptor blocks are all important for good results. The new approach gives near-perfect separation on the original MIT pedestrian database, so we introduce a more challenging dataset containing over 1800 annotated human images with a large range of pose variations and backgrounds.",
                    "title": "Histograms of oriented gradients for human detection",
                    "venue": "computer vision and pattern recognition",
                    "year": 2005,
                    "__v": 3,
                    "citationCount": 8477,
                    "result": 5.518890870051861
                },
                "e0ac4812-7729-4a2d-8a1f-74b1b7c8eb5d": {
                    "authors": [
                        "Svetlana Lazebnik",
                        "Cordelia Schmid",
                        "Jean Ponce"
                    ],
                    "references": [
                        "1ed2cc94-3d0b-4718-80b6-2528e814c921",
                        "1f556c88-b553-4c75-b243-92d8200f8149",
                        "21a8e8fd-0172-4e9a-8474-7024eb0bf979",
                        "26316adf-569e-49bc-a289-c1ba311624f6",
                        "2d5181cd-cf99-4afd-afe7-4e37839ea50d",
                        "829f9b1f-d04f-49e8-aab7-2c278dff5427",
                        "a06e231e-3682-4270-b36a-397d119f504a",
                        "ab3afb93-8ca0-4556-ae60-11199dc263c2",
                        "ae4a15da-5aec-4876-bec6-7c8ce40761b1",
                        "c14bcc73-3061-46a5-9b1e-648faf08f7cf",
                        "c2d3dd5b-6fd3-403f-9a03-e1751360e226",
                        "c3eee093-b3ff-47ae-a5ac-e005bb060e4a",
                        "c455fb04-4566-4648-ad6f-3cf2245e507c",
                        "c9482f1f-6600-44a7-a69a-e63ef13cdff8",
                        "ea64f6ce-6ad4-4e2d-ad18-24c25ff99870"
                    ],
                    "keyword": [
                        "scene",
                        "image",
                        "subregions",
                        "spatial",
                        "pyramid",
                        "proposed",
                        "method",
                        "database",
                        "computing",
                        "categories"
                    ],
                    "group": [
                        null
                    ],
                    "_id": "e0ac4812-7729-4a2d-8a1f-74b1b7c8eb5d",
                    "abstract": "This paper presents a method for recognizing scene categories based on approximate global geometric correspondence. This technique works by partitioning the image into increasingly fine sub-regions and computing histograms of local features found inside each sub-region. The resulting \"spatial pyramid\" is a simple and computationally efficient extension of an orderless bag-of-features image representation, and it shows significantly improved performance on challenging scene categorization tasks. Specifically, our proposed method exceeds the state of the art on the Caltech-101 database and achieves high accuracy on a large database of fifteen natural scene categories. The spatial pyramid framework also offers insights into the success of several recently proposed image descriptions, including Torralbas \"gist\" and Lowes SIFT descriptors.",
                    "title": "Beyond Bags of Features: Spatial Pyramid Matching for Recognizing Natural Scene Categories",
                    "venue": "computer vision and pattern recognition",
                    "year": 2006,
                    "__v": 3,
                    "citationCount": 3815,
                    "result": 6.435592675298558
                },
                "eba773db-f6b9-4fb3-9112-61cd10e0c754": {
                    "authors": [
                        "Van Gemert",
                        "Jan-Mark Geusebroek",
                        "Cor J. Veenman",
                        "Cees G. M. Snoek",
                        "Arnold Smeulders"
                    ],
                    "references": [
                        "26316adf-569e-49bc-a289-c1ba311624f6",
                        "2ac912a3-574e-4da2-a70f-a4b2f40cf102",
                        "327d0f9c-712e-48b5-a95b-602476e52c4f",
                        "3843d2db-d96f-47be-8ece-fa9c1e87d1bc",
                        "45fbec1c-c97d-45dc-85a7-9341b8e975dc",
                        "509e1ae2-768b-4417-bebe-d90cf1e0fdae",
                        "60e77fab-98d4-438b-a664-753b70e98709",
                        "785d5d28-02ed-4141-8252-e0c97af33acd",
                        "904cbad5-94b6-4992-b1fa-4e68c56f18ab",
                        "94ce3d32-4057-4002-a3ef-6f87b0582802",
                        "ab3afb93-8ca0-4556-ae60-11199dc263c2",
                        "ae4a15da-5aec-4876-bec6-7c8ce40761b1",
                        "b944f77f-113b-4a02-ae5e-d4a124b8fd5b",
                        "c3eee093-b3ff-47ae-a5ac-e005bb060e4a",
                        "c455fb04-4566-4648-ad6f-3cf2245e507c",
                        "c9482f1f-6600-44a7-a69a-e63ef13cdff8",
                        "d888c0d6-49bb-4b0f-98c1-5ee897878f2d",
                        "dcb04f92-436b-4a3b-8a6c-a27457fe221e",
                        "ed835ca3-7120-4646-afaf-20c04a57c698"
                    ],
                    "keyword": [
                        "visual",
                        "texture",
                        "scene",
                        "approach",
                        "protoconcepts",
                        "descriptors",
                        "datasets",
                        "context",
                        "categories",
                        "stock"
                    ],
                    "group": [],
                    "_id": "eba773db-f6b9-4fb3-9112-61cd10e0c754",
                    "abstract": "We present a generic and robust approach for scene categorization. A complex scene is described by proto-concepts like vegetation, water, fire, sky etc. These proto-concepts are represented by low level features, where we use natural images statistics to compactly represent color invariant texture information by a Weibull distribution. We introduce the notion of contextures which preserve the context of textures in a visual scene with an occurrence histogram (context) of similarities to proto-concept descriptors (texture). In contrast to a codebook approach, we use the similarity to all vocabulary elements to generalize beyond the code words. Visual descriptors are attained by combining different types of contexts with different texture parameters. The visual scene descriptors are generalized to visual categories by training a support vector machine. We evaluate our approach on 3 different datasets: 1) 50 categories for the TRECVID video dataset; 2) the Caltech 101-object images; 3) 89 categories being the intersection of the Corel photo stock with the Art Explosion photo stock. Results show that our approach is robust over different datasets, while maintaining competitive performance.",
                    "title": "Robust Scene Categorization by Learning Image Statistics in Context",
                    "venue": "computer vision and pattern recognition",
                    "year": 2006,
                    "__v": 2,
                    "citationCount": 76,
                    "result": 6.7928652616733105
                },
                "ed835ca3-7120-4646-afaf-20c04a57c698": {
                    "authors": [
                        "Antonio Torralba"
                    ],
                    "references": [
                        "09c5663f-0e10-42dd-8a06-de98eb6283d0",
                        "0f58e2da-b7b7-47a8-93e1-29ac58631f34",
                        "1ed2cc94-3d0b-4718-80b6-2528e814c921",
                        "3754cd3d-1c71-44d4-ade9-916b9c21ab92",
                        "45b5946e-2dad-4318-9f98-ceb44af530d7",
                        "4a29b56b-b74e-4945-9017-61a7ab844fd9",
                        "5ad7276f-f084-4a24-8187-57873f008c82",
                        "65a76574-1ea8-4b1d-8d29-efe42d06446c",
                        "6c2f97e5-a9f8-4953-9fd1-8e188c0d9302",
                        "6d121e97-e351-4cf9-8c44-d7ab3ce9d9fe",
                        "6e8cc926-79a1-4676-a2bd-f9d49f3144cf",
                        "82d0ec51-e40e-4602-b969-fc0b44464ac3",
                        "895baf65-af49-4daa-bbda-93ab87096ff1",
                        "899de8c7-9cd9-4dd5-82f1-ad9acb801f8e",
                        "92f1db41-9ed7-4384-9635-134797661240",
                        "94ce3d32-4057-4002-a3ef-6f87b0582802",
                        "9bd24114-921d-4869-ba66-48e4afef2303",
                        "a15cddb4-131e-4c80-ac81-e67febff8f4a",
                        "a8c1aa3c-b6e3-4295-92db-edb8d364a93f",
                        "ab3afb93-8ca0-4556-ae60-11199dc263c2",
                        "c027a810-02a3-415b-83ad-e48144273475",
                        "d6e37fb1-5f7e-448e-847b-7d1f1271c574",
                        "eebe49e1-42f0-43b8-b5ec-cfaaaf3b90e1",
                        "ef35a024-f5f3-4a7b-b6f6-61d9167385e6",
                        "f4642ffc-3571-4d02-8b94-142f2448023a",
                        "ff0d990e-90f3-4973-8541-5f7e595710aa"
                    ],
                    "keyword": [
                        "object's",
                        "scenes",
                        "context",
                        "realworld"
                    ],
                    "group": [],
                    "_id": "ed835ca3-7120-4646-afaf-20c04a57c698",
                    "abstract": "There is general consensus that context can be a rich source of information about an object's identity, location and scale. In fact, the structure of many real-world scenes is governed by strong configurational rules akin to those that apply to a single object. Here we introduce a simple framework for modeling the relationship between context and object properties based on the correlation between the statistics of low-level features across the entire scene and the objects that it contains. The resulting scheme serves as an effective procedure for object priming, context driven focus of attention and automatic scale-selection on real-world scenes.",
                    "title": "Contextual Priming for Object Detection",
                    "venue": "International Journal of Computer Vision",
                    "year": 2003,
                    "__v": 1,
                    "citationCount": 361,
                    "result": 2.472748330101271
                },
                "ee9b186c-b7f0-4323-8f28-a55bbbd62b71": {
                    "authors": [
                        "Mark Everingham",
                        "Andrew Zisserman",
                        "Christopher K. I. Williams",
                        "Luc J. Van Gool",
                        "Moray Allan",
                        "Christopher M. Bishop",
                        "Olivier Chapelle",
                        "Navneet Dalal",
                        "Thomas Deselaers",
                        "Gyuri Dorkó",
                        "Stefan Duffner",
                        "J Eichhorn",
                        "Jason D. R. Farquhar",
                        "Mario Fritz",
                        "Christophe Garcia",
                        "Thomas L. Griffiths",
                        "Frédéric Jurie",
                        "Daniel Keysers",
                        "Markus Koskela",
                        "Jorma Laaksonen",
                        "Diane Larlus",
                        "Bastian Leibe",
                        "Hongying Meng",
                        "Hermann Ney",
                        "Bernt Schiele",
                        "Cordelia Schmid",
                        "Edgar Seemann",
                        "John Shawe-Taylor",
                        "Amos Storkey",
                        "Sandor Szedmak",
                        "Bill Triggs",
                        "Ilkay Ulusoy",
                        "Ville Viitaniemi",
                        "Jianguo Zhang"
                    ],
                    "references": [
                        "0289a1a7-579b-42a8-8795-45bb59850e67",
                        "21a8e8fd-0172-4e9a-8474-7024eb0bf979",
                        "2d6c9f60-ea78-44a8-b5f9-6964575dd196",
                        "34758e0a-3def-447b-9c5e-e82a206426b5",
                        "3c383c6f-3503-458d-bdd7-a34cb8f4515f",
                        "526860a6-aea8-4f8d-b7f9-e01d3629a6a9",
                        "59685592-3fcd-499b-969c-e3a927864645",
                        "5ea6e082-6427-4ac3-ac85-95f9232c8213",
                        "6692d3e1-f6a0-48c0-8733-7b1f72587fd0",
                        "6fe37c18-8dc5-4baa-b6e0-5546353907bb",
                        "733eea21-9c61-4935-8ffd-5b8e56dd947d",
                        "758978d8-5908-4afc-8d47-0309601427e3",
                        "8028b8ab-06c2-41f8-b833-88ba9248fd15",
                        "8bc5f80f-af26-47b4-aa0a-aab3a2e6c503",
                        "8d8e7d51-3223-4776-bf6a-40306774b8a1",
                        "930528e2-70a5-48f6-bdd1-5235f98b5255",
                        "a083a1b9-8dfb-45d6-99a9-fa30c4a6e9f5",
                        "b29cb808-1f59-40e9-8afa-26a3701b6284",
                        "b944f77f-113b-4a02-ae5e-d4a124b8fd5b",
                        "b9c9a059-d63a-4abe-9403-449f2352391a",
                        "c1b6b493-01ef-420f-be44-7bacfe34e846",
                        "c455fb04-4566-4648-ad6f-3cf2245e507c",
                        "c591c440-b19b-4d7b-b067-cd8c366b7d6d",
                        "c9482f1f-6600-44a7-a69a-e63ef13cdff8",
                        "ccdefe89-9b16-4c22-8bb8-bd314ccad6e1",
                        "cd13ebd5-6dfc-4dd1-8fc8-aa34c9ce4122",
                        "cf545f57-5abd-4a15-888f-a674b99391ed",
                        "d486ab6f-98b8-46a1-8ae2-521ebd7391d6",
                        "dd83785a-dd19-41e3-9b25-ebabbd48d336",
                        "ffa029cf-7240-4723-8339-51fac57f9f28"
                    ],
                    "keyword": [
                        "object",
                        "classes",
                        "challenge",
                        "visual",
                        "teams",
                        "twelve",
                        "selected",
                        "scenes",
                        "results",
                        "recognize"
                    ],
                    "group": [],
                    "_id": "ee9b186c-b7f0-4323-8f28-a55bbbd62b71",
                    "abstract": "The PASCAL Visual Object Classes Challenge ran from February to March 2005. The goal of the challenge was to recognize objects from a number of visual object classes in realistic scenes (i.e. not pre-segmented objects). Four object classes were selected: motorbikes, bicycles, cars and people. Twelve teams entered the challenge. In this chapter we provide details of the datasets, algorithms used by the teams, evaluation criteria, and results achieved.",
                    "title": "The 2005 PASCAL visual object classes challenge",
                    "venue": "international conference on machine learning",
                    "year": 2005,
                    "__v": 2,
                    "citationCount": 187,
                    "result": 7.498797281150224
                },
                "fc780759-4533-4b33-9774-746ca210842f": {
                    "authors": [
                        "Jianguo Zhang",
                        "Marcin Marszalek",
                        "Svetlana Lazebnik",
                        "Cordelia Schmid"
                    ],
                    "references": [
                        "03f3d290-78fb-4694-86ed-85acc48b0e79",
                        "090af1dd-85e1-49f1-ae85-9928df7f709f",
                        "0d68cae7-51b5-41e9-b66a-01254a8022a3",
                        "1f556c88-b553-4c75-b243-92d8200f8149",
                        "21a8e8fd-0172-4e9a-8474-7024eb0bf979",
                        "26316adf-569e-49bc-a289-c1ba311624f6",
                        "2d6c9f60-ea78-44a8-b5f9-6964575dd196",
                        "354d0df4-594b-4672-bdba-4a4a9310d04d",
                        "37031566-2033-44cb-a87e-91a9bb37996f",
                        "4fddea17-773c-4d66-a8a4-ce4a1d939151",
                        "532dec4c-28bf-4ca8-aa3b-fc5b5b20bb2d",
                        "606f8ecd-75f5-40fa-a70d-d6665cd2990e",
                        "62a46780-e1d9-4186-babe-6179735d785e",
                        "6692d3e1-f6a0-48c0-8733-7b1f72587fd0",
                        "6842d04f-2b92-4298-aee8-92babc53f7c4",
                        "6ed8bba0-4960-4c10-8dfc-b7705bb6c158",
                        "70e86498-0a19-465c-8b73-49c2769b1a53",
                        "71a81f33-5958-4066-990c-39feafe3ed9c",
                        "72c27d5a-23c5-4d1b-a000-280b87b368ee",
                        "758978d8-5908-4afc-8d47-0309601427e3",
                        "8028b8ab-06c2-41f8-b833-88ba9248fd15",
                        "805dd061-a59c-4599-a019-090d2ceb64f8",
                        "81eec382-cc0a-4381-91df-a90054925734",
                        "827ea34a-8b5f-4e39-bf91-361e8dce0d04",
                        "8d8e7d51-3223-4776-bf6a-40306774b8a1",
                        "9f84e529-87a3-42f1-9d63-9af710f40925",
                        "a075f8b3-9c5a-4e43-a72a-8e41e82855a6",
                        "a083a1b9-8dfb-45d6-99a9-fa30c4a6e9f5",
                        "acaea615-8ac3-42b4-a737-28fdce1a8da6",
                        "ae4a15da-5aec-4876-bec6-7c8ce40761b1",
                        "b944f77f-113b-4a02-ae5e-d4a124b8fd5b",
                        "b9c9a059-d63a-4abe-9403-449f2352391a",
                        "bac97ced-fab8-4545-9b91-870dfc6f4bdf",
                        "c3eee093-b3ff-47ae-a5ac-e005bb060e4a",
                        "c455fb04-4566-4648-ad6f-3cf2245e507c",
                        "c9482f1f-6600-44a7-a69a-e63ef13cdff8",
                        "cf09783a-75d7-4d0f-9e3f-c39b39b27cf5",
                        "d1cad764-0045-4592-b8f6-7b879f6bc56a",
                        "d7b1fba1-b5f8-4377-88a8-d2fc69f723b7",
                        "dc45e731-69f8-4829-ac34-97ae79f9a55a",
                        "e46b1853-c375-4277-afa5-6d1278b90736",
                        "e5f122f3-dd0f-4317-9ac2-2a4baa08ba01",
                        "ee9b186c-b7f0-4323-8f28-a55bbbd62b71",
                        "ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d",
                        "f111ff97-89a3-4df6-8f02-962d7b4fe985",
                        "fb5b7aa5-5d68-45b9-be8b-36d217d940d7",
                        "ffa029cf-7240-4723-8339-51fac57f9f28"
                    ],
                    "keyword": [
                        "object",
                        "image",
                        "texture",
                        "recognition",
                        "performance",
                        "local",
                        "features",
                        "evaluation",
                        "distributions",
                        "databases"
                    ],
                    "group": [],
                    "_id": "fc780759-4533-4b33-9774-746ca210842f",
                    "abstract": "Recently, methods based on local image features have shown promise for texture and object recognition tasks. This paper presents a large-scale evaluation of an approach that represents images as distributions (signatures or histograms) of features extracted from a sparse set of keypoint locations and learns a Support Vector Machine classifier with kernels based on two effective measures for comparing distributions, the Earth Mover's Distance and the ?2 distance. We first evaluate the performance of our approach with different keypoint detectors and descriptors, as well as different kernels and classifiers. We then conduct a comparative evaluation with several state-of-the-art recognition methods on four texture and five object databases. On most of these databases, our implementation exceeds the best reported results and achieves comparable performance on the rest. Finally, we investigate the influence of background correlations on recognition performance via extensive tests on the PASCAL database, for which ground-truth object localization information is available. Our experiments demonstrate that image representations based on distributions of local features are surprisingly effective for classification of texture and object images under challenging real-world conditions, including significant intra-class variations and substantial background clutter.",
                    "title": "Local Features and Kernels for Classification of Texture and Object Categories: A Comprehensive Study",
                    "venue": "International Journal of Computer Vision",
                    "year": 2007,
                    "__v": 2,
                    "citationCount": 1010,
                    "result": 9.281271901473142
                },
                "ffa31d0c-ff37-4bf3-b213-6d8a968e6636": {
                    "authors": [
                        "Rob Fergus",
                        "Li Fei-Fei",
                        "Pietro Perona",
                        "Andrew Zisserman"
                    ],
                    "references": [
                        "21a8e8fd-0172-4e9a-8474-7024eb0bf979",
                        "26316adf-569e-49bc-a289-c1ba311624f6",
                        "28903e7b-aa3b-4840-b634-916029ed6c77",
                        "473cf1a4-9f42-4e6d-b34f-77787f329079",
                        "509e1ae2-768b-4417-bebe-d90cf1e0fdae",
                        "5ea6e082-6427-4ac3-ac85-95f9232c8213",
                        "6018a516-8149-4bce-bc33-5449d86e58c2",
                        "820b9eee-e009-4dc1-b464-f5fd4485d6b3",
                        "8bc5f80f-af26-47b4-aa0a-aab3a2e6c503",
                        "c32b12e9-a542-458d-8611-4a22e5193730",
                        "c455fb04-4566-4648-ad6f-3cf2245e507c",
                        "ccdefe89-9b16-4c22-8bb8-bd314ccad6e1",
                        "e649a9fd-f6d9-4aac-b428-29b82c20a484",
                        "fc4a70a7-80c5-43c8-a68f-0a72a46ecce8"
                    ],
                    "keyword": [
                        "images",
                        "approaches",
                        "search",
                        "object",
                        "engines",
                        "category"
                    ],
                    "group": [],
                    "_id": "ffa31d0c-ff37-4bf3-b213-6d8a968e6636",
                    "abstract": "Current approaches to object category recognition require datasets of training images to be manually prepared, with varying degrees of supervision. We present an approach that can learn an object category from just its name, by utilizing the raw output of image search engines available on the Internet. We develop a new model, TSI-pLSA, which extends pLSA (as applied to visual words) to include spatial information in a translation and scale invariant manner. Our approach can handle the high intra-class variability and large proportion of unrelated images returned by search engines. We evaluate tire models on standard test sets, showing performance competitive with existing methods trained on hand prepared datasets",
                    "title": "Learning object categories from Google's image search",
                    "venue": "international conference on computer vision",
                    "year": 2005,
                    "__v": 2,
                    "citationCount": 419,
                    "result": 3.542780258956729
                },
                "ffc56f7f-1295-4647-a1f7-e44ea58f93f2": {
                    "authors": [
                        "Ondřej Chum",
                        "James Philbin",
                        "Michael Isard",
                        "Andrew Zisserman"
                    ],
                    "references": [
                        "081dc64c-0cfe-4eb3-ab8e-87e9e56460e0",
                        "21c67dad-f0eb-4479-afe7-fdf4a71eef01",
                        "252077ed-1442-42f3-a343-ea79ea61e9d9",
                        "3d24420f-4644-468e-b363-b01ebf28ef5b",
                        "6337c29c-5b54-47e5-b8c4-7fb860651512",
                        "6c38b3b4-7562-493d-a40c-fe70abf039a7",
                        "6fe37c18-8dc5-4baa-b6e0-5546353907bb",
                        "7ab7b36d-baae-4b21-89fc-69389fcabc44",
                        "b1e9aedc-494e-4718-b2bc-55e71299d688",
                        "b25e7392-e9f9-4600-8ab0-a76252f1633a",
                        "b944f77f-113b-4a02-ae5e-d4a124b8fd5b",
                        "c40d4ea1-6f4f-49e9-b0d5-c3dd7f5c5347",
                        "dcb04f92-436b-4a3b-8a6c-a27457fe221e",
                        "dda32e99-40c9-4d5f-8982-51e4b1dca885",
                        "e0cc7303-50b3-488a-afa1-04e0299bc152",
                        "ed44c407-d96b-4be6-845e-a82c8a608e91",
                        "ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d"
                    ],
                    "keyword": [
                        "image",
                        "nearduplicate",
                        "video",
                        "retrieval",
                        "frames",
                        "approximate"
                    ],
                    "group": [],
                    "_id": "ffc56f7f-1295-4647-a1f7-e44ea58f93f2",
                    "abstract": "This paper proposes and compares two novel schemes for near duplicate image and video-shot detection. The first approach is based on global hierarchical colour histograms, using Locality Sensitive Hashing for fast retrieval. The second approach uses local feature descriptors (SIFT) and for retrieval exploits techniques used in the information retrieval community to compute approximate set intersections between documents using a min-Hash algorithm.   The requirements for near-duplicate images vary according to the application, and we address two types of near duplicate definition: (i) being perceptually identical (e.g. up to noise, discretization effects, small photometric distortions etc); and (ii) being images of the same 3D scene (so allowing for viewpoint changes and partial occlusion). We define two shots to be near-duplicates if they share a large percentage of near-duplicate frames.   We focus primarily on scalability to very large image and video databases, where fast query processing is necessary. Both methods are designed so that only a small amount of data need be stored for each image. In the case of near-duplicate shot detection it is shown that a weak approximation to histogram matching, consuming substantially less storage, is sufficient for good results. We demonstrate our methods on the TRECVID 2006 data set which contains approximately 165 hours of video (about 17.8M frames with 146K key frames), and also on feature films and pop videos.",
                    "title": "Scalable near identical image and shot detection",
                    "venue": "conference on image and video retrieval",
                    "year": 2007,
                    "__v": 2,
                    "citationCount": 118,
                    "result": 3.555584233448011
                }
            }
        ],
        "_id": "83c737b8-e084-4766-ba6e-131e6a1c017c",
        "abstract": "The Pascal Visual Object Classes (VOC) challenge is a benchmark in visual object category recognition and detection, providing the vision and machine learning communities with a standard dataset of images and annotation, and standard evaluation procedures. Organised annually from 2005 to present, the challenge and its associated dataset has become accepted as the benchmark for object detection.#R##N##R##N#This paper describes the dataset and evaluation procedure. We review the state-of-the-art in evaluated methods for both classification and detection, analyse whether the methods are statistically different, what they are learning from the images (e.g. the object or its context), and what the methods find easy or confuse. The paper concludes with lessons learnt in the three year history of the challenge, and proposes directions for future improvement and extension.",
        "title": "The Pascal Visual Object Classes (VOC) Challenge",
        "venue": "International Journal of Computer Vision",
        "year": 2010,
        "__v": 1,
        "citationCount": 2425
    },
    {
        "authors": [
            "Badrul M. Sarwar",
            "George Karypis",
            "Joseph A. Konstan",
            "John Riedl"
        ],
        "references": [
            "05f5fba9-e7ca-4c46-be79-df57944a8b41",
            "1406f119-82cd-4cbb-9231-f885212a724e",
            "312e54ca-e7e9-4129-99f4-36f3aeff827e",
            "3f8e14d5-4655-4c61-8636-99eb5cc99411",
            "41350086-4320-45bb-a93c-be68975bfff5",
            "44e91111-b413-4143-85a9-81872a97fa9d",
            "5e441d2d-7810-42bb-97f5-6f9542d11f0b",
            "5ee83a3b-d5f8-4532-97dd-c0579bed0d17",
            "60c814e2-c4d1-47d7-9a5a-68f4141505ae",
            "694f475e-f6c4-4105-b645-84c7d592db30",
            "6e425bce-a497-4c63-9eb0-b038e660a54f",
            "7d15ffdf-ec35-4498-b794-c186147b39eb",
            "812c314c-9742-46fa-b1e8-5c7d640f1322",
            "ac14afe6-de4d-4056-b2ac-0f6e36f369a2",
            "c69ef004-087e-486c-97c9-9b4587d0b10a",
            "c7ce0fc7-4d38-4355-aa19-ab35527d2519",
            "d3ca543b-a6d3-4dac-af08-b8e591340aaf",
            "da744ec1-ac83-4fe7-bff2-0ff5fa621460",
            "e5e1e41c-774c-4bb4-a087-bcd02fd37b0f",
            "ed4c0d5d-5152-4915-b9bd-d0bd25f82674"
        ],
        "keyword": [],
        "group": [],
        "_id": "98b23182-8f51-428a-a4af-a91d280471ca",
        "title": "Item-based collaborative filtering recommendation algorithms",
        "venue": "international world wide web conferences",
        "year": 2001,
        "abstract": "",
        "__v": 0,
        "citationCount": 2377
    },
    {
        "authors": [
            "Serge J. Belongie",
            "Jitendra Malik",
            "Jan Puzicha"
        ],
        "references": [
            "00909251-9935-44f3-94a1-629023b5015b",
            "042d18d1-aed3-4a9d-ba8b-fb7f3e14f568",
            "0fc7a847-923c-4742-9b05-2b46eda24b2e",
            "110d4ac1-9abd-4678-882c-56933790933c",
            "13cd743f-beb9-43a1-8e08-2ef08f0d8b3f",
            "1e4f4b5c-55e0-4d5b-b7cc-9e7fada3e341",
            "1ef607fe-5348-4658-8964-25a57fc49270",
            "23c61d04-333b-42c1-b8f8-a93cc33f4411",
            "24187b9b-fe6b-484d-9a0e-0b849362fa18",
            "25b0c9f9-0c8a-4f2a-b075-90d339b6faa3",
            "2a082569-b03f-474a-8e45-dfd713557277",
            "2ae7a9b5-6231-45ca-9813-afc3a6b5f5ff",
            "31d3bf4a-4175-414e-84c4-0eb8e42fc66e",
            "37032748-43bb-410a-8349-d2808bb6f7fa",
            "4a29b56b-b74e-4945-9017-61a7ab844fd9",
            "50dd56db-151d-4d62-8576-65f0ef6f381b",
            "59ade036-678c-42ad-bce8-7aa9301103e1",
            "5ae4ef7f-b13a-4e78-8afd-1e2d22259b87",
            "5ebbd1f5-dfe5-4eec-9883-b8b5efea366c",
            "5f1992df-975f-49e7-bd88-aee0740317cf",
            "6018a516-8149-4bce-bc33-5449d86e58c2",
            "6d86ad90-fe62-40e5-b917-7e3f31350523",
            "772654a7-a951-4327-aca5-ba5da8dfec7c",
            "88f85c71-d474-4d12-9c74-43ac3b7c7ee6",
            "8fc9506c-3603-4af2-b0c8-02b368863fcb",
            "923f5d0a-23a3-4fb1-bee7-ec72122709a4",
            "932ef745-7197-4b00-bcd4-781bd048938f",
            "9f84e529-87a3-42f1-9d63-9af710f40925",
            "a8c6ead3-d61a-4f6a-a702-08743f19eec9",
            "bf1d8c69-aefb-4a7a-8b02-f815b754833c",
            "d5f8e154-e8c9-45e8-a3a0-fd705f00ced4",
            "d6104d9a-faaa-4db4-8c4e-748176157ef2",
            "d9752a5a-1603-45cc-9a21-7997750d429f",
            "f1268507-d7ad-40be-a33a-083131f0ca8c",
            "f3959783-a9aa-48a2-9fcc-978879de365e"
        ],
        "keyword": [
            "shapes",
            "points",
            "similarity",
            "correspondences",
            "transform",
            "solving",
            "problem",
            "measuring",
            "context",
            "aligning"
        ],
        "group": [
            {
                "2ae7a9b5-6231-45ca-9813-afc3a6b5f5ff": {
                    "authors": [
                        "Serge J. Belongie",
                        "Jitendra Malik",
                        "Jan Puzicha"
                    ],
                    "references": [
                        "00909251-9935-44f3-94a1-629023b5015b",
                        "042d18d1-aed3-4a9d-ba8b-fb7f3e14f568",
                        "0fc7a847-923c-4742-9b05-2b46eda24b2e",
                        "13cd743f-beb9-43a1-8e08-2ef08f0d8b3f",
                        "1e4f4b5c-55e0-4d5b-b7cc-9e7fada3e341",
                        "1ef607fe-5348-4658-8964-25a57fc49270",
                        "59ade036-678c-42ad-bce8-7aa9301103e1",
                        "5ebbd1f5-dfe5-4eec-9883-b8b5efea366c",
                        "6d86ad90-fe62-40e5-b917-7e3f31350523",
                        "88f85c71-d474-4d12-9c74-43ac3b7c7ee6",
                        "932ef745-7197-4b00-bcd4-781bd048938f",
                        "a8c6ead3-d61a-4f6a-a702-08743f19eec9",
                        "b592576f-ff29-4a68-9b2f-8a8ad02e9c70"
                    ],
                    "keyword": [],
                    "group": [],
                    "_id": "2ae7a9b5-6231-45ca-9813-afc3a6b5f5ff",
                    "abstract": "We develop an approach to object recognition based on matching shapes and using a resulting measure of similarity in a nearest neighbor classifier. The key algorithmic problem here is that of finding pointwise correspondences between an image shape and a stored prototype shape. We introduce a new shape descriptor, the shape context, which makes this possible, using a simple and robust algorithm. The shape context at a point captures the distribution over relative positions of other shape points and thus summarizes global shape in a rich, local descriptor. We demonstrate that shape contexts greatly simplify recovery of correspondences between points of two given shapes. Once shapes are aligned, shape contexts are used to define a robust score for measuring shape similarity. We have used this score in a nearest-neighbor classifier for recognition of hand written digits as well as 3D objects, using exactly the same distance function. On the benchmark MNIST dataset of handwritten digits, this yields an error rate of 0.63%, outperforming other published techniques.",
                    "title": "Shape Context: A New Descriptor for Shape Matching and Object Recognition",
                    "venue": "neural information processing systems",
                    "year": 2001,
                    "__v": 0,
                    "citationCount": 190,
                    "result": 3.428571428571429
                },
                "50dd56db-151d-4d62-8576-65f0ef6f381b": {
                    "authors": [
                        "Corinna Cortes",
                        "Vladimir Vapnik"
                    ],
                    "references": [
                        "c4dc7b46-01d3-44f5-91ca-0cc063d38c8c",
                        "f006e236-59ad-4647-a59f-4f46dc2c85be"
                    ],
                    "keyword": [
                        "supportvector",
                        "network",
                        "machine",
                        "learning",
                        "training",
                        "surface",
                        "space",
                        "input",
                        "implements",
                        "idea"
                    ],
                    "group": [],
                    "_id": "50dd56db-151d-4d62-8576-65f0ef6f381b",
                    "abstract": "The support-vector network is a new learning machine for two-group classification problems. The machine conceptually implements the following idea: input vectors are non-linearly mapped to a very high-dimension feature space. In this feature space a linear decision surface is constructed. Special properties of the decision surface ensures high generalization ability of the learning machine. The idea behind the support-vector network was previously implemented for the restricted case where the training data can be separated without errors. We here extend this result to non-separable training data.#R##N##R##N#High generalization ability of support-vector networks utilizing polynomial input transformations is demonstrated. We also compare the performance of the support-vector network to various classical learning algorithms that all took part in a benchmark study of Optical Character Recognition.",
                    "title": "Support-Vector Networks",
                    "venue": "Machine Learning",
                    "year": 1995,
                    "__v": 2,
                    "citationCount": 6683,
                    "result": 7.057116590428612
                },
                "59ade036-678c-42ad-bce8-7aa9301103e1": {
                    "authors": [
                        "Daniel P. Huttenlocher",
                        "Ryan H. Lilien",
                        "Clark F. Olson"
                    ],
                    "references": [
                        "5ebbd1f5-dfe5-4eec-9883-b8b5efea366c",
                        "ab28357b-19c1-42d4-9479-6da360aad22c",
                        "c110f7e2-e896-411a-9e09-7194743273bb",
                        "d15e4b6e-465e-483a-9611-a5db993ce20c",
                        "d9752a5a-1603-45cc-9a21-7997750d429f",
                        "ee11b7f0-4aeb-4e0f-a808-2126f1590163"
                    ],
                    "keyword": [
                        "view",
                        "techniques",
                        "methods",
                        "eigenspace",
                        "recognition",
                        "matching",
                        "limited",
                        "intensity",
                        "cluttered",
                        "backgrounds"
                    ],
                    "group": [],
                    "_id": "59ade036-678c-42ad-bce8-7aa9301103e1",
                    "abstract": "View-based recognition methods, such as those using eigenspace techniques, have been successful for a number of recognition tasks. Such approaches, however, are somewhat limited in their ability to recognize objects that are partly hidden from view or occur against cluttered backgrounds. In order to address these limitations, we have developed a view matching technique based on an eigenspace approximation to the generalized Hausdorff measure. This method achieves compact storage and fast indexing that are the main advantages of eigenspace view matching techniques, while also being tolerant of partial occlusion and background clutter. The method applies to binary feature maps, such as intensity edges, rather than directly to intensity images.",
                    "title": "View-based recognition using an eigenspace approximation to the Hausdorff measure",
                    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "year": 1999,
                    "__v": 2,
                    "citationCount": 24,
                    "result": 6.521528485349324
                },
                "5ae4ef7f-b13a-4e78-8afd-1e2d22259b87": {
                    "authors": [
                        "Charles T. Zahn",
                        "Ralph Roskies"
                    ],
                    "references": [
                        "126446a1-730e-44dc-858b-e5c768bd81ac",
                        "7dac4219-13e1-4000-9c51-108613ffa362"
                    ],
                    "keyword": [
                        "fourier",
                        "curves",
                        "descriptors",
                        "function",
                        "symmetry",
                        "symmetric",
                        "starting",
                        "simple",
                        "shape",
                        "series"
                    ],
                    "group": [],
                    "_id": "5ae4ef7f-b13a-4e78-8afd-1e2d22259b87",
                    "abstract": "A method for the analysis and synthesis of closed curves in the plane is developed using the Fourier descriptors FD's of Cosgriff [1]. A curve is represented parametrically as a function of arc length by the accumulated change in direction of the curve since the starting point. This function is expanded in a Fourier series and the coefficients are arranged in the amplitude/phase-angle form. It is shown that the amplitudes are pure form invariants as well as are certain simple functions of phase angles. Rotational and axial symmetry are related directly to simple properties of the Fourier descriptors. An analysis of shape similarity or symmetry can be based on these relationships; also closed symmetric curves can be synthesized from almost arbitrary Fourier descriptors. It is established that the Fourier series expansion is optimal and unique with respect to obtaining coefficients insensitive to starting point. Several examples are provided to indicate the usefulness of Fourier descriptors as features for shape discrimination and a number of interesting symmetric curves are generated by computer and plotted out.",
                    "title": "Fourier Descriptors for Plane Closed Curves",
                    "venue": "IEEE Transactions on Computers",
                    "year": 1972,
                    "__v": 2,
                    "citationCount": 549,
                    "result": 5.945596594667802
                },
                "5ebbd1f5-dfe5-4eec-9883-b8b5efea366c": {
                    "authors": [
                        "Hiroshi Murase",
                        "Shree K. Nayar"
                    ],
                    "references": [
                        "60190e83-16e8-4f2c-a068-b63873a01507",
                        "68277b57-365f-4d91-8bb7-ae1d61356539",
                        "79bd9613-8976-41a1-b0b7-133b80b8477e",
                        "7b462bf0-19e0-4bb7-8b83-572f81803275",
                        "87c6d06a-66ed-4867-b789-2d114525063c",
                        "8f02180a-309b-442b-878a-02a024e94fb8",
                        "9572124b-4045-44a9-969c-73350c5b6a3d",
                        "adda2917-0ddc-4d6e-b7b3-86c043022042"
                    ],
                    "keyword": [
                        "object",
                        "pose",
                        "image",
                        "illumination",
                        "shape",
                        "scene",
                        "recognition",
                        "manifold",
                        "vary",
                        "set"
                    ],
                    "group": [],
                    "_id": "5ebbd1f5-dfe5-4eec-9883-b8b5efea366c",
                    "abstract": "The problem of automatically learning object models for recognition and pose estimation is addressed. In contrast to the traditional approach, the recognition problem is formulated as one of matching appearance rather than shape. The appearance of an object in a two-dimensional image depends on its shape, reflectance properties, pose in the scene, and the illumination conditions. While shape and reflectance are intrinsic properties and constant for a rigid object, pose and illumination vary from scene to scene. A compact representation of object appearance is proposed that is parametrized by pose and illumination. For each object of interest, a large set of images is obtained by automatically varying pose and illumination. This image set is compressed to obtain a low-dimensional subspace, called the eigenspace, in which the object is represented as a manifold. Given an unknown input image, the recognition system projects the image to eigenspace. The object is recognized based on the manifold it lies on. The exact position of the projection on the manifold determines the object's pose in the image.",
                    "title": "Visual learning and recognition of 3-D objects from appearance",
                    "venue": "International Journal of Computer Vision",
                    "year": 1995,
                    "__v": 2,
                    "citationCount": 1061,
                    "result": 4.241684797830309
                },
                "5f1992df-975f-49e7-bd88-aee0740317cf": {
                    "authors": [
                        "Cordelia Schmid",
                        "Roger Mohr"
                    ],
                    "references": [
                        "00909251-9935-44f3-94a1-629023b5015b",
                        "2fa2e5ba-11d3-4691-91e1-807b8ef7d8a5",
                        "34758e0a-3def-447b-9c5e-e82a206426b5",
                        "3bb5658b-131c-4072-9f9c-5f18a8272054",
                        "46da0145-fc17-4096-9624-4828cb32e116",
                        "4ea088d2-1d7e-433e-87ca-f31ad9b1e322",
                        "5dcd5949-faa9-4af3-8c6f-b285dd3b6566",
                        "5ebbd1f5-dfe5-4eec-9883-b8b5efea366c",
                        "643913d9-b72a-4ee3-9c3f-63c1249e9a3c",
                        "774c108a-4002-4123-861f-edd3b7ccb0e7",
                        "79bd9613-8976-41a1-b0b7-133b80b8477e",
                        "7a624075-0930-4956-8d8c-2910a80bdbca",
                        "7d5e97d2-5ebe-4be2-ac67-3c15fcde2c8d",
                        "8ec028ec-a8d0-4963-9e6f-231f0d6104ed",
                        "92551b72-99c5-4882-801c-a419e4eb705e",
                        "a8c76816-3583-47e8-98e1-18db34cb5b67",
                        "c083f584-daa0-4058-9a89-6b03409acfef",
                        "c38cebd1-1503-4321-ab02-28712487b9d3",
                        "c39c2ff9-1401-474d-917e-3776f528b204",
                        "d9b9f667-9d8a-4723-a6c4-c19b941acd46",
                        "dda837ee-640b-48b1-bb19-a00c5894f003"
                    ],
                    "keyword": [
                        "retrieving",
                        "images",
                        "databases",
                        "voting",
                        "visibility",
                        "transformations",
                        "small",
                        "similarity",
                        "show",
                        "semilocal"
                    ],
                    "group": [],
                    "_id": "5f1992df-975f-49e7-bd88-aee0740317cf",
                    "abstract": "This paper addresses the problem of retrieving images from large image databases. The method is based on local grayvalue invariants which are computed at automatically detected interest points. A voting algorithm and semilocal constraints make retrieval possible. Indexing allows for efficient retrieval from a database of more than 1,000 images. Experimental results show correct retrieval in the case of partial visibility, similarity transformations, extraneous features, and small perspective deformations.",
                    "title": "Local grayvalue invariants for image retrieval",
                    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "year": 1997,
                    "__v": 2,
                    "citationCount": 720,
                    "result": 7.789336614986095
                },
                "6018a516-8149-4bce-bc33-5449d86e58c2": {
                    "authors": [
                        "David G. Lowe"
                    ],
                    "references": [
                        "01a0f825-a308-455b-93fc-e62defc0e3b0",
                        "035f8537-61a7-4c4f-b9fe-120f913a38b0",
                        "5dcd5949-faa9-4af3-8c6f-b285dd3b6566",
                        "5ebbd1f5-dfe5-4eec-9883-b8b5efea366c",
                        "5f1992df-975f-49e7-bd88-aee0740317cf",
                        "78dd7c1a-bc00-4993-bd41-8e5da9a7fe5b",
                        "8678514b-e795-4972-b891-c0d31d0d46cf",
                        "899de8c7-9cd9-4dd5-82f1-ad9acb801f8e",
                        "92551b72-99c5-4882-801c-a419e4eb705e",
                        "a00704dc-a2fa-4267-b7a6-427167d99521",
                        "caeecc11-ec92-47d8-b112-c43b88dd4491",
                        "e46bb6ea-7b67-4edf-8cd4-a51ce64cff19",
                        "ee11b7f0-4aeb-4e0f-a808-2126f1590163"
                    ],
                    "keyword": [
                        "image",
                        "object",
                        "features",
                        "scaling",
                        "recognition",
                        "partially",
                        "multiple",
                        "matches",
                        "local",
                        "keys"
                    ],
                    "group": [],
                    "_id": "6018a516-8149-4bce-bc33-5449d86e58c2",
                    "abstract": "An object recognition system has been developed that uses a new class of local image features. The features are invariant to image scaling, translation, and rotation, and partially invariant to illumination changes and affine or 3D projection. These features share similar properties with neurons in inferior temporal cortex that are used for object recognition in primate vision. Features are efficiently detected through a staged filtering approach that identifies stable points in scale space. Image keys are created that allow for local geometric deformations by representing blurred image gradients in multiple orientation planes and at multiple scales. The keys are used as input to a nearest neighbor indexing method that identifies candidate object matches. Final verification of each match is achieved by finding a low residual least squares solution for the unknown model parameters. Experimental results show that robust object recognition can be achieved in cluttered partially occluded images with a computation time of under 2 seconds.",
                    "title": "Object recognition from local scale-invariant features",
                    "venue": "international conference on computer vision",
                    "year": 1999,
                    "__v": 2,
                    "citationCount": 4272,
                    "result": 4.6561730323340225
                },
                "6d86ad90-fe62-40e5-b917-7e3f31350523": {
                    "authors": [
                        "Fred L. Bookstein"
                    ],
                    "references": [
                        "1c63e1d5-b963-455b-829d-e4f3eb63a36a",
                        "71a947ba-be7c-4642-b1df-e42a69bf880b",
                        "936e0ae4-e6e1-4b3b-9d0a-a6bff589fc7b",
                        "f45d6bd0-f1a4-4f80-b6af-5e3b12bbac3a"
                    ],
                    "keyword": [
                        "warps",
                        "vision",
                        "splines",
                        "related",
                        "principal",
                        "method",
                        "medical",
                        "landmarks",
                        "images",
                        "formulation"
                    ],
                    "group": [],
                    "_id": "6d86ad90-fe62-40e5-b917-7e3f31350523",
                    "abstract": "The decomposition of deformations by principal warps is demonstrated. The method is extended to deal with curving edges between landmarks. This formulation is related to other applications of splines current in computer vision. How they might aid in the extraction of features for analysis, comparison, and diagnosis of biological and medical images in indicated. >",
                    "title": "Principal warps: thin-plate splines and the decomposition of deformations",
                    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "year": 1989,
                    "__v": 2,
                    "citationCount": 1197,
                    "result": 5.591374672798821
                },
                "8fc9506c-3603-4af2-b0c8-02b368863fcb": {
                    "authors": [
                        "Serge J. Belongie",
                        "Jitendra Malik",
                        "Jan Puzicha"
                    ],
                    "references": [
                        "00909251-9935-44f3-94a1-629023b5015b",
                        "042d18d1-aed3-4a9d-ba8b-fb7f3e14f568",
                        "0fc7a847-923c-4742-9b05-2b46eda24b2e",
                        "13cd743f-beb9-43a1-8e08-2ef08f0d8b3f",
                        "1ef607fe-5348-4658-8964-25a57fc49270",
                        "24187b9b-fe6b-484d-9a0e-0b849362fa18",
                        "2ae7a9b5-6231-45ca-9813-afc3a6b5f5ff",
                        "37032748-43bb-410a-8349-d2808bb6f7fa",
                        "59ade036-678c-42ad-bce8-7aa9301103e1",
                        "5ae4ef7f-b13a-4e78-8afd-1e2d22259b87",
                        "5ebbd1f5-dfe5-4eec-9883-b8b5efea366c",
                        "772654a7-a951-4327-aca5-ba5da8dfec7c",
                        "88f85c71-d474-4d12-9c74-43ac3b7c7ee6",
                        "923f5d0a-23a3-4fb1-bee7-ec72122709a4",
                        "932ef745-7197-4b00-bcd4-781bd048938f",
                        "9f84e529-87a3-42f1-9d63-9af710f40925",
                        "a8c6ead3-d61a-4f6a-a702-08743f19eec9",
                        "b592576f-ff29-4a68-9b2f-8a8ad02e9c70",
                        "bf1d8c69-aefb-4a7a-8b02-f815b754833c",
                        "f3959783-a9aa-48a2-9fcc-978879de365e"
                    ],
                    "keyword": [
                        "shapes",
                        "points",
                        "correspondences",
                        "transform",
                        "similarity",
                        "solving",
                        "measuring",
                        "context",
                        "aligning",
                        "recognition"
                    ],
                    "group": [],
                    "_id": "8fc9506c-3603-4af2-b0c8-02b368863fcb",
                    "abstract": "We present a novel approach to measuring similarity between shapes and exploit it for object recognition. In our framework, the measurement of similarity is preceded by (1) solving for correspondences between points on the two shapes, (2) using the correspondences to estimate an aligning transform. In order to solve the correspondence problem, we attach a descriptor, the shape context, to each point. The shape context at a reference point captures the distribution of the remaining points relative to it, thus offering a globally discriminative characterization. Corresponding points on two similar shapes will have similar shape contexts, enabling us to solve for correspondences as an optimal assignment problem. Given the point correspondences, we estimate the transformation that best aligns the two shapes; regularized thin-plate splines provide a flexible class of transformation maps for this purpose. Dis-similarity between two shapes is computed as a sum of matching errors between corresponding points, together with a term measuring the magnitude of the aligning transform. We treat recognition in a nearest-neighbor classification framework. Results are presented for silhouettes, trademarks, handwritten digits and the COIL dataset.",
                    "title": "Matching shapes",
                    "venue": "international conference on computer vision",
                    "year": 2001,
                    "__v": 2,
                    "citationCount": 155,
                    "result": 19.5957385236023
                },
                "923f5d0a-23a3-4fb1-bee7-ec72122709a4": {
                    "authors": [
                        "Timothy F. Cootes",
                        "Christopher J. Taylor",
                        "David H. Cooper",
                        "Jim Graham"
                    ],
                    "references": [
                        "035f8537-61a7-4c4f-b9fe-120f913a38b0",
                        "250f917f-a84e-4018-9e6b-43995d0c2bc6",
                        "560f44a5-d696-449d-9163-662c4cf2a538",
                        "6d24a893-dbf9-4baf-9a3d-2b7b6951ac37",
                        "9980a8c8-2c38-437f-b269-2a5bb1c976cb",
                        "9be82f37-3656-4bb8-bfea-b9f399593807",
                        "b9466c12-f15f-46d1-845b-a6abb14d2d35"
                    ],
                    "keyword": [
                        "model",
                        "images",
                        "objects",
                        "methods",
                        "variability",
                        "training",
                        "set",
                        "robust",
                        "modelbased",
                        "locating"
                    ],
                    "group": [],
                    "_id": "923f5d0a-23a3-4fb1-bee7-ec72122709a4",
                    "abstract": "!, Model-based vision is firmly established as a robust approach to recognizing and locating known rigid objects in the presence of noise, clutter, and occlusion. It is more problematic to apply modelbased methods to images of objects whose appearance can vary, though a number of approaches based on the use of flexible templates have been proposed. The problem with existing methods is that they sacrifice model specificity in order to accommodate variability, thereby compromising robustness during image interpretation. We argue that a model should only be able to deform in ways characteristic of the class of objects it represents. We describe a method for building models by learning patterns of variability from a training set of correctly annotated images. These models can be used for image search in an iterative refinement algorithm analogous to that employed by Active Contour Models (Snakes). The key difference is that our Active Shape Models can only deform to fit the data in ways consistent with the training set. We show several practical examples where we have built such models and used them to locate partially occluded objects in noisy, cluttered images. Q 199s A&& prrss, IN.",
                    "title": "Active shape models—their training and application",
                    "venue": "Computer Vision and Image Understanding",
                    "year": 1995,
                    "__v": 1,
                    "citationCount": 2999,
                    "result": 4.836890969815993
                },
                "932ef745-7197-4b00-bcd4-781bd048938f": {
                    "authors": [
                        "Roy Jonker",
                        "A. Volgenant"
                    ],
                    "references": [
                        "31b29e9b-a9f4-495b-8b68-ce7533244706",
                        "39dcac8b-4a6d-4d4f-a39d-b65f237e9c01",
                        "47f912e5-e0ea-4efe-9993-61f74c29428c",
                        "58d97323-01a9-490b-ae14-e0646e0603b2",
                        "5e194748-846b-4603-8782-7101eea1e2be",
                        "a6426813-9b80-4554-ac3b-41418eec9688",
                        "af3dcf0c-6e6f-4190-a9d6-9a9d2551e378",
                        "b6e98aa1-c44f-425a-ab30-742f68213468",
                        "b9758d19-0d14-4e9b-92b2-5da16c30b4df",
                        "c5a4bbd2-72ee-4aa9-a785-8eeb6ef69edc",
                        "d770a73f-ab6f-4be0-976f-5b10f30b8ed9",
                        "e2030ab0-7afd-4f2c-b593-839a949020eb",
                        "ece88e41-0f3e-4ae0-a6cd-db57b433450d",
                        "ff2fea60-7fef-4d3f-8b9c-c9a2c54afe41"
                    ],
                    "keyword": [
                        "algorithm",
                        "shortest",
                        "problem",
                        "path",
                        "implementation",
                        "uniformly",
                        "special",
                        "sparse",
                        "show",
                        "routines"
                    ],
                    "group": [],
                    "_id": "932ef745-7197-4b00-bcd4-781bd048938f",
                    "abstract": "We develop a shortest augmenting path algorithm for the linear assignment problem. It contains new initialization routines and a special implementation of Dijkstra's shortest path method. For both dense and sparse problems computational experiments show this algorithm to be uniformly faster than the best algorithms from the literature. A Pascal implementation is presented.",
                    "title": "A shortest augmenting path algorithm for dense and sparse linear assignment problems",
                    "venue": "Computing",
                    "year": 1987,
                    "__v": 2,
                    "citationCount": 297,
                    "result": 5.93246590297674
                },
                "9f84e529-87a3-42f1-9d63-9af710f40925": {
                    "authors": [
                        "Martin A. Fischler",
                        "Robert A. Elschlager"
                    ],
                    "references": [
                        "0f8d373b-1312-44fd-97c4-a9926ebb29cc",
                        "469db401-52b5-4183-913d-a10e45bb8af2",
                        "7dac4219-13e1-4000-9c51-108613ffa362",
                        "7db93c71-06a6-4d4f-b893-ec4db1872974"
                    ],
                    "keyword": [
                        "problem",
                        "object",
                        "description",
                        "visual",
                        "specification",
                        "solution",
                        "scheme",
                        "primary",
                        "photograph",
                        "part"
                    ],
                    "group": [],
                    "_id": "9f84e529-87a3-42f1-9d63-9af710f40925",
                    "abstract": "The primary problem dealt with in this paper is the following. Given some description of a visual object, find that object in an actual photograph. Part of the solution to this problem is the specification of a descriptive scheme, and a metric on which to base the decision of \"goodness\" of matching or detection.",
                    "title": "The Representation and Matching of Pictorial Structures",
                    "venue": "IEEE Transactions on Computers",
                    "year": 1973,
                    "__v": 1,
                    "citationCount": 560,
                    "result": 4.820596680581201
                },
                "a8c6ead3-d61a-4f6a-a702-08743f19eec9": {
                    "authors": [
                        "Andrew Edie Johnson",
                        "Martial Hebert"
                    ],
                    "references": [
                        "36dd023a-14a7-479a-89c6-26d731dc5ae3",
                        "4b222616-1498-4af3-98d5-695f25e8d513",
                        "4becfab5-4039-4416-a602-5aeeb743ce60",
                        "602adc87-d33c-498b-8b5d-bea1224d0383",
                        "88521079-bcc0-4cd2-8a15-36add320a399",
                        "9460db78-bb00-420d-b159-299ae393858d",
                        "952c0c92-8cdd-4fc3-a2ad-4601ec80b127",
                        "a0d113be-5fb9-4b5b-866b-fe6900c307f1",
                        "a7a01782-8e14-4dd6-9336-60718abbfc0b",
                        "c33a51f5-0450-4172-bce8-a7a29a50b858",
                        "c39c2ff9-1401-474d-917e-3776f528b204",
                        "d57a30b0-c76d-406b-ae07-6a64ecfd5192",
                        "dfe377d1-9e27-4538-a69f-a802ead9f650",
                        "e65ca26e-ef3c-4875-b573-eda8cc7ae814",
                        "f19a8253-22d8-4574-9ddc-5e36000088fb",
                        "f876c897-0d05-4342-bf8a-0c7efdeca74e"
                    ],
                    "keyword": [
                        "point",
                        "objects",
                        "images",
                        "surface",
                        "scenes",
                        "oriented",
                        "results",
                        "recognition",
                        "parameters",
                        "descriptive"
                    ],
                    "group": [],
                    "_id": "a8c6ead3-d61a-4f6a-a702-08743f19eec9",
                    "abstract": "We present an approach to recognition of complex objects in cluttered 3-D scenes that does not require feature extraction or segmentation. Our object representation comprises descriptive images associated with each oriented point on the surface of an object. Using a single point basis constructed from an oriented point, the position of other points on the surface of the object can be described by two parameters. The accumulation of these parameters for many points on the surface of the object results in an image at each oriented point. These images, localized descriptions of the global shape of the object, are invariant to rigid transformations. Through correlation of images, point correspondences between a model and scene data are established and then grouped using geometric consistency. The effectiveness of our algorithm is demonstrated with results showing recognition of complex objects in cluttered scenes with occlusion.",
                    "title": "Recognizing objects by matching oriented points",
                    "venue": "computer vision and pattern recognition",
                    "year": 1997,
                    "__v": 2,
                    "citationCount": 60,
                    "result": 7.046259201754559
                },
                "d5f8e154-e8c9-45e8-a3a0-fd705f00ced4": {
                    "authors": [
                        "Yehezkel Lamdan",
                        "Jacob T. Schwartz",
                        "Haim J. Wolfson"
                    ],
                    "references": [
                        "2958fc5c-15e8-45e7-8da8-d2e0fa46f0c7",
                        "30ba9e61-604d-435c-ac1b-ceb2bb26c841",
                        "3a500e96-9231-4b20-962d-2b76fc976b89",
                        "3e9d854f-9fe6-4043-aff5-8ab1bdae62e3",
                        "410f357b-1489-4a55-bf21-4c7c2805e353",
                        "46da0145-fc17-4096-9624-4828cb32e116",
                        "79bd9613-8976-41a1-b0b7-133b80b8477e",
                        "873c1c6b-ef62-4731-8d1d-e2a9cff16fd2",
                        "a652c3c9-ea8c-4f64-a8ec-1f111e415525",
                        "c39c2ff9-1401-474d-917e-3776f528b204",
                        "c9fa31f7-f6ce-49ea-b42c-8d03ae59dbe4",
                        "caeecc11-ec92-47d8-b112-c43b88dd4491",
                        "e2bbf174-7398-4c3d-a310-6a067bd948a9",
                        "f84b25df-046a-439b-a69d-d9a97b49d9b0"
                    ],
                    "keyword": [
                        "recognition",
                        "scene",
                        "objects",
                        "algorithm",
                        "phase",
                        "occluded",
                        "efficient"
                    ],
                    "group": [],
                    "_id": "d5f8e154-e8c9-45e8-a3a0-fd705f00ced4",
                    "abstract": "New techniques are described for model-based recognition of the objects in 3-D space. The recognition is performed from single gray-scale images taken from unknown viewpoints. The objects in the scene may be overlapping and partially occluded. An efficient matching algorithm, which assumes affine approximation to the prospective viewing transformation, is proposed. The algorithm has an offline model preprocessing (shape representation) phase which is independent of the scene information and a recognition phase based on efficient indexing. It has a straightforward parallel implementation. The algorithm was successfully tested in recognition of industrial objects appearing in composite occluded scenes. >",
                    "title": "Affine invariant model-based object recognition",
                    "venue": "international conference on robotics and automation",
                    "year": 1990,
                    "__v": 2,
                    "citationCount": 163,
                    "result": 2.9925402598777207
                },
                "d6104d9a-faaa-4db4-8c4e-748176157ef2": {
                    "authors": [
                        "Dennis DeCoste",
                        "Bernhard Schölkopf"
                    ],
                    "references": [
                        "186ea3a7-0ce3-41a1-8380-c3d10543f451",
                        "1ef607fe-5348-4658-8964-25a57fc49270",
                        "3514c54b-4a5a-4807-9d10-174915c9202b",
                        "3e60e095-4c4b-46ca-9b6b-97ae0ea9eebb",
                        "50dd56db-151d-4d62-8576-65f0ef6f381b",
                        "549f0527-0f13-4447-9dc0-ca699e2dc219",
                        "56f68d8b-36ca-422e-b721-c1f17ac7a78d",
                        "87969fc2-8332-4ee5-b6b0-e1b26d01ebd4",
                        "8b2c0aff-4589-4e0f-aae4-4f84a4413406",
                        "92af8bc1-80b2-40aa-9c0c-f40dbebee3a0",
                        "94898e1d-1e50-41ab-9dcc-2c2e030cddd0",
                        "ae3e7593-586f-495f-9416-4b50ed1fcd10",
                        "b4c5a572-c0a9-41e3-8782-9d4ee8105d81",
                        "b90f9310-726f-4116-9322-6fc01ab598fd",
                        "c1d82182-8cfa-4d6e-92b7-2b7e430c4f60",
                        "cabaf8b7-46f2-4eed-af57-120fd206f760",
                        "cb4fbf1c-02e4-4ca9-995d-29f5282fdb4a",
                        "ec8c9e00-d026-4d33-b102-ffd5389234cd",
                        "eca46fc4-e594-461f-83b8-aa5247e440ca",
                        "f006e236-59ad-4647-a59f-4f46dc2c85be",
                        "f6c418d7-c420-492f-8d24-de3827674b93"
                    ],
                    "keyword": [
                        "training",
                        "svm",
                        "significant",
                        "results",
                        "reported",
                        "methods",
                        "work",
                        "wellknown",
                        "vector",
                        "times"
                    ],
                    "group": [],
                    "_id": "d6104d9a-faaa-4db4-8c4e-748176157ef2",
                    "abstract": "Practical experience has shown that in order to obtain the best possible performance, prior knowledge about invariances of a classification problem at hand ought to be incorporated into the training procedure. We describe and review all known methods for doing so in support vector machines, provide experimental results, and discuss their respective merits. One of the significant new results reported in this work is our recent achievement of the lowest reported test error on the well-known MNIST digit recognition benchmark task, with SVM training times that are also significantly faster than previous SVM methods.",
                    "title": "Training Invariant Support Vector Machines",
                    "venue": "Machine Learning",
                    "year": 2002,
                    "__v": 2,
                    "citationCount": 226,
                    "result": 5.636672881641922
                },
                "d9752a5a-1603-45cc-9a21-7997750d429f": {
                    "authors": [
                        "Daniel P. Huttenlocher",
                        "Gregory A. Klanderman",
                        "William J. Rucklidge"
                    ],
                    "references": [
                        "14be2ac1-2ade-4c0c-aaa5-9c586b36f6ea",
                        "510eec1d-f82c-4b19-b116-b8fd4c66531a",
                        "79bd9613-8976-41a1-b0b7-133b80b8477e",
                        "cd84aa5d-a982-4c0a-9b56-6c618a57264e",
                        "d209fd88-7dbc-4fff-9646-b5764ad59a42",
                        "d7ec6a14-d907-4a3a-aa7c-acb31a22c0ba",
                        "de65be14-6472-4725-b660-f5fb7370e540",
                        "e9775ae8-8eb4-483a-9210-6eb22d8e68e1",
                        "fded4064-3094-42e0-82e9-a36e993fa5d6"
                    ],
                    "keyword": [
                        "model",
                        "image",
                        "methods",
                        "distance",
                        "hausdorff",
                        "set",
                        "positions",
                        "point",
                        "extended",
                        "computing"
                    ],
                    "group": [],
                    "_id": "d9752a5a-1603-45cc-9a21-7997750d429f",
                    "abstract": "The Hausdorff distance measures the extent to which each point of a model set lies near some point of an image set and vice versa. Thus, this distance can be used to determine the degree of resemblance between two objects that are superimposed on one another. Efficient algorithms for computing the Hausdorff distance between all possible relative positions of a binary image and a model are presented. The focus is primarily on the case in which the model is only allowed to translate with respect to the image. The techniques are extended to rigid motion. The Hausdorff distance computation differs from many other shape comparison methods in that no correspondence between the model and the image is derived. The method is quite tolerant of small position errors such as those that occur with edge detectors and other feature extraction methods. It is shown that the method extends naturally to the problem of comparing a portion of a model against an image. >",
                    "title": "Comparing images using the Hausdorff distance",
                    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                    "year": 1993,
                    "__v": 2,
                    "citationCount": 1275,
                    "result": 5.62592570827865
                }
            }
        ],
        "_id": "b592576f-ff29-4a68-9b2f-8a8ad02e9c70",
        "abstract": "We present a novel approach to measuring similarity between shapes and exploit it for object recognition. In our framework, the measurement of similarity is preceded by: (1) solving for correspondences between points on the two shapes; (2) using the correspondences to estimate an aligning transform. In order to solve the correspondence problem, we attach a descriptor, the shape context, to each point. The shape context at a reference point captures the distribution of the remaining points relative to it, thus offering a globally discriminative characterization. Corresponding points on two similar shapes will have similar shape contexts, enabling us to solve for correspondences as an optimal assignment problem. Given the point correspondences, we estimate the transformation that best aligns the two shapes; regularized thin-plate splines provide a flexible class of transformation maps for this purpose. The dissimilarity between the two shapes is computed as a sum of matching errors between corresponding points, together with a term measuring the magnitude of the aligning transform. We treat recognition in a nearest-neighbor classification framework as the problem of finding the stored prototype shape that is maximally similar to that in the image. Results are presented for silhouettes, trademarks, handwritten digits, and the COIL data set.",
        "title": "Shape matching and object recognition using shape contexts",
        "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
        "year": 2002,
        "__v": 1,
        "citationCount": 2839
    },
    {
        "authors": [
            "Dorin Comaniciu",
            "Peter Meer"
        ],
        "references": [
            "01df6660-e54b-4cab-a20e-179393feb854",
            "088d00cf-ed12-4552-8958-8b550401f355",
            "0c32535a-72bb-4fda-b12b-627147f8b358",
            "1017d9d4-9a4c-423d-ad40-6d9bebbd6b31",
            "1192f1a1-7265-4886-a8f5-abed536b07b2",
            "1f55baf9-4f9a-4c9c-99ff-75e85a560c52",
            "209f46d1-66c6-496c-ba83-6a0a7e03db6a",
            "21c9f688-56e7-4018-8bd0-3995f086598d",
            "2807e6ff-b9a5-49ec-8b9f-892aee014156",
            "35426f5d-4886-4c49-b752-aec497760038",
            "3544f26c-7ca1-458c-9c28-24ac9612597c",
            "3da61fff-399e-4c16-83e1-39f805b34464",
            "3fef39b1-5391-4424-9847-bfe85c9802f2",
            "42609520-598f-421d-8f8c-3dbb26081d95",
            "48b2f9f3-f780-4f6b-95b9-b650bb93ef65",
            "4ef71595-df33-4849-aafd-7092328d04a7",
            "540e185e-4473-4e4a-aef3-b624d0fbf25a",
            "54c6dc5e-b647-4ac3-a31a-afab59c8b4fa",
            "57958425-17fa-46de-a93e-e72f38d481f8",
            "5824891b-fe0c-404b-9365-085843b11f26",
            "6dfd9077-2f59-4692-9fcc-f9e336591a15",
            "70b17c09-d19a-451b-acc4-b3747ffa96d9",
            "756a08c5-b7e8-4dee-a019-cba0f0fe482b",
            "795b3efb-a6e8-479a-81f6-91328002dc03",
            "79ee46f3-5808-4687-bec9-7b35c9e51fe6",
            "7b57db11-7c4d-4d1e-aa62-3a5d7d1f7987",
            "84d43d53-4371-44e7-9cfd-c4be7cc48483",
            "904be517-8954-4149-87ce-889b629463df",
            "970d3cf0-11a6-4c04-b8e1-7eaca9dbc757",
            "9a5c5874-2877-4b08-87cc-cc61ce9b7653",
            "a4f0f562-bbfb-43ac-a175-fa17ca2ff0fb",
            "a77c2879-23b2-476f-884d-20b591a20b1d",
            "b29cb808-1f59-40e9-8afa-26a3701b6284",
            "b3a4feeb-0d9c-4a10-89d3-8ca0852d04e7",
            "b608af66-6368-44dc-a670-2a3e42561ee1",
            "d4096c82-a4ad-41c8-a3c6-4aa2924dfcbb",
            "d69429ef-c8d6-4074-b1b2-73a7bc5e2fa6",
            "e5f5cacc-f6da-458e-b8cb-bcfbd753e611",
            "ee8ff75d-caec-42e9-aa07-cbe4fdd7541b",
            "f2c49442-eed0-4e05-bb94-9fdaa0312e9f",
            "f9c4a94d-c1e6-494f-bff9-1bb96f9ccb33"
        ],
        "keyword": [],
        "group": [],
        "_id": "c8f80ea6-4602-458c-9a70-daf1c646c89b",
        "abstract": "A general non-parametric technique is proposed for the analysis of a complex multimodal feature space and to delineate arbitrarily shaped clusters in it. The basic computational module of the technique is an old pattern recognition procedure: the mean shift. For discrete data, we prove the convergence of a recursive mean shift procedure to the nearest stationary point of the underlying density function and, thus, its utility in detecting the modes of the density. The relation of the mean shift procedure to the Nadaraya-Watson estimator from kernel regression and the robust M-estimators; of location is also established. Algorithms for two low-level vision tasks discontinuity-preserving smoothing and image segmentation - are described as applications. In these algorithms, the only user-set parameter is the resolution of the analysis, and either gray-level or color images are accepted as input. Extensive experimental results illustrate their excellent performance.",
        "title": "Mean shift: a robust approach toward feature space analysis",
        "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
        "year": 2002,
        "__v": 0,
        "citationCount": 3903
    },
    {
        "authors": [
            "Simon Haykin"
        ],
        "references": [
            "0eab603a-3623-4ed4-b9e6-18e7f38b9057",
            "0f2cb38e-b8ec-426f-ab8a-453c4ef98413",
            "310cbba4-d88d-4bf4-a4f2-738f91b5f8c8",
            "3b4570fa-e660-4909-b9ee-4b8f78d25dfe",
            "5697e140-af9e-4d63-87be-99b357d59e3a",
            "720f59d2-acc3-4d5a-91c2-258d137d9647",
            "7d3bff12-8413-4c3e-9bbd-af96df0405d7",
            "8cc9ea80-563f-4e62-bda9-8ff6d71cf6ae",
            "db26488d-78be-44b1-a343-e896f43c5d29",
            "f1e74152-3f7c-4c44-b628-cdf47a17587f"
        ],
        "keyword": [],
        "group": [],
        "_id": "d1ba534e-3f80-4366-bb83-be16006f9e18",
        "abstract": "Cognitive radio is viewed as a novel approach for improving the utilization of a precious natural resource: the radio electromagnetic spectrum. The cognitive radio, built on a software-defined radio, is defined as an intelligent wireless communication system that is aware of its environment and uses the methodology of understanding-by-building to learn from the environment and adapt to statistical variations in the input stimuli, with two primary objectives in mind: /spl middot/ highly reliable communication whenever and wherever needed; /spl middot/ efficient utilization of the radio spectrum. Following the discussion of interference temperature as a new metric for the quantification and management of interference, the paper addresses three fundamental cognitive tasks. 1) Radio-scene analysis. 2) Channel-state estimation and predictive modeling. 3) Transmit-power control and dynamic spectrum management. This work also discusses the emergent behavior of cognitive radio.",
        "title": "Cognitive radio: brain-empowered wireless communications",
        "venue": "IEEE Journal on Selected Areas in Communications",
        "year": 2005,
        "__v": 0,
        "citationCount": 4644
    },
    {
        "authors": [
            "Dan Boneh",
            "Matthew K. Franklin"
        ],
        "references": [
            "062d5c6a-6725-4603-b49c-fb92c4bd0f5a",
            "16f8967e-daa0-40fa-9a66-6f3ee9e78cac",
            "1ae39de8-3d73-4ab1-a158-6acbc17754fe",
            "1e7e39e3-3221-46e0-a63d-46c5a68a2508",
            "22985d1d-f524-4b7b-bb09-f0144488d66a",
            "3d933ed4-75b8-4631-a7a6-6eb5043122d8",
            "45d56db9-7547-4c37-98be-5da5546144dd",
            "49ba0a53-1c29-4515-a592-84fb5dc6e7bc",
            "4da2fc3d-e476-4bc6-9cd4-1dba96e81dbf",
            "5e888611-e345-41ed-8195-3156c3069779",
            "6947b732-592a-48fd-a6fc-cd39c0f758e0",
            "a0254949-6d9c-498c-8022-8d96836c36a0",
            "ac0db18c-141b-499a-9499-bc11ed2a61bc",
            "b10fd24d-6a42-4821-9517-da6d1e14b17b",
            "b68fc787-7817-421e-8e66-8a98ab9db1ad",
            "c14ef99e-1e94-49ca-9fca-8c753aceef73",
            "d21dc479-0ead-4873-b622-c444d1603161",
            "d8dc0d21-c4d7-4408-9417-f300a7aeb4a7",
            "da2fb9dd-8971-49b7-858c-44581348f019",
            "e796f5bf-73b8-4473-9e9c-716887059a92",
            "f81652de-d97b-4935-a1ba-5c290c7695a3"
        ],
        "keyword": [],
        "group": [],
        "_id": "ed804c0f-dad5-4ce5-9da3-f69da43f137a",
        "abstract": "We propose a fully functional identity-based encryption (IBE) scheme. The scheme has chosen ciphertext security in the random oracle model assuming a variant of the computational Diffie--Hellman problem. Our system is based on bilinear maps between groups. The Weil pairing on elliptic curves is an example of such a map. We give precise definitions for secure IBE schemes and give several applications for such systems.",
        "title": "Identity-Based Encryption from the Weil Pairing",
        "venue": "SIAM Journal on Computing",
        "year": 2003,
        "__v": 0,
        "citationCount": 2784
    },
    {
        "authors": [
            "Mikhail Belkin",
            "Partha Niyogi"
        ],
        "references": [
            "0f74fecb-75c8-4089-9d96-9f95f134a1a4",
            "2cd6f789-de0b-4d5d-b3d0-60962bd31d41",
            "3e5fd33f-1fd0-4815-a47a-3c41a26a538a",
            "9438a773-c15c-4ef2-a97c-54f643ce6082",
            "94898e1d-1e50-41ab-9dcc-2c2e030cddd0",
            "a004b495-c45e-483b-ba58-0267bdc8659c",
            "c2812488-7d34-48a7-8916-d4d4bdd89a03",
            "c980c937-f30c-4593-a4a3-a7e85c0e83bc",
            "cbff2ff2-6b8f-425d-a5ef-aff0de9be3e5",
            "dd7b3cc4-02a8-4082-a0a1-4f6d05785841",
            "ea8cd3d8-17ae-4a1e-8f83-1609469087af"
        ],
        "keyword": [],
        "group": [],
        "_id": "05bbaec3-7980-4941-8638-2bbfa4ac8be0",
        "abstract": "One of the central problems in machine learning and pattern recognition is to develop appropriate representations for complex data. We consider the problem of constructing a representation for data lying on a low-dimensional manifold embedded in a high-dimensional space. Drawing on the correspondence between the graph Laplacian, the Laplace Beltrami operator on the manifold, and the connections to the heat equation, we propose a geometrically motivated algorithm for representing the high-dimensional data. The algorithm provides a computationally efficient approach to nonlinear dimensionality reduction that has locality-preserving properties and a natural connection to clustering. Some potential applications and illustrative examples are discussed.",
        "title": "Laplacian Eigenmaps for dimensionality reduction and data representation",
        "venue": "Neural Computation",
        "year": 2003,
        "__v": 0,
        "citationCount": 2308
    },
    {
        "authors": [
            "Viswanath Venkatesh",
            "Michael G. Morris",
            "Gordon B. Davis",
            "Fred D. Davis"
        ],
        "references": [
            "017d7159-547c-4627-9a45-d98331ed2892",
            "0a5567c5-7a18-4e16-9f53-a79c9f21e32d",
            "1014c457-be27-4c1b-b460-f83e82bff2fb",
            "22c866d0-81fe-4011-8149-676ac1fa02b8",
            "2df731d1-37e4-4afb-a9b0-60a5361a79ff",
            "39bd75e5-c40b-474f-85f3-c8ed63c11765",
            "3bac5d08-74d8-4776-b976-c80acffe44d7",
            "54f4f461-e519-492f-aa4e-4aa1286987c4",
            "571de123-77aa-4b08-a25e-7f80cf5a2e5b",
            "662db3d8-b707-420c-9727-42e9f12a5479",
            "67316eeb-77f8-43f4-b0bd-d604387e80f1",
            "7583b6d0-44bd-444e-a311-4c537015a77d",
            "7e304910-1805-4537-9f54-1a96f4023ffd",
            "860c9110-1a3c-416c-87ee-98edd0565a62",
            "881edf4e-5fbe-4f6c-9251-662c115ad0b4",
            "9d912297-e52f-4ab6-add4-633e0f263933",
            "9da2f3bb-2b7f-48e1-86af-7e45c808bc49",
            "b1ba90ca-3599-4363-8703-5acce9f7f3f5",
            "d5707c9f-323b-4336-8c0f-fa28062045b3",
            "ddd277ef-ea52-4d62-ae5b-9dcaec41627f",
            "e1820b51-0c91-47d4-9c66-911b05a2936a",
            "ecc57291-ecac-4ca6-b39a-d68c9d8f2aa6",
            "ee3f66e5-6921-4320-9125-944eb33a04f1"
        ],
        "keyword": [],
        "group": [],
        "_id": "0ffbba6a-4711-4e10-ad37-358bd8cb6873",
        "abstract": "Information technology (IT) acceptance research has yielded many competing models, each with different sets of acceptance determinants. In this paper, we (1) review user acceptance literature and discuss eight prominent models, (2) empirically compare the eight models and their extensions, (3) formulate a unified model that integrates elements across the eight models, and (4) empirically validate the unified model. The eight models reviewed are the theory of reasoned action, the technology acceptance model, the motivational model, the theory of planned behavior, a model combining the technology acceptance model and the theory of planned behavior, the model of PC utilization, the innovation diffusion theory, and the social cognitive theory. Using data from four organizations over a six-month period with three points of measurement, the eight models explained between 17 percent and 53 percent of the variance in user intentions to use information technology. Next, a unified model, called the Unified Theory of Acceptance and Use of Technology (UTAUT), was formulated, with four core determinants of intention and usage, and up to four moderators of key relationships. UTAUT was then tested using the original data and found to outperform the eight individual models (adjusted R2 of 69 percent). UTAUT was then confirmed with data from two new organizations with similar results (adjusted R2 of 70 percent). UTAUT thus provides a useful tool for managers needing to assess the likelihood of success for new technology introductions and helps them understand the drivers of acceptance in order to proactively design interventions (including training, marketing, etc.) targeted at populations of users that may be less inclined to adopt and use new systems. The paper also makes several recommendations for future research including developing a deeper understanding of the dynamic influences studied here, refining measurement of the core constructs used in UTAUT, and understanding the organizational outcomes associated with new technology use.",
        "title": "User acceptance of information technology: toward a unified view",
        "venue": "Management Information Systems Quarterly",
        "year": 2003,
        "__v": 0,
        "citationCount": 3776
    },
    {
        "authors": [
            "Kishore Papineni",
            "Salim Roukos",
            "Todd Ward",
            "Wei-Jing Zhu"
        ],
        "references": [],
        "keyword": [],
        "group": [],
        "_id": "1268112c-a3a5-411d-9469-c9937aed533e",
        "abstract": "Human evaluations of machine translation are extensive but expensive. Human evaluations can take months to finish and involve human labor that can not be reused. We propose a method of automatic machine translation evaluation that is quick, inexpensive, and language-independent, that correlates highly with human evaluation, and that has little marginal cost per run. We present this method as an automated understudy to skilled human judges which substitutes for them when there is need for quick or frequent evaluations.",
        "title": "Bleu: a Method for Automatic Evaluation of Machine Translation",
        "venue": "meeting of the association for computational linguistics",
        "year": 2002,
        "__v": 0,
        "citationCount": 2900
    },
    {
        "authors": [
            "Wendi B. Heinzelman",
            "Anantha P. Chandrakasan",
            "Hari Balakrishnan"
        ],
        "references": [
            "1081ae4c-2a85-4b47-a903-b5518ee62334",
            "23dd7fc0-1ebd-43ce-ab3e-43896512c209",
            "282f60bc-e000-420c-b8f7-6d52d645e2b9",
            "38b10094-82ce-4476-8845-d4e8d027942a",
            "38f54b84-5272-43df-8cde-a3e755b17dee",
            "55a6413a-4a9c-4e8d-957b-8c1a4e5d5f0b",
            "7845a1ac-4941-4d61-b361-a70ddab88fb7",
            "9dc99b87-9617-4871-94d8-d44eb595db13",
            "9e063b41-0ada-4db8-8846-6e5153a0de55",
            "afc06b7c-7fb3-4f88-942b-3076ed77920e",
            "e2baa34c-eba8-45fc-ac64-693761c9680b"
        ],
        "keyword": [],
        "group": [],
        "_id": "1ee4b656-7d2c-45e8-b2e8-b5633b992eeb",
        "abstract": "Networking together hundreds or thousands of cheap microsensor nodes allows users to accurately monitor a remote environment by intelligently combining the data from the individual nodes. These networks require robust wireless communication protocols that are energy efficient and provide low latency. We develop and analyze low-energy adaptive clustering hierarchy (LEACH), a protocol architecture for microsensor networks that combines the ideas of energy-efficient cluster-based routing and media access together with application-specific data aggregation to achieve good performance in terms of system lifetime, latency, and application-perceived quality. LEACH includes a new, distributed cluster formation technique that enables self-organization of large numbers of nodes, algorithms for adapting clusters and rotating cluster head positions to evenly distribute the energy load among all the nodes, and techniques to enable distributed signal processing to save communication resources. Our results show that LEACH can improve system lifetime by an order of magnitude compared with general-purpose multihop approaches.",
        "title": "An application-specific protocol architecture for wireless microsensor networks",
        "venue": "IEEE Transactions on Wireless Communications",
        "year": 2002,
        "__v": 0,
        "citationCount": 2562
    },
    {
        "authors": [
            "Daniel Scharstein",
            "Richard Szeliski",
            "Ramin Zabih"
        ],
        "references": [
            "0047b2cf-bd19-4f8a-979e-ef5cc5b4a43f",
            "004aa844-c144-4f34-b328-e054848d2c82",
            "019da994-fd26-4a39-a1a5-f6e52a18933a",
            "07c8a80e-0892-408f-9e56-4e77d9441a64",
            "0c3cac6b-305e-4f1c-8ab8-72c6a3a551fe",
            "0f9cfb03-c1f3-4a60-886e-08b07d5e005c",
            "11666f79-0a9d-49a3-b327-d194e202c94f",
            "15a2345f-3667-4fde-b64e-30471b6ae9ee",
            "16ccd666-4632-42fa-9e92-8cd740177e6b",
            "1b5dfcf4-8c22-4438-901c-5bed88fdda29",
            "1c09ef91-f69a-43e4-aaa7-571f3a143ea9",
            "1c9d9c56-5ae9-4d13-a4b2-9c0833676f70",
            "200c1972-9f6c-4e1b-9dbe-a1d29c7641cb",
            "239a71ea-70f9-450c-9b3c-658faab40d9d",
            "25b0c9f9-0c8a-4f2a-b075-90d339b6faa3",
            "2bb7edd0-987a-4b75-916f-957764d7d0e0",
            "32148a0b-6ce4-4a1e-a1d2-98a96b27b24f",
            "37e76afb-f79f-41f8-b75d-28dadd7d5cd7",
            "3a8fbc53-3805-4e6f-9f45-6881b640eb5e",
            "3b1b6ffe-75aa-45d1-9f3e-dadd4479a272",
            "3f4cc95c-5f47-4031-8671-e23ff4fe2ed2",
            "4383b14b-805b-43d4-84a3-b70181605b18",
            "45ef6717-ea63-4be0-bb43-26747479ccbb",
            "48e25c19-07a0-46c9-a659-e76db6e72d74",
            "4d6cc0b7-557d-4594-8bc8-ab1ce0ac251e",
            "54b8ad0d-2246-4650-a09b-5f5b9705e0e6",
            "558f4de5-92d8-4e29-a667-3159dd43262a",
            "55df9539-92c1-4080-b4b6-154771405001",
            "598627d0-d01d-4398-a45e-1440d21fe4f2",
            "5be0f6b3-82ef-4371-99eb-f72853a7e1f3",
            "62aa6ba4-1331-4c57-99f5-978d580c9573",
            "6c9927be-dd3f-4a48-8ed6-b969a66e5c91",
            "6e0d7a60-4787-4348-84a5-5b94664a5777",
            "70d6f58b-91bb-4c01-9f18-e62dc01d087d",
            "712f3c82-078f-42a8-9f90-da62b4175b17",
            "76845b3d-e45f-443c-a181-b1b75f17d47b",
            "7781665f-ef39-4237-9857-63477d05f5ac",
            "78bbab5f-b63b-40cc-9c8a-2c146191d833",
            "7e130624-dee1-4b3d-bd66-c6febab5a5a0",
            "7e598ce4-7739-42dd-8761-eb8984ed2b19",
            "850e99fb-725d-4f54-8e01-4791bfffb283",
            "85471950-c85d-4494-ac99-30b5450ad095",
            "8a4274f4-8925-4724-aca5-4f9c3455dc3e",
            "8f4f3015-c03d-46e1-90fb-2c42ea2cb91f",
            "900c927f-8e6e-4290-8eac-63fef682460d",
            "90483bd3-a6a7-4799-93cf-af14e991335c",
            "936e0ae4-e6e1-4b3b-9d0a-a6bff589fc7b",
            "942ceea1-92aa-4e72-94a7-bb65bb5889ed",
            "94acc1d1-4b4e-4796-9b58-8cf91b031e7e",
            "97fcbcf5-3e50-4d78-bbe3-18660872b887",
            "a36cd635-6811-4a18-a424-46fd4719ae31",
            "a57c6dbb-09d2-4c2e-86ba-02e47e78f5af",
            "a7da5f11-1302-4305-a67a-9503dea05eb7",
            "a872c04a-47c6-4f4b-b0b9-3afbaa3538cf",
            "a8eade43-4ee6-4165-a08e-c92d0d748343",
            "b00ef6b5-66d3-480a-ae96-03c3ddf2e26e",
            "b1139559-cdb8-4b39-b8a1-f2125166a223",
            "b1c2251e-7b54-41e5-8130-10d9646e02da",
            "b2ced9a5-3457-48b8-8d4c-66badd866d75",
            "bb138fb8-d3a9-497a-879d-b21aa7347b53",
            "be0f6fa3-438a-4d3e-b809-2a31857642fd",
            "be7fa5a9-6fc4-4aea-8e18-6c206ab42d14",
            "bfeeb55f-4b90-4886-aa57-817ba8de7988",
            "c258aec7-ba1b-4228-b47b-a0900a1bcfe2",
            "c3ec3b14-75be-4b18-af66-195537226585",
            "c6977873-accf-4edd-a522-ad649fc8295a",
            "c7423207-f332-480d-b5d1-7e96279e574c",
            "cae374ce-5b99-482e-950a-0b9e304eb498",
            "d1538940-ff7f-4b82-9f1d-8972c0bdb4ef",
            "d46a67de-c591-4872-a836-47165538b63c",
            "d6edad4f-53c7-4a29-b484-05872a3cc82a",
            "d8229968-5440-4e12-ae6e-d7ba4f8eb389",
            "df847368-a372-4190-aac2-98c4bb9d0ddb",
            "e8a7d5ab-2a86-4f90-a193-c62c686d5ea7",
            "e927dff1-6ed4-45fd-8852-eb804e11e665",
            "e9939b8b-6fcb-4ded-ac64-43c7fdfb52d6",
            "f0887f29-b2e1-4971-a369-4df8b83b8996",
            "f27cb993-16cd-44f9-b0c8-6bbeb3ecf297",
            "f37628db-beac-4a64-ab7b-cd0ce4f943a9",
            "f3868715-abb3-4115-b57b-dc6d874f02d1",
            "f39486db-a4d9-49b4-a659-44c63900a7d5",
            "f45d6bd0-f1a4-4f80-b6af-5e3b12bbac3a",
            "f4d90d70-135a-4d1c-bd61-693a2bf04253",
            "f6326193-ef92-4e64-8a4e-7439f8692fa1",
            "f6706f16-c997-4b7f-a044-1d1a9f85dd51",
            "f7037864-4b92-437b-a90e-509d4ec350c8",
            "fd99a7a7-0aa2-4607-91bd-975285af5ad1"
        ],
        "keyword": [],
        "group": [],
        "_id": "1f520d1a-5870-477d-85d7-0f50be690ea7",
        "abstract": "Stereo matching is one of the most active research areas in computer vision. While a large number of algorithms for stereo correspondence have been developed, relatively little work has been done on characterizing their performance. In this paper, we present a taxonomy of dense, two-frame stereo methods designed to assess the different components and design decisions made in individual stereo algorithms. Using this taxonomy, we compare existing stereo methods and present experiments evaluating the performance of many different variants. In order to establish a common software platform and a collection of data sets for easy evaluation, we have designed a stand-alone, flexible C++ implementation that enables the evaluation of individual components and that can be easily extended to include new algorithms. We have also produced several new multiframe stereo data sets with ground truth, and are making both the code and data sets available on the Web.",
        "title": "A taxonomy and evaluation of dense two-frame stereo correspondence algorithms",
        "venue": "International Journal of Computer Vision",
        "year": 2001,
        "__v": 0,
        "citationCount": 2529
    },
    {
        "authors": [
            "Reza Olfati-Saber",
            "Richard M. Murray"
        ],
        "references": [
            "232cfed7-f88e-4545-b686-8b72b7a96480",
            "51a16a30-666c-4b4a-8962-ec187c59c399",
            "551b0ff9-7423-4376-a3a0-dd6a352c4079",
            "7f5dd462-46b9-429b-ba14-8a60d3d437a0",
            "ab35dc68-62bd-4c54-81d3-9a8406827489",
            "aeabc622-720d-44d0-888c-787e7d377f54",
            "b6a0562d-91b9-4b65-a395-0e705e24f3ba",
            "bf96410c-8b91-41bf-aff4-ed144c1b6e8c",
            "c6fb8895-3ef3-4207-a9bc-5b41a7a17a23",
            "d7b5aadf-ec30-4fb7-9224-7474169d3744",
            "ea1d5c21-fba6-4fae-9fdc-ee7679ee46c9",
            "fb3683fe-a6d4-4918-b96e-595abd299183"
        ],
        "keyword": [],
        "group": [],
        "_id": "2768199c-b9d6-4001-94d3-e6429c93bc5f",
        "abstract": "In this paper, we discuss consensus problems for networks of dynamic agents with fixed and switching topologies. We analyze three cases: 1) directed networks with fixed topology; 2) directed networks with switching topology; and 3) undirected networks with communication time-delays and fixed topology. We introduce two consensus protocols for networks with and without time-delays and provide a convergence analysis in all three cases. We establish a direct connection between the algebraic connectivity (or Fiedler eigenvalue) of the network and the performance (or negotiation speed) of a linear consensus protocol. This required the generalization of the notion of algebraic connectivity of undirected graphs to digraphs. It turns out that balanced digraphs play a key role in addressing average-consensus problems. We introduce disagreement functions for convergence analysis of consensus protocols. A disagreement function is a Lyapunov function for the disagreement network dynamics. We proposed a simple disagreement function that is a common Lyapunov function for the disagreement dynamics of a directed network with switching topology. A distinctive feature of this work is to address consensus problems for networks with directed information flow. We provide analytical tools that rely on algebraic graph theory, matrix theory, and control theory. Simulations are provided that demonstrate the effectiveness of our theoretical results.",
        "title": "Consensus problems in networks of agents with switching topology and time-delays",
        "venue": "IEEE Transactions on Automatic Control",
        "year": 2004,
        "__v": 0,
        "citationCount": 2436
    },
    {
        "authors": [
            "Jia Deng",
            "Wei Dong",
            "Richard Socher",
            "Li-Jia Li",
            "Kai Li",
            "Li Fei-Fei"
        ],
        "references": [
            "23120ec2-cd0d-48ed-abef-567a3f9ea103",
            "32a53bab-1ede-4869-98ad-d2ff0c1e3367",
            "40f728c0-55b3-423b-aff5-a9b3ff27b7d5",
            "433969bb-d29f-4cac-83a5-ccfb5c6c7b4e",
            "52ebe1f5-baab-4da0-aaff-d6972b921e33",
            "595fc59f-a7b2-4eed-b62e-f18dcae4c3ce",
            "61447020-9a4b-4742-affd-fb5cde9d84ae",
            "6c38b3b4-7562-493d-a40c-fe70abf039a7",
            "72cadcf0-6129-4854-a912-a7399008393a",
            "80a2bee0-7dff-45f9-a1b6-b3f467738100",
            "98801e79-fc9d-4c6a-a383-10e937c9d008",
            "9aea2ad1-64c1-4e32-b991-1333e5b60a13",
            "a6ee5009-aebc-4cda-8ef9-d855297b949c",
            "b3e241a6-126f-40fb-a063-8ed7d0223a3c",
            "b944f77f-113b-4a02-ae5e-d4a124b8fd5b",
            "d20eb927-339a-4c81-8b54-1a49cd7b7ec0",
            "e012ba25-c703-4a1b-8d66-bdd2d9048de2",
            "ed72bc77-6dfd-47c7-99f6-2c609c264797",
            "ffa31d0c-ff37-4bf3-b213-6d8a968e6636"
        ],
        "keyword": [],
        "group": [],
        "_id": "2b6a3d0f-368f-45bb-be23-4e82f62fbbf7",
        "abstract": "The explosion of image data on the Internet has the potential to foster more sophisticated and robust models and algorithms to index, retrieve, organize and interact with images and multimedia data. But exactly how such data can be harnessed and organized remains a critical problem. We introduce here a new database called “ImageNet”, a large-scale ontology of images built upon the backbone of the WordNet structure. ImageNet aims to populate the majority of the 80,000 synsets of WordNet with an average of 500-1000 clean and full resolution images. This will result in tens of millions of annotated images organized by the semantic hierarchy of WordNet. This paper offers a detailed analysis of ImageNet in its current state: 12 subtrees with 5247 synsets and 3.2 million images in total. We show that ImageNet is much larger in scale and diversity and much more accurate than the current image datasets. Constructing such a large-scale database is a challenging task. We describe the data collection scheme with Amazon Mechanical Turk. Lastly, we illustrate the usefulness of ImageNet through three simple applications in object recognition, image classification and automatic object clustering. We hope that the scale, accuracy, diversity and hierarchical structure of ImageNet can offer unparalleled opportunities to researchers in the computer vision community and beyond.",
        "title": "ImageNet: A large-scale hierarchical image database",
        "venue": "computer vision and pattern recognition",
        "year": 2009,
        "__v": 0,
        "citationCount": 2307
    },
    {
        "authors": [
            "Tony F. Chan",
            "Luminita A. Vese"
        ],
        "references": [
            "1c63e1d5-b963-455b-829d-e4f3eb63a36a",
            "1e96fa03-e4db-46de-a2e0-848ee4e9ec3b",
            "2ccb01b5-e59c-4ff4-b627-a76a72c9738c",
            "6c341eb6-f901-4353-b5ff-8da4ce990d11",
            "6ef77fc2-226f-4673-ad9d-21c17900b333",
            "81952b4c-f188-447a-a87c-90d281c83256",
            "82eb55e6-39a8-4968-8be6-e2bfbb439a40",
            "a7956261-026b-437c-bda7-b57849df8131",
            "b2de99a5-01d1-4359-be11-10c2ce130a05"
        ],
        "keyword": [],
        "group": [],
        "_id": "443fb8d3-09ba-45a2-98a6-597799c3e63c",
        "abstract": "We propose a new model for active contours to detect objects in a given image, based on techniques of curve evolution, Mumford-Shah (1989) functional for segmentation and level sets. Our model can detect objects whose boundaries are not necessarily defined by the gradient. We minimize an energy which can be seen as a particular case of the minimal partition problem. In the level set formulation, the problem becomes a \"mean-curvature flow\"-like evolving the active contour, which will stop on the desired boundary. However, the stopping term does not depend on the gradient of the image, as in the classical active contour models, but is instead related to a particular segmentation of the image. We give a numerical algorithm using finite differences. Finally, we present various experimental results and in particular some examples for which the classical snakes methods based on the gradient are not applicable. Also, the initial curve can be anywhere in the image, and interior contours are automatically detected.",
        "title": "Active contours without edges",
        "venue": "IEEE Transactions on Image Processing",
        "year": 2001,
        "__v": 0,
        "citationCount": 2938
    },
    {
        "authors": [
            "Yousef Saad"
        ],
        "references": [],
        "keyword": [],
        "group": [],
        "_id": "34d4e37b-e575-4316-847b-d8a661b51473",
        "abstract": "Preface 1. Background in linear algebra 2. Discretization of partial differential equations 3. Sparse matrices 4. Basic iterative methods 5. Projection methods 6. Krylov subspace methods Part I 7. Krylov subspace methods Part II 8. Methods related to the normal equations 9. Preconditioned iterations 10. Preconditioning techniques 11. Parallel implementations 12. Parallel preconditioners 13. Multigrid methods 14. Domain decomposition methods Bibliography Index.",
        "title": "Iterative Methods for Sparse Linear Systems",
        "venue": "",
        "year": 2003,
        "__v": 0,
        "citationCount": 2320
    },
    {
        "authors": [
            "Christopher D. Manning",
            "Prabhakar Raghavan",
            "Hinrich Schütze"
        ],
        "references": [],
        "keyword": [],
        "group": [],
        "_id": "68453f24-4276-4d0c-b37e-19d23af549be",
        "abstract": "Class-tested and coherent, this groundbreaking new textbook teaches web-era information retrieval, including web search and the related areas of text classification and text clustering from basic concepts. Written from a computer science perspective by three leading experts in the field, it gives an up-to-date treatment of all aspects of the design and implementation of systems for gathering, indexing, and searching documents; methods for evaluating systems; and an introduction to the use of machine learning methods on text collections. All the important ideas are explained using examples and figures, making it perfect for introductory courses in information retrieval for advanced undergraduates and graduate students in computer science. Based on feedback from extensive classroom experience, the book has been carefully structured in order to make teaching more natural and effective. Although originally designed as the primary text for a graduate or advanced undergraduate course in information retrieval, the book will also create a buzz for researchers and professionals alike.",
        "title": "Introduction to Information Retrieval",
        "venue": "",
        "year": 2008,
        "__v": 0,
        "citationCount": 3768
    },
    {
        "authors": [
            "Rajeev Alur",
            "Kousha Etessami",
            "P. Madhusudan"
        ],
        "references": [
            "029ec76f-4b8c-476a-8c77-3036d6b7b1f6",
            "09fc7b5d-9220-4088-bdac-eb79cddc9675",
            "0d4cc186-9c63-429b-85e4-83b606481524",
            "16866840-a628-4b75-b3fd-b6321ac5afea",
            "1df30cd7-1d70-4a9c-b95b-0ff4deff5fbd",
            "28248831-d840-4a54-9fab-fe549977fe00",
            "2bb33756-67db-4329-8c0d-f3c5fdab2367",
            "31a873fd-bc11-430f-91ef-b8e4aa0a7c87",
            "35c8c06c-2ad0-46b4-9e92-2d684f3abd94",
            "39373ca0-3987-4dca-8c7a-182f1db17b4a",
            "41cf9713-ed76-43a6-8e9f-538abc2f787c",
            "509473ba-ad2f-4706-89fc-4e537252a8b8",
            "74e3fd8b-f955-4fde-aad8-0a705f05e27e",
            "877fd32f-56eb-4dac-a62f-df6a3694858e",
            "8f36f079-bc77-4428-acbd-e49eac0a6636",
            "9f006832-e8b6-4b96-b096-f1e58098d961",
            "bb28e8ef-624e-44cc-a791-53152af76e4d",
            "d8f45444-76c1-4b84-b909-918211b4bab4",
            "db1dbd30-7a91-4089-8928-a5bf06978d0d",
            "e2e62de3-82aa-40a1-8377-c191f3dc715c",
            "e4be6d6e-c041-4c30-aa59-0537278842b8",
            "f3d52f51-d5a2-472f-8f8a-71fe5ec8609d",
            "f5f1b6cd-64e7-428f-bd7a-90c92ed50bde",
            "fcc366e1-ddca-43df-ae8e-0b068926dc2f"
        ],
        "keyword": [],
        "group": [],
        "_id": "9849d9c4-a97f-452f-882c-42a8c6cab0b5",
        "abstract": "Model checking of linear temporal logic (LTL) specifications with respect to pushdown systems has been shown to be a useful tool for analysis of programs with potentially recursive procedures. LTL, how- ever, can specify only regular properties, and properties such as correct- ness of procedures with respect to pre and post conditions, that require matching of calls and returns, are not regular. We introduce a tempo- ral logic of calls and returns (CaRet) for specification and algorithmic verification of correctness requirements of structured programs. The for- mulas of CaRet are interpreted over sequences of propositional valu- ations tagged with special symbols call and ret. Besides the standard global temporal modalities, CaRet admits the abstract-next operator that allows a path to jump from a call to the matching return. This op- erator can be used to specify a variety of non-regular properties such as partial and total correctness of program blocks with respect to pre and post conditions. The abstract versions of the other temporal modalities can be used to specify regular properties of local paths within a proce- dure that skip over calls to other procedures. CaRet also admits the caller modality that jumps to the most recent pending call, and such caller modalities allow specification of a variety of security properties that involve inspection of the call-stack. Even though verifying context- free properties of pushdown systems is undecidable, we show that model checking CaRet formulas against a pushdown model is decidable. We present a tableau construction that reduces our model checking problem to the emptiness problem for a Buchi pushdown system. The complexity of model checking CaRet formulas is the same as that of checking LTL formulas, namely, polynomial in the model and singly exponential in the size of the specification.",
        "title": "A Temporal Logic of Nested Calls and Returns",
        "venue": "tools and algorithms for construction and analysis of systems",
        "year": 2004,
        "__v": 0,
        "citationCount": 3137
    },
    {
        "authors": [
            "Bernhard Schölkopf",
            "Alexander J. Smola"
        ],
        "references": [],
        "keyword": [],
        "group": [],
        "_id": "a083a1b9-8dfb-45d6-99a9-fa30c4a6e9f5",
        "abstract": "From the Publisher:#R##N#In the 1990s, a new type of learning algorithm was developed, based on results from statistical learning theory: the Support Vector Machine (SVM). This gave rise to a new class of theoretically elegant learning machines that use a central concept of SVMs-kernels--for a number of learning tasks. Kernel machines provide a modular framework that can be adapted to different tasks and domains by the choice of the kernel function and the base algorithm. They are replacing neural networks in a variety of fields, including engineering, information retrieval, and bioinformatics.#R##N#Learning with Kernels provides an introduction to SVMs and related kernel methods. Although the book begins with the basics, it also includes the latest research. It provides all of the concepts necessary to enable a reader equipped with some basic mathematical knowledge to enter the world of machine learning using theoretically well-founded yet easy-to-use kernel algorithms and to understand and apply the powerful algorithms that have been developed over the last few years.",
        "title": "Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond",
        "venue": "Journal of the American Statistical Association",
        "year": 2001,
        "__v": 0,
        "citationCount": 2399
    },
    {
        "authors": [
            "Pang-Ning Tan",
            "Michael M. Steinbach",
            "Vipin Kumar"
        ],
        "references": [],
        "keyword": [],
        "group": [],
        "_id": "a9bb2246-1ffd-4802-a236-db1c4083c57e",
        "abstract": "1 Introduction   1.1 What is Data Mining?   1.2 Motivating Challenges  1.3 The Origins of Data Mining  1.4 Data Mining Tasks  1.5 Scope and Organization of the Book   1.6 Bibliographic Notes  1.7 Exercises      2 Data    2.1 Types of Data   2.2 Data Quality   2.3 Data Preprocessing   2.4 Measures of Similarity and Dissimilarity   2.5 Bibliographic Notes   2.6 Exercises       3 Exploring Data    3.1 The Iris Data Set   3.2 Summary Statistics   3.3 Visualization   3.4 OLAP and Multidimensional Data Analysis  3.5 Bibliographic Notes  3.6 Exercises       4 Classification: Basic Concepts, Decision Trees, and Model Evaluation    4.1 Preliminaries   4.2 General Approach to Solving a Classification Problem   4.3 Decision Tree Induction   4.4 Model Overfitting  4.5 Evaluating the Performance of a Classifier  4.6 Methods for Comparing Classifiers  4.7 Bibliographic Notes   4.8 Exercises       5 Classification: Alternative Techniques    5.1 Rule-Based Classifier   5.2 Nearest-Neighbor Classifiers  5.3 Bayesian Classifiers   5.4 Artificial Neural Network (ANN)   5.5 Support Vector Machine (SVM)   5.6 Ensemble Methods   5.7 Class Imbalance Problem  5.8 Multiclass Problem  5.9 Bibliographic Notes  5.10 Exercises      6 Association Analysis: Basic Concepts and Algorithms    6.1 Problem Definition   6.2 Frequent Itemset Generation   6.3 Rule Generation   6.4 Compact Representation of Frequent Itemsets  6.5 Alternative Methods for Generating Frequent Itemsets  6.6 FP-Growth Algorithm   6.7 Evaluation of Association Patterns   6.8 Effect of Skewed Support Distribution  6.9 Bibliographic Notes   6.10 Exercises       7 Association Analysis: Advanced Concepts      7.1 Handling Categorical Attributes   7.2 Handling Continuous Attributes   7.3 Handling a Concept Hierarchy   7.4 Sequential Patterns   7.5 Subgraph Patterns   7.6 Infrequent Patterns   7.7 Bibliographic Notes   7.8 Exercises       8 Cluster Analysis: Basic Concepts and Algorithms    8.1 Overview   8.2 K-means   8.3 Agglomerative Hierarchical Clustering   8.4 DBSCAN   8.5 Cluster Evaluation   8.6 Bibliographic Notes   8.7 Exercises       9 Cluster Analysis: Additional Issues and Algorithms    9.1 Characteristics of Data, Clusters, and Clustering Algorithms  9.2 Prototype-Based Clustering   9.3 Density-Based Clustering   9.4 Graph-Based Clustering   9.5 Scalable Clustering Algorithms   9.6 Which Clustering Algorithm?   9.7 Bibliographic Notes   9.8 Exercises       10 Anomaly Detection    10.1 Preliminaries  10.2 Statistical Approaches  10.3 Proximity-Based Outlier Detection  10.4 Density-Based Outlier Detection  10.5 Clustering-Based Techniques  10.6 Bibliographic Notes  10.7 Exercises      Appendix A Linear Algebra   Appendix B Dimensionality Reduction  Appendix C Probability and Statistics   Appendix D Regression   Appendix E Optimization      Author Index  Subject Index",
        "title": "Introduction to data mining",
        "venue": "",
        "year": 2006,
        "__v": 0,
        "citationCount": 2071
    },
    {
        "authors": [
            "Janez Demšar"
        ],
        "references": [
            "056e5059-9864-479b-8a2a-fb1cd3d2dd32",
            "2c962c64-02d3-4f07-a5a8-62ba4ebc9b72",
            "31a4f270-4929-4364-b8ca-66577c7f1517",
            "37cd167c-ab59-495a-b5b1-b9f841dea87c",
            "393d1d75-8679-423a-844b-d49e9937e4cc",
            "4b87b8df-828e-453c-b168-3c28f4cc9f7b",
            "513b3123-12c0-442f-b76f-d1291cfa35f5",
            "594b4fe8-54fe-4f3c-aa4f-cdec07b9be2b",
            "6950a3d3-a17f-49d9-a87c-0f2e8126fc33",
            "b9111683-1151-4542-8a10-d1eeb730087e",
            "d20df5c3-667b-42d4-a128-d5f0b649cc32",
            "d697bd65-fc9d-43e5-8bdc-6d068cb6badf",
            "defc400c-738c-4e62-8943-7ffbab6bad9b"
        ],
        "keyword": [],
        "group": [],
        "_id": "aa767a83-de19-4421-bfb4-f63808992758",
        "abstract": "While methods for comparing two learning algorithms on a single data set have been scrutinized for quite some time already, the issue of statistical tests for comparisons of more algorithms on multiple data sets, which is even more essential to typical machine learning studies, has been all but ignored. This article reviews the current practice and then theoretically and empirically examines several suitable tests. Based on that, we recommend a set of simple, yet safe and robust non-parametric tests for statistical comparisons of classifiers: the Wilcoxon signed ranks test for comparison of two classifiers and the Friedman test with the corresponding post-hoc tests for comparison of more classifiers over multiple data sets. Results of the latter can also be neatly presented with the newly introduced CD (critical difference) diagrams.",
        "title": "Statistical Comparisons of Classifiers over Multiple Data Sets",
        "venue": "Journal of Machine Learning Research",
        "year": 2006,
        "__v": 0,
        "citationCount": 2751
    },
    {
        "authors": [
            "Aude Oliva",
            "Antonio Torralba"
        ],
        "references": [
            "1ed2cc94-3d0b-4718-80b6-2528e814c921",
            "30614910-26a5-495c-8bb7-0f723c47db69",
            "4a29b56b-b74e-4945-9017-61a7ab844fd9",
            "58986749-f7f2-4c0c-a0f8-37180df48756",
            "5a6136c8-c73c-4a55-b231-d293bf1b12ee",
            "5eb1916a-bbf2-4413-b5ba-589c62877ac0",
            "65a76574-1ea8-4b1d-8d29-efe42d06446c",
            "6bc07db2-08e3-45a9-99c0-10391f57f6df",
            "6e8cc926-79a1-4676-a2bd-f9d49f3144cf",
            "82d0ec51-e40e-4602-b969-fc0b44464ac3",
            "94ce3d32-4057-4002-a3ef-6f87b0582802",
            "99f2c01b-6d49-4a93-8723-155698197ed6",
            "c027a810-02a3-415b-83ad-e48144273475",
            "cfe61dfb-59d6-4ee4-9324-e591f8cef78f",
            "d12c8fca-a82c-45db-b29c-8fc7a47fce2e",
            "ece37585-dc4e-492a-9f3c-0a143b0a5ab8",
            "f62a1da3-7675-446c-a327-86391e9cb02b"
        ],
        "keyword": [],
        "group": [],
        "_id": "ab3afb93-8ca0-4556-ae60-11199dc263c2",
        "abstract": "In this paper, we propose a computational model of the recognition of real world scenes that bypasses the segmentation and the processing of individual objects or regions. The procedure is based on a very low dimensional representation of the scene, that we term the Spatial Envelope. We propose a set of perceptual dimensions (naturalness, openness, roughness, expansion, ruggedness) that represent the dominant spatial structure of a scene. Then, we show that these dimensions may be reliably estimated using spectral and coarsely localized information. The model generates a multidimensional space in which scenes sharing membership in semantic categories (e.g., streets, highways, coasts) are projected closed together. The performance of the spatial envelope model shows that specific information about object shape or identity is not a requirement for scene categorization and that modeling a holistic representation of the scene informs about its probable semantic category.",
        "title": "Modeling the Shape of the Scene: A Holistic Representation of the Spatial Envelope",
        "venue": "International Journal of Computer Vision",
        "year": 2001,
        "__v": 0,
        "citationCount": 2402
    },
    {
        "authors": [
            "Advaith Siddharthan"
        ],
        "references": [
            "2a7e8624-15f9-41b2-a2bc-6d9bfce0949d",
            "3cc7d99b-2563-47ab-a83a-3555a2bf2736",
            "aa9af505-b437-4081-ba4a-97f0355a7f9e"
        ],
        "keyword": [],
        "group": [],
        "_id": "bc95970b-34c5-4860-a832-41bc04a50889",
        "abstract": "Statistical approaches to processing natural language text have become dominant in recent years. This foundational text is the first comprehensive introduction to statistical natural language processing (NLP) to appear. The book contains all the theory and algorithms needed for building NLP tools. It provides broad but rigorous coverage of mathematical and linguistic foundations, as well as detailed discussion of statistical methods, allowing students and researchers to construct their own implementations. The book covers collocation finding, word sense disambiguation, probabilistic parsing, information retrieval, and other applications.",
        "title": "Christopher D. Manning and Hinrich Schutze. Foundations of Statistical Natural Language Processing . MIT Press, 2000. ISBN 0-262-13360-1. 620 pp. $64.95/£44.95 (cloth).",
        "venue": "Natural Language Engineering",
        "year": 2002,
        "__v": 0,
        "citationCount": 2801
    },
    {
        "authors": [
            "Herbert Bay",
            "Tinne Tuytelaars",
            "Luc J. Van Gool"
        ],
        "references": [
            "0b86c956-29dc-4979-b046-f2ec971d8ac8",
            "21c67dad-f0eb-4479-afe7-fdf4a71eef01",
            "2d6c9f60-ea78-44a8-b5f9-6964575dd196",
            "2fa58737-dfec-48e8-a1d5-dc96c510d44f",
            "34758e0a-3def-447b-9c5e-e82a206426b5",
            "36800655-b2ff-4eb7-9070-c6be304c4baa",
            "3c1e64c0-8e48-45d3-96e8-f2c3252b4b83",
            "472cc3e6-8149-41ef-b4c4-fa9e6a60b66f",
            "473cf1a4-9f42-4e6d-b34f-77787f329079",
            "509e1ae2-768b-4417-bebe-d90cf1e0fdae",
            "5f84f09f-7644-447c-89e1-8dc9ee334197",
            "6018a516-8149-4bce-bc33-5449d86e58c2",
            "60285266-7da2-474e-b05a-b380c836f665",
            "6fe37c18-8dc5-4baa-b6e0-5546353907bb",
            "774c108a-4002-4123-861f-edd3b7ccb0e7",
            "7ab7b36d-baae-4b21-89fc-69389fcabc44",
            "8d8e7d51-3223-4776-bf6a-40306774b8a1",
            "9f5f1500-0df7-4675-8290-b47979bcad38",
            "a5254ae0-1ce1-4390-b9f8-8d5a3dcb1e62",
            "b944f77f-113b-4a02-ae5e-d4a124b8fd5b",
            "e649a9fd-f6d9-4aac-b428-29b82c20a484",
            "ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d",
            "ffa029cf-7240-4723-8339-51fac57f9f28"
        ],
        "keyword": [],
        "group": [],
        "_id": "f225f439-4389-4312-a503-f8c1b0aa02de",
        "abstract": "In this paper, we present a novel scale- and rotation-invariant interest point detector and descriptor, coined SURF (Speeded Up Robust Features). It approximates or even outperforms previously proposed schemes with respect to repeatability, distinctiveness, and robustness, yet can be computed and compared much faster.#R##N##R##N#This is achieved by relying on integral images for image convolutions; by building on the strengths of the leading existing detectors and descriptors (in casu, using a Hessian matrix-based measure for the detector, and a distribution-based descriptor); and by simplifying these methods to the essential. This leads to a combination of novel detection, description, and matching steps. The paper presents experimental results on a standard evaluation set, as well as on imagery obtained in the context of a real-life object recognition application. Both show SURF's strong performance.",
        "title": "SURF: speeded up robust features",
        "venue": "european conference on computer vision",
        "year": 2006,
        "__v": 0,
        "citationCount": 3617
    },
    {
        "authors": [
            "Karen Simonyan",
            "Andrew Zisserman"
        ],
        "references": [
            "04cb0d83-273e-498f-af4f-3c5b0554dbfb",
            "051956bb-f64b-4fdb-87f8-3e2868b8b5d8",
            "0fb0a842-cb06-4b37-9738-a4d18a55ec23",
            "176a7436-78ea-4c2a-82e6-7930ab023bd1",
            "1ce76b6e-e1b0-4c1e-8f24-282b4f686fc5",
            "28d47fcd-4f94-4de9-b57b-99ba4545b867",
            "2b6a3d0f-368f-45bb-be23-4e82f62fbbf7",
            "2d9c1391-7c29-4b74-9c05-d45afeb103bb",
            "32fac192-89d7-4cb2-b6c6-f1a4e5fc9bbf",
            "3b23400e-aa6d-4ee3-b17c-82c04d98d157",
            "493f502b-b1b8-412c-95fd-3c1103480f1d",
            "5edc47ab-a53e-4cb1-8003-de5dc5cc7fb3",
            "65404116-7ed8-404b-a87a-e578deb8d7cb",
            "6a97a03d-7337-4f4a-a8db-714d81cff194",
            "6d324aa1-fcc4-4808-ae21-472982517e5e",
            "8ee6231d-f5b8-41a2-b023-ae33f2c19535",
            "97fa1c18-05bf-47c9-b72d-5d712b186ccd",
            "ae3e7593-586f-495f-9416-4b50ed1fcd10",
            "b9632516-3e2e-4cf7-a6d8-43f317d43488",
            "bf248c6c-2c05-4101-9a38-35460518f9d7",
            "c812244d-0de8-4e3c-8133-1e834bc9dbd0",
            "c9482f1f-6600-44a7-a69a-e63ef13cdff8",
            "ca9cac9c-5952-467c-b8ef-2542bab992c6",
            "d41cbe23-f9c1-40ea-89eb-bc7b840432f1",
            "db8d3f57-09f9-4b09-a057-3e97e2a2b7fc",
            "dc59f316-9db3-49b6-9b19-70a1d4977d86",
            "e2f7a74a-8430-4463-94ce-fe85dfd309f9",
            "ec0ca0bd-9848-4f47-b6d9-8ef37fd9b3ca",
            "eecae39b-f612-4235-8071-448e80a32fe2",
            "f26a8a8a-9ad6-4dc1-8ae2-a59be1f80267",
            "f64b5ccd-849a-4ac1-97ff-f34842543115",
            "fbdfc1ca-09ef-47f8-a0d1-adaf626a8562"
        ],
        "keyword": [],
        "group": [],
        "_id": "153c5014-dc7a-44a8-a93f-5cd27f1193df",
        "abstract": "Abstract: In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.",
        "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
        "venue": "international conference on learning representations",
        "year": 2015,
        "__v": 0,
        "citationCount": 2515
    },
    {
        "authors": [
            "Carl Edward Rasmussen",
            "Christopher K. I. Williams"
        ],
        "references": [],
        "keyword": [],
        "group": [],
        "_id": "fd4e8c45-be77-49de-a6a8-a8ab1acac344",
        "abstract": "Gaussian processes (GPs) provide a principled, practical, probabilistic approach to learning in kernel machines. GPs have received increased attention in the machine-learning community over the past decade, and this book provides a long-needed systematic and unified treatment of theoretical and practical aspects of GPs in machine learning. The treatment is comprehensive and self-contained, targeted at researchers and students in machine learning and applied statistics.The book deals with the supervised-learning problem for both regression and classification, and includes detailed algorithms. A wide variety of covariance (kernel) functions are presented and their properties discussed. Model selection is discussed both from a Bayesian and a classical perspective. Many connections to other well-known techniques from machine learning and statistics are discussed, including support-vector machines, neural networks, splines, regularization networks, relevance vector machines and others. Theoretical issues including learning curves and the PAC-Bayesian framework are treated, and several approximation methods for learning with large datasets are discussed. The book contains illustrative examples and exercises, and code and datasets are available on the Web. Appendixes provide mathematical background and a discussion of Gaussian Markov processes.",
        "title": "Gaussian Processes for Machine Learning",
        "venue": "",
        "year": 2006,
        "__v": 0,
        "citationCount": 2370
    },
    {
        "authors": [
            "Richard M. Karp"
        ],
        "references": [
            "8d09527f-b5ad-4902-ba34-5583f6759d3b"
        ],
        "keyword": [],
        "group": [],
        "_id": "172f9f68-8417-43bb-8fe5-b377d569f6b6",
        "title": "Reducibility Among Combinatorial Problems",
        "venue": "",
        "year": 2010,
        "abstract": "",
        "__v": 0,
        "citationCount": 3807
    },
    {
        "authors": [
            "Wenyi Zhao",
            "R. Chellappa",
            "P.J. Phillips",
            "Avi Rosenfeld"
        ],
        "references": [
            "00909251-9935-44f3-94a1-629023b5015b",
            "019fb6c8-c81b-4ef9-94be-18083093da48",
            "037b9625-bad7-41d3-be15-3d6d109298c2",
            "077f6588-d157-408b-981f-3b3db91d21c9",
            "0f9ab580-e0a8-409c-9555-0f46dee18c62",
            "0fa84c94-ae45-44d3-bd37-aa3d48158977",
            "123dbd0e-74f1-428b-9f16-00d04583f937",
            "14c4dfa0-37fe-45d6-a608-dfc3f7c2e3f8",
            "1863ec2a-4485-4bf6-80c4-6dfce4a8d627",
            "1ba94a3f-ba8a-4aff-8151-3a855803711c",
            "1bfa187e-2966-4a8f-ad71-f62a12204971",
            "20df996a-f7d5-41ba-8895-a6caeabec865",
            "27505f5b-d81f-4b85-b85e-bd357aaa8468",
            "291af141-8d36-44eb-a734-79dd03e99fab",
            "291bceb3-9d76-46ce-b9ea-5dbef5dc2560",
            "31694e30-f279-4014-8a46-cf76272cd058",
            "33d74862-6527-4c30-be0c-95226a3f8a3a",
            "34f6453a-5555-46cf-af48-ac1576ccb367",
            "3a2861b4-a6f7-4ab0-9f88-480006b53bb0",
            "40f728c0-55b3-423b-aff5-a9b3ff27b7d5",
            "44a9fc14-1bf4-489e-add7-84abc2cb3561",
            "4775c95c-c5bc-4a74-a653-e8c94a6e3baa",
            "4eb97838-8c8a-461f-b23e-8da4ac3488a2",
            "54a5822c-e405-44ad-84e3-cea51e7349c2",
            "552d8ea6-1cb0-44db-ba2c-eec5016ef5df",
            "56cd3fdb-73ff-431e-8945-d673f9469f33",
            "56f4b72a-ec39-47ac-8220-899296e7fb18",
            "580cb16b-97bf-43ed-8850-85b5918bdb83",
            "5e8b0e8a-d687-4333-bfe9-73b4c1bebde5",
            "5eb1916a-bbf2-4413-b5ba-589c62877ac0",
            "5ebbd1f5-dfe5-4eec-9883-b8b5efea366c",
            "5fda5f10-7c36-497e-b8b9-31e3a13daf6a",
            "61e615e7-f78f-4f1e-b604-343ecf4b2ec9",
            "62683f45-98a9-44a3-a3ea-219079aae364",
            "64fa74e8-db02-4190-87d7-bf23e9859a7c",
            "6affa0b1-4908-4f5d-9e72-66e66e8a96ef",
            "6e8cc926-79a1-4676-a2bd-f9d49f3144cf",
            "6f10ee49-5baf-4f79-aab2-105ae01326db",
            "6f3c082f-288f-4588-8f53-9476a60cfad7",
            "762c9918-e579-42ef-80e5-4e464870a017",
            "7d738632-dc5d-4ec9-a4cd-1d1a74d33166",
            "810f7115-00c6-42b2-bf8c-142b2a35ed57",
            "85114f9d-70a8-4940-83aa-af504b75acf8",
            "853b9534-32ab-4bf8-a328-1f4c18cf3a1b",
            "8835551e-08fe-468f-8523-3bc1752f41f3",
            "8fbd241e-236d-4a82-9471-0d854326e3cb",
            "9025d4f2-c1f7-4aa1-9632-a859a845a2d4",
            "912aabff-def4-4026-9eb9-9d04cb8fabb1",
            "923f5d0a-23a3-4fb1-bee7-ec72122709a4",
            "94a0b002-578e-4581-ad1d-8fc52a7052ea",
            "9702775a-a8c7-4089-b0f8-418ccdcb8dba",
            "971f156e-04ee-449a-86b1-82b37d50a9ce",
            "9b9c96fb-f880-49fd-bdae-651407dc2e30",
            "9e33c655-8bd8-40ce-a32d-f4a2d1335bd1",
            "9f8626c6-acdb-460a-ace2-050d880219e1",
            "a2c0b7ee-74df-44b9-a22a-111d84bcc8ee",
            "aafd7a81-b545-4ae8-8b9a-cf61896fc6d3",
            "adda2917-0ddc-4d6e-b7b3-86c043022042",
            "b1295c0c-9c1c-41d7-8cd2-74ed1557481c",
            "b5c70352-d0a3-4a6b-b961-ed59491ad43f",
            "bf03f268-de9d-4a80-aee1-200990056503",
            "c95f638a-4ce3-4cba-8028-24d2b213ad18",
            "ce79b8ff-a84b-4138-badd-4e59d7b87737",
            "ce9c0c07-83af-4fb7-9491-38255660025c",
            "cf3b633a-6201-492c-8de3-9af4e03c8f97",
            "d3aa43bb-afc8-4ad6-89d3-8f50d2cc277d",
            "d56847b7-c010-4782-9ef0-f48bb01908dd",
            "d5e5a24d-f80e-4f1a-b48b-22403b653276",
            "d6e37fb1-5f7e-448e-847b-7d1f1271c574",
            "d75d2735-844d-4446-ac4e-1677e338e624",
            "de9218ee-1982-455b-96c4-f28718f76a2f",
            "e17d0924-0ffb-4392-91a5-1d9e2748d3ae",
            "e308777d-43e0-4041-92b2-0c43715b5227",
            "e649a9fd-f6d9-4aac-b428-29b82c20a484",
            "eb63b82d-5108-4abf-8ee7-2d11bc1998a0",
            "ece4f56c-b724-40cf-b23c-d4ec101cf4de",
            "ed59a2e5-7330-4e07-9edf-cc80872135d0",
            "f191f982-a057-4358-bceb-57a3298b533e",
            "fa8167b1-8d7a-482c-b0d6-07ca5db8d823"
        ],
        "keyword": [],
        "group": [],
        "_id": "32d158dc-6f9f-426a-973b-8edc5e4c5dad",
        "abstract": "As one of the most successful applications of image analysis and understanding, face recognition has recently received significant attention, especially during the past several years. At least two reasons account for this trend: the first is the wide range of commercial and law enforcement applications, and the second is the availability of feasible technologies after 30 years of research. Even though current machine recognition systems have reached a certain level of maturity, their success is limited by the conditions imposed by many real applications. For example, recognition of face images acquired in an outdoor environment with changes in illumination and/or pose remains a largely unsolved problem. In other words, current systems are still far away from the capability of the human perception system.This paper provides an up-to-date critical survey of still- and video-based face recognition research. There are two underlying motivations for us to write this survey paper: the first is to provide an up-to-date review of the existing literature, and the second is to offer some insights into the studies of machine recognition of faces. To provide a comprehensive survey, we not only categorize existing recognition techniques but also present detailed descriptions of representative methods within each category. In addition, relevant topics such as psychophysical studies, system evaluation, and issues of illumination and pose variation are covered.",
        "title": "Face recognition: A literature survey",
        "venue": "ACM Computing Surveys",
        "year": 2003,
        "__v": 0,
        "citationCount": 2475
    },
    {
        "authors": [
            "Jeffrey O. Kephart",
            "David M. Chess"
        ],
        "references": [
            "4e2f6f85-f3ba-483a-9477-fbda0c7f816a",
            "609fabe4-129f-4c4c-8905-2f9896534c89",
            "c47bdbf7-c79e-4bb9-8a24-ebc0b2993d56",
            "c72d3bde-7cca-46a2-8d0b-66bc5e1d23c7",
            "e1dea621-611f-4569-9d9e-1d4a20d665d3"
        ],
        "keyword": [],
        "group": [],
        "_id": "352838dd-9583-402f-be39-52df4810a25f",
        "abstract": "A 2001 IBM manifesto observed that a looming software complexity crisis -caused by applications and environments that number into the tens of millions of lines of code - threatened to halt progress in computing. The manifesto noted the almost impossible difficulty of managing current and planned computing systems, which require integrating several heterogeneous environments into corporate-wide computing systems that extend into the Internet. Autonomic computing, perhaps the most attractive approach to solving this problem, creates systems that can manage themselves when given high-level objectives from administrators. Systems manage themselves according to an administrator's goals. New components integrate as effortlessly as a new cell establishes itself in the human body. These ideas are not science fiction, but elements of the grand challenge to create self-managing computing systems.",
        "title": "The vision of autonomic computing",
        "venue": "IEEE Computer",
        "year": 2003,
        "__v": 0,
        "citationCount": 2599
    },
    {
        "authors": [
            "Pedro F. Felzenszwalb",
            "Daniel P. Huttenlocher"
        ],
        "references": [
            "01df6660-e54b-4cab-a20e-179393feb854",
            "1017d9d4-9a4c-423d-ad40-6d9bebbd6b31",
            "2ea16f6a-9fb7-4cbb-b632-4297abca8665",
            "49eba48a-b4c4-49f7-992d-5da76f32072b",
            "61ee16bb-d279-4a22-ab21-463bb86eb01c",
            "6e184d1b-925b-4918-b354-a2647e8fd945",
            "6e96e01e-749d-4247-8802-9d10bc66c0ce",
            "7b8583e6-dbd3-4d2f-859a-f1de071886f2",
            "9438a773-c15c-4ef2-a97c-54f643ce6082",
            "d20995f6-529c-41c6-b75e-a169b005fb5c",
            "d78003db-ad8a-48d2-be57-1c50e95cef72",
            "ee8ff75d-caec-42e9-aa07-cbe4fdd7541b"
        ],
        "keyword": [],
        "group": [],
        "_id": "45beeef2-a57d-436d-8fc4-56136234b4b9",
        "abstract": "This paper addresses the problem of segmenting an image into regions. We define a predicate for measuring the evidence for a boundary between two regions using a graph-based representation of the image. We then develop an efficient segmentation algorithm based on this predicate, and show that although this algorithm makes greedy decisions it produces segmentations that satisfy global properties. We apply the algorithm to image segmentation using two different kinds of local neighborhoods in constructing the graph, and illustrate the results with both real and synthetic images. The algorithm runs in time nearly linear in the number of graph edges and is also fast in practice. An important characteristic of the method is its ability to preserve detail in low-variability image regions while ignoring detail in high-variability regions.",
        "title": "Efficient Graph-Based Image Segmentation",
        "venue": "International Journal of Computer Vision",
        "year": 2004,
        "__v": 0,
        "citationCount": 2057
    }
]