data = {"24173fe9-8fd0-410a-8695-414f594912a0":{"authors":["Shuo-Yen Robert Li","Raymond W. Yeung","Ning Cai"],"references":[],"_id":"24173fe9-8fd0-410a-8695-414f594912a0","abstract":"Consider a communication network in which certain source nodes multicast information to other nodes on the network in the multihop fashion where every node can pass on any of its received data to others. We are interested in how fast each node can receive the complete information, or equivalently, what the information rate arriving at each node is. Allowing a node to encode its received data before passing it on, the question involves optimization of the multicast mechanisms at the nodes. Among the simplest coding schemes is linear coding, which regards a block of data as a vector over a certain base field and allows a node to apply a linear transformation to a vector before passing it on. We formulate this multicast problem and prove that linear coding suffices to achieve the optimum, which is the max-flow from the source to each receiving node.","title":"Linear network coding","venue":"IEEE Transactions on Information Theory","year":2003,"__v":0,"citationCount":1544,"parents":{"2203f921-67d7-42e7-bb8b-a4f39165afc8":0,"5d584f7b-fc9e-4ae0-905c-569ecb90f524":50},"keyword":{"2203f921-67d7-42e7-bb8b-a4f39165afc8":9.41851851851852,"5d584f7b-fc9e-4ae0-905c-569ecb90f524":9.77037037037037},"topic":["node","receiv","pass","multicast","linear"],"groups":[{"authors":["Sidharth Jaggi","Peter Sanders","Philip A. Chou","Michelle Effros","Sebastian Egner","Kamal Jain","Ludo M. G. M. Tolhuizen"],"references":["1f81c292-6ddf-4d05-9c35-baf635fffe26","2203f921-67d7-42e7-bb8b-a4f39165afc8","222e8196-b98b-47bc-a679-641bbf57b770","24173fe9-8fd0-410a-8695-414f594912a0","56d40aa7-4f86-4085-86ec-8f2f88acdb76","665db989-0f33-4d43-af77-bb1e700a73d4","669f5570-64cb-47c1-9386-e5e9f8889f9a","7fee7e10-5189-4dfc-b044-572ef18e995e","90a424e0-d969-4c63-8ab0-fb6922d335d8","d7c9fac8-a400-485c-ad3f-a99bcea83d6b"],"_id":"5d584f7b-fc9e-4ae0-905c-569ecb90f524","abstract":"The famous max-flow min-cut theorem states that a source node s can send information through a network (V, E) to a sink node t at a rate determined by the min-cut separating s and t. Recently, it has been shown that this rate can also be achieved for multicasting to several sinks provided that the intermediate nodes are allowed to re-encode the information they receive. We demonstrate examples of networks where the achievable rates obtained by coding at intermediate nodes are arbitrarily larger than if coding is not allowed. We give deterministic polynomial time algorithms and even faster randomized algorithms for designing linear codes for directed acyclic graphs with edges of unit capacity. We extend these algorithms to integer capacities and to codes that are tolerant to edge failures.","title":"Polynomial time algorithms for multicast network code construction","venue":"IEEE Transactions on Information Theory","year":2005,"__v":0,"citationCount":416}],"offsprings":[]},"50dd56db-151d-4d62-8576-65f0ef6f381b":{"authors":["Corinna Cortes","Vladimir Vapnik"],"references":[],"_id":"50dd56db-151d-4d62-8576-65f0ef6f381b","abstract":"The support-vector network is a new learning machine for two-group classification problems. The machine conceptually implements the following idea: input vectors are non-linearly mapped to a very high-dimension feature space. In this feature space a linear decision surface is constructed. Special properties of the decision surface ensures high generalization ability of the learning machine. The idea behind the support-vector network was previously implemented for the restricted case where the training data can be separated without errors. We here extend this result to non-separable training data.#R##N##R##N#High generalization ability of support-vector networks utilizing polynomial input transformations is demonstrated. We also compare the performance of the support-vector network to various classical learning algorithms that all took part in a benchmark study of Optical Character Recognition.","title":"Support-Vector Networks","venue":"Machine Learning","year":1995,"__v":0,"citationCount":6683,"parents":{"c4dc7b46-01d3-44f5-91ca-0cc063d38c8c":0,"f006e236-59ad-4647-a59f-4f46dc2c85be":50},"keyword":{"c4dc7b46-01d3-44f5-91ca-0cc063d38c8c":11.233553113553114,"f006e236-59ad-4647-a59f-4f46dc2c85be":11.671275946275944},"topic":["supportvector","network","machin","learn","train"],"groups":[{"authors":["Bernhard E. Boser","Isabelle Guyon","Vladimir Vapnik"],"references":["3514c54b-4a5a-4807-9d10-174915c9202b","c0c70cec-318e-477f-a28c-1df32216b847","c4dc7b46-01d3-44f5-91ca-0cc063d38c8c","da4534a6-897c-4431-89ef-cd326bfaf9a8","e85a4f52-0e1c-447b-98b4-33ec8b9ee6f3","ea294286-3cc2-4979-a22b-2fbb78c2ef18","fc95b916-1e4d-4c45-862c-dd34a49e64ad"],"_id":"f006e236-59ad-4647-a59f-4f46dc2c85be","abstract":"A training algorithm that maximizes the margin between the training patterns and the decision boundary is presented. The technique is applicable to a wide variety of the classification functions, including Perceptrons, polynomials, and Radial Basis Functions. The effective number of parameters is adjusted automatically to match the complexity of the problem. The solution is expressed as a linear combination of supporting patterns. These are the subset of training patterns that are closest to the decision boundary. Bounds on the generalization performance based on the leave-one-out method and the VC-dimension are given. Experimental results on optical character recognition problems demonstrate the good generalization obtained when compared with other learning algorithms.","title":"A training algorithm for optimal margin classifiers","venue":"computational learning theory","year":1992,"__v":0,"citationCount":2403}],"offsprings":["91979159-37d8-410f-a245-a33ef80a092b","94898e1d-1e50-41ab-9dcc-2c2e030cddd0","9fa61eb1-0984-4492-955a-4f7aedbdc368","c1b6b493-01ef-420f-be44-7bacfe34e846","feff8862-f47d-4591-a7cb-b62d7efc81a2","a246e432-612a-4481-95b5-29ba3db6369b","b592576f-ff29-4a68-9b2f-8a8ad02e9c70","d28acb36-5766-4c1e-8d57-a55c2630bd90","01b486c4-8955-403b-a0c6-1de74298b215"]},"748a2ab3-8b5f-4d0a-9e2d-af685089843a":{"authors":["Emre Telatar"],"references":[],"_id":"748a2ab3-8b5f-4d0a-9e2d-af685089843a","abstract":"Abstract#R##N##R##N#We investigate the use of multiple transmitting and/or receiving antennas for single user communications over the additive Gaussian channel with and without fading. We derive formulas for the capacities and error exponents of such channels, and describe computational procedures to evaluate such formulas. We show that the potential gains of such multi-antenna systems over single-antenna systems is rather large under independenceassumptions for the fades and noises at different receiving antennas.","title":"Capacity of multi-antenna Gaussian channels","venue":"European Transactions on Telecommunications","year":1999,"__v":0,"citationCount":5059,"parents":{"52787900-26ba-4272-9e1f-42d9fd36943b":0,"68198b02-3da0-4565-a176-9d29195b4313":0},"keyword":{"52787900-26ba-4272-9e1f-42d9fd36943b":10.14910052910053,"68198b02-3da0-4565-a176-9d29195b4313":8.694444444444445},"topic":["system","receiv","formula","fade","channel"],"offsprings":["6d25cd6f-4a67-41ed-9b6d-467c739f531e","720f59d2-acc3-4d5a-91c2-258d137d9647","b22134b3-2419-4d39-b6b8-d7ad60abac26","324c0cc6-829c-4b4f-8ef4-5f2d9b34bf58"]},"23dd7fc0-1ebd-43ce-ab3e-43896512c209":{"authors":["Wendi Rabiner Heinzelman","Anantha P. Chandrakasan","Hari Balakrishnan"],"references":[],"_id":"23dd7fc0-1ebd-43ce-ab3e-43896512c209","abstract":"Wireless distributed microsensor systems will enable the reliable monitoring of a variety of environments for both civil and military applications. In this paper, we look at communication protocols, which can have significant impact on the overall energy dissipation of these networks. Based on our findings that the conventional protocols of direct transmission, minimum-transmission-energy, multi-hop routing, and static clustering may not be optimal for sensor networks, we propose LEACH (Low-Energy Adaptive Clustering Hierarchy), a clustering-based protocol that utilizes randomized rotation of local cluster based station (cluster-heads) to evenly distribute the energy load among the sensors in the network. LEACH uses localized coordination to enable scalability and robustness for dynamic networks, and incorporates data fusion into the routing protocol to reduce the amount of information that must be transmitted to the base station. Simulations show the LEACH can achieve as much as a factor of 8 reduction in energy dissipation compared with conventional outing protocols. In addition, LEACH is able to distribute energy dissipation evenly throughout the sensors, doubling the useful system lifetime for the networks we simulated.","title":"Energy-efficient communication protocol for wireless microsensor networks","venue":"hawaii international conference on system sciences","year":2000,"__v":0,"citationCount":4159,"parents":{"38f54b84-5272-43df-8cde-a3e755b17dee":0,"5eed21bf-bb54-4245-b2b1-979734b1d786":0},"keyword":{"38f54b84-5272-43df-8cde-a3e755b17dee":0,"5eed21bf-bb54-4245-b2b1-979734b1d786":12.40320105820106},"topic":["protocol","network","leach","energi","sensor"],"offsprings":["85352dec-58be-43db-a428-f3f574ff96ec","f3267c01-b670-4b7a-a3a5-79088c0d90ab","96b245c2-47a5-4aec-89f0-d2a362124845","1ee4b656-7d2c-45e8-b2e8-b5633b992eeb"]},"5c158cd2-9a76-4800-9bd9-6311f1de9205":{"authors":["William J. Dally","Brian Towles"],"references":[],"_id":"5c158cd2-9a76-4800-9bd9-6311f1de9205","abstract":"Using on-chip interconnection networks in place of ad-hoc glo-bal wiring structures the top level wires on a chip and facilitates modular design.  With this approach, system modules (processors, memories, peripherals, etc...) communicate by sending packets to one another over the network.  The structured network wiring gives well-controlled electrical parameters that eliminate timing iterations and enable the use of high-performance circuits to reduce latency and increase bandwidth.  The area overhead required to implement an on-chip network is modest, we estimate 6.6%.   This paper introduces the concept of on-chip networks, sketches a simple network, and discusses some challenges in the architecture and design of these networks.","title":"Route packets, not wires: on-chip interconnection networks","venue":"design automation conference","year":2001,"__v":0,"citationCount":1564,"parents":{"06937ba2-e653-4b8e-93c0-7a6d74e69004":50,"1e51da39-6e06-4c67-bc59-bb8074240d47":0},"keyword":{"06937ba2-e653-4b8e-93c0-7a6d74e69004":9.315476190476192,"1e51da39-6e06-4c67-bc59-bb8074240d47":10.283333333333335},"topic":["network","wire","onchip","structur","design"],"groups":[{"authors":["Li-Shiuan Peh","William J. Dally"],"references":["1e51da39-6e06-4c67-bc59-bb8074240d47","28c6006e-2ef0-47e2-84e7-01bfd7ff9045","6bf89450-3950-4def-b2d8-2ce73b5e2988","948a5000-1854-4e22-9073-b51bf6e05613","9d707287-768b-4e04-8ce4-5c6ad0b40b65","9f5e7cf6-b3ca-4aca-a7cc-86d1202c27b2"],"_id":"06937ba2-e653-4b8e-93c0-7a6d74e69004","abstract":"This paper introduces a router delay model that accurately models key aspects of modern routers. The model accounts for the pipelined nature of contemporary routers, the specific flow control method employed the delay of the flow control credit path, and the sharing of crossbar ports across virtual channels. Motivated by this model, we introduce a microarchitecture for a speculative virtual-channel router that significantly reduces its router latency to that of a brown hole router. Simulations using our pipelined model give results that differ considerably from the commonly assumed 'unit-latency' model which is unreasonably optimistic. Using realistic pipeline models, we compare wormhole and virtual-channel flow control. Our results show that a speculative virtual-channel router has the same per-hop router latency as a wormhole router while improving throughput by up to 40%.","title":"A delay model and speculative architecture for pipelined routers","venue":"high performance computer architecture","year":2001,"__v":0,"citationCount":294}],"offsprings":[]},"ab0bfa8d-80b6-47ef-8a91-febce2ce65c5":{"authors":["David L. Donoho"],"references":[],"_id":"ab0bfa8d-80b6-47ef-8a91-febce2ce65c5","abstract":"Donoho and Johnstone (1994) proposed a method for reconstructing an unknown function f on [0,1] from noisy data d/sub i/=f(t/sub i/)+/spl sigma/z/sub i/, i=0, ..., n-1,t/sub i/=i/n, where the z/sub i/ are independent and identically distributed standard Gaussian random variables. The reconstruction f/spl circ/*/sub n/ is defined in the wavelet domain by translating all the empirical wavelet coefficients of d toward 0 by an amount /spl sigma//spl middot//spl radic/(2log (n)/n). The authors prove two results about this type of estimator. [Smooth]: with high probability f/spl circ/*/sub n/ is at least as smooth as f, in any of a wide variety of smoothness measures. [Adapt]: the estimator comes nearly as close in mean square to f as any measurable estimator can come, uniformly over balls in each of two broad scales of smoothness classes. These two properties are unprecedented in several ways. The present proof of these results develops new facts about abstract statistical inference and its connection with an optimal recovery model. >","title":"De-noising by soft-thresholding","venue":"IEEE Transactions on Information Theory","year":1995,"__v":0,"citationCount":1733,"parents":{"28b8d07b-a802-4e3a-9dfb-2735d0ef7dfb":0,"b172a91e-42cf-4e43-a6f3-e4101943786f":0,"bd5acb06-2698-4ce9-a0ae-cbd687e03278":0},"keyword":{"28b8d07b-a802-4e3a-9dfb-2735d0ef7dfb":12.25242905242905,"b172a91e-42cf-4e43-a6f3-e4101943786f":0,"bd5acb06-2698-4ce9-a0ae-cbd687e03278":10.220105820105822},"topic":["smooth","estim","wavelet","result","reconstruct"],"offsprings":["e537d143-155e-4ca0-8ae8-66b777a77fea"]},"c5d73f15-467c-4824-8784-4bf66630fe94":{"authors":["Xiaofei He","Partha Niyogi"],"references":["56f4b72a-ec39-47ac-8220-899296e7fb18"],"_id":"c5d73f15-467c-4824-8784-4bf66630fe94","abstract":"Many problems in information processing involve some form of dimensionality reduction. In this paper, we introduce Locality Preserving Projections (LPP). These are linear projective maps that arise by solving a variational problem that optimally preserves the neighborhood structure of the data set. LPP should be seen as an alternative to Principal Component Analysis (PCA) – a classical linear technique that projects the data along the directions of maximal variance. When the high dimensional data lies on a low dimensional manifold embedded in the ambient space, the Locality Preserving Projections are obtained by finding the optimal linear approximations to the eigenfunctions of the Laplace Beltrami operator on the manifold. As a result, LPP shares many of the data representation properties of nonlinear techniques such as Laplacian Eigenmaps or Locally Linear Embedding. Yet LPP is linear and more crucially is defined everywhere in ambient space rather than just on the training data points. This is borne out by illustrative examples on some high dimensional data sets.","title":"Locality Preserving Projections","venue":"neural information processing systems","year":2004,"__v":0,"citationCount":1522,"parents":{"56f4b72a-ec39-47ac-8220-899296e7fb18":0,"cbff2ff2-6b8f-425d-a5ef-aff0de9be3e5":0},"keyword":{"56f4b72a-ec39-47ac-8220-899296e7fb18":11.120105820105822,"cbff2ff2-6b8f-425d-a5ef-aff0de9be3e5":10.679232804232804},"topic":["data","linear","project","lpp","dimension"],"offsprings":[]},"84f38277-cf2e-4362-b807-4208af039806":{"authors":["Doug Burger","Todd M. Austin"],"references":[],"_id":"84f38277-cf2e-4362-b807-4208af039806","abstract":"This document describes release 2.0 of the SimpleScalar tool set, a suite of free, publicly available simulation tools that offer both detailed and high-performance simulation of modern microprocessors. The new release offers more tools and capabilities, precompiled binaries, cleaner interfaces, better documentation, easier installation, improved portability, and higher performance. This paper contains a complete description of the tool set, including retrieval and installation instructions, a description of how to use the tools, a description of the target SimpleScalar architecture, and many details about the internals of the tools and how to customize them. With this guide, the tool set can be brought up and generating results in under an hour (on supported platforms).","title":"The SimpleScalar tool set, version 2.0","venue":"ACM Sigarch Computer Architecture News","year":1997,"__v":0,"citationCount":1732,"parents":{"16154319-0643-4304-9734-56b35da0a4ad":0,"f26a1fb0-5e43-4d99-a581-733dc0c31d04":0},"keyword":{"16154319-0643-4304-9734-56b35da0a4ad":9.299444444444445,"f26a1fb0-5e43-4d99-a581-733dc0c31d04":11.730833333333333},"topic":["tool","set","descript","simul","simplescalar"],"offsprings":["17d28db6-642c-4b81-aec6-0bcbcf71858d"]},"7f1dc63a-9064-4768-a30d-3383d52aa81e":{"authors":["James A. Gosling","Bill Joy","Guy L. Steele"],"references":[],"_id":"7f1dc63a-9064-4768-a30d-3383d52aa81e","abstract":"From the Publisher:#R##N#Written by the inventors of the technology, The Java(tm) Language Specification, Second Edition is the definitive technical reference for the Java(tm) programming language. If you want to know the precise meaning of the language's constructs, this is the source for you. #R##N#The book provides complete, accurate, and detailed coverage of the syntax and semantics of the Java programming language. It describes all aspects of the language, including the semantics of all types, statements, and expressions, as well as threads and binary compatibility.","title":"The Java Language Specification","venue":"","year":1996,"__v":0,"citationCount":1753,"parents":{"c540b2df-6ebe-4314-b5aa-7acc96044ef9":0,"e2285510-fd4d-4b40-89ca-627a9ce7b76c":0},"keyword":{"c540b2df-6ebe-4314-b5aa-7acc96044ef9":8.054365079365079,"e2285510-fd4d-4b40-89ca-627a9ce7b76c":10.351587301587301},"topic":["languag","semant","program","javatm","type"],"offsprings":[]},"6d121e97-e351-4cf9-8c44-d7ab3ce9d9fe":{"authors":["Laurent Itti","Christof Koch","Ernst Niebur"],"references":[],"_id":"6d121e97-e351-4cf9-8c44-d7ab3ce9d9fe","abstract":"A visual attention system, inspired by the behavior and the neuronal architecture of the early primate visual system, is presented. Multiscale image features are combined into a single topographical saliency map. A dynamical neural network then selects attended locations in order of decreasing saliency. The system breaks down the complex problem of scene understanding by rapidly selecting, in a computationally efficient manner, conspicuous locations to be analyzed in detail.","title":"A model of saliency-based visual attention for rapid scene analysis","venue":"IEEE Transactions on Pattern Analysis and Machine Intelligence","year":1998,"__v":0,"citationCount":3535,"parents":{"f0d33a06-24c8-42c5-a8e9-839ea9891157":0,"f4642ffc-3571-4d02-8b94-142f2448023a":0},"keyword":{"f0d33a06-24c8-42c5-a8e9-839ea9891157":9.28095238095238,"f4642ffc-3571-4d02-8b94-142f2448023a":11.265079365079366},"topic":["system","visual","select","salienc","locat"],"offsprings":["750b0ac1-2ac9-4273-a9c8-baad11e26fcd","8b8a2247-bd77-4736-b493-449734f56b9a","e649a9fd-f6d9-4aac-b428-29b82c20a484"]},"177b7083-bfca-472b-833a-515f1ad77735":{"authors":["Chris Stauffer","W.E.L. Grimson"],"references":[],"_id":"177b7083-bfca-472b-833a-515f1ad77735","abstract":"A common method for real-time segmentation of moving regions in image sequences involves \"background subtraction\", or thresholding the error between an estimate of the image without moving objects and the current image. The numerous approaches to this problem differ in the type of background model used and the procedure used to update the model. This paper discusses modeling each pixel as a mixture of Gaussians and using an on-line approximation to update the model. The Gaussian, distributions of the adaptive mixture model are then evaluated to determine which are most likely to result from a background process. Each pixel is classified based on whether the Gaussian distribution which represents it most effectively is considered part of the background model. This results in a stable, real-time outdoor tracker which reliably deals with lighting changes, repetitive motions from clutter, and long-term scene changes. This system has been run almost continuously for 16 months, 24 hours a day, through rain and snow.","title":"Adaptive background mixture models for real-time tracking","venue":"computer vision and pattern recognition","year":1999,"__v":0,"citationCount":2554,"parents":{"05dfbd43-02b1-4e92-a4f1-e6ecfae601f5":25,"2e8317ef-655e-41d3-86c1-552c627ca9c5":0,"c02803c1-324a-4f8d-8e10-b426574deb90":0,"c9fa31f7-f6ce-49ea-b42c-8d03ae59dbe4":0},"keyword":{"05dfbd43-02b1-4e92-a4f1-e6ecfae601f5":6.974999999999999,"2e8317ef-655e-41d3-86c1-552c627ca9c5":9.252777777777776,"c02803c1-324a-4f8d-8e10-b426574deb90":8.127777777777776,"c9fa31f7-f6ce-49ea-b42c-8d03ae59dbe4":11.459285714285715},"topic":["model","background","imag","gaussian","updat"],"offsprings":["a81d35e6-d5cd-4eef-9144-b0755ef268d1"]},"4adb467d-dacf-4019-b0d5-28ce1f323cf4":{"authors":["Fabrizio Sebastiani"],"references":["bc95970b-34c5-4860-a832-41bc04a50889"],"_id":"4adb467d-dacf-4019-b0d5-28ce1f323cf4","abstract":"The automated categorization (or classification) of texts into predefined categories has witnessed a booming interest in the last 10 years, due to the increased availability of documents in digital form and the ensuing need to organize them. In the research community the dominant approach to this problem is based on machine learning techniques: a general inductive process automatically builds a classifier by learning, from a set of preclassified documents, the characteristics of the categories. The advantages of this approach over the knowledge engineering approach (consisting in the manual definition of a classifier by domain experts) are a very good effectiveness, considerable savings in terms of expert labor power, and straightforward portability to different domains. This survey discusses the main approaches to text categorization that fall within the machine learning paradigm. We will discuss in detail issues pertaining to three different problems, namely, document representation, classifier construction, and classifier evaluation.","title":"Machine learning in automated text categorization","venue":"ACM Computing Surveys","year":2002,"__v":0,"citationCount":2709,"parents":{"01e036ec-11c7-4251-98cc-13d11b59d0f0":0,"0500ddbe-e274-477b-bb6b-54a7269e4577":13.559322033898304,"05268346-81e5-4a59-b6e6-9e7d0ca204eb":5.932203389830509,"0bcf0b45-5d17-4f84-9912-0d35660c4403":10.16949152542373,"0e4d2a3c-f426-434d-981c-6acaf25430d9":0,"0e8681ad-3687-4fd2-8dd6-7991dc6e4068":3.389830508474576,"0f6a4fe2-14a0-4991-8a0f-daf425bb6838":5.932203389830509,"0fdd6fc4-a6ff-4e7b-858c-2daedb168b17":3.389830508474576,"12926501-efe2-4ab3-a7cb-f632a1ac4e64":0.847457627118644,"1437fd93-6c89-45aa-a937-3c555d089289":0,"14d121c5-3655-473a-a6a5-0a27932f6ade":3.389830508474576,"1a8e6293-8d68-4544-916a-66e329ba73b7":0,"1b7418af-1aba-4090-bad4-0dd0e900f5aa":0.847457627118644,"1ce7a9a3-91c4-45d6-984a-e1d240fd81aa":0.847457627118644,"1ec45041-b11f-4785-b9ee-ed99eb029ddc":0.847457627118644,"1f54b4c0-e85f-40bf-a3fe-2fd708c71064":2.5423728813559325,"23f66d97-4abf-479f-8af5-ec833d850a24":2.5423728813559325,"245e4043-ccdb-457a-9be1-e120c7a94753":0,"25f9dfdb-4cb7-4dd2-9b42-90992fd5d8b8":4.23728813559322,"261aefde-fbe5-494f-afd7-c771aff03127":0,"27d381c3-27e0-4c31-89fa-6639b3e06449":0,"28d80fb2-745b-4c03-a8dc-829c46ddf3fb":0.847457627118644,"2d691e6d-df41-4fdc-b226-8068e19d5b34":1.694915254237288,"328e6d1a-73c4-48da-ac29-d671a581cf86":5.932203389830509,"33be9d6d-dab6-45fc-89d9-022149720d24":0.847457627118644,"367d33bc-55f2-4ac9-8adb-72c681914286":1.694915254237288,"38500fe9-7c31-4a6a-aa20-fc96325f2946":0,"3876df95-6893-442c-aeea-09de7c344874":0.847457627118644,"3a77b2e4-44c5-47db-97fd-40dadcca1e02":0,"3b013a2d-ff3b-4ded-bbfa-e36fd67669e7":1.694915254237288,"3d189262-70db-4a04-87bc-9099e6c46e8c":0,"3f394e9d-c50a-4505-9b76-458f5e8be345":9.322033898305085,"4564dd59-3ed0-4987-9dd9-3e30d2dcdb28":0,"49fb51f7-ea3f-4071-82f6-0b8b9571b223":1.694915254237288,"4bf13cbb-9026-4e4a-90da-64104415c0b3":6.779661016949152,"4c4b67d4-ef63-4eab-9fb6-ce2e64dec16e":4.23728813559322,"4d6a41b2-ba88-4c41-b19d-3badcccc2b2f":0.847457627118644,"4edb6ffa-799a-4556-9041-652eabb18a8b":0,"514444a0-7178-4d68-9914-fd018d94fa16":11.864406779661017,"51c8135d-1673-4fa8-9842-a65c4183ac73":0,"51eb4778-5546-45f1-8990-4a527d8b6d33":1.694915254237288,"529f0775-01b2-4f1e-9d89-fc5227058019":0,"52c01d07-28bb-4a1c-98da-1482a380f6db":4.23728813559322,"5465d7f9-4818-4f79-a434-73907d7ae423":1.694915254237288,"55170d49-f3e8-437a-b0ea-a14ba8d5319e":0,"55514f7e-209f-4f0b-ae46-cf5f2b4d70e7":3.389830508474576,"55ab17e9-5c62-4157-adc9-28935eed7120":7.627118644067797,"5694495a-ded0-44ef-ac1d-3e6e0482d90d":11.016949152542372,"57b03a88-b12e-41e3-b3a9-e6ecdaf12730":0,"58110599-9a6d-44ba-9e5f-b9a92d52b820":5.084745762711865,"58913a76-a718-4493-a5e9-2fa8aa3ef52b":0,"5b6620cd-3df0-4309-a24d-b120be89242c":2.5423728813559325,"64578cea-4946-4321-9970-c4b5c43c48ee":0.847457627118644,"67288135-af65-4979-99ef-75e7d603e190":4.23728813559322,"67964a4a-b4c6-445d-88d0-2bdc37c3a5ba":5.932203389830509,"68520ece-23ee-457f-b7a4-f08216c717fd":0.847457627118644,"6d15cd37-496d-44e1-8bfb-004621255173":0,"6e206624-7a7f-4ee9-91c8-d78003892706":1.694915254237288,"73f6b15e-509c-4f2f-9160-35cab954ce59":0.847457627118644,"75ec0b95-65c5-48c9-ae1b-a44c6c378bec":7.627118644067797,"7fd22f4f-deba-415c-ae7c-cdbe5dba2f55":5.932203389830509,"7fd6fe96-a556-4353-8c6a-763dc81514f6":0,"847195a1-97a7-4986-95a2-a5575aa20b09":4.23728813559322,"866d201b-b373-47a7-9860-0f185d90dbe2":7.627118644067797,"87e6130e-51b7-4239-b166-709c0c7ccb26":2.5423728813559325,"8828ba95-7026-4085-9803-7cce05949493":6.779661016949152,"8c0baa91-d32e-478b-89e3-d7c636db2e76":3.389830508474576,"92d0da63-d882-4d22-b5d2-5c41306bda51":4.23728813559322,"9519ccab-8cda-40ff-bd55-b61857c27b56":11.016949152542372,"96d6d9b9-6d69-4c9a-b3f5-c8083966d55c":0,"979fbf34-d977-4a5e-a727-a1038c4d7f97":0.847457627118644,"9bdbf6d6-db2b-4114-969a-37b4e03993b0":0,"9c9be0c6-ab2a-467e-b499-dfb3fd207029":6.779661016949152,"9f4995af-e704-48ab-8717-6972a3d4455b":0,"a12b3831-01ce-48e0-a9b4-d56530df528c":0,"a1e8ab1e-6df3-4383-b708-b5b5c29b4b7f":0.847457627118644,"a506f179-4c89-4cfc-a719-c374b2671279":1.694915254237288,"a5e45f48-d860-4cd5-a638-6122a2d331fe":0,"a677a749-cb49-4d5e-a2d8-2078230e4f88":0.847457627118644,"ab339474-ea21-443b-893f-96ae09e65a2e":0,"b9111683-1151-4542-8a10-d1eeb730087e":5.084745762711865,"b923a531-5949-4b42-966c-5dd551c30585":3.389830508474576,"bb74ee29-c9bd-4ed8-978c-295045e24594":6.779661016949152,"bb98580e-953d-467f-8aa1-f0fd204cdb5c":0.847457627118644,"bbf63075-ea5d-4b47-b13d-961493788d35":0.847457627118644,"bc66f6be-1038-4deb-a11e-35f51f0937d4":5.084745762711865,"bc95970b-34c5-4860-a832-41bc04a50889":0,"c04cc3bb-dd4a-4abd-b55b-3d3ebaccfba5":0,"c08dcfdd-2903-4a29-be58-4747740baa58":6.779661016949152,"c0af1514-af65-4d85-af68-de3409fc6532":5.084745762711865,"c12af7c5-ea9e-41b8-8d0a-eab301f8d270":0,"c13bf4d6-b7f2-4a7e-abf6-d798782b75ea":2.5423728813559325,"c285808d-767a-4900-bb93-72679186d815":10.16949152542373,"c28ea43f-078a-4b68-a690-5a0ec70a983e":0,"c2cce1cf-b653-430b-b5e4-b5141484f09c":1.694915254237288,"c3e99ff5-57f9-4012-8b92-48c8d26bf232":4.23728813559322,"c476f0a8-d3db-43c6-940d-de9c8c9291bd":4.23728813559322,"c4beaa25-a712-4854-803d-fa0d74149e84":0.847457627118644,"d129ed23-bb3d-4ae3-8122-30e2f5baa419":5.932203389830509,"d1a51572-839b-4ae1-97c3-ad045ea6425a":0.847457627118644,"d59fdaf0-3972-4f10-a74f-e8f22a231afb":6.779661016949152,"da0f35bf-8a7b-4d2e-8626-0a098a4bc854":1.694915254237288,"dd7be56b-cc00-41d7-9bf7-99aafe03b600":0,"dedf3259-acc0-41b0-9581-ba89abd14c00":3.389830508474576,"e246b3ef-605d-46c4-9e21-294de09b70ea":5.084745762711865,"e91a0a81-da9c-4009-9007-18ba9b8595b2":0.847457627118644,"e9a10bb1-bcd7-48c4-af6b-df754852d14c":3.389830508474576,"e9abffef-c6bf-44da-a673-be480773dbbb":0,"ec115dba-62a8-45da-8df7-b41d4bf7cc9e":3.389830508474576,"ec508672-6090-4ac3-8939-69e27e9cb977":2.5423728813559325,"ed660ea2-fad8-4bd1-8c0b-8c0679eb1657":3.389830508474576,"f291765d-169d-49de-8972-a0c9692159f7":0,"f644253d-4748-4ef1-847b-c6a41a231c90":2.5423728813559325,"fa81a051-0f8e-4f10-a172-acd5a8923e23":6.779661016949152,"fb2d9162-7ff8-44b4-b73f-f822783dcafe":2.5423728813559325,"fe18f1d7-1c3d-43ce-8b51-acc0e769b1db":0,"febb53cc-a472-4f7e-afac-c530e7010051":1.694915254237288,"ff78f8f6-0559-4be7-a7e1-0e8bb742ecda":8.47457627118644},"keyword":{"01e036ec-11c7-4251-98cc-13d11b59d0f0":9.808730158730159,"0500ddbe-e274-477b-bb6b-54a7269e4577":11.249999999999998,"05268346-81e5-4a59-b6e6-9e7d0ca204eb":11.643716931216929,"0bcf0b45-5d17-4f84-9912-0d35660c4403":10.206150793650792,"0e4d2a3c-f426-434d-981c-6acaf25430d9":0,"0e8681ad-3687-4fd2-8dd6-7991dc6e4068":0,"0f6a4fe2-14a0-4991-8a0f-daf425bb6838":9.123888888888889,"0fdd6fc4-a6ff-4e7b-858c-2daedb168b17":8.438888888888888,"12926501-efe2-4ab3-a7cb-f632a1ac4e64":10.658333333333331,"1437fd93-6c89-45aa-a937-3c555d089289":10.268253968253966,"14d121c5-3655-473a-a6a5-0a27932f6ade":7.086111111111111,"1a8e6293-8d68-4544-916a-66e329ba73b7":9.132804232804233,"1b7418af-1aba-4090-bad4-0dd0e900f5aa":11.369444444444444,"1ce7a9a3-91c4-45d6-984a-e1d240fd81aa":8.77222222222222,"1ec45041-b11f-4785-b9ee-ed99eb029ddc":10.671031746031742,"1f54b4c0-e85f-40bf-a3fe-2fd708c71064":11.416666666666666,"23f66d97-4abf-479f-8af5-ec833d850a24":0,"245e4043-ccdb-457a-9be1-e120c7a94753":11.47222222222222,"25f9dfdb-4cb7-4dd2-9b42-90992fd5d8b8":0,"261aefde-fbe5-494f-afd7-c771aff03127":0,"27d381c3-27e0-4c31-89fa-6639b3e06449":11.151666666666666,"28d80fb2-745b-4c03-a8dc-829c46ddf3fb":12.203769841269839,"2d691e6d-df41-4fdc-b226-8068e19d5b34":11.189563492063492,"328e6d1a-73c4-48da-ac29-d671a581cf86":0,"33be9d6d-dab6-45fc-89d9-022149720d24":12.320370370370368,"367d33bc-55f2-4ac9-8adb-72c681914286":11.041666666666664,"38500fe9-7c31-4a6a-aa20-fc96325f2946":0,"3876df95-6893-442c-aeea-09de7c344874":12.089285714285715,"3a77b2e4-44c5-47db-97fd-40dadcca1e02":0,"3b013a2d-ff3b-4ded-bbfa-e36fd67669e7":8.964166666666666,"3d189262-70db-4a04-87bc-9099e6c46e8c":11.45099206349206,"3f394e9d-c50a-4505-9b76-458f5e8be345":12.032142857142853,"4564dd59-3ed0-4987-9dd9-3e30d2dcdb28":0,"49fb51f7-ea3f-4071-82f6-0b8b9571b223":0,"4bf13cbb-9026-4e4a-90da-64104415c0b3":10.04722222222222,"4c4b67d4-ef63-4eab-9fb6-ce2e64dec16e":0,"4d6a41b2-ba88-4c41-b19d-3badcccc2b2f":9.624999999999998,"4edb6ffa-799a-4556-9041-652eabb18a8b":0,"514444a0-7178-4d68-9914-fd018d94fa16":0,"51c8135d-1673-4fa8-9842-a65c4183ac73":0,"51eb4778-5546-45f1-8990-4a527d8b6d33":11.066269841269841,"529f0775-01b2-4f1e-9d89-fc5227058019":9.613571428571426,"52c01d07-28bb-4a1c-98da-1482a380f6db":9.358333333333334,"5465d7f9-4818-4f79-a434-73907d7ae423":11.180634920634919,"55170d49-f3e8-437a-b0ea-a14ba8d5319e":6.852777777777778,"55514f7e-209f-4f0b-ae46-cf5f2b4d70e7":10.103253968253966,"55ab17e9-5c62-4157-adc9-28935eed7120":0,"5694495a-ded0-44ef-ac1d-3e6e0482d90d":11.19563492063492,"57b03a88-b12e-41e3-b3a9-e6ecdaf12730":0,"58110599-9a6d-44ba-9e5f-b9a92d52b820":0,"58913a76-a718-4493-a5e9-2fa8aa3ef52b":0,"5b6620cd-3df0-4309-a24d-b120be89242c":0,"64578cea-4946-4321-9970-c4b5c43c48ee":0,"67288135-af65-4979-99ef-75e7d603e190":8.950396825396824,"67964a4a-b4c6-445d-88d0-2bdc37c3a5ba":10.464960317460315,"68520ece-23ee-457f-b7a4-f08216c717fd":9.698809523809523,"6d15cd37-496d-44e1-8bfb-004621255173":11.082222222222223,"6e206624-7a7f-4ee9-91c8-d78003892706":8.29722222222222,"73f6b15e-509c-4f2f-9160-35cab954ce59":8.79611111111111,"75ec0b95-65c5-48c9-ae1b-a44c6c378bec":9.216666666666667,"7fd22f4f-deba-415c-ae7c-cdbe5dba2f55":9.111111111111107,"7fd6fe96-a556-4353-8c6a-763dc81514f6":0,"847195a1-97a7-4986-95a2-a5575aa20b09":0,"866d201b-b373-47a7-9860-0f185d90dbe2":8.43095238095238,"87e6130e-51b7-4239-b166-709c0c7ccb26":10.651587301587302,"8828ba95-7026-4085-9803-7cce05949493":10.430952380952377,"8c0baa91-d32e-478b-89e3-d7c636db2e76":0,"92d0da63-d882-4d22-b5d2-5c41306bda51":10.349999999999998,"9519ccab-8cda-40ff-bd55-b61857c27b56":0,"96d6d9b9-6d69-4c9a-b3f5-c8083966d55c":10.947222222222223,"979fbf34-d977-4a5e-a727-a1038c4d7f97":8.330555555555554,"9bdbf6d6-db2b-4114-969a-37b4e03993b0":11.81944444444444,"9c9be0c6-ab2a-467e-b499-dfb3fd207029":11.439484126984125,"9f4995af-e704-48ab-8717-6972a3d4455b":0,"a12b3831-01ce-48e0-a9b4-d56530df528c":0,"a1e8ab1e-6df3-4383-b708-b5b5c29b4b7f":8.805952380952382,"a506f179-4c89-4cfc-a719-c374b2671279":10.030158730158728,"a5e45f48-d860-4cd5-a638-6122a2d331fe":0,"a677a749-cb49-4d5e-a2d8-2078230e4f88":0,"ab339474-ea21-443b-893f-96ae09e65a2e":10.429166666666667,"b9111683-1151-4542-8a10-d1eeb730087e":0,"b923a531-5949-4b42-966c-5dd551c30585":0,"bb74ee29-c9bd-4ed8-978c-295045e24594":0,"bb98580e-953d-467f-8aa1-f0fd204cdb5c":10.765277777777776,"bbf63075-ea5d-4b47-b13d-961493788d35":0,"bc66f6be-1038-4deb-a11e-35f51f0937d4":10.49333333333333,"bc95970b-34c5-4860-a832-41bc04a50889":10.235714285714284,"c04cc3bb-dd4a-4abd-b55b-3d3ebaccfba5":9.133333333333333,"c08dcfdd-2903-4a29-be58-4747740baa58":10.42047619047619,"c0af1514-af65-4d85-af68-de3409fc6532":0,"c12af7c5-ea9e-41b8-8d0a-eab301f8d270":0,"c13bf4d6-b7f2-4a7e-abf6-d798782b75ea":10.048888888888888,"c285808d-767a-4900-bb93-72679186d815":11.180555555555557,"c28ea43f-078a-4b68-a690-5a0ec70a983e":0,"c2cce1cf-b653-430b-b5e4-b5141484f09c":8.736111111111109,"c3e99ff5-57f9-4012-8b92-48c8d26bf232":0,"c476f0a8-d3db-43c6-940d-de9c8c9291bd":10.205238095238094,"c4beaa25-a712-4854-803d-fa0d74149e84":0,"d129ed23-bb3d-4ae3-8122-30e2f5baa419":9.616666666666667,"d1a51572-839b-4ae1-97c3-ad045ea6425a":0,"d59fdaf0-3972-4f10-a74f-e8f22a231afb":0,"da0f35bf-8a7b-4d2e-8626-0a098a4bc854":9.231296296296296,"dd7be56b-cc00-41d7-9bf7-99aafe03b600":0,"dedf3259-acc0-41b0-9581-ba89abd14c00":10.829166666666666,"e246b3ef-605d-46c4-9e21-294de09b70ea":9.87222222222222,"e91a0a81-da9c-4009-9007-18ba9b8595b2":12.28833333333333,"e9a10bb1-bcd7-48c4-af6b-df754852d14c":0,"e9abffef-c6bf-44da-a673-be480773dbbb":9.513492063492063,"ec115dba-62a8-45da-8df7-b41d4bf7cc9e":10.187698412698408,"ec508672-6090-4ac3-8939-69e27e9cb977":11.997222222222222,"ed660ea2-fad8-4bd1-8c0b-8c0679eb1657":10.457222222222223,"f291765d-169d-49de-8972-a0c9692159f7":0,"f644253d-4748-4ef1-847b-c6a41a231c90":10.029166666666665,"fa81a051-0f8e-4f10-a172-acd5a8923e23":0,"fb2d9162-7ff8-44b4-b73f-f822783dcafe":0,"fe18f1d7-1c3d-43ce-8b51-acc0e769b1db":0,"febb53cc-a472-4f7e-afac-c530e7010051":10.917857142857141,"ff78f8f6-0559-4be7-a7e1-0e8bb742ecda":9.01},"topic":["classifi","approach","learn","document","text"],"offsprings":["9b8a49b5-a5cb-4c61-8c60-3bde6d310009"]},"4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4":{"authors":["Ion Stoica","Robert Morris","David Liben-Nowell","David R. Karger","M. Frans Kaashoek","Frank Dabek","Hari Balakrishnan"],"references":["e1263ada-afda-498c-a37d-9b545293118a","f14df1ed-e3e9-4348-9040-fc06e3411b95"],"_id":"4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4","abstract":"A fundamental problem that confronts peer-to-peer applications is the efficient location of the node that stores a desired data item. This paper presents  Chord , a distributed lookup protocol that addresses this problem. Chord provides support for just one operation: given a key, it maps the key onto a node. Data location can be easily implemented on top of Chord by associating a key with each data item, and storing the key/data pair at the node to which the key maps. Chord adapts efficiently as nodes join and leave the system, and can answer queries even if the system is continuously changing. Results from theoretical analysis and simulations show that Chord is scalable: Communication cost and the state maintained by each node scale logarithmically with the number of Chord nodes.","title":"Chord: a scalable peer-to-peer lookup protocol for Internet applications","venue":"IEEE\\/ACM Transactions on Networking","year":2003,"__v":0,"citationCount":5975,"parents":{"1cc64868-4f72-4939-aed4-fc8fb0b45118":5.555555555555555,"48740ddd-afd1-4331-8af7-224ef5d19ed7":5.555555555555555,"59084791-6ebd-4d0d-8f93-2c1da8d47490":0,"6aac8d9c-34bd-42d9-b887-b0a3bd697ee6":0,"6eff83a4-db80-40ea-8c9f-8bda5f506c29":0,"a369afee-a619-4e9a-9250-5fd2b06e8a05":0,"aa89fd2a-319e-48b1-b0ab-099acbe37617":0,"abf003a2-6485-41f0-a111-88b80412d539":0,"b7d7ec53-f079-4bd7-a795-8b6fe77f2db6":38.88888888888889,"b948f5db-4dc3-4151-a9bd-62a3f5be739e":16.666666666666664,"c0ea675b-2479-48ae-817e-3ecedd175ecf":5.555555555555555,"c37c70cb-3956-4249-934d-848845f2f444":0,"e1263ada-afda-498c-a37d-9b545293118a":22.22222222222222,"e4ee2d81-7629-4445-b4f3-55ef57bd42fd":5.555555555555555,"ea44a1ae-ddfe-4694-8df1-0ec69182ec11":27.77777777777778,"f14df1ed-e3e9-4348-9040-fc06e3411b95":33.33333333333333,"f49921e2-fb25-48d1-aaf2-1afcfeb8b268":27.77777777777778,"fad8fc34-ff78-45ac-bc30-ca9e4173740f":0},"keyword":{"1cc64868-4f72-4939-aed4-fc8fb0b45118":9.414407814407813,"48740ddd-afd1-4331-8af7-224ef5d19ed7":9.925555555555556,"59084791-6ebd-4d0d-8f93-2c1da8d47490":9.630555555555555,"6aac8d9c-34bd-42d9-b887-b0a3bd697ee6":9.449074074074076,"6eff83a4-db80-40ea-8c9f-8bda5f506c29":0,"a369afee-a619-4e9a-9250-5fd2b06e8a05":7.527777777777778,"aa89fd2a-319e-48b1-b0ab-099acbe37617":8.865740740740742,"abf003a2-6485-41f0-a111-88b80412d539":9.68425925925926,"b7d7ec53-f079-4bd7-a795-8b6fe77f2db6":7.032222222222222,"b948f5db-4dc3-4151-a9bd-62a3f5be739e":9.59904761904762,"c0ea675b-2479-48ae-817e-3ecedd175ecf":0,"c37c70cb-3956-4249-934d-848845f2f444":0,"e1263ada-afda-498c-a37d-9b545293118a":9.718121693121693,"e4ee2d81-7629-4445-b4f3-55ef57bd42fd":7.896031746031746,"ea44a1ae-ddfe-4694-8df1-0ec69182ec11":8.761097883597884,"f14df1ed-e3e9-4348-9040-fc06e3411b95":9.659523809523808,"f49921e2-fb25-48d1-aaf2-1afcfeb8b268":7.796031746031746,"fad8fc34-ff78-45ac-bc30-ca9e4173740f":11.301190476190476},"topic":["node","chord","kei","data","system"],"groups":[{"authors":["Sameer Ajmani","Dwaine E. Clarke","Chuang-Hue Moh","Steven Richman"],"references":["151d2005-6170-4201-8cee-ea3870353ab7","16828a9e-92bc-4160-89eb-a1b30bd06410","1cc64868-4f72-4939-aed4-fc8fb0b45118","1e440687-918b-46c1-ba06-2e05472261b4","4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4","5fad6d18-3991-4cd2-9bf4-1c50821095aa","6eff83a4-db80-40ea-8c9f-8bda5f506c29","7507e0d5-e5d3-4b54-b83e-8ce26c720ae0","8d697cd1-10e1-460b-a797-c7c41d4b3646","9d11aa6c-586e-40dc-a475-094bf043431f","a83ce62d-7b67-4121-b8d6-d142d630056e","b7d7ec53-f079-4bd7-a795-8b6fe77f2db6","b869c249-f61a-416c-90d7-16ad4a3a1dff","c42097c1-59a6-4105-87d7-104d486ca211","e1263ada-afda-498c-a37d-9b545293118a","e7dd5f64-2732-4426-a522-f3572fddde97","eb02194b-fa72-4f3e-a259-1dd36cd4839d","f14df1ed-e3e9-4348-9040-fc06e3411b95"],"_id":"ea44a1ae-ddfe-4694-8df1-0ec69182ec11","abstract":"We present ConChord, a large-scale certificate distribution system built on a peer-to-peer distributed hash table. ConChord provides load-balanced storage while eliminating many of the administrative difficulties of traditional, hierarchical server architectures.ConChord is specifically designed to support SDSI, a fully-decentralized public key infrastructure that allows principals to define local names and link their namespaces to delegate trust. We discuss the particular challenges ConChord must address to support SDSI efficiently, and we present novel algorithms and distributed data structures to address them. Experiments show that our techniques are effective and practical for large SDSI name hierarchies.","title":"ConChord: Cooperative SDSI Certificate Storage and Name Resolution","venue":"international workshop on peer-to-peer systems","year":2002,"__v":0,"citationCount":18},{"authors":["Antony I. T. Rowstron","Peter Druschel"],"references":["0f290b24-96ae-48f7-9304-9209bba8db17","1cc64868-4f72-4939-aed4-fc8fb0b45118","309f5d34-0bb0-4ffc-aa87-fdffb67dddf6","39adcd6c-0b60-430c-99ab-21cd9e98b385","40fb7878-7a6e-4fc1-af74-a73c1261c20b","42c70869-0dad-4629-93b5-a2d9e29071a7","48740ddd-afd1-4331-8af7-224ef5d19ed7","4ae3d80b-ce75-4c33-8abb-c5358ec01a6d","4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4","4ff9d356-904f-4ad9-835a-bc3ccf6febd9","5e354aca-2d93-43f7-8e80-6bc4eb96e7d9","5e43bfa1-e1fa-428f-847f-b1b575380d14","6500989e-b1e1-4b02-a921-21ec25685b73","747c0c4a-1e59-4af3-a9a6-ad0d081a49ce","b7d7ec53-f079-4bd7-a795-8b6fe77f2db6","c0ea675b-2479-48ae-817e-3ecedd175ecf","c8771a57-de9c-44b7-966c-1ff156d3091f","d81c71d5-dd57-46e3-92e0-daf7a7bbb065","e1263ada-afda-498c-a37d-9b545293118a","e4ee2d81-7629-4445-b4f3-55ef57bd42fd","eb02194b-fa72-4f3e-a259-1dd36cd4839d"],"_id":"f14df1ed-e3e9-4348-9040-fc06e3411b95","abstract":"This paper presents the design and evaluation of Pastry, a scalable, distributed object location and routing substrate for wide-area peer-to-peer ap- plications. Pastry performs application-level routing and object location in a po- tentially very large overlay network of nodes connected via the Internet. It can be used to support a variety of peer-to-peer applications, including global data storage, data sharing, group communication and naming. Each node in the Pastry network has a unique identifier (nodeId). When presented with a message and a key, a Pastry node efficiently routes the message to the node with a nodeId that is numerically closest to the key, among all currently live Pastry nodes. Each Pastry node keeps track of its immediate neighbors in the nodeId space, and notifies applications of new node arrivals, node failures and recoveries. Pastry takes into account network locality; it seeks to minimize the distance messages travel, according to a to scalar proximity metric like the number of IP routing hops. Pastry is completely decentralized, scalable, and self-organizing; it automatically adapts to the arrival, departure and failure of nodes. Experimental results obtained with a prototype implementation on an emulated network of up to 100,000 nodes confirm Pastry's scalability and efficiency, its ability to self-organize and adapt to node failures, and its good network locality properties.","title":"Pastry: Scalable, Decentralized Object Location, and Routing for Large-Scale Peer-to-Peer Systems","venue":"Lecture Notes in Computer Science","year":2001,"__v":0,"citationCount":4022},{"authors":["Frank Dabek","M. Frans Kaashoek","David R. Karger","Robert Morris","Ion Stoica"],"references":["1c729f22-9928-4703-92a0-8819569a1bbb","1cc64868-4f72-4939-aed4-fc8fb0b45118","1dda408f-2203-4793-bfa8-2fab15bce7cf","48740ddd-afd1-4331-8af7-224ef5d19ed7","4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4","5e354aca-2d93-43f7-8e80-6bc4eb96e7d9","5fa0709f-7330-417f-8da7-3ab31d91da5b","6eff83a4-db80-40ea-8c9f-8bda5f506c29","786e7d9f-6e9a-47e5-8482-7ee37809b922","9f65fe84-a2e3-420a-8fe4-7253e4605422","a369afee-a619-4e9a-9250-5fd2b06e8a05","b1ab8eee-7043-4f04-b440-5765752d4845","b90c5640-8e10-4f65-9193-c28af80f45e2","bd61df44-c80e-406c-8c4e-9c13635ce4f5","c0ea675b-2479-48ae-817e-3ecedd175ecf","cb0dcdc4-3c84-4301-891b-42535ac74f8c","cf67f4c1-ff76-4210-ba80-0356733c5be7","e1263ada-afda-498c-a37d-9b545293118a","f14df1ed-e3e9-4348-9040-fc06e3411b95"],"_id":"b7d7ec53-f079-4bd7-a795-8b6fe77f2db6","abstract":"The Cooperative File System (CFS) is a new peer-to-peer read-only storage system that provides provable guarantees for the efficiency, robustness, and load-balance of file storage and retrieval. CFS does this with a completely decentralized architecture that can scale to large systems. CFS servers provide a distributed hash table (DHash) for block storage. CFS clients interpret DHash blocks as a file system. DHash distributes and caches blocks at a fine granularity to achieve load balance, uses replication for robustness, and decreases latency with server selection. DHash finds blocks using the Chord location protocol, which operates in time logarithmic in the number of servers.CFS is implemented using the SFS file system toolkit and runs on Linux, OpenBSD, and FreeBSD. Experience on a globally deployed prototype shows that CFS delivers data to clients as fast as FTP. Controlled tests show that CFS is scalable: with 4,096 servers, looking up a block of data involves contacting only seven servers. The tests also demonstrate nearly perfect robustness and unimpaired performance even when as many as half the servers fail.","title":"Wide-area cooperative storage with CFS","venue":"symposium on operating systems principles","year":2001,"__v":0,"citationCount":784},{"authors":["David Liben-Nowell","Hari Balakrishnan","David R. Karger"],"references":["1cc64868-4f72-4939-aed4-fc8fb0b45118","32b2b6e0-71a1-45ec-be83-0d79c0e9d4ea","48740ddd-afd1-4331-8af7-224ef5d19ed7","4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4","6eff83a4-db80-40ea-8c9f-8bda5f506c29","7502e770-12f7-4fd1-8cd6-f54f456f7aa8","90caa8e6-80d7-4cb6-9953-361bca34ec25","b7d7ec53-f079-4bd7-a795-8b6fe77f2db6","d06f8723-1b89-4684-99c9-c1045ddfb85c","e1263ada-afda-498c-a37d-9b545293118a","f9636795-26d0-4e59-8fd6-f56024fecb00"],"_id":"f49921e2-fb25-48d1-aaf2-1afcfeb8b268","abstract":"In this paper, we give a theoretical analysis of peer-to-peer (P2P) networks operating in the face of concurrent joins and unexpected departures. We focus on Chord, a recently developed P2P system that implements a distributed hash table abstraction, and study the process by which Chord maintains its distributed state as nodes join and leave the system. We argue that traditional performance measures based on run-time are uninformative for a  continually running  P2P network, and that the  rate  at which nodes in the network need to participate to maintain system state is a more useful metric. We give a general lower bound on this rate for a network to remain connected, and prove that an appropriately modified version of Chord's maintenance rate is within a logarithmic factor of the optimum rate.","title":"Analysis of the evolution of peer-to-peer systems","venue":"principles of distributed computing","year":2002,"__v":0,"citationCount":226}],"offsprings":["cb5922c5-575b-4b50-8d58-809f8256e948","d06f8723-1b89-4684-99c9-c1045ddfb85c","e1263ada-afda-498c-a37d-9b545293118a","f14df1ed-e3e9-4348-9040-fc06e3411b95"]},"4cbd7765-c47a-4004-a5f8-c2da7c7d1c7b":{"authors":["Rong-En Fan","Kai-Wei Chang","Cho-Jui Hsieh","Xiang-Rui Wang","Chih-Jen Lin"],"references":["c1b6b493-01ef-420f-be44-7bacfe34e846"],"_id":"4cbd7765-c47a-4004-a5f8-c2da7c7d1c7b","abstract":"LIBLINEAR is an open source library for large-scale linear classification. It supports logistic regression and linear support vector machines. We provide easy-to-use command-line tools and library calls for users and developers. Comprehensive documents are available for both beginners and advanced users. Experiments demonstrate that LIBLINEAR is very efficient on large sparse data sets.","title":"LIBLINEAR: A Library for Large Linear Classification","venue":"Journal of Machine Learning Research","year":2008,"__v":0,"citationCount":2507,"parents":{"8bfb1563-5f31-4127-a98c-8d36c630fce8":20,"c1b6b493-01ef-420f-be44-7bacfe34e846":20,"eadb0f66-1fb0-4b1c-9b8b-76cf5edbfad1":60,"eef64a27-8e9a-40b2-865f-0cca306fdc31":60,"f006e236-59ad-4647-a59f-4f46dc2c85be":0},"keyword":{"8bfb1563-5f31-4127-a98c-8d36c630fce8":9.82063492063492,"c1b6b493-01ef-420f-be44-7bacfe34e846":9.015608465608468,"eadb0f66-1fb0-4b1c-9b8b-76cf5edbfad1":8.774074074074074,"eef64a27-8e9a-40b2-865f-0cca306fdc31":9.918915343915344,"f006e236-59ad-4647-a59f-4f46dc2c85be":11.244444444444444},"topic":["user","support","linear","librari","liblinear"],"groups":[{"authors":["Cho-Jui Hsieh","Kai-Wei Chang","Chih-Jen Lin","S. Sathiya Keerthi","S. Sundararajan"],"references":["0ed949f7-7118-45fa-8a4c-63fcf9f4bd8f","21873321-4d54-456b-b858-ac914b7e6db4","2190c590-c037-4170-9a93-a9d0c4468077","27002288-c316-4416-97b4-a6d582ec83b2","500961bc-9b1a-4010-a6cc-a6bae9b0e406","5959890a-1153-4bc3-b9f6-ec3ee3825eec","5ffac6f9-2456-42cf-830c-9049ce37c899","8bfb1563-5f31-4127-a98c-8d36c630fce8","b90f9310-726f-4116-9322-6fc01ab598fd","c1b6b493-01ef-420f-be44-7bacfe34e846","f006e236-59ad-4647-a59f-4f46dc2c85be","f8b62fcc-2912-427c-a1d8-786f58209193"],"_id":"eadb0f66-1fb0-4b1c-9b8b-76cf5edbfad1","abstract":"In many applications, data appear with a huge number of instances as well as features. Linear Support Vector Machines (SVM) is one of the most popular tools to deal with such large-scale sparse data. This paper presents a novel dual coordinate descent method for linear SVM with L1-and L2-loss functions. The proposed method is simple and reaches an  e -accurate solution in  O (log(1/ e )) iterations. Experiments indicate that our method is much faster than state of the art solvers such as Pegasos, TRON, SVM perf , and a recent primal coordinate descent implementation.","title":"A dual coordinate descent method for large-scale linear SVM","venue":"international conference on machine learning","year":2008,"__v":0,"citationCount":343},{"authors":["S. Sathiya Keerthi","S. Sundararajan","Kai-Wei Chang","Cho-Jui Hsieh","Chih-Jen Lin"],"references":["1b7418af-1aba-4090-bad4-0dd0e900f5aa","2237ab73-a42a-4d5d-807c-5ab6e6abbc95","51c81c66-8666-4756-9383-4fd2db5472b3","5959890a-1153-4bc3-b9f6-ec3ee3825eec","7fbbef81-7c36-4a5d-9e92-e7c59e7b82b7","834f73f1-7468-499e-bbf6-67810694bcc8","8bfb1563-5f31-4127-a98c-8d36c630fce8","a5d347a7-9984-45f4-821e-df7356477185","b5ed7586-8f67-4e79-ac6b-f8cd6422650a","cf93558f-c1b2-4292-8284-1be8d4316af1","eadb0f66-1fb0-4b1c-9b8b-76cf5edbfad1","f006e236-59ad-4647-a59f-4f46dc2c85be","f33acc76-f25e-446f-a834-9d898907b326","feff8862-f47d-4591-a7cb-b62d7efc81a2"],"_id":"eef64a27-8e9a-40b2-865f-0cca306fdc31","abstract":"Efficient training of direct multi-class formulations of linear Support Vector Machines is very useful in applications such as text classification with a huge number examples as well as features. This paper presents a fast dual method for this training. The main idea is to sequentially traverse through the training set and optimize the dual variables associated with one example at a time. The speed of training is enhanced further by shrinking and cooling heuristics. Experiments indicate that our method is much faster than state of the art solvers such as bundle, cutting plane and exponentiated gradient methods.","title":"A sequential dual method for large scale multi-class linear svms","venue":"knowledge discovery and data mining","year":2008,"__v":0,"citationCount":81}],"offsprings":["8026f56a-a93e-4933-8ead-c9aa9e3f0498","12d6aa75-3066-4e5f-a73d-f0d56c9d99f5"]},"4fb87930-7f6c-4f03-ae22-32445138ec83":{"authors":["Isabelle Guyon","André Elisseeff"],"references":["685b313d-8a77-481e-9456-e405a1d29549","9fa61eb1-0984-4492-955a-4f7aedbdc368"],"_id":"4fb87930-7f6c-4f03-ae22-32445138ec83","abstract":"Variable and feature selection have become the focus of much research in areas of application for which datasets with tens or hundreds of thousands of variables are available. These areas include text processing of internet documents, gene expression array analysis, and combinatorial chemistry. The objective of variable selection is three-fold: improving the prediction performance of the predictors, providing faster and more cost-effective predictors, and providing a better understanding of the underlying process that generated the data. The contributions of this special issue cover a wide range of aspects of such problems: providing a better definition of the objective function, feature construction, feature ranking, multivariate feature selection, efficient search methods, and feature validity assessment methods.","title":"An introduction to variable and feature selection","venue":"Journal of Machine Learning Research","year":2003,"__v":0,"citationCount":3396,"parents":{"00686a4c-9370-453a-a25e-6f8415bb3dcb":3.225806451612903,"0781e713-d8ca-4f62-89e8-3047b77dd6e6":12.903225806451612,"15c30ca5-6af6-4acf-b8c5-f2c0e18e6ad8":3.225806451612903,"19d8e565-399d-47a8-bd30-8ff4fe857892":6.451612903225806,"1f684a47-9d17-43a2-93fd-fc04170ee56b":0,"2bd9968a-1e0b-4a11-85a2-19edcf0ee77d":3.225806451612903,"3b4ee100-c0b9-46a4-902b-b8190ef436e8":6.451612903225806,"3fff50e3-6a11-415b-8c8d-6f2c651f658d":0,"4335d1c6-7731-4208-a669-64a932d7805e":16.129032258064516,"4419a7b8-4585-42ab-8713-d28969940448":3.225806451612903,"46c9b8ec-b728-4901-83da-a6e7d4bee165":6.451612903225806,"4746dd3a-008d-4529-be20-578d0f90408c":16.129032258064516,"48a90b30-c40f-40a8-aea4-c5c59b6c611f":0,"4c3fd4d5-c23d-4a24-84cd-21d45208941e":3.225806451612903,"5f8f7c01-a1b8-4f84-b75f-e06768f1ddce":16.129032258064516,"685b313d-8a77-481e-9456-e405a1d29549":3.225806451612903,"69530d71-f2ba-42b6-97dd-42a71316f6a4":0,"69df0789-a06f-4166-9c34-93047de2673d":0,"6c2fee35-a596-416a-bd8a-a7966324f71e":0,"80f32ec0-5100-407e-9e42-a6710b921397":6.451612903225806,"8f72a5f3-5ae7-474a-a85c-7142eba278cc":9.67741935483871,"95fdc823-57bc-4e49-8e5b-8fac0c4cfb7f":9.67741935483871,"967012b4-dd43-4a03-adbd-46cace52c671":3.225806451612903,"9981fac3-aca8-42ce-827d-453ed01176a0":3.225806451612903,"9fa61eb1-0984-4492-955a-4f7aedbdc368":19.35483870967742,"bdd8b9ba-232e-42ed-9fcb-4f57c6f4efba":12.903225806451612,"ce028c76-6040-4f87-b8e7-d6741ce9d1c4":0,"d99d5225-5b3d-406d-9da1-96223bd50daa":0,"df328bfc-4d7e-4aba-b171-0eea8ecdd146":0,"f006e236-59ad-4647-a59f-4f46dc2c85be":0,"fb5dc6a4-869b-42e4-bf81-1ddaff7cc9f7":16.129032258064516},"keyword":{"00686a4c-9370-453a-a25e-6f8415bb3dcb":10.093650793650793,"0781e713-d8ca-4f62-89e8-3047b77dd6e6":9.56084656084656,"15c30ca5-6af6-4acf-b8c5-f2c0e18e6ad8":7.569047619047619,"19d8e565-399d-47a8-bd30-8ff4fe857892":7.551984126984127,"1f684a47-9d17-43a2-93fd-fc04170ee56b":10.692857142857145,"2bd9968a-1e0b-4a11-85a2-19edcf0ee77d":9.64857142857143,"3b4ee100-c0b9-46a4-902b-b8190ef436e8":11.130000000000003,"3fff50e3-6a11-415b-8c8d-6f2c651f658d":10.296031746031744,"4335d1c6-7731-4208-a669-64a932d7805e":10.469047619047618,"4419a7b8-4585-42ab-8713-d28969940448":9.61047619047619,"46c9b8ec-b728-4901-83da-a6e7d4bee165":9.802645502645504,"4746dd3a-008d-4529-be20-578d0f90408c":12.453968253968256,"48a90b30-c40f-40a8-aea4-c5c59b6c611f":11.498809523809523,"4c3fd4d5-c23d-4a24-84cd-21d45208941e":10.928571428571429,"5f8f7c01-a1b8-4f84-b75f-e06768f1ddce":8.879126984126984,"685b313d-8a77-481e-9456-e405a1d29549":10.173544973544972,"69530d71-f2ba-42b6-97dd-42a71316f6a4":0,"69df0789-a06f-4166-9c34-93047de2673d":9.503968253968255,"6c2fee35-a596-416a-bd8a-a7966324f71e":9.341402116402115,"80f32ec0-5100-407e-9e42-a6710b921397":10.684920634920635,"8f72a5f3-5ae7-474a-a85c-7142eba278cc":9.433862433862432,"95fdc823-57bc-4e49-8e5b-8fac0c4cfb7f":10.709523809523812,"967012b4-dd43-4a03-adbd-46cace52c671":10.30904761904762,"9981fac3-aca8-42ce-827d-453ed01176a0":9.811507936507937,"9fa61eb1-0984-4492-955a-4f7aedbdc368":9.195238095238096,"bdd8b9ba-232e-42ed-9fcb-4f57c6f4efba":10.33835978835979,"ce028c76-6040-4f87-b8e7-d6741ce9d1c4":10.83015873015873,"d99d5225-5b3d-406d-9da1-96223bd50daa":8.7984126984127,"df328bfc-4d7e-4aba-b171-0eea8ecdd146":11.57281746031746,"f006e236-59ad-4647-a59f-4f46dc2c85be":11.680357142857142,"fb5dc6a4-869b-42e4-bf81-1ddaff7cc9f7":11.326984126984128},"topic":["featur","variabl","select","provid","process"],"offsprings":[]},"5002dd27-9ce6-4abb-a3d0-2ac112f58c37":{"authors":["Sanjay Ghemawat","Howard Gobioff","Shun-Tak Leung"],"references":[],"_id":"5002dd27-9ce6-4abb-a3d0-2ac112f58c37","abstract":"We have designed and implemented the Google File System, a scalable distributed file system for large distributed data-intensive applications. It provides fault tolerance while running on inexpensive commodity hardware, and it delivers high aggregate performance to a large number of clients. While sharing many of the same goals as previous distributed file systems, our design has been driven by observations of our application workloads and technological environment, both current and anticipated, that reflect a marked departure from some earlier file system assumptions. This has led us to reexamine traditional choices and explore radically different design points. The file system has successfully met our storage needs. It is widely deployed within Google as the storage platform for the generation and processing of data used by our service as well as research and development efforts that require large data sets. The largest cluster to date provides hundreds of terabytes of storage across thousands of disks on over a thousand machines, and it is concurrently accessed by hundreds of clients. In this paper, we present file system interface extensions designed to support distributed applications, discuss many aspects of our design, and report measurements from both micro-benchmarks and real world use.","title":"The Google file system","venue":"symposium on operating systems principles","year":2003,"__v":0,"citationCount":1985,"parents":{"424dc19d-6ea3-4167-a3c9-86af30ccb38a":28.57142857142857,"78001675-2215-4b4e-8a92-cd30f6409d70":14.285714285714285,"7853ec59-161c-4a18-a36f-1fa4f3a97a86":14.285714285714285,"7dfaeb99-65b2-4dc1-b03e-68489b29fb10":14.285714285714285,"8ce5aa42-c9f7-4e6b-87cd-a4f2e13b4aa8":14.285714285714285,"b4489ce3-343e-4540-a074-baccb5207bce":0,"f1b8a32b-2629-476b-a0fe-07bd782d141c":0},"keyword":{"424dc19d-6ea3-4167-a3c9-86af30ccb38a":10.976931216931217,"78001675-2215-4b4e-8a92-cd30f6409d70":11.20835978835979,"7853ec59-161c-4a18-a36f-1fa4f3a97a86":10.692645502645503,"7dfaeb99-65b2-4dc1-b03e-68489b29fb10":0,"8ce5aa42-c9f7-4e6b-87cd-a4f2e13b4aa8":11.461878306878306,"b4489ce3-343e-4540-a074-baccb5207bce":11.572037037037035,"f1b8a32b-2629-476b-a0fe-07bd782d141c":10.368518518518517},"topic":["system","file","design","distribut","storag"],"groups":[{"authors":["Chandramohan A. Thekkath","Timothy Mann","Edward K. Lee"],"references":["0bb4c0b4-339d-48f5-8c75-2c8bc50c7ab7","265a4f8f-2a58-497c-8c6e-9f6a97d5720a","279ea9a1-32e3-4aa0-80c6-f81901fb3f9a","2a089d0b-caec-4712-9220-47ff2e36e524","2b1c8047-4431-4278-a667-fe4cc367dc2e","32b6ee76-33bb-414d-b7e2-6fc7a0f3b457","3dfefac8-c55a-4653-808b-2759aa8a550e","42c7ce0d-a7f5-472d-8957-79e15a9288fb","5ef1d3b1-f564-4b7c-b518-9cc8a768c9dd","6b2818f1-e878-45fb-995f-68bf60645a3f","78001675-2215-4b4e-8a92-cd30f6409d70","78a9d157-caa2-4792-9638-897c79c84bb5","81ad8d98-8e9c-492c-9f0e-dc4b1e6d3d8b","a2805e9e-8eb2-4365-b639-b428869a4b0b","a36add49-324e-46e2-8377-d32d402e2d48","c918b921-6dea-450f-a28e-ca2b0750595a","d6861f11-00db-450e-a035-d8a25c4ebcab","d9c271a7-a67d-4fb4-940d-012282c83b79","ea761bd4-8d9d-42b1-a41b-1f647d6b8606","f1b8a32b-2629-476b-a0fe-07bd782d141c"],"_id":"424dc19d-6ea3-4167-a3c9-86af30ccb38a","abstract":"The ideal distributed file system would provide all its users with coherent, shared access to the same set of files, yet would be arbitrarily scalable to provide more storage space and higher performance to a growing user community. It would be highly available in spite of component failures. It would require minimal human administration, and administration would not become more complex as more components were added. Frangipani is a new file system that approximates this ideal, yet was relatively easy to build because of its two-layer structure. The lower layer is Petal (described in an earlier paper), a distributed storage service that provides incrementally scalable, highly available, automatically managed virtual disks. In the upper layer, multiple machines run the same Frangipani file system code on top of a shared Petal virtual disk, using a distributed lock service to ensure coherence. Frangipani is meant to run in a cluster of machines that are under a common administration and can communicate securely. Thus the machines trust one another and the shared virtual disk approach is practical. Of course, a Frangipani file system can be exported to untrusted machines using ordinary network file access protocols. We have implemented Frangipani on a collection of Alphas running DIGITAL Unix 4.0. Initial measurements indicate that Frangipani has excellent single-server performance and scales well as servers are added.","title":"Frangipani: a scalable distributed file system","venue":"symposium on operating systems principles","year":1997,"__v":0,"citationCount":185}],"offsprings":["e537d143-155e-4ca0-8ae8-66b777a77fea"]},"50252efa-a843-4cc6-a591-22f527ee3d6c":{"authors":["Herbert Bay","Andreas Ess","Tinne Tuytelaars","Luc J. Van Gool"],"references":["6018a516-8149-4bce-bc33-5449d86e58c2","60285266-7da2-474e-b05a-b380c836f665","6c38b3b4-7562-493d-a40c-fe70abf039a7","8d8e7d51-3223-4776-bf6a-40306774b8a1","b944f77f-113b-4a02-ae5e-d4a124b8fd5b","e649a9fd-f6d9-4aac-b428-29b82c20a484","f225f439-4389-4312-a503-f8c1b0aa02de","ffa029cf-7240-4723-8339-51fac57f9f28"],"_id":"50252efa-a843-4cc6-a591-22f527ee3d6c","abstract":"This article presents a novel scale- and rotation-invariant detector and descriptor, coined SURF (Speeded-Up Robust Features). SURF approximates or even outperforms previously proposed schemes with respect to repeatability, distinctiveness, and robustness, yet can be computed and compared much faster. This is achieved by relying on integral images for image convolutions; by building on the strengths of the leading existing detectors and descriptors (specifically, using a Hessian matrix-based measure for the detector, and a distribution-based descriptor); and by simplifying these methods to the essential. This leads to a combination of novel detection, description, and matching steps. The paper encompasses a detailed description of the detector and descriptor and then explores the effects of the most important parameters. We conclude the article with SURF's application to two challenging, yet converse goals: camera calibration as a special case of image registration, and object recognition. Our experiments underline SURF's usefulness in a broad range of topics in computer vision.","title":"Speeded-Up Robust Features (SURF)","venue":"Computer Vision and Image Understanding","year":2008,"__v":0,"citationCount":3151,"parents":{"0b86c956-29dc-4979-b046-f2ec971d8ac8":12.903225806451612,"21c67dad-f0eb-4479-afe7-fdf4a71eef01":35.483870967741936,"2d6c9f60-ea78-44a8-b5f9-6964575dd196":3.225806451612903,"2fa58737-dfec-48e8-a1d5-dc96c510d44f":12.903225806451612,"34758e0a-3def-447b-9c5e-e82a206426b5":0,"36800655-b2ff-4eb7-9070-c6be304c4baa":0,"472cc3e6-8149-41ef-b4c4-fa9e6a60b66f":6.451612903225806,"473cf1a4-9f42-4e6d-b34f-77787f329079":3.225806451612903,"497e3634-6d30-49d5-b10e-a84036394e14":0,"509e1ae2-768b-4417-bebe-d90cf1e0fdae":9.67741935483871,"5f84f09f-7644-447c-89e1-8dc9ee334197":9.67741935483871,"6018a516-8149-4bce-bc33-5449d86e58c2":0,"60285266-7da2-474e-b05a-b380c836f665":9.67741935483871,"62d0a064-3808-4bc0-99bd-f007359ce651":0,"63e5ce6e-5850-45a2-8fbc-6b459352c516":9.67741935483871,"68df2442-9f08-4dc4-80ef-fcf5fede8332":3.225806451612903,"6c38b3b4-7562-493d-a40c-fe70abf039a7":19.35483870967742,"6fe37c18-8dc5-4baa-b6e0-5546353907bb":35.483870967741936,"774c108a-4002-4123-861f-edd3b7ccb0e7":3.225806451612903,"8d8e7d51-3223-4776-bf6a-40306774b8a1":41.935483870967744,"9f5f1500-0df7-4675-8290-b47979bcad38":12.903225806451612,"a3426b1b-ac85-47a0-85f8-c2649ad6c8dc":6.451612903225806,"a5254ae0-1ce1-4390-b9f8-8d5a3dcb1e62":22.58064516129032,"b944f77f-113b-4a02-ae5e-d4a124b8fd5b":19.35483870967742,"c455fb04-4566-4648-ad6f-3cf2245e507c":12.903225806451612,"dda32e99-40c9-4d5f-8982-51e4b1dca885":0,"e649a9fd-f6d9-4aac-b428-29b82c20a484":3.225806451612903,"ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d":16.129032258064516,"f225f439-4389-4312-a503-f8c1b0aa02de":67.74193548387096,"fa02eaed-b311-4f13-9b98-cc0617aafae2":3.225806451612903,"ffa029cf-7240-4723-8339-51fac57f9f28":29.03225806451613},"keyword":{"0b86c956-29dc-4979-b046-f2ec971d8ac8":10.32494708994709,"21c67dad-f0eb-4479-afe7-fdf4a71eef01":8.058412698412697,"2d6c9f60-ea78-44a8-b5f9-6964575dd196":9.804444444444442,"2fa58737-dfec-48e8-a1d5-dc96c510d44f":8.338888888888889,"34758e0a-3def-447b-9c5e-e82a206426b5":0,"36800655-b2ff-4eb7-9070-c6be304c4baa":11.573888888888888,"472cc3e6-8149-41ef-b4c4-fa9e6a60b66f":9.167592592592595,"473cf1a4-9f42-4e6d-b34f-77787f329079":9.864999999999998,"497e3634-6d30-49d5-b10e-a84036394e14":10.536097883597883,"509e1ae2-768b-4417-bebe-d90cf1e0fdae":9.493333333333332,"5f84f09f-7644-447c-89e1-8dc9ee334197":8.304563492063492,"6018a516-8149-4bce-bc33-5449d86e58c2":9.394722222222223,"60285266-7da2-474e-b05a-b380c836f665":9.577777777777778,"62d0a064-3808-4bc0-99bd-f007359ce651":9.292142857142856,"63e5ce6e-5850-45a2-8fbc-6b459352c516":8.3495670995671,"68df2442-9f08-4dc4-80ef-fcf5fede8332":8.681060606060607,"6c38b3b4-7562-493d-a40c-fe70abf039a7":10.563888888888888,"6fe37c18-8dc5-4baa-b6e0-5546353907bb":11.076468253968251,"774c108a-4002-4123-861f-edd3b7ccb0e7":9.995833333333334,"8d8e7d51-3223-4776-bf6a-40306774b8a1":12.339246031746029,"9f5f1500-0df7-4675-8290-b47979bcad38":9.923333333333334,"a3426b1b-ac85-47a0-85f8-c2649ad6c8dc":9.679629629629627,"a5254ae0-1ce1-4390-b9f8-8d5a3dcb1e62":10.843333333333332,"b944f77f-113b-4a02-ae5e-d4a124b8fd5b":10.433134920634922,"c455fb04-4566-4648-ad6f-3cf2245e507c":8.238968253968254,"dda32e99-40c9-4d5f-8982-51e4b1dca885":8.603412698412699,"e649a9fd-f6d9-4aac-b428-29b82c20a484":8.951111111111109,"ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d":9.04888888888889,"f225f439-4389-4312-a503-f8c1b0aa02de":11.6215873015873,"fa02eaed-b311-4f13-9b98-cc0617aafae2":9.538174603174603,"ffa029cf-7240-4723-8339-51fac57f9f28":8.59222222222222},"topic":["surf","detector","descriptor","imag","robust"],"groups":[{"authors":["Herbert Bay","Tinne Tuytelaars","Luc J. Van Gool"],"references":["0b86c956-29dc-4979-b046-f2ec971d8ac8","21c67dad-f0eb-4479-afe7-fdf4a71eef01","2d6c9f60-ea78-44a8-b5f9-6964575dd196","2fa58737-dfec-48e8-a1d5-dc96c510d44f","34758e0a-3def-447b-9c5e-e82a206426b5","36800655-b2ff-4eb7-9070-c6be304c4baa","3c1e64c0-8e48-45d3-96e8-f2c3252b4b83","472cc3e6-8149-41ef-b4c4-fa9e6a60b66f","473cf1a4-9f42-4e6d-b34f-77787f329079","509e1ae2-768b-4417-bebe-d90cf1e0fdae","5f84f09f-7644-447c-89e1-8dc9ee334197","6018a516-8149-4bce-bc33-5449d86e58c2","60285266-7da2-474e-b05a-b380c836f665","6fe37c18-8dc5-4baa-b6e0-5546353907bb","774c108a-4002-4123-861f-edd3b7ccb0e7","7ab7b36d-baae-4b21-89fc-69389fcabc44","8d8e7d51-3223-4776-bf6a-40306774b8a1","9f5f1500-0df7-4675-8290-b47979bcad38","a5254ae0-1ce1-4390-b9f8-8d5a3dcb1e62","b944f77f-113b-4a02-ae5e-d4a124b8fd5b","e649a9fd-f6d9-4aac-b428-29b82c20a484","ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d","ffa029cf-7240-4723-8339-51fac57f9f28"],"_id":"f225f439-4389-4312-a503-f8c1b0aa02de","abstract":"In this paper, we present a novel scale- and rotation-invariant interest point detector and descriptor, coined SURF (Speeded Up Robust Features). It approximates or even outperforms previously proposed schemes with respect to repeatability, distinctiveness, and robustness, yet can be computed and compared much faster.#R##N##R##N#This is achieved by relying on integral images for image convolutions; by building on the strengths of the leading existing detectors and descriptors (in casu, using a Hessian matrix-based measure for the detector, and a distribution-based descriptor); and by simplifying these methods to the essential. This leads to a combination of novel detection, description, and matching steps. The paper presents experimental results on a standard evaluation set, as well as on imagery obtained in the context of a real-life object recognition application. Both show SURF's strong performance.","title":"SURF: speeded up robust features","venue":"european conference on computer vision","year":2006,"__v":0,"citationCount":3617},{"authors":["Krystian Mikolajczyk","Tinne Tuytelaars","C. Schmid","Andrew Zisserman","Jir i Matas","Frederik Schaffalitzky","Timor Kadir","L. Van Gool"],"references":["085204a8-62ca-4a3c-8098-4f75d62d1ae4","0aae4e44-abdb-4948-9462-61f6e52162ba","0bc5747a-2caf-4996-a55b-6ec5e7273636","0d287faa-99bb-42df-98a7-24fcd601b9a4","1dc84769-ff4c-4de6-a1c9-8d3af9299701","21a8e8fd-0172-4e9a-8474-7024eb0bf979","2beaa150-6293-4f05-ba04-8e001993e766","2d6c9f60-ea78-44a8-b5f9-6964575dd196","2dfac644-329c-46f4-a508-749ccb2d7c85","34758e0a-3def-447b-9c5e-e82a206426b5","4e58f9b5-8562-4f17-830f-f055449867fc","50212652-4999-4f13-82d6-a37eb2862a73","509e1ae2-768b-4417-bebe-d90cf1e0fdae","5149d3c0-5ac9-47ba-9fb0-3d2ef757b0e8","5172d9aa-41cc-40dc-949a-cde3d9f05f31","5f1992df-975f-49e7-bd88-aee0740317cf","6018a516-8149-4bce-bc33-5449d86e58c2","60285266-7da2-474e-b05a-b380c836f665","6842d04f-2b92-4298-aee8-92babc53f7c4","6fe37c18-8dc5-4baa-b6e0-5546353907bb","7283fa2b-1f6a-4138-a3da-4bf69809a1a9","776d4b4d-d49f-439f-9db5-7c5c3ce68db3","7ab7b36d-baae-4b21-89fc-69389fcabc44","8ab773a4-49b4-4755-a070-4ab1b1710690","8d8e7d51-3223-4776-bf6a-40306774b8a1","9b480902-c7fd-4d9f-ac9c-3c2fe3aa9c2c","a0be9da4-c423-4f87-a387-822fe304aa03","ab7b7857-e48d-4b94-8bfa-bc9ed61d5853","b25e7392-e9f9-4600-8ab0-a76252f1633a","b3e60214-b54c-4e8f-9315-a6975c760f4c","b944f77f-113b-4a02-ae5e-d4a124b8fd5b","b9e63aeb-aa46-40a0-9b06-01e2270cea70","c455fb04-4566-4648-ad6f-3cf2245e507c","cf9198ae-7e03-401f-a52b-94689ba30a36","ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d","fc9638b8-572c-4b23-aab2-92e2dd3b79f8","ffa029cf-7240-4723-8339-51fac57f9f28"],"_id":"21c67dad-f0eb-4479-afe7-fdf4a71eef01","abstract":"The paper gives a snapshot of the state of the art in affine covariant region detectors, and compares their performance on a set of test images under varying imaging conditions. Six types of detectors are included: detectors based on affine normalization around Harris (Mikolajczyk and Schmid, 2002; Schaffalitzky and Zisserman, 2002) and Hessian points (Mikolajczyk and Schmid, 2002), a detector of `maximally stable extremal regions', proposed by Matas et al. (2002); an edge-based region detector (Tuytelaars and Van Gool, 1999) and a detector based on intensity extrema (Tuytelaars and Van Gool, 2000), and a detector of `salient regions', proposed by Kadir, Zisserman and Brady (2004). The performance is measured against changes in viewpoint, scale, illumination, defocus and image compression.#R##N##R##N#The objective of this paper is also to establish a reference test set of images and performance software, so that future detectors can be evaluated in the same framework.","title":"A Comparison of Affine Region Detectors","venue":"International Journal of Computer Vision","year":2005,"__v":0,"citationCount":1317},{"authors":["Krystian Mikolajczyk","Cordelia Schmid"],"references":["0d287faa-99bb-42df-98a7-24fcd601b9a4","1c016f4a-20fb-44b5-84ad-96c10cb8e61b","2beaa150-6293-4f05-ba04-8e001993e766","2d6c9f60-ea78-44a8-b5f9-6964575dd196","33711daf-2a44-4f42-8466-c7801f29959b","34758e0a-3def-447b-9c5e-e82a206426b5","36800655-b2ff-4eb7-9070-c6be304c4baa","457f15ab-c8e1-461d-b768-e044d88f1917","473cf1a4-9f42-4e6d-b34f-77787f329079","509e1ae2-768b-4417-bebe-d90cf1e0fdae","5149d3c0-5ac9-47ba-9fb0-3d2ef757b0e8","58d0cc4d-9deb-4188-98d2-7ca475ca7221","5f1992df-975f-49e7-bd88-aee0740317cf","5f84f09f-7644-447c-89e1-8dc9ee334197","6018a516-8149-4bce-bc33-5449d86e58c2","60285266-7da2-474e-b05a-b380c836f665","643913d9-b72a-4ee3-9c3f-63c1249e9a3c","64ea9dde-3bd8-4868-9c0b-f15556e67ad5","7283fa2b-1f6a-4138-a3da-4bf69809a1a9","79050acb-3012-4d4b-af60-66040a28043d","7a9f04e3-2883-4204-8fb3-7db1ce5ddc09","7ab7b36d-baae-4b21-89fc-69389fcabc44","899de8c7-9cd9-4dd5-82f1-ad9acb801f8e","8ab773a4-49b4-4755-a070-4ab1b1710690","a00704dc-a2fa-4267-b7a6-427167d99521","a0be9da4-c423-4f87-a387-822fe304aa03","a72802aa-e1ab-4f52-bae8-703d68f9b220","b3e60214-b54c-4e8f-9315-a6975c760f4c","c591c440-b19b-4d7b-b067-cd8c366b7d6d","cc6caca8-1564-4cf8-88a3-f0733c46e0dd","d4e9734a-a4e7-4c19-be20-c32f55d4d26f","e86ce68d-0d77-4f44-a212-518e7d8f394b","eeb31134-612a-42bf-a6c2-8b7d7c17e694","ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d"],"_id":"ffa029cf-7240-4723-8339-51fac57f9f28","abstract":"In this paper we propose a novel approach for detecting interest points invariant to scale and affine transformations. Our scale and affine invariant detectors are based on the following recent results: (1) Interest points extracted with the Harris detector can be adapted to affine transformations and give repeatable results (geometrically stable). (2) The characteristic scale of a local structure is indicated by a local extremum over scale of normalized derivatives (the Laplacian). (3) The affine shape of a point neighborhood is estimated based on the second moment matrix.#R##N##R##N#Our scale invariant detector computes a multi-scale representation for the Harris interest point detector and then selects points at which a local measure (the Laplacian) is maximal over scales. This provides a set of distinctive points which are invariant to scale, rotation and translation as well as robust to illumination changes and limited changes of viewpoint. The characteristic scale determines a scale invariant region for each point. We extend the scale invariant detector to affine invariance by estimating the affine shape of a point neighborhood. An iterative algorithm modifies location, scale and neighborhood of each point and converges to affine invariant points. This method can deal with significant affine transformations including large scale changes. The characteristic scale and the affine shape of neighborhood determine an affine invariant region for each point.#R##N##R##N#We present a comparative evaluation of different detectors and show that our approach provides better results than existing methods. The performance of our detector is also confirmed by excellent matching resultss the image is described by a set of scale/affine invariant descriptors computed on the regions associated with our points.","title":"Scale & Affine Invariant Interest Point Detectors","venue":"International Journal of Computer Vision","year":2004,"__v":0,"citationCount":1525},{"authors":["Krystian Mikolajczyk","Cordelia Schmid"],"references":["00a4e16f-6b65-4ad2-bedc-b19d9cbc2cfe","09346dc3-f4d0-43a4-8f0b-27e02bcd336e","0aae4e44-abdb-4948-9462-61f6e52162ba","0d287faa-99bb-42df-98a7-24fcd601b9a4","19195bc1-7aff-4dd3-91cc-25402c343a19","21a8e8fd-0172-4e9a-8474-7024eb0bf979","21c67dad-f0eb-4479-afe7-fdf4a71eef01","2d6c9f60-ea78-44a8-b5f9-6964575dd196","33711daf-2a44-4f42-8466-c7801f29959b","34758e0a-3def-447b-9c5e-e82a206426b5","36800655-b2ff-4eb7-9070-c6be304c4baa","37031566-2033-44cb-a87e-91a9bb37996f","3b744649-d7a0-46c3-b242-9e0060d8ecfa","4e58f9b5-8562-4f17-830f-f055449867fc","509e1ae2-768b-4417-bebe-d90cf1e0fdae","5149d3c0-5ac9-47ba-9fb0-3d2ef757b0e8","568f1994-f91e-413e-92fd-87dbbb9642a8","5f1992df-975f-49e7-bd88-aee0740317cf","6018a516-8149-4bce-bc33-5449d86e58c2","60285266-7da2-474e-b05a-b380c836f665","608a581a-0e03-435a-9067-c0e0982567af","683dd26d-5c59-4feb-9fbd-2bcf3cc1942f","6fe37c18-8dc5-4baa-b6e0-5546353907bb","72c27d5a-23c5-4d1b-a000-280b87b368ee","7ab7b36d-baae-4b21-89fc-69389fcabc44","853b29ea-c6d1-497e-bad3-b608d370e7e2","a5254ae0-1ce1-4390-b9f8-8d5a3dcb1e62","a8c6ead3-d61a-4f6a-a702-08743f19eec9","b4685927-0ad9-466b-b2c6-2e1764475726","b592576f-ff29-4a68-9b2f-8a8ad02e9c70","b944f77f-113b-4a02-ae5e-d4a124b8fd5b","c455fb04-4566-4648-ad6f-3cf2245e507c","e2204e92-e6dc-4884-9bbc-200029491fc7","e927dff1-6ed4-45fd-8852-eb804e11e665","ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d","fc9638b8-572c-4b23-aab2-92e2dd3b79f8","ffa029cf-7240-4723-8339-51fac57f9f28"],"_id":"8d8e7d51-3223-4776-bf6a-40306774b8a1","abstract":"In this paper, we compare the performance of descriptors computed for local interest regions, as, for example, extracted by the Harris-Affine detector [Mikolajczyk, K and Schmid, C, 2004]. Many different descriptors have been proposed in the literature. It is unclear which descriptors are more appropriate and how their performance depends on the interest region detector. The descriptors should be distinctive and at the same time robust to changes in viewing conditions as well as to errors of the detector. Our evaluation uses as criterion recall with respect to precision and is carried out for different image transformations. We compare shape context [Belongie, S, et al., April 2002], steerable filters [Freeman, W and Adelson, E, Setp. 1991], PCA-SIFT [Ke, Y and Sukthankar, R, 2004], differential invariants [Koenderink, J and van Doorn, A, 1987], spin images [Lazebnik, S, et al., 2003], SIFT [Lowe, D. G., 1999], complex filters [Schaffalitzky, F and Zisserman, A, 2002], moment invariants [Van Gool, L, et al., 1996], and cross-correlation for different types of interest regions. We also propose an extension of the SIFT descriptor and show that it outperforms the original method. Furthermore, we observe that the ranking of the descriptors is mostly independent of the interest region detector and that the SIFT-based descriptors perform best. Moments and steerable filters show the best performance among the low dimensional descriptors.","title":"A performance evaluation of local descriptors","venue":"IEEE Transactions on Pattern Analysis and Machine Intelligence","year":2005,"__v":0,"citationCount":2762},{"authors":["Yan Ke","Rahul Sukthankar"],"references":["28005624-c0e8-4c62-b585-6e362c3dc8d5","34758e0a-3def-447b-9c5e-e82a206426b5","36800655-b2ff-4eb7-9070-c6be304c4baa","509e1ae2-768b-4417-bebe-d90cf1e0fdae","6018a516-8149-4bce-bc33-5449d86e58c2","608a581a-0e03-435a-9067-c0e0982567af","6fe37c18-8dc5-4baa-b6e0-5546353907bb","7ab7b36d-baae-4b21-89fc-69389fcabc44","aec2ffaf-e691-4884-9304-7d7e14733b2e","b944f77f-113b-4a02-ae5e-d4a124b8fd5b","c455fb04-4566-4648-ad6f-3cf2245e507c","d7b1fba1-b5f8-4377-88a8-d2fc69f723b7"],"_id":"a5254ae0-1ce1-4390-b9f8-8d5a3dcb1e62","abstract":"Stable local feature detection and representation is a fundamental component of many image registration and object recognition algorithms. Mikolajczyk and Schmid (June 2003) recently evaluated a variety of approaches and identified the SIFT [D. G. Lowe, 1999] algorithm as being the most resistant to common image deformations. This paper examines (and improves upon) the local image descriptor used by SIFT. Like SIFT, our descriptors encode the salient aspects of the image gradient in the feature point's neighborhood; however, instead of using SIFT's smoothed weighted histograms, we apply principal components analysis (PCA) to the normalized gradient patch. Our experiments demonstrate that the PCA-based local descriptors are more distinctive, more robust to image deformations, and more compact than the standard SIFT representation. We also present results showing that using these descriptors in an image retrieval application results in increased accuracy and faster matching.","title":"PCA-SIFT: a more distinctive representation for local image descriptors","venue":"computer vision and pattern recognition","year":2004,"__v":0,"citationCount":1138},{"authors":["Krystian Mikolajczyk","Cordelia Schmid"],"references":["00a4e16f-6b65-4ad2-bedc-b19d9cbc2cfe","09346dc3-f4d0-43a4-8f0b-27e02bcd336e","0aae4e44-abdb-4948-9462-61f6e52162ba","0d287faa-99bb-42df-98a7-24fcd601b9a4","19195bc1-7aff-4dd3-91cc-25402c343a19","21a8e8fd-0172-4e9a-8474-7024eb0bf979","21c67dad-f0eb-4479-afe7-fdf4a71eef01","2d6c9f60-ea78-44a8-b5f9-6964575dd196","33711daf-2a44-4f42-8466-c7801f29959b","34758e0a-3def-447b-9c5e-e82a206426b5","36800655-b2ff-4eb7-9070-c6be304c4baa","509e1ae2-768b-4417-bebe-d90cf1e0fdae","5149d3c0-5ac9-47ba-9fb0-3d2ef757b0e8","5f1992df-975f-49e7-bd88-aee0740317cf","6018a516-8149-4bce-bc33-5449d86e58c2","60285266-7da2-474e-b05a-b380c836f665","608a581a-0e03-435a-9067-c0e0982567af","683dd26d-5c59-4feb-9fbd-2bcf3cc1942f","853b29ea-c6d1-497e-bad3-b608d370e7e2","a5254ae0-1ce1-4390-b9f8-8d5a3dcb1e62","b4685927-0ad9-466b-b2c6-2e1764475726","b592576f-ff29-4a68-9b2f-8a8ad02e9c70","b944f77f-113b-4a02-ae5e-d4a124b8fd5b","c455fb04-4566-4648-ad6f-3cf2245e507c","e2204e92-e6dc-4884-9bbc-200029491fc7","e927dff1-6ed4-45fd-8852-eb804e11e665","ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d","fc9638b8-572c-4b23-aab2-92e2dd3b79f8"],"_id":"6fe37c18-8dc5-4baa-b6e0-5546353907bb","abstract":"In this paper we compare the performance of interest point descriptors. Many different descriptors have been proposed in the literature. However, it is unclear which descriptors are more appropriate and how their performance depends on the interest point detector. The descriptors should be distinctive and at the same time robust to changes in viewing conditions as well as to errors of the point detector. Our evaluation uses as criterion detection rate with respect to false positive rate and is carried out for different image transformations. We compare SIFT descriptors (Lowe, 1999), steerable filters (Freeman and Adelson, 1991), differential invariants (Koenderink ad van Doorn, 1987), complex filters (Schaffalitzky and Zisserman, 2002), moment invariants (Van Gool et al., 1996) and cross-correlation for different types of interest points. In this evaluation, we observe that the ranking of the descriptors does not depend on the point detector and that SIFT descriptors perform best. Steerable filters come second ; they can be considered a good choice given the low dimensionality.","title":"A performance evaluation of local descriptors","venue":"computer vision and pattern recognition","year":2003,"__v":0,"citationCount":683}],"offsprings":[]},"56f4b72a-ec39-47ac-8220-899296e7fb18":{"authors":["Peter N. Belhumeur","João Pedro Hespanha","David J. Kriegman"],"references":[],"_id":"56f4b72a-ec39-47ac-8220-899296e7fb18","abstract":"We develop a face recognition algorithm which is insensitive to large variation in lighting direction and facial expression. Taking a pattern classification approach, we consider each pixel in an image as a coordinate in a high-dimensional space. We take advantage of the observation that the images of a particular face, under varying illumination but fixed pose, lie in a 3D linear subspace of the high dimensional image space-if the face is a Lambertian surface without shadowing. However, since faces are not truly Lambertian surfaces and do indeed produce self-shadowing, images will deviate from this linear subspace. Rather than explicitly modeling this deviation, we linearly project the image into a subspace in a manner which discounts those regions of the face with large deviation. Our projection method is based on Fisher's linear discriminant and produces well separated classes in a low-dimensional subspace, even under severe variation in lighting and facial expressions. The eigenface technique, another method based on linearly projecting the image space to a low dimensional subspace, has similar computational requirements. Yet, extensive experimental results demonstrate that the proposed \"Fisherface\" method has error rates that are lower than those of the eigenface technique for tests on the Harvard and Yale face databases.","title":"Eigenfaces vs. Fisherfaces: recognition using class specific linear projection","venue":"IEEE Transactions on Pattern Analysis and Machine Intelligence","year":1997,"__v":0,"citationCount":4831,"parents":{"0838d523-ab76-4dcb-8516-b1432251add2":0,"0bc987d1-12c1-4a35-8eaf-e8c9d1a315f0":11.76470588235294,"15eb4587-2636-4c7d-9f1f-8ad6fe903165":0,"22722d7c-0428-484f-85fa-ce3a679c0340":5.88235294117647,"348e218b-7058-451c-b808-5c25010add03":5.88235294117647,"3b3d7569-08b1-4017-9910-2a017a00e43e":0,"5de25331-b39f-4667-a074-b30c99f9a720":5.88235294117647,"5ebbd1f5-dfe5-4eec-9883-b8b5efea366c":0,"5f9f2346-d1e3-4716-a8af-8c14f1490e00":17.647058823529413,"8dee44f9-110a-4575-8be1-5b98015f0456":94.11764705882352,"94a0b002-578e-4581-ad1d-8fc52a7052ea":0,"966c87d0-a518-4641-844a-37c79fa1f8ab":5.88235294117647,"b85ac095-a9f2-4954-b2bf-f53fde98958c":0,"cacef546-cc48-4fb9-814f-9c12141662d8":0,"ce9c0c07-83af-4fb7-9491-38255660025c":23.52941176470588,"d42f853d-12d7-416d-8b27-c314ef563eed":0,"ef50568a-329a-42d8-bb6b-3e10f34ca75a":0},"keyword":{"0838d523-ab76-4dcb-8516-b1432251add2":9.933730158730157,"0bc987d1-12c1-4a35-8eaf-e8c9d1a315f0":8.3,"15eb4587-2636-4c7d-9f1f-8ad6fe903165":9.65047619047619,"22722d7c-0428-484f-85fa-ce3a679c0340":10.667857142857143,"348e218b-7058-451c-b808-5c25010add03":9.715476190476192,"3b3d7569-08b1-4017-9910-2a017a00e43e":9.18095238095238,"5de25331-b39f-4667-a074-b30c99f9a720":8.448015873015873,"5ebbd1f5-dfe5-4eec-9883-b8b5efea366c":10.47952380952381,"5f9f2346-d1e3-4716-a8af-8c14f1490e00":11.14642857142857,"8dee44f9-110a-4575-8be1-5b98015f0456":0,"94a0b002-578e-4581-ad1d-8fc52a7052ea":8.971031746031747,"966c87d0-a518-4641-844a-37c79fa1f8ab":9.535317460317462,"b85ac095-a9f2-4954-b2bf-f53fde98958c":0,"cacef546-cc48-4fb9-814f-9c12141662d8":0,"ce9c0c07-83af-4fb7-9491-38255660025c":9.157857142857143,"d42f853d-12d7-416d-8b27-c314ef563eed":7.680952380952379,"ef50568a-329a-42d8-bb6b-3e10f34ca75a":0},"topic":["imag","face","subspac","linear","project"],"groups":[{"authors":["Peter N. Belhumeur","João Pedro Hespanha","David J. Kriegman"],"references":["0838d523-ab76-4dcb-8516-b1432251add2","0bc987d1-12c1-4a35-8eaf-e8c9d1a315f0","15eb4587-2636-4c7d-9f1f-8ad6fe903165","22722d7c-0428-484f-85fa-ce3a679c0340","348e218b-7058-451c-b808-5c25010add03","3b3d7569-08b1-4017-9910-2a017a00e43e","56f4b72a-ec39-47ac-8220-899296e7fb18","5de25331-b39f-4667-a074-b30c99f9a720","5ebbd1f5-dfe5-4eec-9883-b8b5efea366c","5f9f2346-d1e3-4716-a8af-8c14f1490e00","94a0b002-578e-4581-ad1d-8fc52a7052ea","966c87d0-a518-4641-844a-37c79fa1f8ab","b85ac095-a9f2-4954-b2bf-f53fde98958c","cacef546-cc48-4fb9-814f-9c12141662d8","ce9c0c07-83af-4fb7-9491-38255660025c","d42f853d-12d7-416d-8b27-c314ef563eed","ef50568a-329a-42d8-bb6b-3e10f34ca75a"],"_id":"8dee44f9-110a-4575-8be1-5b98015f0456","title":"Eigenfaces vs. Fisherfaces: Recognition Using Class Specific Linear Projection","venue":"european conference on computer vision","year":1996,"abstract":"","__v":0,"citationCount":676},{"authors":["Peter N. Belhumeur","David J. Kriegman"],"references":["348e218b-7058-451c-b808-5c25010add03","56f4b72a-ec39-47ac-8220-899296e7fb18","59b7eb7b-c50c-49f5-ac10-63902b47677a","5b146739-a8f7-4b19-acb7-0370d72ff561","5ebbd1f5-dfe5-4eec-9883-b8b5efea366c","8dee44f9-110a-4575-8be1-5b98015f0456","a3257b67-d63c-4256-964c-8225a6d4ce1e","b3a4feeb-0d9c-4a10-89d3-8ca0852d04e7","c73fce0b-d7e7-45af-85e3-763d22387cbc","cacef546-cc48-4fb9-814f-9c12141662d8"],"_id":"ce9c0c07-83af-4fb7-9491-38255660025c","abstract":"The appearance of a particular object depends on both the viewpoint from which it is observed and the light sources by which it is illuminated. If the appearance of two objects is never identical for any pose or lighting conditions, then-in theory - the objects can always be distinguished or recognized. The question arises: What is the set of images of an object under all lighting conditions and pose? In this paper, we consider only the set of images of an object under variable illumination (including multiple, extended light sources and attached shadows). We prove that the set of n-pixel images of a convex object with a Lambertian reflectance function, illuminated by an arbitrary number of point light sources at infinity, forms a convex polyhedral cone in IR/sup n/ and that the dimension of this illumination cone equals the number of distinct surface normals. Furthermore, we show that the cone for a particular object can be constructed from three properly chosen images. Finally, we prove that the set of n-pixel images of an object of any shape and with an arbitrary reflectance function, seen under all possible illumination conditions, still forms a convex cone in IR/sup n/. These results immediately suggest certain approaches to object recognition. Throughout this paper, we offer results demonstrating the empirical validity of the illumination cone representation.","title":"What is the set of images of an object under all possible lighting conditions","venue":"computer vision and pattern recognition","year":1996,"__v":0,"citationCount":225}],"offsprings":["c5d73f15-467c-4824-8784-4bf66630fe94","5e8b0e8a-d687-4333-bfe9-73b4c1bebde5","7236dbb7-f0b2-4e28-bb7c-6de187c32d64","32d158dc-6f9f-426a-973b-8edc5e4c5dad"]},"57e35e32-f009-4b9b-bfb2-3747eac40b72":{"authors":["David R. Martin","Charless C. Fowlkes","Doron Tal","Jitendra Malik"],"references":[],"_id":"57e35e32-f009-4b9b-bfb2-3747eac40b72","abstract":"This paper presents a database containing 'ground truth' segmentations produced by humans for images of a wide variety of natural scenes. We define an error measure which quantifies the consistency between segmentations of differing granularities and find that different human segmentations of the same image are highly consistent. Use of this dataset is demonstrated in two applications: (1) evaluating the performance of segmentation algorithms and (2) measuring probability distributions associated with Gestalt grouping factors as well as statistics of image region properties.","title":"A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics","venue":"international conference on computer vision","year":2001,"__v":0,"citationCount":1787,"parents":{"0593b29b-c76e-4f8f-9f93-f7e8c1d42942":20,"58986749-f7f2-4c0c-a0f8-37180df48756":0,"60c8fac6-b4ce-43e1-80a7-d5fef740dc98":0,"613fab48-0df5-4599-9fe5-48b481f98548":0,"6692d3e1-f6a0-48c0-8733-7b1f72587fd0":0,"728dbd56-b64d-4655-b27c-dacba837b1e3":10,"9308c3cb-9b84-4ea4-8e6c-bbb6fb466640":10,"9438a773-c15c-4ef2-a97c-54f643ce6082":0,"b5f9f0ee-6ad7-4ea6-bf3a-a2f695b6728c":0,"ed910b44-6b41-4205-8c73-a970a9306314":0},"keyword":{"0593b29b-c76e-4f8f-9f93-f7e8c1d42942":11.122936507936508,"58986749-f7f2-4c0c-a0f8-37180df48756":10.807063492063492,"60c8fac6-b4ce-43e1-80a7-d5fef740dc98":9.925925925925926,"613fab48-0df5-4599-9fe5-48b481f98548":11.21,"6692d3e1-f6a0-48c0-8733-7b1f72587fd0":9.009126984126985,"728dbd56-b64d-4655-b27c-dacba837b1e3":11.122539682539683,"9308c3cb-9b84-4ea4-8e6c-bbb6fb466640":11.251190476190477,"9438a773-c15c-4ef2-a97c-54f643ce6082":9.757936507936508,"b5f9f0ee-6ad7-4ea6-bf3a-a2f695b6728c":10.57420634920635,"ed910b44-6b41-4205-8c73-a970a9306314":8.506507936507937},"topic":["segment","imag","measur","human","consist"],"offsprings":[]},"5a4a1b04-b36f-402c-a87f-0779098ef050":{"authors":["Varun Chandola","Arindam Banerjee","Vipin Kumar"],"references":["d1c93534-82a5-41fa-a5fa-9d18f5c2577f","e3a40536-5580-4c24-b273-4fa4dab2579e"],"_id":"5a4a1b04-b36f-402c-a87f-0779098ef050","abstract":"Anomaly detection is an important problem that has been researched within diverse research areas and application domains. Many anomaly detection techniques have been specifically developed for certain application domains, while others are more generic. This survey tries to provide a structured and comprehensive overview of the research on anomaly detection. We have grouped existing techniques into different categories based on the underlying approach adopted by each technique. For each category we have identified key assumptions, which are used by the techniques to differentiate between normal and anomalous behavior. When applying a given technique to a particular domain, these assumptions can be used as guidelines to assess the effectiveness of the technique in that domain. For each category, we provide a basic anomaly detection technique, and then show how the different existing techniques in that category are variants of the basic technique. This template provides an easier and more succinct understanding of the techniques belonging to each category. Further, for each category, we identify the advantages and disadvantages of the techniques in that category. We also provide a discussion on the computational complexity of the techniques since it is an important issue in real application domains. We hope that this survey will provide a better understanding of the different directions in which research has been done on this topic, and how techniques developed in one area can be applied in domains for which they were not intended to begin with.","title":"Anomaly detection: A survey","venue":"ACM Computing Surveys","year":2009,"__v":0,"citationCount":1515,"parents":{"0047fb0c-b86a-4086-929f-13e44c1c1318":1.4634146341463417,"00607f4b-5698-42d8-b815-91f619e414bc":3.414634146341464,"014d59ae-8fe7-4bb8-a61d-6e4c89e10ee5":0,"018b63a7-3395-41fd-8797-43a844adae57":0.975609756097561,"01c68d0c-49e5-4114-8251-67f39897376c":0.975609756097561,"04048f12-0262-423f-b015-b46c78fad44f":0.975609756097561,"040d49b6-7346-4e09-9d21-ed289a5e3b0a":5.365853658536586,"0432df92-d9f2-4771-a6cc-30575843a01f":1.951219512195122,"052c526b-c9ce-44db-8b1b-b7e4175f7459":4.878048780487805,"06ccc183-8073-42ee-8720-4885c54c360d":8.292682926829269,"07fc27dc-d51d-474a-bb87-fe025ac27976":0,"09776f1e-39e0-46d8-9a9f-72a588f42fb2":0.4878048780487805,"099cf526-2569-4252-9119-e04a03c70d07":0,"0a929cac-9665-4472-b558-bc0fd0b5439a":0,"0c68a0b9-1ec4-455a-83c2-a38a2fcf7903":1.4634146341463417,"0ccebbfd-5c6a-41cd-b3e5-415896a63e1a":1.4634146341463417,"0e37b2f3-0f4c-4188-bd76-802426b00138":3.902439024390244,"0faaf569-fe40-4dae-ab6b-4f32d73bc18c":1.4634146341463417,"0fb3947f-f8cf-45d5-8781-9a3e2125a0d1":0.4878048780487805,"1017d9d4-9a4c-423d-ad40-6d9bebbd6b31":0,"131bc1cb-3af6-4c5e-8de8-dc60c16b9e0d":1.951219512195122,"14a7f031-ae82-4e78-a90c-b3cbc33350d1":0,"156d2884-bfd1-4487-ad05-308b73963e0b":0.975609756097561,"19ff82c1-f4db-47b8-800b-b8b1ecb36c72":1.951219512195122,"1a350293-48df-4b2c-aa3d-d1f1d75c8abd":0,"1a3a9715-607a-4b0e-8561-1253640436a6":0.4878048780487805,"1cebdd66-4f0c-4d94-9b96-55ae71d35d87":0,"1e0c3445-a760-49c7-81f3-4928db498f5f":1.951219512195122,"1f18d22a-782a-4d52-9d51-da2c73ee5339":0,"1fc594cb-f554-4a37-9e18-9ac2ecac323c":2.9268292682926833,"21fce020-efe8-43ef-82ab-df7c9d5a6bb1":0,"221b1f36-7553-4f0a-99a4-f8dd929fd606":0,"23c4a678-7bf2-4d08-8294-061d0b905197":0,"246887d5-8352-439d-8dca-f256a0870f81":0.975609756097561,"24e8d1a1-eb14-422a-97b7-d36b011eadfa":2.4390243902439024,"266b9e4f-d6a5-4514-818d-8646c0ae5e5e":1.4634146341463417,"27161ba5-434d-4b75-a04f-13b27b637a79":8.780487804878048,"2772ae4c-29e7-463c-86e2-e2922a9a5c20":0.4878048780487805,"2b6d4622-8893-4635-893a-1537c81d15ec":1.951219512195122,"2c627667-1217-4d5d-adc4-b13ff5ad01d1":0.4878048780487805,"2c9bcf03-eee4-4851-bd70-2338ff9c7793":0.975609756097561,"2f1205ff-4c5e-495d-84af-c4cd464e28c0":0,"31221520-63cc-4c20-b64c-89bfc235f466":1.951219512195122,"3226caa0-d59b-4254-830f-0bdce011f630":1.951219512195122,"32454c67-87a6-401d-a513-096740a14ca1":0,"32813c33-62f8-4263-b7ee-2904a8ec84ed":0,"32b5d46d-5e52-4ad9-aa5f-44f6a7ea873f":4.390243902439024,"33834a31-132a-409b-b646-c8918a85afb0":0,"33f6a64c-a396-4634-855c-b853507bb371":2.4390243902439024,"345bd2a5-c8fa-45cb-8501-817bda86b63b":0.4878048780487805,"3601034e-9bf3-45a9-a292-d24307aa23fb":0,"3604fcdd-9fd5-45a3-9697-2129e80c823a":3.414634146341464,"37aaf91d-ee84-445f-8eb0-424cdf7fa4a1":3.414634146341464,"3a004b7b-ed1f-45b3-b6d2-0d6432054fa1":1.4634146341463417,"3a062cc9-112c-441c-b30a-bbc3b6175b20":0.975609756097561,"3a44b35d-d1d6-439c-a06a-46a41eb7716c":1.4634146341463417,"3af550cb-0c3a-4020-9958-d4ce53a28d6a":0,"3b01e130-44d0-486e-b9ce-ee8fb91f7ec9":0.4878048780487805,"3d131569-1b73-47e1-a4eb-c1b634fdd49d":1.951219512195122,"3ed462ed-4847-4b19-b7d9-5229da828abd":1.4634146341463417,"40963709-8669-419b-9118-497a3cb28bfd":0,"410fd41d-548b-48a7-9632-c75196bf85cb":0,"427204e3-eb57-49f7-80c7-84b65e1aad6e":1.951219512195122,"44420133-0774-43fe-a94c-4e1fb2d2d6ea":0.4878048780487805,"460dc67f-6374-48b0-922c-55f4a494c3b4":3.902439024390244,"485ea183-f654-46af-a0df-bee30f2d335a":0.4878048780487805,"4b5e938b-6bb4-4a4a-b60a-0fe355ab24ef":3.414634146341464,"538b7ec3-f5b3-48c3-af21-c78939a00eca":0.975609756097561,"541eccbc-eb59-405d-b4c5-2001b00242cc":0.975609756097561,"547dee54-42df-4e9e-b0e4-b9520b3ae3af":9.268292682926829,"55d54648-f393-4016-ad83-bb4add373ca3":2.9268292682926833,"57697343-4573-43c6-be91-5456f3e16b0c":0.975609756097561,"58a29970-78b0-414b-a44c-c3a12f49b135":0,"58c0e16d-89cb-444b-b410-9406db762cb7":0,"5b03a839-1675-4a8c-aa56-f0b9b1b9fdb3":1.951219512195122,"60995add-b9b9-4313-9afb-a34266773645":3.902439024390244,"61652378-a75b-4958-987c-d7bea2fb585d":2.4390243902439024,"6420958d-c928-4690-be01-66dd7a79577e":3.902439024390244,"64bf339f-c2a0-4f5d-aaa4-ca9fcfca357f":0,"6612b217-e504-4e8f-8dd4-34867a05d04b":0,"67a88a67-68ad-43f7-8b98-bea9ee62faa4":0.4878048780487805,"6b9acb26-f756-4c80-9718-f9447236302a":4.390243902439024,"6ba6acb2-135b-4baf-b055-913271a35263":0,"6ce2a644-1c2e-45cb-8453-2c702e9fb06e":0.4878048780487805,"7070053c-489f-402a-93ac-f87c152902cd":3.902439024390244,"72d31cdb-4029-4612-aabb-615e3d5da439":0.4878048780487805,"737901bc-91b2-4a63-8229-ec6188ae511f":5.365853658536586,"7461d33d-bf97-4395-bd49-1e4585d34f36":2.4390243902439024,"777965dd-6a4c-4f6a-9afa-6e3bf0a7f1f7":0,"79301010-5b1a-4082-ba7b-48788e6a7ddd":0.975609756097561,"7c6a970a-0d6f-4e4b-b50e-6c6fbd23a9ab":0,"7c6e7aea-f51f-4811-9846-529a7c01dfe6":0.4878048780487805,"7c93ac7a-7698-492f-acab-f30c8bc15fb8":1.951219512195122,"7e04e256-33d6-41d1-bb7d-5f9dd8666cd2":4.390243902439024,"7e2d2bc7-35a0-42b9-b1a5-ae9573c69fc1":0,"7e7f84f7-ea67-4692-af36-311ab88ef1b0":0,"81091159-0b76-4a06-9cdf-8c53955c0102":4.878048780487805,"8252fa50-457d-41ca-95a1-3fc9341018e0":1.951219512195122,"83a6afcc-349d-41e1-9c3e-432419dbb563":0.975609756097561,"854fac6a-4f3a-4145-b91d-53bb8829dc3c":0.4878048780487805,"85fa0e6c-a9d6-48e0-ba84-56e71376f47b":0,"8aa2a53a-6992-4d38-93d9-1f4c86021274":6.829268292682928,"8bfb1563-5f31-4127-a98c-8d36c630fce8":0,"8c1173e4-08a3-47b7-8561-2af257a6e443":0.975609756097561,"8c121e57-06d6-48ca-be63-cccbde41bbea":0.4878048780487805,"8c16c6ba-7e92-427c-ae9d-5660479f8038":2.4390243902439024,"8c2d7a95-0531-4702-9ac3-7a85ae9c4785":0.4878048780487805,"8cf0f572-0507-48cf-9ada-37c152f5810f":0,"8f7371f5-964f-44f4-a6c3-bf94709ea74c":0,"8fea5421-a225-408d-aefa-3e025eef0506":2.4390243902439024,"913b3361-f885-4af1-bf76-08e3d7b05c79":1.4634146341463417,"94132414-804f-4ea0-8afe-6141768636ab":0,"958f8ea1-92ec-4420-a581-d819c5691063":0,"9698217a-9e61-451b-b265-e5c74cc7a600":1.4634146341463417,"97211b46-a46d-4886-912e-138333aa50bc":0,"97d90be0-e704-4462-b6d9-ad93ad63c94f":0,"9906f4b5-833d-469b-a67b-a4247a0b91ea":0.975609756097561,"9add7503-2fff-4957-809a-c12d880e7303":0,"9b6ee99a-d3dd-461b-bfb1-f907c69b6e23":1.4634146341463417,"9f8394a5-4018-4395-a5ca-b3e91580aaf6":0.975609756097561,"a0304326-321c-49c0-843e-6ad5ea9f5815":0,"a22d71b6-61c4-4ae4-9843-931feb08e710":3.414634146341464,"a23c7a37-a789-4fe9-b554-dbf2377d5de2":6.341463414634147,"a34e08d7-fdef-4a9c-b343-89974f175a55":1.951219512195122,"a44548b2-92d6-4ae6-b0de-66169c7bf646":3.414634146341464,"a5a9e10d-6925-4b6b-a048-e9f61a9a1739":0,"a883845a-3970-402b-b533-29ed7d075748":0.975609756097561,"a883cd2f-54ff-4133-ad4d-f2f813db7744":1.951219512195122,"a9bb2246-1ffd-4802-a236-db1c4083c57e":0,"aaa52b01-e51f-4c15-8a79-e78c478a17b4":0,"ac36934f-0c9b-441d-a9dd-c98dc4496986":1.951219512195122,"adee22e8-704e-486c-9611-196ac9f9d720":0,"ae829318-5d10-461d-9c99-34a95a3f8732":0.4878048780487805,"aedfd2bf-2a47-4874-910e-1430aa646767":1.4634146341463417,"afcfbfa0-5678-4194-903f-219a90baa8a8":0,"b183a338-50d9-4195-b2d1-78243b3de3e8":2.4390243902439024,"b402ae4e-ec2a-4a0f-94bc-686170283d62":4.390243902439024,"b575735c-de10-4891-b7ce-f4ff14087818":1.951219512195122,"b69c0356-5a2c-4358-ab32-36d7f7b55462":0.975609756097561,"b6ea25fc-e7dc-4d9b-a391-a1327aab94b3":0.4878048780487805,"b869c67e-3995-4843-8ebf-c63c0e7e6013":0,"bd363c40-6a73-40ba-a748-76d0f621697f":3.902439024390244,"bd70917d-9291-4762-a69f-70230f68d9c4":3.414634146341464,"bdb8d83d-1771-4399-b593-d43be5a9f892":0,"bdbfe4d7-a5c9-45ba-a8e9-0945f2786921":0.4878048780487805,"be75bd56-f426-43fa-923c-d7461acd38c6":0.4878048780487805,"bf4cdada-d6d7-4e63-84ee-71ee09652a07":0.975609756097561,"bf646dcb-2ede-4037-933c-a2e6f7da9d66":0,"c01e3902-7326-4db7-b949-478cf589758f":0,"c1a1d611-2010-4357-86da-bce8ad125444":2.4390243902439024,"c21b2320-83d1-48c3-86f0-05e079972dff":0,"c3d04aca-907c-4030-a895-a8ffce75419f":11.707317073170733,"c4dc7b46-01d3-44f5-91ca-0cc063d38c8c":0,"c4dcf4ac-2f75-4960-a0c2-6cb16d9f8ac0":0.4878048780487805,"c5901c2a-d290-45cb-b950-a5443eb311b2":1.951219512195122,"c6c636c7-f3fd-4ce1-9bd2-1667ea3f4902":1.951219512195122,"c7e6a1a6-657a-43bd-89dd-cbeda73dff8c":0.4878048780487805,"ca0c5501-5851-4f69-9f86-41deefcdbc8f":1.4634146341463417,"cae7487c-9466-4519-8b03-d7d415c54876":0.4878048780487805,"cb7950c5-82d5-4d24-bd36-7b9090d54393":3.902439024390244,"cb7a0a24-8d59-4559-a302-3d0cfa787b8c":1.951219512195122,"cc7366c5-21d9-4452-b925-02bf2ab9f0a4":3.902439024390244,"ce8dd9cd-3e6c-438b-8d39-68e36b99690a":0.975609756097561,"cf6baeec-ab83-4681-822f-3796b23e3eb3":4.390243902439024,"cf74c67b-da47-4319-bc0a-9c9059797fb9":2.4390243902439024,"d0538820-6ec8-4065-a7bc-c1d1ac9d8a3d":3.414634146341464,"d0ba110f-d9bb-4fa8-a3c9-873c6ebba028":0,"d177136e-2de4-4e30-b691-9468afa9b089":0.4878048780487805,"d1c93534-82a5-41fa-a5fa-9d18f5c2577f":0,"d22bbe77-c4d1-40a8-88fd-23afbe627e8e":2.4390243902439024,"d32bf933-23c5-4a41-9ac4-d8db22cc3b23":0.975609756097561,"d90f5beb-552a-4654-8043-661ac5fd66ae":0.4878048780487805,"d95d1567-5db2-480a-9228-cece52dc81ac":0.4878048780487805,"dea14908-1f92-4793-b7bd-46f30366a634":1.4634146341463417,"deec27c2-09ac-4932-bf12-f25b805d410f":0.4878048780487805,"df24abbe-9771-4238-a8e2-e5b7c4c63382":0,"dff17f99-1868-4be7-a280-0a7b9357e21f":0,"e0334455-4636-4a83-8ab2-82a0e701fd1c":3.414634146341464,"e1739977-881a-4869-a131-2b0235d2a17b":0,"e1ccce5a-52dc-4a29-bcaa-e26c5521c889":4.390243902439024,"e3a40536-5580-4c24-b273-4fa4dab2579e":0.975609756097561,"e491b67c-ce90-4017-99bd-b74260d9b286":0,"e4b2a935-0bfc-4b70-87f0-a1e9eac47a56":0.4878048780487805,"e4fdcfab-e88f-4f35-b94f-e80edf71fa80":1.4634146341463417,"e6d44982-2c67-4b24-95ac-f1aac15efa7a":0.4878048780487805,"e7c93237-717e-4552-8e56-d378bc43a8b0":0,"e97d9c05-854e-4bd6-9301-11affc0d103f":0,"e9c824cf-74de-450a-9505-228b2ae69692":1.4634146341463417,"eb2f8d56-66b8-442e-a1a0-580cde910e91":0.975609756097561,"ec3b26b9-01e6-40b6-9f43-aae7fcf46366":2.9268292682926833,"ecfded99-3ab2-4603-aba7-9e4d2d2370c4":0,"efc8939e-4f17-4bee-b360-c9aab77a1608":0,"f011b6ee-19e8-468d-a487-05f230f8fbb1":0,"f02854d1-91df-4a22-9ec3-d7d77b9ef434":4.390243902439024,"f0b39364-7a3b-4fc8-9196-8935490d3ef6":2.9268292682926833,"f1b5ef91-592b-41ea-963d-275989d27e28":0,"f7babd40-634e-49c3-bc2a-8829a67ae2d3":0.4878048780487805,"f971a26a-b3bd-4f81-905c-5c0b92f9a44b":0,"fa7f63e4-4bb4-4cee-919a-11c035ed53ea":3.902439024390244,"fbfeca1c-3e45-482b-884b-77c1199eb92b":2.4390243902439024,"fc011694-28de-4ef9-bccb-2f3d9c763fe8":1.951219512195122,"fdad896e-7006-4f81-965b-5624afa2f720":1.951219512195122,"fe46092f-f5d0-4659-9ce3-f35abcbaac8f":2.4390243902439024,"fe7f2770-ddca-4716-a7d9-545e68f691fe":0,"ff87654d-a2ea-4f61-9821-78272089766d":4.878048780487805},"keyword":{"0047fb0c-b86a-4086-929f-13e44c1c1318":11.022354497354497,"00607f4b-5698-42d8-b815-91f619e414bc":0,"014d59ae-8fe7-4bb8-a61d-6e4c89e10ee5":11.813492063492063,"018b63a7-3395-41fd-8797-43a844adae57":10.810555555555554,"01c68d0c-49e5-4114-8251-67f39897376c":12.499999999999998,"04048f12-0262-423f-b015-b46c78fad44f":11.02579365079365,"040d49b6-7346-4e09-9d21-ed289a5e3b0a":9.856349206349204,"0432df92-d9f2-4771-a6cc-30575843a01f":11.844047619047618,"052c526b-c9ce-44db-8b1b-b7e4175f7459":10.190317460317457,"06ccc183-8073-42ee-8720-4885c54c360d":12.542857142857141,"07fc27dc-d51d-474a-bb87-fe025ac27976":11.798650793650793,"09776f1e-39e0-46d8-9a9f-72a588f42fb2":0,"099cf526-2569-4252-9119-e04a03c70d07":12.78829365079365,"0a929cac-9665-4472-b558-bc0fd0b5439a":0,"0c68a0b9-1ec4-455a-83c2-a38a2fcf7903":11.526587301587302,"0ccebbfd-5c6a-41cd-b3e5-415896a63e1a":10.132936507936506,"0e37b2f3-0f4c-4188-bd76-802426b00138":12.837962962962964,"0faaf569-fe40-4dae-ab6b-4f32d73bc18c":10.855423280423281,"0fb3947f-f8cf-45d5-8781-9a3e2125a0d1":10.132936507936506,"1017d9d4-9a4c-423d-ad40-6d9bebbd6b31":0,"131bc1cb-3af6-4c5e-8de8-dc60c16b9e0d":11.679761904761905,"14a7f031-ae82-4e78-a90c-b3cbc33350d1":9.928571428571427,"156d2884-bfd1-4487-ad05-308b73963e0b":12.402248677248679,"19ff82c1-f4db-47b8-800b-b8b1ecb36c72":9.391269841269843,"1a350293-48df-4b2c-aa3d-d1f1d75c8abd":10.07857142857143,"1a3a9715-607a-4b0e-8561-1253640436a6":11.784126984126985,"1cebdd66-4f0c-4d94-9b96-55ae71d35d87":11.712579365079364,"1e0c3445-a760-49c7-81f3-4928db498f5f":10.001388888888888,"1f18d22a-782a-4d52-9d51-da2c73ee5339":11.58244708994709,"1fc594cb-f554-4a37-9e18-9ac2ecac323c":9.313888888888888,"21fce020-efe8-43ef-82ab-df7c9d5a6bb1":11.256388888888887,"221b1f36-7553-4f0a-99a4-f8dd929fd606":11.770833333333334,"23c4a678-7bf2-4d08-8294-061d0b905197":0,"246887d5-8352-439d-8dca-f256a0870f81":10.733333333333333,"24e8d1a1-eb14-422a-97b7-d36b011eadfa":9.916666666666664,"266b9e4f-d6a5-4514-818d-8646c0ae5e5e":12.984695767195767,"27161ba5-434d-4b75-a04f-13b27b637a79":11.063174603174602,"2772ae4c-29e7-463c-86e2-e2922a9a5c20":10.320436507936506,"2b6d4622-8893-4635-893a-1537c81d15ec":11.825000000000001,"2c627667-1217-4d5d-adc4-b13ff5ad01d1":12.106825396825396,"2c9bcf03-eee4-4851-bd70-2338ff9c7793":11.120277777777776,"2f1205ff-4c5e-495d-84af-c4cd464e28c0":12.62488095238095,"31221520-63cc-4c20-b64c-89bfc235f466":10.624007936507937,"3226caa0-d59b-4254-830f-0bdce011f630":11.724206349206348,"32454c67-87a6-401d-a513-096740a14ca1":11.06468253968254,"32813c33-62f8-4263-b7ee-2904a8ec84ed":0,"32b5d46d-5e52-4ad9-aa5f-44f6a7ea873f":11.645873015873015,"33834a31-132a-409b-b646-c8918a85afb0":12.049999999999997,"33f6a64c-a396-4634-855c-b853507bb371":10.55019841269841,"345bd2a5-c8fa-45cb-8501-817bda86b63b":10.792499999999999,"3601034e-9bf3-45a9-a292-d24307aa23fb":10.789047619047619,"3604fcdd-9fd5-45a3-9697-2129e80c823a":11.712499999999997,"37aaf91d-ee84-445f-8eb0-424cdf7fa4a1":12.035714285714285,"3a004b7b-ed1f-45b3-b6d2-0d6432054fa1":11.380039682539683,"3a062cc9-112c-441c-b30a-bbc3b6175b20":10.510317460317458,"3a44b35d-d1d6-439c-a06a-46a41eb7716c":11.406216931216932,"3af550cb-0c3a-4020-9958-d4ce53a28d6a":9.00079365079365,"3b01e130-44d0-486e-b9ce-ee8fb91f7ec9":12.042724867724868,"3d131569-1b73-47e1-a4eb-c1b634fdd49d":12.147619047619047,"3ed462ed-4847-4b19-b7d9-5229da828abd":0,"40963709-8669-419b-9118-497a3cb28bfd":10.430555555555557,"410fd41d-548b-48a7-9632-c75196bf85cb":10.275992063492062,"427204e3-eb57-49f7-80c7-84b65e1aad6e":10.41984126984127,"44420133-0774-43fe-a94c-4e1fb2d2d6ea":11.20357142857143,"460dc67f-6374-48b0-922c-55f4a494c3b4":12.534523809523808,"485ea183-f654-46af-a0df-bee30f2d335a":0,"4b5e938b-6bb4-4a4a-b60a-0fe355ab24ef":12.076626984126987,"538b7ec3-f5b3-48c3-af21-c78939a00eca":11.567857142857143,"541eccbc-eb59-405d-b4c5-2001b00242cc":12.423280423280422,"547dee54-42df-4e9e-b0e4-b9520b3ae3af":10.08148148148148,"55d54648-f393-4016-ad83-bb4add373ca3":0,"57697343-4573-43c6-be91-5456f3e16b0c":0,"58a29970-78b0-414b-a44c-c3a12f49b135":10.90079365079365,"58c0e16d-89cb-444b-b410-9406db762cb7":10.319841269841268,"5b03a839-1675-4a8c-aa56-f0b9b1b9fdb3":10.700132275132276,"60995add-b9b9-4313-9afb-a34266773645":10.04351851851852,"61652378-a75b-4958-987c-d7bea2fb585d":11.621296296296297,"6420958d-c928-4690-be01-66dd7a79577e":10.005,"64bf339f-c2a0-4f5d-aaa4-ca9fcfca357f":10.896031746031744,"6612b217-e504-4e8f-8dd4-34867a05d04b":12.186349206349208,"67a88a67-68ad-43f7-8b98-bea9ee62faa4":10.382936507936508,"6b9acb26-f756-4c80-9718-f9447236302a":11.81642857142857,"6ba6acb2-135b-4baf-b055-913271a35263":11.073412698412698,"6ce2a644-1c2e-45cb-8453-2c702e9fb06e":8.589285714285712,"7070053c-489f-402a-93ac-f87c152902cd":10.838558201058202,"72d31cdb-4029-4612-aabb-615e3d5da439":12.769841269841269,"737901bc-91b2-4a63-8229-ec6188ae511f":11.700000000000001,"7461d33d-bf97-4395-bd49-1e4585d34f36":11.718333333333335,"777965dd-6a4c-4f6a-9afa-6e3bf0a7f1f7":10.890873015873016,"79301010-5b1a-4082-ba7b-48788e6a7ddd":10.995343915343915,"7c6a970a-0d6f-4e4b-b50e-6c6fbd23a9ab":10.524074074074072,"7c6e7aea-f51f-4811-9846-529a7c01dfe6":10.30595238095238,"7c93ac7a-7698-492f-acab-f30c8bc15fb8":11.288888888888888,"7e04e256-33d6-41d1-bb7d-5f9dd8666cd2":12.075793650793651,"7e2d2bc7-35a0-42b9-b1a5-ae9573c69fc1":0,"7e7f84f7-ea67-4692-af36-311ab88ef1b0":11.237962962962962,"81091159-0b76-4a06-9cdf-8c53955c0102":11.804761904761904,"8252fa50-457d-41ca-95a1-3fc9341018e0":9.75,"83a6afcc-349d-41e1-9c3e-432419dbb563":10.597222222222223,"854fac6a-4f3a-4145-b91d-53bb8829dc3c":11.080555555555557,"85fa0e6c-a9d6-48e0-ba84-56e71376f47b":0,"8aa2a53a-6992-4d38-93d9-1f4c86021274":11.915873015873014,"8bfb1563-5f31-4127-a98c-8d36c630fce8":10.90744708994709,"8c1173e4-08a3-47b7-8561-2af257a6e443":10.720833333333331,"8c121e57-06d6-48ca-be63-cccbde41bbea":9.323015873015873,"8c16c6ba-7e92-427c-ae9d-5660479f8038":0,"8c2d7a95-0531-4702-9ac3-7a85ae9c4785":0,"8cf0f572-0507-48cf-9ada-37c152f5810f":10.933174603174603,"8f7371f5-964f-44f4-a6c3-bf94709ea74c":0,"8fea5421-a225-408d-aefa-3e025eef0506":11.99391534391534,"913b3361-f885-4af1-bf76-08e3d7b05c79":10.56329365079365,"94132414-804f-4ea0-8afe-6141768636ab":11.228571428571428,"958f8ea1-92ec-4420-a581-d819c5691063":11.916666666666664,"9698217a-9e61-451b-b265-e5c74cc7a600":10.017129629629627,"97211b46-a46d-4886-912e-138333aa50bc":0,"97d90be0-e704-4462-b6d9-ad93ad63c94f":12.278571428571427,"9906f4b5-833d-469b-a67b-a4247a0b91ea":9.622619047619049,"9add7503-2fff-4957-809a-c12d880e7303":10.599206349206348,"9b6ee99a-d3dd-461b-bfb1-f907c69b6e23":11.20479797979798,"9f8394a5-4018-4395-a5ca-b3e91580aaf6":10.837566137566137,"a0304326-321c-49c0-843e-6ad5ea9f5815":11.089550264550263,"a22d71b6-61c4-4ae4-9843-931feb08e710":9.37142857142857,"a23c7a37-a789-4fe9-b554-dbf2377d5de2":10.073650793650794,"a34e08d7-fdef-4a9c-b343-89974f175a55":0,"a44548b2-92d6-4ae6-b0de-66169c7bf646":7.797222222222221,"a5a9e10d-6925-4b6b-a048-e9f61a9a1739":13.03234126984127,"a883845a-3970-402b-b533-29ed7d075748":10.429126984126984,"a883cd2f-54ff-4133-ad4d-f2f813db7744":10.52142857142857,"a9bb2246-1ffd-4802-a236-db1c4083c57e":8.48109668109668,"aaa52b01-e51f-4c15-8a79-e78c478a17b4":8.969444444444443,"ac36934f-0c9b-441d-a9dd-c98dc4496986":9.744444444444444,"adee22e8-704e-486c-9611-196ac9f9d720":10.95,"ae829318-5d10-461d-9c99-34a95a3f8732":0,"aedfd2bf-2a47-4874-910e-1430aa646767":0,"afcfbfa0-5678-4194-903f-219a90baa8a8":10.621428571428574,"b183a338-50d9-4195-b2d1-78243b3de3e8":10.537698412698413,"b402ae4e-ec2a-4a0f-94bc-686170283d62":10.735317460317459,"b575735c-de10-4891-b7ce-f4ff14087818":11.279761904761905,"b69c0356-5a2c-4358-ab32-36d7f7b55462":11.194550264550264,"b6ea25fc-e7dc-4d9b-a391-a1327aab94b3":12.184695767195768,"b869c67e-3995-4843-8ebf-c63c0e7e6013":11.569444444444445,"bd363c40-6a73-40ba-a748-76d0f621697f":10.338095238095237,"bd70917d-9291-4762-a69f-70230f68d9c4":11.980026455026453,"bdb8d83d-1771-4399-b593-d43be5a9f892":0,"bdbfe4d7-a5c9-45ba-a8e9-0945f2786921":10.448478835978836,"be75bd56-f426-43fa-923c-d7461acd38c6":11.30583333333333,"bf4cdada-d6d7-4e63-84ee-71ee09652a07":0,"bf646dcb-2ede-4037-933c-a2e6f7da9d66":9.263888888888888,"c01e3902-7326-4db7-b949-478cf589758f":11.461507936507939,"c1a1d611-2010-4357-86da-bce8ad125444":11.231349206349208,"c21b2320-83d1-48c3-86f0-05e079972dff":11.484523809523807,"c3d04aca-907c-4030-a895-a8ffce75419f":10.556613756613755,"c4dc7b46-01d3-44f5-91ca-0cc063d38c8c":10.548571428571428,"c4dcf4ac-2f75-4960-a0c2-6cb16d9f8ac0":8.582539682539682,"c5901c2a-d290-45cb-b950-a5443eb311b2":11.989682539682535,"c6c636c7-f3fd-4ce1-9bd2-1667ea3f4902":0,"c7e6a1a6-657a-43bd-89dd-cbeda73dff8c":11.193253968253968,"ca0c5501-5851-4f69-9f86-41deefcdbc8f":12.479365079365081,"cae7487c-9466-4519-8b03-d7d415c54876":0,"cb7950c5-82d5-4d24-bd36-7b9090d54393":11.997222222222224,"cb7a0a24-8d59-4559-a302-3d0cfa787b8c":11.38888888888889,"cc7366c5-21d9-4452-b925-02bf2ab9f0a4":10.385912698412698,"ce8dd9cd-3e6c-438b-8d39-68e36b99690a":11.01058201058201,"cf6baeec-ab83-4681-822f-3796b23e3eb3":9.626984126984127,"cf74c67b-da47-4319-bc0a-9c9059797fb9":10.606415343915344,"d0538820-6ec8-4065-a7bc-c1d1ac9d8a3d":11.506461131461132,"d0ba110f-d9bb-4fa8-a3c9-873c6ebba028":11.094227994227996,"d177136e-2de4-4e30-b691-9468afa9b089":6.538888888888888,"d1c93534-82a5-41fa-a5fa-9d18f5c2577f":10.849404761904763,"d22bbe77-c4d1-40a8-88fd-23afbe627e8e":10.417460317460316,"d32bf933-23c5-4a41-9ac4-d8db22cc3b23":9.470238095238093,"d90f5beb-552a-4654-8043-661ac5fd66ae":10.404797979797978,"d95d1567-5db2-480a-9228-cece52dc81ac":9.730555555555556,"dea14908-1f92-4793-b7bd-46f30366a634":10.505952380952381,"deec27c2-09ac-4932-bf12-f25b805d410f":0,"df24abbe-9771-4238-a8e2-e5b7c4c63382":12.105158730158731,"dff17f99-1868-4be7-a280-0a7b9357e21f":0,"e0334455-4636-4a83-8ab2-82a0e701fd1c":12.67142857142857,"e1739977-881a-4869-a131-2b0235d2a17b":10.614285714285717,"e1ccce5a-52dc-4a29-bcaa-e26c5521c889":0,"e3a40536-5580-4c24-b273-4fa4dab2579e":11.26653439153439,"e491b67c-ce90-4017-99bd-b74260d9b286":11.301984126984127,"e4b2a935-0bfc-4b70-87f0-a1e9eac47a56":0,"e4fdcfab-e88f-4f35-b94f-e80edf71fa80":11.869576719576719,"e6d44982-2c67-4b24-95ac-f1aac15efa7a":9.015555555555554,"e7c93237-717e-4552-8e56-d378bc43a8b0":12.326587301587303,"e97d9c05-854e-4bd6-9301-11affc0d103f":11.990740740740739,"e9c824cf-74de-450a-9505-228b2ae69692":10.091904761904763,"eb2f8d56-66b8-442e-a1a0-580cde910e91":10.874074074074075,"ec3b26b9-01e6-40b6-9f43-aae7fcf46366":11.747724867724868,"ecfded99-3ab2-4603-aba7-9e4d2d2370c4":12.405555555555555,"efc8939e-4f17-4bee-b360-c9aab77a1608":0,"f011b6ee-19e8-468d-a487-05f230f8fbb1":0,"f02854d1-91df-4a22-9ec3-d7d77b9ef434":10.822460317460319,"f0b39364-7a3b-4fc8-9196-8935490d3ef6":10.559523809523808,"f1b5ef91-592b-41ea-963d-275989d27e28":11.071825396825398,"f7babd40-634e-49c3-bc2a-8829a67ae2d3":11.128835978835978,"f971a26a-b3bd-4f81-905c-5c0b92f9a44b":12.41944444444444,"fa7f63e4-4bb4-4cee-919a-11c035ed53ea":10.272089947089947,"fbfeca1c-3e45-482b-884b-77c1199eb92b":10.867724867724867,"fc011694-28de-4ef9-bccb-2f3d9c763fe8":0,"fdad896e-7006-4f81-965b-5624afa2f720":10.745873015873016,"fe46092f-f5d0-4659-9ce3-f35abcbaac8f":10.382407407407404,"fe7f2770-ddca-4716-a7d9-545e68f691fe":10.864682539682539,"ff87654d-a2ea-4f61-9821-78272089766d":10.977420634920634},"topic":["techniqu","categori","domain","research","provid"],"offsprings":[]},"5e8b0e8a-d687-4333-bfe9-73b4c1bebde5":{"authors":["Athinodoros S. Georghiades","Peter N. Belhumeur","David J. Kriegman"],"references":["56f4b72a-ec39-47ac-8220-899296e7fb18","bf03f268-de9d-4a80-aee1-200990056503"],"_id":"5e8b0e8a-d687-4333-bfe9-73b4c1bebde5","abstract":"We present a generative appearance-based method for recognizing human faces under variation in lighting and viewpoint. Our method exploits the fact that the set of images of an object in fixed pose, but under all possible illumination conditions, is a convex cone in the space of images. Using a small number of training images of each face taken with different lighting directions, the shape and albedo of the face can be reconstructed. In turn, this reconstruction serves as a generative model that can be used to render (or synthesize) images of the face under novel poses and illumination conditions. The pose space is then sampled and, for each pose, the corresponding illumination cone is approximated by a low-dimensional linear subspace whose basis vectors are estimated using the generative model. Our recognition algorithm assigns to a test image the identity of the closest approximated illumination cone. Test results show that the method performs almost without error, except on the most extreme lighting directions.","title":"From few to many: illumination cone models for face recognition under variable lighting and pose","venue":"IEEE Transactions on Pattern Analysis and Machine Intelligence","year":2001,"__v":0,"citationCount":1860,"parents":{"04c0fda2-3699-4f61-98d2-3d621931c1f9":6.122448979591836,"0702de7d-688c-460b-bb27-197eaa123a07":6.122448979591836,"0838d523-ab76-4dcb-8516-b1432251add2":0,"0d2d1d04-272d-4968-b52e-5f9f44709f9e":8.16326530612245,"0fa84c94-ae45-44d3-bd37-aa3d48158977":12.244897959183673,"123dbd0e-74f1-428b-9f16-00d04583f937":0,"17ee8c1c-3d4e-4402-8a19-d06ece63b281":18.367346938775512,"1a364b81-4662-4c79-ae11-67429e67ca25":10.204081632653061,"33d74862-6527-4c30-be0c-95226a3f8a3a":8.16326530612245,"342dd278-5caa-499c-89ed-9c644150ff6e":12.244897959183673,"3b3d7569-08b1-4017-9910-2a017a00e43e":0,"40f728c0-55b3-423b-aff5-a9b3ff27b7d5":2.0408163265306123,"424b58a8-4f48-4fed-b532-4fba374e3c0c":0,"4a30b000-b1c6-4281-892b-3b60e83d0c05":2.0408163265306123,"4c857862-1cb7-4ad4-907f-f9f694fe6245":4.081632653061225,"54a5822c-e405-44ad-84e3-cea51e7349c2":12.244897959183673,"56f4b72a-ec39-47ac-8220-899296e7fb18":20.408163265306122,"5b146739-a8f7-4b19-acb7-0370d72ff561":10.204081632653061,"5de25331-b39f-4667-a074-b30c99f9a720":2.0408163265306123,"5ebbd1f5-dfe5-4eec-9883-b8b5efea366c":0,"5f9f2346-d1e3-4716-a8af-8c14f1490e00":6.122448979591836,"6e8cc926-79a1-4676-a2bd-f9d49f3144cf":8.16326530612245,"700061b6-54a5-4f50-a1ef-1d8de3015c43":8.16326530612245,"7099aef8-6ac6-4351-9615-1a6c6ae53487":2.0408163265306123,"7cdb6afa-db51-43a2-a1a6-5939051412a2":4.081632653061225,"8428f986-6dce-46fc-b5f5-5e22df139f80":10.204081632653061,"8c987526-6d8e-46ff-9e5a-403e804623ff":6.122448979591836,"8df7292c-b52e-4888-80ab-776f5fba5810":0,"905461e4-643b-4da0-a669-f52318b9e126":0,"94a0b002-578e-4581-ad1d-8fc52a7052ea":4.081632653061225,"9aeac8e2-4fce-4b5c-a566-3318041472b6":2.0408163265306123,"aa4f1c11-6860-46ed-9188-ce3c10bcb4f3":0,"b1295c0c-9c1c-41d7-8cd2-74ed1557481c":16.3265306122449,"b71b91cc-0ede-49c8-b528-cca5345bbb45":2.0408163265306123,"b85ac095-a9f2-4954-b2bf-f53fde98958c":0,"bdd75c60-ad86-483b-9d5f-99039ef800a2":6.122448979591836,"bf03f268-de9d-4a80-aee1-200990056503":2.0408163265306123,"c42f42f8-d1b5-4965-b7c2-33a0e2d9c8a9":4.081632653061225,"c94373fe-6625-4763-99e6-003e611c2aee":2.0408163265306123,"cacef546-cc48-4fb9-814f-9c12141662d8":0,"d3962f4e-82aa-47cf-92fa-47d90881f5cc":0,"d42f853d-12d7-416d-8b27-c314ef563eed":2.0408163265306123,"d5e5a24d-f80e-4f1a-b48b-22403b653276":2.0408163265306123,"d6e37fb1-5f7e-448e-847b-7d1f1271c574":4.081632653061225,"d9fd463e-26cb-40be-9885-e5c3bc6922d4":0,"de9218ee-1982-455b-96c4-f28718f76a2f":6.122448979591836,"eb63b82d-5108-4abf-8ee7-2d11bc1998a0":2.0408163265306123,"ef50568a-329a-42d8-bb6b-3e10f34ca75a":0,"fdf8a6b9-89bc-42cd-9407-27021d31333d":6.122448979591836},"keyword":{"04c0fda2-3699-4f61-98d2-3d621931c1f9":9.136904761904763,"0702de7d-688c-460b-bb27-197eaa123a07":5.5210317460317455,"0838d523-ab76-4dcb-8516-b1432251add2":10.89285714285714,"0d2d1d04-272d-4968-b52e-5f9f44709f9e":10.823412698412698,"0fa84c94-ae45-44d3-bd37-aa3d48158977":8.886031746031746,"123dbd0e-74f1-428b-9f16-00d04583f937":11.075396825396822,"17ee8c1c-3d4e-4402-8a19-d06ece63b281":10.400793650793652,"1a364b81-4662-4c79-ae11-67429e67ca25":11.031349206349205,"33d74862-6527-4c30-be0c-95226a3f8a3a":10.420396825396827,"342dd278-5caa-499c-89ed-9c644150ff6e":8.586507936507935,"3b3d7569-08b1-4017-9910-2a017a00e43e":9.43515873015873,"40f728c0-55b3-423b-aff5-a9b3ff27b7d5":9.731084656084656,"424b58a8-4f48-4fed-b532-4fba374e3c0c":0,"4a30b000-b1c6-4281-892b-3b60e83d0c05":9.163359788359788,"4c857862-1cb7-4ad4-907f-f9f694fe6245":0,"54a5822c-e405-44ad-84e3-cea51e7349c2":9.979761904761903,"56f4b72a-ec39-47ac-8220-899296e7fb18":9.882539682539683,"5b146739-a8f7-4b19-acb7-0370d72ff561":10.746693121693122,"5de25331-b39f-4667-a074-b30c99f9a720":9.502539682539684,"5ebbd1f5-dfe5-4eec-9883-b8b5efea366c":9.535714285714285,"5f9f2346-d1e3-4716-a8af-8c14f1490e00":10.720793650793649,"6e8cc926-79a1-4676-a2bd-f9d49f3144cf":9.239047619047621,"700061b6-54a5-4f50-a1ef-1d8de3015c43":10.025396825396824,"7099aef8-6ac6-4351-9615-1a6c6ae53487":10.396031746031746,"7cdb6afa-db51-43a2-a1a6-5939051412a2":11.08626984126984,"8428f986-6dce-46fc-b5f5-5e22df139f80":9.165476190476191,"8c987526-6d8e-46ff-9e5a-403e804623ff":8.986111111111112,"8df7292c-b52e-4888-80ab-776f5fba5810":9.13888888888889,"905461e4-643b-4da0-a669-f52318b9e126":11.463095238095239,"94a0b002-578e-4581-ad1d-8fc52a7052ea":9.67222222222222,"9aeac8e2-4fce-4b5c-a566-3318041472b6":10.16388888888889,"aa4f1c11-6860-46ed-9188-ce3c10bcb4f3":8.269444444444444,"b1295c0c-9c1c-41d7-8cd2-74ed1557481c":10.431507936507934,"b71b91cc-0ede-49c8-b528-cca5345bbb45":10.772936507936508,"b85ac095-a9f2-4954-b2bf-f53fde98958c":0,"bdd75c60-ad86-483b-9d5f-99039ef800a2":11.182169312169313,"bf03f268-de9d-4a80-aee1-200990056503":9.438888888888888,"c42f42f8-d1b5-4965-b7c2-33a0e2d9c8a9":9.463095238095239,"c94373fe-6625-4763-99e6-003e611c2aee":0,"cacef546-cc48-4fb9-814f-9c12141662d8":0,"d3962f4e-82aa-47cf-92fa-47d90881f5cc":10.23941798941799,"d42f853d-12d7-416d-8b27-c314ef563eed":9.23904761904762,"d5e5a24d-f80e-4f1a-b48b-22403b653276":11.566428571428569,"d6e37fb1-5f7e-448e-847b-7d1f1271c574":9.875793650793652,"d9fd463e-26cb-40be-9885-e5c3bc6922d4":11.003703703703703,"de9218ee-1982-455b-96c4-f28718f76a2f":10.6015873015873,"eb63b82d-5108-4abf-8ee7-2d11bc1998a0":9.941269841269841,"ef50568a-329a-42d8-bb6b-3e10f34ca75a":0,"fdf8a6b9-89bc-42cd-9407-27021d31333d":9.744708994708994},"topic":["imag","pose","illumin","face","method"],"offsprings":["7236dbb7-f0b2-4e28-bb7c-6de187c32d64","a81d35e6-d5cd-4eef-9144-b0755ef268d1","32d158dc-6f9f-426a-973b-8edc5e4c5dad"]},"5ff5401a-0dc8-4e2b-b5ad-e994b833c79c":{"authors":["Michael Wooldridge","Nicholas R. Jennings"],"references":[],"_id":"5ff5401a-0dc8-4e2b-b5ad-e994b833c79c","abstract":"The concept of an agent has become important in both Artificial Intelligence (AI) and mainstream computer science. Our aim in this paper is to point the reader at what we perceive to be the most important theoretical and practical issues associated with the design and construction of intelligent agents. For convenience, we divide these issues into three areas (though as the reader will see, the divisions are at times somewhat arbitrary). Agent theory is concerned with the question of what an agent is, and the use of mathematical formalisms for representing and reasoning about the properties of agents. Agent architectures can be thought of as software engineering models of agents;researchers in this area are primarily concerned with the problem of designing software or hardware systems that will satisfy the properties specified by agent theorists. Finally, agent languages are software systems for programming and experimenting with agents; these languages may embody principles proposed by theorists. The paper is not intended to serve as a tutorial introduction to all the issues mentioned; we hope instead simply to identify the most important issues, and point to work that elaborates on them. The article includes a short review of current and potential applications of agent technology.","title":"Intelligent agents: theory and practice","venue":"Knowledge Engineering Review","year":1995,"__v":0,"citationCount":1903,"parents":{"015b8db1-b997-47bb-9b26-4bfd9c4a0e75":1.1363636363636365,"02a46801-c4d8-42cc-9361-7e77e983157d":1.1363636363636365,"0499d160-99ef-471b-bb04-9d69ad6f992f":1.1363636363636365,"050f97de-684d-42e3-aec3-ac6f1075a51d":3.4090909090909087,"05ab60cf-7664-46c0-9820-beccb36fba01":6.8181818181818175,"064f3f8e-913a-496f-a972-5caa8e17c4b9":6.8181818181818175,"06e64e99-3717-4646-89e7-941a787fba79":0,"079090cb-9ba8-419b-845c-7cccb6039da3":0,"093a1d08-58b2-4159-a5f1-976751af9284":4.545454545454546,"0abe8148-010b-4d95-ae4b-d9312fae1600":5.681818181818182,"0b89d1b7-2551-4206-ae03-09b504fe9edf":1.1363636363636365,"0bdd1319-aef0-4867-a223-b623ee1772f4":0,"113a4504-4b64-497b-bd9f-77ab0d31f1bd":0,"15d5821e-650f-4f70-8969-da628eb37676":0,"187f3760-de81-4594-acba-0fdde35a48e9":0,"1bcf5418-adcb-4721-a559-0d505f27aa7a":11.363636363636363,"1ccd58ea-19a6-4bcc-a1cb-07bec0de2b7f":0,"1ef5ce37-4ea4-49a7-a110-74ad4ef63ec1":4.545454545454546,"21d91386-84de-46b1-b328-a2743b75e9f0":0,"2329ae1f-1062-4504-9ef1-45d9e5c0dd2e":0,"25508aa7-03c7-4132-a881-4ccb2e34a086":1.1363636363636365,"27e7abac-0fea-4592-af25-acf1296d005d":0,"28f334ad-dba6-41a2-90c4-8c08f161640a":2.272727272727273,"2a3b42d7-3dd7-4e62-a7f9-282d686108cf":0,"2a898b76-5a6a-46fb-8470-566ef2adf07d":1.1363636363636365,"2b90237b-9d8d-4ca4-99ab-3488457e123d":4.545454545454546,"30991cbc-af1e-4a29-b5ff-d5de5568f6e4":0,"30ace301-3d20-4c15-891e-7f451d3ccab7":0,"31171818-643d-4ae6-9a59-63a094fd5cdf":0,"34db7eeb-578e-404b-ade0-b5a81fcbc0aa":5.681818181818182,"34e478d9-da35-4f72-a05b-16fb35e968c5":3.4090909090909087,"36353e2a-4f6d-4eb1-9f8a-964cbbb32c38":4.545454545454546,"3a53fc20-f37c-4b2d-9e7f-e25cc0cc250c":0,"3b92893f-6dc0-4c7c-bbd7-fbb52af9743e":2.272727272727273,"42713eb5-5a69-4c97-906b-1afb20131a67":0,"46019c8a-a5a0-40a5-b0a7-cda819e4ba4d":4.545454545454546,"485b69b5-a452-4f6e-afa2-39106a402dba":1.1363636363636365,"4f469e3f-ae61-4c88-bf4c-e2c8aac01f6e":0,"4f93c731-1c76-4a32-bbd8-c97001c57118":1.1363636363636365,"4fb22fec-3a49-42a3-9922-bf2beea290f4":10.227272727272728,"59efb068-0be4-45bd-8fcb-be6c7a0b1fe5":0,"5a55ad5c-dfc4-45b2-99e4-4bacaa82ad69":1.1363636363636365,"5f0273ed-195e-4a0c-8b1a-339d392ff123":1.1363636363636365,"61f53c22-ff58-45d4-bfd5-80cc4a55ec42":9.090909090909092,"62cce2f9-8203-4c64-9dc9-ae73690280bf":1.1363636363636365,"64dd55a6-9b30-484c-821e-8a7bd85e9ebb":1.1363636363636365,"68eb2902-42f5-4703-8ce6-96afab054407":1.1363636363636365,"694e119c-ab30-4109-b186-9d46c25743c0":0,"74e80fef-6e9a-4ff3-944c-12828878827d":2.272727272727273,"7ae2aa0a-a7c6-49d3-8a87-1050aa0faa01":0,"7d93dff9-72a3-4a7b-b7c2-25dd60ed286d":3.4090909090909087,"82ef62b6-a691-4b1a-b2be-4d92a853a936":1.1363636363636365,"84fb4839-2869-4beb-8527-f4d0abed6eb7":10.227272727272728,"939e931f-1c38-47ab-a5b7-7753b3233abb":3.4090909090909087,"9636f9cd-0a36-44a3-a04a-b33ec8fc6ea0":1.1363636363636365,"98628033-2948-4f30-b6de-4364cb7a646e":4.545454545454546,"a33df330-7faa-4f3e-8750-c12003f18ebf":1.1363636363636365,"af55f019-02fd-4afa-b12c-455d42d5e758":4.545454545454546,"b14e6a89-9b85-4869-a087-9d70acd19c96":1.1363636363636365,"b1875a14-3a5f-4958-94be-3a5193139d09":1.1363636363636365,"b1a10077-957f-4c0a-9047-9cf02644aae6":2.272727272727273,"b823fa7c-6af9-48fa-891c-442b50bc0b8f":4.545454545454546,"b82a831d-20af-4088-86c3-443752add44b":0,"baa929a3-4b86-4e05-8b0f-df6140e569b2":1.1363636363636365,"bed10107-bd78-48c7-9bf0-49cb439a717e":1.1363636363636365,"c2390b3e-db44-4552-8ac6-894317ca9112":4.545454545454546,"c80fef5b-ea77-4a0b-b5aa-d3b259b13342":0,"c977820b-fb46-44ca-8949-4e7b2f708880":0,"cc1ab2f3-c10a-4eaa-9254-7fb8ceda30dc":2.272727272727273,"ccd9e0ff-28e7-4b03-a279-cf64509111e2":2.272727272727273,"ceeedf74-d74a-4d09-8f44-2fab5922459f":0,"cef6ac63-8028-427b-b231-03c0461dce20":5.681818181818182,"da2a9ec8-3846-4cc0-a3f9-818ab13dd66c":5.681818181818182,"da2f5ed4-2fa7-43d0-8c47-9d55079789ce":5.681818181818182,"e2108000-bf67-43ce-9ce4-3a9130a7474f":3.4090909090909087,"e680dcc4-dff9-492e-a0fe-b4fee5669458":0,"e89db39d-0194-4bbe-a0cf-86b8475f8049":6.8181818181818175,"e9032b77-9004-4b3c-a4ef-e69c5c6513fc":0,"e9cfdeaa-2334-4ebe-9d77-09a2f42f52dc":0,"ec3c1c5f-fbfb-4614-81c1-46f86c860574":0,"edb825c6-8759-42b4-85f0-c37f2c8d3de9":3.4090909090909087,"ee6e18d5-483c-43a3-b191-96402462b623":4.545454545454546,"f18dc17f-a0bf-42e0-9730-c27645b1ec27":4.545454545454546,"f65aefb1-5975-485e-a234-af35507e8973":2.272727272727273,"f865df14-142b-409d-a6fb-873098aba655":2.272727272727273,"fcc1fc8d-1885-4aa2-940c-af56a46414fa":0,"fccf36d5-8bfb-4a71-ab9b-0e1e1ba08b72":0,"fe537d93-5826-48ec-a1c5-8728d60b2167":1.1363636363636365},"keyword":{"015b8db1-b997-47bb-9b26-4bfd9c4a0e75":10.431349206349209,"02a46801-c4d8-42cc-9361-7e77e983157d":7.098809523809523,"0499d160-99ef-471b-bb04-9d69ad6f992f":0,"050f97de-684d-42e3-aec3-ac6f1075a51d":10.495436507936509,"05ab60cf-7664-46c0-9820-beccb36fba01":11.192857142857145,"064f3f8e-913a-496f-a972-5caa8e17c4b9":0,"06e64e99-3717-4646-89e7-941a787fba79":0,"079090cb-9ba8-419b-845c-7cccb6039da3":9.900793650793652,"093a1d08-58b2-4159-a5f1-976751af9284":0,"0abe8148-010b-4d95-ae4b-d9312fae1600":0,"0b89d1b7-2551-4206-ae03-09b504fe9edf":7.986349206349207,"0bdd1319-aef0-4867-a223-b623ee1772f4":9.330158730158733,"113a4504-4b64-497b-bd9f-77ab0d31f1bd":0,"15d5821e-650f-4f70-8969-da628eb37676":0,"187f3760-de81-4594-acba-0fdde35a48e9":0,"1bcf5418-adcb-4721-a559-0d505f27aa7a":0,"1ccd58ea-19a6-4bcc-a1cb-07bec0de2b7f":0,"1ef5ce37-4ea4-49a7-a110-74ad4ef63ec1":0,"21d91386-84de-46b1-b328-a2743b75e9f0":10.434523809523812,"2329ae1f-1062-4504-9ef1-45d9e5c0dd2e":10.498544973544973,"25508aa7-03c7-4132-a881-4ccb2e34a086":0,"27e7abac-0fea-4592-af25-acf1296d005d":8.631349206349206,"28f334ad-dba6-41a2-90c4-8c08f161640a":0,"2a3b42d7-3dd7-4e62-a7f9-282d686108cf":0,"2a898b76-5a6a-46fb-8470-566ef2adf07d":9.602976190476191,"2b90237b-9d8d-4ca4-99ab-3488457e123d":11.481111111111112,"30991cbc-af1e-4a29-b5ff-d5de5568f6e4":0,"30ace301-3d20-4c15-891e-7f451d3ccab7":9.857936507936508,"31171818-643d-4ae6-9a59-63a094fd5cdf":10.424497354497355,"34db7eeb-578e-404b-ade0-b5a81fcbc0aa":10.794047619047621,"34e478d9-da35-4f72-a05b-16fb35e968c5":10.470079365079366,"36353e2a-4f6d-4eb1-9f8a-964cbbb32c38":10.46244708994709,"3a53fc20-f37c-4b2d-9e7f-e25cc0cc250c":0,"3b92893f-6dc0-4c7c-bbd7-fbb52af9743e":9.251190476190477,"42713eb5-5a69-4c97-906b-1afb20131a67":10.318809523809524,"46019c8a-a5a0-40a5-b0a7-cda819e4ba4d":0,"485b69b5-a452-4f6e-afa2-39106a402dba":10.048650793650793,"4f469e3f-ae61-4c88-bf4c-e2c8aac01f6e":10.602373737373739,"4f93c731-1c76-4a32-bbd8-c97001c57118":8.282453102453102,"4fb22fec-3a49-42a3-9922-bf2beea290f4":10.224206349206348,"59efb068-0be4-45bd-8fcb-be6c7a0b1fe5":9.87166666666667,"5a55ad5c-dfc4-45b2-99e4-4bacaa82ad69":10.314166666666665,"5f0273ed-195e-4a0c-8b1a-339d392ff123":12.015873015873018,"61f53c22-ff58-45d4-bfd5-80cc4a55ec42":0,"62cce2f9-8203-4c64-9dc9-ae73690280bf":10.548174603174607,"64dd55a6-9b30-484c-821e-8a7bd85e9ebb":0,"68eb2902-42f5-4703-8ce6-96afab054407":0,"694e119c-ab30-4109-b186-9d46c25743c0":10.32857142857143,"74e80fef-6e9a-4ff3-944c-12828878827d":9.622023809523812,"7ae2aa0a-a7c6-49d3-8a87-1050aa0faa01":0,"7d93dff9-72a3-4a7b-b7c2-25dd60ed286d":12.374305555555559,"82ef62b6-a691-4b1a-b2be-4d92a853a936":0,"84fb4839-2869-4beb-8527-f4d0abed6eb7":0,"939e931f-1c38-47ab-a5b7-7753b3233abb":8.218849206349207,"9636f9cd-0a36-44a3-a04a-b33ec8fc6ea0":9.588492063492065,"98628033-2948-4f30-b6de-4364cb7a646e":11.3325,"a33df330-7faa-4f3e-8750-c12003f18ebf":9.82420634920635,"af55f019-02fd-4afa-b12c-455d42d5e758":8.726190476190476,"b14e6a89-9b85-4869-a087-9d70acd19c96":7.744576719576718,"b1875a14-3a5f-4958-94be-3a5193139d09":10.374867724867727,"b1a10077-957f-4c0a-9047-9cf02644aae6":10.128174603174603,"b823fa7c-6af9-48fa-891c-442b50bc0b8f":0,"b82a831d-20af-4088-86c3-443752add44b":0,"baa929a3-4b86-4e05-8b0f-df6140e569b2":8.171984126984126,"bed10107-bd78-48c7-9bf0-49cb439a717e":9.887301587301588,"c2390b3e-db44-4552-8ac6-894317ca9112":0,"c80fef5b-ea77-4a0b-b5aa-d3b259b13342":4.5170634920634924,"c977820b-fb46-44ca-8949-4e7b2f708880":0,"cc1ab2f3-c10a-4eaa-9254-7fb8ceda30dc":11.001785714285718,"ccd9e0ff-28e7-4b03-a279-cf64509111e2":10.973174603174607,"ceeedf74-d74a-4d09-8f44-2fab5922459f":12.526785714285715,"cef6ac63-8028-427b-b231-03c0461dce20":0,"da2a9ec8-3846-4cc0-a3f9-818ab13dd66c":11.158068783068781,"da2f5ed4-2fa7-43d0-8c47-9d55079789ce":10.035714285714286,"e2108000-bf67-43ce-9ce4-3a9130a7474f":0,"e680dcc4-dff9-492e-a0fe-b4fee5669458":9.376031746031746,"e89db39d-0194-4bbe-a0cf-86b8475f8049":10.406150793650797,"e9032b77-9004-4b3c-a4ef-e69c5c6513fc":0,"e9cfdeaa-2334-4ebe-9d77-09a2f42f52dc":12.71660052910053,"ec3c1c5f-fbfb-4614-81c1-46f86c860574":10.761243386243388,"edb825c6-8759-42b4-85f0-c37f2c8d3de9":9.627222222222223,"ee6e18d5-483c-43a3-b191-96402462b623":0,"f18dc17f-a0bf-42e0-9730-c27645b1ec27":10.741269841269844,"f65aefb1-5975-485e-a234-af35507e8973":10.77420634920635,"f865df14-142b-409d-a6fb-873098aba655":12.026322751322754,"fcc1fc8d-1885-4aa2-940c-af56a46414fa":12.502380952380951,"fccf36d5-8bfb-4a71-ab9b-0e1e1ba08b72":10.485000000000003,"fe537d93-5826-48ec-a1c5-8728d60b2167":11.42965608465608},"topic":["agent","issu","softwar","import","theorist"],"offsprings":[]},"5ffadf36-4496-4be6-b8a8-828fa37f7757":{"authors":["Carsten Rother","Vladimir Kolmogorov","Andrew Blake"],"references":["1317365d-c46d-4c09-8261-9d07404e4908","82eb55e6-39a8-4968-8be6-e2bfbb439a40"],"_id":"5ffadf36-4496-4be6-b8a8-828fa37f7757","abstract":"The problem of efficient, interactive foreground/background segmentation in still images is of great practical importance in image editing. Classical image segmentation tools use either texture (colour) information, e.g. Magic Wand, or edge (contrast) information, e.g. Intelligent Scissors. Recently, an approach based on optimization by graph-cut has been developed which successfully combines both types of information. In this paper we extend the graph-cut approach in three respects. First, we have developed a more powerful, iterative version of the optimisation. Secondly, the power of the iterative algorithm is used to simplify substantially the user interaction needed for a given quality of result. Thirdly, a robust algorithm for \"border matting\" has been developed to estimate simultaneously the alpha-matte around an object boundary and the colours of foreground pixels. We show that for moderately difficult examples the proposed method outperforms competitive tools.","title":"\"GrabCut\": interactive foreground extraction using iterated graph cuts","venue":"international conference on computer graphics and interactive techniques","year":2004,"__v":0,"citationCount":2085,"parents":{"1317365d-c46d-4c09-8261-9d07404e4908":10,"19d9d23c-339d-4026-aff7-c81ee3daa0d7":0,"1bcbede9-dcb1-4f5d-a88f-85d9176c5e27":10,"1c63e1d5-b963-455b-829d-e4f3eb63a36a":0,"789f15ca-dd46-4b74-8526-a73b9d6c3e14":20,"82eb55e6-39a8-4968-8be6-e2bfbb439a40":10,"88a1d409-c3f4-4252-b831-56518e6a179a":30,"dd8087bb-bde1-4b8e-8ef0-3f8d0aabce9b":10,"e8247450-abbc-48fe-a022-5f6579f9de14":10,"f3d57b86-0677-4dd8-bbf5-52efaeed9a82":0},"keyword":{"1317365d-c46d-4c09-8261-9d07404e4908":6.092857142857143,"19d9d23c-339d-4026-aff7-c81ee3daa0d7":8.05218253968254,"1bcbede9-dcb1-4f5d-a88f-85d9176c5e27":8.434920634920635,"1c63e1d5-b963-455b-829d-e4f3eb63a36a":8.845396825396826,"789f15ca-dd46-4b74-8526-a73b9d6c3e14":8.98531746031746,"82eb55e6-39a8-4968-8be6-e2bfbb439a40":6.625396825396825,"88a1d409-c3f4-4252-b831-56518e6a179a":11.038492063492063,"dd8087bb-bde1-4b8e-8ef0-3f8d0aabce9b":7.875198412698413,"e8247450-abbc-48fe-a022-5f6579f9de14":0,"f3d57b86-0677-4dd8-bbf5-52efaeed9a82":11.728703703703703},"topic":["inform","imag","develop","tool","segment"],"groups":[{"authors":["Andrew Blake","Carsten Rother","Matthew A. Brown","Patrick Pérez","Philip H. S. Torr"],"references":["1317365d-c46d-4c09-8261-9d07404e4908","19d9d23c-339d-4026-aff7-c81ee3daa0d7","1bcbede9-dcb1-4f5d-a88f-85d9176c5e27","5f70f18c-5f9c-442e-ae2c-ee6aadecab95","98cfeac3-9abb-4f5b-9705-158c3b7b9d3a"],"_id":"88a1d409-c3f4-4252-b831-56518e6a179a","abstract":"The problem of interactive foreground/background segmentation in still images is of great practical importance in image editing. The state of the art in interactive segmentation is probably represented by the graph cut algorithm of Boykov and Jolly (ICCV 2001). Its underlying model uses both colour and contrast information, together with a strong prior for region coherence. Estimation is performed by solving a graph cut problem for which very efficient algorithms have recently been developed. However the model depends on parameters which must be set by hand and the aim of this work is for those constants to be learned from image data. First, a generative, probabilistic formulation of the model is set out in terms of a \"Gaussian Mixture Markov Random Field\" (GMMRF). Secondly, a pseudolike- lihood algorithm is derived which jointly learns the colour mixture and coherence parameters for foreground and background respectively. Error rates for GMMRF segmentation are calculated throughout using a new image database, available on the web, with ground truth provided by a human segmenter. The graph cut al- gorithm, using the learned parameters, generates good object-segmentations with little interaction. However, pseudolikelihood learning proves to be frail, which limits the complexity of usable models, and hence also the achievable error rate.","title":"Interactive Image Segmentation Using an Adaptive GMMRF Model","venue":"european conference on computer vision","year":2004,"__v":0,"citationCount":295}],"offsprings":[]},"6018a516-8149-4bce-bc33-5449d86e58c2":{"authors":["David G. Lowe"],"references":[],"_id":"6018a516-8149-4bce-bc33-5449d86e58c2","abstract":"An object recognition system has been developed that uses a new class of local image features. The features are invariant to image scaling, translation, and rotation, and partially invariant to illumination changes and affine or 3D projection. These features share similar properties with neurons in inferior temporal cortex that are used for object recognition in primate vision. Features are efficiently detected through a staged filtering approach that identifies stable points in scale space. Image keys are created that allow for local geometric deformations by representing blurred image gradients in multiple orientation planes and at multiple scales. The keys are used as input to a nearest neighbor indexing method that identifies candidate object matches. Final verification of each match is achieved by finding a low residual least squares solution for the unknown model parameters. Experimental results show that robust object recognition can be achieved in cluttered partially occluded images with a computation time of under 2 seconds.","title":"Object recognition from local scale-invariant features","venue":"international conference on computer vision","year":1999,"__v":0,"citationCount":4272,"parents":{"01a0f825-a308-455b-93fc-e62defc0e3b0":7.6923076923076925,"035f8537-61a7-4c4f-b9fe-120f913a38b0":7.6923076923076925,"5dcd5949-faa9-4af3-8c6f-b285dd3b6566":0,"5ebbd1f5-dfe5-4eec-9883-b8b5efea366c":0,"5f1992df-975f-49e7-bd88-aee0740317cf":23.076923076923077,"78dd7c1a-bc00-4993-bd41-8e5da9a7fe5b":0,"8678514b-e795-4972-b891-c0d31d0d46cf":7.6923076923076925,"899de8c7-9cd9-4dd5-82f1-ad9acb801f8e":7.6923076923076925,"92551b72-99c5-4882-801c-a419e4eb705e":7.6923076923076925,"a00704dc-a2fa-4267-b7a6-427167d99521":0,"caeecc11-ec92-47d8-b112-c43b88dd4491":7.6923076923076925,"e46bb6ea-7b67-4edf-8cd4-a51ce64cff19":0,"ee11b7f0-4aeb-4e0f-a808-2126f1590163":7.6923076923076925},"keyword":{"01a0f825-a308-455b-93fc-e62defc0e3b0":13.09648148148148,"035f8537-61a7-4c4f-b9fe-120f913a38b0":11.034841269841275,"5dcd5949-faa9-4af3-8c6f-b285dd3b6566":12.433333333333332,"5ebbd1f5-dfe5-4eec-9883-b8b5efea366c":11.348888888888888,"5f1992df-975f-49e7-bd88-aee0740317cf":9.50952380952381,"78dd7c1a-bc00-4993-bd41-8e5da9a7fe5b":8.85410052910053,"8678514b-e795-4972-b891-c0d31d0d46cf":13.036111111111108,"899de8c7-9cd9-4dd5-82f1-ad9acb801f8e":10.764074074074074,"92551b72-99c5-4882-801c-a419e4eb705e":0,"a00704dc-a2fa-4267-b7a6-427167d99521":9.886984126984128,"caeecc11-ec92-47d8-b112-c43b88dd4491":12.252222222222224,"e46bb6ea-7b67-4edf-8cd4-a51ce64cff19":9.381296296296295,"ee11b7f0-4aeb-4e0f-a808-2126f1590163":9.652777777777779},"topic":["imag","object","featur","scale","recognit"],"groups":[{"authors":["Cordelia Schmid","Roger Mohr"],"references":["00909251-9935-44f3-94a1-629023b5015b","2fa2e5ba-11d3-4691-91e1-807b8ef7d8a5","34758e0a-3def-447b-9c5e-e82a206426b5","3bb5658b-131c-4072-9f9c-5f18a8272054","46da0145-fc17-4096-9624-4828cb32e116","4ea088d2-1d7e-433e-87ca-f31ad9b1e322","5dcd5949-faa9-4af3-8c6f-b285dd3b6566","5ebbd1f5-dfe5-4eec-9883-b8b5efea366c","643913d9-b72a-4ee3-9c3f-63c1249e9a3c","774c108a-4002-4123-861f-edd3b7ccb0e7","79bd9613-8976-41a1-b0b7-133b80b8477e","7a624075-0930-4956-8d8c-2910a80bdbca","7d5e97d2-5ebe-4be2-ac67-3c15fcde2c8d","8ec028ec-a8d0-4963-9e6f-231f0d6104ed","92551b72-99c5-4882-801c-a419e4eb705e","a8c76816-3583-47e8-98e1-18db34cb5b67","c083f584-daa0-4058-9a89-6b03409acfef","c38cebd1-1503-4321-ab02-28712487b9d3","c39c2ff9-1401-474d-917e-3776f528b204","d9b9f667-9d8a-4723-a6c4-c19b941acd46","dda837ee-640b-48b1-bb19-a00c5894f003"],"_id":"5f1992df-975f-49e7-bd88-aee0740317cf","abstract":"This paper addresses the problem of retrieving images from large image databases. The method is based on local grayvalue invariants which are computed at automatically detected interest points. A voting algorithm and semilocal constraints make retrieval possible. Indexing allows for efficient retrieval from a database of more than 1,000 images. Experimental results show correct retrieval in the case of partial visibility, similarity transformations, extraneous features, and small perspective deformations.","title":"Local grayvalue invariants for image retrieval","venue":"IEEE Transactions on Pattern Analysis and Machine Intelligence","year":1997,"__v":0,"citationCount":720}],"offsprings":["50252efa-a843-4cc6-a591-22f527ee3d6c","60285266-7da2-474e-b05a-b380c836f665","b944f77f-113b-4a02-ae5e-d4a124b8fd5b","ffa029cf-7240-4723-8339-51fac57f9f28","8d8e7d51-3223-4776-bf6a-40306774b8a1","b592576f-ff29-4a68-9b2f-8a8ad02e9c70","26316adf-569e-49bc-a289-c1ba311624f6","f225f439-4389-4312-a503-f8c1b0aa02de"]},"60285266-7da2-474e-b05a-b380c836f665":{"authors":["Jiri Matas","Ondrej Chum","M. Urban","Tomas Pajdla"],"references":["6018a516-8149-4bce-bc33-5449d86e58c2"],"_id":"60285266-7da2-474e-b05a-b380c836f665","abstract":"The wide-baseline stereo problem, i.e. the problem of establishing correspondences between a pair of images taken from different viewpoints is studied.#R##N##R##N#A new set of image elements that are put into correspondence, the so called extremal regions, is introduced. Extremal regions possess highly desirable properties: the set is closed under (1) continuous (and thus projective) transformation of image coordinates and (2) monotonic transformation of image intensities. An efficient (near linear complexity) and practically fast detection algorithm (near frame rate) is presented for an affinely invariant stable subset of extremal regions, the maximally stable extremal regions (MSER).#R##N##R##N#A new robust similarity measure for establishing tentative correspondences is proposed. The robustness ensures that invariants from multiple measurement regions (regions obtained by invariant constructions from extremal regions), some that are significantly larger (and hence discriminative) than the MSERs, may be used to establish tentative correspondences.#R##N##R##N#The high utility of MSERs, multiple measurement regions and the robust metric is demonstrated in wide-baseline experiments on image pairs from both indoor and outdoor scenes. Significant change of scale (3.5×), illumination conditions, out-of-plane rotation, occlusion, locally anisotropic scale change and 3D translation of the viewpoint are all present in the test problems. Good estimates of epipolar geometry (average distance from corresponding points to the epipolar line below 0.09 of the inter-pixel distance) are obtained.","title":"Robust wide-baseline stereo from maximally stable extremal regions","venue":"Image and Vision Computing","year":2004,"__v":0,"citationCount":1575,"parents":{"1dc84769-ff4c-4de6-a1c9-8d3af9299701":13.333333333333334,"2beaa150-6293-4f05-ba04-8e001993e766":0,"509e1ae2-768b-4417-bebe-d90cf1e0fdae":40,"5f1992df-975f-49e7-bd88-aee0740317cf":0,"5fadd790-4d5c-4a63-9d0c-39661713cf69":0,"6018a516-8149-4bce-bc33-5449d86e58c2":6.666666666666667,"63dbad19-24d8-4646-8e6a-65d85a5c2af3":40,"7a9f04e3-2883-4204-8fb3-7db1ce5ddc09":20,"7ab7b36d-baae-4b21-89fc-69389fcabc44":40,"8f9d2434-c08a-43e5-8152-d41f2784ddc2":0,"a0be9da4-c423-4f87-a387-822fe304aa03":0,"beb947f3-b954-4bb9-8379-e33474f07c6d":0,"ceb9e934-951e-47d6-a256-9ed1bb44b4b6":13.333333333333334,"e86ce68d-0d77-4f44-a212-518e7d8f394b":33.33333333333333,"ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d":46.666666666666664},"keyword":{"1dc84769-ff4c-4de6-a1c9-8d3af9299701":9.87074074074074,"2beaa150-6293-4f05-ba04-8e001993e766":9.1765873015873,"509e1ae2-768b-4417-bebe-d90cf1e0fdae":9.963888888888889,"5f1992df-975f-49e7-bd88-aee0740317cf":9.595238095238095,"5fadd790-4d5c-4a63-9d0c-39661713cf69":11.721693121693121,"6018a516-8149-4bce-bc33-5449d86e58c2":10.151388888888887,"63dbad19-24d8-4646-8e6a-65d85a5c2af3":10.81574074074074,"7a9f04e3-2883-4204-8fb3-7db1ce5ddc09":9.60084175084175,"7ab7b36d-baae-4b21-89fc-69389fcabc44":8.322222222222223,"8f9d2434-c08a-43e5-8152-d41f2784ddc2":10.051851851851852,"a0be9da4-c423-4f87-a387-822fe304aa03":9.823809523809524,"beb947f3-b954-4bb9-8379-e33474f07c6d":11.425423280423281,"ceb9e934-951e-47d6-a256-9ed1bb44b4b6":11.835185185185185,"e86ce68d-0d77-4f44-a212-518e7d8f394b":10.635714285714288,"ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d":9.062037037037038},"topic":["region","imag","extrem","correspond","robust"],"groups":[{"authors":["J. Matas","T. Obdrzalek","Ondrej Chum"],"references":["1dc84769-ff4c-4de6-a1c9-8d3af9299701","2beaa150-6293-4f05-ba04-8e001993e766","509e1ae2-768b-4417-bebe-d90cf1e0fdae","5dcd5949-faa9-4af3-8c6f-b285dd3b6566","5f1992df-975f-49e7-bd88-aee0740317cf","a0be9da4-c423-4f87-a387-822fe304aa03","cf01271b-a283-4435-8c6d-18c3017b6cd5","e86ce68d-0d77-4f44-a212-518e7d8f394b"],"_id":"63dbad19-24d8-4646-8e6a-65d85a5c2af3","abstract":"A novel procedure for establishing wide-baseline correspondence is introduced. Tentative correspondences are established by matching photometrically normalised colour measurements represented in a local affine frame. The affine frames are obtained by a number of affine invariant constructions on robustly detected, maximally stable extremal regions of data-dependent shape. Several processes for local affine frame construction are proposed and proved affine covariant. The potential of the proposed approach is demonstrated on demanding wide-baseline matching problems. Correspondence between two views taken from different viewpoints and camera orientations as well as at very different scales is reliably established. For the scale change present (a factor more than 3), the zoomed-in image covers less than 10% of the wider view.","title":"Local affine frames for wide-baseline stereo","venue":"international conference on pattern recognition","year":2002,"__v":0,"citationCount":27},{"authors":["Frederik Schaffalitzky","Andrew Zisserman"],"references":["0bf51909-709a-42f0-b7e0-7d4618cadcac","0d287faa-99bb-42df-98a7-24fcd601b9a4","167b13c2-1910-4749-bd59-889981448819","1dc84769-ff4c-4de6-a1c9-8d3af9299701","2beaa150-6293-4f05-ba04-8e001993e766","2df5e68b-eb98-4072-85b2-a97f7df3c9e0","4db6c10f-b1bb-49c2-b00c-bca8425aa979","4e7159fd-ca32-4dcd-953b-5e36a3bc9af4","509e1ae2-768b-4417-bebe-d90cf1e0fdae","5149d3c0-5ac9-47ba-9fb0-3d2ef757b0e8","5dcd5949-faa9-4af3-8c6f-b285dd3b6566","5dd7edb3-68c7-4efe-a167-890f6a11da15","5fda5f10-7c36-497e-b8b9-31e3a13daf6a","6a36661f-1030-4ccb-ab0f-90262434bbf5","7e7f30f6-5d7b-4e89-8ece-48e54721ff5f","85336978-6cf2-4e87-b949-d13e7a22cf9e","8ac30372-c1ac-48bc-8370-cc550fc41d91","a0be9da4-c423-4f87-a387-822fe304aa03","ab7b7857-e48d-4b94-8bfa-bc9ed61d5853","e86ce68d-0d77-4f44-a212-518e7d8f394b","ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d"],"_id":"7ab7b36d-baae-4b21-89fc-69389fcabc44","abstract":"There has been considerable success in automated reconstruction for image sequences where small baseline algorithms can be used to establish matches across a number of images. In contrast in the case of widely separated views, methods have generally been restricted to two or three views.In this paper we investigate the problem of establishing relative viewpoints given a large number of images where no ordering information is provided. A typical application would be where images are obtained from different sources or at different times: both the viewpoint (position, orientation, scale) and lighting conditions may vary significantly over the data set.Such a problem is not fundamentally amenable to exhaustive pair wise and triplet wide baseline matching because this would be prohibitively expensive as the number of views increases. Instead, we investiate how a combination of image invariants, covariants, and multiple view relations can be used in concord to enable efficient multiple view matching. The result is a matching algorithm which is linear in the number of views.The methods are illustrated on several real image data sets. The output enables an image based technique for navigating in a 3D scene, moving from one image to whichever image is the next most appropriate.","title":"Multi-view Matching for Unordered Image Sets, or How Do I Organize My Holiday Snaps?","venue":"european conference on computer vision","year":2002,"__v":0,"citationCount":267},{"authors":["Krystian Mikolajczyk","Cordelia Schmid"],"references":["0d287faa-99bb-42df-98a7-24fcd601b9a4","1c016f4a-20fb-44b5-84ad-96c10cb8e61b","1dc84769-ff4c-4de6-a1c9-8d3af9299701","2d6c9f60-ea78-44a8-b5f9-6964575dd196","34758e0a-3def-447b-9c5e-e82a206426b5","36800655-b2ff-4eb7-9070-c6be304c4baa","509e1ae2-768b-4417-bebe-d90cf1e0fdae","5149d3c0-5ac9-47ba-9fb0-3d2ef757b0e8","5f1992df-975f-49e7-bd88-aee0740317cf","6018a516-8149-4bce-bc33-5449d86e58c2","7a9f04e3-2883-4204-8fb3-7db1ce5ddc09","a0be9da4-c423-4f87-a387-822fe304aa03","cc6caca8-1564-4cf8-88a3-f0733c46e0dd","e86ce68d-0d77-4f44-a212-518e7d8f394b"],"_id":"ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d","abstract":"This paper presents a novel approach for detecting affine invariant interest points. Our method can deal with significant affine transformations including large scale changes. Such transformations introduce significant changes in the point location as well as in the scale and the shape of the neighbourhood of an interest point. Our approach allows to solve for these problems simultaneously. It is based on three key ideas : 1) The second moment matrix computed in a point can be used to normalize a region in an affine invariant way (skew and stretch). 2) The scale of the local structure is indicated by local extrema of normalized derivatives over scale. 3) An affine-adapted Harris detector determines the location of interest points. A multi-scale version of this detector is used for initialization. An iterative algorithm then modifies location, scale and neighbourhood of each point and converges to affine invariant points. For matching and recognition, the image is characterized by a set of affine invariant points; the affine transformation associated with each point allows the computation of an affine invariant descriptor which is also invariant to affine illumination changes. A quantitative comparison of our detector with existing ones shows a significant improvement in the presence of large affine deformations. Experimental results for wide baseline matching show an excellent performance in the presence of large perspective transformations including significant scale changes. Results for recognition are very good for a database with more than 5000 images.","title":"An Affine Invariant Interest Point Detector","venue":"european conference on computer vision","year":2002,"__v":0,"citationCount":560},{"authors":["Krystian Mikolajczyk","Cordelia Schmid"],"references":["1c016f4a-20fb-44b5-84ad-96c10cb8e61b","1dc84769-ff4c-4de6-a1c9-8d3af9299701","2beaa150-6293-4f05-ba04-8e001993e766","2d6c9f60-ea78-44a8-b5f9-6964575dd196","2fa2e5ba-11d3-4691-91e1-807b8ef7d8a5","36800655-b2ff-4eb7-9070-c6be304c4baa","457f15ab-c8e1-461d-b768-e044d88f1917","5c179e67-426d-402e-bfbf-1893059ab7cf","5f1992df-975f-49e7-bd88-aee0740317cf","6018a516-8149-4bce-bc33-5449d86e58c2","6b98de8f-f857-417c-9667-de061bd05872","7a9f04e3-2883-4204-8fb3-7db1ce5ddc09","a0be9da4-c423-4f87-a387-822fe304aa03"],"_id":"509e1ae2-768b-4417-bebe-d90cf1e0fdae","abstract":"This paper presents a new method for detecting scale invariant interest points. The method is based on two recent results on scale space: (1) Interest points can be adapted to scale and give repeatable results (geometrically stable). (2) Local extrema over scale of normalized derivatives indicate the presence of characteristic local structures. Our method first computes a multi-scale representation for the Harris interest point detector. We then select points at which a local measure (the Laplacian) is maximal over scales. This allows a selection of distinctive points for which the characteristic scale is known. These points are invariant to scale, rotation and translation as well as robust to illumination changes and limited changes of viewpoint. For indexing, the image is characterized by a set of scale invariant points; the scale associated with each point allows the computation of a scale invariant descriptor. Our descriptors are, in addition, invariant to image rotation, of affine illumination changes and robust to small perspective deformations. Experimental results for indexing show an excellent performance up to a scale factor of 4 for a database with more than 5000 images.","title":"Indexing based on scale invariant interest points","venue":"international conference on computer vision","year":2001,"__v":0,"citationCount":444},{"authors":["Frederik Schaffalitzky","Andrew Zisserman"],"references":["0ab71a43-a7d8-437c-83e0-6caf7523235f","0d287faa-99bb-42df-98a7-24fcd601b9a4","1dc84769-ff4c-4de6-a1c9-8d3af9299701","2733a789-f151-4385-9eea-a57a96a38e96","2958fc5c-15e8-45e7-8da8-d2e0fa46f0c7","2beaa150-6293-4f05-ba04-8e001993e766","34758e0a-3def-447b-9c5e-e82a206426b5","46f9aa23-5ece-4706-9795-95b68332542e","5149d3c0-5ac9-47ba-9fb0-3d2ef757b0e8","5b84e2fc-3ba7-42e7-8c21-dd98add58f6f","5dcd5949-faa9-4af3-8c6f-b285dd3b6566","5f1992df-975f-49e7-bd88-aee0740317cf","5ffd13e9-177c-45f9-8f77-40e6e8f8378d","6018a516-8149-4bce-bc33-5449d86e58c2","611be2d9-59fd-4dc3-82cb-c8e7c0ed2b03","797bd062-91e8-46a2-8d74-e20b1acae0f9","85336978-6cf2-4e87-b949-d13e7a22cf9e","a0be9da4-c423-4f87-a387-822fe304aa03"],"_id":"e86ce68d-0d77-4f44-a212-518e7d8f394b","abstract":"We describe and demonstrate a texture region descriptor which is invariant to affine geometric and photometric transformations, and insensitive to the shape of the texture region. It is applicable to texture patches which are locally planar and have stationary statistics. The novelty of the descriptor is that it is based on statistics aggregated over the region, resulting in richer and more stable descriptors than those computed at a point. Two texture matching applications of this descriptor are demonstrated: (1) it is used to automatically identify, regions of the same type of texture, but with varying surface pose, within a single image; (2) it is used to support wide baseline stereo, i.e. to enable the automatic computation of the epipolar geometry between two images acquired from quite separated viewpoints. Results are presented on several sets of real images.","title":"Viewpoint invariant texture matching and wide baseline stereo","venue":"international conference on computer vision","year":2001,"__v":0,"citationCount":99}],"offsprings":["50252efa-a843-4cc6-a591-22f527ee3d6c","6c38b3b4-7562-493d-a40c-fe70abf039a7","b944f77f-113b-4a02-ae5e-d4a124b8fd5b","ffa029cf-7240-4723-8339-51fac57f9f28","8d8e7d51-3223-4776-bf6a-40306774b8a1","f225f439-4389-4312-a503-f8c1b0aa02de"]},"62a46780-e1d9-4186-babe-6179735d785e":{"authors":["B. S. Manjunath","Wei-Ying Ma"],"references":[],"_id":"62a46780-e1d9-4186-babe-6179735d785e","abstract":"Image content based retrieval is emerging as an important research area with application to digital libraries and multimedia databases. The focus of this paper is on the image processing aspects and in particular using texture information for browsing and retrieval of large image data. We propose the use of Gabor wavelet features for texture analysis and provide a comprehensive experimental evaluation. Comparisons with other multiresolution texture features using the Brodatz texture database indicate that the Gabor features provide the best pattern retrieval accuracy. An application to browsing large air photos is illustrated.","title":"Texture features for browsing and retrieval of image data","venue":"IEEE Transactions on Pattern Analysis and Machine Intelligence","year":1996,"__v":0,"citationCount":1609,"parents":{"00909251-9935-44f3-94a1-629023b5015b":0,"02415fa8-1b54-4448-8220-7ef932a458f5":6.25,"180dea34-18e8-411d-932f-94e714651ac7":12.5,"1a040e34-192c-48da-89c4-a89f05cc6f9b":0,"264ad184-d48d-48da-ba36-54568ca48045":25,"3f0bc2c9-a5c2-4e4c-a4e9-7631e36bc6a3":0,"44a9fc14-1bf4-489e-add7-84abc2cb3561":0,"6c7f9856-a2e6-4a85-8955-66d9529d84f9":6.25,"70e86498-0a19-465c-8b73-49c2769b1a53":0,"894eb91a-ca79-4ae3-bd62-14e51d135de1":12.5,"bbf5e5eb-cd31-45b3-bfd9-d2fa07d4bd8b":0,"f0baaf8e-2483-4f3c-a4fa-39f3bc410f1b":31.25,"f3f1d5e7-ead9-43cd-a210-fbed039d66b1":31.25,"f4e766ac-f68f-4829-a5f8-bc8751f57948":12.5,"fb5b7aa5-5d68-45b9-be8b-36d217d940d7":0,"fc443443-416f-4fd5-ba46-17a06046711d":6.25},"keyword":{"00909251-9935-44f3-94a1-629023b5015b":7.528571428571429,"02415fa8-1b54-4448-8220-7ef932a458f5":11.2,"180dea34-18e8-411d-932f-94e714651ac7":9.753174603174601,"1a040e34-192c-48da-89c4-a89f05cc6f9b":8.404497354497353,"264ad184-d48d-48da-ba36-54568ca48045":9.301587301587302,"3f0bc2c9-a5c2-4e4c-a4e9-7631e36bc6a3":10.796031746031744,"44a9fc14-1bf4-489e-add7-84abc2cb3561":9.558333333333332,"6c7f9856-a2e6-4a85-8955-66d9529d84f9":10.347222222222223,"70e86498-0a19-465c-8b73-49c2769b1a53":11.091269841269842,"894eb91a-ca79-4ae3-bd62-14e51d135de1":10.565211640211643,"bbf5e5eb-cd31-45b3-bfd9-d2fa07d4bd8b":0,"f0baaf8e-2483-4f3c-a4fa-39f3bc410f1b":12.928571428571429,"f3f1d5e7-ead9-43cd-a210-fbed039d66b1":10.67222222222222,"f4e766ac-f68f-4829-a5f8-bc8751f57948":10.33366402116402,"fb5b7aa5-5d68-45b9-be8b-36d217d940d7":10.052380952380952,"fc443443-416f-4fd5-ba46-17a06046711d":10.26138888888889},"topic":["textur","retriev","imag","featur","provid"],"groups":[{"authors":["B. S. Manjunath","Chandra Shekhar","Rama Chellappa"],"references":["00909251-9935-44f3-94a1-629023b5015b","379eef1d-ed43-4149-96ff-20ffb6d55fd3","410f357b-1489-4a55-bf21-4c7c2805e353","44a9fc14-1bf4-489e-add7-84abc2cb3561","4bf46fff-1afd-4747-a549-b2d65f01423f","6c7f9856-a2e6-4a85-8955-66d9529d84f9","8747f12d-32f3-4156-a0b9-ad8d8c8df8f5","94a0b002-578e-4581-ad1d-8fc52a7052ea","aa4f1c11-6860-46ed-9188-ce3c10bcb4f3","ce9f1c0f-bf90-4be6-87bc-763c9ccb55eb","e389fa97-0461-4d42-876f-31d67c0690ca","fc443443-416f-4fd5-ba46-17a06046711d"],"_id":"264ad184-d48d-48da-ba36-54568ca48045","abstract":"Image feature detection is a fundamental issue in many intermediate level vision problems such as stereo, motion correspondence, image registration and object recognition. In this paper we present an approach to feature detection based on a scale-interaction model. This feature detector is responsive to short lines, line endings, corners and other such sharp changes in curvature. We provide extensive experimental results to demonstrate its potential applications to several image analysis problems.","title":"A new approach to image feature detection with applications","venue":"Pattern Recognition","year":1996,"__v":0,"citationCount":51},{"authors":["Wei-Ying Ma","B. S. Manjunath"],"references":["02415fa8-1b54-4448-8220-7ef932a458f5","1a040e34-192c-48da-89c4-a89f05cc6f9b","894eb91a-ca79-4ae3-bd62-14e51d135de1","da0078b4-31f8-486a-9031-d38bee37b7bd","f3f1d5e7-ead9-43cd-a210-fbed039d66b1","f4e766ac-f68f-4829-a5f8-bc8751f57948"],"_id":"f0baaf8e-2483-4f3c-a4fa-39f3bc410f1b","abstract":"This paper addresses two important issues related to texture pattern retrieval: feature extraction and similarity search. A Gabor feature representation for textured images is proposed, and its performance in pattern retrieval is evaluated on a large texture image database. These features compare favorably with other existing texture representations. A simple hybrid neural network algorithm is used to learn the similarity by simple clustering in the texture feature space. With learning similarity the performance of similar pattern retrieval improves significantly. An important aspect of this work is its application to real image data. Texture feature extraction with similarity learning is used to search through large aerial photographs. Feature clustering enables efficient search of the database as our experimental results indicate.","title":"Texture features and learning similarity","venue":"computer vision and pattern recognition","year":1996,"__v":0,"citationCount":110},{"authors":["Fang Liu","Rosalind W. Picard"],"references":["02415fa8-1b54-4448-8220-7ef932a458f5","30614910-26a5-495c-8bb7-0f723c47db69","3601cf80-3d14-4748-a20e-5cf3eff564af","56d6466f-28bc-429c-a969-9b9609398481","62a46780-e1d9-4186-babe-6179735d785e","70e86498-0a19-465c-8b73-49c2769b1a53","7b669cc1-a959-4dcf-b16f-f83688b24a95","8859baf1-a021-4832-9a3f-72e52aa10fc7","988e51d5-75de-4102-8659-b2d9a87db947","b2b35b2e-b052-4370-ae2b-9f172855d48b","bbf5e5eb-cd31-45b3-bfd9-d2fa07d4bd8b","e2fe7a5c-3b21-4b4f-bacf-be28af75689f","e3591fef-6edb-48d7-b499-ea416f0a8c72","f4e766ac-f68f-4829-a5f8-bc8751f57948","f61355ef-468d-4fff-a018-65550189e509","fb5b7aa5-5d68-45b9-be8b-36d217d940d7"],"_id":"f3f1d5e7-ead9-43cd-a210-fbed039d66b1","abstract":"One of the fundamental challenges in pattern recognition is choosing a set of features appropriate to a class of problems. In applications such as database retrieval, it is important that image features used in pattern comparison provide good measures of image perceptual similarities. We present an image model with a new set of features that address the challenge of perceptual similarity. The model is based on the 2D Wold decomposition of homogeneous random fields. The three resulting mutually orthogonal subfields have perceptual properties which can be described as \"periodicity,\" \"directionality,\" and \"randomness,\" approximating what are indicated to be the three most important dimensions of human texture perception. The method presented improves upon earlier Wold-based models in its tolerance to a variety of local inhomogeneities which arise in natural textures and its invariance under image transformation such as rotation. An image retrieval algorithm based on the new texture model is presented. Different types of image features are aggregated for similarity comparison by using a Bayesian probabilistic approach. The, effectiveness of the Wold model at retrieving perceptually similar natural textures is demonstrated in comparison to that of two other well-known pattern recognition methods. The Wold model appears to offer a perceptually more satisfying measure of pattern similarity while exceeding the performance of these other methods by traditional pattern recognition criteria. Examples of natural scene Wold texture modeling are also presented.","title":"Periodicity, directionality, and randomness: Wold features for image modeling and retrieval","venue":"IEEE Transactions on Pattern Analysis and Machine Intelligence","year":1996,"__v":0,"citationCount":240}],"offsprings":["750b0ac1-2ac9-4273-a9c8-baad11e26fcd"]},"65d5ccdc-7022-45b0-adf9-0385273b1283":{"authors":["Kalyanmoy Deb","Amrit Pratap","Sameer Agarwal","T. Meyarivan"],"references":[],"_id":"65d5ccdc-7022-45b0-adf9-0385273b1283","abstract":"Multi-objective evolutionary algorithms (MOEAs) that use non-dominated sorting and sharing have been criticized mainly for: (1) their O(MN/sup 3/) computational complexity (where M is the number of objectives and N is the population size); (2) their non-elitism approach; and (3) the need to specify a sharing parameter. In this paper, we suggest a non-dominated sorting-based MOEA, called NSGA-II (Non-dominated Sorting Genetic Algorithm II), which alleviates all of the above three difficulties. Specifically, a fast non-dominated sorting approach with O(MN/sup 2/) computational complexity is presented. Also, a selection operator is presented that creates a mating pool by combining the parent and offspring populations and selecting the best N solutions (with respect to fitness and spread). Simulation results on difficult test problems show that NSGA-II is able, for most problems, to find a much better spread of solutions and better convergence near the true Pareto-optimal front compared to the Pareto-archived evolution strategy and the strength-Pareto evolutionary algorithm - two other elitist MOEAs that pay special attention to creating a diverse Pareto-optimal front. Moreover, we modify the definition of dominance in order to solve constrained multi-objective problems efficiently. Simulation results of the constrained NSGA-II on a number of test problems, including a five-objective, seven-constraint nonlinear problem, are compared with another constrained multi-objective optimizer, and the much better performance of NSGA-II is observed.","title":"A fast and elitist multiobjective genetic algorithm: NSGA-II","venue":"IEEE Transactions on Evolutionary Computation","year":2002,"__v":0,"citationCount":6696,"parents":{"0cc8a4bb-8bb1-4526-ab1e-ae8ff4eccc6d":0,"1f5b4b74-9c6f-43c8-b490-447ae33d6157":0,"32db0b6b-7326-4bd6-9404-fa88ce9e0746":9.090909090909092,"8666d3c4-737c-48ef-b1bd-a65206527ba9":18.181818181818183,"96954e25-e35d-405a-a01a-cb017ddae552":9.090909090909092,"9cf177c9-48f2-4743-823d-950b096f0008":9.090909090909092,"b8be5256-00f7-4d83-bd1b-f13bfcdf0673":0,"be180e3d-b6df-41ad-a123-521a925a2f06":63.63636363636363,"c6553383-a300-4d96-b68a-398ea1b4389a":36.36363636363637,"da763e77-162f-4d3f-a172-10ec6f7bb599":0,"fbbddfd2-5b7c-4f54-8718-5fe1f58ebf33":0},"keyword":{"0cc8a4bb-8bb1-4526-ab1e-ae8ff4eccc6d":0,"1f5b4b74-9c6f-43c8-b490-447ae33d6157":0,"32db0b6b-7326-4bd6-9404-fa88ce9e0746":12.478463203463201,"8666d3c4-737c-48ef-b1bd-a65206527ba9":11.225488215488213,"96954e25-e35d-405a-a01a-cb017ddae552":10.61690476190476,"9cf177c9-48f2-4743-823d-950b096f0008":12.427287157287154,"b8be5256-00f7-4d83-bd1b-f13bfcdf0673":0,"be180e3d-b6df-41ad-a123-521a925a2f06":10.437265512265514,"c6553383-a300-4d96-b68a-398ea1b4389a":11.031825396825395,"da763e77-162f-4d3f-a172-10ec6f7bb599":12.53226551226551,"fbbddfd2-5b7c-4f54-8718-5fe1f58ebf33":9.822748917748918},"topic":["problem","nsgaii","nondomin","sort","multiobject"],"groups":[{"authors":["Kalyanmoy Deb"],"references":["0bae2284-926b-48ed-a9c1-74c3f4c08f88","0cc8a4bb-8bb1-4526-ab1e-ae8ff4eccc6d","0fa84405-e743-4119-af98-d7b5173dcb86","27681688-e444-4ce4-a802-a12cd89bb132","32db0b6b-7326-4bd6-9404-fa88ce9e0746","441667da-4d23-4862-b80d-36664fec7240","4e490ea3-7655-4bf9-a857-5e73a0295f51","54502992-c2e8-4780-8c09-b3dc3452b9a7","5c4cb3fc-9a25-4aa7-92ff-8044f9662c7d","6a6b9aa6-683f-4c7c-b06e-9c3018d10fd3","8666d3c4-737c-48ef-b1bd-a65206527ba9","8f6bea7e-2956-4d17-927d-968cd850d153","9cf177c9-48f2-4743-823d-950b096f0008","9f9332c3-e3f4-4b52-9786-2866c291f65f","a26620c4-e573-4dca-9144-cf2d203fe559","a4ba09d4-8c4e-4f36-b9d9-2c6b519de69a","b8be5256-00f7-4d83-bd1b-f13bfcdf0673","c73b926a-0c5a-4d32-b1b1-2b572f739965","d05c6688-882c-414f-8fcc-5ebe34a8b8f9","d9a65bd2-f9d9-41e2-a270-677c07d14931","da763e77-162f-4d3f-a172-10ec6f7bb599","e184cb56-a353-42dc-a4d3-8fc7648e63bd","f24c6cd0-7061-4952-8faa-e24922a37ba8","fbbddfd2-5b7c-4f54-8718-5fe1f58ebf33"],"_id":"be180e3d-b6df-41ad-a123-521a925a2f06","abstract":"In this paper, we study the problem features that may cause a multi-objective genetic algorithm (GA) difficulty in converging to the true Pareto-optimal front. Identification of such features helps us develop difficult test problems for multi-objective optimization. Multi-objective test problems are constructed from single-objective optimization problems, thereby allowing known difficult features of single-objective problems (such as multi-modality, isolation, or deception) to be directly transferred to the corresponding multi-objective problem. In addition, test problems having features specific to multi-objective optimization are also constructed. More importantly, these difficult test problems will enable researchers to test their algorithms for specific aspects of multi-objective optimization.","title":"Multi-objective genetic algorithms: Problem difficulties and construction of test problems","venue":"electronic commerce","year":1999,"__v":0,"citationCount":329},{"authors":["Carlos M. Fonseca","Peter J. Fleming"],"references":["0cc8a4bb-8bb1-4526-ab1e-ae8ff4eccc6d","32db0b6b-7326-4bd6-9404-fa88ce9e0746","6a6b9aa6-683f-4c7c-b06e-9c3018d10fd3","6c7024e9-1b71-4d52-b22e-9c9d759df4c6","6d882eb9-28bb-48ea-8156-213cca215014","7306abeb-0a3e-4373-b2c7-b88d616ca94c","858a4272-c06a-4689-82e8-ac71be713972","8666d3c4-737c-48ef-b1bd-a65206527ba9","957d98db-ad29-41a6-bc3a-f8d4e704228f","ae6768ce-3cf1-415b-a489-7d344bdbec5e","b50241aa-a437-4f1d-a5c2-3058f175787c","b8be5256-00f7-4d83-bd1b-f13bfcdf0673","c061069f-29d1-46d4-9974-dede8d5461f9","c6fed450-131c-49e9-bf77-321ff0ea38bf","d05c6688-882c-414f-8fcc-5ebe34a8b8f9"],"_id":"c6553383-a300-4d96-b68a-398ea1b4389a","abstract":"In optimization, multiple objectives and constraints cannot be handled independently of the underlying optimizer. Requirements such as continuity and differentiability of the cost surface add yet another conflicting element to the decision process. While \"better\" solutions should be rated higher than \"worse\" ones, the resulting cost landscape must also comply with such requirements. Evolutionary algorithms (EAs), which have found application in many areas not amenable to optimization by other methods, possess many characteristics desirable in a multiobjective optimizer, most notably the concerted handling of multiple candidate solutions. However, EAs are essentially unconstrained search techniques which require the assignment of a scalar measure of quality, or fitness, to such candidate solutions. After reviewing current revolutionary approaches to multiobjective and constrained optimization, the paper proposes that fitness assignment be interpreted as, or at least related to, a multicriterion decision process. A suitable decision making framework based on goals and priorities is subsequently formulated in terms of a relational operator, characterized, and shown to encompass a number of simpler decision strategies. Finally, the ranking of an arbitrary number of candidates is considered. The effect of preference changes on the cost surface seen by an EA is illustrated graphically for a simple problem. The paper concludes with the formulation of a multiobjective genetic algorithm based on the proposed decision strategy. Niche formation techniques are used to promote diversity among preferable candidates, and progressive articulation of preferences is shown to be possible as long as the genetic algorithm can recover from abrupt changes in the cost landscape.","title":"Multiobjective optimization and multiple constraint handling with evolutionary algorithms. I. A unified formulation","venue":"systems man and cybernetics","year":1998,"__v":0,"citationCount":360}],"offsprings":[]},"68faab18-b537-4f62-85cf-ddc9ef352362":{"authors":["Santo Fortunato"],"references":["7c90045b-63b9-4f29-82a0-bf7c914a6ef6","b0ef6e4d-4c86-4b10-9e0a-7b630ca8d7f7","c7e4e04b-45da-4bae-8c8a-d17ca0087361","ea8cd3d8-17ae-4a1e-8f83-1609469087af","feddae21-3c05-4743-80fa-b8e101f1b93f"],"_id":"68faab18-b537-4f62-85cf-ddc9ef352362","abstract":"The modern science of networks has brought significant advances to our understanding of complex systems. One of the most relevant features of graphs representing real systems is community structure, or clustering, i.e. the organization of vertices in clusters, with many edges joining vertices of the same cluster and comparatively few edges joining vertices of different clusters. Such clusters, or communities, can be considered as fairly independent compartments of a graph, playing a similar role like, e.g., the tissues or the organs in the human body. Detecting communities is of great importance in sociology, biology and computer science, disciplines where systems are often represented as graphs. This problem is very hard and not yet satisfactorily solved, despite the huge effort of a large interdisciplinary community of scientists working on it over the past few years. We will attempt a thorough exposition of the topic, from the definition of the main elements of the problem, to the presentation of most methods developed, with a special focus on techniques designed by statistical physicists, from the discussion of crucial issues like the significance of clustering and how methods should be tested and compared against each other, to the description of applications to real networks.","title":"Community detection in graphs","venue":"Physics Reports","year":2010,"__v":0,"citationCount":2124,"parents":{"043346ea-c1fe-4719-b86e-57d2adaae648":4.310344827586207,"0ad2acb7-43ee-424d-b4d2-472e167a9c84":1.7241379310344827,"0c120a60-a306-4618-96ba-b1aec7a7314e":1.7241379310344827,"0c60f247-abf1-4fbf-92fc-39407c5ed556":1.7241379310344827,"0cdb081e-f2db-49d9-8c65-45cbcc948265":0,"0d6a426e-79ad-4747-b0c6-537078ba6e70":7.758620689655173,"1035fd34-a47d-4c70-93f7-a7b3b20e5b60":0,"106ac945-1fd6-4abd-b059-1b56ca491d0a":0,"10d125fa-b98d-4942-8270-6c63ce1c5890":0,"1431d9db-19ca-45f8-9ee7-e8e23ca316a0":0,"15c30ca5-6af6-4acf-b8c5-f2c0e18e6ad8":0,"15ec420c-7fb8-4950-8ba5-5149c8c78749":1.7241379310344827,"1721b1de-cf3d-4ebd-8229-80a79ab29747":2.586206896551724,"18819165-7f73-4da1-9bf2-792c258be677":4.310344827586207,"1b41d9a0-3857-4fb6-b7ba-d39da73c04dd":0,"1d383765-fe50-4493-9714-3df0c5e05057":0.8620689655172413,"207c393f-ae4c-4426-bdf5-195458a41abd":0,"24065196-bfc0-44b2-998c-4f3c4b5027b4":0.8620689655172413,"26cd1d0d-331d-499a-8d35-a501e6af9200":0,"26e47743-414d-424d-bfa3-d51e253df655":1.7241379310344827,"287df3fe-6f46-4071-8ab5-99274b9887b1":1.7241379310344827,"2ae42d91-fc91-472f-bd7f-426f09e6f912":4.310344827586207,"2b3f5e5a-36cf-41ab-b9e0-a69f792866f2":5.172413793103448,"2f082a6f-9356-45f8-b4ff-4409c48ba0ec":0.8620689655172413,"3044fef1-b4aa-46ca-a1e2-7079b4583362":3.4482758620689653,"32d9efda-7b21-4106-bc1a-47b09e81a27c":0,"33716924-a3c8-407b-8448-0398eaf90bc1":0,"35cad820-9f36-41ac-86e7-b14bf90e75ba":1.7241379310344827,"3f442f61-f9e7-4ed3-aee5-7bf67f1f3b7b":0,"3f4cc95c-5f47-4031-8671-e23ff4fe2ed2":0,"3fe346d3-5a15-4d14-9363-24f402d474a3":0,"414b741a-a47c-40f0-b37a-6b102f442e8c":7.758620689655173,"42fa459d-f2db-47d3-9855-bc6fcfd7204b":0,"440ab2d5-3af6-4a67-9ddb-d1a7b6693063":0.8620689655172413,"48d388af-7e23-4b8f-b245-c92c1f262f42":0.8620689655172413,"4cedadea-4628-455a-8824-17eab0dc790c":2.586206896551724,"516632de-65d2-4342-b358-3c154de44776":0,"5215ff24-af48-4682-8c59-fe9db5fd4515":2.586206896551724,"53649a4b-3941-4221-ae31-c0334a1cfac4":0,"56aacaea-4377-41f7-9e73-0dcdd25984fc":7.758620689655173,"597ecf84-4084-4057-a40d-30988ef74121":0,"5e3020bb-324a-4926-963c-36f66eda1b27":0,"5f1a52f2-faca-45ab-bb82-8d459d1c77ce":0,"608ab163-0fbf-4c6e-bf21-29b3145bae2a":2.586206896551724,"60ef3852-fa16-44bf-9434-9909268ba5d8":0,"63ec4f55-8f3b-431e-88e5-87c04caa7e9f":0.8620689655172413,"646fd5f1-1f89-40a7-b605-8402513ae682":0.8620689655172413,"68f5a094-18a6-4250-85de-214f7840bc6b":0,"6e49eac6-161b-4254-9529-b792395ba1fb":2.586206896551724,"748bce90-b5d8-4759-b733-c75b4e57bfea":2.586206896551724,"756e5f32-dade-48dc-9271-5ca96ce73d0f":0.8620689655172413,"75830a91-6bd3-47b9-a517-5e1e0b68bf04":0,"76395316-a3bc-43c9-9113-cf11eff1ccbf":0,"764a3426-aaea-4b4a-a692-a6cc215fe34e":2.586206896551724,"772e015f-5e9e-4b55-9b08-394ff78f3529":0,"79433674-7ae3-4613-9914-2db2b16fd01f":3.4482758620689653,"7a1a3bf9-8c23-4c13-8c8e-85b79ad6143e":1.7241379310344827,"7c90045b-63b9-4f29-82a0-bf7c914a6ef6":4.310344827586207,"7d4be6a0-afa0-4c75-a3dd-e04b3cd0b874":0,"86b69247-af69-4276-a105-b5e821559946":0.8620689655172413,"881ffdab-0f89-4a72-8655-8bc3a3fc6577":0.8620689655172413,"8e245630-549b-4b1c-afe7-cdf466295f32":0,"90916b32-f4d4-44a6-a6f2-c6e6398703a2":0,"9167c2df-4b86-4b47-98c9-3807261c343a":0,"940e7ab9-c036-4e6a-8942-b90dc6b9c339":0.8620689655172413,"9438a773-c15c-4ef2-a97c-54f643ce6082":0.8620689655172413,"993143bf-fe78-4033-b59b-cba01cc3861e":0,"9ce54ae7-19f5-423e-bf83-5e0eb187d460":10.344827586206897,"9dbdc129-b8f3-4712-9c95-406bc8911bee":0,"9df2aa63-11f9-4a64-b6c4-1fef1f8cde91":3.4482758620689653,"a2fa78b2-9eb2-4d93-b2f5-f33579e4cbdf":0,"a86e0c46-2085-4d1f-a712-a03be726ae4e":1.7241379310344827,"aa35f1f9-396c-4909-b303-493b5cb44b89":12.068965517241379,"ab7366d4-1ed3-4673-a39c-ac67c54f735e":0,"b09f2059-32bd-444f-9919-49ef62b99691":0,"b0afa6ff-6528-4701-800b-5dc0b5411b0c":0,"b0ef6e4d-4c86-4b10-9e0a-7b630ca8d7f7":6.896551724137931,"b6af7a3b-1d82-44df-94e9-1297c7c6c542":0.8620689655172413,"b6c8bcad-70a8-4d76-82f7-109c0439a645":9.482758620689655,"b7fb5dc9-9016-436d-a365-55c52e3c3e62":0,"b80d9c8a-c008-495f-a1e3-01da69ec54d9":1.7241379310344827,"b92f5495-64f2-4712-80ae-ceaf751618d0":4.310344827586207,"baeb6078-a7bb-4f89-9807-c67791def7a5":0.8620689655172413,"c5ec6a5c-ff8d-494d-b093-66383861fe51":0.8620689655172413,"c6765391-ea04-40cc-ac43-a37261c94cc1":2.586206896551724,"c7e4e04b-45da-4bae-8c8a-d17ca0087361":0,"c8678358-846c-457d-a775-b74aa2f56b8d":3.4482758620689653,"ca25acbc-7ec2-453c-911f-077a06d76ebf":0.8620689655172413,"cc248270-c3d6-4613-8b30-df4a066a5cb9":0,"d9a1466a-0e41-4eb7-b751-d7c282b53460":1.7241379310344827,"dc88af6e-158d-4a2e-badd-2afaf5c95648":0,"dd90433d-a428-4ff1-833d-050702f7699c":4.310344827586207,"e2a97ffb-90b0-4f1a-b01d-b15a77a820de":0,"e6d5b127-aa36-4add-971a-aa4dc2689baa":0,"e75d428e-9877-4d52-8660-1bb3bf0b9f5e":0,"e96828f8-70d7-4df8-a75a-5cf81e168601":0,"ea8cd3d8-17ae-4a1e-8f83-1609469087af":0,"eb141c7c-b6d9-48d4-8e96-150d4f59bac5":0,"ecd9f620-88b9-4f98-95a5-cca95d2722ff":6.0344827586206895,"ee86124f-174f-47ad-944a-52ba1a637d22":1.7241379310344827,"ef2e097d-9060-4e66-ab5a-ba742240f5e2":0.8620689655172413,"f0b1c421-218b-484a-85d2-162058a63b60":0,"f15b19f2-4b37-454c-851e-a71cccf3e53a":0,"f246f6f3-f5c6-4cb8-a08f-1ca8d0d63cf8":0,"f48eee6b-7421-48bc-92ea-b571bef6af20":0.8620689655172413,"f5ab3435-0ea9-4db2-82db-f42f12df9aa6":3.4482758620689653,"f5de6b41-0df8-4270-8211-a67a081dad45":0,"f6326c6d-6313-43fb-a028-5bfe5cf3505c":2.586206896551724,"f6a607ee-8043-4137-a6e6-070108fff1dd":4.310344827586207,"f780dea5-4a66-4de2-8288-f6a1e9ae0d23":2.586206896551724,"f972e14c-debe-452d-a9ba-aa7156923a76":1.7241379310344827,"fa0e3a65-c218-4eff-bf8b-cf284855bb32":0.8620689655172413,"fb244d98-60f6-40f8-8c42-a233dfa5843f":0,"fbdbd8f0-1b0d-4eff-bb82-cdb6fee483e9":2.586206896551724,"fc93dd72-b331-4f0c-8b54-4b52deaf6764":0,"feddae21-3c05-4743-80fa-b8e101f1b93f":0},"keyword":{"043346ea-c1fe-4719-b86e-57d2adaae648":10.276719576719575,"0ad2acb7-43ee-424d-b4d2-472e167a9c84":9.79920634920635,"0c120a60-a306-4618-96ba-b1aec7a7314e":9.729761904761906,"0c60f247-abf1-4fbf-92fc-39407c5ed556":0,"0cdb081e-f2db-49d9-8c65-45cbcc948265":0,"0d6a426e-79ad-4747-b0c6-537078ba6e70":9.644801587301588,"1035fd34-a47d-4c70-93f7-a7b3b20e5b60":9.156798941798943,"106ac945-1fd6-4abd-b059-1b56ca491d0a":10.392857142857142,"10d125fa-b98d-4942-8270-6c63ce1c5890":8.442063492063491,"1431d9db-19ca-45f8-9ee7-e8e23ca316a0":10.368783068783069,"15c30ca5-6af6-4acf-b8c5-f2c0e18e6ad8":7.5507936507936515,"15ec420c-7fb8-4950-8ba5-5149c8c78749":9.91031746031746,"1721b1de-cf3d-4ebd-8229-80a79ab29747":1.4555555555555555,"18819165-7f73-4da1-9bf2-792c258be677":9.312830687830688,"1b41d9a0-3857-4fb6-b7ba-d39da73c04dd":9.564021164021163,"1d383765-fe50-4493-9714-3df0c5e05057":7.1761904761904765,"207c393f-ae4c-4426-bdf5-195458a41abd":0,"24065196-bfc0-44b2-998c-4f3c4b5027b4":9.094523809523809,"26cd1d0d-331d-499a-8d35-a501e6af9200":11.137632275132272,"26e47743-414d-424d-bfa3-d51e253df655":9.89457671957672,"287df3fe-6f46-4071-8ab5-99274b9887b1":0,"2ae42d91-fc91-472f-bd7f-426f09e6f912":10.518386243386244,"2b3f5e5a-36cf-41ab-b9e0-a69f792866f2":10.076349206349207,"2f082a6f-9356-45f8-b4ff-4409c48ba0ec":10.670634920634921,"3044fef1-b4aa-46ca-a1e2-7079b4583362":9.505555555555556,"32d9efda-7b21-4106-bc1a-47b09e81a27c":12.40978835978836,"33716924-a3c8-407b-8448-0398eaf90bc1":9.220634920634918,"35cad820-9f36-41ac-86e7-b14bf90e75ba":8.850158730158732,"3f442f61-f9e7-4ed3-aee5-7bf67f1f3b7b":12.410317460317462,"3f4cc95c-5f47-4031-8671-e23ff4fe2ed2":0,"3fe346d3-5a15-4d14-9363-24f402d474a3":10.678571428571427,"414b741a-a47c-40f0-b37a-6b102f442e8c":10.412698412698411,"42fa459d-f2db-47d3-9855-bc6fcfd7204b":8.700992063492063,"440ab2d5-3af6-4a67-9ddb-d1a7b6693063":0,"48d388af-7e23-4b8f-b245-c92c1f262f42":11.227777777777778,"4cedadea-4628-455a-8824-17eab0dc790c":11.58505291005291,"516632de-65d2-4342-b358-3c154de44776":0,"5215ff24-af48-4682-8c59-fe9db5fd4515":10.344603174603176,"53649a4b-3941-4221-ae31-c0334a1cfac4":10.148544973544972,"56aacaea-4377-41f7-9e73-0dcdd25984fc":8.050793650793652,"597ecf84-4084-4057-a40d-30988ef74121":9.224126984126984,"5e3020bb-324a-4926-963c-36f66eda1b27":9.462698412698414,"5f1a52f2-faca-45ab-bb82-8d459d1c77ce":8.926190476190477,"608ab163-0fbf-4c6e-bf21-29b3145bae2a":8.20968253968254,"60ef3852-fa16-44bf-9434-9909268ba5d8":8.935714285714287,"63ec4f55-8f3b-431e-88e5-87c04caa7e9f":10.065079365079367,"646fd5f1-1f89-40a7-b605-8402513ae682":8.925396825396827,"68f5a094-18a6-4250-85de-214f7840bc6b":10.42632275132275,"6e49eac6-161b-4254-9529-b792395ba1fb":10.620238095238097,"748bce90-b5d8-4759-b733-c75b4e57bfea":9.03904761904762,"756e5f32-dade-48dc-9271-5ca96ce73d0f":8.818253968253968,"75830a91-6bd3-47b9-a517-5e1e0b68bf04":8.062857142857144,"76395316-a3bc-43c9-9113-cf11eff1ccbf":8.28941798941799,"764a3426-aaea-4b4a-a692-a6cc215fe34e":9.563492063492065,"772e015f-5e9e-4b55-9b08-394ff78f3529":10.409656084656087,"79433674-7ae3-4613-9914-2db2b16fd01f":8.933333333333334,"7a1a3bf9-8c23-4c13-8c8e-85b79ad6143e":9.27936507936508,"7c90045b-63b9-4f29-82a0-bf7c914a6ef6":7.928902116402115,"7d4be6a0-afa0-4c75-a3dd-e04b3cd0b874":9.788095238095238,"86b69247-af69-4276-a105-b5e821559946":10.318386243386243,"881ffdab-0f89-4a72-8655-8bc3a3fc6577":9.143253968253967,"8e245630-549b-4b1c-afe7-cdf466295f32":11.926388888888889,"90916b32-f4d4-44a6-a6f2-c6e6398703a2":10.821428571428571,"9167c2df-4b86-4b47-98c9-3807261c343a":9.552910052910054,"940e7ab9-c036-4e6a-8942-b90dc6b9c339":9.584126984126986,"9438a773-c15c-4ef2-a97c-54f643ce6082":10.677275132275133,"993143bf-fe78-4033-b59b-cba01cc3861e":10.780714285714286,"9ce54ae7-19f5-423e-bf83-5e0eb187d460":10.543650793650796,"9dbdc129-b8f3-4712-9c95-406bc8911bee":5.508412698412699,"9df2aa63-11f9-4a64-b6c4-1fef1f8cde91":9.89642857142857,"a2fa78b2-9eb2-4d93-b2f5-f33579e4cbdf":11.411640211640211,"a86e0c46-2085-4d1f-a712-a03be726ae4e":11.022222222222224,"aa35f1f9-396c-4909-b303-493b5cb44b89":9.495238095238097,"ab7366d4-1ed3-4673-a39c-ac67c54f735e":8.80952380952381,"b09f2059-32bd-444f-9919-49ef62b99691":9.966666666666667,"b0afa6ff-6528-4701-800b-5dc0b5411b0c":10.042857142857143,"b0ef6e4d-4c86-4b10-9e0a-7b630ca8d7f7":8.606349206349204,"b6af7a3b-1d82-44df-94e9-1297c7c6c542":9.211904761904762,"b6c8bcad-70a8-4d76-82f7-109c0439a645":10.168253968253968,"b7fb5dc9-9016-436d-a365-55c52e3c3e62":8.73968253968254,"b80d9c8a-c008-495f-a1e3-01da69ec54d9":8.357539682539683,"b92f5495-64f2-4712-80ae-ceaf751618d0":7.84920634920635,"baeb6078-a7bb-4f89-9807-c67791def7a5":8.883465608465608,"c5ec6a5c-ff8d-494d-b093-66383861fe51":10.424404761904762,"c6765391-ea04-40cc-ac43-a37261c94cc1":10.74063492063492,"c7e4e04b-45da-4bae-8c8a-d17ca0087361":7.288359788359789,"c8678358-846c-457d-a775-b74aa2f56b8d":11.507936507936508,"ca25acbc-7ec2-453c-911f-077a06d76ebf":10.311243386243385,"cc248270-c3d6-4613-8b30-df4a066a5cb9":10.439285714285715,"d9a1466a-0e41-4eb7-b751-d7c282b53460":10.704761904761906,"dc88af6e-158d-4a2e-badd-2afaf5c95648":11.016005291005293,"dd90433d-a428-4ff1-833d-050702f7699c":9.303968253968256,"e2a97ffb-90b0-4f1a-b01d-b15a77a820de":9.108941798941798,"e6d5b127-aa36-4add-971a-aa4dc2689baa":10.434497354497356,"e75d428e-9877-4d52-8660-1bb3bf0b9f5e":10.37031746031746,"e96828f8-70d7-4df8-a75a-5cf81e168601":10.07714285714286,"ea8cd3d8-17ae-4a1e-8f83-1609469087af":11.65321669071669,"eb141c7c-b6d9-48d4-8e96-150d4f59bac5":9.9288961038961,"ecd9f620-88b9-4f98-95a5-cca95d2722ff":9.76547619047619,"ee86124f-174f-47ad-944a-52ba1a637d22":8.112698412698412,"ef2e097d-9060-4e66-ab5a-ba742240f5e2":9.211666666666668,"f0b1c421-218b-484a-85d2-162058a63b60":10.696428571428573,"f15b19f2-4b37-454c-851e-a71cccf3e53a":6.193650793650794,"f246f6f3-f5c6-4cb8-a08f-1ca8d0d63cf8":10.465912698412698,"f48eee6b-7421-48bc-92ea-b571bef6af20":11.698280423280423,"f5ab3435-0ea9-4db2-82db-f42f12df9aa6":8.075793650793651,"f5de6b41-0df8-4270-8211-a67a081dad45":10.258862433862433,"f6326c6d-6313-43fb-a028-5bfe5cf3505c":9.481349206349206,"f6a607ee-8043-4137-a6e6-070108fff1dd":10.781481481481478,"f780dea5-4a66-4de2-8288-f6a1e9ae0d23":10.268650793650794,"f972e14c-debe-452d-a9ba-aa7156923a76":11.643055555555554,"fa0e3a65-c218-4eff-bf8b-cf284855bb32":9.011111111111113,"fb244d98-60f6-40f8-8c42-a233dfa5843f":9.289021164021165,"fbdbd8f0-1b0d-4eff-bb82-cdb6fee483e9":10.197023809523808,"fc93dd72-b331-4f0c-8b54-4b52deaf6764":10.90095238095238,"feddae21-3c05-4743-80fa-b8e101f1b93f":11.117989417989417},"topic":["cluster","commun","vertic","system","graph"],"offsprings":[]},"69b9ef96-11d5-49b0-9ae3-492763e02ca8":{"authors":["Joel A. Tropp","Anna C. Gilbert"],"references":["6ff01654-66d1-49c7-b526-1c8ed7fa893a","71a18de9-e543-4337-ab7a-3db31d9f8c00","a53a3dda-b003-4d5c-96b1-e9afd8e35692","f56b877b-4060-4754-b303-e8140968544c"],"_id":"69b9ef96-11d5-49b0-9ae3-492763e02ca8","abstract":"This paper demonstrates theoretically and empirically that a greedy algorithm called orthogonal matching pursuit (OMP) can reliably recover a signal with m nonzero entries in dimension d given O(m ln d) random linear measurements of that signal. This is a massive improvement over previous results, which require  O (m 2 ) measurements. The new results for OMP are comparable with recent results for another approach called basis pursuit (BP). In some settings, the OMP algorithm is faster and easier to implement, so it is an attractive alternative to BP for signal recovery problems.","title":"Signal Recovery From Random Measurements Via Orthogonal Matching Pursuit","venue":"IEEE Transactions on Information Theory","year":2007,"__v":0,"citationCount":2067,"parents":{"0bb77e7f-bfc4-4d0d-873a-3d6d3c28b316":29.411764705882355,"0cd544e3-4888-4707-8a20-4a6780a71925":0,"15e40102-1512-4446-9850-c8102506cbd4":5.88235294117647,"449bfdfc-f916-422c-ac0d-ebfdd2ab773a":11.76470588235294,"6ea0a74d-1f54-4187-a299-7f6706432563":41.17647058823529,"6ff01654-66d1-49c7-b526-1c8ed7fa893a":23.52941176470588,"71a18de9-e543-4337-ab7a-3db31d9f8c00":17.647058823529413,"8fed7067-5f57-4f15-88cc-c948bcdd83f4":0,"9ec51dea-b1bb-49cc-9e36-9a13dfcadd52":5.88235294117647,"a53a3dda-b003-4d5c-96b1-e9afd8e35692":5.88235294117647,"bb3c38fa-c2b0-4d4f-8c9d-ca1884343474":0,"c380b798-6583-4821-9613-0a9731b1ced1":0,"de4fea1d-2739-4e0f-b5a3-08f0df58d787":0,"e43d02bf-6474-4b51-b481-fe1b09b29406":41.17647058823529,"eacf08f1-1e8b-44ee-90b5-234724ae8355":5.88235294117647,"f56b877b-4060-4754-b303-e8140968544c":35.294117647058826,"fd7205d5-656f-4fda-a9dc-3851a2c1da6f":11.76470588235294},"keyword":{"0bb77e7f-bfc4-4d0d-873a-3d6d3c28b316":10.245793650793651,"0cd544e3-4888-4707-8a20-4a6780a71925":9.857619047619048,"15e40102-1512-4446-9850-c8102506cbd4":12.619206349206348,"449bfdfc-f916-422c-ac0d-ebfdd2ab773a":10.829126984126985,"6ea0a74d-1f54-4187-a299-7f6706432563":10.65080808080808,"6ff01654-66d1-49c7-b526-1c8ed7fa893a":7.881269841269841,"71a18de9-e543-4337-ab7a-3db31d9f8c00":11.075,"8fed7067-5f57-4f15-88cc-c948bcdd83f4":9.372910052910054,"9ec51dea-b1bb-49cc-9e36-9a13dfcadd52":11.761587301587303,"a53a3dda-b003-4d5c-96b1-e9afd8e35692":10.75984126984127,"bb3c38fa-c2b0-4d4f-8c9d-ca1884343474":9.098571428571429,"c380b798-6583-4821-9613-0a9731b1ced1":10.735714285714286,"de4fea1d-2739-4e0f-b5a3-08f0df58d787":9.415873015873016,"e43d02bf-6474-4b51-b481-fe1b09b29406":11.464973544973546,"eacf08f1-1e8b-44ee-90b5-234724ae8355":0,"f56b877b-4060-4754-b303-e8140968544c":11.342063492063492,"fd7205d5-656f-4fda-a9dc-3851a2c1da6f":12.610396825396824},"topic":["signal","result","omp","pursuit","measur"],"groups":[{"authors":["Deanna Needell","Roman Vershynin"],"references":["000b6195-a08b-4775-86fc-e6787547bd3e","05c85ace-c998-47cd-a285-f6ecfd72004d","154ba112-2438-4621-a4ae-0110895207c0","5da96caa-c879-4877-8d55-771137f6643b","69b9ef96-11d5-49b0-9ae3-492763e02ca8","6ff01654-66d1-49c7-b526-1c8ed7fa893a","71a18de9-e543-4337-ab7a-3db31d9f8c00","88bf340b-5d4a-4446-9758-73e0c6e4ce86","941f432f-1ea2-477e-86c4-4f7bebd8cb70","a53a3dda-b003-4d5c-96b1-e9afd8e35692","dbb8606e-3419-45c0-84ee-8872c86fdcd8","e27ac60c-b7e6-4bcd-bf8c-5edcddf5d6b7","eacf08f1-1e8b-44ee-90b5-234724ae8355","f56b877b-4060-4754-b303-e8140968544c"],"_id":"0bb77e7f-bfc4-4d0d-873a-3d6d3c28b316","abstract":"This paper seeks to bridge the two major algorithmic approaches to sparse signal recovery from an incomplete set of linear measurements—L1-minimization methods and iterative methods (Matching Pursuits). We find a simple regularized version of Orthogonal Matching Pursuit (ROMP) which has advantages of both approaches: the speed and transparency of OMP and the strong uniform guarantees of L1-minimization. Our algorithm, ROMP, reconstructs a sparse signal in a number of iterations linear in the sparsity, and the reconstruction is exact provided the linear measurements satisfy the uniform uncertainty principle.","title":"Uniform Uncertainty Principle and Signal Recovery via Regularized Orthogonal Matching Pursuit","venue":"Foundations of Computational Mathematics","year":2009,"__v":0,"citationCount":260},{"authors":["Stefan Kunis","Holger Rauhut"],"references":["07b31ae6-8ce6-4acf-97ab-1cd9d45246ca","1ab0f330-2dca-496c-8992-111e9e80fc0e","38c8c7a7-e6f4-4f59-91de-76d74e801418","3ab1d996-976c-43ff-adbc-15ec54f31af9","449bfdfc-f916-422c-ac0d-ebfdd2ab773a","5eb8608d-d0a1-4f14-af98-8a26bab51fae","69b9ef96-11d5-49b0-9ae3-492763e02ca8","6ea0a74d-1f54-4187-a299-7f6706432563","6ff01654-66d1-49c7-b526-1c8ed7fa893a","71a18de9-e543-4337-ab7a-3db31d9f8c00","a53a3dda-b003-4d5c-96b1-e9afd8e35692","bb3c38fa-c2b0-4d4f-8c9d-ca1884343474","bef09d21-c47a-4966-8e6d-644bcab384dc","d84405a3-88f2-4f71-8575-d16f3c8d4ca1","e35e172e-0856-4aaf-bdbc-f23711f40232","f56b877b-4060-4754-b303-e8140968544c"],"_id":"e43d02bf-6474-4b51-b481-fe1b09b29406","abstract":"We investigate the problem of reconstructing sparse multivariate trigonometric polynomials from few randomly taken samples by Basis Pursuit and greedy algorithms such as Orthogonal Matching Pursuit (OMP) and Thresholding. While recovery by Basis Pursuit has recently been studied by several authors, we provide theoretical results on the success probability of reconstruction via Thresholding and OMP for both a continuous and a discrete probability model for the sampling points. We present numerical experiments, which indicate that usually Basis Pursuit is significantly slower than greedy algorithms, while the recovery rates are very similar.","title":"Random Sampling of Sparse Trigonometric Polynomials, II. Orthogonal Matching Pursuit versus Basis Pursuit","venue":"Foundations of Computational Mathematics","year":2008,"__v":0,"citationCount":52},{"authors":["David L. Donoho"],"references":["036a19f8-fdca-4e84-a237-e54f2108dcb4","05c85ace-c998-47cd-a285-f6ecfd72004d","0bb77e7f-bfc4-4d0d-873a-3d6d3c28b316","0ed39048-dd26-467a-bcd5-7017fcccddb5","225591b8-1c1a-4854-81d4-5b5f364c20a9","2862ec34-58f4-41c0-8790-1740130f1814","2a15f947-2402-4979-94b8-53de9ceef26e","3d414a5e-b97a-498e-8a75-920997235c6b","3dd913b8-e22d-434e-9015-bf68fbbb7bef","3ddea798-1e4f-408a-86db-a611c7bbcdcf","449bfdfc-f916-422c-ac0d-ebfdd2ab773a","4c9f2bac-2f23-4170-a0f1-a3001f63a7b9","5eb8608d-d0a1-4f14-af98-8a26bab51fae","71a18de9-e543-4337-ab7a-3db31d9f8c00","7291a02d-1d94-48b7-a4e2-35406c0e52ad","834863b2-34f0-40dc-b4d2-f4189eaa262a","87a4faed-c1a5-45c8-81eb-3bf19ae19011","8dd4158a-bbc4-40cf-a4d5-14e0fe630387","9b021b12-2e59-42bc-9e29-86e480e652b7","9e65914c-bfef-45e7-9fd7-85c39ed13ac4","a53a3dda-b003-4d5c-96b1-e9afd8e35692","adc31a96-1f8e-4793-8ee9-ecef04a16ac6","ae4ab999-5078-4348-9a3d-94c019952bcc","aecf8a08-eff7-4182-8bbb-a7b29de2f281","bb3c38fa-c2b0-4d4f-8c9d-ca1884343474","c380b798-6583-4821-9613-0a9731b1ced1","c9bf7235-7aad-4e6d-a9a6-e4a6bbddc327","ca546a51-ffda-46b1-b783-ff512ec9c4bd","cd9bd50b-d672-43a9-b0c2-0b332cf0b88e","d2104367-6389-4b06-8dbe-bab7e05b903b","d6457de8-9f03-4671-91da-f557a0ec20e0","defc112d-f91d-4b34-9d44-bd7f702c2391","f11bfae2-e272-4acc-b231-a9619f1e4d6c","ff44599f-5e74-4d9b-94d3-286592973471"],"_id":"f56b877b-4060-4754-b303-e8140968544c","abstract":"Suppose x is an unknown vector in Ropf m  (a digital image or signal); we plan to measure n general linear functionals of x and then reconstruct. If x is known to be compressible by transform coding with a known transform, and we reconstruct via the nonlinear procedure defined here, the number of measurements n can be dramatically smaller than the size m. Thus, certain natural classes of images with m pixels need only n=O(m 1/4 log 5/2 (m)) nonadaptive nonpixel samples for faithful recovery, as opposed to the usual m pixel samples. More specifically, suppose x has a sparse representation in some orthonormal basis (e.g., wavelet, Fourier) or tight frame (e.g., curvelet, Gabor)-so the coefficients belong to an lscr p  ball for 0 2  error O(N 1/2-1 p/). It is possible to design n=O(Nlog(m)) nonadaptive measurements allowing reconstruction with accuracy comparable to that attainable with direct knowledge of the N most important coefficients. Moreover, a good approximation to those N important coefficients is extracted from the n measurements by solving a linear program-Basis Pursuit in signal processing. The nonadaptive measurements have the character of \"random\" linear combinations of basis/frame elements. Our results use the notions of optimal recovery, of n-widths, and information-based complexity. We estimate the Gel'fand n-widths of lscr p  balls in high-dimensional Euclidean space in the case 0<ples1, and give a criterion identifying near- optimal subspaces for Gel'fand n-widths. We show that \"most\" subspaces are near-optimal, and show that convex optimization (Basis Pursuit) is a near-optimal way to extract information derived from these near-optimal subspaces","title":"Compressed sensing","venue":"IEEE Transactions on Information Theory","year":2006,"__v":0,"citationCount":6079},{"authors":["Holger Rauhut"],"references":["014cfe85-5aef-4543-abba-772b0ff3c87f","05c85ace-c998-47cd-a285-f6ecfd72004d","0bb77e7f-bfc4-4d0d-873a-3d6d3c28b316","38c8c7a7-e6f4-4f59-91de-76d74e801418","449bfdfc-f916-422c-ac0d-ebfdd2ab773a","692d603d-a504-4899-928e-5cb5643b66b7","69b9ef96-11d5-49b0-9ae3-492763e02ca8","71a18de9-e543-4337-ab7a-3db31d9f8c00","a53a3dda-b003-4d5c-96b1-e9afd8e35692","bb3c38fa-c2b0-4d4f-8c9d-ca1884343474","e43d02bf-6474-4b51-b481-fe1b09b29406","f56b877b-4060-4754-b303-e8140968544c"],"_id":"6ea0a74d-1f54-4187-a299-7f6706432563","abstract":"Recently, it has been observed that a sparse trigonometric polynomial, i.e., having only a small number of nonzero coefficients, can be reconstructed exactly from a small number of random samples using basis pursuit (BP) or orthogonal matching pursuit (OMP). In this paper, it is shown that recovery by a BP variant is stable under perturbation of the samples values by noise. A similar partial result for OMP is provided. For BP, in addition, the stability result is extended to (nonsparse) trigonometric polynomials that can be well approximated by sparse ones. The theoretical findings are illustrated by numerical experiments.","title":"Stability Results for Random Sampling of Sparse Trigonometric Polynomials","venue":"IEEE Transactions on Information Theory","year":2008,"__v":0,"citationCount":44}],"offsprings":[]},"6bfdf9a3-6cd9-43d8-9785-0073dbe96f1b":{"authors":["Alan Mainwaring","David E. Culler","Joseph Polastre","Robert Szewczyk","John Anderson"],"references":["85352dec-58be-43db-a428-f3f574ff96ec"],"_id":"6bfdf9a3-6cd9-43d8-9785-0073dbe96f1b","abstract":"We provide an in-depth study of applying wireless sensor networks to real-world habitat monitoring. A set of system design requirements are developed that cover the hardware design of the nodes, the design of the sensor network, and the capabilities for remote data access and management. A system architecture is proposed to address these requirements for habitat monitoring in general, and an instance of the architecture for monitoring seabird nesting environment and behavior is presented. The currently deployed network consists of 32 nodes on a small island off the coast of Maine streaming useful live data onto the web. The application-driven design exercise serves to identify important areas of further work in data sampling, communications, network retasking, and health monitoring.","title":"Wireless sensor networks for habitat monitoring","venue":"acm/ieee international conference on mobile computing and networking","year":2002,"__v":0,"citationCount":1698,"parents":{"05fb3436-276f-43ca-979b-0a3323240c19":0,"612910b7-24f8-4f67-9d3d-a2814b7c15f8":20,"84dc5aaa-7b2c-4f15-97f4-aa867b4328e2":20,"85352dec-58be-43db-a428-f3f574ff96ec":0,"9e063b41-0ada-4db8-8846-6e5153a0de55":0},"keyword":{"05fb3436-276f-43ca-979b-0a3323240c19":8.662698412698411,"612910b7-24f8-4f67-9d3d-a2814b7c15f8":13.338095238095235,"84dc5aaa-7b2c-4f15-97f4-aa867b4328e2":11.01190476190476,"85352dec-58be-43db-a428-f3f574ff96ec":10.52579365079365,"9e063b41-0ada-4db8-8846-6e5153a0de55":0},"topic":["network","monitor","design","data","system"],"groups":[{"authors":["Philip Levis","David E. Culler"],"references":["1dd8c68d-3b20-4171-9245-3a12c64c2838","2088d2fd-d0ed-477f-b350-5d342624e91e","2ebde61f-7761-409f-8ec7-842de39b4331","37eaf728-4067-4de2-88b4-d94dd9d75d43","38bc2646-a363-4160-84a2-e3fdc02ed96d","4ac80067-bbea-4eaf-8b7a-89c97db7ecfe","53254eb7-7cb4-4155-ba83-6f6994eae0a4","53f82d8c-22d7-43e4-be03-fe0cdd7b8abc","852f714e-385b-43ad-953e-c9b5e396734c","8828d2f5-0b50-4715-863d-66c787fc40e0","9e063b41-0ada-4db8-8846-6e5153a0de55","a7be55fb-7b81-4f53-a2a8-4ded41bc2375","afc06b7c-7fb3-4f88-942b-3076ed77920e","b4bdb461-47d0-4ade-a2e3-fb5846a08f9a","b9732d1d-1bf6-40d8-a846-e3d8ba75a8a6","c67c9508-e4b3-41ea-9e3c-8b9c0a5bd211","d5bf68d1-c29b-4072-8b71-934c0107e3c7","efa04de8-fec3-4c73-8031-5b7990b88e57"],"_id":"612910b7-24f8-4f67-9d3d-a2814b7c15f8","abstract":"Composed of tens of thousands of tiny devices with very limited resources (\"motes\"), sensor networks are subject to novel systems problems and constraints. The large number of motes in a sensor network means that there will often be some failing nodes; networks must be easy to repopulate. Often there is no feasible method to recharge motes, so energy is a precious resource. Once deployed, a network must be reprogrammable although physically unreachable, and this reprogramming can be a significant energy cost.We present Mate, a tiny communication-centric virtual machine designed for sensor networks. Mate's high-level interface allows complex programs to be very short (under 100 bytes), reducing the energy cost of transmitting new programs. Code is broken up into small capsules of 24 instructions, which can self-replicate through the network. Packet sending and reception capsules enable the deployment of ad-hoc routing and data aggregation algorithms. Mate's concise, high-level program representation simplifies programming and allows large networks to be frequently reprogrammed in an energy-efficient manner; in addition, its safe execution environment suggests a use of virtual machines to provide the user/kernel boundary on motes that have no hardware protection mechanisms.","title":"Maté: a tiny virtual machine for sensor networks","venue":"architectural support for programming languages and operating systems","year":2002,"__v":0,"citationCount":536}],"offsprings":["b5b8132d-0a8c-4e6c-999f-839f0cef48b7"]},"6c38b3b4-7562-493d-a40c-fe70abf039a7":{"authors":["David Nister","Henrik Stewenius"],"references":["60285266-7da2-474e-b05a-b380c836f665","8d8e7d51-3223-4776-bf6a-40306774b8a1","adf6fdf9-01a0-4051-9d99-965f4a5baa4d","b944f77f-113b-4a02-ae5e-d4a124b8fd5b","ffa029cf-7240-4723-8339-51fac57f9f28"],"_id":"6c38b3b4-7562-493d-a40c-fe70abf039a7","abstract":"A recognition scheme that scales efficiently to a large number of objects is presented. The efficiency and quality is exhibited in a live demonstration that recognizes CD-covers from a database of 40000 images of popular music CDs. The scheme builds upon popular techniques of indexing descriptors extracted from local regions, and is robust to background clutter and occlusion. The local region descriptors are hierarchically quantized in a vocabulary tree. The vocabulary tree allows a larger and more discriminatory vocabulary to be used efficiently, which we show experimentally leads to a dramatic improvement in retrieval quality. The most significant property of the scheme is that the tree directly defines the quantization. The quantization and the indexing are therefore fully integrated, essentially being one and the same. The recognition quality is evaluated through retrieval on a database with ground truth, showing the power of the vocabulary tree approach, going as high as 1 million images.","title":"Scalable Recognition with a Vocabulary Tree","venue":"computer vision and pattern recognition","year":2006,"__v":0,"citationCount":1886,"parents":{"0aae4e44-abdb-4948-9462-61f6e52162ba":0,"0d287faa-99bb-42df-98a7-24fcd601b9a4":0,"1f556c88-b553-4c75-b243-92d8200f8149":6.666666666666667,"21c67dad-f0eb-4479-afe7-fdf4a71eef01":46.666666666666664,"33711daf-2a44-4f42-8466-c7801f29959b":0,"60285266-7da2-474e-b05a-b380c836f665":0,"7729fafc-7053-4dd8-ac08-78232e0f2a74":13.333333333333334,"85336978-6cf2-4e87-b949-d13e7a22cf9e":0,"8d8e7d51-3223-4776-bf6a-40306774b8a1":46.666666666666664,"adf6fdf9-01a0-4051-9d99-965f4a5baa4d":0,"b944f77f-113b-4a02-ae5e-d4a124b8fd5b":6.666666666666667,"b9e63aeb-aa46-40a0-9b06-01e2270cea70":20,"dda32e99-40c9-4d5f-8982-51e4b1dca885":6.666666666666667,"e7fe111a-3c9f-454c-9255-f8283407df2b":26.666666666666668,"ffa029cf-7240-4723-8339-51fac57f9f28":20},"keyword":{"0aae4e44-abdb-4948-9462-61f6e52162ba":8.84920634920635,"0d287faa-99bb-42df-98a7-24fcd601b9a4":9.9810582010582,"1f556c88-b553-4c75-b243-92d8200f8149":11.346825396825398,"21c67dad-f0eb-4479-afe7-fdf4a71eef01":7.56904761904762,"33711daf-2a44-4f42-8466-c7801f29959b":12.134523809523808,"60285266-7da2-474e-b05a-b380c836f665":8.951190476190476,"7729fafc-7053-4dd8-ac08-78232e0f2a74":10.668253968253968,"85336978-6cf2-4e87-b949-d13e7a22cf9e":9.41015873015873,"8d8e7d51-3223-4776-bf6a-40306774b8a1":11.001587301587302,"adf6fdf9-01a0-4051-9d99-965f4a5baa4d":11.08854700854701,"b944f77f-113b-4a02-ae5e-d4a124b8fd5b":10.685714285714287,"b9e63aeb-aa46-40a0-9b06-01e2270cea70":9.276984126984125,"dda32e99-40c9-4d5f-8982-51e4b1dca885":8.996825396825397,"e7fe111a-3c9f-454c-9255-f8283407df2b":0,"ffa029cf-7240-4723-8339-51fac57f9f28":10.203650793650793},"topic":["vocabulari","tree","scheme","quantiz","qualiti"],"groups":[{"authors":["Krystian Mikolajczyk","Tinne Tuytelaars","C. Schmid","Andrew Zisserman","Jir i Matas","Frederik Schaffalitzky","Timor Kadir","L. Van Gool"],"references":["085204a8-62ca-4a3c-8098-4f75d62d1ae4","0aae4e44-abdb-4948-9462-61f6e52162ba","0bc5747a-2caf-4996-a55b-6ec5e7273636","0d287faa-99bb-42df-98a7-24fcd601b9a4","1dc84769-ff4c-4de6-a1c9-8d3af9299701","21a8e8fd-0172-4e9a-8474-7024eb0bf979","2beaa150-6293-4f05-ba04-8e001993e766","2d6c9f60-ea78-44a8-b5f9-6964575dd196","2dfac644-329c-46f4-a508-749ccb2d7c85","34758e0a-3def-447b-9c5e-e82a206426b5","4e58f9b5-8562-4f17-830f-f055449867fc","50212652-4999-4f13-82d6-a37eb2862a73","509e1ae2-768b-4417-bebe-d90cf1e0fdae","5149d3c0-5ac9-47ba-9fb0-3d2ef757b0e8","5172d9aa-41cc-40dc-949a-cde3d9f05f31","5f1992df-975f-49e7-bd88-aee0740317cf","6018a516-8149-4bce-bc33-5449d86e58c2","60285266-7da2-474e-b05a-b380c836f665","6842d04f-2b92-4298-aee8-92babc53f7c4","6fe37c18-8dc5-4baa-b6e0-5546353907bb","7283fa2b-1f6a-4138-a3da-4bf69809a1a9","776d4b4d-d49f-439f-9db5-7c5c3ce68db3","7ab7b36d-baae-4b21-89fc-69389fcabc44","8ab773a4-49b4-4755-a070-4ab1b1710690","8d8e7d51-3223-4776-bf6a-40306774b8a1","9b480902-c7fd-4d9f-ac9c-3c2fe3aa9c2c","a0be9da4-c423-4f87-a387-822fe304aa03","ab7b7857-e48d-4b94-8bfa-bc9ed61d5853","b25e7392-e9f9-4600-8ab0-a76252f1633a","b3e60214-b54c-4e8f-9315-a6975c760f4c","b944f77f-113b-4a02-ae5e-d4a124b8fd5b","b9e63aeb-aa46-40a0-9b06-01e2270cea70","c455fb04-4566-4648-ad6f-3cf2245e507c","cf9198ae-7e03-401f-a52b-94689ba30a36","ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d","fc9638b8-572c-4b23-aab2-92e2dd3b79f8","ffa029cf-7240-4723-8339-51fac57f9f28"],"_id":"21c67dad-f0eb-4479-afe7-fdf4a71eef01","abstract":"The paper gives a snapshot of the state of the art in affine covariant region detectors, and compares their performance on a set of test images under varying imaging conditions. Six types of detectors are included: detectors based on affine normalization around Harris (Mikolajczyk and Schmid, 2002; Schaffalitzky and Zisserman, 2002) and Hessian points (Mikolajczyk and Schmid, 2002), a detector of `maximally stable extremal regions', proposed by Matas et al. (2002); an edge-based region detector (Tuytelaars and Van Gool, 1999) and a detector based on intensity extrema (Tuytelaars and Van Gool, 2000), and a detector of `salient regions', proposed by Kadir, Zisserman and Brady (2004). The performance is measured against changes in viewpoint, scale, illumination, defocus and image compression.#R##N##R##N#The objective of this paper is also to establish a reference test set of images and performance software, so that future detectors can be evaluated in the same framework.","title":"A Comparison of Affine Region Detectors","venue":"International Journal of Computer Vision","year":2005,"__v":0,"citationCount":1317},{"authors":["Krystian Mikolajczyk","Cordelia Schmid"],"references":["00a4e16f-6b65-4ad2-bedc-b19d9cbc2cfe","09346dc3-f4d0-43a4-8f0b-27e02bcd336e","0aae4e44-abdb-4948-9462-61f6e52162ba","0d287faa-99bb-42df-98a7-24fcd601b9a4","19195bc1-7aff-4dd3-91cc-25402c343a19","21a8e8fd-0172-4e9a-8474-7024eb0bf979","21c67dad-f0eb-4479-afe7-fdf4a71eef01","2d6c9f60-ea78-44a8-b5f9-6964575dd196","33711daf-2a44-4f42-8466-c7801f29959b","34758e0a-3def-447b-9c5e-e82a206426b5","36800655-b2ff-4eb7-9070-c6be304c4baa","37031566-2033-44cb-a87e-91a9bb37996f","3b744649-d7a0-46c3-b242-9e0060d8ecfa","4e58f9b5-8562-4f17-830f-f055449867fc","509e1ae2-768b-4417-bebe-d90cf1e0fdae","5149d3c0-5ac9-47ba-9fb0-3d2ef757b0e8","568f1994-f91e-413e-92fd-87dbbb9642a8","5f1992df-975f-49e7-bd88-aee0740317cf","6018a516-8149-4bce-bc33-5449d86e58c2","60285266-7da2-474e-b05a-b380c836f665","608a581a-0e03-435a-9067-c0e0982567af","683dd26d-5c59-4feb-9fbd-2bcf3cc1942f","6fe37c18-8dc5-4baa-b6e0-5546353907bb","72c27d5a-23c5-4d1b-a000-280b87b368ee","7ab7b36d-baae-4b21-89fc-69389fcabc44","853b29ea-c6d1-497e-bad3-b608d370e7e2","a5254ae0-1ce1-4390-b9f8-8d5a3dcb1e62","a8c6ead3-d61a-4f6a-a702-08743f19eec9","b4685927-0ad9-466b-b2c6-2e1764475726","b592576f-ff29-4a68-9b2f-8a8ad02e9c70","b944f77f-113b-4a02-ae5e-d4a124b8fd5b","c455fb04-4566-4648-ad6f-3cf2245e507c","e2204e92-e6dc-4884-9bbc-200029491fc7","e927dff1-6ed4-45fd-8852-eb804e11e665","ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d","fc9638b8-572c-4b23-aab2-92e2dd3b79f8","ffa029cf-7240-4723-8339-51fac57f9f28"],"_id":"8d8e7d51-3223-4776-bf6a-40306774b8a1","abstract":"In this paper, we compare the performance of descriptors computed for local interest regions, as, for example, extracted by the Harris-Affine detector [Mikolajczyk, K and Schmid, C, 2004]. Many different descriptors have been proposed in the literature. It is unclear which descriptors are more appropriate and how their performance depends on the interest region detector. The descriptors should be distinctive and at the same time robust to changes in viewing conditions as well as to errors of the detector. Our evaluation uses as criterion recall with respect to precision and is carried out for different image transformations. We compare shape context [Belongie, S, et al., April 2002], steerable filters [Freeman, W and Adelson, E, Setp. 1991], PCA-SIFT [Ke, Y and Sukthankar, R, 2004], differential invariants [Koenderink, J and van Doorn, A, 1987], spin images [Lazebnik, S, et al., 2003], SIFT [Lowe, D. G., 1999], complex filters [Schaffalitzky, F and Zisserman, A, 2002], moment invariants [Van Gool, L, et al., 1996], and cross-correlation for different types of interest regions. We also propose an extension of the SIFT descriptor and show that it outperforms the original method. Furthermore, we observe that the ranking of the descriptors is mostly independent of the interest region detector and that the SIFT-based descriptors perform best. Moments and steerable filters show the best performance among the low dimensional descriptors.","title":"A performance evaluation of local descriptors","venue":"IEEE Transactions on Pattern Analysis and Machine Intelligence","year":2005,"__v":0,"citationCount":2762}],"offsprings":["50252efa-a843-4cc6-a591-22f527ee3d6c","2b6a3d0f-368f-45bb-be23-4e82f62fbbf7"]},"6d25cd6f-4a67-41ed-9b6d-467c739f531e":{"authors":["Aggelos Bletsas","Ashish Khisti","David P. Reed","Andrew Lippman"],"references":["2659531e-eb9d-4dd5-b46f-10f66a4819c6","720f59d2-acc3-4d5a-91c2-258d137d9647","748a2ab3-8b5f-4d0a-9e2d-af685089843a","7ae0e791-2e2b-4504-a2fe-caa9b0589c44","b22134b3-2419-4d39-b6b8-d7ad60abac26"],"_id":"6d25cd6f-4a67-41ed-9b6d-467c739f531e","abstract":"Cooperative diversity has been recently proposed as a way to form virtual antenna arrays that provide dramatic gains in slow fading wireless environments. However, most of the proposed solutions require distributed space-time coding algorithms, the careful design of which is left for future investigation if there is more than one cooperative relay. We propose a novel scheme that alleviates these problems and provides diversity gains on the order of the number of relays in the network. Our scheme first selects the best relay from a set of M available relays and then uses this \"best\" relay for cooperation between the source and the destination. We develop and analyze a distributed method to select the best relay that requires no topology information and is based on local measurements of the instantaneous channel conditions. This method also requires no explicit communication among the relays. The success (or failure) to select the best available path depends on the statistics of the wireless channel, and a methodology to evaluate performance for any kind of wireless channel statistics, is provided. Information theoretic analysis of outage probability shows that our scheme achieves the same diversity-multiplexing tradeoff as achieved by more complex protocols, where coordination and distributed space-time coding for M relay nodes is required, such as those proposed by Laneman and Wornell (2003). The simplicity of the technique allows for immediate implementation in existing radio hardware and its adoption could provide for improved flexibility, reliability, and efficiency in future 4G wireless systems.","title":"A simple Cooperative diversity method based on network path selection","venue":"IEEE Journal on Selected Areas in Communications","year":2006,"__v":0,"citationCount":1603,"parents":{"01384514-9529-4960-b6e3-81286b2b6e21":21.052631578947366,"18843e53-1f3b-49d0-b847-a186df55cda1":26.31578947368421,"1f1b86fb-2c1b-451a-af5f-c251107c4bcf":10.526315789473683,"2659531e-eb9d-4dd5-b46f-10f66a4819c6":0,"42ac4cd0-4af5-4103-9e83-36b72e29f0c6":10.526315789473683,"59d18ef8-cadf-4f4b-bdaf-4b2f82e732c4":5.263157894736842,"691cf3dc-4d67-4f10-b74e-e7a015e94fa5":5.263157894736842,"692c732f-b433-4413-bae3-763a76a8f2c1":15.789473684210526,"6fae9bf2-9b54-4fe3-b53d-95a8b7ff4187":5.263157894736842,"720f59d2-acc3-4d5a-91c2-258d137d9647":10.526315789473683,"748a2ab3-8b5f-4d0a-9e2d-af685089843a":0,"7ae0e791-2e2b-4504-a2fe-caa9b0589c44":10.526315789473683,"878eef89-8bd3-4925-81cb-09a4f0151328":21.052631578947366,"90b4d4cb-35c2-498f-b777-63cc4882cdad":0,"a45e2d68-ce46-4aab-ab01-150b84f32a9a":0,"b22134b3-2419-4d39-b6b8-d7ad60abac26":5.263157894736842,"bbab87e7-3bc2-456f-80ba-c6a7065370d1":5.263157894736842,"dd3151e6-9756-4260-bc37-3507976fa578":5.263157894736842,"f9bb2e49-fba7-4df5-8119-4bb30e83307a":0},"keyword":{"01384514-9529-4960-b6e3-81286b2b6e21":13.705396825396823,"18843e53-1f3b-49d0-b847-a186df55cda1":12.151666666666664,"1f1b86fb-2c1b-451a-af5f-c251107c4bcf":12.061666666666664,"2659531e-eb9d-4dd5-b46f-10f66a4819c6":12.144920634920636,"42ac4cd0-4af5-4103-9e83-36b72e29f0c6":10.117989417989417,"59d18ef8-cadf-4f4b-bdaf-4b2f82e732c4":12.325079365079365,"691cf3dc-4d67-4f10-b74e-e7a015e94fa5":10.944444444444443,"692c732f-b433-4413-bae3-763a76a8f2c1":8.926587301587302,"6fae9bf2-9b54-4fe3-b53d-95a8b7ff4187":11.550396825396824,"720f59d2-acc3-4d5a-91c2-258d137d9647":10.223412698412698,"748a2ab3-8b5f-4d0a-9e2d-af685089843a":8.792142857142856,"7ae0e791-2e2b-4504-a2fe-caa9b0589c44":12.605370370370368,"878eef89-8bd3-4925-81cb-09a4f0151328":11.5615873015873,"90b4d4cb-35c2-498f-b777-63cc4882cdad":10.763809523809526,"a45e2d68-ce46-4aab-ab01-150b84f32a9a":9.843518518518518,"b22134b3-2419-4d39-b6b8-d7ad60abac26":12.087777777777776,"bbab87e7-3bc2-456f-80ba-c6a7065370d1":10.215079365079365,"dd3151e6-9756-4260-bc37-3507976fa578":10.679365079365079,"f9bb2e49-fba7-4df5-8119-4bb30e83307a":10.903174603174604},"topic":["relai","wireless","requir","propos","select"],"groups":[{"authors":["K. Azarian","H. El Gamal","P. Schniter"],"references":["18843e53-1f3b-49d0-b847-a186df55cda1","39225250-1e4b-4b03-91cc-5d72f01208b1","720f59d2-acc3-4d5a-91c2-258d137d9647","73fec0bf-70f7-4eec-aac4-9c22f48cded5","7ae0e791-2e2b-4504-a2fe-caa9b0589c44","90272f7a-316d-4f1e-ba86-74af8c4f70ac","9f68b680-a689-41c6-83cf-e0065ece0462","af710838-5887-4725-9464-db29d581b6fe","b22134b3-2419-4d39-b6b8-d7ad60abac26","d6cff3c8-ff1f-4d89-85cd-4831b65768bb","efcbfcea-e8b0-4ca9-a883-92f42f862307","fc5ef880-8414-4eef-9b79-6c88355b81ee"],"_id":"878eef89-8bd3-4925-81cb-09a4f0151328","abstract":"We propose novel cooperative transmission protocols for delay-limited coherent fading channels consisting of N (half-duplex and single-antenna) partners and one cell site. In our work, we differentiate between the relay, cooperative broadcast (down-link), and cooperative multiple-access (CMA) (up-link) channels. The proposed protocols are evaluated using Zheng-Tse diversity-multiplexing tradeoff. For the relay channel, we investigate two classes of cooperation schemes; namely, amplify and forward (AF) protocols and decode and forward (DF) protocols. For the first class, we establish an upper bound on the achievable diversity-multiplexing tradeoff with a single relay. We then construct a new AF protocol that achieves this upper bound. The proposed algorithm is then extended to the general case with (N-1) relays where it is shown to outperform the space-time coded protocol of Laneman and Wornell without requiring decoding/encoding at the relays. For the class of DF protocols, we develop a dynamic decode and forward (DDF) protocol that achieves the optimal tradeoff for multiplexing gains 0lesrles1/N. Furthermore, with a single relay, the DDF protocol is shown to dominate the class of AF protocols for all multiplexing gains. The superiority of the DDF protocol is shown to be more significant in the cooperative broadcast channel. The situation is reversed in the CMA channel where we propose a new AF protocol that achieves the optimal tradeoff for all multiplexing gains. A distinguishing feature of the proposed protocols in the three scenarios is that they do not rely on orthogonal subspaces, allowing for a more efficient use of resources. In fact, using our results one can argue that the suboptimality of previously proposed protocols stems from their use of orthogonal subspaces rather than the half-duplex constraint.","title":"On the achievable diversity-multiplexing tradeoff in half-duplex cooperative channels","venue":"IEEE Transactions on Information Theory","year":2005,"__v":0,"citationCount":636},{"authors":["Bin Zhao","Matthew C. Valenti"],"references":["0463cf54-d4b7-42e2-942d-204b64007a08","064005b0-00e1-40c6-888b-a5c7314b6c68","0af670c7-9d5e-4919-b252-8aac6c08a3a5","112f85ca-88ac-4217-bf30-4150a6ea651d","59d18ef8-cadf-4f4b-bdaf-4b2f82e732c4","73323d01-3557-4b31-86f6-95bea6cf2d5a","73fec0bf-70f7-4eec-aac4-9c22f48cded5","7ae0e791-2e2b-4504-a2fe-caa9b0589c44","7f7fd004-7853-4c6c-b120-e9a9b9ea4821","89925ea3-ffcc-406f-9b38-432275ce2bd9","8cc9ea80-563f-4e62-bda9-8ff6d71cf6ae","b1223439-c642-44c4-ad5d-dd74c6b8133a","b22134b3-2419-4d39-b6b8-d7ad60abac26","b5741c8a-84a5-4b8d-9e5e-29d97732b48f","bbab87e7-3bc2-456f-80ba-c6a7065370d1","c8759517-046e-4919-8ded-68c3d827238e","efcbfcea-e8b0-4ca9-a883-92f42f862307","fc5ef880-8414-4eef-9b79-6c88355b81ee"],"_id":"01384514-9529-4960-b6e3-81286b2b6e21","abstract":"Wireless networks contain an inherent distributed spatial diversity that can be exploited by the use of relaying. Relay networks take advantage of the broadcast-oriented nature of radio and require node-based, rather than link-based protocols. Prior work on relay networks has studied performance limits either with unrealistic assumptions, complicated protocols, or only a single relay. In this paper, a practical approach to networks comprising multiple relays operating over orthogonal time slots is proposed based on a generalization of hybrid-automatic repeat request (ARQ). In contrast with conventional hybrid-ARQ, retransmitted packets do not need to come from the original source radio but could instead be sent by relays that overhear the transmission. An information theoretic framework is exposed that establishes the performance limits of such systems in a block fading environment, and numerical results are presented for some representative topologies and protocols. The results indicate a significant improvement in the energy-latency tradeoff when compared with conventional multihop protocols implemented as a cascade of point-to-point links.","title":"Practical relay networks: a generalization of hybrid-ARQ","venue":"IEEE Journal on Selected Areas in Communications","year":2005,"__v":0,"citationCount":278},{"authors":["Rohit U. Nabar","Helmut Bölcskei","Felix W. Kneubühler"],"references":["064005b0-00e1-40c6-888b-a5c7314b6c68","222e8196-b98b-47bc-a679-641bbf57b770","2659531e-eb9d-4dd5-b46f-10f66a4819c6","324c0cc6-829c-4b4f-8ef4-5f2d9b34bf58","627996e9-13ca-44e7-81fa-b8e1239487ff","720f59d2-acc3-4d5a-91c2-258d137d9647","748a2ab3-8b5f-4d0a-9e2d-af685089843a","79086636-f7d8-4429-be74-0a63bbb19b1f","7ae0e791-2e2b-4504-a2fe-caa9b0589c44","87761466-c0f0-4ec7-9a97-0f1beabc4eeb","8cc9ea80-563f-4e62-bda9-8ff6d71cf6ae","90a424e0-d969-4c63-8ab0-fb6922d335d8","b22134b3-2419-4d39-b6b8-d7ad60abac26","efcbfcea-e8b0-4ca9-a883-92f42f862307","fc5ef880-8414-4eef-9b79-6c88355b81ee"],"_id":"18843e53-1f3b-49d0-b847-a186df55cda1","abstract":"Cooperative diversity is a transmission technique, where multiple terminals pool their resources to form a virtual antenna array that realizes spatial diversity gain in a distributed fashion. In this paper, we examine the basic building block of cooperative diversity systems, a simple fading relay channel where the source, destination, and relay terminals are each equipped with single antenna transceivers. We consider three different time-division multiple-access-based cooperative protocols that vary the degree of broadcasting and receive collision. The relay terminal operates in either the amplify-and-forward (AF) or decode-and-forward (DF) modes. For each protocol, we study the ergodic and outage capacity behavior (assuming Gaussian code books) under the AF and DF modes of relaying. We analyze the spatial diversity performance of the various protocols and find that full spatial diversity (second-order in this case) is achieved by certain protocols provided that appropriate power control is employed. Our analysis unifies previous results reported in the literature and establishes the superiority (both from a capacity, as well as a diversity point-of-view) of a new protocol proposed in this paper. The second part of the paper is devoted to (distributed) space-time code design for fading relay channels operating in the AF mode. We show that the corresponding code design criteria consist of the traditional rank and determinant criteria for the case of colocated antennas, as well as appropriate power control rules. Consequently space-time codes designed for the case of colocated multiantenna channels can be used to realize cooperative diversity provided that appropriate power control is employed.","title":"Fading relay channels: performance limits and space-time signal design","venue":"IEEE Journal on Selected Areas in Communications","year":2004,"__v":0,"citationCount":1051}],"offsprings":[]},"6f77b214-9d71-41c8-b51a-3dbff153ad5a":{"authors":["Lydia E. Kavraki","Petr Svestka","Jean-Claude Latombe","Mark H. Overmars"],"references":[],"_id":"6f77b214-9d71-41c8-b51a-3dbff153ad5a","abstract":"A new motion planning method for robots in static workspaces is presented. This method proceeds in two phases: a learning phase and a query phase. In the learning phase, a probabilistic roadmap is constructed and stored as a graph whose nodes correspond to collision-free configurations and whose edges correspond to feasible paths between these configurations. These paths are computed using a simple and fast local planner. In the query phase, any given start and goal configurations of the robot are connected to two nodes of the roadmap; the roadmap is then searched for a path joining these two nodes. The method is general and easy to implement. It can be applied to virtually any type of holonomic robot. It requires selecting certain parameters (e.g., the duration of the learning phase) whose values depend on the scene, that is the robot and its workspace. But these values turn out to be relatively easy to choose, Increased efficiency can also be achieved by tailoring some components of the method (e.g., the local planner) to the considered robots. In this paper the method is applied to planar articulated robots with many degrees of freedom. Experimental results show that path planning can be done in a fraction of a second on a contemporary workstation (/spl ap/150 MIPS), after learning for relatively short periods of time (a few dozen seconds).","title":"Probabilistic roadmaps for path planning in high-dimensional configuration spaces","venue":"international conference on robotics and automation","year":1996,"__v":0,"citationCount":1532,"parents":{"036be3f9-d3a4-4436-a5b4-14dec87f9d1a":10.344827586206897,"037e3a66-d6a4-4e72-9007-927f3627c901":17.24137931034483,"03cddc81-e7cc-4eeb-aeb7-978eca83805e":3.4482758620689653,"13c1f2f0-1dbd-4796-9c8a-8d83b4cf572a":6.896551724137931,"1cb952b3-a4b8-47f4-9951-64f53080b7ae":6.896551724137931,"1f17cd4e-2562-48e1-8933-eaf11ab80abe":6.896551724137931,"2ac7a17b-c1f3-418f-9db5-5728521e0656":6.896551724137931,"2ca2ca9b-5cfa-4c21-b67d-53d891a71697":10.344827586206897,"30932642-fd17-4ae9-9a5b-90e67adcfe41":0,"5c3729f0-f67b-4a3a-8261-58f681ddfdb3":3.4482758620689653,"5fdf3803-c8eb-43cd-a541-0d0d6dee8794":20.689655172413794,"62fb38f0-0bba-41bb-aeac-845b986da3e1":0,"6564cdc9-846d-4a52-8591-b6e4f8717161":0,"779b25dc-8b81-49c9-ae5c-2d423cecccf0":10.344827586206897,"7cc24776-ccae-473d-9bf5-83ab7e5fdfdb":10.344827586206897,"85b8e527-3642-47c0-985b-fefaae4295a5":0,"9116eeca-bd00-421d-a122-04d9c89a67d9":0,"9628d45f-73b3-4143-90d5-71333a22bce6":3.4482758620689653,"a549ab42-7e09-4641-82b6-23ee9c00de6b":3.4482758620689653,"a8a57fce-68b0-4a82-bc8e-9dac2a21d868":3.4482758620689653,"ac53aee2-efd8-40c3-a864-186ab8ec61a3":0,"bc07f110-3c53-423a-bce2-2ae220c61096":3.4482758620689653,"c6c496b9-1668-4fef-8efb-e78878a0d7ca":6.896551724137931,"c7c14626-f462-4760-b12c-d5b117e815c9":0,"d18a9377-8bb4-42b3-a569-65b938881328":0,"d41d7f5a-6c88-4455-b0e2-debaeb78c599":6.896551724137931,"d99bc636-5d8b-4435-aaa1-955f5cb1ca83":6.896551724137931,"e18b68bc-9a58-44cb-83b8-5d8e3a1143df":0,"ec835496-802c-4c1b-9f94-12af1dc092b3":3.4482758620689653},"keyword":{"036be3f9-d3a4-4436-a5b4-14dec87f9d1a":10.271507936507936,"037e3a66-d6a4-4e72-9007-927f3627c901":9.763809523809524,"03cddc81-e7cc-4eeb-aeb7-978eca83805e":12.337539682539681,"13c1f2f0-1dbd-4796-9c8a-8d83b4cf572a":9.996296296296293,"1cb952b3-a4b8-47f4-9951-64f53080b7ae":8.97952380952381,"1f17cd4e-2562-48e1-8933-eaf11ab80abe":9.338888888888889,"2ac7a17b-c1f3-418f-9db5-5728521e0656":12.301385281385283,"2ca2ca9b-5cfa-4c21-b67d-53d891a71697":9.489285714285714,"30932642-fd17-4ae9-9a5b-90e67adcfe41":9.476111111111111,"5c3729f0-f67b-4a3a-8261-58f681ddfdb3":10.43074074074074,"5fdf3803-c8eb-43cd-a541-0d0d6dee8794":9.56373015873016,"62fb38f0-0bba-41bb-aeac-845b986da3e1":8.492063492063494,"6564cdc9-846d-4a52-8591-b6e4f8717161":8.794920634920633,"779b25dc-8b81-49c9-ae5c-2d423cecccf0":0,"7cc24776-ccae-473d-9bf5-83ab7e5fdfdb":8.857142857142858,"85b8e527-3642-47c0-985b-fefaae4295a5":11.558994708994707,"9116eeca-bd00-421d-a122-04d9c89a67d9":9.234074074074075,"9628d45f-73b3-4143-90d5-71333a22bce6":10.395000000000001,"a549ab42-7e09-4641-82b6-23ee9c00de6b":10.526984126984129,"a8a57fce-68b0-4a82-bc8e-9dac2a21d868":12.117936507936506,"ac53aee2-efd8-40c3-a864-186ab8ec61a3":11.23444444444444,"bc07f110-3c53-423a-bce2-2ae220c61096":10.10416666666667,"c6c496b9-1668-4fef-8efb-e78878a0d7ca":7.484444444444445,"c7c14626-f462-4760-b12c-d5b117e815c9":9.51074074074074,"d18a9377-8bb4-42b3-a569-65b938881328":8.887777777777778,"d41d7f5a-6c88-4455-b0e2-debaeb78c599":9.358412698412698,"d99bc636-5d8b-4435-aaa1-955f5cb1ca83":9.880714285714287,"e18b68bc-9a58-44cb-83b8-5d8e3a1143df":0,"ec835496-802c-4c1b-9f94-12af1dc092b3":10.237698412698412},"topic":["robot","phase","method","path","learn"],"offsprings":[]},"6ff01654-66d1-49c7-b526-1c8ed7fa893a":{"authors":["Emmanuel J. Candès","Terence Tao"],"references":["71a18de9-e543-4337-ab7a-3db31d9f8c00","a53a3dda-b003-4d5c-96b1-e9afd8e35692","f56b877b-4060-4754-b303-e8140968544c"],"_id":"6ff01654-66d1-49c7-b526-1c8ed7fa893a","abstract":"This paper considers a natural error correcting problem with real valued input/output. We wish to recover an input vector f/spl isin/R/sup n/ from corrupted measurements y=Af+e. Here, A is an m by n (coding) matrix and e is an arbitrary and unknown vector of errors. Is it possible to recover f exactly from the data y? We prove that under suitable conditions on the coding matrix A, the input f is the unique solution to the /spl lscr//sub 1/-minimization problem (/spl par/x/spl par//sub /spl lscr/1/:=/spl Sigma//sub i/|x/sub i/|) min(g/spl isin/R/sup n/) /spl par/y - Ag/spl par//sub /spl lscr/1/ provided that the support of the vector of errors is not too large, /spl par/e/spl par//sub /spl lscr/0/:=|{i:e/sub i/ /spl ne/ 0}|/spl les//spl rho//spl middot/m for some /spl rho/>0. In short, f can be recovered exactly by solving a simple convex optimization problem (which one can recast as a linear program). In addition, numerical experiments suggest that this recovery procedure works unreasonably well; f is recovered exactly even in situations where a significant fraction of the output is corrupted. This work is related to the problem of finding sparse solutions to vastly underdetermined systems of linear equations. There are also significant connections with the problem of recovering signals from highly incomplete measurements. In fact, the results introduced in this paper improve on our earlier work. Finally, underlying the success of /spl lscr//sub 1/ is a crucial property we call the uniform uncertainty principle that we shall describe in detail.","title":"Decoding by linear programming","venue":"IEEE Transactions on Information Theory","year":2005,"__v":0,"citationCount":1991,"parents":{"0e654e87-bc20-4fed-bcf8-cb2b99cbd39c":10,"449bfdfc-f916-422c-ac0d-ebfdd2ab773a":20,"71a18de9-e543-4337-ab7a-3db31d9f8c00":40,"87a4faed-c1a5-45c8-81eb-3bf19ae19011":10,"87c3242f-f4a5-4ef1-8ec3-e52c4402b8c0":0,"a53a3dda-b003-4d5c-96b1-e9afd8e35692":30,"d84405a3-88f2-4f71-8575-d16f3c8d4ca1":50,"f11bfae2-e272-4acc-b231-a9619f1e4d6c":0,"f56b877b-4060-4754-b303-e8140968544c":50,"f56dbdc3-f2ee-4a66-a3fb-df142f830dc5":20},"keyword":{"0e654e87-bc20-4fed-bcf8-cb2b99cbd39c":8.716984126984126,"449bfdfc-f916-422c-ac0d-ebfdd2ab773a":8.841190476190476,"71a18de9-e543-4337-ab7a-3db31d9f8c00":9.517619047619046,"87a4faed-c1a5-45c8-81eb-3bf19ae19011":9.797804232804234,"87c3242f-f4a5-4ef1-8ec3-e52c4402b8c0":8.697460317460317,"a53a3dda-b003-4d5c-96b1-e9afd8e35692":8.784170274170275,"d84405a3-88f2-4f71-8575-d16f3c8d4ca1":7.8748556998557016,"f11bfae2-e272-4acc-b231-a9619f1e4d6c":9.847248677248677,"f56b877b-4060-4754-b303-e8140968544c":8.007186147186147,"f56dbdc3-f2ee-4a66-a3fb-df142f830dc5":10.012169312169311},"topic":["spl","recov","problem","work","vector"],"groups":[{"authors":["Emmanuel J. Candès","Terence Tao"],"references":["036a19f8-fdca-4e84-a237-e54f2108dcb4","2d75f21b-8617-4c21-a1bf-467a82458459","5eb8608d-d0a1-4f14-af98-8a26bab51fae","6ff01654-66d1-49c7-b526-1c8ed7fa893a","87a4faed-c1a5-45c8-81eb-3bf19ae19011","9b021b12-2e59-42bc-9e29-86e480e652b7","a53a3dda-b003-4d5c-96b1-e9afd8e35692","c385db5b-803b-4d88-b756-f7cc417bbfb0","d84405a3-88f2-4f71-8575-d16f3c8d4ca1","e33adb02-12d9-47b9-af5e-b9a79070a920","f56b877b-4060-4754-b303-e8140968544c"],"_id":"71a18de9-e543-4337-ab7a-3db31d9f8c00","abstract":"Suppose we are given a vector f in a class FsubeRopf N  , e.g., a class of digital signals or digital images. How many linear measurements do we need to make about f to be able to recover f to within precision epsi in the Euclidean (lscr 2 ) metric? This paper shows that if the objects of interest are sparse in a fixed basis or compressible, then it is possible to reconstruct f to within very high accuracy from a small number of random measurements by solving a simple linear program. More precisely, suppose that the nth largest entry of the vector |f| (or of its coefficients in a fixed basis) obeys |f| (n) lesRmiddotn -1 p/, where R>0 and p>0. Suppose that we take measurements y k =langf #  ,X k rang,k=1,...,K, where the X k  are N-dimensional Gaussian vectors with independent standard normal entries. Then for each f obeying the decay estimate above for some 0 t , defined as the solution to the constraints y k =langf #  ,X k rang with minimal lscr 1  norm, obeys parf-f # par lscr2 lesC p  middotRmiddot(K/logN) -r , r=1/p-1/2. There is a sense in which this result is optimal; it is generally impossible to obtain a higher accuracy from any set of K measurements whatsoever. The methodology extends to various other random measurement ensembles; for example, we show that similar results hold if one observes a few randomly sampled Fourier coefficients of f. In fact, the results are quite general and require only two hypotheses on the measurement ensemble which are detailed","title":"Near-Optimal Signal Recovery From Random Projections: Universal Encoding Strategies?","venue":"IEEE Transactions on Information Theory","year":2006,"__v":0,"citationCount":1928},{"authors":["Emmanuel J. Candès","Justin K. Romberg"],"references":["2dc6f03e-d39c-4372-9d77-c7a7ee1ee369","4114181f-6f48-4cb6-b6d3-b337515d57f8","449bfdfc-f916-422c-ac0d-ebfdd2ab773a","71a18de9-e543-4337-ab7a-3db31d9f8c00","87a4faed-c1a5-45c8-81eb-3bf19ae19011","a53a3dda-b003-4d5c-96b1-e9afd8e35692","c6417c11-878b-4492-8d25-6f5af6a53741","f11bfae2-e272-4acc-b231-a9619f1e4d6c"],"_id":"d84405a3-88f2-4f71-8575-d16f3c8d4ca1","abstract":"In this paper we develop a robust uncertainty principle for finite signals in ${\\Bbb C}^N$ which states that, for nearly all choices $T, \\Omega\\subset\\{0,\\ldots,N-1\\}$ such that $|T| + |\\Omega| \\asymp (\\log N)^{-1/2} \\cdot N,$ there is no signal $f$ supported on $T$ whose discrete Fourier transform $\\hat{f}$ is supported on $\\Omega.$ In fact, we can make the above uncertainty principle quantitative in the sense that if $f$ is supported on $T,$ then only a small percentage of the energy (less than half, say) of $\\hat{f}$ is concentrated on $\\Omega.$ As an application of this robust uncertainty principle (QRUP), we consider the problem of decomposing a signal into a sparse superposition of spikes and complex sinusoids $f(s) = \\sum_{t\\in T}\\alpha_1(t)\\delta(s-t) + \\sum_{\\omega\\in\\Omega}\\alpha_2(\\omega)e^{i2\\pi \\omega s/N}/\\sqrt{N}.$ We show that if a generic signal $f$ has a decomposition $(\\alpha_1,\\alpha_2)$ using spike and frequency locations in $T$ and $\\Omega,$ respectively, and obeying $|T| + |\\Omega| \\leq {\\rm Const}\\cdot (\\log N)^{-1/2}\\cdot N,$ then $(\\alpha_1, \\alpha_2)$ is the unique sparsest possible decomposition (all other decompositions have more nonzero terms). In addition, if $|T| + |\\Omega| \\leq {\\rm Const}\\cdot (\\log N)^{-1}\\cdot N,$ then the sparsest $(\\alpha_1,\\alpha_2)$ can be found by solving a convex optimization problem. Underlying our results is a new probabilistic approach which insists on finding the correct uncertainty relation, or the optimally sparse solution for nearly all subsets but not necessarily all of them, and allows us to considerably sharpen previously known results [9], [10]. In fact, we show that the fraction of sets $(T, \\Omega)$ for which the above properties do not hold can be upper bounded by quantities like $N^{-\\alpha}$ for large values of $\\alpha.$ The QRUP (and the application to finding sparse representations) can be extended to general pairs of orthogonal bases $\\Phi_1,\\Phi_2 \\mbox{of} {\\Bbb C}^N.$ For nearly all choices ${\\Gamma_1},{\\Gamma_2}\\subset\\{0,\\ldots,N-1\\}$ obeying $|{\\Gamma_1}| + |{\\Gamma_2}| \\asymp \\mu(\\Phi_1,\\Phi_2)^{-2} \\cdot (\\log N)^{-m},$ where $m\\leq 6,$ there is no signal $f$ such that $\\Phi_1 f$ is supported on ${\\Gamma_1}$ and $\\Phi_2 f$ is supported on ${\\Gamma_2}$ where $\\mu(\\Phi_1,\\Phi_2)$ is the mutual coherence between $\\Phi_1$ and $\\Phi_2.$","title":"Quantitative Robust Uncertainty Principles and Optimally Sparse Decompositions","venue":"Foundations of Computational Mathematics","year":2006,"__v":0,"citationCount":131},{"authors":["David L. Donoho"],"references":["036a19f8-fdca-4e84-a237-e54f2108dcb4","05c85ace-c998-47cd-a285-f6ecfd72004d","0bb77e7f-bfc4-4d0d-873a-3d6d3c28b316","0ed39048-dd26-467a-bcd5-7017fcccddb5","225591b8-1c1a-4854-81d4-5b5f364c20a9","2862ec34-58f4-41c0-8790-1740130f1814","2a15f947-2402-4979-94b8-53de9ceef26e","3d414a5e-b97a-498e-8a75-920997235c6b","3dd913b8-e22d-434e-9015-bf68fbbb7bef","3ddea798-1e4f-408a-86db-a611c7bbcdcf","449bfdfc-f916-422c-ac0d-ebfdd2ab773a","4c9f2bac-2f23-4170-a0f1-a3001f63a7b9","5eb8608d-d0a1-4f14-af98-8a26bab51fae","71a18de9-e543-4337-ab7a-3db31d9f8c00","7291a02d-1d94-48b7-a4e2-35406c0e52ad","834863b2-34f0-40dc-b4d2-f4189eaa262a","87a4faed-c1a5-45c8-81eb-3bf19ae19011","8dd4158a-bbc4-40cf-a4d5-14e0fe630387","9b021b12-2e59-42bc-9e29-86e480e652b7","9e65914c-bfef-45e7-9fd7-85c39ed13ac4","a53a3dda-b003-4d5c-96b1-e9afd8e35692","adc31a96-1f8e-4793-8ee9-ecef04a16ac6","ae4ab999-5078-4348-9a3d-94c019952bcc","aecf8a08-eff7-4182-8bbb-a7b29de2f281","bb3c38fa-c2b0-4d4f-8c9d-ca1884343474","c380b798-6583-4821-9613-0a9731b1ced1","c9bf7235-7aad-4e6d-a9a6-e4a6bbddc327","ca546a51-ffda-46b1-b783-ff512ec9c4bd","cd9bd50b-d672-43a9-b0c2-0b332cf0b88e","d2104367-6389-4b06-8dbe-bab7e05b903b","d6457de8-9f03-4671-91da-f557a0ec20e0","defc112d-f91d-4b34-9d44-bd7f702c2391","f11bfae2-e272-4acc-b231-a9619f1e4d6c","ff44599f-5e74-4d9b-94d3-286592973471"],"_id":"f56b877b-4060-4754-b303-e8140968544c","abstract":"Suppose x is an unknown vector in Ropf m  (a digital image or signal); we plan to measure n general linear functionals of x and then reconstruct. If x is known to be compressible by transform coding with a known transform, and we reconstruct via the nonlinear procedure defined here, the number of measurements n can be dramatically smaller than the size m. Thus, certain natural classes of images with m pixels need only n=O(m 1/4 log 5/2 (m)) nonadaptive nonpixel samples for faithful recovery, as opposed to the usual m pixel samples. More specifically, suppose x has a sparse representation in some orthonormal basis (e.g., wavelet, Fourier) or tight frame (e.g., curvelet, Gabor)-so the coefficients belong to an lscr p  ball for 0 2  error O(N 1/2-1 p/). It is possible to design n=O(Nlog(m)) nonadaptive measurements allowing reconstruction with accuracy comparable to that attainable with direct knowledge of the N most important coefficients. Moreover, a good approximation to those N important coefficients is extracted from the n measurements by solving a linear program-Basis Pursuit in signal processing. The nonadaptive measurements have the character of \"random\" linear combinations of basis/frame elements. Our results use the notions of optimal recovery, of n-widths, and information-based complexity. We estimate the Gel'fand n-widths of lscr p  balls in high-dimensional Euclidean space in the case 0<ples1, and give a criterion identifying near- optimal subspaces for Gel'fand n-widths. We show that \"most\" subspaces are near-optimal, and show that convex optimization (Basis Pursuit) is a near-optimal way to extract information derived from these near-optimal subspaces","title":"Compressed sensing","venue":"IEEE Transactions on Information Theory","year":2006,"__v":0,"citationCount":6079},{"authors":["Emmanuel J. Candès","Justin K. Romberg","Terence Tao"],"references":["2d75f21b-8617-4c21-a1bf-467a82458459","4114181f-6f48-4cb6-b6d3-b337515d57f8","449bfdfc-f916-422c-ac0d-ebfdd2ab773a","53c1d13a-863d-4db2-bc77-bbc7f8a45fa8","5eb8608d-d0a1-4f14-af98-8a26bab51fae","7291a02d-1d94-48b7-a4e2-35406c0e52ad","87a4faed-c1a5-45c8-81eb-3bf19ae19011","d2104367-6389-4b06-8dbe-bab7e05b903b","f11bfae2-e272-4acc-b231-a9619f1e4d6c"],"_id":"a53a3dda-b003-4d5c-96b1-e9afd8e35692","abstract":"This paper considers the model problem of reconstructing an object from incomplete frequency samples. Consider a discrete-time signal f/spl isin/C/sup N/ and a randomly chosen set of frequencies /spl Omega/. Is it possible to reconstruct f from the partial knowledge of its Fourier coefficients on the set /spl Omega/? A typical result of this paper is as follows. Suppose that f is a superposition of |T| spikes f(t)=/spl sigma//sub /spl tau//spl isin/T/f(/spl tau/)/spl delta/(t-/spl tau/) obeying |T|/spl les/C/sub M//spl middot/(log N)/sup -1/ /spl middot/ |/spl Omega/| for some constant C/sub M/>0. We do not know the locations of the spikes nor their amplitudes. Then with probability at least 1-O(N/sup -M/), f can be reconstructed exactly as the solution to the /spl lscr//sub 1/ minimization problem. In short, exact recovery may be obtained by solving a convex optimization problem. We give numerical values for C/sub M/ which depend on the desired probability of success. Our result may be interpreted as a novel kind of nonlinear sampling theorem. In effect, it says that any signal made out of |T| spikes may be recovered by convex programming from almost every set of frequencies of size O(|T|/spl middot/logN). Moreover, this is nearly optimal in the sense that any method succeeding with probability 1-O(N/sup -M/) would in general require a number of frequency samples at least proportional to |T|/spl middot/logN. The methodology extends to a variety of other situations and higher dimensions. For example, we show how one can reconstruct a piecewise constant (one- or two-dimensional) object from incomplete frequency samples - provided that the number of jumps (discontinuities) obeys the condition above - by minimizing other convex functionals such as the total variation of f.","title":"Robust uncertainty principles: exact signal reconstruction from highly incomplete frequency information","venue":"IEEE Transactions on Information Theory","year":2006,"__v":0,"citationCount":3800}],"offsprings":["69b9ef96-11d5-49b0-9ae3-492763e02ca8","71a18de9-e543-4337-ab7a-3db31d9f8c00","d28acb36-5766-4c1e-8d57-a55c2630bd90"]},"71a18de9-e543-4337-ab7a-3db31d9f8c00":{"authors":["Emmanuel J. Candès","Terence Tao"],"references":["6ff01654-66d1-49c7-b526-1c8ed7fa893a","a53a3dda-b003-4d5c-96b1-e9afd8e35692","f56b877b-4060-4754-b303-e8140968544c"],"_id":"71a18de9-e543-4337-ab7a-3db31d9f8c00","abstract":"Suppose we are given a vector f in a class FsubeRopf N  , e.g., a class of digital signals or digital images. How many linear measurements do we need to make about f to be able to recover f to within precision epsi in the Euclidean (lscr 2 ) metric? This paper shows that if the objects of interest are sparse in a fixed basis or compressible, then it is possible to reconstruct f to within very high accuracy from a small number of random measurements by solving a simple linear program. More precisely, suppose that the nth largest entry of the vector |f| (or of its coefficients in a fixed basis) obeys |f| (n) lesRmiddotn -1 p/, where R>0 and p>0. Suppose that we take measurements y k =langf #  ,X k rang,k=1,...,K, where the X k  are N-dimensional Gaussian vectors with independent standard normal entries. Then for each f obeying the decay estimate above for some 0 t , defined as the solution to the constraints y k =langf #  ,X k rang with minimal lscr 1  norm, obeys parf-f # par lscr2 lesC p  middotRmiddot(K/logN) -r , r=1/p-1/2. There is a sense in which this result is optimal; it is generally impossible to obtain a higher accuracy from any set of K measurements whatsoever. The methodology extends to various other random measurement ensembles; for example, we show that similar results hold if one observes a few randomly sampled Fourier coefficients of f. In fact, the results are quite general and require only two hypotheses on the measurement ensemble which are detailed","title":"Near-Optimal Signal Recovery From Random Projections: Universal Encoding Strategies?","venue":"IEEE Transactions on Information Theory","year":2006,"__v":0,"citationCount":1928,"parents":{"036a19f8-fdca-4e84-a237-e54f2108dcb4":0,"2d75f21b-8617-4c21-a1bf-467a82458459":0,"5eb8608d-d0a1-4f14-af98-8a26bab51fae":9.090909090909092,"6ff01654-66d1-49c7-b526-1c8ed7fa893a":36.36363636363637,"87a4faed-c1a5-45c8-81eb-3bf19ae19011":0,"9b021b12-2e59-42bc-9e29-86e480e652b7":0,"a53a3dda-b003-4d5c-96b1-e9afd8e35692":27.27272727272727,"c385db5b-803b-4d88-b756-f7cc417bbfb0":0,"d84405a3-88f2-4f71-8575-d16f3c8d4ca1":18.181818181818183,"e33adb02-12d9-47b9-af5e-b9a79070a920":0,"f56b877b-4060-4754-b303-e8140968544c":45.45454545454545},"keyword":{"036a19f8-fdca-4e84-a237-e54f2108dcb4":10.011243386243386,"2d75f21b-8617-4c21-a1bf-467a82458459":10.225396825396825,"5eb8608d-d0a1-4f14-af98-8a26bab51fae":8.530185185185186,"6ff01654-66d1-49c7-b526-1c8ed7fa893a":9.517619047619048,"87a4faed-c1a5-45c8-81eb-3bf19ae19011":11.101296296296294,"9b021b12-2e59-42bc-9e29-86e480e652b7":8.17210012210012,"a53a3dda-b003-4d5c-96b1-e9afd8e35692":8.287979797979798,"c385db5b-803b-4d88-b756-f7cc417bbfb0":9.123968253968254,"d84405a3-88f2-4f71-8575-d16f3c8d4ca1":9.319494949494949,"e33adb02-12d9-47b9-af5e-b9a79070a920":11.383227513227514,"f56b877b-4060-4754-b303-e8140968544c":11.45631313131313},"topic":["measur","vector","suppos","random","obei"],"groups":[{"authors":["Emmanuel J. Candès","Terence Tao"],"references":["0e654e87-bc20-4fed-bcf8-cb2b99cbd39c","449bfdfc-f916-422c-ac0d-ebfdd2ab773a","71a18de9-e543-4337-ab7a-3db31d9f8c00","87a4faed-c1a5-45c8-81eb-3bf19ae19011","87c3242f-f4a5-4ef1-8ec3-e52c4402b8c0","a53a3dda-b003-4d5c-96b1-e9afd8e35692","d84405a3-88f2-4f71-8575-d16f3c8d4ca1","f11bfae2-e272-4acc-b231-a9619f1e4d6c","f56b877b-4060-4754-b303-e8140968544c","f56dbdc3-f2ee-4a66-a3fb-df142f830dc5"],"_id":"6ff01654-66d1-49c7-b526-1c8ed7fa893a","abstract":"This paper considers a natural error correcting problem with real valued input/output. We wish to recover an input vector f/spl isin/R/sup n/ from corrupted measurements y=Af+e. Here, A is an m by n (coding) matrix and e is an arbitrary and unknown vector of errors. Is it possible to recover f exactly from the data y? We prove that under suitable conditions on the coding matrix A, the input f is the unique solution to the /spl lscr//sub 1/-minimization problem (/spl par/x/spl par//sub /spl lscr/1/:=/spl Sigma//sub i/|x/sub i/|) min(g/spl isin/R/sup n/) /spl par/y - Ag/spl par//sub /spl lscr/1/ provided that the support of the vector of errors is not too large, /spl par/e/spl par//sub /spl lscr/0/:=|{i:e/sub i/ /spl ne/ 0}|/spl les//spl rho//spl middot/m for some /spl rho/>0. In short, f can be recovered exactly by solving a simple convex optimization problem (which one can recast as a linear program). In addition, numerical experiments suggest that this recovery procedure works unreasonably well; f is recovered exactly even in situations where a significant fraction of the output is corrupted. This work is related to the problem of finding sparse solutions to vastly underdetermined systems of linear equations. There are also significant connections with the problem of recovering signals from highly incomplete measurements. In fact, the results introduced in this paper improve on our earlier work. Finally, underlying the success of /spl lscr//sub 1/ is a crucial property we call the uniform uncertainty principle that we shall describe in detail.","title":"Decoding by linear programming","venue":"IEEE Transactions on Information Theory","year":2005,"__v":0,"citationCount":1991},{"authors":["Emmanuel J. Candès","Justin K. Romberg","Terence Tao"],"references":["2d75f21b-8617-4c21-a1bf-467a82458459","4114181f-6f48-4cb6-b6d3-b337515d57f8","449bfdfc-f916-422c-ac0d-ebfdd2ab773a","53c1d13a-863d-4db2-bc77-bbc7f8a45fa8","5eb8608d-d0a1-4f14-af98-8a26bab51fae","7291a02d-1d94-48b7-a4e2-35406c0e52ad","87a4faed-c1a5-45c8-81eb-3bf19ae19011","d2104367-6389-4b06-8dbe-bab7e05b903b","f11bfae2-e272-4acc-b231-a9619f1e4d6c"],"_id":"a53a3dda-b003-4d5c-96b1-e9afd8e35692","abstract":"This paper considers the model problem of reconstructing an object from incomplete frequency samples. Consider a discrete-time signal f/spl isin/C/sup N/ and a randomly chosen set of frequencies /spl Omega/. Is it possible to reconstruct f from the partial knowledge of its Fourier coefficients on the set /spl Omega/? A typical result of this paper is as follows. Suppose that f is a superposition of |T| spikes f(t)=/spl sigma//sub /spl tau//spl isin/T/f(/spl tau/)/spl delta/(t-/spl tau/) obeying |T|/spl les/C/sub M//spl middot/(log N)/sup -1/ /spl middot/ |/spl Omega/| for some constant C/sub M/>0. We do not know the locations of the spikes nor their amplitudes. Then with probability at least 1-O(N/sup -M/), f can be reconstructed exactly as the solution to the /spl lscr//sub 1/ minimization problem. In short, exact recovery may be obtained by solving a convex optimization problem. We give numerical values for C/sub M/ which depend on the desired probability of success. Our result may be interpreted as a novel kind of nonlinear sampling theorem. In effect, it says that any signal made out of |T| spikes may be recovered by convex programming from almost every set of frequencies of size O(|T|/spl middot/logN). Moreover, this is nearly optimal in the sense that any method succeeding with probability 1-O(N/sup -M/) would in general require a number of frequency samples at least proportional to |T|/spl middot/logN. The methodology extends to a variety of other situations and higher dimensions. For example, we show how one can reconstruct a piecewise constant (one- or two-dimensional) object from incomplete frequency samples - provided that the number of jumps (discontinuities) obeys the condition above - by minimizing other convex functionals such as the total variation of f.","title":"Robust uncertainty principles: exact signal reconstruction from highly incomplete frequency information","venue":"IEEE Transactions on Information Theory","year":2006,"__v":0,"citationCount":3800},{"authors":["David L. Donoho"],"references":["036a19f8-fdca-4e84-a237-e54f2108dcb4","05c85ace-c998-47cd-a285-f6ecfd72004d","0bb77e7f-bfc4-4d0d-873a-3d6d3c28b316","0ed39048-dd26-467a-bcd5-7017fcccddb5","225591b8-1c1a-4854-81d4-5b5f364c20a9","2862ec34-58f4-41c0-8790-1740130f1814","2a15f947-2402-4979-94b8-53de9ceef26e","3d414a5e-b97a-498e-8a75-920997235c6b","3dd913b8-e22d-434e-9015-bf68fbbb7bef","3ddea798-1e4f-408a-86db-a611c7bbcdcf","449bfdfc-f916-422c-ac0d-ebfdd2ab773a","4c9f2bac-2f23-4170-a0f1-a3001f63a7b9","5eb8608d-d0a1-4f14-af98-8a26bab51fae","71a18de9-e543-4337-ab7a-3db31d9f8c00","7291a02d-1d94-48b7-a4e2-35406c0e52ad","834863b2-34f0-40dc-b4d2-f4189eaa262a","87a4faed-c1a5-45c8-81eb-3bf19ae19011","8dd4158a-bbc4-40cf-a4d5-14e0fe630387","9b021b12-2e59-42bc-9e29-86e480e652b7","9e65914c-bfef-45e7-9fd7-85c39ed13ac4","a53a3dda-b003-4d5c-96b1-e9afd8e35692","adc31a96-1f8e-4793-8ee9-ecef04a16ac6","ae4ab999-5078-4348-9a3d-94c019952bcc","aecf8a08-eff7-4182-8bbb-a7b29de2f281","bb3c38fa-c2b0-4d4f-8c9d-ca1884343474","c380b798-6583-4821-9613-0a9731b1ced1","c9bf7235-7aad-4e6d-a9a6-e4a6bbddc327","ca546a51-ffda-46b1-b783-ff512ec9c4bd","cd9bd50b-d672-43a9-b0c2-0b332cf0b88e","d2104367-6389-4b06-8dbe-bab7e05b903b","d6457de8-9f03-4671-91da-f557a0ec20e0","defc112d-f91d-4b34-9d44-bd7f702c2391","f11bfae2-e272-4acc-b231-a9619f1e4d6c","ff44599f-5e74-4d9b-94d3-286592973471"],"_id":"f56b877b-4060-4754-b303-e8140968544c","abstract":"Suppose x is an unknown vector in Ropf m  (a digital image or signal); we plan to measure n general linear functionals of x and then reconstruct. If x is known to be compressible by transform coding with a known transform, and we reconstruct via the nonlinear procedure defined here, the number of measurements n can be dramatically smaller than the size m. Thus, certain natural classes of images with m pixels need only n=O(m 1/4 log 5/2 (m)) nonadaptive nonpixel samples for faithful recovery, as opposed to the usual m pixel samples. More specifically, suppose x has a sparse representation in some orthonormal basis (e.g., wavelet, Fourier) or tight frame (e.g., curvelet, Gabor)-so the coefficients belong to an lscr p  ball for 0 2  error O(N 1/2-1 p/). It is possible to design n=O(Nlog(m)) nonadaptive measurements allowing reconstruction with accuracy comparable to that attainable with direct knowledge of the N most important coefficients. Moreover, a good approximation to those N important coefficients is extracted from the n measurements by solving a linear program-Basis Pursuit in signal processing. The nonadaptive measurements have the character of \"random\" linear combinations of basis/frame elements. Our results use the notions of optimal recovery, of n-widths, and information-based complexity. We estimate the Gel'fand n-widths of lscr p  balls in high-dimensional Euclidean space in the case 0<ples1, and give a criterion identifying near- optimal subspaces for Gel'fand n-widths. We show that \"most\" subspaces are near-optimal, and show that convex optimization (Basis Pursuit) is a near-optimal way to extract information derived from these near-optimal subspaces","title":"Compressed sensing","venue":"IEEE Transactions on Information Theory","year":2006,"__v":0,"citationCount":6079}],"offsprings":["69b9ef96-11d5-49b0-9ae3-492763e02ca8","6ff01654-66d1-49c7-b526-1c8ed7fa893a","7236dbb7-f0b2-4e28-bb7c-6de187c32d64","e537d143-155e-4ca0-8ae8-66b777a77fea","f56b877b-4060-4754-b303-e8140968544c"]},"720f59d2-acc3-4d5a-91c2-258d137d9647":{"authors":["Lizhong Zheng","David Tse"],"references":["2659531e-eb9d-4dd5-b46f-10f66a4819c6","324c0cc6-829c-4b4f-8ef4-5f2d9b34bf58","748a2ab3-8b5f-4d0a-9e2d-af685089843a"],"_id":"720f59d2-acc3-4d5a-91c2-258d137d9647","abstract":"Multiple antennas can be used for increasing the amount of diversity or the number of degrees of freedom in wireless communication systems. We propose the point of view that both types of gains can be simultaneously obtained for a given multiple-antenna channel, but there is a fundamental tradeoff between how much of each any coding scheme can get. For the richly scattered Rayleigh-fading channel, we give a simple characterization of the optimal tradeoff curve and use it to evaluate the performance of existing multiple antenna schemes.","title":"Diversity and multiplexing: a fundamental tradeoff in multiple-antenna channels","venue":"IEEE Transactions on Information Theory","year":2003,"__v":0,"citationCount":1901,"parents":{"03eca440-3c16-4758-9706-c853469f7d71":0,"25d7ce16-e254-4d4c-97f4-1b575c0d3e24":33.33333333333333,"2659531e-eb9d-4dd5-b46f-10f66a4819c6":0,"324c0cc6-829c-4b4f-8ef4-5f2d9b34bf58":33.33333333333333,"48a5daf3-5217-4b07-8f66-82dd2934cba6":83.33333333333334,"748a2ab3-8b5f-4d0a-9e2d-af685089843a":0},"keyword":{"03eca440-3c16-4758-9706-c853469f7d71":10.664682539682543,"25d7ce16-e254-4d4c-97f4-1b575c0d3e24":11.846150793650793,"2659531e-eb9d-4dd5-b46f-10f66a4819c6":12.365079365079367,"324c0cc6-829c-4b4f-8ef4-5f2d9b34bf58":11.96468253968254,"48a5daf3-5217-4b07-8f66-82dd2934cba6":12.026587301587302,"748a2ab3-8b5f-4d0a-9e2d-af685089843a":12.866666666666669},"topic":["tradeoff","scheme","multipl","channel","antenna"],"groups":[{"authors":["Babak Hassibi","Bertrand M. Hochwald"],"references":["03eca440-3c16-4758-9706-c853469f7d71","18c098e6-53d8-46a6-a5df-ec51e2c2336f","1ea643f1-3820-4ca3-9297-9ac9ee3c6be6","25d7ce16-e254-4d4c-97f4-1b575c0d3e24","2659531e-eb9d-4dd5-b46f-10f66a4819c6","2a69f973-4ad7-4d6c-bd17-27c13e58768c","2cf70f2e-9996-477e-9ba1-d02ec769c507","324c0cc6-829c-4b4f-8ef4-5f2d9b34bf58","4eec044b-7d46-4ebd-b387-4adca987ad43","748a2ab3-8b5f-4d0a-9e2d-af685089843a","7e78d227-bc04-4fa3-a38b-079ca5f71368","85bd9cc6-e41a-4fd4-8f3b-e776329efc4b","9b17227e-8fa9-4c0e-8487-4b05df9064eb","b99e567e-a281-41cb-a6ec-de5d0ec08063","cab91964-4e8d-4211-8d32-455cfd690b60","ebac2b26-3187-4435-88a2-049cb5463806","fbc50327-e90c-4509-a450-b9942f5b20d4"],"_id":"48a5daf3-5217-4b07-8f66-82dd2934cba6","abstract":"Multiple-antenna systems that operate at high rates require simple yet effective space-time transmission schemes to handle the large traffic volume in real time. At rates of tens of bits per second per hertz, Vertical Bell Labs Layered Space-Time (V-BLAST), where every antenna transmits its own independent substream of data, has been shown to have good performance and simple encoding and decoding. Yet V-BLAST suffers from its inability to work with fewer receive antennas than transmit antennas-this deficiency is especially important for modern cellular systems, where a base station typically has more antennas than the mobile handsets. Furthermore, because V-BLAST transmits independent data streams on its antennas there is no built-in spatial coding to guard against deep fades from any given transmit antenna. On the other hand, there are many previously proposed space-time codes that have good fading resistance and simple decoding, but these codes generally have poor performance at high data rates or with many antennas. We propose a high-rate coding scheme that can handle any configuration of transmit and receive antennas and that subsumes both V-BLAST and many proposed space-time block codes as special cases. The scheme transmits substreams of data in linear combinations over space and time. The codes are designed to optimize the mutual information between the transmitted and received signals. Because of their linear structure, the codes retain the decoding simplicity of V-BLAST, and because of their information-theoretic optimality, they possess many coding advantages. We give examples of the codes and show that their performance is generally superior to earlier proposed methods over a wide range of rates and signal-to-noise ratios (SNRs).","title":"High-rate codes that are linear in space and time","venue":"IEEE Transactions on Information Theory","year":2002,"__v":0,"citationCount":669},{"authors":["Babak Hassibi","Bertrand M. Hochwald"],"references":["03eca440-3c16-4758-9706-c853469f7d71","3688adda-d6ac-4e0b-ad0a-fa0ea618c63b","5012e472-5e5a-40e0-8bef-861918a01641","53bf8c3a-25d7-4d2c-b24b-fcbd835ceb21","748a2ab3-8b5f-4d0a-9e2d-af685089843a","7d911d74-c4c1-4d4d-a737-5cf51e404c83","85bd9cc6-e41a-4fd4-8f3b-e776329efc4b","b99e567e-a281-41cb-a6ec-de5d0ec08063","cab91964-4e8d-4211-8d32-455cfd690b60"],"_id":"25d7ce16-e254-4d4c-97f4-1b575c0d3e24","abstract":"Multiple-antenna wireless communication links promise very high data rates with low error probabilities, especially when the wireless channel response is known at the receiver. In practice, knowledge of the channel is often obtained by sending known training symbols to the receiver. We show how training affects the capacity of a fading channel-too little training and the channel is improperly learned, too much training and there is no time left for data transmission before the channel changes. We compute a lower bound on the capacity of a channel that is learned by training, and maximize the bound as a function of the received signal-to-noise ratio (SNR), fading coherence time, and number of transmitter antennas. When the training and data powers are allowed to vary, we show that the optimal number of training symbols is equal to the number of transmit antennas-this number is also the smallest training interval length that guarantees meaningful estimates of the channel matrix. When the training and data powers are instead required to be equal, the optimal number of symbols may be larger than the number of antennas. We show that training-based schemes can be optimal at high SNR, but suboptimal at low SNR.","title":"How much training is needed in multiple-antenna wireless links?","venue":"IEEE Transactions on Information Theory","year":2003,"__v":0,"citationCount":983},{"authors":["Vahid Tarokh","Hamid Jafarkhani","A.R. Calderbank"],"references":["1c0fc247-3ed3-471c-9976-0ee93bf82e98","2659531e-eb9d-4dd5-b46f-10f66a4819c6","70900ce7-fd5e-4779-a73d-8bdc42cfb3ff","748a2ab3-8b5f-4d0a-9e2d-af685089843a","ebac2b26-3187-4435-88a2-049cb5463806"],"_id":"324c0cc6-829c-4b4f-8ef4-5f2d9b34bf58","abstract":"We introduce space-time block coding, a new paradigm for communication over Rayleigh fading channels using multiple transmit antennas. Data is encoded using a space-time block code and the encoded data is split into n streams which are simultaneously transmitted using n transmit antennas. The received signal at each receive antenna is a linear superposition of the n transmitted signals perturbed by noise. Maximum-likelihood decoding is achieved in a simple way through decoupling of the signals transmitted from different antennas rather than joint detection. This uses the orthogonal structure of the space-time block code and gives a maximum-likelihood decoding algorithm which is based only on linear processing at the receiver. Space-time block codes are designed to achieve the maximum diversity order for a given number of transmit and receive antennas subject to the constraint of having a simple decoding algorithm. The classical mathematical framework of orthogonal designs is applied to construct space-time block codes. It is shown that space-time block codes constructed in this way only exist for few sporadic values of n. Subsequently, a generalization of orthogonal designs is shown to provide space-time block codes for both real and complex constellations for any number of transmit antennas. These codes achieve the maximum possible transmission rate for any number of transmit antennas using any arbitrary real constellation such as PAM. For an arbitrary complex constellation such as PSK and QAM, space-time block codes are designed that achieve 1/2 of the maximum possible transmission rate for any number of transmit antennas. For the specific cases of two, three, and four transmit antennas, space-time block codes are designed that achieve, respectively, all, 3/4, and 3/4 of maximum possible transmission rate using arbitrary complex constellations. The best tradeoff between the decoding delay and the number of transmit antennas is also computed and it is shown that many of the codes presented here are optimal in this sense as well.","title":"Space-time block codes from orthogonal designs","venue":"IEEE Transactions on Information Theory","year":1999,"__v":0,"citationCount":2924}],"offsprings":["6d25cd6f-4a67-41ed-9b6d-467c739f531e","7ae0e791-2e2b-4504-a2fe-caa9b0589c44","d1ba534e-3f80-4366-bb83-be16006f9e18"]},"7236dbb7-f0b2-4e28-bb7c-6de187c32d64":{"authors":["John Wright","Allen Y. Yang","Arvind Ganesh","Shankar Sastry","Yi Ma"],"references":["32d158dc-6f9f-426a-973b-8edc5e4c5dad","56f4b72a-ec39-47ac-8220-899296e7fb18","5e8b0e8a-d687-4333-bfe9-73b4c1bebde5","71a18de9-e543-4337-ab7a-3db31d9f8c00","e3a5cec9-7e82-4c14-86ab-0d95a92712a7"],"_id":"7236dbb7-f0b2-4e28-bb7c-6de187c32d64","abstract":"We consider the problem of automatically recognizing human faces from frontal views with varying expression and illumination, as well as occlusion and disguise. We cast the recognition problem as one of classifying among multiple linear regression models and argue that new theory from sparse signal representation offers the key to addressing this problem. Based on a sparse representation computed by C 1 -minimization, we propose a general classification algorithm for (image-based) object recognition. This new framework provides new insights into two crucial issues in face recognition: feature extraction and robustness to occlusion. For feature extraction, we show that if sparsity in the recognition problem is properly harnessed, the choice of features is no longer critical. What is critical, however, is whether the number of features is sufficiently large and whether the sparse representation is correctly computed. Unconventional features such as downsampled images and random projections perform just as well as conventional features such as eigenfaces and Laplacianfaces, as long as the dimension of the feature space surpasses certain threshold, predicted by the theory of sparse representation. This framework can handle errors due to occlusion and corruption uniformly by exploiting the fact that these errors are often sparse with respect to the standard (pixel) basis. The theory of sparse representation helps predict how much occlusion the recognition algorithm can handle and how to choose the training images to maximize robustness to occlusion. We conduct extensive experiments on publicly available databases to verify the efficacy of the proposed algorithm and corroborate the above claims.","title":"Robust Face Recognition via Sparse Representation","venue":"IEEE Transactions on Pattern Analysis and Machine Intelligence","year":2009,"__v":0,"citationCount":3393,"parents":{"00909251-9935-44f3-94a1-629023b5015b":0,"0ddbfee1-8cc2-49f6-be79-59276f496884":0,"0fa84c94-ae45-44d3-bd37-aa3d48158977":0,"225591b8-1c1a-4854-81d4-5b5f364c20a9":6.0606060606060606,"25e9d8cf-7f9d-4b60-834f-b162c6fb922b":6.0606060606060606,"27505f5b-d81f-4b85-b85e-bd357aaa8468":6.0606060606060606,"2d11c1d7-cd1a-41d8-8468-67ae0bdd3198":6.0606060606060606,"32d158dc-6f9f-426a-973b-8edc5e4c5dad":15.151515151515152,"494b497b-836b-445a-8bcb-095600835d89":6.0606060606060606,"56f4b72a-ec39-47ac-8220-899296e7fb18":0,"5da29eee-8cfd-4916-8b9e-01f58f218f9e":3.0303030303030303,"5e8b0e8a-d687-4333-bfe9-73b4c1bebde5":6.0606060606060606,"649fc07a-8aa2-48d1-97ac-520b6526a3bd":3.0303030303030303,"65106f7a-8bce-4521-ac08-a545f9fd59fa":3.0303030303030303,"71a18de9-e543-4337-ab7a-3db31d9f8c00":0,"7dd65996-11c9-427d-83f6-917895da8a28":3.0303030303030303,"876d9f73-86e8-4af2-87cc-adaf94b2912f":3.0303030303030303,"89bbd7d2-749b-4ec1-8f30-fc1d7c3a39e8":6.0606060606060606,"a0fd543e-bbb5-4e10-ba43-8dc54ad9f4fc":3.0303030303030303,"a1f6fc9b-b718-4c9f-93ee-ca53dcd46468":12.121212121212121,"a2c00050-3078-4ed8-a52d-070859e42c5e":3.0303030303030303,"a866200f-b4ed-4f38-86d5-bd55ba2d0591":6.0606060606060606,"ac8bcd1e-4510-498c-b51b-d85e5d827614":15.151515151515152,"adcd100c-2ef5-409e-8d80-06cfc83fad9e":0,"b0afa6ff-6528-4701-800b-5dc0b5411b0c":0,"b8b938f5-cc7f-40ae-b34b-6b592a487a10":0,"cc2d6b33-8c70-4f7f-be72-897ccde5c95e":3.0303030303030303,"d99d5225-5b3d-406d-9da1-96223bd50daa":0,"db3572c6-2a7e-47d7-9aec-1f57291c55d5":0,"de4fea1d-2739-4e0f-b5a3-08f0df58d787":0,"e3a5cec9-7e82-4c14-86ab-0d95a92712a7":3.0303030303030303,"e6a1607a-88cf-4964-afb5-41f97f7fe2e2":0,"f43261e9-b984-4746-97b2-613e071f6357":3.0303030303030303},"keyword":{"00909251-9935-44f3-94a1-629023b5015b":8.459259259259259,"0ddbfee1-8cc2-49f6-be79-59276f496884":11.761296296296297,"0fa84c94-ae45-44d3-bd37-aa3d48158977":10.100925925925923,"225591b8-1c1a-4854-81d4-5b5f364c20a9":11.280000000000001,"25e9d8cf-7f9d-4b60-834f-b162c6fb922b":10.931084656084655,"27505f5b-d81f-4b85-b85e-bd357aaa8468":9.366164021164021,"2d11c1d7-cd1a-41d8-8468-67ae0bdd3198":10.735410052910053,"32d158dc-6f9f-426a-973b-8edc5e4c5dad":11.150185185185181,"494b497b-836b-445a-8bcb-095600835d89":10.154629629629628,"56f4b72a-ec39-47ac-8220-899296e7fb18":9.642222222222221,"5da29eee-8cfd-4916-8b9e-01f58f218f9e":10.423148148148147,"5e8b0e8a-d687-4333-bfe9-73b4c1bebde5":9.535714285714283,"649fc07a-8aa2-48d1-97ac-520b6526a3bd":9.006084656084655,"65106f7a-8bce-4521-ac08-a545f9fd59fa":8.804312169312169,"71a18de9-e543-4337-ab7a-3db31d9f8c00":11.513796296296295,"7dd65996-11c9-427d-83f6-917895da8a28":7.192328042328043,"876d9f73-86e8-4af2-87cc-adaf94b2912f":9.674338624338624,"89bbd7d2-749b-4ec1-8f30-fc1d7c3a39e8":10.546464646464646,"a0fd543e-bbb5-4e10-ba43-8dc54ad9f4fc":11.199470899470898,"a1f6fc9b-b718-4c9f-93ee-ca53dcd46468":10.301031746031745,"a2c00050-3078-4ed8-a52d-070859e42c5e":12.163624338624338,"a866200f-b4ed-4f38-86d5-bd55ba2d0591":13.033756613756612,"ac8bcd1e-4510-498c-b51b-d85e5d827614":11.957566137566136,"adcd100c-2ef5-409e-8d80-06cfc83fad9e":10.641574074074073,"b0afa6ff-6528-4701-800b-5dc0b5411b0c":9.436375661375662,"b8b938f5-cc7f-40ae-b34b-6b592a487a10":11.086851851851849,"cc2d6b33-8c70-4f7f-be72-897ccde5c95e":6.353703703703704,"d99d5225-5b3d-406d-9da1-96223bd50daa":8.86398148148148,"db3572c6-2a7e-47d7-9aec-1f57291c55d5":11.653465608465607,"de4fea1d-2739-4e0f-b5a3-08f0df58d787":10.45899470899471,"e3a5cec9-7e82-4c14-86ab-0d95a92712a7":10.588888888888889,"e6a1607a-88cf-4964-afb5-41f97f7fe2e2":12.018518518518517,"f43261e9-b984-4746-97b2-613e071f6357":11.747817460317462},"topic":["featur","spars","represent","recognit","occlus"],"offsprings":[]},"750b0ac1-2ac9-4273-a9c8-baad11e26fcd":{"authors":["Arnold W. M. Smeulders","Marcel Worring","Simone Santini","Amarnath Gupta","Ramesh Jain"],"references":["62a46780-e1d9-4186-babe-6179735d785e","6d121e97-e351-4cf9-8c44-d7ab3ce9d9fe","7b57db11-7c4d-4d1e-aa62-3a5d7d1f7987"],"_id":"750b0ac1-2ac9-4273-a9c8-baad11e26fcd","abstract":"Presents a review of 200 references in content-based image retrieval. The paper starts with discussing the working conditions of content-based retrieval: patterns of use, types of pictures, the role of semantics, and the sensory gap. Subsequent sections discuss computational steps for image retrieval systems. Step one of the review is image processing for retrieval sorted by color, texture, and local geometry. Features for retrieval are discussed next, sorted by: accumulative and global features, salient points, object and shape features, signs, and structural combinations thereof. Similarity of pictures and objects in pictures is reviewed for each of the feature types, in close connection to the types and means of feedback the user of the systems is capable of giving by interaction. We briefly discuss aspects of system engineering: databases, system architecture, and evaluation. In the concluding section, we present our view on: the driving force of the field, the heritage from computer vision, the influence on computer vision, the role of similarity and of interaction, the need for databases, the problem of evaluation, and the role of the semantic gap.","title":"Content-based image retrieval at the end of the early years","venue":"IEEE Transactions on Pattern Analysis and Machine Intelligence","year":2000,"__v":0,"citationCount":2724,"parents":{"01a82643-758b-46db-917e-144215d3915d":3.4246575342465753,"01dc8979-b89f-40d9-9aa9-7de7e9907262":0,"057e5c13-bfd9-4aa0-9300-1d8093749691":0,"07c804bf-b60d-4b5d-b004-8f4652e7d81b":0,"08683b46-e544-4abe-9c8f-39d157c68445":0,"09346dc3-f4d0-43a4-8f0b-27e02bcd336e":0.684931506849315,"0b44ebf7-4eae-409f-b741-b2db25325411":0,"0b8a2709-0063-4669-9f4b-0ddc97727562":0,"0f1eaa0c-eee7-4acc-af94-73d15916c178":0.684931506849315,"0fc7a847-923c-4742-9b05-2b46eda24b2e":4.10958904109589,"105edb54-d48b-4470-a4dc-528270ee4c4a":0.684931506849315,"10d5ee98-134d-46be-b7af-dc0d5acc1405":0,"124ea71f-13fc-4665-a482-9fa98c580f0c":4.10958904109589,"13b91eb0-0857-4556-b32a-0f85a1cf43f6":3.4246575342465753,"16088d1a-5061-4460-a562-239f2c64854a":0,"16fb90c7-64db-4630-81a8-1cbe11b50f63":1.36986301369863,"1ba3444f-56b8-417b-bf32-b7d4697e02cb":1.36986301369863,"1d53c20e-0525-4fbe-b3bb-7c67c25d7c40":1.36986301369863,"204e83c6-f9d6-4bbe-8c74-4584f5089fe2":0,"2430d105-9797-43da-ae3f-85eb05580219":0.684931506849315,"292bf0c4-63d9-49ec-b92c-c80af3981a2f":0.684931506849315,"299bc19f-b360-40a9-8a5a-3ba1a2b81b50":0.684931506849315,"2beaa150-6293-4f05-ba04-8e001993e766":1.36986301369863,"2d6fdce7-9dcd-4fed-ac60-99b1a6561a69":0,"2fbc8597-c73d-4ef8-a476-d62dfa8d75c2":2.054794520547945,"32c98966-f9c7-470f-878f-dfa58254f49d":2.054794520547945,"33c875a8-18bd-4d09-ac44-94b9f7c8c86c":1.36986301369863,"349fb506-a6a4-45f2-87cf-b1655b1a0c17":0,"36324e2d-6eee-410e-9263-e91360e09146":2.73972602739726,"37904fdf-66ad-42b1-9694-48e32ac43720":1.36986301369863,"38d2f262-574a-4f9d-a722-eb344dcaa6fe":0,"43ebfc6a-57cb-438f-bafa-37d31ea89f62":0.684931506849315,"4692ae23-5e7b-4148-9a20-c43de265df2d":0.684931506849315,"47da7bf4-23fc-4482-aab2-10edf5a09fca":0.684931506849315,"49bdb7c5-8896-4a89-972b-2dc55021513d":2.054794520547945,"49d17a56-7f35-46bb-8097-19648e664592":0,"4c0ae3e7-45b4-441e-81b2-7b325af64e32":0,"4d65c147-3ff3-4c80-82ad-760057fd2310":0,"4e9492bf-6cf2-4656-8e74-1e001f53c1a0":0,"4ef71595-df33-4849-aafd-7092328d04a7":0,"4f335df3-3e1c-4509-8d1f-37150da1cbca":0,"4fd91387-fce5-4148-8b26-4f8ac2ccbcd8":0,"5147226a-9f85-4006-ac06-86c4e3e68e04":0,"5437c0a0-8f20-49c3-86e5-9d860f3e4f04":1.36986301369863,"56d6466f-28bc-429c-a969-9b9609398481":1.36986301369863,"59131c16-c0b5-46c9-b92d-704cf4bf3916":0,"5af538d7-841b-403f-8289-cdffe6561a9f":2.054794520547945,"5b13695a-1a15-46de-8c88-720b038ac7c2":0,"5dc5d4ae-c0b9-493f-a1c3-b58620a0e954":1.36986301369863,"5ebbd1f5-dfe5-4eec-9883-b8b5efea366c":0,"5f1992df-975f-49e7-bd88-aee0740317cf":2.054794520547945,"613ccc65-c740-48c2-bc5a-a40201830c00":2.054794520547945,"62a46780-e1d9-4186-babe-6179735d785e":1.36986301369863,"67955163-d1e2-47b3-b3ff-c4597c864c66":0.684931506849315,"68741c78-6856-4d2d-80d2-56d4cb2d0c00":0,"6c7e9a4a-9c8f-485c-be97-09ff0a7de6bd":0,"6d121e97-e351-4cf9-8c44-d7ab3ce9d9fe":0,"6e8cc926-79a1-4676-a2bd-f9d49f3144cf":1.36986301369863,"6fe00417-973f-4935-982b-927938de9b4e":1.36986301369863,"70e86498-0a19-465c-8b73-49c2769b1a53":0,"7160e003-46c6-4cc7-b427-f6c5ddb34285":0,"71a0b4b3-2a10-47f8-b4e6-02d021bd2cdb":0,"71bbf2ac-bbe2-4c4b-8695-20e007b18be3":0,"72fdf74e-92ae-42f8-b198-6a41bb040aae":2.73972602739726,"73b8b48b-5bb9-4753-809a-7b09808dbcc4":0.684931506849315,"785d5d28-02ed-4141-8252-e0c97af33acd":0,"79ee46f3-5808-4687-bec9-7b35c9e51fe6":1.36986301369863,"7aaad71c-367e-4140-b65e-fb85ca331eef":0,"7b57db11-7c4d-4d1e-aa62-3a5d7d1f7987":0.684931506849315,"7e7d82ae-865f-46eb-9a38-ad180c1d1d60":4.10958904109589,"863cf94a-5f04-46cf-851a-f074fa05c5eb":0,"873c9c21-6bfd-484c-95ed-c4831ec8e00a":0.684931506849315,"884ae67a-1cbe-4218-a127-49d627c5a366":0,"888335b0-4f9b-4d8c-bef7-193713bb17f0":2.73972602739726,"8b7eb9e8-6dce-481c-a086-c82fcc38e183":0.684931506849315,"93378e13-0f38-429d-964b-abf990d6a37d":0,"93c7b640-cc46-456a-b28e-766535c678ca":0,"940dd83f-b957-4723-ac16-85e1fa052e11":0,"97836b4b-6178-49ca-8e15-806c7b25d6d4":0,"9a6cc355-4198-4d9d-beb3-7debff92fdc1":0.684931506849315,"9aafad2d-9ad2-4d4e-854a-84d07fe650ca":0.684931506849315,"9d92ca2e-e41d-4c3b-b2ba-aef0da9b059a":0,"a0d90db8-3d64-4824-8776-39509d3ab85a":0.684931506849315,"a458241b-dae3-4e7e-aff9-56870bcc1582":0,"a4e97948-d341-4b3a-8bca-692be4b3e954":6.8493150684931505,"a6a2d587-afa3-444d-a42e-323859a3d453":0,"a7456172-92d3-42ee-a7a2-40468d83ae98":0,"a752f75c-ec3e-4d99-8c41-722d11c71edf":0.684931506849315,"a86e5414-94ec-47ea-a612-eea2570f1f9f":4.10958904109589,"ada79c60-f8d7-41d3-a8dc-7a88d22ea37d":0,"b02413cf-84cc-4a82-85f1-6778caf8655e":1.36986301369863,"b1d35657-c2c6-4419-8426-8f08fb2789e1":0,"b1fbed62-1a39-48d6-8eb5-ea103ad6423e":0,"b2e26359-ec4b-4b16-b984-ebf09f74712f":0,"b35967ec-91cc-42cc-8f3b-f2b549b38c8e":1.36986301369863,"b438b1ea-2383-4020-a846-bc45ed142134":0.684931506849315,"b5ccde33-cb4d-406b-85d6-1795f5461d02":1.36986301369863,"b68a4499-9ddb-4138-a69a-0b581d81db7d":5.47945205479452,"b90550fe-58fd-493d-acd5-69abfda625f7":0,"b9d5d8e9-ea08-4a60-a1fe-2164382647b8":2.054794520547945,"bc3816cf-6947-449c-9701-73f313bfea19":0,"bc6cf401-7f1d-4876-a1c5-14af6db3fd06":0.684931506849315,"be049338-2fc9-474c-b985-6746d68cc7ff":0.684931506849315,"bf56425a-14bd-4d62-b98f-f59007edc9f8":0.684931506849315,"c083f584-daa0-4058-9a89-6b03409acfef":1.36986301369863,"c1cfca53-cd2a-475e-838a-abc3a213bd5c":0,"c1fcaf5b-b9f4-4637-8aac-1f884c464bdd":4.10958904109589,"c2ff7aa5-f553-4af9-b17f-3b373eb8603f":1.36986301369863,"c35281be-a5f8-40ad-a5e0-83b4cf051d0b":0.684931506849315,"c698b0f4-e5d4-46da-80f1-d6d75fea9ded":4.10958904109589,"c6e70d2e-f3e2-40e2-aa9d-13942a14710e":0,"c7d7ddbb-63e4-47b8-845e-058c14f87ee1":0,"c8dad09e-e7b4-4a2d-b4b3-0ea3cd49ac52":0.684931506849315,"ca6eae4e-2c85-47b8-ae4c-826ab391e7de":1.36986301369863,"cb10c3e0-5720-49d7-a104-092e044fe976":0,"cd3f5b7e-474f-4f81-8190-f49d040aa621":1.36986301369863,"cf2c28c1-cd51-460d-a17b-d5c55327dfd5":0,"cfe61dfb-59d6-4ee4-9324-e591f8cef78f":2.73972602739726,"d4b8ac10-9d01-426c-bbc3-7c7c3d502bd0":0,"d5888121-db69-44ea-a094-1a84ea8ecfd5":0,"d5f73e0c-bd7d-49aa-8e5b-c659be86408d":3.4246575342465753,"d63dfe13-a2e9-4830-b5f9-05dbb2860871":0,"d77d2585-d702-48e0-859f-4b375e98d148":2.73972602739726,"d9b9f667-9d8a-4723-a6c4-c19b941acd46":0.684931506849315,"da4242f8-17da-4f70-bec8-34b737482e8e":0,"db24cbf4-bb4a-40cf-8acb-dbb142640edd":2.054794520547945,"dc9b7b49-eef6-405d-9708-040d1e79589d":2.054794520547945,"e37185ff-428f-49b5-a976-9b8fdd8b19b2":2.054794520547945,"e5838dcd-d7e4-4782-89fb-808a952a8123":0.684931506849315,"e5adc7b5-fab7-412b-a348-eee57a6a8b2f":1.36986301369863,"e82109f9-480f-445c-b4d7-01ebdcd8dcf8":0.684931506849315,"e9f97d2b-8c49-4b93-ae02-681211621c0d":0,"ea19e0f7-bf6d-4e7e-b1f4-126e3210449b":0,"ec77182b-f881-41b7-a3c1-10cb9a2c65aa":0.684931506849315,"ee93ef28-8456-4d4b-b06f-06f2dfa92be2":0,"f111ff97-89a3-4df6-8f02-962d7b4fe985":0,"f126b5b7-1901-483f-b82b-da1f2975c162":0,"f25abff7-ebe4-4183-bfd1-bd9e82edf603":0.684931506849315,"f3f1d5e7-ead9-43cd-a210-fbed039d66b1":2.054794520547945,"f4a8918d-6016-49e6-931c-81d458bbecb9":0,"f521065e-5afd-4096-9634-f6975ccf1c22":0,"f540f910-52ef-46ae-bc57-aa9115c926c6":1.36986301369863,"f6272ea9-0360-47ed-90a5-651ea958143f":0,"f81d2ba1-0be0-4a5b-b835-a00b6030cc90":1.36986301369863,"f9823250-795a-4899-bb7a-a535cb734de9":0,"feeaf634-76d5-4891-bba3-e56b3f6613ff":0},"keyword":{"01a82643-758b-46db-917e-144215d3915d":9.105555555555556,"01dc8979-b89f-40d9-9aa9-7de7e9907262":11.396587301587301,"057e5c13-bfd9-4aa0-9300-1d8093749691":12.786507936507936,"07c804bf-b60d-4b5d-b004-8f4652e7d81b":0,"08683b46-e544-4abe-9c8f-39d157c68445":10.304603174603173,"09346dc3-f4d0-43a4-8f0b-27e02bcd336e":11.58333333333333,"0b44ebf7-4eae-409f-b741-b2db25325411":11.380661375661376,"0b8a2709-0063-4669-9f4b-0ddc97727562":9.461111111111109,"0f1eaa0c-eee7-4acc-af94-73d15916c178":12.74126984126984,"0fc7a847-923c-4742-9b05-2b46eda24b2e":0,"105edb54-d48b-4470-a4dc-528270ee4c4a":9.523412698412695,"10d5ee98-134d-46be-b7af-dc0d5acc1405":11.758549783549784,"124ea71f-13fc-4665-a482-9fa98c580f0c":10.726984126984124,"13b91eb0-0857-4556-b32a-0f85a1cf43f6":9.565079365079365,"16088d1a-5061-4460-a562-239f2c64854a":12.561904761904762,"16fb90c7-64db-4630-81a8-1cbe11b50f63":10.523015873015876,"1ba3444f-56b8-417b-bf32-b7d4697e02cb":9.23968253968254,"1d53c20e-0525-4fbe-b3bb-7c67c25d7c40":11.000952380952379,"204e83c6-f9d6-4bbe-8c74-4584f5089fe2":0,"2430d105-9797-43da-ae3f-85eb05580219":10.976825396825395,"292bf0c4-63d9-49ec-b92c-c80af3981a2f":9.887301587301588,"299bc19f-b360-40a9-8a5a-3ba1a2b81b50":10.363095238095237,"2beaa150-6293-4f05-ba04-8e001993e766":10.237301587301587,"2d6fdce7-9dcd-4fed-ac60-99b1a6561a69":8.978571428571428,"2fbc8597-c73d-4ef8-a476-d62dfa8d75c2":9.115079365079364,"32c98966-f9c7-470f-878f-dfa58254f49d":9.574603174603173,"33c875a8-18bd-4d09-ac44-94b9f7c8c86c":10.31046176046176,"349fb506-a6a4-45f2-87cf-b1655b1a0c17":0,"36324e2d-6eee-410e-9263-e91360e09146":11.036349206349204,"37904fdf-66ad-42b1-9694-48e32ac43720":9.773809523809522,"38d2f262-574a-4f9d-a722-eb344dcaa6fe":10.872222222222218,"43ebfc6a-57cb-438f-bafa-37d31ea89f62":10.640608465608464,"4692ae23-5e7b-4148-9a20-c43de265df2d":10.354365079365078,"47da7bf4-23fc-4482-aab2-10edf5a09fca":11.413492063492061,"49bdb7c5-8896-4a89-972b-2dc55021513d":11.018253968253967,"49d17a56-7f35-46bb-8097-19648e664592":11.468412698412697,"4c0ae3e7-45b4-441e-81b2-7b325af64e32":9.87077922077922,"4d65c147-3ff3-4c80-82ad-760057fd2310":9.194708994708995,"4e9492bf-6cf2-4656-8e74-1e001f53c1a0":8.434920634920635,"4ef71595-df33-4849-aafd-7092328d04a7":9.549999999999997,"4f335df3-3e1c-4509-8d1f-37150da1cbca":9.245238095238093,"4fd91387-fce5-4148-8b26-4f8ac2ccbcd8":10.174603174603172,"5147226a-9f85-4006-ac06-86c4e3e68e04":12.238253968253968,"5437c0a0-8f20-49c3-86e5-9d860f3e4f04":9.233730158730157,"56d6466f-28bc-429c-a969-9b9609398481":8.935780423280425,"59131c16-c0b5-46c9-b92d-704cf4bf3916":12.334126984126984,"5af538d7-841b-403f-8289-cdffe6561a9f":9.550793650793649,"5b13695a-1a15-46de-8c88-720b038ac7c2":9.680952380952379,"5dc5d4ae-c0b9-493f-a1c3-b58620a0e954":11.000315055315054,"5ebbd1f5-dfe5-4eec-9883-b8b5efea366c":10.167619047619048,"5f1992df-975f-49e7-bd88-aee0740317cf":9.392857142857142,"613ccc65-c740-48c2-bc5a-a40201830c00":10.627777777777778,"62a46780-e1d9-4186-babe-6179735d785e":10.396031746031746,"67955163-d1e2-47b3-b3ff-c4597c864c66":8.750727513227513,"68741c78-6856-4d2d-80d2-56d4cb2d0c00":8.53968253968254,"6c7e9a4a-9c8f-485c-be97-09ff0a7de6bd":10.885317460317458,"6d121e97-e351-4cf9-8c44-d7ab3ce9d9fe":11.51111111111111,"6e8cc926-79a1-4676-a2bd-f9d49f3144cf":11.422619047619047,"6fe00417-973f-4935-982b-927938de9b4e":9.660873015873014,"70e86498-0a19-465c-8b73-49c2769b1a53":12.383333333333333,"7160e003-46c6-4cc7-b427-f6c5ddb34285":10.598968253968252,"71a0b4b3-2a10-47f8-b4e6-02d021bd2cdb":8.880952380952378,"71bbf2ac-bbe2-4c4b-8695-20e007b18be3":9.721428571428572,"72fdf74e-92ae-42f8-b198-6a41bb040aae":11.796190476190478,"73b8b48b-5bb9-4753-809a-7b09808dbcc4":8.962698412698412,"785d5d28-02ed-4141-8252-e0c97af33acd":9.456084656084656,"79ee46f3-5808-4687-bec9-7b35c9e51fe6":8.425793650793649,"7aaad71c-367e-4140-b65e-fb85ca331eef":10.656507936507937,"7b57db11-7c4d-4d1e-aa62-3a5d7d1f7987":4.728571428571428,"7e7d82ae-865f-46eb-9a38-ad180c1d1d60":8.94563492063492,"863cf94a-5f04-46cf-851a-f074fa05c5eb":8.624801587301587,"873c9c21-6bfd-484c-95ed-c4831ec8e00a":10.94222222222222,"884ae67a-1cbe-4218-a127-49d627c5a366":10.600793650793648,"888335b0-4f9b-4d8c-bef7-193713bb17f0":12.129761904761903,"8b7eb9e8-6dce-481c-a086-c82fcc38e183":9.868253968253969,"93378e13-0f38-429d-964b-abf990d6a37d":8.386904761904761,"93c7b640-cc46-456a-b28e-766535c678ca":10.684523809523808,"940dd83f-b957-4723-ac16-85e1fa052e11":8.603174603174603,"97836b4b-6178-49ca-8e15-806c7b25d6d4":10.681640211640211,"9a6cc355-4198-4d9d-beb3-7debff92fdc1":9.921031746031746,"9aafad2d-9ad2-4d4e-854a-84d07fe650ca":9.341269841269844,"9d92ca2e-e41d-4c3b-b2ba-aef0da9b059a":10.279523809523809,"a0d90db8-3d64-4824-8776-39509d3ab85a":9.761507936507936,"a458241b-dae3-4e7e-aff9-56870bcc1582":9.975277777777777,"a4e97948-d341-4b3a-8bca-692be4b3e954":10.264285714285712,"a6a2d587-afa3-444d-a42e-323859a3d453":10.427936507936506,"a7456172-92d3-42ee-a7a2-40468d83ae98":11.617989417989419,"a752f75c-ec3e-4d99-8c41-722d11c71edf":11.26111111111111,"a86e5414-94ec-47ea-a612-eea2570f1f9f":9.632142857142856,"ada79c60-f8d7-41d3-a8dc-7a88d22ea37d":0,"b02413cf-84cc-4a82-85f1-6778caf8655e":8.117857142857144,"b1d35657-c2c6-4419-8426-8f08fb2789e1":9.123174603174604,"b1fbed62-1a39-48d6-8eb5-ea103ad6423e":6.3478306878306885,"b2e26359-ec4b-4b16-b984-ebf09f74712f":11.390873015873018,"b35967ec-91cc-42cc-8f3b-f2b549b38c8e":0,"b438b1ea-2383-4020-a846-bc45ed142134":8.728571428571428,"b5ccde33-cb4d-406b-85d6-1795f5461d02":10.46111111111111,"b68a4499-9ddb-4138-a69a-0b581d81db7d":9.414117364117363,"b90550fe-58fd-493d-acd5-69abfda625f7":7.467460317460318,"b9d5d8e9-ea08-4a60-a1fe-2164382647b8":9.83531746031746,"bc3816cf-6947-449c-9701-73f313bfea19":9.792857142857143,"bc6cf401-7f1d-4876-a1c5-14af6db3fd06":9.741666666666667,"be049338-2fc9-474c-b985-6746d68cc7ff":8.83015873015873,"bf56425a-14bd-4d62-b98f-f59007edc9f8":10.369047619047617,"c083f584-daa0-4058-9a89-6b03409acfef":11.456507936507935,"c1cfca53-cd2a-475e-838a-abc3a213bd5c":8.472222222222221,"c1fcaf5b-b9f4-4637-8aac-1f884c464bdd":9.939841269841269,"c2ff7aa5-f553-4af9-b17f-3b373eb8603f":9.08095238095238,"c35281be-a5f8-40ad-a5e0-83b4cf051d0b":11.800396825396824,"c698b0f4-e5d4-46da-80f1-d6d75fea9ded":9.816666666666666,"c6e70d2e-f3e2-40e2-aa9d-13942a14710e":9.95515873015873,"c7d7ddbb-63e4-47b8-845e-058c14f87ee1":0,"c8dad09e-e7b4-4a2d-b4b3-0ea3cd49ac52":12.046031746031746,"ca6eae4e-2c85-47b8-ae4c-826ab391e7de":9.5815873015873,"cb10c3e0-5720-49d7-a104-092e044fe976":0,"cd3f5b7e-474f-4f81-8190-f49d040aa621":12.189603174603173,"cf2c28c1-cd51-460d-a17b-d5c55327dfd5":8.330555555555556,"cfe61dfb-59d6-4ee4-9324-e591f8cef78f":9.585317460317459,"d4b8ac10-9d01-426c-bbc3-7c7c3d502bd0":11.816031746031744,"d5888121-db69-44ea-a094-1a84ea8ecfd5":11.620634920634918,"d5f73e0c-bd7d-49aa-8e5b-c659be86408d":12.576984126984126,"d63dfe13-a2e9-4830-b5f9-05dbb2860871":8.927777777777775,"d77d2585-d702-48e0-859f-4b375e98d148":11.224603174603173,"d9b9f667-9d8a-4723-a6c4-c19b941acd46":8.991904761904761,"da4242f8-17da-4f70-bec8-34b737482e8e":10.363333333333333,"db24cbf4-bb4a-40cf-8acb-dbb142640edd":11.538492063492065,"dc9b7b49-eef6-405d-9708-040d1e79589d":7.815343915343915,"e37185ff-428f-49b5-a976-9b8fdd8b19b2":10.10722222222222,"e5838dcd-d7e4-4782-89fb-808a952a8123":10.753373015873015,"e5adc7b5-fab7-412b-a348-eee57a6a8b2f":9.76058201058201,"e82109f9-480f-445c-b4d7-01ebdcd8dcf8":0,"e9f97d2b-8c49-4b93-ae02-681211621c0d":8.288888888888888,"ea19e0f7-bf6d-4e7e-b1f4-126e3210449b":11.126322751322752,"ec77182b-f881-41b7-a3c1-10cb9a2c65aa":10.111772486772486,"ee93ef28-8456-4d4b-b06f-06f2dfa92be2":9.982698412698412,"f111ff97-89a3-4df6-8f02-962d7b4fe985":10.733412698412698,"f126b5b7-1901-483f-b82b-da1f2975c162":6.901587301587302,"f25abff7-ebe4-4183-bfd1-bd9e82edf603":10.9484126984127,"f3f1d5e7-ead9-43cd-a210-fbed039d66b1":10.325396825396828,"f4a8918d-6016-49e6-931c-81d458bbecb9":11.824603174603174,"f521065e-5afd-4096-9634-f6975ccf1c22":8.128571428571428,"f540f910-52ef-46ae-bc57-aa9115c926c6":8.55079365079365,"f6272ea9-0360-47ed-90a5-651ea958143f":0,"f81d2ba1-0be0-4a5b-b835-a00b6030cc90":8.986349206349207,"f9823250-795a-4899-bb7a-a535cb734de9":11.583888888888888,"feeaf634-76d5-4891-bba3-e56b3f6613ff":0},"topic":["retriev","system","featur","discuss","type"],"offsprings":[]},"78991392-db9c-45a4-86a2-b4ce93ab0ec0":{"authors":["Paul Barham","Boris Dragovic","Keir Fraser","Steven Hand","Timothy L. Harris","Alex Ho","Rolf Neugebauer","Ian Pratt","Andrew Warfield"],"references":[],"_id":"78991392-db9c-45a4-86a2-b4ce93ab0ec0","abstract":"Numerous systems have been designed which use virtualization to subdivide the ample resources of a modern computer. Some require specialized hardware, or cannot support commodity operating systems. Some target 100% binary compatibility at the expense of performance. Others sacrifice security or functionality for speed. Few offer resource isolation or performance guarantees; most provide only best-effort provisioning, risking denial of service.This paper presents Xen, an x86 virtual machine monitor which allows multiple commodity operating systems to share conventional hardware in a safe and resource managed fashion, but without sacrificing either performance or functionality. This is achieved by providing an idealized virtual machine abstraction to which operating systems such as Linux, BSD and Windows XP, can be  ported  with minimal effort.Our design is targeted at hosting up to 100 virtual machine instances simultaneously on a modern server. The virtualization approach taken by Xen is extremely efficient: we allow operating systems such as Linux and Windows XP to be hosted simultaneously for a negligible performance overhead --- at most a few percent compared with the unvirtualized case. We considerably outperform competing commercial and freely available solutions in a range of microbenchmarks and system-wide tests.","title":"Xen and the art of virtualization","venue":"symposium on operating systems principles","year":2003,"__v":0,"citationCount":2835,"parents":{"115ce5c8-8c08-46b1-a100-f6aaa68f20d5":0,"17d502ec-9d95-412a-b1d4-004fc5d8ab04":7.6923076923076925,"207aecbb-81f9-48c2-b8be-21119bcceafc":0,"2c9ebc3d-713f-42d8-a867-0ff2d24644d3":0,"37c3f144-3bb2-4df7-a05d-d482dbca0398":0,"53f82d8c-22d7-43e4-be03-fe0cdd7b8abc":3.8461538461538463,"553db688-bb98-4ed0-a2a4-42f1e5678559":0,"569b777f-eb40-4fa8-9567-c5844c8c3522":15.384615384615385,"6993119b-feb4-4f91-b2d8-5fe12bcdfa84":0,"70177cf6-e1e7-4624-b371-75b49a1b837f":0,"79df819e-bae3-4d67-bee8-baa3fc148d82":0,"84cdb716-319a-430a-b8e1-90e4848aa187":3.8461538461538463,"9dddf29d-dcfe-4a5c-85cc-6a7b6b2d91b4":0,"b5b9d83b-c85b-4418-8d01-4d00ef8a091f":23.076923076923077,"b5ba979f-ba02-4ba4-975d-8687812f4b70":7.6923076923076925,"c7bf74ee-739c-45c6-9713-6a0eeb08e76d":3.8461538461538463,"d693ff4a-02ea-43a1-bc66-c64970f275a9":7.6923076923076925,"da8e4122-1d7b-449c-b52d-0a43c32fc6e7":15.384615384615385,"dfcd55ef-26c0-41c9-8681-9af2a2afd43b":0,"e49e1d41-99eb-41f7-971b-d9c2544198ed":3.8461538461538463,"e883ae1e-0c54-4fcb-9c38-4165bb0fcc7a":0,"e96dc7d8-19a8-4495-861e-bfc3963361a7":3.8461538461538463,"f483eabe-4858-4d94-88bc-82df43f32a81":19.230769230769234,"f4d35f6d-e961-4f7e-bd18-fda32093cfd0":0,"f67bf40c-fdad-4215-942b-b23b2a017115":3.8461538461538463,"fd5b4339-0328-41fc-90b7-12d5f093072c":11.538461538461538},"keyword":{"115ce5c8-8c08-46b1-a100-f6aaa68f20d5":11.582738095238094,"17d502ec-9d95-412a-b1d4-004fc5d8ab04":11.422222222222222,"207aecbb-81f9-48c2-b8be-21119bcceafc":13.030555555555557,"2c9ebc3d-713f-42d8-a867-0ff2d24644d3":8.361111111111112,"37c3f144-3bb2-4df7-a05d-d482dbca0398":9.24973544973545,"53f82d8c-22d7-43e4-be03-fe0cdd7b8abc":10.022619047619047,"553db688-bb98-4ed0-a2a4-42f1e5678559":7.361904761904762,"569b777f-eb40-4fa8-9567-c5844c8c3522":9.302380952380952,"6993119b-feb4-4f91-b2d8-5fe12bcdfa84":7.434126984126985,"70177cf6-e1e7-4624-b371-75b49a1b837f":11.058412698412699,"79df819e-bae3-4d67-bee8-baa3fc148d82":12.234920634920634,"84cdb716-319a-430a-b8e1-90e4848aa187":9.81190476190476,"9dddf29d-dcfe-4a5c-85cc-6a7b6b2d91b4":11.341269841269842,"b5b9d83b-c85b-4418-8d01-4d00ef8a091f":6.752380952380953,"b5ba979f-ba02-4ba4-975d-8687812f4b70":14.135714285714283,"c7bf74ee-739c-45c6-9713-6a0eeb08e76d":12.62222222222222,"d693ff4a-02ea-43a1-bc66-c64970f275a9":10.38888888888889,"da8e4122-1d7b-449c-b52d-0a43c32fc6e7":10.13968253968254,"dfcd55ef-26c0-41c9-8681-9af2a2afd43b":9.094761904761906,"e49e1d41-99eb-41f7-971b-d9c2544198ed":12.626984126984127,"e883ae1e-0c54-4fcb-9c38-4165bb0fcc7a":13.54484126984127,"e96dc7d8-19a8-4495-861e-bfc3963361a7":9.946031746031744,"f483eabe-4858-4d94-88bc-82df43f32a81":9.743506493506494,"f4d35f6d-e961-4f7e-bd18-fda32093cfd0":8.083982683982683,"f67bf40c-fdad-4215-942b-b23b2a017115":11.755436507936507,"fd5b4339-0328-41fc-90b7-12d5f093072c":10.818888888888889},"topic":["virtual","system","perform","oper","resourc"],"offsprings":["1ae994d8-ddfa-4f61-bf18-8ea62039101f"]},"79da913e-c4d6-4d89-831c-f68f7976dcfc":{"authors":["Dorin Comaniciu","Visvanathan Ramesh","Peter Meer"],"references":["c8f80ea6-4602-458c-9a70-daf1c646c89b","d8116977-0962-4d4d-832d-f9b0a095c75c"],"_id":"79da913e-c4d6-4d89-831c-f68f7976dcfc","abstract":"A new approach toward target representation and localization, the central component in visual tracking of nonrigid objects, is proposed. The feature histogram-based target representations are regularized by spatial masking with an isotropic kernel. The masking induces spatially-smooth similarity functions suitable for gradient-based optimization, hence, the target localization problem can be formulated using the basin of attraction of the local maxima. We employ a metric derived from the Bhattacharyya coefficient as similarity measure, and use the mean shift procedure to perform the optimization. In the presented tracking examples, the new method successfully coped with camera motion, partial occlusions, clutter, and target scale variations. Integration with motion filters and data association techniques is also discussed. We describe only a few of the potential applications: exploitation of background information, Kalman tracking using motion models, and face tracking.","title":"Kernel-based object tracking","venue":"IEEE Transactions on Pattern Analysis and Machine Intelligence","year":2003,"__v":0,"citationCount":1830,"parents":{"0356c68a-a89c-414f-94c9-14d5e08d14c5":6,"042fb7ec-9450-41eb-8d4f-13c10dfe70fd":0,"108c473e-db74-4339-822e-e17a74d2f329":0,"13c491a8-d910-4451-9cc9-fe4a8033976b":2,"1804fbfc-2ae4-453d-a4e2-c8ab074ad3f7":4,"190d4c2a-5e02-4c57-a36e-c8006c62bfc4":0,"198bb43a-bbb0-404b-8368-f96e71a247c0":0,"1b60e8ab-841b-42d9-8747-952d6fe04f24":0,"1ce35e7a-1a66-4397-b498-b3d8e1a19d7e":10,"1e6d4c29-98e4-4007-a16c-3a295919c19d":2,"20334ede-d00f-48aa-999d-6d45f7ea71fd":0,"25628852-b94d-441b-b3ad-0457653b60ae":0,"276c4b24-bf26-4171-b5d4-43bf0b5f2651":4,"2807e6ff-b9a5-49ec-8b9f-892aee014156":0,"2a2192ba-7ef8-4846-8be4-d821c2c80942":0,"2a6552f2-7b75-42c5-89db-b67b6dcbb06f":0,"31548231-500c-4604-b6a5-529d00d691dd":2,"34f6453a-5555-46cf-af48-ac1576ccb367":0,"4388b9be-b7f0-4ee0-8cc6-7732cbc79835":14.000000000000002,"57958425-17fa-46de-a93e-e72f38d481f8":2,"5ea1d692-f72c-472e-8eee-34c564dd6ef1":0,"5f54fdf9-4d11-4f33-945a-db3caa7fabce":2,"64b48bff-1aa8-4367-926a-36a3ac3efa83":0,"64ff61b0-aecc-408b-9da4-8f2b5defe143":2,"67efeb3a-56bb-4bd8-bc0b-dca8f84fa3d3":0,"6aa53073-1db7-4261-a62e-4de18771b83e":2,"6f4c80f6-e108-47c0-8418-9384bd9916b3":6,"779db54d-a398-4ba9-aacf-7fd6cf976dcb":4,"785d5d28-02ed-4141-8252-e0c97af33acd":0,"83961835-aea6-4af4-81a2-4f4ebc03cb64":2,"86b92e76-2e9b-4b45-9343-764916d5f36a":0,"9566466e-3a52-4c00-8ce9-866b938150ff":0,"9e782ace-7971-4a8b-bed8-6d01fbbb88e1":2,"a6c211bd-6b52-4e7c-9ab5-f8ad62f48bf4":2,"ab68780d-3419-4b9f-be4a-354c01e6ca6c":0,"b5f9f0ee-6ad7-4ea6-bf3a-a2f695b6728c":0,"b67d6332-9fa6-47f0-b8e8-40a645c33af1":2,"b68a4499-9ddb-4138-a69a-0b581d81db7d":2,"b85ccd53-b7e0-4023-aa56-36fa9c32cd23":2,"c8f80ea6-4602-458c-9a70-daf1c646c89b":6,"cd42c8ba-6635-44c0-9c18-694f1230f911":0,"d4096c82-a4ad-41c8-a3c6-4aa2924dfcbb":18,"d8116977-0962-4d4d-832d-f9b0a095c75c":6,"d8fe555f-d2ab-4a08-b9e7-ad7e98bab1ff":6,"daa1934c-7847-4ca5-9aa8-143a21f0d61e":0,"e0af11a9-b7e7-4d50-927d-14cc136f484b":0,"ea1ba5e1-b764-40bf-a74e-9a624698ca13":2,"f0b39050-7f52-4ed4-83e0-fd86256c9b3b":0,"f29447e3-0d26-4bcb-993e-a3fc543a07bd":2,"f3eb4ac3-9302-42aa-be89-7cf746f286fd":4},"keyword":{"0356c68a-a89c-414f-94c9-14d5e08d14c5":12.041666666666668,"042fb7ec-9450-41eb-8d4f-13c10dfe70fd":10.007936507936508,"108c473e-db74-4339-822e-e17a74d2f329":11.30478835978836,"13c491a8-d910-4451-9cc9-fe4a8033976b":11.173015873015872,"1804fbfc-2ae4-453d-a4e2-c8ab074ad3f7":11.36920634920635,"190d4c2a-5e02-4c57-a36e-c8006c62bfc4":11.939444444444446,"198bb43a-bbb0-404b-8368-f96e71a247c0":8.340317460317461,"1b60e8ab-841b-42d9-8747-952d6fe04f24":10.37063492063492,"1ce35e7a-1a66-4397-b498-b3d8e1a19d7e":11.377724867724869,"1e6d4c29-98e4-4007-a16c-3a295919c19d":10.57079365079365,"20334ede-d00f-48aa-999d-6d45f7ea71fd":10.436613756613758,"25628852-b94d-441b-b3ad-0457653b60ae":10.172857142857143,"276c4b24-bf26-4171-b5d4-43bf0b5f2651":11.488333333333332,"2807e6ff-b9a5-49ec-8b9f-892aee014156":10.153174603174604,"2a2192ba-7ef8-4846-8be4-d821c2c80942":9.864550264550264,"2a6552f2-7b75-42c5-89db-b67b6dcbb06f":11.899444444444445,"31548231-500c-4604-b6a5-529d00d691dd":12.915793650793653,"34f6453a-5555-46cf-af48-ac1576ccb367":10.210396825396828,"4388b9be-b7f0-4ee0-8cc6-7732cbc79835":12.157962962962962,"57958425-17fa-46de-a93e-e72f38d481f8":10.87989417989418,"5ea1d692-f72c-472e-8eee-34c564dd6ef1":12.363015873015874,"5f54fdf9-4d11-4f33-945a-db3caa7fabce":11.24153439153439,"64b48bff-1aa8-4367-926a-36a3ac3efa83":10.684761904761904,"64ff61b0-aecc-408b-9da4-8f2b5defe143":10.603174603174603,"67efeb3a-56bb-4bd8-bc0b-dca8f84fa3d3":9.963809523809523,"6aa53073-1db7-4261-a62e-4de18771b83e":10.606349206349208,"6f4c80f6-e108-47c0-8418-9384bd9916b3":7.798015873015872,"779db54d-a398-4ba9-aacf-7fd6cf976dcb":11.773386243386245,"785d5d28-02ed-4141-8252-e0c97af33acd":10.313280423280423,"83961835-aea6-4af4-81a2-4f4ebc03cb64":10.218650793650795,"86b92e76-2e9b-4b45-9343-764916d5f36a":9.418571428571427,"9566466e-3a52-4c00-8ce9-866b938150ff":11.22595238095238,"9e782ace-7971-4a8b-bed8-6d01fbbb88e1":12.225343915343913,"a6c211bd-6b52-4e7c-9ab5-f8ad62f48bf4":11.573333333333336,"ab68780d-3419-4b9f-be4a-354c01e6ca6c":9.565608465608467,"b5f9f0ee-6ad7-4ea6-bf3a-a2f695b6728c":9.00952380952381,"b67d6332-9fa6-47f0-b8e8-40a645c33af1":12.329646464646466,"b68a4499-9ddb-4138-a69a-0b581d81db7d":11.71166426166426,"b85ccd53-b7e0-4023-aa56-36fa9c32cd23":9.139523809523808,"c8f80ea6-4602-458c-9a70-daf1c646c89b":10.448333333333332,"cd42c8ba-6635-44c0-9c18-694f1230f911":12.084273504273504,"d4096c82-a4ad-41c8-a3c6-4aa2924dfcbb":7.0689682539682535,"d8116977-0962-4d4d-832d-f9b0a095c75c":10.494960317460317,"d8fe555f-d2ab-4a08-b9e7-ad7e98bab1ff":11.563015873015873,"daa1934c-7847-4ca5-9aa8-143a21f0d61e":8.189603174603175,"e0af11a9-b7e7-4d50-927d-14cc136f484b":9.039523809523809,"ea1ba5e1-b764-40bf-a74e-9a624698ca13":9.49642857142857,"f0b39050-7f52-4ed4-83e0-fd86256c9b3b":10.414285714285715,"f29447e3-0d26-4bcb-993e-a3fc543a07bd":8.95079365079365,"f3eb4ac3-9302-42aa-be89-7cf746f286fd":8.600952380952382},"topic":["track","target","motion","local","similar"],"offsprings":["3ed17ffd-b416-470a-973a-77d7085a3503"]},"7a1624d7-9b8e-44fd-a778-e0d3179b509a":{"authors":["Pascal Paillier"],"references":[],"_id":"7a1624d7-9b8e-44fd-a778-e0d3179b509a","abstract":"This paper investigates a novel computational problem, namely the Composite Residuosity Class Problem, and its applications to public-key cryptography. We propose a new trapdoor mechanism and derive from this technique three encryption schemes : a trapdoor permutation and two homomorphic probabilistic encryption schemes computationally comparable to RSA. Our cryptosystems, based on usual modular arithmetics, are provably secure under appropriate assumptions in the standard model.","title":"Public-key cryptosystems based on composite degree residuosity classes","venue":"theory and application of cryptographic techniques","year":1999,"__v":0,"citationCount":1762,"parents":{"148cb9e4-3fcc-400a-8c3f-1db889f5a580":6.666666666666667,"23b3f5eb-788d-4f7a-bfa7-6c91740ff9ae":13.333333333333334,"3e0b07bd-8cce-4bda-8f9d-3a11ee85d7ab":0,"3fb43b00-905c-4a08-934d-198ea4eb66c3":6.666666666666667,"636420e7-f4cd-4b97-b9a3-fe0afd48e8d5":46.666666666666664,"87bdc5de-ecc3-427a-9c52-4c1190252e73":13.333333333333334,"8cc15b3d-19bc-4a30-be02-ee6dafb6d3a2":20,"90295c5c-f4ab-454c-b414-fb9d50c09232":6.666666666666667,"992c36d4-2f01-499a-9e3c-060a2a6349d4":13.333333333333334,"ac0db18c-141b-499a-9499-bc11ed2a61bc":13.333333333333334,"c9f945e3-a08d-4d60-8330-5e297d21854c":6.666666666666667,"ca394e6a-59e0-466c-a66a-d976555db689":0,"e5a81ae3-0b0f-44de-a676-a851ab030aa2":33.33333333333333,"f36285f7-2106-46e9-9541-f641f53ee5cb":0,"f93b7baa-f5d9-4e6b-a334-acd93db0c14a":0},"keyword":{"148cb9e4-3fcc-400a-8c3f-1db889f5a580":11.457539682539682,"23b3f5eb-788d-4f7a-bfa7-6c91740ff9ae":9.446428571428571,"3e0b07bd-8cce-4bda-8f9d-3a11ee85d7ab":0,"3fb43b00-905c-4a08-934d-198ea4eb66c3":9.77202380952381,"636420e7-f4cd-4b97-b9a3-fe0afd48e8d5":11.120925925925926,"87bdc5de-ecc3-427a-9c52-4c1190252e73":10.986111111111112,"8cc15b3d-19bc-4a30-be02-ee6dafb6d3a2":11.68292328042328,"90295c5c-f4ab-454c-b414-fb9d50c09232":10.784126984126985,"992c36d4-2f01-499a-9e3c-060a2a6349d4":9.669444444444444,"ac0db18c-141b-499a-9499-bc11ed2a61bc":11.99186507936508,"c9f945e3-a08d-4d60-8330-5e297d21854c":0,"ca394e6a-59e0-466c-a66a-d976555db689":10.8859126984127,"e5a81ae3-0b0f-44de-a676-a851ab030aa2":10.262698412698413,"f36285f7-2106-46e9-9541-f641f53ee5cb":11.657936507936508,"f93b7baa-f5d9-4e6b-a334-acd93db0c14a":12.080595238095238},"topic":["trapdoor","scheme","problem","encrypt","comput"],"groups":[{"authors":["Tatsuaki Okamoto","Shigenori Uchiyama"],"references":["0c0be3eb-bae4-4cbc-adb4-f4576b3dcf52","148cb9e4-3fcc-400a-8c3f-1db889f5a580","23b3f5eb-788d-4f7a-bfa7-6c91740ff9ae","29c593e2-6811-440d-b195-872b25fe4085","2c33bdb1-6f8e-4453-8e10-5153056ae70f","36bc98d1-80f2-489a-b3f8-c4a275d4473e","3fb43b00-905c-4a08-934d-198ea4eb66c3","473eebc6-5e23-47ba-a490-baeb9facb5e7","4dff0b06-dc4d-45e9-addc-4f706ef583be","8cc15b3d-19bc-4a30-be02-ee6dafb6d3a2","909e9b98-9692-4087-b0e7-dd31d737a1a2","992c36d4-2f01-499a-9e3c-060a2a6349d4","9bb71c45-6223-4971-83c8-1a7abbf6cbce","afc44d48-8431-409c-86c4-92e69884f08c","b2bd7e0c-7cc0-4c25-80af-c0086065192e","b347416d-111b-495d-a5d2-5aedc3026260","b5214962-41df-43d0-bc1b-5c14af5dd4d7","c9f945e3-a08d-4d60-8330-5e297d21854c","ca394e6a-59e0-466c-a66a-d976555db689","dc736148-208c-484e-8b46-86d8fc45ffb9","e4d8f52b-ebe0-413f-98c8-e3adb2ff3dd5","ec83bc35-2adf-4bff-a33b-bd26b66d4f96"],"_id":"636420e7-f4cd-4b97-b9a3-fe0afd48e8d5","abstract":"This paper proposes a novel public-key cryptosystem, which is practical, provably secure and has some other interesting properties as follows: 1. Its trapdoor technique is essentially different from any other previous schemes including RSA-Rabin and Diffie-Hellman. 2. It is a probabilistic encryption scheme. 3. It can be proven to be as secure as the intractability of factoring n = p 2 q (in the sense of the security of the whole plaintext) against passive adversaries. 4. It is semantically secure under the p-subgroup assumption, which is comparable to the quadratic residue and higher degree residue assumptions. 5. Under the most practical environment, the encryption and decryption speeds of our scheme are comparable to (around twice slower than) those of elliptic curve cryptosystems. 6. It has a homomorphic property: E(m 0 , r 0 )E(m 1 , r 1 ) mod n = E(m 0  + m 1 , r 2 ), where E(m, r) means a ciphertext of plaintext m as randomized by r and m 0  + m 1  < p. 7. Anyone can change a ciphertext, C = E(m,r), into another ciphertext, C' = Ch r  mod n, while preserving plaintext of C (i.e., C '  = E(m,r) ), and the relationship between C and C' can be concealed.","title":"A new public-key cryptosystem as secure as factoring","venue":"theory and application of cryptographic techniques","year":1998,"__v":0,"citationCount":258},{"authors":["David Naccache","Jacques Stern"],"references":["19919bce-f848-407c-8b3f-3860509f6b1d","1ae39de8-3d73-4ab1-a158-6acbc17754fe","2247fa6d-6d9a-45ce-99a6-c45b6ae9796b","3fb43b00-905c-4a08-934d-198ea4eb66c3","5dbc3884-fc05-449c-8adb-755a8a35b253","636420e7-f4cd-4b97-b9a3-fe0afd48e8d5","64503e52-7bab-4b8f-840e-99297e3e3823","87bdc5de-ecc3-427a-9c52-4c1190252e73","8ac5dc1d-ca5d-4095-92a3-611900825422","8cc15b3d-19bc-4a30-be02-ee6dafb6d3a2","9cf7376b-27d1-485a-8690-fedce032e147","a54228e5-b3ee-440d-885f-0cb69fa697cc","ba5ec268-89bc-4e36-b4e1-d6694c24045e","c5920c8a-ace1-48a2-bf68-67f3c6d41512","ca394e6a-59e0-466c-a66a-d976555db689","df4b9319-db76-4f7f-b9b2-74f04347269d","e80394de-f79c-4470-84d3-5586f3d022f4","ea3f24dd-cb99-4993-86cb-5dd35b430fe1"],"_id":"e5a81ae3-0b0f-44de-a676-a851ab030aa2","abstract":"This paper describes a new public-key cryptosystem based on the hardness of computing higher residues modulo a composite RSA integer. We introduce two versions of our scheme, one deterministic and the other probabilistic. The deterministic version is practically oriented: encryption amounts to a single exponentiation w.r.t. a modulus with at least 768 bits and a 160-bit exponent. Decryption can be suitably opti- mized so as to become less demanding than a couple RSA decryptions. Although slower than RSA, the new scheme is still reasonably compet- itive and has several specific applications. The probabilistic version ex- hibits an homomorphic encryption scheme whose expansion rate is much better than previously proposed such systems. Furthermore, it has se- mantic security, relative to the hardness of computing higher residues for suitable moduli.","title":"A new public key cryptosystem based on higher residues","venue":"computer and communications security","year":1998,"__v":0,"citationCount":140}],"offsprings":[]},"7b57db11-7c4d-4d1e-aa62-3a5d7d1f7987":{"authors":["Anil K. Jain","Robert P. W. Duin","Jianchang Mao"],"references":["3704f939-09a2-4e9f-b851-1261bcd310df","91979159-37d8-410f-a245-a33ef80a092b","94898e1d-1e50-41ab-9dcc-2c2e030cddd0","d130ecec-e5cf-4f59-b4f8-1cbda4b0c307"],"_id":"7b57db11-7c4d-4d1e-aa62-3a5d7d1f7987","abstract":"The primary goal of pattern recognition is supervised or unsupervised classification. Among the various frameworks in which pattern recognition has been traditionally formulated, the statistical approach has been most intensively studied and used in practice. More recently, neural network techniques and methods imported from statistical learning theory have been receiving increasing attention. The design of a recognition system requires careful attention to the following issues: definition of pattern classes, sensing environment, pattern representation, feature extraction and selection, cluster analysis, classifier design and learning, selection of training and test samples, and performance evaluation. In spite of almost 50 years of research and development in this field, the general problem of recognizing complex patterns with arbitrary orientation, location, and scale remains unsolved. New and emerging applications, such as data mining, web searching, retrieval of multimedia data, face recognition, and cursive handwriting recognition, require robust and efficient pattern recognition techniques. The objective of this review paper is to summarize and compare some of the well-known methods used in various stages of a pattern recognition system and identify research topics and applications which are at the forefront of this exciting and challenging field.","title":"Statistical pattern recognition: a review","venue":"IEEE Transactions on Pattern Analysis and Machine Intelligence","year":2000,"__v":0,"citationCount":1832,"parents":{"0ddbfee1-8cc2-49f6-be79-59276f496884":0,"0f115eea-2272-431f-9f21-6d6789b2bbc9":0,"1017d9d4-9a4c-423d-ad40-6d9bebbd6b31":0,"1570e0c2-bcf6-4f5a-92db-d1b0936d68d3":1.0416666666666665,"15b9de4b-b1bf-468c-895a-4068f0c91b10":0,"17d88dfa-a5b8-47dd-9fb6-8779e5091c85":2.083333333333333,"17f811d8-8607-4270-bbec-1cc7883edd68":3.125,"18813ec9-e78b-44d3-a5ba-da7e7dc6015d":0,"1f4cd1a9-6aff-45a1-a128-e8b152c53234":1.0416666666666665,"1fb87d62-3355-4868-96f6-e63ae59e677a":1.0416666666666665,"2294d8c1-a608-457a-9f4b-f42ecc9f1a1e":1.0416666666666665,"291970fb-6cf3-4bb5-9be3-48fe984663dc":1.0416666666666665,"2950b285-f9c7-4eb0-bfc7-fe4df52ccac0":1.0416666666666665,"2f040841-f021-43d5-9cd6-774f4bc5400b":0,"3368261c-4a7b-4ccc-b565-bf9748ea1bef":1.0416666666666665,"3514c54b-4a5a-4807-9d10-174915c9202b":0,"3704f939-09a2-4e9f-b851-1261bcd310df":4.166666666666666,"38d2f262-574a-4f9d-a722-eb344dcaa6fe":1.0416666666666665,"3ae9664a-bf6f-45d2-852f-bba9b47e2b8a":5.208333333333334,"46510028-2e6e-4ac6-a306-b63fdac85019":1.0416666666666665,"4a29b56b-b74e-4945-9017-61a7ab844fd9":7.291666666666667,"4aaa373d-ccf1-4c6e-b830-1460e64e685f":1.0416666666666665,"4be27794-9327-4ad0-8ce9-cd349ef2bccf":3.125,"4f2a5d1a-5499-4276-9ce5-877d800c9185":0,"4fdf4d14-8b2a-4800-9c19-bc596f205332":1.0416666666666665,"5206bed9-d48d-44ab-b0cd-4731dfe5679c":1.0416666666666665,"549ecc91-a3d6-4686-be6f-6e98ce9759f1":0,"56e10759-373b-47c1-96be-ae3cfa4821ba":0,"5a542967-6031-4500-9bdf-f3cd017857d1":0,"5babd738-a55d-4da8-898b-bfc590ea0cd0":0,"5baf1067-2662-4a20-8913-37a1cc13b8ac":0,"60a33967-3cc7-4a40-a12b-2d9b3b10481c":0,"63a90a64-9287-49a3-a32b-e64f5ca24734":1.0416666666666665,"6698a29d-42cc-4616-baea-75218c6aef36":0,"69f00f82-45eb-4e2b-b239-5526d80f11ea":0,"6c68311c-2745-446f-9c09-df4632392a78":1.0416666666666665,"6c8cffb5-1552-434d-8941-d5fa38cfdfec":1.0416666666666665,"6d903194-6be4-4780-9ccf-d60916e00770":0,"6e2c579d-7a32-43db-a556-220018b1862a":0,"704a25d2-af53-4637-80cb-47e526b8cfcc":0,"731476cc-0c0f-464b-b397-30192a249ebf":0,"7e0c3b46-e615-4ad8-9552-eee0fc6b0afb":0,"80b153d5-1b0d-4d12-8571-f0d6a6a9a5c8":2.083333333333333,"81501a41-02ee-4d59-a404-9fbf09e65877":0,"842c30d5-98b6-463d-9a23-4841a3e07eb9":0,"8652612a-9673-4d74-90f5-30958bb08e43":0,"898fc99a-3cc7-4c25-9b6f-9a7da43aabc1":0,"8b2c0aff-4589-4e0f-aae4-4f84a4413406":1.0416666666666665,"8d0419f0-7b5b-4765-839d-259b8063a6b3":1.0416666666666665,"8effc0b5-f445-4aca-af07-367f692a4fe2":1.0416666666666665,"8f9b43a0-1ead-4809-bca2-fcd02cd879c4":0,"90951460-27a9-4fab-8d0c-d4cc6faed6c9":2.083333333333333,"90d70858-8bec-48a4-9f03-845a7ed294d7":0,"91979159-37d8-410f-a245-a33ef80a092b":4.166666666666666,"938bce64-1834-47f5-b1d5-3ba473a50655":0,"93c046f1-d93a-48d6-80ba-982b1f0dd1c9":0,"94898e1d-1e50-41ab-9dcc-2c2e030cddd0":1.0416666666666665,"95fdc823-57bc-4e49-8e5b-8fac0c4cfb7f":2.083333333333333,"97d69ea5-2aaf-4b8d-a1b5-795504f7c3fa":1.0416666666666665,"9ba769f6-84ca-4d03-b982-f27c89862ea5":0,"9bd24114-921d-4869-ba66-48e4afef2303":1.0416666666666665,"9ef9becd-d4d5-479d-acc4-bb1c8a17a096":0,"a1dc5d6e-116f-4656-8f57-e4d97dd92cfc":0,"a2f95413-3600-4872-8799-0f10bd845956":0,"a7fd0b86-f937-49e7-a9cd-ee1b06f1bcb0":0,"ab5018cb-1699-434e-858a-a533c0718f2a":0,"ae3e7593-586f-495f-9416-4b50ed1fcd10":0,"b03abbe3-5413-4ef2-a723-24dc15712c3e":1.0416666666666665,"b1067825-8ba0-4b93-be2d-393b00193430":4.166666666666666,"b1731731-ecab-4fe2-8862-18954021c910":1.0416666666666665,"b25d230c-cf98-48d6-a351-a208f7c9ee07":3.125,"b381f9a8-afdb-48e7-a003-c7102373e9be":2.083333333333333,"b4fcc119-4eb1-4094-b16a-1202968654be":2.083333333333333,"b889d6ec-330d-406f-87b6-ea34804fadfd":0,"be4b368f-0e6e-4173-97c7-1f2e54569f75":1.0416666666666665,"c4bbbf1f-8743-4811-8393-9485c7bc01cd":2.083333333333333,"c9fad4d1-d0da-4b5a-bbf9-52a596627b69":0,"d0caab80-3a2b-4538-ac69-0e6f2579662b":2.083333333333333,"d120a352-5f1e-4a64-b65a-85fda703f3be":0,"d130ecec-e5cf-4f59-b4f8-1cbda4b0c307":8.333333333333332,"d589d8c8-b077-4149-8ccd-7690ae8a6770":0,"d90d9345-ccc0-45c4-8c5b-4ef3d7aaf011":0,"da0f35bf-8a7b-4d2e-8626-0a098a4bc854":0,"da4534a6-897c-4431-89ef-cd326bfaf9a8":2.083333333333333,"db3572c6-2a7e-47d7-9aec-1f57291c55d5":0,"dcb051fc-3a36-48d6-b3d8-d2355616b867":0,"e231f2c0-35f5-439b-831e-1bcd1ded5883":3.125,"e62ff43e-b9cf-4db3-91ad-8e1e74384a7c":0,"ea3e7ab3-e7c2-4007-93db-5c459bf3f42e":1.0416666666666665,"ef50a015-6fa7-4d19-8f39-f92c78e2737b":1.0416666666666665,"ef896c6c-0192-4c37-894c-83c30e01e4b8":1.0416666666666665,"f255fe78-83e5-4d24-a7db-6853adcc7d24":0,"f484f56b-640f-4f4a-a9cf-05f9adcafe8d":0,"f60b0079-9454-4cb5-8c7e-ea199e76d8bc":0,"f6c418d7-c420-492f-8d24-de3827674b93":0,"fc603eb6-d237-4584-842c-c80805f31370":0},"keyword":{"0ddbfee1-8cc2-49f6-be79-59276f496884":4.9980158730158735,"0f115eea-2272-431f-9f21-6d6789b2bbc9":0,"1017d9d4-9a4c-423d-ad40-6d9bebbd6b31":0,"1570e0c2-bcf6-4f5a-92db-d1b0936d68d3":5.005952380952381,"15b9de4b-b1bf-468c-895a-4068f0c91b10":4.692063492063491,"17d88dfa-a5b8-47dd-9fb6-8779e5091c85":4.843650793650794,"17f811d8-8607-4270-bbec-1cc7883edd68":4.755952380952381,"18813ec9-e78b-44d3-a5ba-da7e7dc6015d":5.758862433862434,"1f4cd1a9-6aff-45a1-a128-e8b152c53234":5.142063492063491,"1fb87d62-3355-4868-96f6-e63ae59e677a":5.3997354497354495,"2294d8c1-a608-457a-9f4b-f42ecc9f1a1e":3.0615079365079367,"291970fb-6cf3-4bb5-9be3-48fe984663dc":5.239880952380953,"2950b285-f9c7-4eb0-bfc7-fe4df52ccac0":3.0257936507936507,"2f040841-f021-43d5-9cd6-774f4bc5400b":4.011640211640212,"3368261c-4a7b-4ccc-b565-bf9748ea1bef":4.959126984126984,"3514c54b-4a5a-4807-9d10-174915c9202b":5.619841269841269,"3704f939-09a2-4e9f-b851-1261bcd310df":5.398015873015874,"38d2f262-574a-4f9d-a722-eb344dcaa6fe":4.711904761904761,"3ae9664a-bf6f-45d2-852f-bba9b47e2b8a":5.228174603174603,"46510028-2e6e-4ac6-a306-b63fdac85019":4.697222222222221,"4a29b56b-b74e-4945-9017-61a7ab844fd9":4.288888888888889,"4aaa373d-ccf1-4c6e-b830-1460e64e685f":4.565079365079366,"4be27794-9327-4ad0-8ce9-cd349ef2bccf":3.9051587301587305,"4f2a5d1a-5499-4276-9ce5-877d800c9185":4.494047619047619,"4fdf4d14-8b2a-4800-9c19-bc596f205332":4.613095238095238,"5206bed9-d48d-44ab-b0cd-4731dfe5679c":5.340079365079365,"549ecc91-a3d6-4686-be6f-6e98ce9759f1":5.081746031746032,"56e10759-373b-47c1-96be-ae3cfa4821ba":5.367857142857142,"5a542967-6031-4500-9bdf-f3cd017857d1":5.537301587301587,"5babd738-a55d-4da8-898b-bfc590ea0cd0":5.05484126984127,"5baf1067-2662-4a20-8913-37a1cc13b8ac":1.9783068783068785,"60a33967-3cc7-4a40-a12b-2d9b3b10481c":5.14047619047619,"63a90a64-9287-49a3-a32b-e64f5ca24734":5.086904761904761,"6698a29d-42cc-4616-baea-75218c6aef36":4.848571428571428,"69f00f82-45eb-4e2b-b239-5526d80f11ea":0,"6c68311c-2745-446f-9c09-df4632392a78":4.779365079365078,"6c8cffb5-1552-434d-8941-d5fa38cfdfec":4.6874338624338625,"6d903194-6be4-4780-9ccf-d60916e00770":4.919841269841269,"6e2c579d-7a32-43db-a556-220018b1862a":5.161904761904761,"704a25d2-af53-4637-80cb-47e526b8cfcc":5.518650793650793,"731476cc-0c0f-464b-b397-30192a249ebf":3.9208994708994713,"7e0c3b46-e615-4ad8-9552-eee0fc6b0afb":4.101825396825396,"80b153d5-1b0d-4d12-8571-f0d6a6a9a5c8":4.627380952380952,"81501a41-02ee-4d59-a404-9fbf09e65877":4.999206349206349,"842c30d5-98b6-463d-9a23-4841a3e07eb9":5.385978835978836,"8652612a-9673-4d74-90f5-30958bb08e43":5.321031746031745,"898fc99a-3cc7-4c25-9b6f-9a7da43aabc1":5.404365079365079,"8b2c0aff-4589-4e0f-aae4-4f84a4413406":4.904761904761904,"8d0419f0-7b5b-4765-839d-259b8063a6b3":4.397222222222222,"8effc0b5-f445-4aca-af07-367f692a4fe2":4.835281385281385,"8f9b43a0-1ead-4809-bca2-fcd02cd879c4":5.134126984126984,"90951460-27a9-4fab-8d0c-d4cc6faed6c9":5.230952380952381,"90d70858-8bec-48a4-9f03-845a7ed294d7":4.1989417989417985,"91979159-37d8-410f-a245-a33ef80a092b":3.809523809523809,"938bce64-1834-47f5-b1d5-3ba473a50655":5.390873015873015,"93c046f1-d93a-48d6-80ba-982b1f0dd1c9":0,"94898e1d-1e50-41ab-9dcc-2c2e030cddd0":5.18015873015873,"95fdc823-57bc-4e49-8e5b-8fac0c4cfb7f":4.549920634920635,"97d69ea5-2aaf-4b8d-a1b5-795504f7c3fa":4.805555555555555,"9ba769f6-84ca-4d03-b982-f27c89862ea5":4.99537037037037,"9bd24114-921d-4869-ba66-48e4afef2303":4.846190476190476,"9ef9becd-d4d5-479d-acc4-bb1c8a17a096":4.397222222222222,"a1dc5d6e-116f-4656-8f57-e4d97dd92cfc":4.1722222222222225,"a2f95413-3600-4872-8799-0f10bd845956":5.397222222222222,"a7fd0b86-f937-49e7-a9cd-ee1b06f1bcb0":4.785291005291005,"ab5018cb-1699-434e-858a-a533c0718f2a":3.534126984126984,"ae3e7593-586f-495f-9416-4b50ed1fcd10":5.314285714285714,"b03abbe3-5413-4ef2-a723-24dc15712c3e":5.086507936507936,"b1067825-8ba0-4b93-be2d-393b00193430":5.322354497354498,"b1731731-ecab-4fe2-8862-18954021c910":4.265277777777778,"b25d230c-cf98-48d6-a351-a208f7c9ee07":3.6474206349206346,"b381f9a8-afdb-48e7-a003-c7102373e9be":3.9416666666666664,"b4fcc119-4eb1-4094-b16a-1202968654be":5.773703703703704,"b889d6ec-330d-406f-87b6-ea34804fadfd":5.626388888888889,"be4b368f-0e6e-4173-97c7-1f2e54569f75":6.027777777777777,"c4bbbf1f-8743-4811-8393-9485c7bc01cd":5.174603174603175,"c9fad4d1-d0da-4b5a-bbf9-52a596627b69":6.507936507936508,"d0caab80-3a2b-4538-ac69-0e6f2579662b":4.562301587301588,"d120a352-5f1e-4a64-b65a-85fda703f3be":5.182539682539683,"d130ecec-e5cf-4f59-b4f8-1cbda4b0c307":4.47420634920635,"d589d8c8-b077-4149-8ccd-7690ae8a6770":4.9744708994709,"d90d9345-ccc0-45c4-8c5b-4ef3d7aaf011":5.302910052910052,"da0f35bf-8a7b-4d2e-8626-0a098a4bc854":4.567460317460317,"da4534a6-897c-4431-89ef-cd326bfaf9a8":5.019603174603174,"db3572c6-2a7e-47d7-9aec-1f57291c55d5":4.972619047619048,"dcb051fc-3a36-48d6-b3d8-d2355616b867":4.7670634920634924,"e231f2c0-35f5-439b-831e-1bcd1ded5883":5.696560846560846,"e62ff43e-b9cf-4db3-91ad-8e1e74384a7c":4.392195767195767,"ea3e7ab3-e7c2-4007-93db-5c459bf3f42e":5.051719576719577,"ef50a015-6fa7-4d19-8f39-f92c78e2737b":4.541269841269841,"ef896c6c-0192-4c37-894c-83c30e01e4b8":4.958492063492064,"f255fe78-83e5-4d24-a7db-6853adcc7d24":5.1682539682539685,"f484f56b-640f-4f4a-a9cf-05f9adcafe8d":4.6345238095238095,"f60b0079-9454-4cb5-8c7e-ea199e76d8bc":4.442063492063491,"f6c418d7-c420-492f-8d24-de3827674b93":0,"fc603eb6-d237-4584-842c-c80805f31370":5.464417989417989},"topic":["recognit","pattern"],"offsprings":["750b0ac1-2ac9-4273-a9c8-baad11e26fcd","94898e1d-1e50-41ab-9dcc-2c2e030cddd0","c8f80ea6-4602-458c-9a70-daf1c646c89b"]},"7c90045b-63b9-4f29-82a0-bf7c914a6ef6":{"authors":["Ulrike von Luxburg"],"references":["05bbaec3-7980-4941-8638-2bbfa4ac8be0","ea8cd3d8-17ae-4a1e-8f83-1609469087af"],"_id":"7c90045b-63b9-4f29-82a0-bf7c914a6ef6","abstract":"In recent years, spectral clustering has become one of the most popular modern clustering algorithms. It is simple to implement, can be solved efficiently by standard linear algebra software, and very often outperforms traditional clustering algorithms such as the k-means algorithm. On the first glance spectral clustering appears slightly mysterious, and it is not obvious to see why it works at all and what it really does. The goal of this tutorial is to give some intuition on those questions. We describe different graph Laplacians and their basic properties, present the most common spectral clustering algorithms, and derive those algorithms from scratch by several different approaches. Advantages and disadvantages of the different spectral clustering algorithms are discussed.","title":"A tutorial on spectral clustering","venue":"Statistics and Computing","year":2007,"__v":0,"citationCount":2009,"parents":{"05bbaec3-7980-4941-8638-2bbfa4ac8be0":6.0606060606060606,"05c81472-37d6-460f-9343-675d70402c7e":0,"089053a7-cf4b-43fa-9c17-e1e13cdc9278":0,"0a3876f3-df2f-4dd8-b2a1-53bfe7714348":0,"0cdb081e-f2db-49d9-8c65-45cbcc948265":0,"158f4525-404a-4ffc-be57-51f02a53445c":3.0303030303030303,"1b806dc6-7d06-48c4-b8a9-16111d135559":3.0303030303030303,"213ccf22-1ea7-42a3-8369-644a47a5fbe2":27.27272727272727,"2cd6f789-de0b-4d5d-b3d0-60962bd31d41":6.0606060606060606,"31d1a3f9-73ab-4dd3-8977-6b322e5ecc1d":9.090909090909092,"3549c862-c615-4f80-ac53-f562d3e2b846":9.090909090909092,"3b64a259-80c2-4b82-9c04-34a0ee4a20aa":9.090909090909092,"3e1c7e71-b0ee-4ddd-8fb9-09a6bf51181f":0,"44d7e2c1-7a65-4fb8-86e5-ea0bfdad98e9":0,"4d4df750-7647-42f4-b1bb-120d91bc0352":6.0606060606060606,"5d3ddeee-5a39-49b8-8fa3-28099a31f7aa":0,"63ec4f55-8f3b-431e-88e5-87c04caa7e9f":0,"7a1a3bf9-8c23-4c13-8c8e-85b79ad6143e":18.181818181818183,"7ec5f06e-2fe3-495a-84a0-94fcfe08bb7b":3.0303030303030303,"82a4ef1a-c503-49bd-a2f4-34d13537a5f1":3.0303030303030303,"89492dcb-ea5d-4dda-a5fb-687818cbe384":3.0303030303030303,"98da593f-2756-4d08-b67b-f8c610f41354":15.151515151515152,"991b5edd-202d-4194-ac57-e2edb1fb0201":3.0303030303030303,"9fa127d1-10cf-4a8b-b938-bcb079cbc96c":12.121212121212121,"a64c03c2-ba6c-4cc5-afc1-16b4108ea29d":9.090909090909092,"a7da3014-5be5-49a0-a77c-4271633b941c":12.121212121212121,"b6208d93-998c-4593-b2d9-1d3ff936750f":0,"bd55a32a-8dab-4551-806c-bce9e4a32c67":3.0303030303030303,"d33a7b23-08c6-4de6-95c8-e3b6bf8c16bb":9.090909090909092,"dd90433d-a428-4ff1-833d-050702f7699c":9.090909090909092,"ea8cd3d8-17ae-4a1e-8f83-1609469087af":0,"f3b1b423-aa89-4484-b985-666ee01b06c4":3.0303030303030303,"f99a6b3a-0980-4a9e-bbce-f9397c45106f":0},"keyword":{"05bbaec3-7980-4941-8638-2bbfa4ac8be0":6.607549857549857,"05c81472-37d6-460f-9343-675d70402c7e":7.742328042328041,"089053a7-cf4b-43fa-9c17-e1e13cdc9278":0,"0a3876f3-df2f-4dd8-b2a1-53bfe7714348":7.209126984126984,"0cdb081e-f2db-49d9-8c65-45cbcc948265":0,"158f4525-404a-4ffc-be57-51f02a53445c":7.61845238095238,"1b806dc6-7d06-48c4-b8a9-16111d135559":6.839060846560845,"213ccf22-1ea7-42a3-8369-644a47a5fbe2":6.737145262145262,"2cd6f789-de0b-4d5d-b3d0-60962bd31d41":7.433597883597883,"31d1a3f9-73ab-4dd3-8977-6b322e5ecc1d":8.467857142857142,"3549c862-c615-4f80-ac53-f562d3e2b846":6.117195767195767,"3b64a259-80c2-4b82-9c04-34a0ee4a20aa":8.090343915343915,"3e1c7e71-b0ee-4ddd-8fb9-09a6bf51181f":0,"44d7e2c1-7a65-4fb8-86e5-ea0bfdad98e9":7.956283068783069,"4d4df750-7647-42f4-b1bb-120d91bc0352":7.174603174603176,"5d3ddeee-5a39-49b8-8fa3-28099a31f7aa":4.876164021164021,"63ec4f55-8f3b-431e-88e5-87c04caa7e9f":7.636243386243386,"7a1a3bf9-8c23-4c13-8c8e-85b79ad6143e":5.278439153439153,"7ec5f06e-2fe3-495a-84a0-94fcfe08bb7b":8.493650793650795,"82a4ef1a-c503-49bd-a2f4-34d13537a5f1":6.705291005291005,"89492dcb-ea5d-4dda-a5fb-687818cbe384":8.935582010582012,"98da593f-2756-4d08-b67b-f8c610f41354":7.711944444444444,"991b5edd-202d-4194-ac57-e2edb1fb0201":8.801587301587302,"9fa127d1-10cf-4a8b-b938-bcb079cbc96c":6.423863636363636,"a64c03c2-ba6c-4cc5-afc1-16b4108ea29d":6.666005291005291,"a7da3014-5be5-49a0-a77c-4271633b941c":5.93776455026455,"b6208d93-998c-4593-b2d9-1d3ff936750f":7.3001719576719575,"bd55a32a-8dab-4551-806c-bce9e4a32c67":8.391044973544973,"d33a7b23-08c6-4de6-95c8-e3b6bf8c16bb":5.804232804232805,"dd90433d-a428-4ff1-833d-050702f7699c":6.434788359788358,"ea8cd3d8-17ae-4a1e-8f83-1609469087af":8.245478595478595,"f3b1b423-aa89-4484-b985-666ee01b06c4":8.403902116402115,"f99a6b3a-0980-4a9e-bbce-f9397c45106f":7.944179894179895},"topic":["cluster","algorithm","spectral"],"groups":[{"authors":["Boaz Nadler","Stephane Lafon","Ioannis G. Kevrekidis","Ronald R. Coifman"],"references":["05bbaec3-7980-4941-8638-2bbfa4ac8be0","0cdb081e-f2db-49d9-8c65-45cbcc948265","1b806dc6-7d06-48c4-b8a9-16111d135559","220df5f8-cf66-41f0-a25a-be08c4b29d72","2cd6f789-de0b-4d5d-b3d0-60962bd31d41","691b653a-fb64-4c8d-88b5-fc51354f4a9b","7a1a3bf9-8c23-4c13-8c8e-85b79ad6143e","93a14c23-d227-41fd-ad18-7de38817cb52","94898e1d-1e50-41ab-9dcc-2c2e030cddd0","98da593f-2756-4d08-b67b-f8c610f41354","a7da3014-5be5-49a0-a77c-4271633b941c","bd55a32a-8dab-4551-806c-bce9e4a32c67","c472bfe1-9ef6-43c6-89b5-a86b22c9f5df","cbff2ff2-6b8f-425d-a5ef-aff0de9be3e5","d78003db-ad8a-48d2-be57-1c50e95cef72","ea8cd3d8-17ae-4a1e-8f83-1609469087af","f346663a-7df3-4474-97e4-4923cef60cdb"],"_id":"213ccf22-1ea7-42a3-8369-644a47a5fbe2","abstract":"This paper presents a diffusion based probabilistic interpretation of spectral clustering and dimensionality reduction algorithms that use the eigenvectors of the normalized graph Laplacian. Given the pairwise adjacency matrix of all points, we define a diffusion distance between any two data points and show that the low dimensional representation of the data by the first few eigenvectors of the corresponding Markov matrix is optimal under a certain mean squared error criterion. Furthermore, assuming that data points are random samples from a density p(x) = e-U(x) we identify these eigenvectors as discrete approximations of eigenfunctions of a Fokker-Planck operator in a potential 2U(x) with reflecting boundary conditions. Finally, applying known results regarding the eigenvalues and eigenfunctions of the continuous Fokker-Planck operator, we provide a mathematical justification for the success of spectral clustering and dimensional reduction algorithms based on these first few eigenvectors. This analysis elucidates, in terms of the characteristics of diffusion processes, many empirical findings regarding spectral clustering algorithms.","title":"Diffusion Maps, Spectral Clustering and Eigenfunctions of Fokker-Planck Operators","venue":"neural information processing systems","year":2006,"__v":0,"citationCount":121}],"offsprings":["68faab18-b537-4f62-85cf-ddc9ef352362"]},"7c9f8cd8-d0ef-4954-b4db-4a6c803459c2":{"authors":["Josh Broch","David A. Maltz","David B. Johnson","Yih-Chun Hu","Jorjeta G. Jetcheva"],"references":[],"_id":"7c9f8cd8-d0ef-4954-b4db-4a6c803459c2","abstract":"An ad hoc network is a collection of wireless mobile nodes dynamically forming a temporary network without the use of any existing network infrastructure or centralized administration. Due to the limited transmission range of wireless network interfaces, multiple network \"hops\" may be needed for one node to exchange data with another across the network. In recent years, a variety of new routing protocols targeted specifically at this environment have been developed, but little performance information on each protocol and no realistic performance comparison between them is available. This paper presents the results of a detailed packet-level simulation comparing four multi-hop wireless ad hoc network routing protocols that cover a range of design choices: DSDV, TORA, DSR, and AODV. We have extended the ns-2 network simulator to accurately model the MAC and physical-layer behavior of the IEEE 802.11 wireless LAN standard, including a realistic wireless transmission channel model, and present the results of simulations of networks of 50 mobile nodes.","title":"A performance comparison of multi-hop wireless ad hoc network routing protocols","venue":"acm ieee international conference on mobile computing and networking","year":1998,"__v":0,"citationCount":2035,"parents":{"0b93552e-74e8-483f-82cb-5c04e1cd9232":0,"185dfc84-5463-4022-b36f-7e95073d5042":16.666666666666664,"1b0d9aea-0256-494f-a570-f04715825bb1":0,"60fb0dc2-bde3-4714-948e-de0ed12ab460":0,"795ac717-1d24-4688-84c5-984d615cfcc6":33.33333333333333,"83a2eb55-b330-4e0c-8dc9-05e9466d5028":33.33333333333333},"keyword":{"0b93552e-74e8-483f-82cb-5c04e1cd9232":9.950396825396824,"185dfc84-5463-4022-b36f-7e95073d5042":10.731547619047618,"1b0d9aea-0256-494f-a570-f04715825bb1":12.486507936507937,"60fb0dc2-bde3-4714-948e-de0ed12ab460":9.510714285714284,"795ac717-1d24-4688-84c5-984d615cfcc6":9.414285714285713,"83a2eb55-b330-4e0c-8dc9-05e9466d5028":10.843650793650795},"topic":["network","wireless","simul","protocol","node"],"groups":[{"authors":["Vincent Park","M.S. Corson"],"references":["05be6db9-8f44-477b-8b74-ccc734933525","136c4780-2f25-4068-90a5-aed6afaf2890","1b0d9aea-0256-494f-a570-f04715825bb1","47ffb4e4-4dfc-4801-8ec1-588bcfd368cc","60fb0dc2-bde3-4714-948e-de0ed12ab460","7f4325f4-f14b-445d-b0d0-0a5b9aa54114","9014ccd6-8aa0-4c55-9133-91ab7317e309","b29ea294-1a6b-4d57-9b6a-507c87c05ce2","bf12ea29-894b-4bda-b35b-f817257a3d0e"],"_id":"83a2eb55-b330-4e0c-8dc9-05e9466d5028","abstract":"We present a new distributed routing protocol for mobile, multihop, wireless networks. The protocol is one of a family of protocols which we term \"link reversal\" algorithms. The protocol's reaction is structured as a temporally-ordered sequence of diffusing computations; each computation consisting of a sequence of directed link reversals. The protocol is highly adaptive, efficient and scalable; being best-suited for use in large, dense, mobile networks. In these networks, the protocol's reaction to link failures typically involves only a localized \"single pass\" of the distributed algorithm. This capability is unique among protocols which are stable in the face of network partitions, and results in the protocol's high degree of adaptivity. This desirable behavior is achieved through the novel use of a \"physical or logical clock\" to establish the \"temporal order\" of topological change events which is used to structure (or order) the algorithm's reaction to topological changes. We refer to the protocol as the temporally-ordered routing algorithm (TORA).","title":"A highly adaptive distributed routing algorithm for mobile wireless networks","venue":"international conference on computer communications","year":1997,"__v":0,"citationCount":954},{"authors":["Chane L. Fullmer","J. J. Garcia-Luna-Aceves"],"references":["0b93552e-74e8-483f-82cb-5c04e1cd9232","185dfc84-5463-4022-b36f-7e95073d5042","1aaee431-d884-4764-b1ab-fa15594bf745","fb74187b-e0ee-43f4-9383-d95e72e10538"],"_id":"795ac717-1d24-4688-84c5-984d615cfcc6","abstract":"The floor acquisition multiple access (FAMA) discipline is analyzed in networks with hidden terminals. According to FAMA, control of the channel (the floor) is assigned to at most one station in the network at any given time, and this station is guaranteed to be able to transmit one or more data packets to different destinations with no collisions. The FAMA protocols described consist of non-persistent carrier or packet sensing, plus a collision-avoidance dialogue between a source and the intended receiver of a packet. Sufficient conditions under which these protocols provide correct floor acquisition are presented and verified for networks with hidden terminals; it is shown that FAMA protocols must use carrier sensing to support correct floor acquisition. The throughput of FAMA protocols is analyzed for single-channel networks with hidden terminals; it is shown that carrier-sensing FAMA protocols perform better than ALOHA and CSMA protocols in the presence of hidden terminals.","title":"Solutions to hidden terminal problems in wireless networks","venue":"acm special interest group on data communication","year":1997,"__v":0,"citationCount":163}],"offsprings":["afc06b7c-7fb3-4f88-942b-3076ed77920e","96b245c2-47a5-4aec-89f0-d2a362124845","1545dfd3-2c25-4ff1-b43c-df4a2a501d06"]},"7d3726d8-21e5-4321-833d-dfde277c3693":{"authors":["Thomas R. Gruber"],"references":[],"_id":"7d3726d8-21e5-4321-833d-dfde277c3693","abstract":"Recent work in Artificial Intelligence is exploring the use of formal ontologies as a way of specifying content-specific agreements for the sharing and reuse of knowledge among software entities. We take an engineering perspective on the development of such ontologies. Formal ontologies are viewed as designed artifacts, formulated for specific purposes and evaluated against objective design criteria. We describe the role of ontologies in supporting knowledge sharing activities, and then present a set of criteria to guide the development of ontologies for these purposes. We show how these criteria are applied in case studies from the design of ontologies for engineering mathematics and bibliographic data. Selected design decisions are discussed, and alternative representation choices and evaluated against the design criteria.","title":"Toward principles for the design of ontologies used for knowledge sharing","venue":"International Journal of Human-computer Studies \\/ International Journal of Man-machine Studies","year":1995,"__v":0,"citationCount":2347,"parents":{"30991cbc-af1e-4a29-b5ff-d5de5568f6e4":0,"51c34b57-2205-498a-a6cd-eb177d71ee65":11.11111111111111,"598262fa-aa3d-4b51-a653-d1d46ea9a992":0,"59efb068-0be4-45bd-8fcb-be6c7a0b1fe5":0,"70cbf480-918f-400c-8394-fd74f95fc417":0,"8757d294-77c0-42a9-96ec-f5e32c71a4d4":0,"d1c02eba-6883-455c-a3df-91fae59c7d2e":0,"e4969cda-8363-4edc-a39c-f3bab720e197":0,"fccf36d5-8bfb-4a71-ab9b-0e1e1ba08b72":11.11111111111111},"keyword":{"30991cbc-af1e-4a29-b5ff-d5de5568f6e4":0,"51c34b57-2205-498a-a6cd-eb177d71ee65":10.849325396825396,"598262fa-aa3d-4b51-a653-d1d46ea9a992":11.754126984126984,"59efb068-0be4-45bd-8fcb-be6c7a0b1fe5":9.794841269841271,"70cbf480-918f-400c-8394-fd74f95fc417":11.35462962962963,"8757d294-77c0-42a9-96ec-f5e32c71a4d4":0,"d1c02eba-6883-455c-a3df-91fae59c7d2e":10.16111111111111,"e4969cda-8363-4edc-a39c-f3bab720e197":9.490382819794583,"fccf36d5-8bfb-4a71-ab9b-0e1e1ba08b72":11.279682539682538},"topic":["ontolog","design","criteria","share","purpos"],"offsprings":[]},"7f1214b2-e070-4ff2-a5d3-647e7c16c2d7":{"authors":["Zhou Wang","Alan C. Bovik","Hamid Rahim Sheikh","Eero P. Simoncelli"],"references":["9bd00024-b302-407e-92af-5d62759757bd"],"_id":"7f1214b2-e070-4ff2-a5d3-647e7c16c2d7","abstract":"Objective methods for assessing perceptual image quality traditionally attempted to quantify the visibility of errors (differences) between a distorted image and a reference image using a variety of known properties of the human visual system. Under the assumption that human visual perception is highly adapted for extracting structural information from a scene, we introduce an alternative complementary framework for quality assessment based on the degradation of structural information. As a specific example of this concept, we develop a structural similarity index and demonstrate its promise through a set of intuitive examples, as well as comparison to both subjective ratings and state-of-the-art objective methods on a database of images compressed with JPEG and JPEG2000. A MATLAB implementation of the proposed algorithm is available online at http://www.cns.nyu.edu//spl sim/lcv/ssim/.","title":"Image quality assessment: from error visibility to structural similarity","venue":"IEEE Transactions on Image Processing","year":2004,"__v":0,"citationCount":5713,"parents":{"016e3dfb-350a-40c1-872f-ed1b8be4108a":28.57142857142857,"037d3257-c6f1-4ca7-8afe-7d788b23d2da":0,"0566c6b1-834f-44cb-900f-a2fd8f47f8cc":7.142857142857142,"1982b7ad-363d-4a4d-9673-3c431cd22b4d":7.142857142857142,"28b8d07b-a802-4e3a-9dfb-2735d0ef7dfb":0,"2b9cbced-5342-477e-b082-cf15a3be2934":0,"4392923d-3552-451b-8c14-663fa12d79dd":10.714285714285714,"58915db1-cde0-456c-9271-4e43b7efe153":0,"613fab48-0df5-4599-9fe5-48b481f98548":7.142857142857142,"65a38557-50dc-4f3c-bc41-f7bc45b63b54":3.571428571428571,"6bfa4f30-2a89-4ae2-bf1a-41ad952df5d8":14.285714285714285,"91d3815e-d707-4951-ba99-122f7e3b4fd5":10.714285714285714,"9489a56e-051b-4da3-8664-5c021debcc06":10.714285714285714,"9524aeae-f790-443a-a543-9fa47205b54e":0,"9b030b43-281f-42ca-aa9b-c625af825185":21.428571428571427,"9bd00024-b302-407e-92af-5d62759757bd":3.571428571428571,"9cd86bc3-7187-49e5-ab11-9dcd4c70b423":0,"9f542713-2bb2-4d2a-987f-5d3735422bdc":0,"a78c096f-3835-428e-9bbb-c8688f652e16":3.571428571428571,"ab99a18a-b0c2-4f86-91c4-d53f6ed4ebb1":0,"aecf8a08-eff7-4182-8bbb-a7b29de2f281":0,"b74101d6-0cfc-4298-a58d-71ff5d92ea9a":21.428571428571427,"d2275b1f-5443-4243-a1ed-c840ba187d87":7.142857142857142,"e09dd998-1039-4df0-9fe6-10cc77a41c77":3.571428571428571,"e30b7c7e-cbaa-48ce-9ee5-7a4c29b2a4ef":3.571428571428571,"f0563415-aadf-4013-b007-a75ce8db7714":3.571428571428571,"f1e7c5a5-779e-4899-8d9e-62d5127a1939":0,"f286c7c9-8d20-4f20-a0e0-341e76570ea0":0},"keyword":{"016e3dfb-350a-40c1-872f-ed1b8be4108a":10.898809523809524,"037d3257-c6f1-4ca7-8afe-7d788b23d2da":8.17706349206349,"0566c6b1-834f-44cb-900f-a2fd8f47f8cc":10.46005291005291,"1982b7ad-363d-4a4d-9673-3c431cd22b4d":11.52579365079365,"28b8d07b-a802-4e3a-9dfb-2735d0ef7dfb":12.150529100529099,"2b9cbced-5342-477e-b082-cf15a3be2934":11.565277777777778,"4392923d-3552-451b-8c14-663fa12d79dd":10.20410052910053,"58915db1-cde0-456c-9271-4e43b7efe153":11.674603174603176,"613fab48-0df5-4599-9fe5-48b481f98548":10.273809523809522,"65a38557-50dc-4f3c-bc41-f7bc45b63b54":12.075714285714287,"6bfa4f30-2a89-4ae2-bf1a-41ad952df5d8":10.571746031746033,"91d3815e-d707-4951-ba99-122f7e3b4fd5":8.532142857142858,"9489a56e-051b-4da3-8664-5c021debcc06":10.771957671957672,"9524aeae-f790-443a-a543-9fa47205b54e":10.977513227513228,"9b030b43-281f-42ca-aa9b-c625af825185":10.99206349206349,"9bd00024-b302-407e-92af-5d62759757bd":3.6349206349206353,"9cd86bc3-7187-49e5-ab11-9dcd4c70b423":0,"9f542713-2bb2-4d2a-987f-5d3735422bdc":12.347222222222221,"a78c096f-3835-428e-9bbb-c8688f652e16":9.894074074074073,"ab99a18a-b0c2-4f86-91c4-d53f6ed4ebb1":0,"aecf8a08-eff7-4182-8bbb-a7b29de2f281":10.051917989417989,"b74101d6-0cfc-4298-a58d-71ff5d92ea9a":8.890211640211641,"d2275b1f-5443-4243-a1ed-c840ba187d87":11.75277777777778,"e09dd998-1039-4df0-9fe6-10cc77a41c77":10.575873015873016,"e30b7c7e-cbaa-48ce-9ee5-7a4c29b2a4ef":13.406309523809524,"f0563415-aadf-4013-b007-a75ce8db7714":9.976190476190474,"f1e7c5a5-779e-4899-8d9e-62d5127a1939":11.628174603174601,"f286c7c9-8d20-4f20-a0e0-341e76570ea0":12.180158730158729},"topic":["imag","structur","visual","qualiti","object"],"groups":[{"authors":["Michael P. Eckert","Andrew P. Bradley"],"references":["037d3257-c6f1-4ca7-8afe-7d788b23d2da","139cf2f3-19e0-489f-85b7-4881dcfff165","1982b7ad-363d-4a4d-9673-3c431cd22b4d","1d3cdad2-0c96-4693-a08c-f0f4d38647ea","1ef6b375-068c-4691-8a61-4d30dc39808d","23d0131f-4822-41e3-aed7-9701516c2e0a","28b8d07b-a802-4e3a-9dfb-2735d0ef7dfb","36800655-b2ff-4eb7-9070-c6be304c4baa","480a2c09-fdc6-4348-9b03-7a5170df834b","929213d2-97f1-4ef6-8c1b-253f67ad0b77","9bd00024-b302-407e-92af-5d62759757bd","a78c096f-3835-428e-9bbb-c8688f652e16","ab99a18a-b0c2-4f86-91c4-d53f6ed4ebb1","b0e448de-f181-4a33-ac19-ddd0e1eeeaba","b2b23a63-ad26-4cc6-bcd5-d5dc9104ce77","b74101d6-0cfc-4298-a58d-71ff5d92ea9a","d63564a1-6c85-4f2d-bb1f-45d17cec4bed","dfb9bc26-b116-4a6d-8acd-46aed7e02592","eb42fb1b-ebb9-4b7f-abd2-6ef09becd655","f1e7c5a5-779e-4899-8d9e-62d5127a1939","f42aad97-6be2-4c58-8e3b-2b6b4ded606c","f758f489-1bd9-405f-bb6b-9c6dc087e335","fad0058a-cf91-4f4e-859a-12d817db5d53"],"_id":"016e3dfb-350a-40c1-872f-ed1b8be4108a","abstract":"We present a review of perceptual image quality metrics and their application to still image compression. The review describes how image quality metrics can be used to guide an image compression scheme and outlines the advantages, disadvantages and limitations of a number of quality metrics. We examine a broad range of metrics ranging from simple mathematical measures to those which incorporate full perceptual models. We highlight some variation in the models for luminance adaptation and the contrast sensitivity function and discuss what appears to be a lack of a general consensus regarding the models which best describe contrast masking and error summation. We identify how the various perceptual components have been incorporated in quality metrics, and identify a number of psychophysical testing techniques that can be used to validate the metrics. We conclude by illustrating some of the issues discussed throughout the paper with a simple demonstration. (C) 1998 Elsevier Science B.V. All rights reserved.","title":"Perceptual quality metrics applied to still image compression","venue":"Signal Processing","year":1998,"__v":0,"citationCount":110},{"authors":["Zhou Wang","Alan C. Bovik"],"references":["02ad2ee4-f101-4df0-b2cf-9e9a4cc29904","0d3ab957-2162-40cc-ad73-433b081a8099","26df4bb5-0596-4725-96e0-5cae9e3a9de9","380ee98a-c203-4017-93be-facc127989f5","4729a1b8-b9bf-496e-a642-d9f0ef4bcae5","9524aeae-f790-443a-a543-9fa47205b54e","9bd00024-b302-407e-92af-5d62759757bd","a2ca9333-af8b-4b08-bfef-6c553c24d31e","a6702d98-8961-4aef-a09c-9a8bf23bb7ab","a78c096f-3835-428e-9bbb-c8688f652e16","a980d215-6c62-4c1e-8f1c-ea78ad66b83e","aecf8a08-eff7-4182-8bbb-a7b29de2f281","b0e448de-f181-4a33-ac19-ddd0e1eeeaba","b74101d6-0cfc-4298-a58d-71ff5d92ea9a","bd21a55f-7854-4e67-889d-61e3c7b9842e","c0be4d67-bf26-45a0-a056-483b4c3dc82f","d0059d86-9e2d-48cb-b116-cfec0b24d5fb","ee3fa7f4-a88d-4b58-8ee8-843370ed51be","f1b87c3e-d079-41bb-b788-6af5f1af2eb2","f286c7c9-8d20-4f20-a0e0-341e76570ea0","f9966ac4-728f-4864-8644-9d4aa0d6c311"],"_id":"9b030b43-281f-42ca-aa9b-c625af825185","abstract":"The human visual system (HVS) is highly space-variant in sampling, coding, processing, and understanding. The spatial resolution of the HVS is highest around the point of fixation (foveation point) and decreases rapidly with increasing eccentricity. By taking advantage of this fact, it is possible to remove considerable high-frequency information redundancy from the peripheral regions and still reconstruct a perceptually good quality image. Great success has been obtained previously by a class of embedded wavelet image coding algorithms, such as the embedded zerotree wavelet (EZW) and the set partitioning in hierarchical trees (SPIHT) algorithms. Embedded wavelet coding not only provides very good compression performance, but also has the property that the bitstream can be truncated at any point and still be decoded to recreate a reasonably good quality image. In this paper, we propose an embedded foveation image coding (EFIC) algorithm, which orders the encoded bitstream to optimize foveated visual quality at arbitrary bit-rates. A foveation-based image quality metric, namely, foveated wavelet image quality index (FWQI), plays an important role in the EFIC system. We also developed a modified SPIHT algorithm to improve the coding efficiency. Experiments show that EFIC integrates foveation filtering with foveated image coding and demonstrates very good coding performance and scalability in terms of foveated image quality measurement.","title":"Embedded foveation image coding","venue":"IEEE Transactions on Image Processing","year":2001,"__v":0,"citationCount":91}],"offsprings":[]},"8026f56a-a93e-4933-8ead-c9aa9e3f0498":{"authors":["Mark A. Hall","Eibe Frank","Geoffrey Holmes","Bernhard Pfahringer","Peter Reutemann","Ian H. Witten"],"references":["4cbd7765-c47a-4004-a5f8-c2da7c7d1c7b","c1b6b493-01ef-420f-be44-7bacfe34e846"],"_id":"8026f56a-a93e-4933-8ead-c9aa9e3f0498","abstract":"More than twelve years have elapsed since the first public release of WEKA. In that time, the software has been rewritten entirely from scratch, evolved substantially and now accompanies a text on data mining [35]. These days, WEKA enjoys widespread acceptance in both academia and business, has an active community, and has been downloaded more than 1.4 million times since being placed on Source-Forge in April 2000. This paper provides an introduction to the WEKA workbench, reviews the history of the project, and, in light of the recent 3.6 stable release, briefly discusses what has been added since the last stable version (Weka 3.4) released in 2003.","title":"The WEKA data mining software: an update","venue":"knowledge discovery and data mining","year":2009,"__v":0,"citationCount":5847,"parents":{"2f3397df-feb5-48bf-b120-74f8643cf85f":0,"307db816-5b31-4902-b554-29597320719d":0,"3b247c61-c539-4f54-9295-8d6b379316e6":0,"3e0ad93f-aa9f-402a-b2a6-bcd008aa5eb4":0,"4cbd7765-c47a-4004-a5f8-c2da7c7d1c7b":4,"5113d676-dde0-4807-86e1-460567719413":0,"55fff3f7-2df2-4ff1-833a-f040099a0958":0,"57a3a136-170f-4557-90ec-b46bc4095260":0,"5af5a87e-9360-4dd6-bde1-0aae7d9d1ab0":0,"5daf2270-cd5c-4833-a0c8-50a584d59c63":0,"76d74d72-d6eb-4240-9677-2760b375b75d":0,"78a8e7be-0693-414f-a88d-3525d294c94f":0,"853c9c28-f8e8-49ff-9a53-7e2472d4a670":0,"863f58c4-462b-41ba-a018-79371353d959":0,"8ed6c561-0706-4724-b0f3-bbce686ec3c6":0,"99a154b1-f489-4d8d-8c46-44ade2a250f1":4,"a5f043bb-8503-4578-998e-0298edabcb83":0,"b17ce4d9-37c3-4568-b9c4-a00bb44ec0fd":0,"b7e95219-3a35-4515-9559-66e58a01a9c9":0,"b81cf038-b064-473b-8178-086b21b92788":0,"bc889676-4be9-4288-a05e-580080038bac":0,"c1b6b493-01ef-420f-be44-7bacfe34e846":0,"cab6ead4-35d5-4cf6-80ba-1b9a14bf2fd5":0,"eb957b6d-4f22-4f13-94cc-847210fad714":0,"f7b1307a-d793-4f56-8a72-215db0f593a3":0},"keyword":{"2f3397df-feb5-48bf-b120-74f8643cf85f":7.842328042328043,"307db816-5b31-4902-b554-29597320719d":10.384920634920634,"3b247c61-c539-4f54-9295-8d6b379316e6":7.743650793650793,"3e0ad93f-aa9f-402a-b2a6-bcd008aa5eb4":8.053253968253967,"4cbd7765-c47a-4004-a5f8-c2da7c7d1c7b":10.590687830687829,"5113d676-dde0-4807-86e1-460567719413":11.040555555555553,"55fff3f7-2df2-4ff1-833a-f040099a0958":10.915608465608464,"57a3a136-170f-4557-90ec-b46bc4095260":9.55916305916306,"5af5a87e-9360-4dd6-bde1-0aae7d9d1ab0":5.766031746031747,"5daf2270-cd5c-4833-a0c8-50a584d59c63":9.581666666666665,"76d74d72-d6eb-4240-9677-2760b375b75d":10.16111111111111,"78a8e7be-0693-414f-a88d-3525d294c94f":11.664814814814813,"853c9c28-f8e8-49ff-9a53-7e2472d4a670":8.415555555555557,"863f58c4-462b-41ba-a018-79371353d959":11.626613756613754,"8ed6c561-0706-4724-b0f3-bbce686ec3c6":10.094708994708995,"99a154b1-f489-4d8d-8c46-44ade2a250f1":9.565608465608465,"a5f043bb-8503-4578-998e-0298edabcb83":10.179444444444444,"b17ce4d9-37c3-4568-b9c4-a00bb44ec0fd":7.8687830687830695,"b7e95219-3a35-4515-9559-66e58a01a9c9":7.765740740740741,"b81cf038-b064-473b-8178-086b21b92788":11.086666666666666,"bc889676-4be9-4288-a05e-580080038bac":9.210714285714284,"c1b6b493-01ef-420f-be44-7bacfe34e846":10.126666666666665,"cab6ead4-35d5-4cf6-80ba-1b9a14bf2fd5":0,"eb957b6d-4f22-4f13-94cc-847210fad714":8.298412698412697,"f7b1307a-d793-4f56-8a72-215db0f593a3":10.424999999999999},"topic":["weka","releas","time","stabl","year"],"offsprings":[]},"824bdcf9-0415-4d86-b93f-3789fd2d053c":{"authors":["Chi-Keung Luk","Robert S. Cohn","Robert Muth","Harish Patil","Artur Klauser","P. Geoffrey Lowney","Steven Wallace","Vijay Janapa Reddi","Kim M. Hazelwood"],"references":[],"_id":"824bdcf9-0415-4d86-b93f-3789fd2d053c","abstract":"Robust and powerful software instrumentation tools are essential for program analysis tasks such as profiling, performance evaluation, and bug detection. To meet this need, we have developed a new instrumentation system called  Pin . Our goals are to provide  easy-to-use, portable, transparent , and  efficient  instrumentation. Instrumentation tools (called  Pintools ) are written in C/C++ using Pin's rich API. Pin follows the model of ATOM, allowing the tool writer to analyze an application at the instruction level without the need for detailed knowledge of the underlying instruction set. The API is designed to be  architecture independent  whenever possible, making Pintools source compatible across different architectures. However, a Pintool can access architecture-specific details when necessary. Instrumentation with Pin is mostly  transparent  as the application and Pintool observe the application's original, uninstrumented behavior. Pin uses  dynamic compilation  to instrument executables while they are running. For efficiency, Pin uses several techniques, including inlining, register re-allocation, liveness analysis, and instruction scheduling to optimize instrumentation. This fully automated approach delivers significantly better instrumentation performance than similar tools. For example, Pin is 3.3x faster than Valgrind and 2x faster than DynamoRIO for basic-block counting. To illustrate Pin's versatility, we describe two Pintools in daily use to analyze production software. Pin is publicly available for Linux platforms on four architectures: IA32 (32-bit x86), EM64T (64-bit x86), Itanium®, and ARM. In the ten months since Pin 2 was released in July 2004, there have been over 3000 downloads from its website.","title":"Pin: building customized program analysis tools with dynamic instrumentation","venue":"programming language design and implementation","year":2005,"__v":0,"citationCount":1545,"parents":{"0243e135-7f62-4182-8e4f-b4e4add01140":7.142857142857142,"09d89f23-5855-4e18-a2b8-d791b01fb035":0,"4454f4ed-f386-47af-a620-45e899256811":14.285714285714285,"5b58b998-7d67-4b44-805a-7393f2716414":14.285714285714285,"5b8af319-5ff1-48f3-96ab-0c6f0d7c9dbb":0,"740a960f-1599-41d4-96e8-50dabda9d808":0,"94a25085-e644-4777-845c-c14ee764da78":0,"94dbbe06-3920-4b02-9c60-d04e3f73f276":0,"b63d9b77-f545-45d7-b0e6-c70a53953534":14.285714285714285,"c11ea1c5-ab9a-406f-bce1-02b46ee2a706":0,"c96a48b7-32ae-457d-97df-01411dc3b59e":42.857142857142854,"d88177cf-df45-4a24-a4d6-4bcf75fdba2c":7.142857142857142,"ea6ab276-7d09-44b3-bbcd-decb9c803110":0,"f0040b63-e713-4784-94f6-e6517bae4f18":0},"keyword":{"0243e135-7f62-4182-8e4f-b4e4add01140":0,"09d89f23-5855-4e18-a2b8-d791b01fb035":12.060886243386244,"4454f4ed-f386-47af-a620-45e899256811":10.520238095238094,"5b58b998-7d67-4b44-805a-7393f2716414":4.7027777777777775,"5b8af319-5ff1-48f3-96ab-0c6f0d7c9dbb":10.780952380952382,"740a960f-1599-41d4-96e8-50dabda9d808":8.959920634920634,"94a25085-e644-4777-845c-c14ee764da78":9.89920634920635,"94dbbe06-3920-4b02-9c60-d04e3f73f276":7.7634920634920634,"b63d9b77-f545-45d7-b0e6-c70a53953534":10.512301587301588,"c11ea1c5-ab9a-406f-bce1-02b46ee2a706":8.548989898989898,"c96a48b7-32ae-457d-97df-01411dc3b59e":9.208862433862434,"d88177cf-df45-4a24-a4d6-4bcf75fdba2c":13.57198412698413,"ea6ab276-7d09-44b3-bbcd-decb9c803110":9.320383597883598,"f0040b63-e713-4784-94f6-e6517bae4f18":12.172698412698415},"topic":["pin","instrument","pintool","tool","instruct"],"groups":[{"authors":["Derek Bruening","Saman P. Amarasinghe"],"references":["09d89f23-5855-4e18-a2b8-d791b01fb035","0b54d04a-4913-4213-a575-6d9d849e1215","0b721b96-8a8a-49e7-a017-aabc5bd492b0","1745557e-d393-4b0b-861d-f49e79084b2e","1b1de7a0-5add-49c9-b4da-2589aba4093c","212b2a84-65a5-40ef-bd85-30e9c76926af","29cc5a0a-3aa9-4be6-97ed-e7a26c84901d","2b2ec4fd-8f16-464d-b9cf-fccae38ae88c","2bef8d6c-ad15-4982-af66-7c7b588fcae9","30c07ec5-5f7c-46e7-a109-e1cc39f29d7c","36c85006-2dfc-4079-82ad-6381ec498bc9","3a6bbf92-20f8-42a3-9eac-9552e5239ce7","3a6d6ea9-a6f9-49c3-8ece-e63c04c8b7c6","4454f4ed-f386-47af-a620-45e899256811","47d5ae16-c93f-4cc3-bd53-2c29694f4daa","49998f08-756d-45cb-b80a-edc96db034c4","4b435485-0a7b-4d97-bf25-cac6f20c1996","4ff8e05d-b403-4b72-97e4-86d5d453b84d","509473ba-ad2f-4706-89fc-4e537252a8b8","5299e62a-9d0b-4998-94ff-423fc1775fe0","53f82d8c-22d7-43e4-be03-fe0cdd7b8abc","564a7370-0f07-43a4-a56f-530369aab5af","569b777f-eb40-4fa8-9567-c5844c8c3522","5b58b998-7d67-4b44-805a-7393f2716414","5d5f1fd2-2059-4775-ac09-2198f3fc6964","5e6d87c2-6b68-4033-98cc-f7cf03a71f8b","65cb8b4d-b4ff-4db8-9852-18f78138eaaa","69abc2f5-b15c-447c-90cf-18ce8f740134","714b9b11-563e-4194-8bbb-e1abe8a02c60","78991392-db9c-45a4-86a2-b4ce93ab0ec0","7abbc5d1-6ee4-4ea2-bdf2-1eb46fb80155","7d38ede7-dc56-421f-8033-6db6b1237b56","7e182520-45bd-491b-855c-31aceef3d6f7","7f75a7c1-0140-4309-ba95-a64ba8550ce0","81e0c8c3-f275-4b31-926d-0a3dc185c4b8","83ff3981-c4c8-47db-a7fd-cee8fca7d88b","8cfbc4e3-c8cc-41ce-b9b8-71a6800b9db0","90c889ca-6e78-4b0e-88d7-6d684e670050","9223b6ff-e6cf-4712-89d0-588fc800b340","94a25085-e644-4777-845c-c14ee764da78","94fbc0ff-4485-4899-a1ea-e317bbdc07e3","96c9a5b2-6a2c-4ceb-abe7-707ff60f060b","985d03bc-5708-4a21-a7f7-6f15cab23f03","9bb6c7e9-4991-4041-b29c-6ee38af8c813","9dc7ccfb-9771-40cb-9e77-436398d337cc","a3ae983a-a5b1-4a66-85c4-f7eaba90def6","af0bdc04-be44-43c0-aba6-a3b04834fd58","b4f7a3ff-ab3a-495e-a0ae-b26ca8f76fc8","b682b7a2-aa37-48a1-b644-15198ca308dc","bf73f520-4d69-4396-a71c-c7dcbfc9d761","c0acc669-36c2-4f5e-9022-7e61f69a8700","c11ea1c5-ab9a-406f-bce1-02b46ee2a706","c6626bb5-a96e-42b0-b1d1-7bc3ecb69b31","c6aa11f4-6556-4aff-94b1-0a78c465b0c8","ca0f8470-acb8-4352-b016-366d161e0b13","d88177cf-df45-4a24-a4d6-4bcf75fdba2c","dae0401b-c49e-4261-a262-6e62d5ea26bc","dbe707a1-ecde-425c-a028-2e6e164bdcc0","dcd2ba06-38e5-4298-95b3-406e7f452c30","dd978e70-b1a7-4c90-b8cf-28b8614aba10","df018f89-195d-4917-9cfe-18e1229666d6","dfa95972-fa91-45b7-b140-76cfbd81e5a7","dfe956b4-b304-497f-8db3-40b2b990282e","e4124519-003e-4064-876c-865014bf6e2f","e90ae5c7-15ba-4ce7-ba32-0a2a6dcc37c5","e9b4081d-d54d-4bfd-8c83-238d1be7401d","ee2e72dc-6ddc-4a88-859a-1422d359c9e3","f3da6894-a3a0-48ed-bcf7-dde3afa572e2","fe62a189-7e0f-4129-802b-a992fd12666e","ff6b7c27-f17b-4e6c-ae88-57099b14309d"],"_id":"c96a48b7-32ae-457d-97df-01411dc3b59e","abstract":"This thesis addresses the challenges of building a software system for general-purpose runtime code manipulation. Modern applications, with dynamically-loaded modules and dynamically-generated code, are assembled at runtime. While it was once feasible at compile time to observe and manipulate every instruction—which is critical for program analysis, instrumentation, trace gathering, optimization, and similar tools—it can now only be done at runtime. Existing runtime tools are successful at inserting instrumentation calls, but no general framework has been developed for fine-grained and comprehensive code observation and modification without high overheads. #R##N#This thesis demonstrates the feasibility of building such a system in software. We present DynamoRIO, a fully-implemented runtime code manipulation system that supports code transformations on any part of a program, while it executes. DynamoRIO uses code caching technology to provide efficient, transparent, and comprehensive manipulation of an unmodified application running on a stock operating system and commodity hardware. DynamoRIO executes large, complex, modern applications with dynamically-loaded, generated, or even modified code. Despite the formidable obstacles inherent in the IA-32 architecture, DynamoRIO provides these capabilities efficiently, with zero to thirty percent time and memory overhead on both Windows and Linux. #R##N#DynamoRIO exports an interface for building custom runtime code manipulation tools of all types. It has been used by many researchers, with several hundred downloads of our public release, and is being commercialized in a product for protection against remote security exploits, one of numerous applications of runtime code manipulation. (Copies available exclusively from MIT Libraries, Rm. 14-0551, Cambridge, MA 02139-4307. Ph. 617-253-5668; Fax 617-253-1690.)","title":"Efficient, transparent, and comprehensive runtime code manipulation","venue":"","year":2004,"__v":0,"citationCount":105}],"offsprings":[]},"82eb55e6-39a8-4968-8be6-e2bfbb439a40":{"authors":["Vicent Caselles","Ron Kimmel","Guillermo Sapiro"],"references":[],"_id":"82eb55e6-39a8-4968-8be6-e2bfbb439a40","abstract":"A novel scheme for the detection of object boundaries is presented. The technique is based on active contours deforming according to intrinsic geometric measures of the image. The evolving contours naturally split and merge, allowing the simultaneous detection of several objects and both interior and exterior boundaries. The proposed approach is based on the relation between active contours and the computation of geodesics or minimal distance curves. The minimal distance curve lays in a Riemannian space whose metric as defined by the image content. This geodesic approach for object segmentation allows to connect classical \"snakes\" based on energy minimization and geometric active contours based on the theory of curve evolution. Previous models of geometric active contours are improved as showed by a number of examples. Formal results concerning existence, uniqueness, stability, and correctness of the evolution are presented as well. >","title":"Geodesic active contours","venue":"international conference on computer vision","year":1995,"__v":0,"citationCount":2129,"parents":{"050ca16f-ca2a-4614-b2a1-6f56154238c0":4,"1aab9f45-5ddc-407d-813d-ef41f63e6208":4,"1c63e1d5-b963-455b-829d-e4f3eb63a36a":0,"270de21e-f73e-44bb-a424-43441369f827":4,"2ccb01b5-e59c-4ff4-b627-a76a72c9738c":8,"3620aa43-c845-4b25-9da5-61a5d4f85609":20,"36800655-b2ff-4eb7-9070-c6be304c4baa":4,"36dd023a-14a7-479a-89c6-26d731dc5ae3":4,"3f4cc95c-5f47-4031-8671-e23ff4fe2ed2":0,"5b255d3a-5639-41cf-886b-8377bea8193f":4,"61aa50fc-f75b-4246-9235-5e8e1b2846bc":0,"85a39731-9a54-4d2c-9b92-d8ba04b28763":0,"893791c5-4414-4db6-a307-472768e36e3b":8,"8c80ee9a-3e0f-40a6-965c-d0a0fc3aa9d9":16,"a32162d0-5f52-44b4-8bb1-be62d003f5d0":12,"b1d5effd-27a3-417f-8ac3-8988e00c4558":12,"b2de99a5-01d1-4359-be11-10c2ce130a05":12,"b3c68e31-fa5b-49c8-9fac-bf19a78e41b6":12,"c5e1a14b-3106-4195-820a-3d57b17a590b":0,"e500049d-e42e-43a5-8e0c-4f57cdf91fa7":16,"e89b3a55-ab36-4ed2-ae8f-cf297b58efa8":16,"ef330947-bc34-4f55-834b-40469ee33769":8,"f18355d4-bc52-48c8-bae0-309cb9d4307a":8,"f4353d3d-9909-40cb-be04-9fc4d5ef8635":12,"fc33562a-70e0-4279-887a-de8bc085d565":4},"keyword":{"050ca16f-ca2a-4614-b2a1-6f56154238c0":8.695489417989416,"1aab9f45-5ddc-407d-813d-ef41f63e6208":7.688783068783067,"1c63e1d5-b963-455b-829d-e4f3eb63a36a":7.369047619047619,"270de21e-f73e-44bb-a424-43441369f827":6.939867724867725,"2ccb01b5-e59c-4ff4-b627-a76a72c9738c":10.858888888888888,"3620aa43-c845-4b25-9da5-61a5d4f85609":8.143121693121692,"36800655-b2ff-4eb7-9070-c6be304c4baa":10.789841269841272,"36dd023a-14a7-479a-89c6-26d731dc5ae3":8.438275613275612,"3f4cc95c-5f47-4031-8671-e23ff4fe2ed2":0,"5b255d3a-5639-41cf-886b-8377bea8193f":7.111111111111112,"61aa50fc-f75b-4246-9235-5e8e1b2846bc":10.179656084656084,"85a39731-9a54-4d2c-9b92-d8ba04b28763":8.816666666666668,"893791c5-4414-4db6-a307-472768e36e3b":8.477777777777778,"8c80ee9a-3e0f-40a6-965c-d0a0fc3aa9d9":10.096031746031747,"a32162d0-5f52-44b4-8bb1-be62d003f5d0":8.845238095238095,"b1d5effd-27a3-417f-8ac3-8988e00c4558":6.9071428571428575,"b2de99a5-01d1-4359-be11-10c2ce130a05":8.658492063492064,"b3c68e31-fa5b-49c8-9fac-bf19a78e41b6":5.1975,"c5e1a14b-3106-4195-820a-3d57b17a590b":7.152380952380953,"e500049d-e42e-43a5-8e0c-4f57cdf91fa7":8.926349206349206,"e89b3a55-ab36-4ed2-ae8f-cf297b58efa8":8.658492063492064,"ef330947-bc34-4f55-834b-40469ee33769":6.5400793650793645,"f18355d4-bc52-48c8-bae0-309cb9d4307a":9.93452380952381,"f4353d3d-9909-40cb-be04-9fc4d5ef8635":8.30952380952381,"fc33562a-70e0-4279-887a-de8bc085d565":6.89957671957672},"topic":["contour","base","activ","object","minim"],"offsprings":["5ffadf36-4496-4be6-b8a8-828fa37f7757","443fb8d3-09ba-45a2-98a6-597799c3e63c","3ed17ffd-b416-470a-973a-77d7085a3503"]},"839e59b8-b356-4329-ba79-97f981cf6768":{"authors":["Daniel D. Lee","H. Sebastian Seung"],"references":[],"_id":"839e59b8-b356-4329-ba79-97f981cf6768","abstract":"Non-negative matrix factorization (NMF) has previously been shown to be a useful decomposition for multivariate data. Two different multiplicative algorithms for NMF are analyzed. They differ only slightly in the multiplicative factor used in the update rules. One algorithm can be shown to minimize the conventional least squares error while the other minimizes the generalized Kullback-Leibler divergence. The monotonic convergence of both algorithms can be proven using an auxiliary function analogous to that used for proving convergence of the Expectation-Maximization algorithm. The algorithms can also be interpreted as diagonally rescaled gradient descent, where the rescaling factor is optimally chosen to ensure convergence.","title":"Algorithms for Non-negative Matrix Factorization","venue":"neural information processing systems","year":2001,"__v":0,"citationCount":2397,"parents":{"328aafa9-db5d-4ac4-9338-fe918ea60f42":0,"5cd74e0b-f25c-4aaf-8327-7ec949c7d098":20,"9707d672-9d01-4f8e-bfa0-028ed63f0837":0,"b0217d71-3709-4ada-a5de-a78af1de2e02":0,"cd17473b-9aec-4099-bf27-b116490b43ea":0},"keyword":{"328aafa9-db5d-4ac4-9338-fe918ea60f42":9.79052429052429,"5cd74e0b-f25c-4aaf-8327-7ec949c7d098":0,"9707d672-9d01-4f8e-bfa0-028ed63f0837":9.11984126984127,"b0217d71-3709-4ada-a5de-a78af1de2e02":11.558068783068782,"cd17473b-9aec-4099-bf27-b116490b43ea":9.344047619047616},"topic":["algorithm","factor","converg","shown","rescal"],"offsprings":["e537d143-155e-4ca0-8ae8-66b777a77fea"]},"85352dec-58be-43db-a428-f3f574ff96ec":{"authors":["Wei Ye","John S. Heidemann","Deborah Estrin"],"references":["23dd7fc0-1ebd-43ce-ab3e-43896512c209","afc06b7c-7fb3-4f88-942b-3076ed77920e"],"_id":"85352dec-58be-43db-a428-f3f574ff96ec","abstract":"This paper proposes S-MAC, a medium-access control (MAC) protocol designed for wireless sensor networks. Wireless sensor networks use battery-operated computing and sensing devices. A network of these devices will collaborate for a common application such as environmental monitoring. We expect sensor networks to be deployed in an ad hoc fashion, with individual nodes remaining largely inactive for long periods of time, but then becoming suddenly active when something is detected. These characteristics of sensor networks and applications motivate a MAC that is different from traditional wireless MACs such as IEEE 802.11 in almost every way: energy conservation and self-configuration are primary goals, while per-node fairness and latency are less important. S-MAC uses three novel techniques to reduce energy consumption and support self-configuration. To reduce energy consumption in listening to an idle channel, nodes periodically sleep. Neighboring nodes form virtual clusters to auto-synchronize on sleep schedules. Inspired by PAMAS, S-MAC also sets the radio to sleep during transmissions of other nodes. Unlike PAMAS, it only uses in-channel signaling. Finally, S-MAC applies message passing to reduce contention latency for sensor-network applications that require store-and-forward processing as data move through the network. We evaluate our implementation of S-MAC over a sample sensor node, the Mote, developed at University of California, Berkeley. The experiment results show that, on a source node, an 802.11-like MAC consumes 2-6 times more energy than S-MAC for traffic load with messages sent every 1-10 s.","title":"An energy-efficient MAC protocol for wireless sensor networks","venue":"international conference on computer communications","year":2002,"__v":0,"citationCount":2377,"parents":{"0b93552e-74e8-483f-82cb-5c04e1cd9232":0,"1dd8c68d-3b20-4171-9245-3a12c64c2838":20,"2088d2fd-d0ed-477f-b350-5d342624e91e":50,"23dd7fc0-1ebd-43ce-ab3e-43896512c209":0,"330841ef-6d92-4fe7-aebe-c8e7abaf9cd2":0,"4f60dbc7-9647-4b91-b96f-9f77d07fea7c":10,"55a6413a-4a9c-4e8d-957b-8c1a4e5d5f0b":0,"6858fa05-89cf-48b9-ab78-507b868de4bd":10,"73574f5f-bf4f-44fb-b13f-d5eaa8c96619":30,"afc06b7c-7fb3-4f88-942b-3076ed77920e":20},"keyword":{"0b93552e-74e8-483f-82cb-5c04e1cd9232":10.360396825396824,"1dd8c68d-3b20-4171-9245-3a12c64c2838":9.984523809523807,"2088d2fd-d0ed-477f-b350-5d342624e91e":10.521957671957672,"23dd7fc0-1ebd-43ce-ab3e-43896512c209":11.144047619047617,"330841ef-6d92-4fe7-aebe-c8e7abaf9cd2":10.086111111111112,"4f60dbc7-9647-4b91-b96f-9f77d07fea7c":11.50277777777778,"55a6413a-4a9c-4e8d-957b-8c1a4e5d5f0b":0,"6858fa05-89cf-48b9-ab78-507b868de4bd":10.200649350649348,"73574f5f-bf4f-44fb-b13f-d5eaa8c96619":9.726587301587303,"afc06b7c-7fb3-4f88-942b-3076ed77920e":9.671428571428573},"topic":["smac","node","network","sensor","mac"],"groups":[{"authors":["Alec Woo","David E. Culler"],"references":["0b93552e-74e8-483f-82cb-5c04e1cd9232","10f58ff9-c14e-4bf5-9c44-0a3f14626d3f","1dd8c68d-3b20-4171-9245-3a12c64c2838","3804c050-c207-4072-8077-f61297d009aa","38f54b84-5272-43df-8cde-a3e755b17dee","6858fa05-89cf-48b9-ab78-507b868de4bd","686b1f97-3cb7-47a6-bbd2-e8ba891dc1b5"],"_id":"73574f5f-bf4f-44fb-b13f-d5eaa8c96619","abstract":"We study the problem of media access control in the novel regime of sensor networks, where unique application behavior and tight constraints in computation power, storage, energy resources, and radio technology have shaped this design space to be very different from that found in traditional mobile computing regime. Media access control in sensor networks must not only be energy efficient but should also allow fair bandwidth allocation to the infrastructure for all nodes in a multihop network. We propose an adaptive rate control mechanism aiming to support these two goals and find that such a scheme is most effective in achieving our fairness goal while being energy efficient for both low and high duty cycle of network traffic.","title":"A transmission control scheme for media access in sensor networks","venue":"acm ieee international conference on mobile computing and networking","year":2001,"__v":0,"citationCount":445},{"authors":["John S. Heidemann","Fabio Silva","Chalermek Intanagonwiwat","Ramesh Govindan","Deborah Estrin","Deepak Ganesan"],"references":["05fb3436-276f-43ca-979b-0a3323240c19","094c330a-2a29-4c7f-b1da-21f35dd85560","23dd7fc0-1ebd-43ce-ab3e-43896512c209","31c5e39a-3f24-4d20-bf8c-3d00036baf95","4ce4d734-c29c-4097-9ca9-314feaccc642","4f60dbc7-9647-4b91-b96f-9f77d07fea7c","5520148d-133b-4512-91d3-bf4379992ac8","55a6413a-4a9c-4e8d-957b-8c1a4e5d5f0b","6500989e-b1e1-4b02-a921-21ec25685b73","6858fa05-89cf-48b9-ab78-507b868de4bd","7c9f8cd8-d0ef-4954-b4db-4a6c803459c2","83cff325-43e0-4161-aedd-01bd59463cc7","8448e4d9-0abd-4733-a786-f808673ea8b4","84dc5aaa-7b2c-4f15-97f4-aa867b4328e2","8887b1ca-a0eb-40a0-ae8e-52c935dcafec","9b2403f1-010a-490b-bff6-d607b24c4009","9eac8f56-e6ce-4d57-89ba-6f1119209b9a","afc06b7c-7fb3-4f88-942b-3076ed77920e","afe332fa-d8bd-425f-b861-f32a53e2a1f1","c2ae33d8-85e5-4d1d-8f17-b71a210b4546","cabe73d6-d410-47fc-8604-02ec6d37b57c","cae1e692-9d2c-48ca-80da-956c63397390","cc24b268-96b4-4a06-83af-eee9be5c7ac9","f8ece2c5-c8b1-4a1e-8528-c09357ec23a4"],"_id":"2088d2fd-d0ed-477f-b350-5d342624e91e","abstract":"In most distributed systems, naming of nodes for low-level communication leverages topological location (such as node addresses) and is independent of any application. In this paper, we investigate an emerging class of distributed systems where low-level communication does not rely on network topological location. Rather, low-level communication is based on attributes that are  external  to the network topology and  relevant  to the application. When combined with dense deployment of nodes, this kind of named data enables  in-network processing  for data aggregation, collaborative signal processing, and similar problems. These approaches are essential for emerging applications such as sensor networks where resources such as bandwidth and energy are limited. This paper is the first description of the software architecture that supports named data and in-network processing in an operational, multi-application sensor-network. We show that approaches such as in-network aggregation and nested queries can significantly affect network traffic. In one experiment aggregation reduces traffic by up to 42% and nested queries reduce loss rates by 30%. Although aggregation has been previously studied in simulation, this paper demonstrates nested queries as another form of in-network processing, and it presents the first evaluation of these approaches over an operational testbed.","title":"Building efficient wireless sensor networks with low-level naming","venue":"symposium on operating systems principles","year":2001,"__v":0,"citationCount":289}],"offsprings":["6bfdf9a3-6cd9-43d8-9785-0073dbe96f1b","b5b8132d-0a8c-4e6c-999f-839f0cef48b7"]},"885cfaf9-43e5-4101-9554-40962d09fe53":{"authors":["Alan R. Hevner","Salvatore T. March","Jinsoo Park","Sudha Ram"],"references":["9b19a579-dc25-4dc8-8139-fd9f264983ac"],"_id":"885cfaf9-43e5-4101-9554-40962d09fe53","abstract":"Two paradigms characterize much of the research in the Information Systems discipline: behavioral science and design science. The behavioral-science paradigm seeks to develop and verify theories that explain or predict human or organizational behavior. The design-science paradigm seeks to extend the boundaries of human and organizational capabilities by creating new and innovative artifacts. Both paradigms are foundational to the IS discipline, positioned as it is at the confluence of people, organizations, and technology. Our objective is to describe the performance of design-science research in Information Systems via a concise conceptual framework and clear guidelines for understanding, executing, and evaluating the research. In the design-science paradigm, knowledge and understanding of a problem domain and its solution are achieved in the building and application of the designed artifact. Three recent exemplars in the research literature are used to demonstrate the application of these guidelines. We conclude with an analysis of the challenges of performing high-quality design-science research in the context of the broader IS community.","title":"Design science in information systems research","venue":"Management Information Systems Quarterly","year":2004,"__v":0,"citationCount":2732,"parents":{"1a0748e8-7784-4443-85ce-24b0bb7b10dc":0,"1aadbbb6-93df-48fb-92dc-5bac61391316":0,"1c95d184-179f-44d1-88a8-5fab9e567e69":1.694915254237288,"207b6ea8-acd9-4479-8543-f46f9c73cbec":1.694915254237288,"2819d0c5-ecb8-47bf-a039-6ae12e308990":0,"2d629e02-11eb-472f-880f-e66813d1f8d0":3.389830508474576,"33d6dabd-c086-4a6e-939a-c322b6ada724":0,"349b1a29-5e0f-421e-b4f7-5290441be737":0,"34e244ae-84ef-4c21-a09d-b0e8384d976c":1.694915254237288,"3b15b0a1-c6a2-4660-8b7a-e44a74c6783d":0,"41de53c6-ae14-4507-80df-56c80dbaca18":1.694915254237288,"42adc492-2606-43c9-af6d-43bd4264d939":1.694915254237288,"42cf5b6d-b65f-4ae1-b9bd-81165896db95":0,"44d2324a-d9dc-472e-a4fc-e0644b5609e1":0,"50468a24-0fa9-45a8-a341-3a61c91af35a":1.694915254237288,"55571c5a-e9c9-40b8-a4b4-0b706f7e82ec":0,"5d7a48c5-605f-45df-856c-7053120194fc":3.389830508474576,"6583dbde-1c44-439f-a6ca-a8e2df87bf82":3.389830508474576,"7b05662e-0286-4000-bab6-ff33c5bb148b":1.694915254237288,"7e88ab32-1149-48e7-a1be-ef76f9a6acbd":0,"7ee0fa98-5997-45fd-8be9-590cac338cc2":0,"7ef21340-0ea9-4835-a1e1-e2b2c9890a5e":5.084745762711865,"818d5415-3f96-4533-86ce-8439aadedc72":1.694915254237288,"8323156f-9f08-4bb2-9c3a-9a0642beb2a5":0,"86a5e25c-9baf-4e34-add5-b9dc543e54fc":0,"8b8804d5-a240-4134-bc87-01c6ac4b68c3":0,"91d002d5-e891-4cf3-ac94-d2aca279fe03":0,"91dc1d1f-6803-44ec-8d93-073db4ba289f":0,"9685b232-5492-4c1b-a76a-c087e105c1ab":3.389830508474576,"9b19a579-dc25-4dc8-8139-fd9f264983ac":3.389830508474576,"9f6dfbd6-c3cf-40c2-9187-ac2460ca2b19":0,"afd63c47-1b9b-4ca0-8693-e8f3efd61b64":0,"b0d91fa2-50f4-4380-8cf5-558fb08e3644":0,"b4f3c77c-33dd-46a6-8745-342bdb72546a":3.389830508474576,"b541380f-8e36-4fd8-91b3-04cf1f8d2736":0,"b9282b89-c224-453b-bb4a-40254b6cf8a9":0,"ba76c3e1-dbba-479f-8b50-e27299668d51":3.389830508474576,"bf22519c-7596-44b7-8102-7256ab462fbb":0,"c4311469-79c7-4253-bf67-1eab02723305":0,"c86c217e-0e21-44cb-82a9-ddb68399d34d":0,"c8a77118-2518-4b98-85cc-f6024215f2de":0,"d169eecc-adbe-4278-b9e6-106aa543b0f7":1.694915254237288,"d2762077-af8d-406e-9a01-51b8747f7ea7":5.084745762711865,"d2f8e7b6-6290-486c-981b-44db12bce30e":1.694915254237288,"db3f8780-9cce-4d22-81f7-84aef42bcedb":1.694915254237288,"df4bbccc-151a-4e2e-a62a-c25e6db9e6ee":0,"e186ea05-4dac-48cc-8710-6290edc2a3d1":1.694915254237288,"e56598ba-3d5a-4413-ba28-e92afd3a7b49":6.779661016949152,"e5767879-f411-46ae-9e47-be1dc2b893ec":1.694915254237288,"e84f8f3a-e60f-4f6e-82a3-1d0bf40f9922":3.389830508474576,"e986651a-4554-4c1e-a86b-97d89d56020d":0,"eadb780b-eac5-4cc7-ada6-eadd74cfe027":0,"eafe9070-ec42-4439-96db-5e2cf7d3a0f7":0,"eba77fc3-7b23-427b-b01d-48aac84e364a":0,"ee3f66e5-6921-4320-9125-944eb33a04f1":0,"f1501991-4872-4fd8-bc0e-3e16e4cfa7e0":0,"f578c7a8-aceb-4bdf-ac64-70b5a815463b":1.694915254237288,"f686ddf0-8e02-4edf-9f36-1c266a88b098":0,"fe2918f3-a823-44cc-ae45-5ae902336497":1.694915254237288},"keyword":{"1a0748e8-7784-4443-85ce-24b0bb7b10dc":0,"1aadbbb6-93df-48fb-92dc-5bac61391316":10.84415343915344,"1c95d184-179f-44d1-88a8-5fab9e567e69":11.199153439153438,"207b6ea8-acd9-4479-8543-f46f9c73cbec":11.426190476190476,"2819d0c5-ecb8-47bf-a039-6ae12e308990":11.97910052910053,"2d629e02-11eb-472f-880f-e66813d1f8d0":13.060555555555556,"33d6dabd-c086-4a6e-939a-c322b6ada724":0,"349b1a29-5e0f-421e-b4f7-5290441be737":9.903968253968253,"34e244ae-84ef-4c21-a09d-b0e8384d976c":11.401851851851852,"3b15b0a1-c6a2-4660-8b7a-e44a74c6783d":11.023597883597882,"41de53c6-ae14-4507-80df-56c80dbaca18":12.260185185185183,"42adc492-2606-43c9-af6d-43bd4264d939":12.280251322751322,"42cf5b6d-b65f-4ae1-b9bd-81165896db95":12.19728835978836,"44d2324a-d9dc-472e-a4fc-e0644b5609e1":0,"50468a24-0fa9-45a8-a341-3a61c91af35a":11.136044973544973,"55571c5a-e9c9-40b8-a4b4-0b706f7e82ec":12.88611111111111,"5d7a48c5-605f-45df-856c-7053120194fc":12.011111111111113,"6583dbde-1c44-439f-a6ca-a8e2df87bf82":12.646560846560849,"7b05662e-0286-4000-bab6-ff33c5bb148b":10.288095238095238,"7e88ab32-1149-48e7-a1be-ef76f9a6acbd":11.638095238095238,"7ee0fa98-5997-45fd-8be9-590cac338cc2":0,"7ef21340-0ea9-4835-a1e1-e2b2c9890a5e":7.596296296296297,"818d5415-3f96-4533-86ce-8439aadedc72":11.034325396825395,"8323156f-9f08-4bb2-9c3a-9a0642beb2a5":12.31494708994709,"86a5e25c-9baf-4e34-add5-b9dc543e54fc":11.024338624338622,"8b8804d5-a240-4134-bc87-01c6ac4b68c3":12.539841269841268,"91d002d5-e891-4cf3-ac94-d2aca279fe03":11.181349206349207,"91dc1d1f-6803-44ec-8d93-073db4ba289f":11.252248677248677,"9685b232-5492-4c1b-a76a-c087e105c1ab":11.302777777777777,"9b19a579-dc25-4dc8-8139-fd9f264983ac":11.991137566137565,"9f6dfbd6-c3cf-40c2-9187-ac2460ca2b19":11.851137566137567,"afd63c47-1b9b-4ca0-8693-e8f3efd61b64":12.634814814814815,"b0d91fa2-50f4-4380-8cf5-558fb08e3644":13.718412698412697,"b4f3c77c-33dd-46a6-8745-342bdb72546a":10.444708994708993,"b541380f-8e36-4fd8-91b3-04cf1f8d2736":12.113359788359787,"b9282b89-c224-453b-bb4a-40254b6cf8a9":10.700740740740743,"ba76c3e1-dbba-479f-8b50-e27299668d51":11.843518518518518,"bf22519c-7596-44b7-8102-7256ab462fbb":12.217592592592592,"c4311469-79c7-4253-bf67-1eab02723305":10.173809523809524,"c86c217e-0e21-44cb-82a9-ddb68399d34d":10.434589947089947,"c8a77118-2518-4b98-85cc-f6024215f2de":0,"d169eecc-adbe-4278-b9e6-106aa543b0f7":12.053174603174604,"d2762077-af8d-406e-9a01-51b8747f7ea7":11.36111111111111,"d2f8e7b6-6290-486c-981b-44db12bce30e":11.685449735449735,"db3f8780-9cce-4d22-81f7-84aef42bcedb":0,"df4bbccc-151a-4e2e-a62a-c25e6db9e6ee":12.738888888888887,"e186ea05-4dac-48cc-8710-6290edc2a3d1":11.690185185185184,"e56598ba-3d5a-4413-ba28-e92afd3a7b49":10.825886243386243,"e5767879-f411-46ae-9e47-be1dc2b893ec":12.039285714285715,"e84f8f3a-e60f-4f6e-82a3-1d0bf40f9922":0,"e986651a-4554-4c1e-a86b-97d89d56020d":12.341402116402115,"eadb780b-eac5-4cc7-ada6-eadd74cfe027":7.441402116402116,"eafe9070-ec42-4439-96db-5e2cf7d3a0f7":0,"eba77fc3-7b23-427b-b01d-48aac84e364a":11.19537037037037,"ee3f66e5-6921-4320-9125-944eb33a04f1":11.990939153439154,"f1501991-4872-4fd8-bc0e-3e16e4cfa7e0":11.23425925925926,"f578c7a8-aceb-4bdf-ac64-70b5a815463b":12.17989417989418,"f686ddf0-8e02-4edf-9f36-1c266a88b098":0,"fe2918f3-a823-44cc-ae45-5ae902336497":11.170000000000003},"topic":["research","paradigm","designsci","understand","system"],"offsprings":[]},"89f10062-acf1-4171-b882-f3222c3a357e":{"authors":["Geoffrey E. Hinton","Simon Osindero","Yee Whye Teh"],"references":["b592576f-ff29-4a68-9b2f-8a8ad02e9c70"],"_id":"89f10062-acf1-4171-b882-f3222c3a357e","abstract":"We show how to use \"complementary priors\" to eliminate the explaining-away effects that make inference difficult in densely connected belief nets that have many hidden layers. Using complementary priors, we derive a fast, greedy algorithm that can learn deep, directed belief networks one layer at a time, provided the top two layers form an undirected associative memory. The fast, greedy algorithm is used to initialize a slower learning procedure that fine-tunes the weights using a contrastive version of the wake-sleep algorithm. After fine-tuning, a network with three hidden layers forms a very good generative model of the joint distribution of handwritten digit images and their labels. This generative model gives better digit classification than the best discriminative learning algorithms. The low-dimensional manifolds on which the digits lie are modeled by long ravines in the free-energy landscape of the top-level associative memory, and it is easy to explore these ravines by using the directed connections to display what the associative memory has in mind.","title":"A fast learning algorithm for deep belief nets","venue":"Neural Computation","year":2006,"__v":0,"citationCount":2595,"parents":{"061d43fb-e3af-4700-bdc2-2e34dfbace26":11.11111111111111,"13439034-6d0a-4842-a6a1-dac976b6c120":0,"146aac22-d446-44ec-9e85-ca24284d7371":5.555555555555555,"3df2f42c-eb57-4a76-99c1-311c20ed6d8e":5.555555555555555,"4453fa3b-308f-472a-be61-65d1ce5c3de2":16.666666666666664,"5055413d-4850-4d6a-b4d4-4343550be9ec":11.11111111111111,"61dcad2b-ef68-4240-95e2-79c12c6bfda9":11.11111111111111,"7745e216-83f5-4a17-8452-d8fb2969c937":0,"7876d86f-e782-4ca6-9504-5f347d1c388f":11.11111111111111,"873b967f-3823-4587-b177-36317e57ee68":5.555555555555555,"8f0a7a93-0b28-4dd1-801b-fdbab29c5283":5.555555555555555,"b592576f-ff29-4a68-9b2f-8a8ad02e9c70":5.555555555555555,"c414c2ad-81f0-4af9-b63a-9e40c8233cdb":11.11111111111111,"ca250ca4-70fd-411f-8cc7-fb17be31cd9e":5.555555555555555,"cf740e2c-f5bf-4e0c-8375-2948d6dff2c7":0,"d2de642b-7044-4d04-85ea-1e05eea964c6":5.555555555555555,"d6104d9a-faaa-4db4-8c4e-748176157ef2":0,"e8571238-943e-46d2-920b-63013e5dd5cd":0},"keyword":{"061d43fb-e3af-4700-bdc2-2e34dfbace26":0,"13439034-6d0a-4842-a6a1-dac976b6c120":12.948518518518515,"146aac22-d446-44ec-9e85-ca24284d7371":14.049074074074072,"3df2f42c-eb57-4a76-99c1-311c20ed6d8e":12.973148148148145,"4453fa3b-308f-472a-be61-65d1ce5c3de2":11.20962962962963,"5055413d-4850-4d6a-b4d4-4343550be9ec":10.962693602693601,"61dcad2b-ef68-4240-95e2-79c12c6bfda9":12.687671957671958,"7745e216-83f5-4a17-8452-d8fb2969c937":12.276931216931217,"7876d86f-e782-4ca6-9504-5f347d1c388f":12.319629629629627,"873b967f-3823-4587-b177-36317e57ee68":9.870634920634922,"8f0a7a93-0b28-4dd1-801b-fdbab29c5283":11.445555555555554,"b592576f-ff29-4a68-9b2f-8a8ad02e9c70":10.059126984126983,"c414c2ad-81f0-4af9-b63a-9e40c8233cdb":9.017037037037035,"ca250ca4-70fd-411f-8cc7-fb17be31cd9e":11.32516354016354,"cf740e2c-f5bf-4e0c-8375-2948d6dff2c7":13.337777777777777,"d2de642b-7044-4d04-85ea-1e05eea964c6":10.528412698412698,"d6104d9a-faaa-4db4-8c4e-748176157ef2":9.214814814814815,"e8571238-943e-46d2-920b-63013e5dd5cd":13.140634920634918},"topic":["layer","algorithm","model","memori","learn"],"offsprings":["d28acb36-5766-4c1e-8d57-a55c2630bd90"]},"8b8a2247-bd77-4736-b493-449734f56b9a":{"authors":["Paul A. Viola","Michael J. Jones"],"references":["310cbba4-d88d-4bf4-a4f2-738f91b5f8c8","6d121e97-e351-4cf9-8c44-d7ab3ce9d9fe"],"_id":"8b8a2247-bd77-4736-b493-449734f56b9a","abstract":"This paper describes a face detection framework that is capable of processing images extremely rapidly while achieving high detection rates. There are three key contributions. The first is the introduction of a new image representation called the “Integral Image” which allows the features used by our detector to be computed very quickly. The second is a simple and efficient classifier which is built using the AdaBoost learning algorithm (Freund and Schapire, 1995) to select a small number of critical visual features from a very large set of potential features. The third contribution is a method for combining classifiers in a “cascade” which allows background regions of the image to be quickly discarded while spending more computation on promising face-like regions. A set of experiments in the domain of face detection is presented. The system yields face detection performance comparable to the best previous systems (Sung and Poggio, 1998; Rowley et al., 1998; Schneiderman and Kanade, 2000; Roth et al., 2000). Implemented on a conventional desktop, face detection proceeds at 15 frames per second.","title":"Robust real-time face detection","venue":"international conference on computer vision","year":2001,"__v":0,"citationCount":4436,"parents":{"13cd743f-beb9-43a1-8e08-2ef08f0d8b3f":0,"17f811d8-8607-4270-bbec-1cc7883edd68":5,"245e4043-ccdb-457a-9be1-e120c7a94753":5,"310cbba4-d88d-4bf4-a4f2-738f91b5f8c8":0,"36800655-b2ff-4eb7-9070-c6be304c4baa":0,"43530fe4-10a9-4ddf-b61d-8844f0ff3f04":5,"55fa440a-2b98-4e8e-bb45-fa09598b4eca":10,"5ffac6f9-2456-42cf-830c-9049ce37c899":5,"613841ae-c925-4aee-9c2e-8675213e4bbf":10,"62d0a064-3808-4bc0-99bd-f007359ce651":0,"6d121e97-e351-4cf9-8c44-d7ab3ce9d9fe":5,"8f6a657e-e387-4572-bb88-91aee042e8da":15,"9fa55b0f-eaa6-4c59-b6e5-77e5f1a406f0":0,"b49c1e2b-0cd0-4950-a724-00c698e5b49d":0,"c7f93552-c1ef-4ae4-b1f5-2317e1c9d904":25,"d5e5a24d-f80e-4f1a-b48b-22403b653276":0,"d6e37fb1-5f7e-448e-847b-7d1f1271c574":5,"db26488d-78be-44b1-a343-e896f43c5d29":0,"f1bd37c4-d033-4cd1-af44-4df9f11c71e4":25,"f4642ffc-3571-4d02-8b94-142f2448023a":0},"keyword":{"13cd743f-beb9-43a1-8e08-2ef08f0d8b3f":11.66722222222222,"17f811d8-8607-4270-bbec-1cc7883edd68":7.102777777777778,"245e4043-ccdb-457a-9be1-e120c7a94753":12.166666666666668,"310cbba4-d88d-4bf4-a4f2-738f91b5f8c8":10.0484126984127,"36800655-b2ff-4eb7-9070-c6be304c4baa":13.081944444444444,"43530fe4-10a9-4ddf-b61d-8844f0ff3f04":10.34074074074074,"55fa440a-2b98-4e8e-bb45-fa09598b4eca":12.080555555555556,"5ffac6f9-2456-42cf-830c-9049ce37c899":8.618253968253969,"613841ae-c925-4aee-9c2e-8675213e4bbf":9.100000000000001,"62d0a064-3808-4bc0-99bd-f007359ce651":10.45452380952381,"6d121e97-e351-4cf9-8c44-d7ab3ce9d9fe":11.326984126984126,"8f6a657e-e387-4572-bb88-91aee042e8da":12.352777777777776,"9fa55b0f-eaa6-4c59-b6e5-77e5f1a406f0":9.701388888888888,"b49c1e2b-0cd0-4950-a724-00c698e5b49d":11.46190476190476,"c7f93552-c1ef-4ae4-b1f5-2317e1c9d904":11.195502645502646,"d5e5a24d-f80e-4f1a-b48b-22403b653276":12.041666666666666,"d6e37fb1-5f7e-448e-847b-7d1f1271c574":11.913888888888888,"db26488d-78be-44b1-a343-e896f43c5d29":0,"f1bd37c4-d033-4cd1-af44-4df9f11c71e4":9.855555555555554,"f4642ffc-3571-4d02-8b94-142f2448023a":8.915873015873016},"topic":["detect","imag","face","featur","system"],"groups":[{"authors":["Henry Schneiderman","Takeo Kanade"],"references":["310cbba4-d88d-4bf4-a4f2-738f91b5f8c8","4a29b56b-b74e-4945-9017-61a7ab844fd9","8f6a657e-e387-4572-bb88-91aee042e8da","96d6d9b9-6d69-4c9a-b3f5-c8083966d55c","bb83383f-0de9-408b-9ba2-aa902c63f14a","d5e5a24d-f80e-4f1a-b48b-22403b653276","d6e37fb1-5f7e-448e-847b-7d1f1271c574","db26488d-78be-44b1-a343-e896f43c5d29","ed59a2e5-7330-4e07-9edf-cc80872135d0"],"_id":"c7f93552-c1ef-4ae4-b1f5-2317e1c9d904","abstract":"In this paper, we describe a statistical method for 3D object detection. We represent the statistics of both object appearance and \"non-object\" appearance using a product of histograms. Each histogram represents the joint statistics of a subset of wavelet coefficients and their position on the object. Our approach is to use many such histograms representing a wide variety of visual attributes. Using this method, we have developed the first algorithm that can reliably detect human faces with out-of-plane rotation and the first algorithm that can reliably detect passenger cars over a wide range of viewpoints.","title":"A statistical method for 3D object detection applied to faces and cars","venue":"computer vision and pattern recognition","year":2000,"__v":0,"citationCount":525},{"authors":["F. Fleuret","Donald Geman"],"references":["2958fc5c-15e8-45e7-8da8-d2e0fa46f0c7","5242f101-1511-4660-9a4c-4eb597aaa3c6","55fa440a-2b98-4e8e-bb45-fa09598b4eca","5ffac6f9-2456-42cf-830c-9049ce37c899","613841ae-c925-4aee-9c2e-8675213e4bbf","64fa74e8-db02-4190-87d7-bf23e9859a7c","6610284f-1f5a-4460-95d6-b0ad690e171d","6da113cb-3257-4014-990b-2ebbb7d998f2","757078f8-0e20-4c8b-a907-5d068db66fc4","762c9918-e579-42ef-80e5-4e464870a017","b85ac095-a9f2-4954-b2bf-f53fde98958c","bcc5343a-dee5-4e42-bd84-6700cbab125e","bec76d54-02fb-4e7e-8a9c-c058f780194d","cd9494ab-fbd2-401d-8afe-376c0bd24c80","d5e5a24d-f80e-4f1a-b48b-22403b653276","d6e37fb1-5f7e-448e-847b-7d1f1271c574","ea294286-3cc2-4979-a22b-2fbb78c2ef18"],"_id":"f1bd37c4-d033-4cd1-af44-4df9f11c71e4","abstract":"We study visual selection: Detect and roughly localize all instances of a generic object class, such as a face, in a greyscale scene, measuring performance in terms of computation and false alarms. Our approach is sequential testing which is coarse-to-fine in both in the exploration of poses and the representation of objects. All the tests are binary and indicate the presence or absence of loose spatial arrangements of oriented edge fragments. Starting from training examples, we recursively find larger and larger arrangements which are “decomposable,” which implies the probability of an arrangement appearing on an object decays slowly with its size. Detection means finding a sufficient number of arrangements of each size along a decreasing sequence of pose cells. At the beginning, the tests are simple and universal, accommodating many poses simultaneously, but the false alarm rate is relatively high. Eventually, the tests are more discriminating, but also more complex and dedicated to specific poses. As a result, the spatial distribution of processing is highly skewed and detection is rapid, but at the expense of (isolated) false alarms which, presumably, could be eliminated with localized, more intensive, processing.","title":"Coarse-to-Fine Face Detection","venue":"International Journal of Computer Vision","year":2001,"__v":0,"citationCount":131}],"offsprings":["f2d49150-35de-4fd5-ac46-eb071d1cc73e","83c737b8-e084-4766-ba6e-131e6a1c017c"]},"8cc9ea80-563f-4e62-bda9-8ff6d71cf6ae":{"authors":["Piyush Gupta","P. Kumar"],"references":[],"_id":"8cc9ea80-563f-4e62-bda9-8ff6d71cf6ae","abstract":"When n identical randomly located nodes, each capable of transmitting at W bits per second and using a fixed range, form a wireless network, the throughput /spl lambda/(n) obtainable by each node for a randomly chosen destination is /spl Theta/(W//spl radic/(nlogn)) bits per second under a noninterference protocol. If the nodes are optimally placed in a disk of unit area, traffic patterns are optimally assigned, and each transmission's range is optimally chosen, the bit-distance product that can be transported by the network per second is /spl Theta/(W/spl radic/An) bit-meters per second. Thus even under optimal circumstances, the throughput is only /spl Theta/(W//spl radic/n) bits per second for each node for a destination nonvanishingly far away. Similar results also hold under an alternate physical model where a required signal-to-interference ratio is specified for successful receptions. Fundamentally, it is the need for every node all over the domain to share whatever portion of the channel it is utilizing with nodes in its local neighborhood that is the reason for the constriction in capacity. Splitting the channel into several subchannels does not change any of the results. Some implications may be worth considering by designers. Since the throughput furnished to each user diminishes to zero as the number of users is increased, perhaps networks connecting smaller numbers of users, or featuring connections mostly with nearby neighbors, may be more likely to be find acceptance.","title":"The capacity of wireless networks","venue":"IEEE Transactions on Information Theory","year":2000,"__v":0,"citationCount":4280,"parents":{"0b93552e-74e8-483f-82cb-5c04e1cd9232":0,"276dcefc-4b6b-4c4f-a0af-c512bff148ff":0,"5f2d5905-b31f-4582-b699-410c123c9398":0,"a56bc6d2-0287-4dfd-ac22-f655a849c20e":0,"ff56835b-e3b8-4a86-8510-917c6bb58d84":0},"keyword":{"0b93552e-74e8-483f-82cb-5c04e1cd9232":7.3805555555555555,"276dcefc-4b6b-4c4f-a0af-c512bff148ff":11.170767195767198,"5f2d5905-b31f-4582-b699-410c123c9398":8.484814814814815,"a56bc6d2-0287-4dfd-ac22-f655a849c20e":10.27142857142857,"ff56835b-e3b8-4a86-8510-917c6bb58d84":8.940515873015872},"topic":["node","spl","optim","user","throughput"],"offsprings":["b857298c-92c9-4f05-a704-3b9fc6be06e3","d1ba534e-3f80-4366-bb83-be16006f9e18"]},"8cea470a-9c6d-4137-8f4c-acda7e0d1904":{"authors":["Frank R. Kschischang","Brendan J. Frey","Hans-Andrea Loeliger"],"references":[],"_id":"8cea470a-9c6d-4137-8f4c-acda7e0d1904","abstract":"Algorithms that must deal with complicated global functions of many variables often exploit the manner in which the given functions factor as a product of \"local\" functions, each of which depends on a subset of the variables. Such a factorization can be visualized with a bipartite graph that we call a factor graph, In this tutorial paper, we present a generic message-passing algorithm, the sum-product algorithm, that operates in a factor graph. Following a single, simple computational rule, the sum-product algorithm computes-either exactly or approximately-various marginal functions derived from the global function. A wide variety of algorithms developed in artificial intelligence, signal processing, and digital communications can be derived as specific instances of the sum-product algorithm, including the forward/backward algorithm, the Viterbi algorithm, the iterative \"turbo\" decoding algorithm, Pearl's (1988) belief propagation algorithm for Bayesian networks, the Kalman filter, and certain fast Fourier transform (FFT) algorithms.","title":"Factor graphs and the sum-product algorithm","venue":"IEEE Transactions on Information Theory","year":2001,"__v":0,"citationCount":2388,"parents":{"6f9aeb94-bd72-4ac6-8ec4-4c3f98dcb993":62.5,"7963ab0f-472d-47ec-a2d9-d21d72e390b2":62.5,"7d13dc57-6231-4275-bbd6-ecc7a2935795":0,"8285b7c1-a2cd-4916-ad56-afc0eceeb815":62.5,"8611c7fe-134c-47dd-8ae2-0bf04fe8f224":50,"9ec287ca-9bbf-4b96-96e3-fdb78a808228":0,"b897fabf-4e80-4491-87db-3e5bb81a8bd3":0,"c5a3d783-7e53-43b0-9ef5-a333af312ced":12.5},"keyword":{"6f9aeb94-bd72-4ac6-8ec4-4c3f98dcb993":10.069444444444445,"7963ab0f-472d-47ec-a2d9-d21d72e390b2":11.418518518518516,"7d13dc57-6231-4275-bbd6-ecc7a2935795":10.766296296296296,"8285b7c1-a2cd-4916-ad56-afc0eceeb815":10.123148148148147,"8611c7fe-134c-47dd-8ae2-0bf04fe8f224":11.60298941798942,"9ec287ca-9bbf-4b96-96e3-fdb78a808228":10.455079365079365,"b897fabf-4e80-4491-87db-3e5bb81a8bd3":0,"c5a3d783-7e53-43b0-9ef5-a333af312ced":8.634391534391535},"topic":["algorithm","function","factor","sumproduct","graph"],"groups":[{"authors":["Frank R. Kschischang","Brendan J. Frey"],"references":["6f9aeb94-bd72-4ac6-8ec4-4c3f98dcb993","7d13dc57-6231-4275-bbd6-ecc7a2935795","8611c7fe-134c-47dd-8ae2-0bf04fe8f224","9ec287ca-9bbf-4b96-96e3-fdb78a808228","aa8df09d-259d-490d-b1b6-d3775a02ab07","b897fabf-4e80-4491-87db-3e5bb81a8bd3","d3e00e7e-1c64-4d7a-b2b2-1ad98ba4c706","e3053caa-aafc-45a5-9e84-929dd3d997f4"],"_id":"8285b7c1-a2cd-4916-ad56-afc0eceeb815","abstract":"We present a unified graphical model framework for describing compound codes and deriving iterative decoding algorithms. After reviewing a variety of graphical models (Markov random fields, Tanner graphs, and Bayesian networks), we derive a general distributed marginalization algorithm for functions described by factor graphs. From this general algorithm, Pearl's (1986) belief propagation algorithm is easily derived as a special case. We point out that iterative decoding algorithms for various codes, including \"turbo decoding\" of parallel-concatenated convolutional codes, may be viewed as probability propagation in a graphical model of the code. We focus on Bayesian network descriptions of codes, which give a natural input/state/output/channel description of a code and channel, and we indicate how iterative decoders can be developed for parallel-and serially concatenated coding systems, product codes, and low-density parity-check codes.","title":"Iterative decoding of compound codes by probability propagation in graphical models","venue":"IEEE Journal on Selected Areas in Communications","year":1998,"__v":0,"citationCount":157},{"authors":["David J. C. MacKay"],"references":["04fc518d-bcb8-46ae-aae0-e762a4bd6b45","0a857f96-7979-4cfe-be07-b38556c11379","163c33dd-5a9c-44c4-98ab-5b045734e6a8","190fd656-b653-42b4-b77b-c6ae42488a1c","2a071733-dc94-441a-ac07-521913dfc736","347d0792-c17f-413c-8ec4-b82ab726f2c0","3595fa71-68db-476e-9cb7-ad6ece6f446e","5c89a51d-ec74-4587-b06c-60bbfd28c75f","62febf9b-1438-4218-a965-93b136fb428f","6bdc98d8-224c-4d2a-b7ef-12ee06ae6400","6f9aeb94-bd72-4ac6-8ec4-4c3f98dcb993","786e1963-5f8e-40dc-90fe-a770fffbea18","7ca4edce-5361-461e-b158-6b44218acc59","7d13dc57-6231-4275-bbd6-ecc7a2935795","84d51516-9812-4d83-b9e3-337a078a8100","8c6298f3-6edb-4fbd-832a-11c8cb03d009","8ff0a138-f1a0-4419-8b3a-e2542fb11e03","9ec287ca-9bbf-4b96-96e3-fdb78a808228","a78c0f40-ccf7-44ab-af61-a3433b168795","accd62a4-3a66-4fbe-b9d5-0c9128321aee","ad743da8-f0fc-4f28-9c25-1981b5667c93","adfe0dda-5d6c-46cd-9e45-a5f1c671151c","b897fabf-4e80-4491-87db-3e5bb81a8bd3","b8b308ec-022c-4baf-9d7c-3a1dbc487cb1","bff11fa3-5279-4b9a-8522-c580c3960db2","d3e00e7e-1c64-4d7a-b2b2-1ad98ba4c706","e33d89f1-291f-4ceb-9b6f-ecc166412650","e6b0a4fb-9126-4766-9d53-348789ad27ec"],"_id":"8611c7fe-134c-47dd-8ae2-0bf04fe8f224","abstract":"We study two families of error-correcting codes defined in terms of very sparse matrices. \"MN\" (MacKay-Neal (1995)) codes are recently invented, and \"Gallager codes\" were first investigated in 1962, but appear to have been largely forgotten, in spite of their excellent properties. The decoding of both codes can be tackled with a practical sum-product algorithm. We prove that these codes are \"very good\", in that sequences of codes exist which, when optimally decoded, achieve information rates up to the Shannon limit. This result holds not only for the binary-symmetric channel but also for any channel with symmetric stationary ergodic noise. We give experimental results for binary-symmetric channels and Gaussian channels demonstrating that practical performance substantially better than that of standard convolutional and concatenated codes can be achieved; indeed, the performance of Gallager codes is almost as close to the Shannon limit as that of turbo codes.","title":"Good error-correcting codes based on very sparse matrices","venue":"international symposium on information theory","year":1997,"__v":0,"citationCount":1265},{"authors":["Robert J. McEliece","David J. C. MacKay","Jung-Fu Cheng"],"references":["20e2f5a8-deb4-4216-8f9e-69ed379bd66a","2b65cf67-1c71-4509-9f2c-52e48ac183f8","333fea0a-edb1-48d6-8efe-d4425b3d4396","3595fa71-68db-476e-9cb7-ad6ece6f446e","3e7689e9-49da-4607-b1e8-034f3359f47c","45a83c74-42cf-4193-b8fc-17c1853f26e4","610c0014-3812-4ade-9c60-746a9acf3f73","62febf9b-1438-4218-a965-93b136fb428f","736eee36-d6fd-4d8d-86bc-ed3047007cad","7d13dc57-6231-4275-bbd6-ecc7a2935795","8192d2df-8e42-4366-9d0a-efba8b748cef","8285b7c1-a2cd-4916-ad56-afc0eceeb815","84d51516-9812-4d83-b9e3-337a078a8100","8611c7fe-134c-47dd-8ae2-0bf04fe8f224","9ec287ca-9bbf-4b96-96e3-fdb78a808228","a74969a9-0bd6-4cfd-a520-f57088deaed0","aa8df09d-259d-490d-b1b6-d3775a02ab07","ad3a4ba4-5b88-4d61-9ba5-263cda996e9c","b897fabf-4e80-4491-87db-3e5bb81a8bd3","c9ea1ab7-b2db-4c0f-9696-80e3310cec6c","d92b0700-ed07-40b9-b3e2-0273fea711dd","db6588f7-45b8-4083-8845-d99f1d8f2b2d"],"_id":"6f9aeb94-bd72-4ac6-8ec4-4c3f98dcb993","abstract":"We describe the close connection between the now celebrated iterative turbo decoding algorithm of Berrou et al. (1993) and an algorithm that has been well known in the artificial intelligence community for a decade, but which is relatively unknown to information theorists: Pearl's (1982) belief propagation algorithm. We see that if Pearl's algorithm is applied to the \"belief network\" of a parallel concatenation of two or more codes, the turbo decoding algorithm immediately results. Unfortunately, however, this belief diagram has loops, and Pearl only proved that his algorithm works when there are no loops, so an explanation of the experimental performance of turbo decoding is still lacking. However, we also show that Pearl's algorithm can be used to routinely derive previously known iterative, but suboptimal, decoding algorithms for a number of other error-control systems, including Gallager's (1962) low-density parity-check codes, serially concatenated codes, and product codes. Thus, belief propagation provides a very attractive general methodology for devising low-complexity iterative decoding algorithms for hybrid coded systems.","title":"Turbo decoding as an instance of Pearl's \"belief propagation\" algorithm","venue":"IEEE Journal on Selected Areas in Communications","year":1998,"__v":0,"citationCount":340},{"authors":["Srinivas M. Aji","Robert J. McEliece"],"references":["248875d2-e08a-4566-bc6f-650bf1734313","3595fa71-68db-476e-9cb7-ad6ece6f446e","51657f5d-8e60-4a5f-9797-d7bd64609284","527187d3-e96a-4e67-b947-a5911f51804f","6f9aeb94-bd72-4ac6-8ec4-4c3f98dcb993","7d13dc57-6231-4275-bbd6-ecc7a2935795","8285b7c1-a2cd-4916-ad56-afc0eceeb815","8cea470a-9c6d-4137-8f4c-acda7e0d1904","9ec287ca-9bbf-4b96-96e3-fdb78a808228","b897fabf-4e80-4491-87db-3e5bb81a8bd3","c37d3e37-e57b-44c4-bcde-888112e7695c","d68203bb-77bb-45fa-9ea8-8e014c3e26d8"],"_id":"7963ab0f-472d-47ec-a2d9-d21d72e390b2","abstract":"We discuss a general message passing algorithm, which we call the generalized distributive law (GDL). The GDL is a synthesis of the work of many authors in information theory, digital communications, signal processing, statistics, and artificial intelligence. It includes as special cases the Baum-Welch algorithm, the fast Fourier transform (FFT) on any finite Abelian group, the Gallager-Tanner-Wiberg decoding algorithm, Viterbi's algorithm, the BCJR algorithm, Pearl's \"belief propagation\" algorithm, the Shafer-Shenoy probability propagation algorithm, and the turbo decoding algorithm. Although this algorithm is guaranteed to give exact answers only in certain cases (the \"junction tree\" condition), unfortunately not including the cases of GTW with cycles or turbo decoding, there is much experimental evidence, and a few theorems, suggesting that it often works approximately even when it is not supposed to.","title":"The generalized distributive law","venue":"IEEE Transactions on Information Theory","year":2000,"__v":0,"citationCount":301}],"offsprings":["222e8196-b98b-47bc-a679-641bbf57b770"]},"8e34b9ea-e947-41f3-a097-5964b058bdc8":{"authors":["Ben Shneiderman"],"references":[],"_id":"8e34b9ea-e947-41f3-a097-5964b058bdc8","abstract":"A useful starting point for designing advanced graphical user interfaces is the visual information seeking Mantra: overview first, zoom and filter, then details on demand. But this is only a starting point in trying to understand the rich and varied set of information visualizations that have been proposed in recent years. The paper offers a task by data type taxonomy with seven data types (one, two, three dimensional data, temporal and multi dimensional data, and tree and network data) and seven tasks (overview, zoom, filter, details-on-demand, relate, history, and extracts).","title":"The eyes have it: a task by data type taxonomy for information visualizations","venue":"","year":1996,"__v":0,"citationCount":1526,"parents":{"03f39a56-c0de-462c-a899-a6031a756b5f":0,"0417722f-038d-410f-83e0-7f7fd61772ee":2.7777777777777777,"1487d4b1-9a86-477b-9151-4390b6e4c04b":5.555555555555555,"15fb5021-a0b4-440d-8da4-1f9fa55b985e":0,"1c3cc9a4-69fc-45b9-b80c-24a46e1530d1":5.555555555555555,"1e83f2a3-27ac-47c1-b36f-97ab5137d903":2.7777777777777777,"24b4ca75-f7fb-4001-b473-f21b60f5a932":0,"40362186-4aa0-4596-80f4-c26ae5f45b8a":16.666666666666664,"48bded0e-e719-4aa7-88d0-3ff84a3dc1d9":0,"52906219-086a-4196-9608-4064dc29ff8c":5.555555555555555,"53bda780-143e-4671-bcc9-f6ab487eecb7":2.7777777777777777,"53bfacba-a308-4353-a446-06f10847ed14":13.88888888888889,"53d36c5c-cd85-4872-bda3-72ebc464a913":11.11111111111111,"55502b3e-ffc0-432a-9986-26bcb018ccd4":2.7777777777777777,"5cb097c8-8760-4db4-80cb-60bbf7ebc214":2.7777777777777777,"720a176c-a787-490e-9401-2981765775ef":0,"7669bae4-428e-4ee2-9a45-9df3067eb9ad":2.7777777777777777,"7762a6b2-643d-4fd4-b492-9e1af9874470":11.11111111111111,"7a1e7cd5-eb9d-4726-a5df-cebe0fcb6161":11.11111111111111,"8a3aea7c-88f3-4d30-a26f-3b7c8ebe2470":2.7777777777777777,"979e23d0-bc5d-444f-8c89-33d3b998f9fd":5.555555555555555,"9d37e5b7-6d4c-4927-9b99-23f969a4a996":2.7777777777777777,"a1f07d16-eba7-4155-89c5-01913087a00b":0,"a87dea65-5533-493b-acd5-1dd25b50bf43":5.555555555555555,"ab268b64-fac4-4947-9c11-8e3f9901b6b7":2.7777777777777777,"ac077ae4-57be-495e-8a74-dfa2b770f096":5.555555555555555,"adeac47f-3f0d-485b-aaf4-3b02a7493446":2.7777777777777777,"ae6581cd-e184-4ccd-aac2-e275f86d529b":2.7777777777777777,"b65b1177-f376-421b-9097-16d71017de91":0,"baec9dfe-e53d-476e-a399-dcf8ae4e1906":8.333333333333332,"bd5c3777-8e80-4631-bc7f-93f2cbf3a5b6":2.7777777777777777,"c052700b-b856-4df9-8f86-4ffe288eb503":11.11111111111111,"c5456709-7e4d-4aad-8971-0602efb48412":0,"c6dac88f-fbb8-46eb-a6c1-c26eb084942e":2.7777777777777777,"c6fb590e-176f-457d-b2a4-1c3296bf560f":2.7777777777777777,"dc35322f-1b21-47a6-b7cb-8844cd7f8ef0":5.555555555555555},"keyword":{"03f39a56-c0de-462c-a899-a6031a756b5f":8.982936507936508,"0417722f-038d-410f-83e0-7f7fd61772ee":5.625925925925926,"1487d4b1-9a86-477b-9151-4390b6e4c04b":0,"15fb5021-a0b4-440d-8da4-1f9fa55b985e":0,"1c3cc9a4-69fc-45b9-b80c-24a46e1530d1":0,"1e83f2a3-27ac-47c1-b36f-97ab5137d903":0,"24b4ca75-f7fb-4001-b473-f21b60f5a932":0,"40362186-4aa0-4596-80f4-c26ae5f45b8a":7.075396825396826,"48bded0e-e719-4aa7-88d0-3ff84a3dc1d9":8.083333333333332,"52906219-086a-4196-9608-4064dc29ff8c":0,"53bda780-143e-4671-bcc9-f6ab487eecb7":6.393650793650794,"53bfacba-a308-4353-a446-06f10847ed14":7.345833333333334,"53d36c5c-cd85-4872-bda3-72ebc464a913":0,"55502b3e-ffc0-432a-9986-26bcb018ccd4":8.244444444444444,"5cb097c8-8760-4db4-80cb-60bbf7ebc214":0,"720a176c-a787-490e-9401-2981765775ef":7.533597883597883,"7669bae4-428e-4ee2-9a45-9df3067eb9ad":9.019047619047619,"7762a6b2-643d-4fd4-b492-9e1af9874470":0,"7a1e7cd5-eb9d-4726-a5df-cebe0fcb6161":8.511177248677248,"8a3aea7c-88f3-4d30-a26f-3b7c8ebe2470":11.652777777777777,"979e23d0-bc5d-444f-8c89-33d3b998f9fd":8.692592592592591,"9d37e5b7-6d4c-4927-9b99-23f969a4a996":8.122222222222222,"a1f07d16-eba7-4155-89c5-01913087a00b":6.278968253968254,"a87dea65-5533-493b-acd5-1dd25b50bf43":0,"ab268b64-fac4-4947-9c11-8e3f9901b6b7":8.133597883597885,"ac077ae4-57be-495e-8a74-dfa2b770f096":8.691428571428572,"adeac47f-3f0d-485b-aaf4-3b02a7493446":0,"ae6581cd-e184-4ccd-aac2-e275f86d529b":8.337698412698412,"b65b1177-f376-421b-9097-16d71017de91":7.865079365079366,"baec9dfe-e53d-476e-a399-dcf8ae4e1906":10.020634920634919,"bd5c3777-8e80-4631-bc7f-93f2cbf3a5b6":9.681349206349205,"c052700b-b856-4df9-8f86-4ffe288eb503":7.355555555555556,"c5456709-7e4d-4aad-8971-0602efb48412":9.283084415584415,"c6dac88f-fbb8-46eb-a6c1-c26eb084942e":8.695833333333333,"c6fb590e-176f-457d-b2a4-1c3296bf560f":0,"dc35322f-1b21-47a6-b7cb-8844cd7f8ef0":8.546296296296296},"topic":["data","zoom","visual","type","task"],"offsprings":[]},"8f9e92cf-f266-4e51-807f-c098a260a0dc":{"authors":["Jon M. Kleinberg"],"references":["c7e4e04b-45da-4bae-8c8a-d17ca0087361"],"_id":"8f9e92cf-f266-4e51-807f-c098a260a0dc","abstract":"The network structure of a hyperlinked environment can be a rich source of information about the content of the environment, provided we have effective means for understanding it. We develop a set of algorithmic tools for extracting information from the link structures of such environments, and report on experiments that demonstrate their effectiveness in a variety of context on the World Wide Web. The central issue we address within our framework is the distillation of broad search topics, through the discovery of “authorative” information sources on such topics. We propose and test an algorithmic formulation of the notion of authority, based on the relationship between a set of relevant authoritative pages and the set of “hub pages” that join them together in  the link structure. Our formulation has connections to the eigenvectors of certain matrices associated with the link graph; these connections in turn motivate additional heuristrics for link-based analysis.","title":"Authoritative sources in a hyperlinked environment","venue":"Journal of the ACM","year":1999,"__v":0,"citationCount":3448,"parents":{"0c23971f-2165-4a9b-83b1-00b08556d421":3.571428571428571,"18b76b58-2d45-4dae-9f1f-0f4f7aae043c":14.285714285714285,"27e4ec4d-0ce3-437b-9511-db610b7ba805":0,"373b4f77-3e42-4683-9ae4-0378241e7325":0,"3ed1f08a-a411-4078-b187-d95da5a38c4f":0,"407ceb18-464f-4ab3-b731-68f7681fb26d":0,"50d9a0e1-00a5-4445-b8b2-9f1405cbe6e1":0,"529f0775-01b2-4f1e-9d89-fc5227058019":21.428571428571427,"5a7d936d-b433-47c4-8955-a529c23e1498":0,"5cc06390-77b7-4589-b42b-8b3254d755ad":10.714285714285714,"6e551a7c-6769-49c1-93c5-037a06f4aaef":32.142857142857146,"7dce00bc-8d45-4886-a341-63b5039217a7":3.571428571428571,"8f6cafa9-28c3-424e-87bd-c28c8e57a44f":0,"9785caef-a673-488d-9eaf-cf6d24108013":7.142857142857142,"9cbb490c-d8e9-4dc9-84a7-8238ca21d0a5":0,"a5f0deb7-ce61-46d5-8cc2-b8362fd63db3":3.571428571428571,"ac14afe6-de4d-4056-b2ac-0f6e36f369a2":0,"afa37e9f-2a18-4d29-bae1-ba93edd2a163":3.571428571428571,"afa3a972-e82d-49fb-ad16-be307431134f":0,"b84a20e0-0f9a-4a1c-82d3-1a940ffc4163":0,"b9a25393-edf2-4e39-8252-64d332f225dd":3.571428571428571,"c19c233b-6b1d-40a9-b553-a6efbe11932c":3.571428571428571,"c7e4e04b-45da-4bae-8c8a-d17ca0087361":14.285714285714285,"d7953b97-e51b-45e2-b0f7-5e2eed1f9bd3":3.571428571428571,"e127b1a6-04b4-4a24-9caf-59738ad3ee4b":14.285714285714285,"ed52603b-0cce-4606-a75c-a700bc4305bf":10.714285714285714,"f1011b3e-1a8f-4cd2-bdb8-d5b6dce8f77a":0,"ff269dbf-6570-4409-8cab-6ac142450d05":3.571428571428571},"keyword":{"0c23971f-2165-4a9b-83b1-00b08556d421":9.006746031746031,"18b76b58-2d45-4dae-9f1f-0f4f7aae043c":9.576236263736265,"27e4ec4d-0ce3-437b-9511-db610b7ba805":9.44845238095238,"373b4f77-3e42-4683-9ae4-0378241e7325":9.93941798941799,"3ed1f08a-a411-4078-b187-d95da5a38c4f":9.34404761904762,"407ceb18-464f-4ab3-b731-68f7681fb26d":9.180555555555555,"50d9a0e1-00a5-4445-b8b2-9f1405cbe6e1":8.231944444444444,"529f0775-01b2-4f1e-9d89-fc5227058019":8.037460317460317,"5a7d936d-b433-47c4-8955-a529c23e1498":9.898677248677247,"5cc06390-77b7-4589-b42b-8b3254d755ad":12.074285714285713,"6e551a7c-6769-49c1-93c5-037a06f4aaef":0,"7dce00bc-8d45-4886-a341-63b5039217a7":9.17301587301587,"8f6cafa9-28c3-424e-87bd-c28c8e57a44f":0,"9785caef-a673-488d-9eaf-cf6d24108013":4.7182539682539675,"9cbb490c-d8e9-4dc9-84a7-8238ca21d0a5":10.712698412698414,"a5f0deb7-ce61-46d5-8cc2-b8362fd63db3":7.38015873015873,"ac14afe6-de4d-4056-b2ac-0f6e36f369a2":10.915079365079364,"afa37e9f-2a18-4d29-bae1-ba93edd2a163":8.874007936507939,"afa3a972-e82d-49fb-ad16-be307431134f":9.628214285714286,"b84a20e0-0f9a-4a1c-82d3-1a940ffc4163":7.763888888888889,"b9a25393-edf2-4e39-8252-64d332f225dd":5.661111111111111,"c19c233b-6b1d-40a9-b553-a6efbe11932c":0,"c7e4e04b-45da-4bae-8c8a-d17ca0087361":9.540383597883597,"d7953b97-e51b-45e2-b0f7-5e2eed1f9bd3":7.9509920634920634,"e127b1a6-04b4-4a24-9caf-59738ad3ee4b":8.314285714285715,"ed52603b-0cce-4606-a75c-a700bc4305bf":0,"f1011b3e-1a8f-4cd2-bdb8-d5b6dce8f77a":9.468253968253968,"ff269dbf-6570-4409-8cab-6ac142450d05":0},"topic":["structur","set","link","inform","environ"],"groups":[{"authors":["David Gibson","Jon M. Kleinberg","Prabhakar Raghavan"],"references":["06bb57a0-0e68-4438-b8db-c0c3956a53c3","19255b29-9a5d-4e88-97b4-3b4411d85526","2256cad0-cf03-42da-bcf3-4a89be0ebf8e","373b4f77-3e42-4683-9ae4-0378241e7325","3d660c86-e014-40f1-83e2-988c55f6e5b4","45f87cdb-d440-49ea-9467-73013b4c915d","4b7e718d-4898-4231-954b-1fa575bcb4c8","529f0775-01b2-4f1e-9d89-fc5227058019","7dce00bc-8d45-4886-a341-63b5039217a7","8f6cafa9-28c3-424e-87bd-c28c8e57a44f","8f9e92cf-f266-4e51-807f-c098a260a0dc","a5f0deb7-ce61-46d5-8cc2-b8362fd63db3","ac14afe6-de4d-4056-b2ac-0f6e36f369a2","afa3a972-e82d-49fb-ad16-be307431134f","b9a25393-edf2-4e39-8252-64d332f225dd","ff269dbf-6570-4409-8cab-6ac142450d05"],"_id":"6e551a7c-6769-49c1-93c5-037a06f4aaef","title":"Inferring Web communities from link topology","venue":"acm conference on hypertext","year":1998,"abstract":"","__v":0,"citationCount":376}],"offsprings":["b0ef6e4d-4c86-4b10-9e0a-7b630ca8d7f7"]},"91979159-37d8-410f-a245-a33ef80a092b":{"authors":["Christopher J. C. Burges"],"references":["50dd56db-151d-4d62-8576-65f0ef6f381b","94898e1d-1e50-41ab-9dcc-2c2e030cddd0"],"_id":"91979159-37d8-410f-a245-a33ef80a092b","abstract":"The tutorial starts with an overview of the concepts of VC dimension and structural risk minimization. We then describe linear Support Vector Machines (SVMs) for separable and non-separable data, working through a non-trivial example in detail. We describe a mechanical analogy, and discuss when SVM solutions are unique and when they are global. We describe how support vector training can be practically implemented, and discuss in detail the kernel mapping technique which is used to construct SVM solutions which are nonlinear in the data. We show how Support Vector machines can have very large (even infinite) VC dimension by computing the VC dimension for homogeneous polynomial and Gaussian radial basis function kernels. While very high VC dimension would normally bode ill for generalization performance, and while at present there exists no theory which shows that good generalization performance is guaranteed for SVMs, there are several arguments which support the observed high accuracy of SVMs, which we review. Results of some experiments which were inspired by these arguments are also presented. We give numerous examples and proofs of most of the key theorems. There is new material, and I hope that the reader will find that even old material is cast in a fresh light.","title":"A Tutorial on Support Vector Machines for Pattern Recognition","venue":"Data Mining and Knowledge Discovery","year":1998,"__v":0,"citationCount":4878,"parents":{"0d9f5547-6e05-4ad1-ad8b-3e91b842b9ec":13.636363636363635,"186ea3a7-0ce3-41a1-8380-c3d10543f451":18.181818181818183,"24627c32-96e9-4f6d-8193-059b20e2f57e":18.181818181818183,"3e2664f4-109e-4b0b-b86f-2e7a26b241cf":31.818181818181817,"50dd56db-151d-4d62-8576-65f0ef6f381b":4.545454545454546,"549f0527-0f13-4447-9dc0-ca699e2dc219":50,"56f68d8b-36ca-422e-b721-c1f17ac7a78d":18.181818181818183,"5dedaf52-0a62-4822-b9eb-4b86acca6842":0,"5ffac6f9-2456-42cf-830c-9049ce37c899":13.636363636363635,"79b2c6a4-bc06-40b4-96ae-0d7da88fdaa9":0,"87969fc2-8332-4ee5-b6b0-e1b26d01ebd4":9.090909090909092,"8af54182-bed5-4224-b11d-a5ec3bbbb069":0,"94898e1d-1e50-41ab-9dcc-2c2e030cddd0":18.181818181818183,"b25d230c-cf98-48d6-a351-a208f7c9ee07":40.909090909090914,"c1f94cf8-05cf-4c5f-a8cf-c13cb0d618eb":18.181818181818183,"cb4fbf1c-02e4-4ca9-995d-29f5282fdb4a":13.636363636363635,"d46e68dc-dbb7-4296-8f40-f3c513b432bc":0,"da4534a6-897c-4431-89ef-cd326bfaf9a8":0,"e85a4f52-0e1c-447b-98b4-33ec8b9ee6f3":0,"f006e236-59ad-4647-a59f-4f46dc2c85be":9.090909090909092,"f6c418d7-c420-492f-8d24-de3827674b93":0,"fd0b4dea-6e59-444f-8d1e-0f2a4e6b75b6":9.090909090909092},"keyword":{"0d9f5547-6e05-4ad1-ad8b-3e91b842b9ec":0,"186ea3a7-0ce3-41a1-8380-c3d10543f451":0,"24627c32-96e9-4f6d-8193-059b20e2f57e":8.465079365079365,"3e2664f4-109e-4b0b-b86f-2e7a26b241cf":10.35873015873016,"50dd56db-151d-4d62-8576-65f0ef6f381b":8.112942612942613,"549f0527-0f13-4447-9dc0-ca699e2dc219":9.545238095238096,"56f68d8b-36ca-422e-b721-c1f17ac7a78d":9.969179894179891,"5dedaf52-0a62-4822-b9eb-4b86acca6842":12.065873015873017,"5ffac6f9-2456-42cf-830c-9049ce37c899":6.995634920634922,"79b2c6a4-bc06-40b4-96ae-0d7da88fdaa9":7.906666666666667,"87969fc2-8332-4ee5-b6b0-e1b26d01ebd4":6.703968253968253,"8af54182-bed5-4224-b11d-a5ec3bbbb069":10.261746031746034,"94898e1d-1e50-41ab-9dcc-2c2e030cddd0":8.653544973544975,"b25d230c-cf98-48d6-a351-a208f7c9ee07":6.757936507936508,"c1f94cf8-05cf-4c5f-a8cf-c13cb0d618eb":10.446031746031746,"cb4fbf1c-02e4-4ca9-995d-29f5282fdb4a":8.99952380952381,"d46e68dc-dbb7-4296-8f40-f3c513b432bc":0,"da4534a6-897c-4431-89ef-cd326bfaf9a8":8.847619047619046,"e85a4f52-0e1c-447b-98b4-33ec8b9ee6f3":9.21924603174603,"f006e236-59ad-4647-a59f-4f46dc2c85be":7.268253968253968,"f6c418d7-c420-492f-8d24-de3827674b93":0,"fd0b4dea-6e59-444f-8d1e-0f2a4e6b75b6":0},"topic":["vc","support","dimens","vector","svm"],"groups":[{"authors":["Bernhard Schölkopf","Kah Kay Sung","Christopher J. C. Burges","Federico Girosi","Partha Niyogi","Tomaso Poggio","Vladimir Vapnik"],"references":["186ea3a7-0ce3-41a1-8380-c3d10543f451","1ef607fe-5348-4658-8964-25a57fc49270","38f6e4bd-ee1c-4851-9352-18751ddf3172","3e2664f4-109e-4b0b-b86f-2e7a26b241cf","50dd56db-151d-4d62-8576-65f0ef6f381b","5dedaf52-0a62-4822-b9eb-4b86acca6842","87969fc2-8332-4ee5-b6b0-e1b26d01ebd4","8b2c0aff-4589-4e0f-aae4-4f84a4413406","94898e1d-1e50-41ab-9dcc-2c2e030cddd0","9499c3b8-c1f9-4d80-9cfb-c0b9b26b2511","ae3e7593-586f-495f-9416-4b50ed1fcd10","c1f94cf8-05cf-4c5f-a8cf-c13cb0d618eb","d46e68dc-dbb7-4296-8f40-f3c513b432bc","da51ab33-125e-4d94-8c9b-180b72a2b535","f006e236-59ad-4647-a59f-4f46dc2c85be"],"_id":"b25d230c-cf98-48d6-a351-a208f7c9ee07","abstract":"The support vector (SV) machine is a novel type of learning machine, based on statistical learning theory, which contains polynomial classifiers, neural networks, and radial basis function (RBF) networks as special cases. In the RBF case, the SV algorithm automatically determines centers, weights, and threshold that minimize an upper bound on the expected test error. The present study is devoted to an experimental comparison of these machines with a classical approach, where the centers are determined by X-means clustering, and the weights are computed using error backpropagation. We consider three machines, namely, a classical RBF machine, an SV machine with Gaussian kernel, and a hybrid system with the centers determined by the SV method and the weights trained by error backpropagation. Our results show that on the United States postal service database of handwritten digits, the SV machine achieves the highest recognition accuracy, followed by the hybrid system. The SV approach is thus not only theoretically well-founded but also superior in a practical application.","title":"Comparing support vector machines with Gaussian kernels to radial basis function classifiers","venue":"IEEE Transactions on Signal Processing","year":1997,"__v":0,"citationCount":327},{"authors":["Alexander J. Smola","Bernhard Schölkopf"],"references":["09ddc504-bc30-4a5e-b29f-09644e174375","3514c54b-4a5a-4807-9d10-174915c9202b","43668140-057f-400d-99eb-4f2b758f5faa","50dd56db-151d-4d62-8576-65f0ef6f381b","5dedaf52-0a62-4822-b9eb-4b86acca6842","87969fc2-8332-4ee5-b6b0-e1b26d01ebd4","8b2c0aff-4589-4e0f-aae4-4f84a4413406","a1e762ba-4019-4722-b9e1-b7ed9a7644a9","b25d230c-cf98-48d6-a351-a208f7c9ee07","c1f94cf8-05cf-4c5f-a8cf-c13cb0d618eb","d46e68dc-dbb7-4296-8f40-f3c513b432bc","f006e236-59ad-4647-a59f-4f46dc2c85be"],"_id":"3e2664f4-109e-4b0b-b86f-2e7a26b241cf","abstract":"We present a kernel-based framework for pattern recognition, regression estimation, function approximation, and multiple operator inversion. Adopting a regularization-theoretic framework, the above are formulated as constrained optimization problems. Previous approaches such as ridge regression, support vector methods, and regularization networks are included as special cases. We show connections between the cost function and some properties up to now believed to apply to support vector machines only. For appropriately chosen cost functions, the optimal solution of all the problems described above can be found by solving a simple quadratic programming problem.","title":"On a kernel-based method for pattern recognition, regression, approximation, and operator inversion","venue":"Algorithmica","year":1998,"__v":0,"citationCount":76},{"authors":["Alexander J. Smola","Bernhard Schölkopf","Klaus-Robert Müller"],"references":["3e2664f4-109e-4b0b-b86f-2e7a26b241cf","4a19318b-d54f-49cf-a42e-915f1f855927","50dd56db-151d-4d62-8576-65f0ef6f381b","56f68d8b-36ca-422e-b721-c1f17ac7a78d","5dedaf52-0a62-4822-b9eb-4b86acca6842","79b2c6a4-bc06-40b4-96ae-0d7da88fdaa9","86d97800-98df-445d-84a7-23e24b20884d","87969fc2-8332-4ee5-b6b0-e1b26d01ebd4","94898e1d-1e50-41ab-9dcc-2c2e030cddd0","9844913d-6cf1-49fc-b070-eaead4a894da","9a3d89a3-cf57-4db1-8cab-d3d7fef4d065","b25d230c-cf98-48d6-a351-a208f7c9ee07","be07152f-940c-40c7-bb8d-e04316f94cac","cb4fbf1c-02e4-4ca9-995d-29f5282fdb4a","f006e236-59ad-4647-a59f-4f46dc2c85be","f6c418d7-c420-492f-8d24-de3827674b93","fde7e6db-a925-440e-b27f-3f162da5f793"],"_id":"549f0527-0f13-4447-9dc0-ca699e2dc219","abstract":"In this paper a correspondence is derived between regularization operators used in regularization networks and support vector kernels. We prove that the Green's Functions associated with regularization operators are suitable support vector kernels with equivalent regularization properties. Moreover, the paper provides an analysis of currently used support vector kernels in the view of regularization theory and corresponding operators associated with the classes of both polynomial kernels and translation invariant kernels. The latter are also analyzed on periodical domains. As a by-product we show that a large number of radial basis functions, namely conditionally positive definite functions, may be used as support vector kernels.","title":"The connection between regularization operators and support vector kernels","venue":"Neural Networks","year":1998,"__v":0,"citationCount":197}],"offsprings":["7b57db11-7c4d-4d1e-aa62-3a5d7d1f7987","01b486c4-8955-403b-a0c6-1de74298b215"]},"94898e1d-1e50-41ab-9dcc-2c2e030cddd0":{"authors":["Bernhard Schölkopf","Alexander J. Smola","Klaus-Robert Müller"],"references":["50dd56db-151d-4d62-8576-65f0ef6f381b","7b57db11-7c4d-4d1e-aa62-3a5d7d1f7987"],"_id":"94898e1d-1e50-41ab-9dcc-2c2e030cddd0","abstract":"A new method for performing a nonlinear form of principal component analysis is proposed. By the use of integral operator kernel functions, one can efficiently compute principal components in high-dimensional feature spaces, related to input space by some nonlinear map—for instance, the space of all possible five-pixel products in 16 × 16 images. We give the derivation of the method and present experimental results on polynomial feature extraction for pattern recognition.","title":"Nonlinear component analysis as a kernel eigenvalue problem","venue":"Neural Computation","year":1998,"__v":0,"citationCount":2527,"parents":{"29e06cb4-0ae3-4c7b-863a-d63ced9b1fa2":13.333333333333334,"50dd56db-151d-4d62-8576-65f0ef6f381b":6.666666666666667,"7b57db11-7c4d-4d1e-aa62-3a5d7d1f7987":6.666666666666667,"7c016469-519e-4f34-9655-cf37f116942b":0,"7d575c42-b8c4-43fe-bf75-842cfe0a3fe3":0,"85114f9d-70a8-4940-83aa-af504b75acf8":0,"87969fc2-8332-4ee5-b6b0-e1b26d01ebd4":13.333333333333334,"a8693e98-1ed1-457b-a9fa-0f03395ce3fe":6.666666666666667,"ae3e7593-586f-495f-9416-4b50ed1fcd10":0,"aec3237b-b440-4d97-91a7-f57c249f82d6":0,"b33eea94-414c-4232-a1b8-1ffc687c1d61":20,"d46e68dc-dbb7-4296-8f40-f3c513b432bc":0,"db84fccc-eb21-4b65-9ea5-7be175c6fc24":0,"f006e236-59ad-4647-a59f-4f46dc2c85be":0,"f15b056f-a577-4391-9724-a5be885e2bd2":20},"keyword":{"29e06cb4-0ae3-4c7b-863a-d63ced9b1fa2":11.177248677248677,"50dd56db-151d-4d62-8576-65f0ef6f381b":11.650970695970697,"7b57db11-7c4d-4d1e-aa62-3a5d7d1f7987":5.1801587301587295,"7c016469-519e-4f34-9655-cf37f116942b":11.295873015873015,"7d575c42-b8c4-43fe-bf75-842cfe0a3fe3":11.626137566137567,"85114f9d-70a8-4940-83aa-af504b75acf8":11.707698412698413,"87969fc2-8332-4ee5-b6b0-e1b26d01ebd4":10.446825396825396,"a8693e98-1ed1-457b-a9fa-0f03395ce3fe":11.716957671957672,"ae3e7593-586f-495f-9416-4b50ed1fcd10":10.874603174603175,"aec3237b-b440-4d97-91a7-f57c249f82d6":9.145052910052911,"b33eea94-414c-4232-a1b8-1ffc687c1d61":11.859947089947088,"d46e68dc-dbb7-4296-8f40-f3c513b432bc":0,"db84fccc-eb21-4b65-9ea5-7be175c6fc24":9.540105820105818,"f006e236-59ad-4647-a59f-4f46dc2c85be":12.318981481481483,"f15b056f-a577-4391-9724-a5be885e2bd2":10.165555555555555},"topic":["space","princip","nonlinear","method","featur"],"offsprings":["7b57db11-7c4d-4d1e-aa62-3a5d7d1f7987","91979159-37d8-410f-a245-a33ef80a092b","9fa61eb1-0984-4492-955a-4f7aedbdc368","ea8cd3d8-17ae-4a1e-8f83-1609469087af","d28acb36-5766-4c1e-8d57-a55c2630bd90","05bbaec3-7980-4941-8638-2bbfa4ac8be0","01b486c4-8955-403b-a0c6-1de74298b215"]},"94e25efe-d596-4767-99f0-d87f8c950f0c":{"authors":["Thomas Wiegand","Gary J. Sullivan","Gisle Bjontegaard","Ajay Luthra"],"references":["237a87ca-d393-4173-a89d-fd2c5c1f3d37"],"_id":"94e25efe-d596-4767-99f0-d87f8c950f0c","abstract":"H.264/AVC is newest video coding standard of the ITU-T Video Coding Experts Group and the ISO/IEC Moving Picture Experts Group. The main goals of the H.264/AVC standardization effort have been enhanced compression performance and provision of a \"network-friendly\" video representation addressing \"conversational\" (video telephony) and \"nonconversational\" (storage, broadcast, or streaming) applications. H.264/AVC has achieved a significant improvement in rate-distortion efficiency relative to existing standards. This article provides an overview of the technical features of H.264/AVC, describes profiles and applications for the standard, and outlines the history of the standardization process.","title":"Overview of the H.264/AVC video coding standard","venue":"IEEE Transactions on Circuits and Systems for Video Technology","year":2003,"__v":0,"citationCount":2925,"parents":{"1ea5125c-2c09-47c7-ba82-913bda694a3f":0,"237a87ca-d393-4173-a89d-fd2c5c1f3d37":41.66666666666667,"260a8eb0-9e62-4156-b89b-bb8c9a48e962":0,"32e67a88-4535-4734-8e1b-b79d04ce064d":25,"4aa6d2f8-2633-4e06-849f-f81badaac3d6":0,"55ac55cc-c6ea-4f37-ad4a-e8d8322202d1":0,"586b90e7-e84c-4129-8d7b-8c14cdf2ce78":0,"696bf9e4-eb9d-4d3a-96b3-b41e18d4ac6f":25,"7210fb5d-2d76-4639-9365-e3fe830307b4":8.333333333333332,"7b88373c-de8f-420b-ab8f-94c4da5753f8":25,"7ddd1b00-19c3-4b04-b002-6156433b9af0":16.666666666666664,"d5327892-4102-4cd1-b8e2-87e3d0a3d279":0},"keyword":{"1ea5125c-2c09-47c7-ba82-913bda694a3f":8.91031746031746,"237a87ca-d393-4173-a89d-fd2c5c1f3d37":9.619444444444442,"260a8eb0-9e62-4156-b89b-bb8c9a48e962":9.839784289784289,"32e67a88-4535-4734-8e1b-b79d04ce064d":8.647619047619047,"4aa6d2f8-2633-4e06-849f-f81badaac3d6":10.946825396825398,"55ac55cc-c6ea-4f37-ad4a-e8d8322202d1":8.178042328042327,"586b90e7-e84c-4129-8d7b-8c14cdf2ce78":9.739166666666668,"696bf9e4-eb9d-4d3a-96b3-b41e18d4ac6f":11.081190476190477,"7210fb5d-2d76-4639-9365-e3fe830307b4":9.813888888888888,"7b88373c-de8f-420b-ab8f-94c4da5753f8":8.818650793650797,"7ddd1b00-19c3-4b04-b002-6156433b9af0":7.427063492063493,"d5327892-4102-4cd1-b8e2-87e3d0a3d279":9.839285714285715},"topic":["standard","video","264avc","group","expert"],"groups":[{"authors":["Thomas Wiegand","Heiko Schwarz","Joch A","Faouzi Kossentini","Gary J. Sullivan"],"references":["21528d31-71fa-4244-a272-1df8a0492107","260a8eb0-9e62-4156-b89b-bb8c9a48e962","32e67a88-4535-4734-8e1b-b79d04ce064d","37708b6d-80cd-4d60-bc32-9255c830032a","40004921-c73a-4c14-b261-7581f3628da2","7210fb5d-2d76-4639-9365-e3fe830307b4","7b88373c-de8f-420b-ab8f-94c4da5753f8","94e25efe-d596-4767-99f0-d87f8c950f0c","bc5b0e19-28da-4859-922a-38c9735fea87","d5327892-4102-4cd1-b8e2-87e3d0a3d279"],"_id":"237a87ca-d393-4173-a89d-fd2c5c1f3d37","abstract":"A unified approach to the coder control of video coding standards such as MPEG-2, H.263, MPEG-4, and the draft video coding standard H.264/AVC (advanced video coding) is presented. The performance of the various standards is compared by means of PSNR and subjective testing results. The results indicate that H.264/AVC compliant encoders typically achieve essentially the same reproduction quality as encoders that are compliant with the previous standards while typically requiring 60% or less of the bit rate.","title":"Rate-constrained coder control and comparison of video coding standards","venue":"IEEE Transactions on Circuits and Systems for Video Technology","year":2003,"__v":0,"citationCount":1998},{"authors":["Thomas Wedi","Hans Georg Musmann"],"references":["237a87ca-d393-4173-a89d-fd2c5c1f3d37","7b88373c-de8f-420b-ab8f-94c4da5753f8","7ec5bf8c-ef1d-4561-a2a4-2b96dc4b95b7","818a3e74-f654-4a75-b0b9-f7f8346d9160","94e25efe-d596-4767-99f0-d87f8c950f0c","bad538ec-41a8-4fb0-81b3-83a87cdd1c32","d5327892-4102-4cd1-b8e2-87e3d0a3d279"],"_id":"696bf9e4-eb9d-4d3a-96b3-b41e18d4ac6f","abstract":"In order to reduce the bit rate of video signals, the standardized coding techniques apply motion-compensated prediction in combination with transform coding of the prediction error. By mathematical analysis, it is shown that aliasing components are deteriorating the prediction efficiency. In order to compensate the aliasing, two-dimensional (2-D) and three-dimensional interpolation filters are developed. As a result, motion- and aliasing-compensated prediction with 1/4-pel displacement vector resolution and a separable 2-D Wiener interpolation filter provide a coding gain of up to 2 dB when compared to 1/2-pel displacement vector resolution as it is used in H.263 or MPEG-2. An additional coding gain of 1 dB can be obtained with 1/8-pel displacement vector resolution when compared to 1/4-pel displacement vector resolution. In consequence of the significantly improved coding efficiency, a Wiener interpolation filter and 1/4-pel displacement vector resolution is applied in H.264/AVC and in MPEG-4 (advanced simple profile).","title":"Motion- and aliasing-compensated prediction for hybrid video coding","venue":"IEEE Transactions on Circuits and Systems for Video Technology","year":2003,"__v":0,"citationCount":83},{"authors":["Markus Flierl","Bernd Girod"],"references":["237a87ca-d393-4173-a89d-fd2c5c1f3d37","239d0c17-d44e-43ce-b0f3-18ebc8823de3","2eef0cb1-cc0c-48ee-9eea-2034711aa345","31907507-643d-4bf0-a6f2-8cec94d9d779","40004921-c73a-4c14-b261-7581f3628da2","59b905dd-c832-4d30-8e29-5062a0d6d8c9","7210fb5d-2d76-4639-9365-e3fe830307b4","8af0e559-c8c4-4960-a883-f6a23c840215","d5327892-4102-4cd1-b8e2-87e3d0a3d279"],"_id":"7b88373c-de8f-420b-ab8f-94c4da5753f8","abstract":"This paper reviews recent advances in using B pictures in the context of the draft H.264/AVC video-compression standard. We focus on reference picture selection and linearly combined motion-compensated prediction signals. We show that bidirectional prediction exploits partially the efficiency of combined prediction signals whereas multihypothesis prediction allows a more general form of B pictures. The general concept of linearly combined prediction signals chosen from an arbitrary set of reference pictures improves the H.264/AVC test model TML-9 which is used in the following. We outline H.264/AVC macroblock prediction modes for B pictures, classify them into four groups and compare their efficiency in terms of rate-distortion performance. When investigating multihypothesis prediction, we show that bidirectional prediction is a special case of this concept. Multihypothesis prediction allows also two combined forward prediction signals. Experimental results show that this case is also advantageous in terms of compression efficiency. The draft H.264/AVC video-compression standard offers improved entropy coding by context-based adaptive binary arithmetic coding. Simulations show that the gains by multihypothesis prediction and arithmetic coding are additive. B pictures establish an enhancement layer and are predicted from reference pictures that are provided by the base layer. The quality of the base layer influences the rate-distortion trade-off for B pictures. We demonstrate how the quality of the B pictures should be reduced to improve the overall rate-distortion performance of the scalable representation.","title":"Generalized B pictures and the draft H.264/AVC video-compression standard","venue":"IEEE Transactions on Circuits and Systems for Video Technology","year":2003,"__v":0,"citationCount":79},{"authors":["Thomas Stockhammer","Miska M. Hannuksela","Thomas Wiegand"],"references":["1c556d44-b168-4491-a6ea-8b84f7d69971","21528d31-71fa-4244-a272-1df8a0492107","237a87ca-d393-4173-a89d-fd2c5c1f3d37","2eb82ba0-d2dd-46a8-8fbd-6872c3abe1a5","3df4d827-20a8-4e4f-b454-5f8261080a4d","4aa6d2f8-2633-4e06-849f-f81badaac3d6","68b10ecd-f306-4e04-af8d-b040a1d5b67b","7ddd1b00-19c3-4b04-b002-6156433b9af0","93e2599f-e6b0-4df4-949c-7840cb02794a","94e25efe-d596-4767-99f0-d87f8c950f0c","9bafdb60-ae87-47be-92f3-14ad87f489d6","9f2086af-047d-4b6a-80e4-7b52d3aa3eeb","a0582c2f-2516-4a51-b227-8f2f8b41b5e0","b884a36e-0c4d-49d7-a815-9fd9b5e4a8b5","b88ad275-e83f-4751-9e2f-16cbecbcaacc","cb43e76e-caeb-403d-b1d5-96503a362e3d","cb6b6e17-ad50-4984-807e-5b33a9b28c02","cede2f70-f1f1-4484-b5d3-d3c2d0adf8cb","dbfb0dd3-5bea-4064-98e8-03c977f40873","ed063f6e-7a7d-4215-b391-d2d10da5e9b7","fa72ee30-f4e1-4173-b2fa-8723df31a7cd"],"_id":"32e67a88-4535-4734-8e1b-b79d04ce064d","abstract":"Video transmission in wireless environments is a challenging task calling for high-compression efficiency as well as a network friendly design. Both have been major goals of the H.264/AVC standardization effort addressing \"conversational\" (i.e., video telephony) and \"nonconversational\" (i.e., storage, broadcast, or streaming) applications. The video compression performance of the H.264/AVC video coding layer typically provides a significant improvement. The network-friendly design goal of H.264/AVC is addressed via the network abstraction layer that has been developed to transport the coded video data over any existing and future networks including wireless systems. The main objective of this paper is to provide an overview over the tools which are likely to be used in wireless environments and discusses the most challenging application, wireless conversational services in greater detail. Appropriate justifications for the application of different tools based on experimental results are presented.","title":"H.264/AVC in wireless environments","venue":"IEEE Transactions on Circuits and Systems for Video Technology","year":2003,"__v":0,"citationCount":233}],"offsprings":["ff3e8103-1378-408b-adc2-c42b1c25b065","237a87ca-d393-4173-a89d-fd2c5c1f3d37"]},"9a8236cc-7394-47f7-a19a-17af169d5a22":{"authors":["Marco Punta","Penny Coggill","Ruth Y. Eberhardt","Jaina Mistry","John G. Tate","Chris Boursnell","Ningze Pang","Kristoffer Forslund","Goran Ceric","Jody Clements","Andreas Heger","Liisa Holm","Erik L. L. Sonnhammer","Sean R. Eddy","Alex Bateman","Robert D. Finn"],"references":[],"_id":"9a8236cc-7394-47f7-a19a-17af169d5a22","abstract":"Pfam is a large collection of protein families and domains. Over the past 2 years the number of families in Pfam has doubled and now stands at 6190 (version 10.0). Methodology improvements for searching the Pfam collection locally as well as via the web are described. Other recent innovations include modelling of discontinuous domains allowing Pfam domain definitions to be closer to those found in structure databases. Pfam is available on the web in the UK (http://www.sanger.ac.uk/ Software/Pfam/), the USA (http://pfam.wustl.edu/), France (http://pfam.jouy.inra.fr/) and Sweden (http:// Pfam.cgb.ki.se/).","title":"The Pfam protein families database","venue":"Nucleic Acids Research","year":2000,"__v":0,"citationCount":1607,"parents":{"031ee1f7-92be-41e4-8139-8566b48cd2d2":0,"2fa6ce4c-2893-4863-8599-c94531d65a92":0,"307e9a21-bfb6-4469-bf91-6a33a7818a7a":0,"3b2e9095-2606-42cb-ad07-84274f05eabe":0,"4cd944ce-f57f-44de-b1ef-3f20a82e1647":0,"ac8684fc-f474-4728-92e5-fe123981f1da":0,"be9698e8-ef21-4479-ad11-e9854ea96b66":0,"c093fb5b-15c2-4ac6-a8c8-5240e41aea3e":18.181818181818183,"c80087dd-ade8-49d9-ae99-e3917dbe530e":0,"cf55297d-fb26-486a-8f32-ecab886be835":0,"d1493bbd-4951-4f09-8769-dd73c23e3368":18.181818181818183},"keyword":{"031ee1f7-92be-41e4-8139-8566b48cd2d2":6.946031746031746,"2fa6ce4c-2893-4863-8599-c94531d65a92":8.31111111111111,"307e9a21-bfb6-4469-bf91-6a33a7818a7a":8.225183150183149,"3b2e9095-2606-42cb-ad07-84274f05eabe":8.793650793650794,"4cd944ce-f57f-44de-b1ef-3f20a82e1647":7.346031746031746,"ac8684fc-f474-4728-92e5-fe123981f1da":7.290476190476191,"be9698e8-ef21-4479-ad11-e9854ea96b66":7.64047619047619,"c093fb5b-15c2-4ac6-a8c8-5240e41aea3e":8.783333333333333,"c80087dd-ade8-49d9-ae99-e3917dbe530e":6.729365079365079,"cf55297d-fb26-486a-8f32-ecab886be835":6.77579365079365,"d1493bbd-4951-4f09-8769-dd73c23e3368":5.483333333333333},"topic":["pfam","domain","web","uk","famili"],"offsprings":[]},"9b8a49b5-a5cb-4c61-8c60-3bde6d310009":{"authors":["Ivan Laptev","Marcin Marszalek","Cordelia Schmid","Benjamin Rozenfeld"],"references":["4adb467d-dacf-4019-b0d5-28ce1f323cf4","e0ac4812-7729-4a2d-8a1f-74b1b7c8eb5d"],"_id":"9b8a49b5-a5cb-4c61-8c60-3bde6d310009","abstract":"The aim of this paper is to address recognition of natural human actions in diverse and realistic video settings. This challenging but important subject has mostly been ignored in the past due to several problems one of which is the lack of realistic and annotated video datasets. Our first contribution is to address this limitation and to investigate the use of movie scripts for automatic annotation of human actions in videos. We evaluate alternative methods for action retrieval from scripts and show benefits of a text-based classifier. Using the retrieved action samples for visual learning, we next turn to the problem of action classification in video. We present a new method for video classification that builds upon and extends several recent ideas including local space-time features, space-time pyramids and multi-channel non-linear SVMs. The method is shown to improve state-of-the-art results on the standard KTH action dataset by achieving 91.8% accuracy. Given the inherent problem of noisy labels in automatic annotation, we particularly investigate and show high tolerance of our method to annotation errors in the training set. We finally apply the method to learning and classifying challenging action classes in movies and show promising results.","title":"Learning realistic human actions from movies","venue":"computer vision and pattern recognition","year":2008,"__v":0,"citationCount":1556,"parents":{"03ace88b-1acb-44f9-8cbd-e9f2c40cce52":13.333333333333334,"19343949-1bdf-4a0e-b597-4a88f483ecdd":20,"4adb467d-dacf-4019-b0d5-28ce1f323cf4":0,"6dd46f95-cad2-4e02-b0f7-1c04cd64d5be":6.666666666666667,"71b9bab3-9116-4123-84fb-7168e657cc1b":6.666666666666667,"80a2bee0-7dff-45f9-a1b6-b3f467738100":0,"8947ffba-a802-4081-94f4-4bc721b14c47":0,"c5360ce9-89ea-494f-b58e-59c76568823b":13.333333333333334,"cba76e40-4de9-485b-b6a1-a9b6413eb8d7":6.666666666666667,"da19944a-6197-486e-8f2a-56c4b07342ba":0,"e0ac4812-7729-4a2d-8a1f-74b1b7c8eb5d":0,"e1dc64ee-3858-462b-9d9f-a4e11facba19":20,"e2593dfa-7bc9-41ec-af60-e2c2ca4ec6ca":13.333333333333334,"f4f7690d-7640-473e-85ed-22165b54e716":0,"fc780759-4533-4b33-9774-746ca210842f":0},"keyword":{"03ace88b-1acb-44f9-8cbd-e9f2c40cce52":10.871666666666668,"19343949-1bdf-4a0e-b597-4a88f483ecdd":11.77222222222222,"4adb467d-dacf-4019-b0d5-28ce1f323cf4":8.847777777777777,"6dd46f95-cad2-4e02-b0f7-1c04cd64d5be":9.76111111111111,"71b9bab3-9116-4123-84fb-7168e657cc1b":10.28833333333333,"80a2bee0-7dff-45f9-a1b6-b3f467738100":8.092222222222222,"8947ffba-a802-4081-94f4-4bc721b14c47":11.621666666666664,"c5360ce9-89ea-494f-b58e-59c76568823b":9.213015873015873,"cba76e40-4de9-485b-b6a1-a9b6413eb8d7":0,"da19944a-6197-486e-8f2a-56c4b07342ba":10.2,"e0ac4812-7729-4a2d-8a1f-74b1b7c8eb5d":9.140291005291004,"e1dc64ee-3858-462b-9d9f-a4e11facba19":11.749166666666666,"e2593dfa-7bc9-41ec-af60-e2c2ca4ec6ca":5.484444444444445,"f4f7690d-7640-473e-85ed-22165b54e716":10.806825396825396,"fc780759-4533-4b33-9774-746ca210842f":10.130555555555555},"topic":["action","video","method","annot","show"],"offsprings":[]},"9bd00024-b302-407e-92af-5d62759757bd":{"authors":["Amir Said","William A. Pearlman"],"references":[],"_id":"9bd00024-b302-407e-92af-5d62759757bd","abstract":"Embedded zerotree wavelet (EZW) coding, introduced by Shapiro (see IEEE Trans. Signal Processing, vol.41, no.12, p.3445, 1993), is a very effective and computationally simple technique for image compression. We offer an alternative explanation of the principles of its operation, so that the reasons for its excellent performance can be better understood. These principles are partial ordering by magnitude with a set partitioning sorting algorithm, ordered bit plane transmission, and exploitation of self-similarity across different scales of an image wavelet transform. Moreover, we present a new and different implementation based on set partitioning in hierarchical trees (SPIHT), which provides even better performance than our previously reported extension of EZW that surpassed the performance of the original EZW. The image coding results, calculated from actual file sizes and images reconstructed by the decoding algorithm, are either comparable to or surpass previous results obtained through much more sophisticated and computationally complex methods. In addition, the new coding and decoding procedures are extremely fast, and they can be made even faster, with only small loss in performance, by omitting entropy coding of the bit stream by the arithmetic code.","title":"A new, fast, and efficient image codec based on set partitioning in hierarchical trees","venue":"IEEE Transactions on Circuits and Systems for Video Technology","year":1996,"__v":0,"citationCount":2084,"parents":{"010951bc-22ff-4d96-811f-d64d20435465":0,"48ffef7f-9d41-47b6-9b00-6cdc419ad207":20,"49b0508a-feaf-4799-bc92-1b63f67bfeff":30,"678f1bf9-947c-4a8c-8fe2-4b81e22edeb5":40,"8eaaee11-fdcc-479e-adcf-9ef720a18cbf":10,"8fef809b-f2e7-4828-91f4-e9ceb6b71e8b":0,"aecf8a08-eff7-4182-8bbb-a7b29de2f281":30,"b0e448de-f181-4a33-ac19-ddd0e1eeeaba":10,"eb42fb1b-ebb9-4b7f-abd2-6ef09becd655":0,"fd9761a2-c929-4912-b36c-6954ac9cb60b":0},"keyword":{"010951bc-22ff-4d96-811f-d64d20435465":5.656746031746032,"48ffef7f-9d41-47b6-9b00-6cdc419ad207":6.786375661375662,"49b0508a-feaf-4799-bc92-1b63f67bfeff":8.289464285714287,"678f1bf9-947c-4a8c-8fe2-4b81e22edeb5":5.303968253968255,"8eaaee11-fdcc-479e-adcf-9ef720a18cbf":6.8658730158730155,"8fef809b-f2e7-4828-91f4-e9ceb6b71e8b":4.044920634920635,"aecf8a08-eff7-4182-8bbb-a7b29de2f281":6.482222222222223,"b0e448de-f181-4a33-ac19-ddd0e1eeeaba":6.166666666666668,"eb42fb1b-ebb9-4b7f-abd2-6ef09becd655":7.500793650793651,"fd9761a2-c929-4912-b36c-6954ac9cb60b":5.784603174603174},"topic":["code","perform","imag","ezw"],"groups":[{"authors":["Diego P. de Garrido","William A. Pearlman","Weiler Alves Finamore"],"references":["1a3d891e-8b86-402c-99b9-244a8ec0644f","24ffdc6f-e0d4-469a-94ea-ddcd709924ed","5df16225-5bf6-4b16-8f73-e1663a6115b8","6ddde508-3b1c-4155-9986-9211a27f6d0d","73dbac7a-3580-4ab9-9825-aae9453bb6bd","781a6016-9ed4-4ebf-95c6-dc3c72f4457e","8eaaee11-fdcc-479e-adcf-9ef720a18cbf","8fef809b-f2e7-4828-91f4-e9ceb6b71e8b","938b98e9-7c7e-4d9e-9d26-53f5f9c44c25","c9ece2fc-8035-4903-86aa-4e26586e0851","fd9761a2-c929-4912-b36c-6954ac9cb60b"],"_id":"49b0508a-feaf-4799-bc92-1b63f67bfeff","abstract":"A clustering algorithm for the design of efficient vector quantizers to be followed by entropy coding is proposed. The algorithm, called entropy-constrained pairwise nearest neighbor (ECPNN), designs codebooks by merging the pair of Voronoi regions which gives the least increase in distortion for a given decrease in entropy. The algorithm can be used as an alternative to the entropy-constrained vector quantizer design (ECVQ) proposed by Chou, Lookabaugh, and Gray (1989). By a natural extension of the ECPNN algorithm the authors develop another algorithm that designs alphabet and entropy-constrained vector quantizers and call it alphabet- and entropy-constrained pairwise nearest neighbor (AECPNN) design. Through simulations on synthetic sources, it is shown that ECPNN and ECVQ have indistinguishable mean-square-error versus rate performance and that the ECPNN and AECPNN algorithms obtain as close performance by the same measure as the ECVQ and AECVQ (Rao and Pearlman, 1993) algorithms. The advantages over ECVQ are that the ECPNN approach enables much faster codebook design and uses smaller codebooks. A single pass through the ECPNN (or AECPNN) design algorithm, which progresses from larger to successively smaller rates, allows the storage of any desired number of intermediate codebooks. In the context of multirate subband (or transform) coders, this feature is especially desirable. The performance of coding image pyramids using ECPNN and AECPNN codebooks at rates from 1/3 to 1.0 bit/pixel is discussed. >","title":"A clustering algorithm for entropy-constrained vector quantizer design with applications in coding image pyramids","venue":"IEEE Transactions on Circuits and Systems for Video Technology","year":1995,"__v":0,"citationCount":11},{"authors":["James H. Kasner","Michael W. Marcellin"],"references":["00811184-fce0-4972-9418-929fa0ed0c65","1b9b0477-9ccc-4b49-a066-25bfc0bf425e","75449d86-4cf8-45aa-9e8c-9ca80ed4f3a5","781a6016-9ed4-4ebf-95c6-dc3c72f4457e","7fcb2263-dd42-4e54-80d0-fb3bfb6eaba8","8eaaee11-fdcc-479e-adcf-9ef720a18cbf","aecf8a08-eff7-4182-8bbb-a7b29de2f281","b0e448de-f181-4a33-ac19-ddd0e1eeeaba","f13ab94f-20dd-4098-bf15-d3116590134c","fd9761a2-c929-4912-b36c-6954ac9cb60b"],"_id":"678f1bf9-947c-4a8c-8fe2-4b81e22edeb5","abstract":"In this work, we propose end-to-end image compression/decompression systems based on the discrete wavelet transform (DWT), entropy-constrained trellis coded quantization (ECTCQ), and arithmetic coding. Two forms of adaptation (codebook and image subblock) are investigated. The baseline system uses neither form of adaptation, while the adaptive systems use one or both forms of adaptivity. Excellent peak signal-to-noise ratios are obtained for the 512/spl times/512 \"Lenna\" image. Comparison of the systems with other results from the literature show that the fully adaptive system is quite competitive. >","title":"Adaptive wavelet coding of images","venue":"international conference on image processing","year":1994,"__v":0,"citationCount":6},{"authors":["Jerome M. Shapiro"],"references":["011ac5b7-efca-4771-aca8-c16af5f31143","3f0bc2c9-a5c2-4e4c-a4e9-7631e36bc6a3","7ccbdf09-a84e-4ad2-ab20-cb28b6c41155","87624da4-289a-4c42-92a0-c239a103b029","8d611b4b-5120-494f-b5bd-d234be570072","8eaaee11-fdcc-479e-adcf-9ef720a18cbf","a6656b9e-ac90-42eb-8b65-9bd78b66f1f2","b9c3ab48-c632-4ec2-9e03-72c00b2d21ed","cb17c20e-e335-43dc-b2ae-350e43b74faa","d846cbd5-1ce3-40c0-b528-3669185e3c6c","eb42fb1b-ebb9-4b7f-abd2-6ef09becd655","ee3fa7f4-a88d-4b58-8ee8-843370ed51be","fd9761a2-c929-4912-b36c-6954ac9cb60b","ffe19a00-434e-4208-b764-27ce16f1b83e"],"_id":"aecf8a08-eff7-4182-8bbb-a7b29de2f281","abstract":"The embedded zerotree wavelet algorithm (EZW) is a simple, yet remarkably effective, image compression algorithm, having the property that the bits in the bit stream are generated in order of importance, yielding a fully embedded code. The embedded code represents a sequence of binary decisions that distinguish an image from the \"null\" image. Using an embedded coding algorithm, an encoder can terminate the encoding at any point thereby allowing a target rate or target distortion metric to be met exactly. Also, given a bit stream, the decoder can cease decoding at any point in the bit stream and still produce exactly the same image that would have been encoded at the bit rate corresponding to the truncated bit stream. In addition to producing a fully embedded bit stream, the EZW consistently produces compression results that are competitive with virtually all known compression algorithms on standard test images. Yet this performance is achieved with a technique that requires absolutely no training, no pre-stored tables or codebooks, and requires no prior knowledge of the image source. The EZW algorithm is based on four key concepts: (1) a discrete wavelet transform or hierarchical subband decomposition, (2) prediction of the absence of significant information across scales by exploiting the self-similarity inherent in images, (3) entropy-coded successive-approximation quantization, and (4) universal lossless data compression which is achieved via adaptive arithmetic coding. >","title":"Embedded image coding using zerotrees of wavelet coefficients","venue":"IEEE Transactions on Signal Processing","year":1993,"__v":0,"citationCount":1846}],"offsprings":["7f1214b2-e070-4ff2-a5d3-647e7c16c2d7"]},"9d826763-53f1-4bfd-a7f9-6a27fc26a8ae":{"authors":["Matthew W. Moskewicz","Conor F. Madigan","Ying Zhao","Lintao Zhang","Sharad Malik"],"references":[],"_id":"9d826763-53f1-4bfd-a7f9-6a27fc26a8ae","abstract":"Boolean satisfiability is probably the most studied of the combinatorial optimization/search problems. Significant effort has been devoted to trying to provide practical solutions to this problem for problem instances encountered in a range of applications in electronic design automation (EDA), as well as in artificial intelligence (AI). This study has culminated in the development of several SAT packages, both proprietary and in the public domain (e.g. GRASP, SATO) which find significant use in both research and industry. Most existing complete solvers are variants of the Davis-Putnam (DP) search algorithm. In this paper we describe the development of a new complete solver, Chaff which achieves significant performance gains through careful engineering of all aspects of the search-especially a particularly efficient implementation of Boolean constraint propagation (BCP) and a novel low overhead decision strategy. Chaff has been able to obtain one to two orders of magnitude performance improvement on difficult SAT benchmarks in comparison with other solvers (DP or otherwise), including GRASP and SATO.","title":"Chaff: engineering an efficient SAT solver","venue":"design automation conference","year":2001,"__v":0,"citationCount":1556,"parents":{"24368035-5db2-4d01-b231-75582d8f7d0a":5.555555555555555,"2b8bae9d-40c1-4def-85c9-858688cac846":8.333333333333332,"3e5d18f4-a087-4eda-9d3f-96ae80cfd094":2.7777777777777777,"4ec23a89-145e-4575-910a-b8c6c395c570":11.11111111111111,"527dd478-3ad0-494c-8c3d-3a5ac282f20e":2.7777777777777777,"575b0b79-a1a9-485d-beb1-9a5344a6c8b2":8.333333333333332,"6da33f3e-bb59-4b0f-843a-25ba8541402d":0,"72b48de1-1b35-4e46-b05f-c66baa9dd457":5.555555555555555,"74703f80-bea9-4f83-910a-ff90285462b5":19.444444444444446,"7993cb55-046f-409e-bb5a-bb4b6f06e222":2.7777777777777777,"81c6882d-1e6e-4757-b839-283520e94519":8.333333333333332,"8590b0eb-aa82-41d0-b50a-f0942ca1f658":0,"8ac3941f-4b9d-4cc6-bcd2-941653ea1579":5.555555555555555,"8c3cafc2-667a-4d43-b1a4-8fbfbfd902cc":11.11111111111111,"8d6dc616-8728-49a3-8962-71a2530d16bc":5.555555555555555,"94a54cdb-24cb-401c-9f12-b6e6e97d9cfe":2.7777777777777777,"9d1ed045-51bd-44ee-8e2e-a370b02b4aae":8.333333333333332,"a9d0be6b-d4e5-4d78-bc9e-15501c4c9813":0,"ac39dba5-04ee-4ac3-9cc0-75bab50ad629":0,"b265a7bf-5e62-4626-a375-6c88f0ca9f4c":2.7777777777777777,"b404f701-5c40-4d66-8ab0-4b74af40d9eb":11.11111111111111,"b51aef16-825c-479c-9cc8-36480e020143":11.11111111111111,"b5edf6d3-9177-4c78-aaf8-6171992fafaf":0,"c7635f59-061c-42f9-b956-a5542649c7b6":2.7777777777777777,"c77fa96f-1a60-444c-ac23-d65ad48f68fb":2.7777777777777777,"c9d38247-83ba-4f7c-979e-47a4ac52da04":0,"cf7f48dd-fc88-4f47-8f8e-f7b24e5de011":0,"d8d2eee8-8c8a-4ede-9b70-42dc155c34ba":5.555555555555555,"e8df1a74-0e2f-475a-ad50-33d398d89150":2.7777777777777777,"ec59a0e8-5c61-4b20-8708-0a7c2a195977":8.333333333333332,"f5de6b41-0df8-4270-8211-a67a081dad45":0,"f72a4f45-05ec-4031-a4aa-ac29fdb4ef74":5.555555555555555,"f8c97eca-bf90-4c18-8e7f-44b831d0a995":11.11111111111111,"facd8e57-ecb8-4bfe-967c-8ffe059822bb":0,"fc17d09d-d231-45e5-b770-832ad81b7b0e":2.7777777777777777,"ffb4183d-259e-4654-9b09-2368e49ded05":16.666666666666664},"keyword":{"24368035-5db2-4d01-b231-75582d8f7d0a":11.397738095238093,"2b8bae9d-40c1-4def-85c9-858688cac846":9.966031746031746,"3e5d18f4-a087-4eda-9d3f-96ae80cfd094":0,"4ec23a89-145e-4575-910a-b8c6c395c570":9.64015873015873,"527dd478-3ad0-494c-8c3d-3a5ac282f20e":12.379285714285714,"575b0b79-a1a9-485d-beb1-9a5344a6c8b2":11.421626984126984,"6da33f3e-bb59-4b0f-843a-25ba8541402d":0,"72b48de1-1b35-4e46-b05f-c66baa9dd457":9.678809523809525,"74703f80-bea9-4f83-910a-ff90285462b5":9.598888888888888,"7993cb55-046f-409e-bb5a-bb4b6f06e222":12.472896825396827,"81c6882d-1e6e-4757-b839-283520e94519":11.478412698412697,"8590b0eb-aa82-41d0-b50a-f0942ca1f658":9.024603174603175,"8ac3941f-4b9d-4cc6-bcd2-941653ea1579":0,"8c3cafc2-667a-4d43-b1a4-8fbfbfd902cc":12.636600529100528,"8d6dc616-8728-49a3-8962-71a2530d16bc":6.840476190476189,"94a54cdb-24cb-401c-9f12-b6e6e97d9cfe":10.024285714285712,"9d1ed045-51bd-44ee-8e2e-a370b02b4aae":11.29686507936508,"a9d0be6b-d4e5-4d78-bc9e-15501c4c9813":7.155555555555557,"ac39dba5-04ee-4ac3-9cc0-75bab50ad629":0,"b265a7bf-5e62-4626-a375-6c88f0ca9f4c":10.143253968253967,"b404f701-5c40-4d66-8ab0-4b74af40d9eb":12.722460317460317,"b51aef16-825c-479c-9cc8-36480e020143":12.231706349206348,"b5edf6d3-9177-4c78-aaf8-6171992fafaf":10.103888888888887,"c7635f59-061c-42f9-b956-a5542649c7b6":11.144642857142857,"c77fa96f-1a60-444c-ac23-d65ad48f68fb":8.048015873015874,"c9d38247-83ba-4f7c-979e-47a4ac52da04":8.947222222222221,"cf7f48dd-fc88-4f47-8f8e-f7b24e5de011":10.483611111111111,"d8d2eee8-8c8a-4ede-9b70-42dc155c34ba":11.030119047619046,"e8df1a74-0e2f-475a-ad50-33d398d89150":7.807222222222222,"ec59a0e8-5c61-4b20-8708-0a7c2a195977":9.04956349206349,"f5de6b41-0df8-4270-8211-a67a081dad45":9.13452380952381,"f72a4f45-05ec-4031-a4aa-ac29fdb4ef74":11.591865079365077,"f8c97eca-bf90-4c18-8e7f-44b831d0a995":11.529880952380951,"facd8e57-ecb8-4bfe-967c-8ffe059822bb":0,"fc17d09d-d231-45e5-b770-832ad81b7b0e":13.630238095238093,"ffb4183d-259e-4654-9b09-2368e49ded05":10.236190476190476},"topic":["solver","signific","problem","studi","sato"],"offsprings":[]},"9fa61eb1-0984-4492-955a-4f7aedbdc368":{"authors":["Isabelle Guyon","Jason Weston","Stephen D. Barnhill","Vladimir Vapnik"],"references":["50dd56db-151d-4d62-8576-65f0ef6f381b","685b313d-8a77-481e-9456-e405a1d29549","94898e1d-1e50-41ab-9dcc-2c2e030cddd0"],"_id":"9fa61eb1-0984-4492-955a-4f7aedbdc368","abstract":"DNA micro-arrays now permit scientists to screen thousands of genes simultaneously and determine whether those genes are active, hyperactive or silent in normal or cancerous tissue. Because these new micro-array devices generate bewildering amounts of raw data, new analytical methods must be developed to sort out whether cancer tissues have distinctive signatures of gene expression over normal tissues or other types of cancer tissues.#R##N##R##N#In this paper, we address the problem of selection of a small subset of genes from broad patterns of gene expression data, recorded on DNA micro-arrays. Using available training examples from cancer and normal patients, we build a classifier suitable for genetic diagnosis, as well as drug discovery. Previous attempts to address this problem select genes with correlation techniques. We propose a new method of gene selection utilizing Support Vector Machine methods based on Recursive Feature Elimination (RFE). We demonstrate experimentally that the genes selected by our techniques yield better classification performance and are biologically relevant to cancer.#R##N##R##N#In contrast with the baseline method, our method eliminates gene redundancy automatically and yields better and more compact gene subsets. In patients with leukemia our method discovered 2 genes that yield zero leave-one-out error, while 64 genes are necessary for the baseline method to get the best result (one leave-one-out error). In the colon cancer database, using only 4 genes our method is 98% accurate, while the baseline method is only 86% accurate.","title":"Gene Selection for Cancer Classification using Support Vector Machines","venue":"Machine Learning","year":2002,"__v":0,"citationCount":2006,"parents":{"07398a91-b607-4d52-ad00-586caceb0ac9":0,"0781e713-d8ca-4f62-89e8-3047b77dd6e6":25,"08dcb9a2-1d9e-4094-a9ed-144d4343167e":0,"1e37aa02-2911-45db-867f-bc2043492c08":12.5,"2bd9968a-1e0b-4a11-85a2-19edcf0ee77d":12.5,"404775ac-d2d2-4a0b-8195-9458da97105b":0,"4c3fd4d5-c23d-4a24-84cd-21d45208941e":0,"50d6ceff-8829-44e3-a8a0-96b69b1805b4":0,"50dd56db-151d-4d62-8576-65f0ef6f381b":6.25,"685b313d-8a77-481e-9456-e405a1d29549":0,"94898e1d-1e50-41ab-9dcc-2c2e030cddd0":12.5,"95fdc823-57bc-4e49-8e5b-8fac0c4cfb7f":6.25,"dc92e76f-e502-44a0-898b-a3e12d7fabe9":6.25,"e85a4f52-0e1c-447b-98b4-33ec8b9ee6f3":0,"ec039631-17e8-4794-bc48-2840c96ba044":0,"f006e236-59ad-4647-a59f-4f46dc2c85be":6.25},"keyword":{"07398a91-b607-4d52-ad00-586caceb0ac9":9.922222222222222,"0781e713-d8ca-4f62-89e8-3047b77dd6e6":10.727777777777778,"08dcb9a2-1d9e-4094-a9ed-144d4343167e":0,"1e37aa02-2911-45db-867f-bc2043492c08":7.133015873015874,"2bd9968a-1e0b-4a11-85a2-19edcf0ee77d":9.053333333333333,"404775ac-d2d2-4a0b-8195-9458da97105b":10.100000000000001,"4c3fd4d5-c23d-4a24-84cd-21d45208941e":11.862698412698412,"50d6ceff-8829-44e3-a8a0-96b69b1805b4":12.074444444444444,"50dd56db-151d-4d62-8576-65f0ef6f381b":9.618977411477411,"685b313d-8a77-481e-9456-e405a1d29549":11.149206349206349,"94898e1d-1e50-41ab-9dcc-2c2e030cddd0":11.234761904761905,"95fdc823-57bc-4e49-8e5b-8fac0c4cfb7f":9.393650793650794,"dc92e76f-e502-44a0-898b-a3e12d7fabe9":9.194708994708995,"e85a4f52-0e1c-447b-98b4-33ec8b9ee6f3":9.099166666666665,"ec039631-17e8-4794-bc48-2840c96ba044":10.120396825396826,"f006e236-59ad-4647-a59f-4f46dc2c85be":10.804603174603177},"topic":["gene","method","cancer","tissu","select"],"groups":[{"authors":["Jason Weston","Sayan Mukherjee","Olivier Chapelle","Massimiliano Pontil","Tomaso Poggio","Vladimir Vapnik"],"references":["08dcb9a2-1d9e-4094-a9ed-144d4343167e","1e4f4b5c-55e0-4d5b-b7cc-9e7fada3e341","43530fe4-10a9-4ddf-b61d-8844f0ff3f04","4c3fd4d5-c23d-4a24-84cd-21d45208941e","685b313d-8a77-481e-9456-e405a1d29549","95fdc823-57bc-4e49-8e5b-8fac0c4cfb7f","9fa61eb1-0984-4492-955a-4f7aedbdc368","d04682be-3715-4727-b177-709d7eab30d7"],"_id":"0781e713-d8ca-4f62-89e8-3047b77dd6e6","abstract":"We introduce a method of feature selection for Support Vector Machines. The method is based upon finding those features which minimize bounds on the leave-one-out error. This search can be efficiently performed via gradient descent. The resulting algorithms are shown to be superior to some standard feature selection algorithms on both toy data and real-life problems of face recognition, pedestrian detection and analyzing DNA microarray data.","title":"Feature Selection for SVMs","venue":"neural information processing systems","year":2001,"__v":0,"citationCount":374}],"offsprings":["4fb87930-7f6c-4f03-ae22-32445138ec83"]},"a2cd0e23-f184-441d-b90e-d4492a9ef508":{"authors":["Ian F. Akyildiz","Won-Yeol Lee","Mehmet C. Vuran","Shantidev Mohanty"],"references":["b857298c-92c9-4f05-a704-3b9fc6be06e3","d1ba534e-3f80-4366-bb83-be16006f9e18"],"_id":"a2cd0e23-f184-441d-b90e-d4492a9ef508","abstract":"Today's wireless networks are characterized by a fixed spectrum assignment policy. However, a large portion of the assigned spectrum is used sporadically and geographical variations in the utilization of assigned spectrum ranges from 15% to 85% with a high variance in time. The limited available spectrum and the inefficiency in the spectrum usage necessitate a new communication paradigm to exploit the existing wireless spectrum opportunistically. This new networking paradigm is referred to as NeXt Generation (xG) Networks as well as Dynamic Spectrum Access (DSA) and cognitive radio networks. The term xG networks is used throughout the paper. The novel functionalities and current research challenges of the xG networks are explained in detail. More specifically, a brief overview of the cognitive radio technology is provided and the xG network architecture is introduced. Moreover, the xG network functions such as spectrum management, spectrum mobility and spectrum sharing are explained in detail. The influence of these functions on the performance of the upper layer protocols such as routing and transport are investigated and open research issues in these areas are also outlined. Finally, the cross-layer design challenges in xG networks are discussed.","title":"NeXt generation/dynamic spectrum access/cognitive radio wireless networks: a survey","venue":"Computer Networks","year":2006,"__v":0,"citationCount":2483,"parents":{"04c58307-939e-481d-b4d7-6579d1607543":0,"097d282b-beed-47c1-9e6f-07255fee1a3a":6.666666666666667,"17d3c566-60ad-491a-b63c-ae7f3b46dd54":6.666666666666667,"269e006a-d493-4ade-be8b-cfc3b56d5752":0,"4d4338a1-d3e7-482a-9f8c-9bd3a4eae9c3":0,"602e89cc-75ec-4d21-925a-39fb38e46877":0,"9683e149-7dd9-40d0-be7c-2bd6303588c4":0,"b857298c-92c9-4f05-a704-3b9fc6be06e3":6.666666666666667,"c0beb0e0-d0a2-4a9e-a99c-39f5e975849e":0,"caa552a1-c1b7-48d6-9d30-046d360f8ce9":0,"d1ba534e-3f80-4366-bb83-be16006f9e18":0,"d75e2955-a86c-44dd-b3e2-37d87559c9a1":13.333333333333334,"e6a15cfd-755e-4f05-b47c-e77190473a9b":0,"f0ce34fb-5858-4dac-bd79-d3b020ec4270":0,"fba22e0f-c734-41c0-804a-51ffac08e852":6.666666666666667},"keyword":{"04c58307-939e-481d-b4d7-6579d1607543":8.637301587301586,"097d282b-beed-47c1-9e6f-07255fee1a3a":8.862011599511598,"17d3c566-60ad-491a-b63c-ae7f3b46dd54":9.454365079365077,"269e006a-d493-4ade-be8b-cfc3b56d5752":8.647830687830686,"4d4338a1-d3e7-482a-9f8c-9bd3a4eae9c3":9.50079365079365,"602e89cc-75ec-4d21-925a-39fb38e46877":8.40674603174603,"9683e149-7dd9-40d0-be7c-2bd6303588c4":9.374999999999998,"b857298c-92c9-4f05-a704-3b9fc6be06e3":6.966269841269841,"c0beb0e0-d0a2-4a9e-a99c-39f5e975849e":9.066468253968251,"caa552a1-c1b7-48d6-9d30-046d360f8ce9":9.28611111111111,"d1ba534e-3f80-4366-bb83-be16006f9e18":9.560317460317458,"d75e2955-a86c-44dd-b3e2-37d87559c9a1":0,"e6a15cfd-755e-4f05-b47c-e77190473a9b":7.2678571428571415,"f0ce34fb-5858-4dac-bd79-d3b020ec4270":11.358730158730156,"fba22e0f-c734-41c0-804a-51ffac08e852":8.127857142857142},"topic":["spectrum","network","xg","function","assign"],"offsprings":[]},"a4f95e3a-17b0-46ed-a588-341d2bc53a33":{"authors":["Steven Cameron Woo","Moriyoshi Ohara","Evan Torrie","Jaswinder Pal Singh","Anoop Gupta"],"references":[],"_id":"a4f95e3a-17b0-46ed-a588-341d2bc53a33","abstract":"The SPLASH-2 suite of parallel applications has recently been released to facilitate the study of centralized and distributed shared-address-space multiprocessors. In this context, this paper has two goals. One is to quantitatively characterize the SPLASH-2 programs in terms of fundamental properties and architectural interactions that are important to understand them well. The properties we study include the computational load balance, communication to computation ratio and traffic needs, important working set sizes, and issues related to spatial locality, as well as how these properties scale with problem size and the number of processors. The other, related goal is methodological: to assist people who will use the programs in architectural evaluations to prune the space of application and machine parameters in an informed and meaningful way. For example, by characterizing the working sets of the applications, we describe which operating points in terms of cache size and problem size are representative of realistic situations, which are not, and which re redundant. Using SPLASH-2 as an example, we hope to convey the importance of understanding the interplay of problem size, number of processors, and working sets in designing experiments and interpreting their results.","title":"The SPLASH-2 programs: characterization and methodological considerations","venue":"international symposium on computer architecture","year":1995,"__v":0,"citationCount":2019,"parents":{"040582d2-eff7-444f-8c5d-7c47224f0094":0,"0570eb1e-e66a-480e-923a-a998bf01033e":0,"11541748-93eb-4226-8a50-149dbe70d9d8":23.076923076923077,"11c36e8f-753d-491d-955b-30074419fd08":15.384615384615385,"28b963bc-fb0e-45f4-963a-8004b0e38bf7":0,"4a15d049-0832-405c-9d83-05c519442cc3":15.384615384615385,"4fb5b716-dcd0-4a47-805a-62f8eb427b16":0,"9eca8597-3b27-4286-adf1-bc3eb455b1b6":7.6923076923076925,"9f97be2c-754a-4b86-b240-1c699157b56a":0,"adb36578-4301-4f01-9906-a9efd9e04282":0,"e75f8a85-a079-4e50-9639-47de653f0bcb":15.384615384615385,"e961bcba-fcdd-4d63-8bf2-fa44bddfe015":7.6923076923076925,"e9a84043-8223-424f-a84f-585d441e3038":0},"keyword":{"040582d2-eff7-444f-8c5d-7c47224f0094":9.721706349206348,"0570eb1e-e66a-480e-923a-a998bf01033e":11.035714285714285,"11541748-93eb-4226-8a50-149dbe70d9d8":9.810317460317462,"11c36e8f-753d-491d-955b-30074419fd08":10.597685185185185,"28b963bc-fb0e-45f4-963a-8004b0e38bf7":9.119828042328043,"4a15d049-0832-405c-9d83-05c519442cc3":10.798809523809524,"4fb5b716-dcd0-4a47-805a-62f8eb427b16":7.140873015873016,"9eca8597-3b27-4286-adf1-bc3eb455b1b6":11.157936507936508,"9f97be2c-754a-4b86-b240-1c699157b56a":0,"adb36578-4301-4f01-9906-a9efd9e04282":9.983214285714284,"e75f8a85-a079-4e50-9639-47de653f0bcb":10.219642857142857,"e961bcba-fcdd-4d63-8bf2-fa44bddfe015":6.35515873015873,"e9a84043-8223-424f-a84f-585d441e3038":8.533730158730158},"topic":["size","work","splash2","set","properti"],"groups":[{"authors":["J. Pal Singh","Akhil Gupta","Marc Levoy"],"references":["11c36e8f-753d-491d-955b-30074419fd08","26162728-24a2-4d03-bb17-871f59a2e39c","5954664c-417f-4cc0-a04d-d3e7420934de","73c99500-2324-456d-9044-e6af049127fd","9eaf520d-8c0b-4231-b251-3ce155305b7e","c29bc764-afec-45e7-9367-132a96f87355","e961bcba-fcdd-4d63-8bf2-fa44bddfe015","e9a84043-8223-424f-a84f-585d441e3038"],"_id":"11541748-93eb-4226-8a50-149dbe70d9d8","abstract":"Recently, a new class of scalable, shared-address-space multiprocessors has emerged. Like message-passing machines, these multiprocessors have a distributed interconnection network and physically distributed main memory. However, they provide hardware support for efficient implicit communication through a shared address space, and they automatically exploit temporal locality by caching both local and remote data in a processor's hardware cache. In this article, we show that these architectural characteristics make it much easier to obtain very good speedups on the best known visualization algorithms. Simple and natural parallelizations work very well, the sequential implementations do not have to be fundamentally restructured, and the high degree of temporal locality obviates the need for explicit data distribution and communication management. We demonstrate our claims through parallel versions of three state-of-the-art algorithms: a recent hierarchical radiosity algorithm by Hanrahan et al. (1991), a parallelized ray-casting volume renderer by Levoy (1992), and an optimized ray-tracer by Spach and Pulleyblank (1992). We also discuss a new shear-warp volume rendering algorithm that provides the first demonstration of interactive frame rates for a 256/spl times/256/spl times/256 voxel data set on a general-purpose multiprocessor. >","title":"Parallel visualization algorithms: performance and architectural implications","venue":"IEEE Computer","year":1994,"__v":0,"citationCount":72}],"offsprings":[]},"a524be55-f906-4c4f-afdc-e008dbd15ffc":{"authors":["Algirdas Avizienis","Jean-Claude Laprie","Brian Randell","Carl E. Landwehr"],"references":[],"_id":"a524be55-f906-4c4f-afdc-e008dbd15ffc","abstract":"This paper gives the main definitions relating to dependability, a generic concept including a special case of such attributes as reliability, availability, safety, integrity, maintainability, etc. Security brings in concerns for confidentiality, in addition to availability and integrity. Basic definitions are given first. They are then commented upon, and supplemented by additional definitions, which address the threats to dependability and security (faults, errors, failures), their attributes, and the means for their achievement (fault prevention, fault tolerance, fault removal, fault forecasting). The aim is to explicate a set of general concepts, of relevance across a wide range of situations and, therefore, helping communication and cooperation among a number of scientific and technical communities, including ones that are concentrating on particular types of system, of system failures, or of causes of system failures.","title":"Basic concepts and taxonomy of dependable and secure computing","venue":"IEEE Transactions on Dependable and Secure Computing","year":2004,"__v":0,"citationCount":1665,"parents":{"02302d84-381f-4154-9b10-ee216d7ebd20":0,"0c68a0b9-1ec4-455a-83c2-a38a2fcf7903":4,"26198970-1705-4d72-a622-c619c0b2a78e":0,"2b0f5d32-7ffa-48c2-9331-3be27c0ac1c4":0,"2e8eca55-6084-4d83-987d-4e367d96d1f6":4,"31916a3f-5247-44ae-b32c-fdc7cab42f16":4,"532a17ef-5f37-4ead-9f4d-2fd31369966e":0,"6b261cc9-d6be-43c4-801c-42c00769e67d":0,"6ce2a644-1c2e-45cb-8453-2c702e9fb06e":0,"74796e03-b980-4eca-8715-04e093f5d41e":4,"7d858c10-2f60-4a71-b51c-be58827083d8":0,"85e8ebf8-9524-4ba6-99b5-a94bbabe5b33":0,"87acf2dc-3c1e-47f8-aa00-3fc0550a6de9":0,"9885d407-ddbb-4dd1-b266-7fac30e358d9":0,"9959d167-0b05-46b9-821b-f686a5c4eb21":4,"9a16d353-cf01-4dc5-853a-defbcfc68c7a":0,"af5536e7-6535-44c8-9c0e-333d36ac65e8":8,"b7175b68-3fd2-47dc-8ab7-d5e955f697bb":0,"b90c5640-8e10-4f65-9193-c28af80f45e2":0,"c4cb5dac-a649-4fee-9609-4afea5f091cc":0,"ca0c5501-5851-4f69-9f86-41deefcdbc8f":4,"cd1585bb-ec76-4598-8efd-dee886bb644b":0,"cf216dbc-d892-4904-bd9a-cf8a50086805":0,"dc0b9ac5-b710-457e-8b54-565935c5632a":8,"f5cdca0e-51a5-4caf-b28c-39c53d947ee9":0},"keyword":{"02302d84-381f-4154-9b10-ee216d7ebd20":11.700343915343916,"0c68a0b9-1ec4-455a-83c2-a38a2fcf7903":9.240396825396825,"26198970-1705-4d72-a622-c619c0b2a78e":0,"2b0f5d32-7ffa-48c2-9331-3be27c0ac1c4":9.899947089947089,"2e8eca55-6084-4d83-987d-4e367d96d1f6":10.470476190476191,"31916a3f-5247-44ae-b32c-fdc7cab42f16":9.722222222222223,"532a17ef-5f37-4ead-9f4d-2fd31369966e":9.575079365079365,"6b261cc9-d6be-43c4-801c-42c00769e67d":11.788888888888888,"6ce2a644-1c2e-45cb-8453-2c702e9fb06e":6.525873015873016,"74796e03-b980-4eca-8715-04e093f5d41e":8.944920634920635,"7d858c10-2f60-4a71-b51c-be58827083d8":9.376984126984125,"85e8ebf8-9524-4ba6-99b5-a94bbabe5b33":11.225714285714286,"87acf2dc-3c1e-47f8-aa00-3fc0550a6de9":10.019206349206348,"9885d407-ddbb-4dd1-b266-7fac30e358d9":11.34063492063492,"9959d167-0b05-46b9-821b-f686a5c4eb21":10.846666666666668,"9a16d353-cf01-4dc5-853a-defbcfc68c7a":10.209047619047618,"af5536e7-6535-44c8-9c0e-333d36ac65e8":11.090661375661375,"b7175b68-3fd2-47dc-8ab7-d5e955f697bb":9.620634920634922,"b90c5640-8e10-4f65-9193-c28af80f45e2":10.31875901875902,"c4cb5dac-a649-4fee-9609-4afea5f091cc":10.095952380952381,"ca0c5501-5851-4f69-9f86-41deefcdbc8f":9.236904761904762,"cd1585bb-ec76-4598-8efd-dee886bb644b":10.707133520074699,"cf216dbc-d892-4904-bd9a-cf8a50086805":9.433015873015872,"dc0b9ac5-b710-457e-8b54-565935c5632a":11.894126984126984,"f5cdca0e-51a5-4caf-b28c-39c53d947ee9":11.353809523809524},"topic":["fault","system","failur","definit","secur"],"offsprings":[]},"a53a3dda-b003-4d5c-96b1-e9afd8e35692":{"authors":["Emmanuel J. Candès","Justin K. Romberg","Terence Tao"],"references":[],"_id":"a53a3dda-b003-4d5c-96b1-e9afd8e35692","abstract":"This paper considers the model problem of reconstructing an object from incomplete frequency samples. Consider a discrete-time signal f/spl isin/C/sup N/ and a randomly chosen set of frequencies /spl Omega/. Is it possible to reconstruct f from the partial knowledge of its Fourier coefficients on the set /spl Omega/? A typical result of this paper is as follows. Suppose that f is a superposition of |T| spikes f(t)=/spl sigma//sub /spl tau//spl isin/T/f(/spl tau/)/spl delta/(t-/spl tau/) obeying |T|/spl les/C/sub M//spl middot/(log N)/sup -1/ /spl middot/ |/spl Omega/| for some constant C/sub M/>0. We do not know the locations of the spikes nor their amplitudes. Then with probability at least 1-O(N/sup -M/), f can be reconstructed exactly as the solution to the /spl lscr//sub 1/ minimization problem. In short, exact recovery may be obtained by solving a convex optimization problem. We give numerical values for C/sub M/ which depend on the desired probability of success. Our result may be interpreted as a novel kind of nonlinear sampling theorem. In effect, it says that any signal made out of |T| spikes may be recovered by convex programming from almost every set of frequencies of size O(|T|/spl middot/logN). Moreover, this is nearly optimal in the sense that any method succeeding with probability 1-O(N/sup -M/) would in general require a number of frequency samples at least proportional to |T|/spl middot/logN. The methodology extends to a variety of other situations and higher dimensions. For example, we show how one can reconstruct a piecewise constant (one- or two-dimensional) object from incomplete frequency samples - provided that the number of jumps (discontinuities) obeys the condition above - by minimizing other convex functionals such as the total variation of f.","title":"Robust uncertainty principles: exact signal reconstruction from highly incomplete frequency information","venue":"IEEE Transactions on Information Theory","year":2006,"__v":0,"citationCount":3800,"parents":{"2d75f21b-8617-4c21-a1bf-467a82458459":0,"4114181f-6f48-4cb6-b6d3-b337515d57f8":11.11111111111111,"449bfdfc-f916-422c-ac0d-ebfdd2ab773a":33.33333333333333,"53c1d13a-863d-4db2-bc77-bbc7f8a45fa8":0,"5eb8608d-d0a1-4f14-af98-8a26bab51fae":0,"7291a02d-1d94-48b7-a4e2-35406c0e52ad":0,"87a4faed-c1a5-45c8-81eb-3bf19ae19011":22.22222222222222,"d2104367-6389-4b06-8dbe-bab7e05b903b":0,"f11bfae2-e272-4acc-b231-a9619f1e4d6c":0},"keyword":{"2d75f21b-8617-4c21-a1bf-467a82458459":7.875685425685427,"4114181f-6f48-4cb6-b6d3-b337515d57f8":7.636601731601732,"449bfdfc-f916-422c-ac0d-ebfdd2ab773a":11.119444444444444,"53c1d13a-863d-4db2-bc77-bbc7f8a45fa8":8.2003367003367,"5eb8608d-d0a1-4f14-af98-8a26bab51fae":8.959478114478113,"7291a02d-1d94-48b7-a4e2-35406c0e52ad":11.259700577200576,"87a4faed-c1a5-45c8-81eb-3bf19ae19011":11.198468013468013,"d2104367-6389-4b06-8dbe-bab7e05b903b":9.118787878787879,"f11bfae2-e272-4acc-b231-a9619f1e4d6c":11.440892255892253},"topic":["spl","frequenc","sampl","reconstruct","spike"],"groups":[{"authors":["Joel A. Tropp"],"references":["38c8c7a7-e6f4-4f59-91de-76d74e801418","4114181f-6f48-4cb6-b6d3-b337515d57f8","5d887090-2713-49d5-9f0e-8ecbc57d6862","87a4faed-c1a5-45c8-81eb-3bf19ae19011","913bb59b-71fe-4bd1-8f97-1c974a93575c","bb3c38fa-c2b0-4d4f-8c9d-ca1884343474","cb17c20e-e335-43dc-b2ae-350e43b74faa","dbb8606e-3419-45c0-84ee-8872c86fdcd8","eacf08f1-1e8b-44ee-90b5-234724ae8355","f11bfae2-e272-4acc-b231-a9619f1e4d6c"],"_id":"449bfdfc-f916-422c-ac0d-ebfdd2ab773a","abstract":"This article presents new results on using a greedy algorithm, orthogonal matching pursuit (OMP), to solve the sparse approximation problem over redundant dictionaries. It provides a sufficient condition under which both OMP and Donoho's basis pursuit (BP) paradigm can recover the optimal representation of an exactly sparse signal. It leverages this theory to show that both OMP and BP succeed for every sparse input signal from a wide class of dictionaries. These quasi-incoherent dictionaries offer a natural generalization of incoherent dictionaries, and the cumulative coherence function is introduced to quantify the level of incoherence. This analysis unifies all the recent results on BP and extends them to OMP. Furthermore, the paper develops a sufficient condition under which OMP can identify atoms from an optimal approximation of a nonsparse signal. From there, it argues that OMP is an approximation algorithm for the sparse problem over a quasi-incoherent dictionary. That is, for every input signal, OMP calculates a sparse approximant whose error is only a small factor worse than the minimal error that can be attained with the same number of terms.","title":"Greed is good: algorithmic results for sparse approximation","venue":"IEEE Transactions on Information Theory","year":2004,"__v":0,"citationCount":1107},{"authors":["Rémi Gribonval","Morten Nielsen"],"references":["4114181f-6f48-4cb6-b6d3-b337515d57f8","f11bfae2-e272-4acc-b231-a9619f1e4d6c"],"_id":"87a4faed-c1a5-45c8-81eb-3bf19ae19011","abstract":"The purpose of this correspondence is to generalize a result by Donoho and Huo and Elad and Bruckstein on sparse representations of signals in a union of two orthonormal bases for R/sup N/. We consider general (redundant) dictionaries for R/sup N/, and derive sufficient conditions for having unique sparse representations of signals in such dictionaries. The special case where the dictionary is given by the union of L/spl ges/2 orthonormal bases for R/sup N/ is studied in more detail. In particular, it is proved that the result of Donoho and Huo, concerning the replacement of the /spl lscr//sup 0/ optimization problem with a linear programming problem when searching for sparse representations, has an analog for dictionaries that may be highly redundant.","title":"Sparse representations in unions of bases","venue":"IEEE Transactions on Information Theory","year":2003,"__v":0,"citationCount":284}],"offsprings":["69b9ef96-11d5-49b0-9ae3-492763e02ca8","6ff01654-66d1-49c7-b526-1c8ed7fa893a","71a18de9-e543-4337-ab7a-3db31d9f8c00","a81d35e6-d5cd-4eef-9144-b0755ef268d1","e537d143-155e-4ca0-8ae8-66b777a77fea","f56b877b-4060-4754-b303-e8140968544c"]},"a81d35e6-d5cd-4eef-9144-b0755ef268d1":{"authors":["Emmanuel J. Candès","Xiaodong Li","Yi Ma","John Wright"],"references":["05bbaec3-7980-4941-8638-2bbfa4ac8be0","109367fa-db04-4db0-8777-d6ca7e9e78fd","177b7083-bfca-472b-833a-515f1ad77735","5e8b0e8a-d687-4333-bfe9-73b4c1bebde5","a53a3dda-b003-4d5c-96b1-e9afd8e35692"],"_id":"a81d35e6-d5cd-4eef-9144-b0755ef268d1","abstract":"This article is about a curious phenomenon. Suppose we have a data matrix, which is the superposition of a low-rank component and a sparse component. Can we recover each component individuallyq We prove that under some suitable assumptions, it is possible to recover both the low-rank and the sparse components  exactly  by solving a very convenient convex program called  Principal Component Pursuit ; among all feasible decompositions, simply minimize a weighted combination of the nuclear norm and of the e 1  norm. This suggests the possibility of a principled approach to robust principal component analysis since our methodology and results assert that one can recover the principal components of a data matrix even though a positive fraction of its entries are arbitrarily corrupted. This extends to the situation where a fraction of the entries are missing as well. We discuss an algorithm for solving this optimization problem, and present applications in the area of video surveillance, where our methodology allows for the detection of objects in a cluttered background, and in the area of face recognition, where it offers a principled way of removing shadows and specularities in images of faces.","title":"Robust principal component analysis","venue":"Journal of the ACM","year":2011,"__v":0,"citationCount":1522,"parents":{"05bbaec3-7980-4941-8638-2bbfa4ac8be0":0,"109367fa-db04-4db0-8777-d6ca7e9e78fd":0,"177b7083-bfca-472b-833a-515f1ad77735":0,"1bfaea19-9ccb-4a78-9572-773eca9143be":22.58064516129032,"2684fb9b-5b4d-400c-91fb-27fd5c083879":0,"3f90046c-1c24-4a11-abc5-831c4d30f660":3.225806451612903,"420acfbb-a503-4d34-915d-354a3048b83e":0,"471026f6-8a3b-425e-a838-671d6f86bac2":19.35483870967742,"4a3fc8b1-1a6d-45c4-b378-845b711fe5b3":35.483870967741936,"4c9f2bac-2f23-4170-a0f1-a3001f63a7b9":6.451612903225806,"545f7483-37e3-4014-b4ff-e92b8201840e":25.806451612903224,"5c6cd648-83ab-41c1-9bb7-95d4040a412a":0,"5cc51c6b-04cc-4d21-b78c-c291f776b859":29.03225806451613,"5e8b0e8a-d687-4333-bfe9-73b4c1bebde5":0,"74b9aa5f-e5e4-4789-a5ca-254030320eca":12.903225806451612,"76c13b0f-60d1-48c8-bc29-2c0bbf25b8cc":0,"79985a61-c881-41b2-8a18-effeeeeb3760":3.225806451612903,"814abbf2-665f-48e9-a94a-07e511b4f2aa":19.35483870967742,"a1fc9ff4-c101-4416-9a16-7390a5166074":22.58064516129032,"a4019710-0953-42a8-af18-703ce48a8423":19.35483870967742,"a53a3dda-b003-4d5c-96b1-e9afd8e35692":0,"a5d31c22-bdb4-4f0d-ab7b-4af2a8e37b9c":9.67741935483871,"ac14afe6-de4d-4056-b2ac-0f6e36f369a2":0,"b7380d17-27b2-48ea-a8dd-37e63c9952c9":0,"b9a62f13-fc35-4716-add9-9e33a8a488a4":25.806451612903224,"c19c233b-6b1d-40a9-b553-a6efbe11932c":3.225806451612903,"de4fea1d-2739-4e0f-b5a3-08f0df58d787":0,"eb84d73f-402b-40a6-84c5-0f2a81d6bb9c":25.806451612903224,"ebfca554-7a3c-4597-954b-07336a2e3030":0,"f0c0249b-4cef-436c-904f-1d70ef15d300":0,"fe4934dc-beb3-4c3d-a1e5-0fb8c8bfbcc0":0},"keyword":{"05bbaec3-7980-4941-8638-2bbfa4ac8be0":8.384190069190069,"109367fa-db04-4db0-8777-d6ca7e9e78fd":11.155502645502647,"177b7083-bfca-472b-833a-515f1ad77735":7.671428571428572,"1bfaea19-9ccb-4a78-9572-773eca9143be":9.65907407407407,"2684fb9b-5b4d-400c-91fb-27fd5c083879":9.108253968253969,"3f90046c-1c24-4a11-abc5-831c4d30f660":11.839920634920636,"420acfbb-a503-4d34-915d-354a3048b83e":10.489047619047616,"471026f6-8a3b-425e-a838-671d6f86bac2":10.283734968734969,"4a3fc8b1-1a6d-45c4-b378-845b711fe5b3":9.395582010582011,"4c9f2bac-2f23-4170-a0f1-a3001f63a7b9":6.537380952380951,"545f7483-37e3-4014-b4ff-e92b8201840e":5.824603174603174,"5c6cd648-83ab-41c1-9bb7-95d4040a412a":10.941904761904762,"5cc51c6b-04cc-4d21-b78c-c291f776b859":10.324232804232803,"5e8b0e8a-d687-4333-bfe9-73b4c1bebde5":7.957539682539683,"74b9aa5f-e5e4-4789-a5ca-254030320eca":12.600401635401635,"76c13b0f-60d1-48c8-bc29-2c0bbf25b8cc":9.831854256854257,"79985a61-c881-41b2-8a18-effeeeeb3760":11.424814814814813,"814abbf2-665f-48e9-a94a-07e511b4f2aa":8.141349206349206,"a1fc9ff4-c101-4416-9a16-7390a5166074":9.115714285714285,"a4019710-0953-42a8-af18-703ce48a8423":10.283734968734969,"a53a3dda-b003-4d5c-96b1-e9afd8e35692":11.35569264069264,"a5d31c22-bdb4-4f0d-ab7b-4af2a8e37b9c":9.40674603174603,"ac14afe6-de4d-4056-b2ac-0f6e36f369a2":8.938055555555556,"b7380d17-27b2-48ea-a8dd-37e63c9952c9":9.455555555555554,"b9a62f13-fc35-4716-add9-9e33a8a488a4":9.303968253968254,"c19c233b-6b1d-40a9-b553-a6efbe11932c":0,"de4fea1d-2739-4e0f-b5a3-08f0df58d787":9.358333333333333,"eb84d73f-402b-40a6-84c5-0f2a81d6bb9c":9.395,"ebfca554-7a3c-4597-954b-07336a2e3030":7.480714285714287,"f0c0249b-4cef-436c-904f-1d70ef15d300":9.654179894179896,"fe4934dc-beb3-4c3d-a1e5-0fb8c8bfbcc0":11.211803751803751},"topic":["compon","recov","princip","spars","solv"],"groups":[{"authors":["Zhang Liu","Lieven Vandenberghe"],"references":["0cbc071c-5319-4ce2-8504-93222e61bc64","1bfaea19-9ccb-4a78-9572-773eca9143be","4333a219-e7e1-4196-8a9c-897cc6931372","47ab195c-7144-4aee-a3db-1950d2ce38b9","4c9f2bac-2f23-4170-a0f1-a3001f63a7b9","4ffb137f-5775-4668-93c2-5d42456ac598","57ce9c76-0cc6-470a-917b-dbedab0d601c","5cc51c6b-04cc-4d21-b78c-c291f776b859","6ff01654-66d1-49c7-b526-1c8ed7fa893a","738c462f-8706-4a45-9af2-a8e1724ceac1","7aaa5e58-0206-4abf-8c16-59be096a0a16","814abbf2-665f-48e9-a94a-07e511b4f2aa","8d9c707b-3a9f-40a1-94c2-435b9ca69b73","905461e4-643b-4da0-a669-f52318b9e126","9a994ade-1d0f-49d5-baea-367cb5865993","a1fc9ff4-c101-4416-9a16-7390a5166074","a4db7563-dac1-4045-b85b-76090466fd12","a53a3dda-b003-4d5c-96b1-e9afd8e35692","adc31a96-1f8e-4793-8ee9-ecef04a16ac6","b5218d8c-32f4-4255-9726-87fc750fa3da","c78d10a2-3325-40cb-a3e3-7d79ff443f31","de4fea1d-2739-4e0f-b5a3-08f0df58d787","f0c0249b-4cef-436c-904f-1d70ef15d300","f16bd8e8-b1cf-41e3-8709-62da17caa0c6","f56b877b-4060-4754-b303-e8140968544c"],"_id":"b9a62f13-fc35-4716-add9-9e33a8a488a4","abstract":"The nuclear norm (sum of singular values) of a matrix is often used in convex heuristics for rank minimization problems in control, signal processing, and statistics. Such heuristics can be viewed as extensions of $\\ell_1$-norm minimization techniques for cardinality minimization and sparse signal estimation. In this paper we consider the problem of minimizing the nuclear norm of an affine matrix-valued function. This problem can be formulated as a semidefinite program, but the reformulation requires large auxiliary matrix variables, and is expensive to solve by general-purpose interior-point solvers. We show that problem structure in the semidefinite programming formulation can be exploited to develop more efficient implementations of interior-point methods. In the fast implementation, the cost per iteration is reduced to a quartic function of the problem dimensions and is comparable to the cost of solving the approximation problem in the Frobenius norm. In the second part of the paper, the nuclear norm approximation algorithm is applied to system identification. A variant of a simple subspace algorithm is presented in which low-rank matrix approximations are computed via nuclear norm minimization instead of the singular value decomposition. This has the important advantage of preserving linear matrix structure in the low-rank approximation. The method is shown to perform well on publicly available benchmark data.","title":"Interior-Point Method for Nuclear Norm Approximation with Application to System Identification","venue":"SIAM Journal on Matrix Analysis and Applications","year":2009,"__v":0,"citationCount":144},{"authors":["David J. Gross"],"references":["02d872a3-ac2c-453d-9237-5f694f09c0ee","3a31de66-0555-4af7-9690-b84960fbebad","471026f6-8a3b-425e-a838-671d6f86bac2","4c9f2bac-2f23-4170-a0f1-a3001f63a7b9","545f7483-37e3-4014-b4ff-e92b8201840e","71a18de9-e543-4337-ab7a-3db31d9f8c00","814abbf2-665f-48e9-a94a-07e511b4f2aa","81591b41-b15b-4fe9-9790-372b7f0cc220","821ae036-30f1-46a2-ab58-bee4e28ff24c","8376c98d-36c9-4af9-ac91-5648bf23c55f","a1fc9ff4-c101-4416-9a16-7390a5166074","a4019710-0953-42a8-af18-703ce48a8423","a53a3dda-b003-4d5c-96b1-e9afd8e35692","a5d31c22-bdb4-4f0d-ab7b-4af2a8e37b9c","f0f58cbd-f57a-464a-946e-a99413397439","f56b877b-4060-4754-b303-e8140968544c"],"_id":"eb84d73f-402b-40a6-84c5-0f2a81d6bb9c","abstract":"We present novel techniques for analyzing the problem of low-rank matrix recovery. The methods are both considerably simpler and more general than previous approaches. It is shown that an unknown matrix of rank can be efficiently reconstructed from only randomly sampled expansion coefficients with respect to any given matrix basis. The number quantifies the “degree of incoherence” between the unknown matrix and the basis. Existing work concentrated mostly on the problem of “matrix completion” where one aims to recover a low-rank matrix from randomly selected matrix elements. Our result covers this situation as a special case. The proof consists of a series of relatively elementary steps, which stands in contrast to the highly involved methods previously employed to obtain comparable results. In cases where bounds had been known before, our estimates are slightly tighter. We discuss operator bases which are incoherent to all low-rank matrices simultaneously. For these bases, we show that randomly sampled expansion coefficients suffice to recover any low-rank matrix with high probability. The latter bound is tight up to multiplicative constants.","title":"Recovering Low-Rank Matrices From Few Coefficients in Any Basis","venue":"IEEE Transactions on Information Theory","year":2011,"__v":0,"citationCount":192},{"authors":["Donald Goldfarb","Shiqian Ma"],"references":["0dc16a9e-1123-4e2c-9345-528dfe1343a3","1760c31c-bb1f-4423-be5c-54855cf82498","1bfaea19-9ccb-4a78-9572-773eca9143be","3f90046c-1c24-4a11-abc5-831c4d30f660","471026f6-8a3b-425e-a838-671d6f86bac2","4c9f2bac-2f23-4170-a0f1-a3001f63a7b9","4ffb137f-5775-4668-93c2-5d42456ac598","552bfdc4-a46f-438c-99dc-12a949f69547","5cc51c6b-04cc-4d21-b78c-c291f776b859","716ac33f-7206-4836-bc47-ccdf485749d0","75fdce7f-366a-427a-a0ba-0400c26feabf","814abbf2-665f-48e9-a94a-07e511b4f2aa","86e83387-985d-4169-be03-5fe7a5f52785","9a33ddde-c275-4997-b037-0b48648bb1f7","a1fc9ff4-c101-4416-9a16-7390a5166074","a4019710-0953-42a8-af18-703ce48a8423","a53a3dda-b003-4d5c-96b1-e9afd8e35692","a5d31c22-bdb4-4f0d-ab7b-4af2a8e37b9c","adc31a96-1f8e-4793-8ee9-ecef04a16ac6","b35f5dee-2877-4574-ab66-09120eb66d21","b96b3626-20c3-4001-a366-ce1ac8055d66","b9a62f13-fc35-4716-add9-9e33a8a488a4","d35a46c7-6300-4c7c-82e1-1fe48d522ca6","da3591c1-6a8f-4ac3-8481-b1fe147deb85","e7af7694-28e7-4b6a-b23c-b7f4f8647ed2","e8f276d4-6f13-468f-902f-ee1e270fa75e","f56b877b-4060-4754-b303-e8140968544c","f68f3200-b814-4fe1-9093-10ac7507f816"],"_id":"4a3fc8b1-1a6d-45c4-b378-845b711fe5b3","abstract":"The matrix rank minimization problem has applications in many fields, such as system identification, optimal control, low-dimensional embedding, etc. As this problem is NP-hard in general, its convex relaxation, the nuclear norm minimization problem, is often solved instead. Recently, Ma, Goldfarb and Chen proposed a fixed-point continuation algorithm for solving the nuclear norm minimization problem (Math. Program., doi: 10.1007/s10107-009-0306-5, 2009). By incorporating an approximate singular value decomposition technique in this algorithm, the solution to the matrix rank minimization problem is usually obtained. In this paper, we study the convergence/recoverability properties of the fixed-point continuation algorithm and its variants for matrix rank minimization. Heuristics for determining the rank of the matrix when its true rank is not known are also proposed. Some of these algorithms are closely related to greedy algorithms in compressed sensing. Numerical results for these algorithms for solving affinely constrained matrix rank minimization problems are reported.","title":"Convergence of Fixed-Point Continuation Algorithms for Matrix Rank Minimization","venue":"Foundations of Computational Mathematics","year":2011,"__v":0,"citationCount":46},{"authors":["Shiqian Ma","Donald Goldfarb","Lifeng Chen"],"references":["044074e8-31cb-44b6-ab74-fa21c93dd14b","0dc16a9e-1123-4e2c-9345-528dfe1343a3","1976db1f-ba16-433b-b918-c04a50293153","1bfaea19-9ccb-4a78-9572-773eca9143be","3f90046c-1c24-4a11-abc5-831c4d30f660","471026f6-8a3b-425e-a838-671d6f86bac2","48a1dbbd-b496-4b37-b3ba-db144c654d23","4a3fc8b1-1a6d-45c4-b378-845b711fe5b3","4ffb137f-5775-4668-93c2-5d42456ac598","5c6cd648-83ab-41c1-9bb7-95d4040a412a","5f8a39bc-731a-45d6-a6bd-d7f51a53a374","62bc7cc3-76a2-4bed-acad-c4811bb00b33","7292eb6c-3d6a-4a17-b837-c1d74e849044","75fdce7f-366a-427a-a0ba-0400c26feabf","814abbf2-665f-48e9-a94a-07e511b4f2aa","8f3ab1c2-e5ce-4e83-8a2f-1aa66dfb28c1","9a33ddde-c275-4997-b037-0b48648bb1f7","9e79e32e-e99f-4ad8-9351-4e901fdabe2a","a53a3dda-b003-4d5c-96b1-e9afd8e35692","a5d31c22-bdb4-4f0d-ab7b-4af2a8e37b9c","adc31a96-1f8e-4793-8ee9-ecef04a16ac6","b9a62f13-fc35-4716-add9-9e33a8a488a4","c78d10a2-3325-40cb-a3e3-7d79ff443f31","c79fa5f7-bd43-4fb6-97cc-e1c56e044062","e7af7694-28e7-4b6a-b23c-b7f4f8647ed2","e8f276d4-6f13-468f-902f-ee1e270fa75e","f56b877b-4060-4754-b303-e8140968544c","fc2aafdb-950b-4031-a9e2-46952518a135"],"_id":"5cc51c6b-04cc-4d21-b78c-c291f776b859","abstract":"The linearly constrained matrix rank minimization problem is widely applicable in many fields such as control, signal processing and system identification. The tightest convex relaxation of this problem is the linearly constrained nuclear norm minimization. Although the latter can be cast as a semidefinite programming problem, such an approach is computationally expensive to solve when the matrices are large. In this paper, we propose fixed point and Bregman iterative algorithms for solving the nuclear norm minimization problem and prove convergence of the first of these algorithms. By using a homotopy approach together with an approximate singular value decomposition procedure, we get a very fast, robust and powerful algorithm, which we call FPCA (Fixed Point Continuation with Approximate SVD), that can solve very large matrix rank minimization problems (the code can be downloaded from http://www.columbia.edu/~sm2756/FPCA.htmfor non-commercial use). Our numerical results on randomly generated and real matrix completion problems demonstrate that this algorithm is much faster and provides much better recoverability than semidefinite programming solvers such as SDPT3. For example, our algorithm can recover 1000 × 1000 matrices of rank 50 with a relative error of 10−5 in about 3 min by sampling only 20% of the elements. We know of no other method that achieves as good recoverability. Numerical experiments on online recommendation, DNA microarray data set and image inpainting problems demonstrate the effectiveness of our algorithms.","title":"Fixed point and Bregman iterative methods for matrix rank minimization","venue":"Mathematical Programming","year":2011,"__v":0,"citationCount":321},{"authors":["Jian-Feng Cai","Emmanuel J. Candès","Zuowei Shen"],"references":["050cbd64-68da-407e-b0bd-fe0475566079","0834e24b-d006-4cd1-bedb-c4542d8ec9af","1e46bd4c-ad0c-4742-b42c-b876161d9c97","28d67152-f6b8-4a58-824a-3487117377bd","2aef9638-6d52-405a-9cdd-75f603abab91","31c883b9-75b1-4ea6-b9e2-776cc33a287f","38711beb-3c11-4f5f-8f61-3530053446e3","3f90046c-1c24-4a11-abc5-831c4d30f660","4f599fcf-c0fa-4e08-96e6-8c4bdcb008fc","509ba4be-958f-4496-afc2-bbd0e59b50c3","52e55346-2fb4-45a8-9e50-db06f3343982","5712f1a3-57dc-4c76-9666-0d8bd2d6aca9","5c6cd648-83ab-41c1-9bb7-95d4040a412a","5cc51c6b-04cc-4d21-b78c-c291f776b859","6a52f241-7fd1-4a1d-b2eb-c0f8d3d5148d","6b6db1a1-9404-43a6-bdb9-a56b5639558e","6ff01654-66d1-49c7-b526-1c8ed7fa893a","71a18de9-e543-4337-ab7a-3db31d9f8c00","77b5a86e-011e-4752-a159-c1b11802cbef","7b71d9cc-4158-414d-98cc-5ff251ac5748","905461e4-643b-4da0-a669-f52318b9e126","9431eeba-3bc3-4e65-bf62-639f7a6306de","a1fc9ff4-c101-4416-9a16-7390a5166074","a53a3dda-b003-4d5c-96b1-e9afd8e35692","a5d31c22-bdb4-4f0d-ab7b-4af2a8e37b9c","b2425f3b-5b13-483a-8fd1-fdf13fa238fd","b9a0bb2b-abb9-4512-b104-c75ff0a248bd","b9a62f13-fc35-4716-add9-9e33a8a488a4","e9c7e788-78d7-41f1-bf29-fa85bd7dc137","f56b877b-4060-4754-b303-e8140968544c"],"_id":"1bfaea19-9ccb-4a78-9572-773eca9143be","abstract":"This paper introduces a novel algorithm to approximate the matrix with minimum nuclear norm among all matrices obeying a set of convex constraints. This problem may be understood as the convex relaxation of a rank minimization problem and arises in many important applications as in the task of recovering a large matrix from a small subset of its entries (the famous Netflix problem). Off-the-shelf algorithms such as interior point methods are not directly amenable to large problems of this kind with over a million unknown entries. This paper develops a simple first-order and easy-to-implement algorithm that is extremely efficient at addressing problems in which the optimal solution has low rank. The algorithm is iterative, produces a sequence of matrices $\\{\\boldsymbol{X}^k,\\boldsymbol{Y}^k\\}$, and at each step mainly performs a soft-thresholding operation on the singular values of the matrix $\\boldsymbol{Y}^k$. There are two remarkable features making this attractive for low-rank matrix completion problems. The first is that the soft-thresholding operation is applied to a sparse matrix; the second is that the rank of the iterates $\\{\\boldsymbol{X}^k\\}$ is empirically nondecreasing. Both these facts allow the algorithm to make use of very minimal storage space and keep the computational cost of each iteration low. On the theoretical side, we provide a convergence analysis showing that the sequence of iterates converges. On the practical side, we provide numerical examples in which $1,000\\times1,000$ matrices are recovered in less than a minute on a modest desktop computer. We also demonstrate that our approach is amenable to very large scale problems by recovering matrices of rank about 10 with nearly a billion unknowns from just about 0.4% of their sampled entries. Our methods are connected with the recent literature on linearized Bregman iterations for $\\ell_1$ minimization, and we develop a framework in which one can understand these algorithms in terms of well-known Lagrange multiplier algorithms.","title":"A Singular Value Thresholding Algorithm for Matrix Completion","venue":"Siam Journal on Optimization","year":2010,"__v":0,"citationCount":1233}],"offsprings":[]},"abf7f290-5b74-4b9a-9661-a1af46b0083a":{"authors":["Nick McKeown","Thomas E. Anderson","Hari Balakrishnan","Guru M. Parulkar","Larry L. Peterson","Jennifer Rexford","Scott Shenker","Jonathan S. Turner"],"references":[],"_id":"abf7f290-5b74-4b9a-9661-a1af46b0083a","abstract":"This whitepaper proposes OpenFlow: a way for researchers to run experimental protocols in the networks they use every day. OpenFlow is based on an Ethernet switch, with an internal flow-table, and a standardized interface to add and remove flow entries. Our goal is to encourage networking vendors to add OpenFlow to their switch products for deployment in college campus backbones and wiring closets. We believe that OpenFlow is a pragmatic compromise: on one hand, it allows researchers to run experiments on heterogeneous switches in a uniform way at line-rate and with high port-density; while on the other hand, vendors do not need to expose the internal workings of their switches. In addition to allowing researchers to evaluate their ideas in real-world traffic settings, OpenFlow could serve as a useful campus component in proposed large-scale testbeds like GENI. Two buildings at Stanford University will soon run OpenFlow networks, using commercial Ethernet switches and routers. We will work to encourage deployment at other schools; and We encourage you to consider deploying OpenFlow in your university network too","title":"OpenFlow: enabling innovation in campus networks","venue":"acm special interest group on data communication","year":2008,"__v":0,"citationCount":2359,"parents":{"2305da97-ee8b-4023-9f94-c0a9ea7e580f":20,"5477474b-c802-4696-b2e5-57a8f6bd14ae":0,"5ad83b9b-6ae3-42ea-9b5f-e2fabe669c74":0,"72db976e-5886-4750-a650-0ef209e3a51c":20,"cdadb79e-6542-4947-8b3b-e4a0341e8389":20},"keyword":{"2305da97-ee8b-4023-9f94-c0a9ea7e580f":11.188624338624336,"5477474b-c802-4696-b2e5-57a8f6bd14ae":11.507142857142858,"5ad83b9b-6ae3-42ea-9b5f-e2fabe669c74":9.478373015873014,"72db976e-5886-4750-a650-0ef209e3a51c":0,"cdadb79e-6542-4947-8b3b-e4a0341e8389":10.731349206349204},"topic":["openflow","switch","run","research","network"],"offsprings":[]},"ad6cebdf-e58f-4be5-8c0a-74b48fbd43ce":{"authors":["Barbara Zitová","Jan Flusser"],"references":[],"_id":"ad6cebdf-e58f-4be5-8c0a-74b48fbd43ce","abstract":"This paper aims to present a review of recent as well as classic image registration methods. Image registration is the process of overlaying images (two or more) of the same scene taken at different times, from different viewpoints, and/or by different sensors. The registration geometrically align two images (the reference and sensed images). The reviewed approaches are classified according to their nature (areabased and feature-based) and according to four basic steps of image registration procedure: feature detection, feature matching, mapping function design, and image transformation and resampling. Main contributions, advantages, and drawbacks of the methods are mentioned in the paper. Problematic issues of image registration and outlook for the future research are discussed too. The major goal of the paper is to provide a comprehensive reference source for the researchers involved in image registration, regardless of particular application areas. q 2003 Elsevier B.V. All rights reserved.","title":"Image registration methods: a survey","venue":"Image and Vision Computing","year":2003,"__v":0,"citationCount":1532,"parents":{"0047b2cf-bd19-4f8a-979e-ef5cc5b4a43f":11.11111111111111,"00e6f131-0fce-4b6f-8500-c1d701bb3cf8":0,"017537f0-82e6-424c-b169-b2bad005b40f":0,"04e444f3-d7b6-4925-b3dc-0b2d3b0e88a7":0.7936507936507936,"05ef5747-ce10-4431-999b-c60a70ee3d29":1.5873015873015872,"0684a9f8-cf32-4161-ac7b-fb45a6c1329b":0.7936507936507936,"0a590588-1790-4632-bdd7-544399784bf4":1.5873015873015872,"0b8a2709-0063-4669-9f4b-0ddc97727562":1.5873015873015872,"0c4f8382-a5df-4110-a416-b0287722979f":0,"0cc4bb9c-9d49-4ad2-bf8e-39e827ef70d6":2.380952380952381,"0d66d358-49fa-4d9c-931e-98c828313246":0,"0ebd3b62-4acd-431b-b1ea-4e22edfd55cc":3.1746031746031744,"116a9789-2756-4743-820c-2b1048e8d092":0,"1191781d-1d00-4773-8f32-fd1dbe3c76c8":0,"17923047-53b6-499d-b1e1-7c1f6c78fefd":1.5873015873015872,"1b60e8ab-841b-42d9-8747-952d6fe04f24":4.761904761904762,"20ee86b8-fc94-4647-9a98-d0f174557f54":0,"2186fc1e-e677-4eb1-93b0-1eb39fde4856":0,"23daf90f-0393-4382-a964-b3c8b0bcb99e":5.555555555555555,"264ad184-d48d-48da-ba36-54568ca48045":1.5873015873015872,"287aeb9e-8e91-4b3e-b207-60917b05150b":3.1746031746031744,"2ac0c715-c7c1-43ae-8b28-b765021021e5":2.380952380952381,"2c30e243-29ff-458c-b1d7-1ed8cb145243":1.5873015873015872,"32bff9f0-5248-4d25-afc2-ff9ebab45916":1.5873015873015872,"348a7b30-4698-46d8-8f9d-e1382e72a236":2.380952380952381,"36d50089-f4d1-4bfb-b9f3-65a0087c9039":0,"379eef1d-ed43-4149-96ff-20ffb6d55fd3":0,"3bd92880-c1bf-47bd-a02d-2a8aa86b2fb2":0.7936507936507936,"422ee3ff-9012-4a99-a3a8-494027f4d0cd":0,"42848e46-661a-4652-9ab1-6d02244fc5ff":0.7936507936507936,"46755cfc-8bff-4d16-b80d-0ca30762a641":3.968253968253968,"4b211ac5-d024-4b43-a8af-08919c7b17be":2.380952380952381,"4b78a087-39d4-435e-8830-2074224f82e8":0,"4bf46fff-1afd-4747-a549-b2d65f01423f":0,"4bf62224-a6e0-4632-9949-c5c72f3ed19e":0,"51ff14b3-bfe6-4d61-8f0b-153c93b925d3":1.5873015873015872,"549ecc91-a3d6-4686-be6f-6e98ce9759f1":0,"57c6fa5a-01c5-49ce-9178-1343109df1c2":1.5873015873015872,"592e4083-7c59-4820-a364-fc635b9494d4":0.7936507936507936,"59e7526c-01d2-4977-96ee-7a7e86b6fa2d":1.5873015873015872,"5fd60a58-0688-4ce0-bebc-a08f3cc604dd":6.349206349206349,"60faa10c-1da8-4fb0-a5b1-54bc1e3f34c8":1.5873015873015872,"6286926a-208e-4090-b387-98f291237857":1.5873015873015872,"636fa7ed-a670-42d3-a700-3a0bd0dc78a7":3.1746031746031744,"63dbad19-24d8-4646-8e6a-65d85a5c2af3":0,"64cf8e78-632f-4abf-9944-c78bd46eb2bc":0.7936507936507936,"669474d9-ef19-4790-927d-91448d3faf37":0,"683b99c4-f8e4-441d-9fb9-8875ed563b37":2.380952380952381,"689572f0-88f0-4a60-874e-f070c159cae6":0,"6a8fd03b-3f6d-4c5f-9977-a9aac31717cb":5.555555555555555,"6d86ad90-fe62-40e5-b917-7e3f31350523":0,"723c19d5-eb5e-41b9-b2fa-e4d881f0fb55":1.5873015873015872,"731d5963-c13e-46a9-b205-10460967c9c3":0,"79242994-7a27-4153-bae4-650220483c61":2.380952380952381,"794d43f7-a434-4c8e-ba51-c6883befb942":3.968253968253968,"7e8d94aa-96fa-409f-bbed-cf9d71dd5f90":2.380952380952381,"7eccd04d-fdac-4282-96f7-87b2b1d3398e":3.968253968253968,"7fe5bc1a-2470-4804-9d3f-6ad316a2d322":2.380952380952381,"8053df14-c7c4-4fe2-ae35-41f73ff80bb6":0.7936507936507936,"82f76e26-1453-4d3e-aff7-29a77189d862":3.968253968253968,"8517c98e-52b3-4048-80a1-75a4e8e7c059":0.7936507936507936,"897b0d64-16f8-4abe-b3a6-19cad2753449":0.7936507936507936,"899bcfac-02df-4fa1-a6ee-b1c493a32471":3.1746031746031744,"8a183167-cad2-4728-a800-5da01be5e8b4":1.5873015873015872,"8aaefebb-d82b-420f-b96f-4dcb850ea076":2.380952380952381,"8b79771e-3cc8-4159-9c27-8cb76cbb4703":4.761904761904762,"8b8328e4-f7a3-469e-8cb4-c6df53055725":3.968253968253968,"8f428609-07da-4bf1-af24-de19b252939b":0.7936507936507936,"906071a4-b40f-4134-a5a9-44e574b89dfe":0.7936507936507936,"93644ab0-4880-407e-8c8e-6a15a2646f8b":1.5873015873015872,"94c5c94e-66aa-4abb-8faf-a60352167973":0.7936507936507936,"97f96017-c14c-47cb-aa45-7b841a83e999":4.761904761904762,"981f51e9-f0ed-4afe-9aee-f4dd5d1bdab5":0.7936507936507936,"9854aaf2-e92e-4750-a0a0-df28c8cc2920":2.380952380952381,"9d8876fa-b1ef-4246-86f4-f25a6f22e142":5.555555555555555,"9ead3a0d-e5a6-48b7-94a4-cadfb40354aa":0,"9fd0ae42-56b0-48f0-838d-d95aea9c515a":1.5873015873015872,"a873cd95-581a-4557-b0ff-35f6cdfef390":6.349206349206349,"af7e4274-dbfc-4fd3-a59c-35f56b2cd7cc":1.5873015873015872,"b14ef753-c23d-43b5-a53b-e357331894be":1.5873015873015872,"b156dfb5-1b83-4f78-9c7b-29d6fb55306d":2.380952380952381,"b2489a29-e0b8-4d7f-b0ef-918e2e867646":3.968253968253968,"b2d10062-0eeb-408b-81ee-e33518aef2b7":0,"b50d3401-c4fc-479e-89ff-197c0a129dbf":2.380952380952381,"b659275f-35a2-4c08-8f50-523d0c41cb84":0,"b72b736e-e3bc-4682-b1ab-0b10ab1f92d2":2.380952380952381,"bba2be41-4759-49a2-9977-c8bac4787b2e":0.7936507936507936,"bbf9758e-0e75-41ef-91cf-83f1b0ad86ff":1.5873015873015872,"c0988a9e-f60e-4752-b105-577d20a4d955":3.1746031746031744,"c2c6631f-4caa-4970-a466-338667651fdb":0,"c3dfdc78-c969-4e59-890a-683649a8cce3":0,"c47bf62b-df95-47ce-9253-22b860b36250":1.5873015873015872,"c9f94862-0337-406f-ac1c-366d57fa31de":2.380952380952381,"ccf6b35e-60e1-4fd7-8593-f27be272e428":0.7936507936507936,"cd0c16a9-9964-4fb4-b361-da6d3ca97d37":3.1746031746031744,"d0d439b4-e1c1-4cc3-88cc-190ca24fcdd5":3.968253968253968,"d1c8cad6-9ebf-49f5-ab10-a06d27bc9ad3":1.5873015873015872,"d8a179ed-1db4-47af-845a-d23e6fff293b":0,"d9752a5a-1603-45cc-9a21-7997750d429f":0,"d98d389d-ca5f-43f4-b9bc-7dbea42e718e":1.5873015873015872,"da65a641-6bbe-4d12-8aad-e3badcd8f620":2.380952380952381,"dc21a1a0-1a2e-47a0-8841-be68ad7a0062":2.380952380952381,"e0fb91e5-b91f-482c-9327-1fa269b65c55":0,"e328ff33-5c62-4aa9-bfc2-a9dbc6e05359":4.761904761904762,"e3817f44-d249-447d-ad6b-59f68f4861f9":0.7936507936507936,"e44dc0fd-dcf7-43b4-8f27-4cea26c6611c":0,"e7f58691-1615-46be-887b-bdc064b05c24":5.555555555555555,"e88fef1b-f9c6-4f0b-bc14-952a3e39ebd7":5.555555555555555,"ea8949fc-04e5-449e-b083-f6b35762a562":0,"ebb5b586-9d4f-4f9f-a532-7028b960a9bb":1.5873015873015872,"ef53977d-8d52-4925-a8d9-a5fcd8b05085":0.7936507936507936,"efd6e955-2273-4be7-90c6-f078fd4dffc3":0,"f0744bfb-0134-44cb-bf92-cce68ab5e9c3":3.968253968253968,"f6eddac7-0e14-4d73-87b5-edfe83800b87":0.7936507936507936,"f7aa3fde-047a-4f34-acbe-ce37e82cbd92":2.380952380952381,"f8cad8aa-bd27-48fa-94a2-b6cddd32a3cd":3.1746031746031744,"f8fe376d-dd06-4474-a948-d5c3296e6eae":3.968253968253968,"f9362a6b-b8a3-40c1-9f86-bd160e63458b":0.7936507936507936,"f97e9acb-667f-460d-bb6d-72747badcef2":0.7936507936507936,"f9b24819-0c71-486b-ad05-4e293c8337b0":2.380952380952381,"fb194489-3dea-4020-ab41-3114dc632995":0,"fbeec176-d8ca-4700-9ad9-484d78f2a609":0,"fd6d4d38-f6df-4c33-9bae-8e83be87e5c0":3.1746031746031744,"fdb37059-2b78-4e6d-81e7-ae788014db5e":0,"ff637848-06e3-41aa-bb97-544f55f4469f":2.380952380952381,"ffeaf676-f3c2-4a93-a262-68774488656e":0},"keyword":{"0047b2cf-bd19-4f8a-979e-ef5cc5b4a43f":12.434523809523807,"00e6f131-0fce-4b6f-8500-c1d701bb3cf8":11.539682539682541,"017537f0-82e6-424c-b169-b2bad005b40f":9.074801587301588,"04e444f3-d7b6-4925-b3dc-0b2d3b0e88a7":11.404841269841272,"05ef5747-ce10-4431-999b-c60a70ee3d29":11.01468253968254,"0684a9f8-cf32-4161-ac7b-fb45a6c1329b":8.874074074074073,"0a590588-1790-4632-bdd7-544399784bf4":0,"0b8a2709-0063-4669-9f4b-0ddc97727562":11.948333333333332,"0c4f8382-a5df-4110-a416-b0287722979f":12.093650793650795,"0cc4bb9c-9d49-4ad2-bf8e-39e827ef70d6":11.319841269841268,"0d66d358-49fa-4d9c-931e-98c828313246":10.909920634920637,"0ebd3b62-4acd-431b-b1ea-4e22edfd55cc":11.877645502645501,"116a9789-2756-4743-820c-2b1048e8d092":11.688095238095237,"1191781d-1d00-4773-8f32-fd1dbe3c76c8":9.749603174603175,"17923047-53b6-499d-b1e1-7c1f6c78fefd":9.508333333333333,"1b60e8ab-841b-42d9-8747-952d6fe04f24":13.287698412698413,"20ee86b8-fc94-4647-9a98-d0f174557f54":12.219841269841272,"2186fc1e-e677-4eb1-93b0-1eb39fde4856":10.021428571428574,"23daf90f-0393-4382-a964-b3c8b0bcb99e":10.63984126984127,"264ad184-d48d-48da-ba36-54568ca48045":11.755714285714285,"287aeb9e-8e91-4b3e-b207-60917b05150b":10.106150793650794,"2ac0c715-c7c1-43ae-8b28-b765021021e5":10.048174603174601,"2c30e243-29ff-458c-b1d7-1ed8cb145243":11.174444444444447,"32bff9f0-5248-4d25-afc2-ff9ebab45916":10.85304232804233,"348a7b30-4698-46d8-8f9d-e1382e72a236":9.427380952380952,"36d50089-f4d1-4bfb-b9f3-65a0087c9039":7.616428571428571,"379eef1d-ed43-4149-96ff-20ffb6d55fd3":10.894246031746032,"3bd92880-c1bf-47bd-a02d-2a8aa86b2fb2":10.441071428571428,"422ee3ff-9012-4a99-a3a8-494027f4d0cd":10.63611111111111,"42848e46-661a-4652-9ab1-6d02244fc5ff":10.10820105820106,"46755cfc-8bff-4d16-b80d-0ca30762a641":12.836984126984124,"4b211ac5-d024-4b43-a8af-08919c7b17be":9.85410052910053,"4b78a087-39d4-435e-8830-2074224f82e8":11.840502645502646,"4bf46fff-1afd-4747-a549-b2d65f01423f":10.138492063492063,"4bf62224-a6e0-4632-9949-c5c72f3ed19e":11.85531746031746,"51ff14b3-bfe6-4d61-8f0b-153c93b925d3":9.480555555555556,"549ecc91-a3d6-4686-be6f-6e98ce9759f1":10.29351851851852,"57c6fa5a-01c5-49ce-9178-1343109df1c2":11.81706349206349,"592e4083-7c59-4820-a364-fc635b9494d4":10.970634920634918,"59e7526c-01d2-4977-96ee-7a7e86b6fa2d":10.560357142857141,"5fd60a58-0688-4ce0-bebc-a08f3cc604dd":10.319047619047621,"60faa10c-1da8-4fb0-a5b1-54bc1e3f34c8":8.831349206349207,"6286926a-208e-4090-b387-98f291237857":10.444999999999999,"636fa7ed-a670-42d3-a700-3a0bd0dc78a7":9.940873015873017,"63dbad19-24d8-4646-8e6a-65d85a5c2af3":10.994215969215967,"64cf8e78-632f-4abf-9944-c78bd46eb2bc":9.794629629629629,"669474d9-ef19-4790-927d-91448d3faf37":12.852380952380951,"683b99c4-f8e4-441d-9fb9-8875ed563b37":11.453333333333333,"689572f0-88f0-4a60-874e-f070c159cae6":8.631904761904762,"6a8fd03b-3f6d-4c5f-9977-a9aac31717cb":10.004365079365076,"6d86ad90-fe62-40e5-b917-7e3f31350523":11.737857142857141,"723c19d5-eb5e-41b9-b2fa-e4d881f0fb55":12.872936507936505,"731d5963-c13e-46a9-b205-10460967c9c3":10.40320105820106,"79242994-7a27-4153-bae4-650220483c61":12.519642857142856,"794d43f7-a434-4c8e-ba51-c6883befb942":12.153439153439155,"7e8d94aa-96fa-409f-bbed-cf9d71dd5f90":10.752380952380953,"7eccd04d-fdac-4282-96f7-87b2b1d3398e":11.800079365079363,"7fe5bc1a-2470-4804-9d3f-6ad316a2d322":9.558201058201059,"8053df14-c7c4-4fe2-ae35-41f73ff80bb6":13.350555555555555,"82f76e26-1453-4d3e-aff7-29a77189d862":10.6,"8517c98e-52b3-4048-80a1-75a4e8e7c059":8.969920634920637,"897b0d64-16f8-4abe-b3a6-19cad2753449":12.07010582010582,"899bcfac-02df-4fa1-a6ee-b1c493a32471":9.762301587301588,"8a183167-cad2-4728-a800-5da01be5e8b4":11.039682539682538,"8aaefebb-d82b-420f-b96f-4dcb850ea076":11.325396825396828,"8b79771e-3cc8-4159-9c27-8cb76cbb4703":10.979761904761906,"8b8328e4-f7a3-469e-8cb4-c6df53055725":10.422777777777776,"8f428609-07da-4bf1-af24-de19b252939b":11.130555555555555,"906071a4-b40f-4134-a5a9-44e574b89dfe":0,"93644ab0-4880-407e-8c8e-6a15a2646f8b":10.362089947089947,"94c5c94e-66aa-4abb-8faf-a60352167973":0,"97f96017-c14c-47cb-aa45-7b841a83e999":12.157142857142857,"981f51e9-f0ed-4afe-9aee-f4dd5d1bdab5":10.752142857142859,"9854aaf2-e92e-4750-a0a0-df28c8cc2920":11.428809523809525,"9d8876fa-b1ef-4246-86f4-f25a6f22e142":11.027116402116404,"9ead3a0d-e5a6-48b7-94a4-cadfb40354aa":11.425820105820108,"9fd0ae42-56b0-48f0-838d-d95aea9c515a":11.481507936507937,"a873cd95-581a-4557-b0ff-35f6cdfef390":11.909999999999998,"af7e4274-dbfc-4fd3-a59c-35f56b2cd7cc":0,"b14ef753-c23d-43b5-a53b-e357331894be":9.496428571428572,"b156dfb5-1b83-4f78-9c7b-29d6fb55306d":10.611269841269841,"b2489a29-e0b8-4d7f-b0ef-918e2e867646":13.54126984126984,"b2d10062-0eeb-408b-81ee-e33518aef2b7":13.499603174603173,"b50d3401-c4fc-479e-89ff-197c0a129dbf":10.268253968253967,"b659275f-35a2-4c08-8f50-523d0c41cb84":12.941375661375663,"b72b736e-e3bc-4682-b1ab-0b10ab1f92d2":0,"bba2be41-4759-49a2-9977-c8bac4787b2e":12.564563492063492,"bbf9758e-0e75-41ef-91cf-83f1b0ad86ff":12.160634920634921,"c0988a9e-f60e-4752-b105-577d20a4d955":11.773968253968254,"c2c6631f-4caa-4970-a466-338667651fdb":0,"c3dfdc78-c969-4e59-890a-683649a8cce3":11.908888888888887,"c47bf62b-df95-47ce-9253-22b860b36250":12.176428571428575,"c9f94862-0337-406f-ac1c-366d57fa31de":9.920396825396827,"ccf6b35e-60e1-4fd7-8593-f27be272e428":11.523015873015874,"cd0c16a9-9964-4fb4-b361-da6d3ca97d37":11.195899470899473,"d0d439b4-e1c1-4cc3-88cc-190ca24fcdd5":10.003968253968255,"d1c8cad6-9ebf-49f5-ab10-a06d27bc9ad3":12.076150793650795,"d8a179ed-1db4-47af-845a-d23e6fff293b":10.255523088023086,"d9752a5a-1603-45cc-9a21-7997750d429f":11.147486772486774,"d98d389d-ca5f-43f4-b9bc-7dbea42e718e":11.327579365079366,"da65a641-6bbe-4d12-8aad-e3badcd8f620":10.862698412698412,"dc21a1a0-1a2e-47a0-8841-be68ad7a0062":12.73690476190476,"e0fb91e5-b91f-482c-9327-1fa269b65c55":11.319404761904762,"e328ff33-5c62-4aa9-bfc2-a9dbc6e05359":11.75952380952381,"e3817f44-d249-447d-ad6b-59f68f4861f9":11.824312169312172,"e44dc0fd-dcf7-43b4-8f27-4cea26c6611c":9.128968253968253,"e7f58691-1615-46be-887b-bdc064b05c24":9.881904761904764,"e88fef1b-f9c6-4f0b-bc14-952a3e39ebd7":11.122619047619047,"ea8949fc-04e5-449e-b083-f6b35762a562":11.083597883597882,"ebb5b586-9d4f-4f9f-a532-7028b960a9bb":12.360952380952382,"ef53977d-8d52-4925-a8d9-a5fcd8b05085":8.888023088023088,"efd6e955-2273-4be7-90c6-f078fd4dffc3":10.141137566137564,"f0744bfb-0134-44cb-bf92-cce68ab5e9c3":10.198677248677248,"f6eddac7-0e14-4d73-87b5-edfe83800b87":11.953730158730158,"f7aa3fde-047a-4f34-acbe-ce37e82cbd92":11.839947089947087,"f8cad8aa-bd27-48fa-94a2-b6cddd32a3cd":9.421587301587302,"f8fe376d-dd06-4474-a948-d5c3296e6eae":10.401984126984129,"f9362a6b-b8a3-40c1-9f86-bd160e63458b":8.795436507936508,"f97e9acb-667f-460d-bb6d-72747badcef2":12.456706349206353,"f9b24819-0c71-486b-ad05-4e293c8337b0":8.338492063492064,"fb194489-3dea-4020-ab41-3114dc632995":8.81126984126984,"fbeec176-d8ca-4700-9ad9-484d78f2a609":8.499603174603175,"fd6d4d38-f6df-4c33-9bae-8e83be87e5c0":11.5765873015873,"fdb37059-2b78-4e6d-81e7-ae788014db5e":9.71047619047619,"ff637848-06e3-41aa-bb97-544f55f4469f":0,"ffeaf676-f3c2-4a93-a262-68774488656e":10.309920634920635},"topic":["imag","registr","paper","review","research"],"offsprings":[]},"adf6fdf9-01a0-4051-9d99-965f4a5baa4d":{"authors":["Piotr Indyk","Rajeev Motwani"],"references":[],"_id":"adf6fdf9-01a0-4051-9d99-965f4a5baa4d","abstract":"We present two algorithms for the approximate nearest neighbor problem in high-dimensional spaces. For data sets of size n living in R d , the algorithms require space that is only polynomial in n and d, while achieving query times that are sub-linear in n and polynomial in d. We also show applications to other high-dimensional geometric problems, such as the approximate minimum spanning tree. The article is based on the material from the authors' STOC'98 and FOCS'01 papers. It unifies, generalizes and simplifies the results from those papers.","title":"Approximate nearest neighbors: towards removing the curse of dimensionality","venue":"symposium on the theory of computing","year":1998,"__v":0,"citationCount":1547,"parents":{"04b85a51-0611-4690-be84-9ac7bb80ddd4":0,"07c804bf-b60d-4b5d-b004-8f4652e7d81b":7.317073170731707,"0d41d9b5-6e7d-476e-a484-36758a6b209a":7.317073170731707,"0f094852-0668-4dfe-92cc-ae5659ffc1d9":36.58536585365854,"105edb54-d48b-4470-a4dc-528270ee4c4a":9.75609756097561,"17f01f85-4909-41b7-bafd-88939c01894a":4.878048780487805,"1bb7e651-6703-413c-b8d1-10f8e8867205":4.878048780487805,"25f49f47-6576-4c22-af2c-c3b7435e05b9":4.878048780487805,"2e0c0709-138c-461c-af4f-64037b7feee4":26.82926829268293,"3c281c4e-8302-4c37-96d7-1e615167c5f5":0,"43dfd110-6a4d-4463-838a-dad26db1b846":4.878048780487805,"4ca9b504-fdf7-4963-89a1-170608086f35":2.4390243902439024,"5437c0a0-8f20-49c3-86e5-9d860f3e4f04":34.146341463414636,"5581c810-1b67-4d28-be77-d82af988d09b":0,"5880d47f-8b99-416d-a743-28d6b49f7ba9":0,"5ce1553b-2b02-4469-ae72-04a31418fc52":9.75609756097561,"5fec7ec9-a6ad-4793-89a7-f834305b4e4f":0,"6d927d56-fab4-4058-9282-bff49da68895":14.634146341463413,"71e7d436-a839-4f9d-ad70-d9faf15e8034":0,"760e3094-e883-4439-9704-b7bb7b7cbec2":12.195121951219512,"768eea6d-8e82-4bbf-8bdd-1f2338ded29f":4.878048780487805,"833da8cb-e068-44eb-955c-48b52adabfae":4.878048780487805,"8a4a40c5-5169-4b74-9a4c-69a3dc2d3ac1":2.4390243902439024,"90c94ae6-0039-4446-b2c6-4ac59a11a258":7.317073170731707,"93f7f432-84f0-4878-bcce-fdd4e367f926":0,"9a33ddde-c275-4997-b037-0b48648bb1f7":2.4390243902439024,"a6d1807f-6c63-470e-8767-31a9f14f3962":12.195121951219512,"ac14afe6-de4d-4056-b2ac-0f6e36f369a2":2.4390243902439024,"af6ea43b-eb0f-4aa5-aeb3-e6e435e43263":0,"bbf5e5eb-cd31-45b3-bfd9-d2fa07d4bd8b":0,"bc46277f-2a3c-466e-a646-1a5394ace50d":0,"be23df9d-eee9-4db4-8e88-55c3b9dd0481":0,"be9cbf3c-2975-4226-b6b9-3d4b4ebe8a66":0,"bf132fef-c091-4f7e-a850-22b83ff7a9e2":0,"ceb2285b-cf69-4c11-811d-93c273dc2ddd":0,"d20995f6-529c-41c6-b75e-a169b005fb5c":4.878048780487805,"d6ffd0e7-61aa-4dea-9fe0-4345e2382e96":0,"e75d8e62-a86d-4241-953f-1b315005d920":0,"e97d9c05-854e-4bd6-9301-11affc0d103f":0,"e9b4081d-d54d-4bfd-8c83-238d1be7401d":0,"f6272ea9-0360-47ed-90a5-651ea958143f":14.634146341463413},"keyword":{"04b85a51-0611-4690-be84-9ac7bb80ddd4":14.263348595848594,"07c804bf-b60d-4b5d-b004-8f4652e7d81b":0,"0d41d9b5-6e7d-476e-a484-36758a6b209a":6.8952808302808295,"0f094852-0668-4dfe-92cc-ae5659ffc1d9":0,"105edb54-d48b-4470-a4dc-528270ee4c4a":9.269261294261293,"17f01f85-4909-41b7-bafd-88939c01894a":9.629188034188035,"1bb7e651-6703-413c-b8d1-10f8e8867205":12.33866910866911,"25f49f47-6576-4c22-af2c-c3b7435e05b9":0,"2e0c0709-138c-461c-af4f-64037b7feee4":0,"3c281c4e-8302-4c37-96d7-1e615167c5f5":9.739713064713065,"43dfd110-6a4d-4463-838a-dad26db1b846":9.662429792429792,"4ca9b504-fdf7-4963-89a1-170608086f35":11.872313797313797,"5437c0a0-8f20-49c3-86e5-9d860f3e4f04":10.801739926739927,"5581c810-1b67-4d28-be77-d82af988d09b":12.157197802197803,"5880d47f-8b99-416d-a743-28d6b49f7ba9":11.368833943833943,"5ce1553b-2b02-4469-ae72-04a31418fc52":11.237057387057385,"5fec7ec9-a6ad-4793-89a7-f834305b4e4f":0,"6d927d56-fab4-4058-9282-bff49da68895":0,"71e7d436-a839-4f9d-ad70-d9faf15e8034":11.233050468050466,"760e3094-e883-4439-9704-b7bb7b7cbec2":0,"768eea6d-8e82-4bbf-8bdd-1f2338ded29f":0,"833da8cb-e068-44eb-955c-48b52adabfae":8.112490842490843,"8a4a40c5-5169-4b74-9a4c-69a3dc2d3ac1":11.490149572649573,"90c94ae6-0039-4446-b2c6-4ac59a11a258":11.061642246642249,"93f7f432-84f0-4878-bcce-fdd4e367f926":8.546013431013431,"9a33ddde-c275-4997-b037-0b48648bb1f7":12.804652014652014,"a6d1807f-6c63-470e-8767-31a9f14f3962":10.47435286935287,"ac14afe6-de4d-4056-b2ac-0f6e36f369a2":8.146953601953602,"af6ea43b-eb0f-4aa5-aeb3-e6e435e43263":11.180596255596255,"bbf5e5eb-cd31-45b3-bfd9-d2fa07d4bd8b":0,"bc46277f-2a3c-466e-a646-1a5394ace50d":11.467210012210012,"be23df9d-eee9-4db4-8e88-55c3b9dd0481":8.603949938949938,"be9cbf3c-2975-4226-b6b9-3d4b4ebe8a66":11.745604395604392,"bf132fef-c091-4f7e-a850-22b83ff7a9e2":12.470604395604395,"ceb2285b-cf69-4c11-811d-93c273dc2ddd":0,"d20995f6-529c-41c6-b75e-a169b005fb5c":0,"d6ffd0e7-61aa-4dea-9fe0-4345e2382e96":0,"e75d8e62-a86d-4241-953f-1b315005d920":0,"e97d9c05-854e-4bd6-9301-11affc0d103f":9.997673992673993,"e9b4081d-d54d-4bfd-8c83-238d1be7401d":8.246404151404152,"f6272ea9-0360-47ed-90a5-651ea958143f":0},"topic":["space","problem","polynomi","paper","highdimension"],"groups":[{"authors":["Sunil Arya","David M. Mount","Nathan S. Netanyahu","Ruth Silverman","Angela Y. Wu"],"references":["0d41d9b5-6e7d-476e-a484-36758a6b209a","0f094852-0668-4dfe-92cc-ae5659ffc1d9","12196e53-1567-458b-9d49-6a66fd6e6adf","1333cbbd-dbc1-457f-a16d-bd057c347156","1c7f6b4c-ea89-45d4-9778-8d64987f8a0f","2713ce7e-3ad8-4654-90db-2a035d588713","413a659f-2cb8-4ae5-89b5-5f773685c82f","4279b898-2775-4f22-bdf8-f289d54b4867","43dfd110-6a4d-4463-838a-dad26db1b846","485d6dc2-0ef4-4955-875b-c245a131a6a9","4ca9b504-fdf7-4963-89a1-170608086f35","510eec1d-f82c-4b19-b116-b8fd4c66531a","5660105d-43ae-4091-a6b7-380dc22cd9b5","5880d47f-8b99-416d-a743-28d6b49f7ba9","593a7087-a716-40ee-af9f-caa3d41a1b6e","5ce1553b-2b02-4469-ae72-04a31418fc52","6b32b11e-238f-4500-b513-ccd53424637a","71e7d436-a839-4f9d-ad70-d9faf15e8034","768eea6d-8e82-4bbf-8bdd-1f2338ded29f","76c004a0-487a-4313-a344-fc4a299e4b66","7850841f-2874-48cc-aa4e-83ca63f77aeb","7de3ee18-6bc8-42b2-98d0-745e02c372c1","8b4e6725-0e70-4801-9ce5-78fab6158fbc","8fda0651-1e04-4439-afb0-e8e7e5ae8072","a0304326-321c-49c0-843e-6ad5ea9f5815","a6d1807f-6c63-470e-8767-31a9f14f3962","aa5afbbc-13b9-4685-bc36-5f7f06d8d2a4","adf6fdf9-01a0-4051-9d99-965f4a5baa4d","af6ea43b-eb0f-4aa5-aeb3-e6e435e43263","b546dd1a-7e2d-4527-ba3c-2e6ce5e0a405","b7e8c571-d956-4072-b028-754dc40a0e56","be9cbf3c-2975-4226-b6b9-3d4b4ebe8a66","c8dad09e-e7b4-4a2d-b4b3-0ea3cd49ac52","ce05fc9f-0abd-4843-8d77-ceb4ce9a6ebf","d11d6520-e64b-4a9b-abc9-3729ab6ca8e7","d20995f6-529c-41c6-b75e-a169b005fb5c","d6ffd0e7-61aa-4dea-9fe0-4345e2382e96","da4e248d-7eec-4400-a0e7-97ab5d4b3698","ea3dd2d7-2031-4938-b8b9-495eba8886a8","f6272ea9-0360-47ed-90a5-651ea958143f"],"_id":"5437c0a0-8f20-49c3-86e5-9d860f3e4f04","abstract":"Consider a set of  S  of  n  data points  in real  d -dimensional space, R d , where distances are measured using any Minkowski metric. In nearest neighbor searching, we preprocess  S  into a data structure, so that given any query point  q    ∈   R d , is the closest point of S to  q  can be reported quickly. Given any positive real e, data point  p  is a (1 +e)- approximate nearest neighbor  of  q  if its distance from  q  is within a factor of (1 + e) of the distance to the true nearest neighbor. We show that it is possible to preprocess a    set of  n  points in     R d  in  O(dn  log  n ) time and  O(dn)  space, so that given a query point   q     ∈   R d , and e > 0, a (1 + e)-approximate nearest neighbor of  q  can be computed in  O ( c   d , e  log  n ) time, where  c d,e  ≤ d      1 + 6d/ e     ; d  is a factor depending only on dimension and e. In general, we show that given an integer  k  ≥ 1, (1 + e)-approximations  to the   k  nearest neighbors of  q  can  be computed in additional  O(kd  log  n ) time.","title":"An optimal algorithm for approximate nearest neighbor searching fixed dimensions","venue":"Journal of the ACM","year":1998,"__v":0,"citationCount":928},{"authors":["Jon M. Kleinberg"],"references":["0d41d9b5-6e7d-476e-a484-36758a6b209a","29f196b0-3df4-43c9-bf33-6411f5adf879","2a399365-c617-4f8c-a748-678cef034014","4279b898-2775-4f22-bdf8-f289d54b4867","5437c0a0-8f20-49c3-86e5-9d860f3e4f04","56a41f3c-7b53-43c4-a7f9-dfdcdb51de7c","5880d47f-8b99-416d-a743-28d6b49f7ba9","5b0cbce2-e9cb-42c2-bb0a-f3636fbf139a","71e7d436-a839-4f9d-ad70-d9faf15e8034","768eea6d-8e82-4bbf-8bdd-1f2338ded29f","7fb4d286-ab8c-44ab-97fc-4d8995ae7858","90c94ae6-0039-4446-b2c6-4ac59a11a258","93f7f432-84f0-4878-bcce-fdd4e367f926","ac14afe6-de4d-4056-b2ac-0f6e36f369a2","af6ea43b-eb0f-4aa5-aeb3-e6e435e43263","bbf5e5eb-cd31-45b3-bfd9-d2fa07d4bd8b","be9cbf3c-2975-4226-b6b9-3d4b4ebe8a66","bf132fef-c091-4f7e-a850-22b83ff7a9e2","ce0f46fe-395e-411f-b73b-4c769b05828a","d6ffd0e7-61aa-4dea-9fe0-4345e2382e96","ddaddf72-e527-455d-8a1b-67553b867fb2","e97d9c05-854e-4bd6-9301-11affc0d103f","f6272ea9-0360-47ed-90a5-651ea958143f"],"_id":"0f094852-0668-4dfe-92cc-ae5659ffc1d9","title":"Two algorithms for nearest-neighbor search in high dimensions","venue":"symposium on the theory of computing","year":1997,"abstract":"","__v":0,"citationCount":168}],"offsprings":["6c38b3b4-7562-493d-a40c-fe70abf039a7"]},"af5d0939-0728-4464-a59d-a1b68dec5533":{"authors":["Tracy Camp","Jeff Boleng","Vanessa Davies"],"references":[],"_id":"af5d0939-0728-4464-a59d-a1b68dec5533","abstract":"In the performance evaluation of a protocol for an ad hoc network, the protocol should be tested under realistic conditions including, but not limited to, a sensible transmission range, limited buffer space for the storage of messages, representative data traffic models, and realistic movements of the mobile users (i.e., a mobility model). This paper is a survey of mobility models that are used in the simulations of ad hoc networks. We describe several mobility models that represent mobile nodes whose movements are independent of each other (i.e., entity mobility models) and several mobility models that represent mobile nodes whose movements are dependent on each other (i.e., group mobility models). The goal of this paper is to present a number of mobility models in order to offer researchers more informed choices when they are deciding upon a mobility model to use in their performance evaluations. Lastly, we present simulation results that illustrate the importance of choosing a mobility model in the simulation of an ad hoc network protocol. Specifically, we illustrate how the performance results of an ad hoc network protocol drastically change as a result of changing the mobility model simulated.","title":"A Survey of Mobility Models for Ad Hoc Network Research","venue":"communications and mobile computing","year":2002,"__v":0,"citationCount":1866,"parents":{"03865aaf-4fb9-4abd-ab46-9f79334f6c6a":0,"2395ff67-d7e9-4f98-b67d-eccb7cebce82":7.6923076923076925,"3de86707-67a7-4dd9-b97a-e814a998c99e":0,"6b2fb7b2-0612-4cf2-b55c-b7d2dc710357":0,"91e9ffba-7445-46fd-8813-f9f96e2a0bbb":7.6923076923076925,"9ac93557-c501-4560-b309-f34d6dfcc17b":7.6923076923076925,"9b14bb43-59dc-4fd7-a139-daf74c84a4a4":0,"9f79006e-f0b8-4795-9f71-f6331d80ed95":0,"a81646c5-ac23-47c1-8202-2fc9e14e1bc6":0,"bb903371-03e6-43d5-83a0-d82c103cfaa8":0,"ccf71166-6a65-499a-8373-6dcf9a332efe":7.6923076923076925,"d0b9428d-dfb9-477c-ac05-5844e4a0ad19":0,"e3af190a-754d-415d-a32d-f1d9999c599f":0},"keyword":{"03865aaf-4fb9-4abd-ab46-9f79334f6c6a":10.071190476190475,"2395ff67-d7e9-4f98-b67d-eccb7cebce82":9.576785714285712,"3de86707-67a7-4dd9-b97a-e814a998c99e":11.47558201058201,"6b2fb7b2-0612-4cf2-b55c-b7d2dc710357":9.993571428571428,"91e9ffba-7445-46fd-8813-f9f96e2a0bbb":10.098624338624337,"9ac93557-c501-4560-b309-f34d6dfcc17b":11.344603174603172,"9b14bb43-59dc-4fd7-a139-daf74c84a4a4":9.782222222222222,"9f79006e-f0b8-4795-9f71-f6331d80ed95":0,"a81646c5-ac23-47c1-8202-2fc9e14e1bc6":6.395634920634919,"bb903371-03e6-43d5-83a0-d82c103cfaa8":10.44457671957672,"ccf71166-6a65-499a-8373-6dcf9a332efe":8.179761904761905,"d0b9428d-dfb9-477c-ac05-5844e4a0ad19":11.762738095238095,"e3af190a-754d-415d-a32d-f1d9999c599f":0},"topic":["mobil","model","simul","protocol","network"],"offsprings":[]},"af647f42-0b8d-480b-a36e-c7f351a95473":{"authors":["Nitesh V. Chawla","Kevin W. Bowyer","Lawrence O. Hall","W. Philip Kegelmeyer"],"references":[],"_id":"af647f42-0b8d-480b-a36e-c7f351a95473","abstract":"An approach to the construction of classifiers from imbalanced datasets is described. A dataset is imbalanced if the classification categories are not approximately equally represented. Often real-world data sets are predominately composed of \"normal\" examples with only a small percentage of \"abnormal\" or \"interesting\" examples. It is also the case that the cost of misclassifying an abnormal (interesting) example as a normal example is often much higher than the cost of the reverse error. Under-sampling of the majority (normal) class has been proposed as a good means of increasing the sensitivity of a classifier to the minority class. This paper shows that a combination of our method of oversampling the minority (abnormal)cla ss and under-sampling the majority (normal) class can achieve better classifier performance (in ROC space)tha n only under-sampling the majority class. This paper also shows that a combination of our method of over-sampling the minority class and under-sampling the majority class can achieve better classifier performance (in ROC space)t han varying the loss ratios in Ripper or class priors in Naive Bayes. Our method of over-sampling the minority class involves creating synthetic minority class examples. Experiments are performed using C4.5, Ripper and a Naive Bayes classifier. The method is evaluated using the area under the Receiver Operating Characteristic curve (AUC)and the ROC convex hull strategy.","title":"SMOTE: synthetic minority over-sampling technique","venue":"Journal of Artificial Intelligence Research","year":2002,"__v":0,"citationCount":1659,"parents":{"0483f49f-2737-491d-9353-8ceeb8e2d788":47.368421052631575,"39bab7c4-e376-44a7-bd6f-deaa1b7e1264":5.263157894736842,"44b54aab-e9a0-423c-aa2b-698f78731fe0":0,"4ca9b504-fdf7-4963-89a1-170608086f35":5.263157894736842,"4ec36265-5224-4162-8c3a-aba0d36d2a23":0,"594b4fe8-54fe-4f3c-aa4f-cdec07b9be2b":0,"5e441d2d-7810-42bb-97f5-6f9542d11f0b":10.526315789473683,"62549bc2-e0b3-46e8-8d32-390dded105d5":0,"8b0e25ad-0fce-4658-8407-5dcf7ea742ca":0,"ab5bba40-c975-4ccf-8e51-0747a405ee29":0,"b89566a9-a192-4aa4-8338-5dd99f394454":10.526315789473683,"bcdb7caf-03b7-4b54-a9e6-08e7692c3f01":0,"c87293a3-25f2-473b-9b13-1b37d871c754":5.263157894736842,"d71616bf-e9f8-41a2-9ea4-8fed5241f56b":10.526315789473683,"d8ddd4ae-16ab-4702-b4f5-65aff0e33533":0,"e5519055-460a-4547-952b-d51cdc9202d4":5.263157894736842,"f0f43739-dbde-40c8-8f76-138ef0f19dd7":21.052631578947366,"fa81a051-0f8e-4f10-a172-acd5a8923e23":0,"fb763eac-1e1e-423d-b65f-c9d69565dbff":0},"keyword":{"0483f49f-2737-491d-9353-8ceeb8e2d788":10.527777777777777,"39bab7c4-e376-44a7-bd6f-deaa1b7e1264":0,"44b54aab-e9a0-423c-aa2b-698f78731fe0":8.080555555555556,"4ca9b504-fdf7-4963-89a1-170608086f35":12.494510582010582,"4ec36265-5224-4162-8c3a-aba0d36d2a23":10.982323232323232,"594b4fe8-54fe-4f3c-aa4f-cdec07b9be2b":0,"5e441d2d-7810-42bb-97f5-6f9542d11f0b":8.392777777777777,"62549bc2-e0b3-46e8-8d32-390dded105d5":8.648333333333332,"8b0e25ad-0fce-4658-8407-5dcf7ea742ca":0,"ab5bba40-c975-4ccf-8e51-0747a405ee29":7.437857142857143,"b89566a9-a192-4aa4-8338-5dd99f394454":0,"bcdb7caf-03b7-4b54-a9e6-08e7692c3f01":0,"c87293a3-25f2-473b-9b13-1b37d871c754":10.19240740740741,"d71616bf-e9f8-41a2-9ea4-8fed5241f56b":7.252777777777778,"d8ddd4ae-16ab-4702-b4f5-65aff0e33533":8.100277777777778,"e5519055-460a-4547-952b-d51cdc9202d4":9.317222222222222,"f0f43739-dbde-40c8-8f76-138ef0f19dd7":0,"fa81a051-0f8e-4f10-a172-acd5a8923e23":0,"fb763eac-1e1e-423d-b65f-c9d69565dbff":8.987936507936507},"topic":["class","minor","classifi","undersampl","normal"],"groups":[{"authors":["Foster Provost","Tom Fawcett"],"references":["0f115eea-2272-431f-9f21-6d6789b2bbc9","36313bb8-e0c2-4900-a399-3e772f9f51dc","36338d50-6305-4d9f-9065-cde919913bfb","38500fe9-7c31-4a6a-aa20-fc96325f2946","39bab7c4-e376-44a7-bd6f-deaa1b7e1264","485ea183-f654-46af-a0df-bee30f2d335a","4a277eb6-42cb-4712-9304-71760fc83a02","594b4fe8-54fe-4f3c-aa4f-cdec07b9be2b","62549bc2-e0b3-46e8-8d32-390dded105d5","96d6d9b9-6d69-4c9a-b3f5-c8083966d55c","99586b3c-4b95-41a3-adb9-0853ffd9727d","a575e7f2-cc80-4740-8e08-3dec69d57378","ab5bba40-c975-4ccf-8e51-0747a405ee29","b89566a9-a192-4aa4-8338-5dd99f394454","c146fe70-b870-4da0-b3b9-0a39eaaa6a38","c87293a3-25f2-473b-9b13-1b37d871c754","cf434515-9059-40f5-9d1a-4f6560304c88","d71616bf-e9f8-41a2-9ea4-8fed5241f56b","e3f27652-688a-457b-ad96-07a7e3c05543","e5519055-460a-4547-952b-d51cdc9202d4","e56921ad-e4e0-45e1-bd62-8da8a6db4a66","f0f43739-dbde-40c8-8f76-138ef0f19dd7","f76331c6-7be5-4f61-bbb1-25ea462536e6","fb5fd524-e3c0-4ae1-9767-915e943a0aa0","fcb41378-32f7-4aab-8458-fc5a99d74f92"],"_id":"0483f49f-2737-491d-9353-8ceeb8e2d788","abstract":"In real-world environments it usually is difficult to specify target operating conditions precisely, for example, target misclassification costs. This uncertainty makes building robust classification systems problematic. We show that it is possible to build a hybrid classifier that will perform at least as well as the best available classifier for any target conditions. In some cases, the performance of the hybrid actually can surpass that of the best known classifier. This robust performance extends across a wide variety of comparison frameworks, including the optimization of metrics such as accuracy, expected cost, lift, precision, recall, and workforce utilization. The hybrid also is efficient to build, to store, and to update. The hybrid is based on a method for the comparison of classifier performance that is robust to imprecise class distributions and misclassification costs. The ROC convex hull (ROCCH) method combines techniques from ROC analysis, decision analysis and computational geometry, and adapts them to the particulars of analyzing learned classifiers. The method is efficient and incremental, minimizes the management of classifier performance data, and allows for clear visual comparisons and sensitivity analyses. Finally, we point to empirical evidence that a robust hybrid classifier indeed is needed for many real-world problems.","title":"Robust Classification for Imprecise Environments","venue":"Machine Learning","year":2001,"__v":0,"citationCount":483}],"offsprings":[]},"afc06b7c-7fb3-4f88-942b-3076ed77920e":{"authors":["Chalermek Intanagonwiwat","Ramesh Govindan","Deborah Estrin"],"references":["7c9f8cd8-d0ef-4954-b4db-4a6c803459c2"],"_id":"afc06b7c-7fb3-4f88-942b-3076ed77920e","abstract":"Advances in processor, memory and radio technology will enable small and cheap nodes capable of sensing, communication and computation. Networks of such nodes can coordinate to perform distributed sensing of environmental phenomena. In this paper, we explore the  directed diffusion  paradigm for such coordination. Directed diffusion is datacentric in that all communication is for named data. All nodes in a directed diffusion-based network are application-aware. This enables diffusion to achieve energy savings by selecting empirically good paths and by caching and processing data in-network. We explore and evaluate the use of directed diffusion for a simple remote-surveillance sensor network.","title":"Directed diffusion: a scalable and robust communication paradigm for sensor networks","venue":"acm ieee international conference on mobile computing and networking","year":2000,"__v":0,"citationCount":2463,"parents":{"027291a7-a3fd-4ab0-a81c-6e350f989cc5":0,"19bb3151-ecc6-47d3-a639-476590858f2b":0,"4f60dbc7-9647-4b91-b96f-9f77d07fea7c":0,"55a6413a-4a9c-4e8d-957b-8c1a4e5d5f0b":0,"6500989e-b1e1-4b02-a921-21ec25685b73":8.333333333333332,"7c9f8cd8-d0ef-4954-b4db-4a6c803459c2":8.333333333333332,"83a2eb55-b330-4e0c-8dc9-05e9466d5028":0,"b46af373-5147-4193-9c1d-70adb1f5a527":16.666666666666664,"cae1e692-9d2c-48ca-80da-956c63397390":0,"d563bff2-b63b-470e-a53f-567f8927dbf4":0,"dc0c4146-bf52-4584-85d9-1ea648aecc14":8.333333333333332,"f8ece2c5-c8b1-4a1e-8528-c09357ec23a4":16.666666666666664},"keyword":{"027291a7-a3fd-4ab0-a81c-6e350f989cc5":8.98068783068783,"19bb3151-ecc6-47d3-a639-476590858f2b":0,"4f60dbc7-9647-4b91-b96f-9f77d07fea7c":11.056349206349205,"55a6413a-4a9c-4e8d-957b-8c1a4e5d5f0b":0,"6500989e-b1e1-4b02-a921-21ec25685b73":11.519775132275132,"7c9f8cd8-d0ef-4954-b4db-4a6c803459c2":10.734603174603176,"83a2eb55-b330-4e0c-8dc9-05e9466d5028":9.441931216931216,"b46af373-5147-4193-9c1d-70adb1f5a527":9.662698412698413,"cae1e692-9d2c-48ca-80da-956c63397390":8.163492063492063,"d563bff2-b63b-470e-a53f-567f8927dbf4":6.351587301587302,"dc0c4146-bf52-4584-85d9-1ea648aecc14":10.125793650793652,"f8ece2c5-c8b1-4a1e-8528-c09357ec23a4":0},"topic":["direct","diffus","node","network","sens"],"offsprings":["85352dec-58be-43db-a428-f3f574ff96ec","b5b8132d-0a8c-4e6c-999f-839f0cef48b7","f3267c01-b670-4b7a-a3a5-79088c0d90ab","1ee4b656-7d2c-45e8-b2e8-b5633b992eeb"]},"afd4c865-5c81-424b-82c3-1dcb6150ea6d":{"authors":["Vern Paxson","Sally Floyd"],"references":[],"_id":"afd4c865-5c81-424b-82c3-1dcb6150ea6d","abstract":"Network arrivals are often modeled as Poisson processes for analytic simplicity, even though a number of traffic studies have shown that packet interarrivals are not exponentially distributed. We evaluate 24 wide area traces, investigating a number of wide area TCP arrival processes (session and connection arrivals, FTP data connection arrivals within FTP sessions, and TELNET packet arrivals) to determine the error introduced by modeling them using Poisson processes. We find that user-initiated TCP session arrivals, such as remote-login and file-transfer, are well-modeled as Poisson processes with fixed hourly rates, but that other connection arrivals deviate considerably from Poisson; that modeling TELNET packet interarrivals as exponential grievously underestimates the burstiness of TELNET traffic, but using the empirical Tcplib interarrivals preserves burstiness over many time scales; and that FTP data connection arrivals within FTP sessions come bunched into \"connection bursts\", the largest of which are so large that they completely dominate FTP data traffic. Finally, we offer some results regarding how our findings relate to the possible self-similarity of wide area traffic. >","title":"Wide area traffic: the failure of Poisson modeling","venue":"IEEE\\/ACM Transactions on Networking","year":1995,"__v":0,"citationCount":1565,"parents":{"0117b1c1-0405-4676-9ff5-0b75fdfad1bd":0,"0c397a13-73fa-4bbd-99c9-2a4f9c722bf8":6.666666666666667,"19c730f7-24d3-4c1f-9c85-af826d0509b5":26.666666666666668,"1ece4859-34df-4469-bec1-5a6f3d26e8a4":0,"2222f1f9-b357-45ef-8943-ae096e660c5f":20,"238474f3-787b-4e66-9f49-c197d110f93f":13.333333333333334,"3194faee-2398-4d19-b9da-1e3fbfbe1d64":6.666666666666667,"412f8879-77c5-4751-af29-f3e53da72185":13.333333333333334,"5d7d8304-f78d-4332-aefd-4f4d8d78f0e1":0,"6ed13d45-3965-4a51-bc0c-c7a49f49af56":6.666666666666667,"7116f6d8-e970-4cc9-8e29-9ed6831b8a9f":0,"a1b950a0-345b-4471-ba60-872e4f8cc058":13.333333333333334,"c2cf0a04-29fe-4b40-b705-2b4ea4377a4b":0,"d2a57597-5f45-4c41-8020-03cdfc0ebb3f":13.333333333333334,"f0853f1c-3a53-4adc-9357-feabc0c1479c":6.666666666666667},"keyword":{"0117b1c1-0405-4676-9ff5-0b75fdfad1bd":8.527380952380952,"0c397a13-73fa-4bbd-99c9-2a4f9c722bf8":10.491666666666665,"19c730f7-24d3-4c1f-9c85-af826d0509b5":8.92984126984127,"1ece4859-34df-4469-bec1-5a6f3d26e8a4":10.520000000000001,"2222f1f9-b357-45ef-8943-ae096e660c5f":12.050468975468979,"238474f3-787b-4e66-9f49-c197d110f93f":9.218253968253968,"3194faee-2398-4d19-b9da-1e3fbfbe1d64":9.122222222222222,"412f8879-77c5-4751-af29-f3e53da72185":8.317063492063493,"5d7d8304-f78d-4332-aefd-4f4d8d78f0e1":10.950793650793653,"6ed13d45-3965-4a51-bc0c-c7a49f49af56":12.050468975468977,"7116f6d8-e970-4cc9-8e29-9ed6831b8a9f":0,"a1b950a0-345b-4471-ba60-872e4f8cc058":11.20297619047619,"c2cf0a04-29fe-4b40-b705-2b4ea4377a4b":11.005714285714289,"d2a57597-5f45-4c41-8020-03cdfc0ebb3f":7.49484126984127,"f0853f1c-3a53-4adc-9357-feabc0c1479c":10.64246031746032},"topic":["arriv","ftp","connect","traffic","session"],"groups":[{"authors":["Will E. Leland","Murad S. Taqqu","Walter Willinger","Daniel V. Wilson"],"references":["3a265cec-75cb-418e-9607-647369f79dd0","4086aec0-82bf-4810-9ec7-a0f8dccde0a8","412f8879-77c5-4751-af29-f3e53da72185","56904468-b807-4f2b-87c8-c145b59bfdd7","7bcfe8a0-2ff2-4072-958d-55a8c1267d82","7d371899-f6a5-4e16-8365-835827db041e","7d7dcaad-1b7c-4eff-a09e-dcef99b17dd3","c2cf0a04-29fe-4b40-b705-2b4ea4377a4b","e977fe06-34a0-4bc7-baa8-2ab386b962e8","f0853f1c-3a53-4adc-9357-feabc0c1479c","fe980878-f809-42ad-82a1-55bc898c6ebb"],"_id":"2222f1f9-b357-45ef-8943-ae096e660c5f","abstract":"Demonstrates that Ethernet LAN traffic is statistically self-similar, that none of the commonly used traffic models is able to capture this fractal-like behavior, that such behavior has serious implications for the design, control, and analysis of high-speed, cell-based networks, and that aggregating streams of such traffic typically intensifies the self-similarity (\"burstiness\") instead of smoothing it. These conclusions are supported by a rigorous statistical analysis of hundreds of millions of high quality Ethernet traffic measurements collected between 1989 and 1992, coupled with a discussion of the underlying mathematical and statistical properties of self-similarity and their relationship with actual network behavior. The authors also present traffic models based on self-similar stochastic processes that provide simple, accurate, and realistic descriptions of traffic scenarios expected during B-ISDN deployment. >","title":"On the self-similar nature of Ethernet traffic (extended version)","venue":"IEEE\\/ACM Transactions on Networking","year":1994,"__v":0,"citationCount":1810},{"authors":["Vern Paxson"],"references":["0c397a13-73fa-4bbd-99c9-2a4f9c722bf8","3340d505-a639-4a69-bf18-c7e03981d858","3bb9b6ca-18dd-4d95-8c16-e7003ef32df4","5daf6f84-0d4a-445a-b173-8d2a55a98438","6ed13d45-3965-4a51-bc0c-c7a49f49af56","7116f6d8-e970-4cc9-8e29-9ed6831b8a9f","7d371899-f6a5-4e16-8365-835827db041e","8ed0c977-c4e4-4183-8ec3-b2fc7bea41cf","a1b950a0-345b-4471-ba60-872e4f8cc058","afd4c865-5c81-424b-82c3-1dcb6150ea6d","b9cd3885-ef04-4ddd-a63c-1d0155d5896f","c1d9af07-a130-482b-a49f-e8716492d55c","c274a612-da61-4b92-a77a-421e6ed9dd14","cab95689-0a52-40f3-9a7c-987da74fb402","f5241be9-4c87-46c4-8b6f-6b7388fb2b5d"],"_id":"19c730f7-24d3-4c1f-9c85-af826d0509b5","abstract":"Analyzes 3 million TCP connections that occurred during 15 wide-area traffic traces. The traces were gathered at five \"stub\" networks and two internetwork gateways, providing a diverse look at wide-area traffic. The author derives analytic models describing the random variables associated with TELNET, NNTP, SMTP, and FTP connections. To assess these models the author presents a quantitative methodology for comparing their effectiveness with that of empirical models such as Tcplib [Danzig and Jamin, 1991]. The methodology also allows to determine which random variables show significant variation from site to site, over time, or between stub networks and internetwork gateways. Overall the author finds that the analytic models provide good descriptions, and generally model the various distributions as well as empirical models. >","title":"Empirically derived analytic models of wide-area TCP connections","venue":"IEEE\\/ACM Transactions on Networking","year":1994,"__v":0,"citationCount":264}],"offsprings":["1a24e9c7-d0ce-4be4-8e3a-c849b4630851"]},"b0ef6e4d-4c86-4b10-9e0a-7b630ca8d7f7":{"authors":["M. E. J. Newman"],"references":["1a24e9c7-d0ce-4be4-8e3a-c849b4630851","38135245-8eff-4078-af6a-ea559ffa660b","8f9e92cf-f266-4e51-807f-c098a260a0dc","c7e4e04b-45da-4bae-8c8a-d17ca0087361"],"_id":"b0ef6e4d-4c86-4b10-9e0a-7b630ca8d7f7","abstract":"Inspired by empirical studies of networked systems such as the Internet, social networks, and biological networks, researchers have in recent years developed a variety of techniques and models to help us understand or predict the behavior of these systems. Here we review developments in this field, including such concepts as the small-world effect, degree distributions, clustering, network correlations, random graph models, models of network growth and preferential attachment, and dynamical processes taking place on networks.","title":"The Structure and Function of Complex Networks","venue":"Siam Review","year":2003,"__v":0,"citationCount":3109,"parents":{"008d95fd-26f0-47f3-8774-6a896446baea":1.8181818181818181,"05332f60-3d2e-45bb-9ecd-a7c7aa7774dc":9.090909090909092,"05f5fba9-e7ca-4c46-be79-df57944a8b41":0,"0718dc34-4b49-4b24-8a2e-b5cd0d9d82c6":0,"0d8eb1a3-5b89-419b-9eea-8fffd03c78a1":0,"16e3c2f7-37fb-4192-bf76-20fe7838958a":3.6363636363636362,"18819165-7f73-4da1-9bf2-792c258be677":7.2727272727272725,"19f41085-f8c3-4087-a48a-27205b43bdb8":0,"1a24e9c7-d0ce-4be4-8e3a-c849b4630851":0,"1b41d9a0-3857-4fb6-b7ba-d39da73c04dd":0,"27e4ec4d-0ce3-437b-9511-db610b7ba805":1.8181818181818181,"2a2fd168-2bcf-4527-afcd-5c99e75ad511":0,"38135245-8eff-4078-af6a-ea559ffa660b":0,"3bbad1d7-7c16-4c85-ae98-4cfd6913794f":1.8181818181818181,"3f610d75-809b-4a12-858f-95e346c17e8c":0,"424bab1d-a362-4bd2-a878-eb81372b689d":0,"4c343995-619f-4859-bd00-321c87adcd3c":0,"597ecf84-4084-4057-a40d-30988ef74121":0,"5ea35ec7-ab9f-4d0e-9a85-ef4add482ec7":3.6363636363636362,"606e4423-5a84-4c3b-bfb1-0cf549bf21e9":0,"60c814e2-c4d1-47d7-9a5a-68f4141505ae":1.8181818181818181,"60ef3852-fa16-44bf-9434-9909268ba5d8":0,"63245010-95d3-4eb1-a0d0-62894531d092":10.909090909090908,"686c5563-3f13-4744-ac6d-1020e39953bf":5.454545454545454,"6e6cac85-1ca8-4d49-8e16-aa3d353fc20a":3.6363636363636362,"71414cbd-e8f3-43ce-b536-029959d08b14":0,"7192626f-12df-45f7-889d-c78e4da08773":7.2727272727272725,"7291c68d-db95-48a0-b856-6545ef18b503":5.454545454545454,"8a4d517a-da96-4f80-879d-dda81e69d9c9":3.6363636363636362,"8f12317e-0ea6-455c-a973-7c7440af5f37":0,"8f9e92cf-f266-4e51-807f-c098a260a0dc":3.6363636363636362,"98c4a2e2-f046-4e49-9173-91779f961cc0":0,"9dbdc129-b8f3-4712-9c95-406bc8911bee":1.8181818181818181,"a0181d7d-c725-4bc4-8371-2510c70c96a4":1.8181818181818181,"a08549f5-fa6a-4adb-b643-714867228a0c":0,"a0c94b9b-d64e-40d5-ba44-4208dec791d0":5.454545454545454,"a22c015f-fa44-4b73-b906-ef030405d9c9":1.8181818181818181,"a4a93e4a-68f2-4509-bf87-5b33122ff614":0,"a78ddf3f-d0ac-4262-bd99-ca8d5bd8309e":0,"af8a7a02-c5f2-4367-9a67-7593d92f6003":10.909090909090908,"b2f1d79b-d47a-4f2a-b810-ac3c837d7ee4":0,"b407837a-0eae-4882-9a2c-2c185d5c16e0":3.6363636363636362,"baad4ab4-a3f2-45fc-b87d-954f608e8db7":0,"bd34626f-94ae-46a2-8037-8c367831fa78":1.8181818181818181,"c2165f5b-d07b-4cd2-9d2b-e6f3002c80db":7.2727272727272725,"c4716aad-c8bc-431b-8173-0300064a77b0":3.6363636363636362,"c7e4e04b-45da-4bae-8c8a-d17ca0087361":0,"ce115523-6b89-47ad-8cf3-1cb3e2a865d3":1.8181818181818181,"d71f089c-0658-478a-b58e-bb8e6f131c21":0,"dd38911a-f68b-4bb5-a817-fd7153f0ff2f":12.727272727272727,"df4b8e90-b404-47f8-a384-c93aa1313694":1.8181818181818181,"e2a97ffb-90b0-4f1a-b01d-b15a77a820de":0,"e4f056cc-ab1e-4ca0-8754-fc81b133a47d":3.6363636363636362,"f15b19f2-4b37-454c-851e-a71cccf3e53a":0,"f8088d69-04af-49f3-84b9-daf7682cc5f5":1.8181818181818181},"keyword":{"008d95fd-26f0-47f3-8774-6a896446baea":7.341269841269841,"05332f60-3d2e-45bb-9ecd-a7c7aa7774dc":8.793333333333333,"05f5fba9-e7ca-4c46-be79-df57944a8b41":0,"0718dc34-4b49-4b24-8a2e-b5cd0d9d82c6":6.440476190476191,"0d8eb1a3-5b89-419b-9eea-8fffd03c78a1":8.907539682539683,"16e3c2f7-37fb-4192-bf76-20fe7838958a":11.898520923520923,"18819165-7f73-4da1-9bf2-792c258be677":9.178677248677248,"19f41085-f8c3-4087-a48a-27205b43bdb8":7.591904761904762,"1a24e9c7-d0ce-4be4-8e3a-c849b4630851":8.967857142857143,"1b41d9a0-3857-4fb6-b7ba-d39da73c04dd":7.747037037037037,"27e4ec4d-0ce3-437b-9511-db610b7ba805":9.769801587301584,"2a2fd168-2bcf-4527-afcd-5c99e75ad511":9.411111111111113,"38135245-8eff-4078-af6a-ea559ffa660b":11.388492063492063,"3bbad1d7-7c16-4c85-ae98-4cfd6913794f":12.40515873015873,"3f610d75-809b-4a12-858f-95e346c17e8c":0,"424bab1d-a362-4bd2-a878-eb81372b689d":9.556666666666667,"4c343995-619f-4859-bd00-321c87adcd3c":9.67936507936508,"597ecf84-4084-4057-a40d-30988ef74121":11.595396825396824,"5ea35ec7-ab9f-4d0e-9a85-ef4add482ec7":10.232222222222221,"606e4423-5a84-4c3b-bfb1-0cf549bf21e9":8.613145743145743,"60c814e2-c4d1-47d7-9a5a-68f4141505ae":0,"60ef3852-fa16-44bf-9434-9909268ba5d8":13.358412698412698,"63245010-95d3-4eb1-a0d0-62894531d092":10.032539682539683,"686c5563-3f13-4744-ac6d-1020e39953bf":9.314761904761902,"6e6cac85-1ca8-4d49-8e16-aa3d353fc20a":11.5705291005291,"71414cbd-e8f3-43ce-b536-029959d08b14":9.987936507936507,"7192626f-12df-45f7-889d-c78e4da08773":8.457301587301588,"7291c68d-db95-48a0-b856-6545ef18b503":7.123015873015873,"8a4d517a-da96-4f80-879d-dda81e69d9c9":12.911984126984125,"8f12317e-0ea6-455c-a973-7c7440af5f37":10.05126984126984,"8f9e92cf-f266-4e51-807f-c098a260a0dc":8.593650793650795,"98c4a2e2-f046-4e49-9173-91779f961cc0":9.028571428571427,"9dbdc129-b8f3-4712-9c95-406bc8911bee":5.896031746031747,"a0181d7d-c725-4bc4-8371-2510c70c96a4":8.348412698412698,"a08549f5-fa6a-4adb-b643-714867228a0c":12.296904761904763,"a0c94b9b-d64e-40d5-ba44-4208dec791d0":13.554761904761902,"a22c015f-fa44-4b73-b906-ef030405d9c9":10.423888888888888,"a4a93e4a-68f2-4509-bf87-5b33122ff614":12.319047619047618,"a78ddf3f-d0ac-4262-bd99-ca8d5bd8309e":9.119973544973545,"af8a7a02-c5f2-4367-9a67-7593d92f6003":13.464814814814815,"b2f1d79b-d47a-4f2a-b810-ac3c837d7ee4":9.850396825396826,"b407837a-0eae-4882-9a2c-2c185d5c16e0":9.212698412698412,"baad4ab4-a3f2-45fc-b87d-954f608e8db7":0,"bd34626f-94ae-46a2-8037-8c367831fa78":8.3,"c2165f5b-d07b-4cd2-9d2b-e6f3002c80db":9.009259259259258,"c4716aad-c8bc-431b-8173-0300064a77b0":10.743253968253967,"c7e4e04b-45da-4bae-8c8a-d17ca0087361":9.792063492063495,"ce115523-6b89-47ad-8cf3-1cb3e2a865d3":9.091746031746032,"d71f089c-0658-478a-b58e-bb8e6f131c21":8.455357142857142,"dd38911a-f68b-4bb5-a817-fd7153f0ff2f":9.311111111111112,"df4b8e90-b404-47f8-a384-c93aa1313694":10.878373015873015,"e2a97ffb-90b0-4f1a-b01d-b15a77a820de":8.823492063492063,"e4f056cc-ab1e-4ca0-8754-fc81b133a47d":0,"f15b19f2-4b37-454c-851e-a71cccf3e53a":6.069841269841269,"f8088d69-04af-49f3-84b9-daf7682cc5f5":7.778174603174604},"topic":["network","model","system","develop","year"],"offsprings":["68faab18-b537-4f62-85cf-ddc9ef352362","d9162547-fd7f-4605-855d-0a3173c4b08e"]},"b22134b3-2419-4d39-b6b8-d7ad60abac26":{"authors":["Andrew Sendonaris","Elza Erkip","Behnaam Aazhang"],"references":["748a2ab3-8b5f-4d0a-9e2d-af685089843a"],"_id":"b22134b3-2419-4d39-b6b8-d7ad60abac26","abstract":"Mobile users' data rate and quality of service are limited by the fact that, within the duration of any given call, they experience severe variations in signal attenuation, thereby necessitating the use of some type of diversity. In this two-part paper, we propose a new form of spatial diversity, in which diversity gains are achieved via the cooperation of mobile users. Part I describes the user cooperation strategy, while Part II (see ibid., p.1939-48) focuses on implementation issues and performance analysis. Results show that, even though the interuser channel is noisy, cooperation leads not only to an increase in capacity for both users but also to a more robust system, where users' achievable rates are less susceptible to channel variations.","title":"User cooperation diversity. Part I. System description","venue":"IEEE Transactions on Communications","year":2003,"__v":0,"citationCount":3364,"parents":{"2861a324-b628-4668-96be-143b94b5e938":0,"2898d033-bbfd-49c8-ba3a-b15187e815fe":10,"4296a611-0cd3-4c26-9229-22b591d59028":0,"51bc0d88-d328-4d53-9340-00aa948cf11d":30,"73fec0bf-70f7-4eec-aac4-9c22f48cded5":20,"748a2ab3-8b5f-4d0a-9e2d-af685089843a":0,"93ae61c8-57f9-452e-a7b3-83aa1cdd1be4":0,"e0bcaa03-f72d-400b-89eb-97f17b5f0693":0,"e7ce6f9e-715f-4f6c-b7cb-c26cd42ca188":20,"efcbfcea-e8b0-4ca9-a883-92f42f862307":0},"keyword":{"2861a324-b628-4668-96be-143b94b5e938":11.755449735449734,"2898d033-bbfd-49c8-ba3a-b15187e815fe":10.921428571428569,"4296a611-0cd3-4c26-9229-22b591d59028":12.328571428571427,"51bc0d88-d328-4d53-9340-00aa948cf11d":10.067195767195768,"73fec0bf-70f7-4eec-aac4-9c22f48cded5":11.976851851851848,"748a2ab3-8b5f-4d0a-9e2d-af685089843a":12.21190476190476,"93ae61c8-57f9-452e-a7b3-83aa1cdd1be4":8.264285714285716,"e0bcaa03-f72d-400b-89eb-97f17b5f0693":12.177777777777777,"e7ce6f9e-715f-4f6c-b7cb-c26cd42ca188":9.25174603174603,"efcbfcea-e8b0-4ca9-a883-92f42f862307":4.088968253968254},"topic":["users'","divers","cooper","variat","rate"],"groups":[{"authors":["Chao-Ming Zeng","Federico Kuhlmann","Andres Buzo"],"references":["6b638ffe-e01f-498a-a381-7fe9e33e3698","850e2885-2353-4f5f-b1fd-632c68317493","8854882a-40a7-4059-9db4-862cf68f25a7","cac3fc3f-ffc3-4b8f-a77d-078358ea6e4c","cdd26d4b-3066-4e76-918e-5b11d5d39680","e0bcaa03-f72d-400b-89eb-97f17b5f0693","e7ce6f9e-715f-4f6c-b7cb-c26cd42ca188","efcbfcea-e8b0-4ca9-a883-92f42f862307","f4ac49a9-4dd2-49a8-8e4b-07c41f76b465"],"_id":"51bc0d88-d328-4d53-9340-00aa948cf11d","abstract":"New and simpler achievability proofs that are based on the backward decoding technique are presented for the well-known coding theorems for the multiple-access channel (MAC) with perfect feedback and the degraded relay channel. A class of MACs with different generalized feedback signals is also considered, and achievable-rate regions that are larger than those previously presented in the literature are established. >","title":"Achievability proof of some multiuser channel coding theorems using backward decoding","venue":"IEEE Transactions on Information Theory","year":1989,"__v":0,"citationCount":28}],"offsprings":["6d25cd6f-4a67-41ed-9b6d-467c739f531e"]},"b53a4e8b-970b-4a62-9789-71e333441489":{"authors":["Hiroshi Ishii","Brygg Ullmer"],"references":[],"_id":"b53a4e8b-970b-4a62-9789-71e333441489","abstract":"This paper presents our vision of Human Computer Interaction (HCI): \"Tangible Bits.\" Tangible Bits allows users to \"grasp & manipulate\" bits in the center of users’ attention by coupling the bits with everyday physical objects and architectural surfaces. Tangible Bits also enables users to be aware of background bits at the periphery of human perception using ambient display media such as light, sound, airflow, and water movement in an augmented space. The goal of Tangible Bits is to bridge the gaps between both cyberspace and the physical environment, as well as the foreground and background of human activities. This paper describes three key concepts of Tangible Bits: interactive surfaces; the coupling of bits with graspable physical objects; and ambient media for background awareness. We illustrate these concepts with three prototype systems ‐ the metaDESK, transBOARD and ambientROOM ‐ to identify underlying research issues.","title":"Tangible bits: towards seamless interfaces between people, bits and atoms","venue":"human factors in computing systems","year":1997,"__v":0,"citationCount":1519,"parents":{"27648d64-f108-4bf3-8ea1-68f7a6106344":0,"397aa984-d831-47e3-9913-c894434754fe":0,"6aa879d4-554d-47ff-b457-6c4b586c6971":0,"6d9f55be-495a-49ca-826a-c5156e0110d4":12.5,"73f7e769-eee7-4863-a5db-b9c5eecc23e0":0,"959ceb33-4297-418a-925f-51b2682e7d3a":0,"eb8e907d-403d-4484-b320-6bed9b27a5e3":12.5,"f098d2c1-9b10-48d2-82bd-05659dc73271":25},"keyword":{"27648d64-f108-4bf3-8ea1-68f7a6106344":0,"397aa984-d831-47e3-9913-c894434754fe":0,"6aa879d4-554d-47ff-b457-6c4b586c6971":8.831944444444444,"6d9f55be-495a-49ca-826a-c5156e0110d4":0,"73f7e769-eee7-4863-a5db-b9c5eecc23e0":0,"959ceb33-4297-418a-925f-51b2682e7d3a":0,"eb8e907d-403d-4484-b320-6bed9b27a5e3":0,"f098d2c1-9b10-48d2-82bd-05659dc73271":9.391031746031743},"topic":["bit","tangibl","user","physic","human"],"groups":[{"authors":["George W. Fitzmaurice","Hiroshi Ishii","William Buxton"],"references":["0fe750d0-05d8-44ac-9422-1939fc41ea5c","73f7e769-eee7-4863-a5db-b9c5eecc23e0","c26ca1b5-606e-4116-af63-7315bd45caf6","db50b470-3f98-404e-9f49-fe3db913e4ee","eb8e907d-403d-4484-b320-6bed9b27a5e3"],"_id":"f098d2c1-9b10-48d2-82bd-05659dc73271","abstract":"We introduce the concept of Graspable User Interfaces that allow direct control of electronic or virtual objects through physical handles for control. These physical artifacts, which we call \"bricks,\" are essentially new input devices that can be tightly coupled or “attached” to virtual objects for manipulation or for expressing action (e.g., to set parameters or for initiating processes). Our bricks operate on top of a large horizontal display surface known as the \"ActiveDesk.\" We present four stages in the development of Graspable UIs: (1) a series of exploratory studies on hand gestures and grasping; (2) interaction simulations using mock-ups and rapid prototyping tools; (3) a working prototype and sample application called GraspDraw; and (4) the initial integrating of the Graspable UI concepts into a commercial application. Finally, we conclude by presenting a design space for Bricks which lay the foundation for further exploring and developing Graspable User Interfaces.","title":"Bricks: laying the foundations for graspable user interfaces","venue":"human factors in computing systems","year":1995,"__v":0,"citationCount":432}],"offsprings":[]},"b5b8132d-0a8c-4e6c-999f-839f0cef48b7":{"authors":["Joseph Polastre","Jason L. Hill","David E. Culler"],"references":["6bfdf9a3-6cd9-43d8-9785-0073dbe96f1b","85352dec-58be-43db-a428-f3f574ff96ec","afc06b7c-7fb3-4f88-942b-3076ed77920e"],"_id":"b5b8132d-0a8c-4e6c-999f-839f0cef48b7","abstract":"We propose  B-MAC , a carrier sense media access protocol for wireless sensor networks that provides a flexible interface to obtain ultra low power operation, effective collision avoidance, and high channel utilization. To achieve low power operation,  B-MAC  employs an adaptive preamble sampling scheme to reduce duty cycle and minimize idle listening.  B-MAC  supports on-the-fly reconfiguration and provides bidirectional interfaces for system services to optimize performance, whether it be for throughput, latency, or power conservation. We build an analytical model of a class of sensor network applications. We use the model to show the effect of changing  B-MAC 's parameters and predict the behavior of sensor network applications. By comparing  B-MAC  to conventional 802.11-inspired protocols, specifically SMAC, we develop an experimental characterization of  B-MAC  over a wide range of network conditions. We show that  B-MAC 's flexibility results in better packet delivery rates, throughput, latency, and energy consumption than S-MAC. By deploying a real world monitoring application with multihop networking, we validate our protocol design and model. Our results illustrate the need for flexible protocols to effectively realize energy efficient sensor network applications.","title":"Versatile low power media access for wireless sensor networks","venue":"international conference on embedded networked sensor systems","year":2004,"__v":0,"citationCount":1562,"parents":{"1af2080f-7848-4795-a98c-6e38e7731cdc":21.428571428571427,"2d33d7b4-c68a-4847-9455-c09c8497b662":7.142857142857142,"38f54b84-5272-43df-8cde-a3e755b17dee":0,"3bd9a208-194a-470a-ae5c-2250b65077a7":28.57142857142857,"6bfdf9a3-6cd9-43d8-9785-0073dbe96f1b":14.285714285714285,"73574f5f-bf4f-44fb-b13f-d5eaa8c96619":7.142857142857142,"84dc5aaa-7b2c-4f15-97f4-aa867b4328e2":7.142857142857142,"85352dec-58be-43db-a428-f3f574ff96ec":14.285714285714285,"afc06b7c-7fb3-4f88-942b-3076ed77920e":0,"c4d75f12-4c23-4fa7-ad44-5f86d572082f":14.285714285714285,"d3a6b91d-9fad-4438-82e2-ac405428cae2":21.428571428571427,"e9e45e77-7dd0-4da0-9e74-b4d468626027":14.285714285714285,"ec502134-b61e-4124-a0a3-f34c20c4b262":21.428571428571427,"f682f022-3c5c-4638-a9d4-5b08bfa136a1":21.428571428571427},"keyword":{"1af2080f-7848-4795-a98c-6e38e7731cdc":9.57638888888889,"2d33d7b4-c68a-4847-9455-c09c8497b662":9.14642857142857,"38f54b84-5272-43df-8cde-a3e755b17dee":0,"3bd9a208-194a-470a-ae5c-2250b65077a7":8.621825396825395,"6bfdf9a3-6cd9-43d8-9785-0073dbe96f1b":9.498809523809523,"73574f5f-bf4f-44fb-b13f-d5eaa8c96619":9.817460317460316,"84dc5aaa-7b2c-4f15-97f4-aa867b4328e2":9.348015873015871,"85352dec-58be-43db-a428-f3f574ff96ec":9.970238095238093,"afc06b7c-7fb3-4f88-942b-3076ed77920e":7.664285714285714,"c4d75f12-4c23-4fa7-ad44-5f86d572082f":10.837738095238096,"d3a6b91d-9fad-4438-82e2-ac405428cae2":10.50515873015873,"e9e45e77-7dd0-4da0-9e74-b4d468626027":9.175793650793647,"ec502134-b61e-4124-a0a3-f34c20c4b262":9.997222222222224,"f682f022-3c5c-4638-a9d4-5b08bfa136a1":8.394047619047617},"topic":["bmac","network","sensor","protocol","applic"],"groups":[{"authors":["Robert Szewczyk","Joseph Polastre","Alan Mainwaring","David E. Culler"],"references":["05fb3436-276f-43ca-979b-0a3323240c19","1dd8c68d-3b20-4171-9245-3a12c64c2838","2d33d7b4-c68a-4847-9455-c09c8497b662","30ac1757-80f7-4b9e-bb10-639a76916d66","3e9e39c1-9982-4a65-bd02-eac41f27e76d","526681c0-a533-4b1d-b9f8-f04059a11d36","5e39866a-8748-461e-a5f1-e8460234284c","6bfdf9a3-6cd9-43d8-9785-0073dbe96f1b","84dc5aaa-7b2c-4f15-97f4-aa867b4328e2","afc06b7c-7fb3-4f88-942b-3076ed77920e","bcb96aed-f8d8-4150-9cb6-637d2ccc0a8e","e3284cc8-30cb-4cd1-bc5e-9ff3115e7210","e7d61875-305b-4319-b592-1524e84472d7","efa04de8-fec3-4c73-8031-5b7990b88e57"],"_id":"3bd9a208-194a-470a-ae5c-2250b65077a7","abstract":"Habitat monitoring is an important driving application for wireless sensor networks (WSNs). Although researchers anticipate some challenges arising in the real-world deployments of sensor networks, a number of problems can be discovered only through experience. This paper evaluates a sensor network system described in an earlier work and presents a set of experiences from a four month long deployment on a remote island off the coast of Maine. We present an in-depth analysis of the environmental and node health data. The close integration of WSNs with their environment provides biological data at densities previous impossible; however, we show that the sensor data is also useful for predicting system operation and network failures. Based on over one million data and health readings, we analyze the node and network design and develop network reliability profiles and failure models.","title":"Lessons from a Sensor Network Expedition","venue":"international conference on embedded wireless systems and networks","year":2004,"__v":0,"citationCount":221}],"offsprings":[]},"b857298c-92c9-4f05-a704-3b9fc6be06e3":{"authors":["Ian F. Akyildiz","Xudong Wang","Weilin Wang"],"references":["2659531e-eb9d-4dd5-b46f-10f66a4819c6","8cc9ea80-563f-4e62-bda9-8ff6d71cf6ae","96b245c2-47a5-4aec-89f0-d2a362124845","f3267c01-b670-4b7a-a3a5-79088c0d90ab"],"_id":"b857298c-92c9-4f05-a704-3b9fc6be06e3","abstract":"Wireless mesh networks (WMNs) consist of mesh routers and mesh clients, where mesh routers have minimal mobility and form the backbone of WMNs. They provide network access for both mesh and conventional clients. The integration of WMNs with other networks such as the Internet, cellular, IEEE 802.11, IEEE 802.15, IEEE 802.16, sensor networks, etc., can be accomplished through the gateway and bridging functions in the mesh routers. Mesh clients can be either stationary or mobile, and can form a client mesh network among themselves and with mesh routers. WMNs are anticipated to resolve the limitations and to significantly improve the performance of ad hoc networks, wireless local area networks (WLANs), wireless personal area networks (WPANs), and wireless metropolitan area networks (WMANs). They are undergoing rapid progress and inspiring numerous deployments. WMNs will deliver wireless services for a large variety of applications in personal, local, campus, and metropolitan areas. Despite recent advances in wireless mesh networking, many research challenges remain in all protocol layers. This paper presents a detailed study on recent advances and open research issues in WMNs. System architectures and applications of WMNs are described, followed by discussing the critical factors influencing protocol design. Theoretical network capacity and the state-of-the-art protocols for WMNs are explored with an objective to point out a number of open research issues. Finally, testbeds, industrial practice, and current standard activities related to WMNs are highlighted. ed by discussing the critical factors influencing protocol design. Theoretical network capacity and the state-of-the-art protocols for WMNs are explored with an objective to outline a number of open research issues. Finally, testbeds, industrial practice, and current standard activities related to WMNs are highlighted.","title":"Wireless mesh networks: a survey","venue":"Computer Networks","year":2005,"__v":0,"citationCount":1690,"parents":{"02eefe0f-b029-4fbb-b41a-906e8f04639d":5.194805194805195,"03a67937-3823-48ca-8b6c-98bf2774800b":3.896103896103896,"04d08d28-706c-492a-b2a2-68be407e3ce4":0,"0998b7fa-b6ab-4494-8f8a-80136f4ddbd2":1.2987012987012987,"11ce2a5f-c26f-4d92-83da-65ba632c1195":2.5974025974025974,"12b6f373-f5d1-46f4-85ee-16ee239ee862":0,"14a274e3-6ec3-40f7-80ad-334711dc3222":9.090909090909092,"190378e2-8617-4add-835c-3e7ed4805bd1":2.5974025974025974,"1b7ff6d2-5664-4f68-b6b0-7ec24900db9e":6.493506493506493,"22b55f59-1aa1-4dc4-92fe-5e82014652cf":0,"2659531e-eb9d-4dd5-b46f-10f66a4819c6":0,"269e006a-d493-4ade-be8b-cfc3b56d5752":0,"29424b9c-c448-4679-8472-044e701a11ea":2.5974025974025974,"2962277b-7da6-4a64-9dbd-6ca9370c577d":2.5974025974025974,"29f75862-97b4-4116-9e91-70bde085bcca":0,"2b06e029-ba76-4924-96ce-815670c8e2e3":2.5974025974025974,"32591c3e-f867-4910-91ec-ce8d8113767a":3.896103896103896,"35239e8a-a6d8-4297-8818-e8965b5d2472":1.2987012987012987,"380c3e95-47c3-4e83-ba1a-be8351b787d8":5.194805194805195,"3a8d5801-1361-43d4-a4cd-e70133c245d4":5.194805194805195,"3d32516c-e687-4b1d-8788-646dddfd7008":5.194805194805195,"3f538b4c-767e-4749-82f9-9a970e9f83e6":0,"425664d5-08ce-49f6-979d-5e6eff993ed2":7.792207792207792,"42f3128f-69d0-4659-8039-d2e45f4cbb4f":0,"474dd419-342a-4a4b-9f04-85803e77459c":0,"4cfd1b21-4c46-47c5-88ed-9bff442a8165":0,"53509df6-4f4f-4652-bf8a-43098126e01b":3.896103896103896,"58d586c7-9f54-45ee-8349-62526bbdc1f9":0,"5a878cce-f516-4bcb-84fa-8f19f1656099":1.2987012987012987,"66a2e736-3c79-46db-bfa4-340cb1cd1c1a":0,"6b4920a9-9dbd-411e-9618-0dd545bc97d7":0,"71cec942-481a-4e22-a5e9-ff40ba582e5d":2.5974025974025974,"735f0549-832b-4c65-bf41-70039c3d63b8":1.2987012987012987,"809c50af-7512-4ca9-ad47-b8e1dd6ba77b":0,"83034d86-0f0f-4082-8752-91759086afaa":0,"83b5fe2e-6156-4963-9a80-1dd52c4d71bc":2.5974025974025974,"880c15cf-7b29-4c58-a601-c1f0affd1808":0,"8c1ed25a-4316-48e1-9dab-9185e4b9af42":7.792207792207792,"8ca979cf-f9d5-451a-84a7-e91ca2a592e2":2.5974025974025974,"8cc9ea80-563f-4e62-bda9-8ff6d71cf6ae":0,"8d372af4-9bbd-499c-a00d-c6cfd91f6dfb":0,"96318e18-6d91-4f89-8739-24f6d2a30b5f":0,"96b245c2-47a5-4aec-89f0-d2a362124845":1.2987012987012987,"98783db9-d399-4537-9eaa-8964f92d99c7":0,"9de43d04-c7fa-48a9-b092-67c2888745d4":0,"a08d8f1a-5612-46dc-9af0-9ee800438b0a":1.2987012987012987,"a301962a-6d47-4fcc-9a89-5c67e1fac20f":3.896103896103896,"a7be922e-d9fc-4df1-98ba-02afcbb0cb37":2.5974025974025974,"aed9b791-eaec-40f8-94df-fdef3291f6d5":0,"af92cf97-d046-4072-a64b-001789344745":1.2987012987012987,"b5741c8a-84a5-4b8d-9e5e-29d97732b48f":1.2987012987012987,"b612af14-d537-4a3d-8bb7-cd5c6d248927":1.2987012987012987,"b68a422e-b2f3-4cf4-86ec-453b1de928dc":0,"b97cdda8-3d21-4197-8c05-235cd9ff447f":0,"bc3c7b56-c0cd-4762-b8f1-dd53fa3905aa":1.2987012987012987,"c041e7c4-39f4-4b29-aed9-95a346efb2ea":0,"c7a0e971-e3f6-457b-8de5-693528bc6d9a":1.2987012987012987,"c9985150-ff5a-489c-93ca-8e626dc4dc46":5.194805194805195,"ca44ad79-a14d-4ba2-a118-e0dde960d3ba":18.181818181818183,"ccabb476-c38d-4867-bf93-60f1abe6e95b":2.5974025974025974,"cd7b4b1f-8614-4fab-8c33-a89394f0d6f9":1.2987012987012987,"d158cc4a-309b-4425-82b1-4f7f336c5c42":5.194805194805195,"d33673af-391e-43b0-bd73-f5e02fb81531":0,"d7bebab6-5327-4744-b315-a1d19e3989ab":6.493506493506493,"e01cbb09-7ac9-480b-b49b-e1198c5e33e0":1.2987012987012987,"e2d56e70-7eb7-495c-91b4-b11b127cd278":3.896103896103896,"e4047eee-fc9e-4f97-b354-64ef1d941719":1.2987012987012987,"eda5c9f4-7ed3-4663-a1a0-15ec4828af4d":1.2987012987012987,"ee99bfa9-086e-4d9a-9494-56a8281b8b78":1.2987012987012987,"f09510a5-a108-46c3-917d-0d8d145c4a0e":1.2987012987012987,"f3046808-ca07-4fb2-a8d5-9821b37e4f7b":0,"f3267c01-b670-4b7a-a3a5-79088c0d90ab":0,"f5a0a0a7-e045-4da5-815b-41964cffbaab":2.5974025974025974,"f65a4365-2696-47f3-849b-501792da7e23":2.5974025974025974,"f85ab3f5-3596-4704-a57e-873e6e0a80a9":0,"fb2003f6-ed7b-424e-94b2-6b150f8e7302":1.2987012987012987,"fc160e6d-da14-40c6-8b68-725aa841f6b2":0},"keyword":{"02eefe0f-b029-4fbb-b41a-906e8f04639d":7.732142857142858,"03a67937-3823-48ca-8b6c-98bf2774800b":9.679365079365079,"04d08d28-706c-492a-b2a2-68be407e3ce4":7.436507936507935,"0998b7fa-b6ab-4494-8f8a-80136f4ddbd2":7.45047619047619,"11ce2a5f-c26f-4d92-83da-65ba632c1195":9.485714285714286,"12b6f373-f5d1-46f4-85ee-16ee239ee862":6.033531746031745,"14a274e3-6ec3-40f7-80ad-334711dc3222":11.461904761904764,"190378e2-8617-4add-835c-3e7ed4805bd1":9.640211640211641,"1b7ff6d2-5664-4f68-b6b0-7ec24900db9e":9.07281746031746,"22b55f59-1aa1-4dc4-92fe-5e82014652cf":7.611150793650793,"2659531e-eb9d-4dd5-b46f-10f66a4819c6":10.095238095238095,"269e006a-d493-4ade-be8b-cfc3b56d5752":9.465145502645504,"29424b9c-c448-4679-8472-044e701a11ea":9.832142857142857,"2962277b-7da6-4a64-9dbd-6ca9370c577d":6.628968253968253,"29f75862-97b4-4116-9e91-70bde085bcca":10.210317460317459,"2b06e029-ba76-4924-96ce-815670c8e2e3":8.091825396825396,"32591c3e-f867-4910-91ec-ce8d8113767a":11.088571428571429,"35239e8a-a6d8-4297-8818-e8965b5d2472":9.258373015873014,"380c3e95-47c3-4e83-ba1a-be8351b787d8":9.11111111111111,"3a8d5801-1361-43d4-a4cd-e70133c245d4":5.477380952380952,"3d32516c-e687-4b1d-8788-646dddfd7008":9.63936507936508,"3f538b4c-767e-4749-82f9-9a970e9f83e6":8.386507936507936,"425664d5-08ce-49f6-979d-5e6eff993ed2":9.309722222222222,"42f3128f-69d0-4659-8039-d2e45f4cbb4f":10.597261904761904,"474dd419-342a-4a4b-9f04-85803e77459c":6.881124338624338,"4cfd1b21-4c46-47c5-88ed-9bff442a8165":9.559325396825399,"53509df6-4f4f-4652-bf8a-43098126e01b":10.837103174603175,"58d586c7-9f54-45ee-8349-62526bbdc1f9":6.126785714285714,"5a878cce-f516-4bcb-84fa-8f19f1656099":9.557539682539682,"66a2e736-3c79-46db-bfa4-340cb1cd1c1a":8.727116402116401,"6b4920a9-9dbd-411e-9618-0dd545bc97d7":6.916534391534392,"71cec942-481a-4e22-a5e9-ff40ba582e5d":11.664880952380953,"735f0549-832b-4c65-bf41-70039c3d63b8":2.742857142857143,"809c50af-7512-4ca9-ad47-b8e1dd6ba77b":9.011984126984126,"83034d86-0f0f-4082-8752-91759086afaa":8.558597883597882,"83b5fe2e-6156-4963-9a80-1dd52c4d71bc":6.817857142857141,"880c15cf-7b29-4c58-a601-c1f0affd1808":8.889947089947087,"8c1ed25a-4316-48e1-9dab-9185e4b9af42":10.595171957671957,"8ca979cf-f9d5-451a-84a7-e91ca2a592e2":6.728835978835979,"8cc9ea80-563f-4e62-bda9-8ff6d71cf6ae":7.6464285714285705,"8d372af4-9bbd-499c-a00d-c6cfd91f6dfb":11.343849206349208,"96318e18-6d91-4f89-8739-24f6d2a30b5f":9.831388888888888,"96b245c2-47a5-4aec-89f0-d2a362124845":10.384325396825398,"98783db9-d399-4537-9eaa-8964f92d99c7":6.5551587301587295,"9de43d04-c7fa-48a9-b092-67c2888745d4":7.5011243386243365,"a08d8f1a-5612-46dc-9af0-9ee800438b0a":9.076190476190474,"a301962a-6d47-4fcc-9a89-5c67e1fac20f":9.987500000000002,"a7be922e-d9fc-4df1-98ba-02afcbb0cb37":9.4994708994709,"aed9b791-eaec-40f8-94df-fdef3291f6d5":11.133822751322752,"af92cf97-d046-4072-a64b-001789344745":10.631904761904764,"b5741c8a-84a5-4b8d-9e5e-29d97732b48f":9.142738095238094,"b612af14-d537-4a3d-8bb7-cd5c6d248927":9.523055555555553,"b68a422e-b2f3-4cf4-86ec-453b1de928dc":5.7255291005291,"b97cdda8-3d21-4197-8c05-235cd9ff447f":10.116576479076478,"bc3c7b56-c0cd-4762-b8f1-dd53fa3905aa":7.269246031746031,"c041e7c4-39f4-4b29-aed9-95a346efb2ea":6.8511904761904745,"c7a0e971-e3f6-457b-8de5-693528bc6d9a":5.006746031746032,"c9985150-ff5a-489c-93ca-8e626dc4dc46":6.558333333333332,"ca44ad79-a14d-4ba2-a118-e0dde960d3ba":8.336984126984126,"ccabb476-c38d-4867-bf93-60f1abe6e95b":10.565079365079365,"cd7b4b1f-8614-4fab-8c33-a89394f0d6f9":10.731031746031746,"d158cc4a-309b-4425-82b1-4f7f336c5c42":8.815873015873015,"d33673af-391e-43b0-bd73-f5e02fb81531":7.910317460317458,"d7bebab6-5327-4744-b315-a1d19e3989ab":9.457936507936509,"e01cbb09-7ac9-480b-b49b-e1198c5e33e0":6.979960317460316,"e2d56e70-7eb7-495c-91b4-b11b127cd278":7.69285714285714,"e4047eee-fc9e-4f97-b354-64ef1d941719":6.558333333333332,"eda5c9f4-7ed3-4663-a1a0-15ec4828af4d":7.408862433862432,"ee99bfa9-086e-4d9a-9494-56a8281b8b78":8.059920634920635,"f09510a5-a108-46c3-917d-0d8d145c4a0e":9.077471139971138,"f3046808-ca07-4fb2-a8d5-9821b37e4f7b":10.768560606060607,"f3267c01-b670-4b7a-a3a5-79088c0d90ab":11.666468253968253,"f5a0a0a7-e045-4da5-815b-41964cffbaab":6.845833333333331,"f65a4365-2696-47f3-849b-501792da7e23":5.2662698412698425,"f85ab3f5-3596-4704-a57e-873e6e0a80a9":8.949841269841269,"fb2003f6-ed7b-424e-94b2-6b150f8e7302":8.67222222222222,"fc160e6d-da14-40c6-8b68-725aa841f6b2":9.257222222222222},"topic":["network","wmn","mesh","wireless","protocol"],"offsprings":["a2cd0e23-f184-441d-b90e-d4492a9ef508"]},"b944f77f-113b-4a02-ae5e-d4a124b8fd5b":{"authors":["David G. Lowe"],"references":["6018a516-8149-4bce-bc33-5449d86e58c2","60285266-7da2-474e-b05a-b380c836f665"],"_id":"b944f77f-113b-4a02-ae5e-d4a124b8fd5b","abstract":"This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance.","title":"Distinctive Image Features from Scale-Invariant Keypoints","venue":"International Journal of Computer Vision","year":2004,"__v":0,"citationCount":16229,"parents":{"00a4e16f-6b65-4ad2-bedc-b19d9cbc2cfe":9.67741935483871,"01a0f825-a308-455b-93fc-e62defc0e3b0":6.451612903225806,"035f8537-61a7-4c4f-b9fe-120f913a38b0":0,"03a42efa-a19c-4b19-a881-9c7ff63865ce":6.451612903225806,"05c3e696-6add-4b0d-b867-e6f1c98deb9b":0,"2fa2e5ba-11d3-4691-91e1-807b8ef7d8a5":0,"32d9eaee-c68f-4479-aa67-837d3cc91a05":3.225806451612903,"34758e0a-3def-447b-9c5e-e82a206426b5":0,"5437c0a0-8f20-49c3-86e5-9d860f3e4f04":9.67741935483871,"5dcd5949-faa9-4af3-8c6f-b285dd3b6566":3.225806451612903,"5f1992df-975f-49e7-bd88-aee0740317cf":12.903225806451612,"5f84f09f-7644-447c-89e1-8dc9ee334197":9.67741935483871,"6018a516-8149-4bce-bc33-5449d86e58c2":19.35483870967742,"60285266-7da2-474e-b05a-b380c836f665":12.903225806451612,"768eea6d-8e82-4bbf-8bdd-1f2338ded29f":0,"791e9257-d7a0-41fe-b471-bde48f3c4a04":9.67741935483871,"7ab7b36d-baae-4b21-89fc-69389fcabc44":6.451612903225806,"7b3f5f5b-a965-4656-9a6f-2f9740625176":6.451612903225806,"899de8c7-9cd9-4dd5-82f1-ad9acb801f8e":3.225806451612903,"a00704dc-a2fa-4267-b7a6-427167d99521":0,"a0fa7ae2-61e5-48a9-be10-86440416129f":3.225806451612903,"a748e0f4-ee6f-41ad-a2a5-1a5a6751086d":0,"b3e60214-b54c-4e8f-9315-a6975c760f4c":19.35483870967742,"b4685927-0ad9-466b-b2c6-2e1764475726":9.67741935483871,"c455fb04-4566-4648-ad6f-3cf2245e507c":3.225806451612903,"ccdefe89-9b16-4c22-8bb8-bd314ccad6e1":0,"d20995f6-529c-41c6-b75e-a169b005fb5c":3.225806451612903,"d9b9f667-9d8a-4723-a6c4-c19b941acd46":0,"df9fe96c-752e-49be-a8c4-8b098ab51e22":12.903225806451612,"ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d":9.67741935483871,"f6272ea9-0360-47ed-90a5-651ea958143f":6.451612903225806},"keyword":{"00a4e16f-6b65-4ad2-bedc-b19d9cbc2cfe":11.423452380952384,"01a0f825-a308-455b-93fc-e62defc0e3b0":12.697089947089946,"035f8537-61a7-4c4f-b9fe-120f913a38b0":11.241507936507938,"03a42efa-a19c-4b19-a881-9c7ff63865ce":10.871388888888887,"05c3e696-6add-4b0d-b867-e6f1c98deb9b":9.484444444444444,"2fa2e5ba-11d3-4691-91e1-807b8ef7d8a5":9.356746031746033,"32d9eaee-c68f-4479-aa67-837d3cc91a05":12.402539682539684,"34758e0a-3def-447b-9c5e-e82a206426b5":0,"5437c0a0-8f20-49c3-86e5-9d860f3e4f04":10.317936507936507,"5dcd5949-faa9-4af3-8c6f-b285dd3b6566":11.295634920634921,"5f1992df-975f-49e7-bd88-aee0740317cf":8.231746031746031,"5f84f09f-7644-447c-89e1-8dc9ee334197":10.756349206349205,"6018a516-8149-4bce-bc33-5449d86e58c2":12.432936507936507,"60285266-7da2-474e-b05a-b380c836f665":10.872420634920633,"768eea6d-8e82-4bbf-8bdd-1f2338ded29f":0,"791e9257-d7a0-41fe-b471-bde48f3c4a04":12.222366522366523,"7ab7b36d-baae-4b21-89fc-69389fcabc44":10.09563492063492,"7b3f5f5b-a965-4656-9a6f-2f9740625176":10.936243386243387,"899de8c7-9cd9-4dd5-82f1-ad9acb801f8e":10.01521164021164,"a00704dc-a2fa-4267-b7a6-427167d99521":8.249206349206348,"a0fa7ae2-61e5-48a9-be10-86440416129f":11.963650793650793,"a748e0f4-ee6f-41ad-a2a5-1a5a6751086d":12.921190476190478,"b3e60214-b54c-4e8f-9315-a6975c760f4c":13.356990231990228,"b4685927-0ad9-466b-b2c6-2e1764475726":11.101031746031747,"c455fb04-4566-4648-ad6f-3cf2245e507c":11.612777777777776,"ccdefe89-9b16-4c22-8bb8-bd314ccad6e1":12.856746031746033,"d20995f6-529c-41c6-b75e-a169b005fb5c":0,"d9b9f667-9d8a-4723-a6c4-c19b941acd46":9.791309523809522,"df9fe96c-752e-49be-a8c4-8b098ab51e22":9.468015873015872,"ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d":9.631560846560847,"f6272ea9-0360-47ed-90a5-651ea958143f":0},"topic":["featur","object","match","recognit","perform"],"groups":[{"authors":["Krystian Mikolajczyk","Andrew Zisserman","Cordelia Schmid"],"references":["27dfa95c-90d4-4d56-b987-0d2721b4b9b0","2958fc5c-15e8-45e7-8da8-d2e0fa46f0c7","34758e0a-3def-447b-9c5e-e82a206426b5","509e1ae2-768b-4417-bebe-d90cf1e0fdae","5149d3c0-5ac9-47ba-9fb0-3d2ef757b0e8","5ebbd1f5-dfe5-4eec-9883-b8b5efea366c","5f1992df-975f-49e7-bd88-aee0740317cf","5f84f09f-7644-447c-89e1-8dc9ee334197","6018a516-8149-4bce-bc33-5449d86e58c2","60285266-7da2-474e-b05a-b380c836f665","613841ae-c925-4aee-9c2e-8675213e4bbf","6fe37c18-8dc5-4baa-b6e0-5546353907bb","7283fa2b-1f6a-4138-a3da-4bf69809a1a9","75c6e7ad-f17c-40e1-8c39-965534096b2b","937cc256-e6e2-4bfa-928b-52f01cd416f4","97df7134-9cbf-43ea-9809-472115004999","a0be9da4-c423-4f87-a387-822fe304aa03","b1a8637d-9b27-4128-8c10-364a38230afc","b592576f-ff29-4a68-9b2f-8a8ad02e9c70","c591c440-b19b-4d7b-b067-cd8c366b7d6d","ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d"],"_id":"b3e60214-b54c-4e8f-9315-a6975c760f4c","abstract":"In this paper we describe an approach to recognizing poorly textured objects, that may contain holes and tubular parts, in cluttered scenes under arbitrary viewing conditions. To this end we develop a number of novel components. First, we introduce a new edge-based local feature detector that is invariant to similarity transformations. The features are localized on edges and a neighbourhood is estimated in a scale invariant manner. Second, the neighbourhood descriptor computed for foreground features is not affected by background clutter, even if the feature is on an object boundary. Third, the descriptor generalizes Lowe's SIFT method to edges. An object model is learnt from a single training image. The object is then recognized in new images in a series of steps which apply progressively tighter geometric restrictions. A final contribution of this work is to allow sufficient flexibility in the geometric representation that objects in the same visual class can be recognized. Results are demonstrated for various object classes including bikes and rackets.","title":"Shape recognition with edge-based features.","venue":"british machine vision conference","year":2003,"__v":0,"citationCount":91}],"offsprings":["50252efa-a843-4cc6-a591-22f527ee3d6c","6c38b3b4-7562-493d-a40c-fe70abf039a7","dd83785a-dd19-41e3-9b25-ebabbd48d336","f2d49150-35de-4fd5-ac46-eb071d1cc73e","8d8e7d51-3223-4776-bf6a-40306774b8a1","83c737b8-e084-4766-ba6e-131e6a1c017c","176a7436-78ea-4c2a-82e6-7930ab023bd1","2b6a3d0f-368f-45bb-be23-4e82f62fbbf7","f225f439-4389-4312-a503-f8c1b0aa02de","3ed17ffd-b416-470a-973a-77d7085a3503"]},"bac5da35-9009-41a3-b758-21aec812a9ee":{"authors":["David H. Wolpert","William G. Macready"],"references":[],"_id":"bac5da35-9009-41a3-b758-21aec812a9ee","abstract":"A framework is developed to explore the connection between effective optimization algorithms and the problems they are solving. A number of \"no free lunch\" (NFL) theorems are presented which establish that for any algorithm, any elevated performance over one class of problems is offset by performance over another class. These theorems result in a geometric interpretation of what it means for an algorithm to be well suited to an optimization problem. Applications of the NFL theorems to information-theoretic aspects of optimization and benchmark measures of performance are also presented. Other issues addressed include time-varying optimization problems and a priori \"head-to-head\" minimax distinctions between optimization algorithms, distinctions that result despite the NFL theorems' enforcing of a type of uniformity over all algorithms.","title":"No free lunch theorems for optimization","venue":"IEEE Transactions on Evolutionary Computation","year":1997,"__v":0,"citationCount":1816,"parents":{"09418cce-2efd-4786-9c35-0b182af22b71":0,"1e4e8925-3328-4af5-be88-56eef2f6aa8f":0,"a4ad4808-e7c3-4470-8c43-d6862a42bc8e":0},"keyword":{"09418cce-2efd-4786-9c35-0b182af22b71":10.9484126984127,"1e4e8925-3328-4af5-be88-56eef2f6aa8f":10.983597883597884,"a4ad4808-e7c3-4470-8c43-d6862a42bc8e":12.238492063492064},"topic":["optim","algorithm","theorem","problem","perform"],"offsprings":["23dc6e53-9579-4198-bb00-dedfd3e6071b"]},"bf03f268-de9d-4a80-aee1-200990056503":{"authors":["Timothy F. Cootes","G. Edwards","Christopher J. Taylor"],"references":["923f5d0a-23a3-4fb1-bee7-ec72122709a4"],"_id":"bf03f268-de9d-4a80-aee1-200990056503","abstract":"We describe a new method of matching statistical models of appearance to images. A set of model parameters control modes of shape and gray-level variation learned from a training set. We construct an efficient iterative matching algorithm by learning the relationship between perturbations in the model parameters and the induced image errors.","title":"Active appearance models","venue":"IEEE Transactions on Pattern Analysis and Machine Intelligence","year":2001,"__v":0,"citationCount":2362,"parents":{"13c491a8-d910-4451-9cc9-fe4a8033976b":7.6923076923076925,"1b2ca840-c231-4d15-b1d5-09fd8d61400c":7.6923076923076925,"1ba94a3f-ba8a-4aff-8151-3a855803711c":0,"1d150ea3-d6c0-4c75-822f-433639a7dbcc":0,"45521624-faa8-4fed-a2e1-fdcdf96a7c56":38.46153846153847,"504af9f2-1981-4066-b835-1b69f6536b0f":30.76923076923077,"700061b6-54a5-4f50-a1ef-1d8de3015c43":7.6923076923076925,"7cdaaa8a-8ddc-4ccd-89b0-d85ff20c41b7":23.076923076923077,"923f5d0a-23a3-4fb1-bee7-ec72122709a4":0,"9a342fc2-984f-443e-9597-99b3432afbd0":7.6923076923076925,"ae66f3ec-b67d-4193-bb89-a19576fe3eb2":0,"ae9fd662-5816-4bc6-8cdf-390d15c2d6f2":0,"f6f9c3fa-6575-4408-ac39-3c7431c5a818":23.076923076923077},"keyword":{"13c491a8-d910-4451-9cc9-fe4a8033976b":9.477460317460316,"1b2ca840-c231-4d15-b1d5-09fd8d61400c":11.70095238095238,"1ba94a3f-ba8a-4aff-8151-3a855803711c":9.965079365079365,"1d150ea3-d6c0-4c75-822f-433639a7dbcc":9.556613756613755,"45521624-faa8-4fed-a2e1-fdcdf96a7c56":10.541005291005288,"504af9f2-1981-4066-b835-1b69f6536b0f":10.487460317460314,"700061b6-54a5-4f50-a1ef-1d8de3015c43":9.633333333333331,"7cdaaa8a-8ddc-4ccd-89b0-d85ff20c41b7":9.390476190476189,"923f5d0a-23a3-4fb1-bee7-ec72122709a4":11.108888888888888,"9a342fc2-984f-443e-9597-99b3432afbd0":8.910317460317462,"ae66f3ec-b67d-4193-bb89-a19576fe3eb2":0,"ae9fd662-5816-4bc6-8cdf-390d15c2d6f2":11.046190476190473,"f6f9c3fa-6575-4408-ac39-3c7431c5a818":10.683703703703703},"topic":["model","set","paramet","match","learn"],"groups":[{"authors":["G. Edwards","Timothy F. Cootes","Christopher J. Taylor"],"references":["00909251-9935-44f3-94a1-629023b5015b","137456ad-4f9c-4083-9e2a-362b21248976","5f9f2346-d1e3-4716-a8af-8c14f1490e00","700061b6-54a5-4f50-a1ef-1d8de3015c43","923f5d0a-23a3-4fb1-bee7-ec72122709a4","ae66f3ec-b67d-4193-bb89-a19576fe3eb2","ae9fd662-5816-4bc6-8cdf-390d15c2d6f2","c38bddce-cba4-4096-92d7-07b248df5979","f6f9c3fa-6575-4408-ac39-3c7431c5a818"],"_id":"45521624-faa8-4fed-a2e1-fdcdf96a7c56","abstract":"We present a new framework for interpreting face images and image sequences using an Active Appearance Model (AAM). The AAM contains a statistical, photo-realistic model of the shape and grey-level appearance of faces. This paper demonstrates the use of the AAM's efficient iterative matching scheme for image interpretation. We use the AAM as a basis for face recognition, obtain good results for difficult images. We show how the AAM framework allows identity information to be decoupled from other variation, allowing evidence of identity to be integrated over a sequence. The AAM approach makes optimal use of the evidence from either a single image or image sequence. Since we derive a complete description of a given image our method can be used as the basis for a range of face image interpretation tasks.","title":"Face Recognition Using Active Appearance Models","venue":"european conference on computer vision","year":1998,"__v":0,"citationCount":151},{"authors":["M. La Cascia","Stan Sclaroff","Vassilis Athitsos"],"references":["019fb6c8-c81b-4ef9-94be-18083093da48","13c491a8-d910-4451-9cc9-fe4a8033976b","15d1e544-36a4-454a-94c3-1dd11098a36d","1ba94a3f-ba8a-4aff-8151-3a855803711c","1d150ea3-d6c0-4c75-822f-433639a7dbcc","25628852-b94d-441b-b3ad-0457653b60ae","2da8025a-06d3-41f6-8b93-917219ad9792","31b6a50a-c6ec-421d-965c-43b1df24b8f2","37e37831-6d5d-4093-99d4-95e1901629ac","3a2861b4-a6f7-4ab0-9f88-480006b53bb0","4423e524-cda6-4d7b-a81f-1fad66125b04","4e66dcf4-0228-4e26-9219-3d026b66698d","528f4f4d-7995-48ca-8e9a-83182d9d1c36","57eadb55-c2fa-42e1-a0c4-9da5e1658ff9","6300a64b-4e61-472d-8e92-4daaf85c2163","644bec95-ebd2-4f36-91a3-83ff08b24c9f","64fa74e8-db02-4190-87d7-bf23e9859a7c","6c8e9a18-6101-42a2-b97b-083ee288c431","6e8cc926-79a1-4676-a2bd-f9d49f3144cf","74ffdb73-6e2b-455d-bdf0-d089daad8329","843a8154-e055-43a8-abc6-0f441eb8cc49","91f6094c-f0e1-45ac-b887-89d5c09aa3d2","b5c70352-d0a3-4a6b-b961-ed59491ad43f","c97a48bf-396c-4c73-af34-feab9f4039d5","d6e37fb1-5f7e-448e-847b-7d1f1271c574","da19c758-4c30-472b-91e4-3ef0c4b8270f","f2c8158c-ff5d-43dd-872e-9b52caa02597","fc3749ea-d66b-4bcd-929a-02a4e1ad3f7d"],"_id":"7cdaaa8a-8ddc-4ccd-89b0-d85ff20c41b7","abstract":"A technique for 3D head tracking under varying illumination is proposed. The head is modeled as a texture mapped cylinder. Tracking is formulated as an image registration problem in the cylinder's texture map image. The resulting dynamic texture map provides a stabilized view of the face that can be used as input to many existing 2D techniques for face recognition, facial expressions analysis, lip reading, and eye tracking. To solve the registration problem with lighting variation and head motion, the residual registration error is modeled as a linear combination of texture warping templates and orthogonal illumination templates. Fast stable online tracking is achieved via regularized weighted least-squares error minimization. The regularization tends to limit potential ambiguities that arise in the warping and illumination templates. It enables stable tracking over extended sequences. Tracking does not require a precise initial model fit; the system is initialized automatically using a simple 2D face detector. It is assumed that the target is facing the camera in the first frame. The formulation uses texture mapping hardware. The nonoptimized implementation runs at about 15 frames per second on a SGI O2 graphic workstation. Extensive experiments evaluating the effectiveness of the formulation are reported. The sensitivity of the technique to illumination, regularization parameters, errors in the initial positioning, and internal camera parameters are analyzed. Examples and applications of tracking are reported.","title":"Fast, reliable head tracking under varying illumination: an approach based on registration of texture-mapped 3D models","venue":"IEEE Transactions on Pattern Analysis and Machine Intelligence","year":2000,"__v":0,"citationCount":324},{"authors":["G. Edwards","Andreas Lanitis","Christopher J. Taylor","Timothy F. Cootes"],"references":["00909251-9935-44f3-94a1-629023b5015b","019fb6c8-c81b-4ef9-94be-18083093da48","0aaed614-9b84-43c5-af94-9cf7d8224251","0e8b9fa7-733c-4434-8244-c0a101c0c978","137456ad-4f9c-4083-9e2a-362b21248976","13769a56-92cf-4920-8428-9549926b7ffc","291bceb3-9d76-46ce-b9ea-5dbef5dc2560","3b3d7569-08b1-4017-9910-2a017a00e43e","46bf03a3-2f99-43f5-8e3b-5505faa0aebd","56f4b72a-ec39-47ac-8220-899296e7fb18","5f9f2346-d1e3-4716-a8af-8c14f1490e00","62157500-e397-46f1-93be-5b215ddbc092","644bec95-ebd2-4f36-91a3-83ff08b24c9f","64fa74e8-db02-4190-87d7-bf23e9859a7c","6d4dd8a3-a299-4f19-8852-eff3fa729758","700061b6-54a5-4f50-a1ef-1d8de3015c43","85114f9d-70a8-4940-83aa-af504b75acf8","923f5d0a-23a3-4fb1-bee7-ec72122709a4","94a0b002-578e-4581-ad1d-8fc52a7052ea","9b9c96fb-f880-49fd-bdae-651407dc2e30","9be82f37-3656-4bb8-bfea-b9f399593807","a1f1edad-49c5-46f6-a3db-8bbe9e6613b9","ae66f3ec-b67d-4193-bb89-a19576fe3eb2","ef50568a-329a-42d8-bb6b-3e10f34ca75a","f5cba99d-69df-4916-b907-ff6f8fa0b593"],"_id":"f6f9c3fa-6575-4408-ac39-3c7431c5a818","abstract":"Model-based approaches to the interpretation of face images have proved very successful. We have previously described statistically based models of face shape and grey-level appearance and shown how they can be used to perform various coding and interpretation tasks. In the paper we describe improved methods of modelling which couple shape and grey-level information more directly than our existing methods, isolate the changes in appearance due to different sources of variability (person, expression, pose, lighting) and deal with non-linear shape variation. We show that the new methods are better suited to interpretation and tracking tasks.","title":"Statistical models of face images - improving specificity","venue":"Image and Vision Computing","year":1998,"__v":0,"citationCount":63},{"authors":["G. Edwards","Christopher J. Taylor","Timothy F. Cootes"],"references":["0c74037a-2723-4134-b0a6-3ddef3bc15c8","13c491a8-d910-4451-9cc9-fe4a8033976b","5a4024a0-43d3-4cb8-864a-6f1b0bfd4437","700061b6-54a5-4f50-a1ef-1d8de3015c43","97571808-28e5-400a-8793-5ca824c4fc6e","ae66f3ec-b67d-4193-bb89-a19576fe3eb2","ae9fd662-5816-4bc6-8cdf-390d15c2d6f2","e6c03ded-e92c-4a46-b647-f9011b04eb71"],"_id":"504af9f2-1981-4066-b835-1b69f6536b0f","abstract":"We demonstrate a fast, robust method of interpreting face images using an Active Appearance Model (AAM). An AAM contains a statistical model of shape and grey level appearance which can generalise to almost any face. Matching to an image involves finding model parameters which minimise the difference between the image and a synthesised face. We observe that displacing each model parameter from the correct value induces a particular pattern in the residuals. In a training phase, the AAM learns a linear model of the correlation between parameter displacements and the induced residuals. During search it measures the residuals and uses this model to correct the current parameters, leading to a better fit. A good overall match is obtained in a few iterations, even from poor starting estimates. We describe the technique in detail and show it matching to new face images.","title":"Interpreting face images using active appearance models","venue":"ieee international conference on automatic face and gesture recognition","year":1998,"__v":0,"citationCount":220}],"offsprings":["5e8b0e8a-d687-4333-bfe9-73b4c1bebde5","f2d49150-35de-4fd5-ac46-eb071d1cc73e","32d158dc-6f9f-426a-973b-8edc5e4c5dad","3ed17ffd-b416-470a-973a-77d7085a3503"]},"c186e8f6-42e1-4bb8-8fe3-039e0cd02532":{"authors":["Tomas Mikolov","Ilya Sutskever","Kai Chen","Gregory S. Corrado","Jeffrey Dean"],"references":["12f40b38-cd99-4801-8074-d765a29a2101"],"_id":"c186e8f6-42e1-4bb8-8fe3-039e0cd02532","abstract":"The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alternative to the hierarchical softmax called negative sampling.#R##N##R##N#An inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases. For example, the meanings of \"Canada\" and \"Air\" cannot be easily combined to obtain \"Air Canada\". Motivated by this example, we present a simple method for finding phrases in text, and show that learning good vector representations for millions of phrases is possible.","title":"Distributed Representations of Words and Phrases and their Compositionality","venue":"neural information processing systems","year":2013,"__v":0,"citationCount":1828,"parents":{"033f5f9b-d487-49dc-b4a0-aef9b9433d19":22.22222222222222,"0df95054-6f57-4e89-9c50-1b9dd870a263":11.11111111111111,"12f40b38-cd99-4801-8074-d765a29a2101":55.55555555555556,"357628ef-a0a2-4821-b2f8-d8f47b46cb1e":11.11111111111111,"40cdb454-de56-41a3-a2da-a6f47f5f7ba0":16.666666666666664,"47e20669-55b1-4e50-9ef2-e9f0496ce79a":0,"54554fcd-dd8c-457a-8f80-33dd5a0a5648":38.88888888888889,"59a820d9-abc9-456c-846d-992eb80943b6":0,"6666464e-18c5-4fa6-95f7-b8fa84a097a3":5.555555555555555,"77b79c16-03f5-4c75-994e-38a9e0cc7bfe":11.11111111111111,"7aa454b2-47c6-4117-b823-1df65289e8e7":0,"8e39b3d3-dda8-4f1f-98bd-5d6b5141ad23":0,"998e48b9-7d74-42c5-ac15-a0cd80c345b0":22.22222222222222,"bc1cf646-43d9-4fb8-a1ce-c8f5ea5c18b9":5.555555555555555,"d0bbf973-4708-42b7-a2a0-04b564023015":27.77777777777778,"d2bb63e7-e65b-4a14-a9bb-1cf87e0c692f":5.555555555555555,"f7ed80ad-be57-45ca-82d5-4ace810eed95":16.666666666666664,"fec1b0f3-30d2-4877-8db9-2844eb9f8e2e":11.11111111111111},"keyword":{"033f5f9b-d487-49dc-b4a0-aef9b9433d19":11.384656084656084,"0df95054-6f57-4e89-9c50-1b9dd870a263":9.01335978835979,"12f40b38-cd99-4801-8074-d765a29a2101":10.498412698412698,"357628ef-a0a2-4821-b2f8-d8f47b46cb1e":10.403174603174604,"40cdb454-de56-41a3-a2da-a6f47f5f7ba0":8.416005291005291,"47e20669-55b1-4e50-9ef2-e9f0496ce79a":9.021005291005292,"54554fcd-dd8c-457a-8f80-33dd5a0a5648":9.445,"59a820d9-abc9-456c-846d-992eb80943b6":8.329629629629629,"6666464e-18c5-4fa6-95f7-b8fa84a097a3":0,"77b79c16-03f5-4c75-994e-38a9e0cc7bfe":10.814692159692157,"7aa454b2-47c6-4117-b823-1df65289e8e7":11.657407407407405,"8e39b3d3-dda8-4f1f-98bd-5d6b5141ad23":9.701058201058201,"998e48b9-7d74-42c5-ac15-a0cd80c345b0":11.895502645502644,"bc1cf646-43d9-4fb8-a1ce-c8f5ea5c18b9":7.735185185185186,"d0bbf973-4708-42b7-a2a0-04b564023015":11.725925925925926,"d2bb63e7-e65b-4a14-a9bb-1cf87e0c692f":0,"f7ed80ad-be57-45ca-82d5-4ace810eed95":11.655555555555555,"fec1b0f3-30d2-4877-8db9-2844eb9f8e2e":9.166666666666664},"topic":["word","represent","vector","phrase","learn"],"groups":[{"authors":["Tomas Mikolov","Anoop Deoras","Daniel Povey","Lukas Burget","Jan Cernocky"],"references":["0df95054-6f57-4e89-9c50-1b9dd870a263","111a25a1-44ca-44fb-bca8-51e8157463d3","2024cecc-3c3a-4ed6-abb5-011633f2f3fe","393d1887-e68a-4fa8-b01e-8e41fce2f866","40c1f32d-2e92-4172-a714-db0efed14973","61d3f2f6-1b70-4630-bb62-5d3961e1340e","6666464e-18c5-4fa6-95f7-b8fa84a097a3","75e639dd-3cdb-452f-b5e8-60677f3f7c94","7aa454b2-47c6-4117-b823-1df65289e8e7","7ff7b392-bab1-4a61-a47a-fb9a79e8297e","88103971-d06c-4f2b-9338-e16c51ff5632","967cfa49-e7cc-420c-be14-8f6ac66e1655","a0a2060c-3c21-42c8-bab4-044a1c3461ad","a98bf926-765e-43e9-9c61-1c213692a258","b241b294-4de6-4424-affc-f5fa268939fd","c4ce3e24-58a6-46f1-975e-9209228cdc6f","c6a882d8-dc37-4e7b-b36f-74f48a370f65","cfc571c4-574d-4835-ac41-ead585c71d29","d0d18692-434c-4c7a-b4d8-33ff328f3e3e","fec1b0f3-30d2-4877-8db9-2844eb9f8e2e"],"_id":"033f5f9b-d487-49dc-b4a0-aef9b9433d19","abstract":"We describe how to effectively train neural network based language models on large data sets. Fast convergence during training and better overall performance is observed when the training data are sorted by their relevance. We introduce hash-based implementation of a maximum entropy model, that can be trained as a part of the neural network model. This leads to significant reduction of computational complexity. We achieved around 10% relative reduction of word error rate on English Broadcast News speech recognition task, against large 4-gram model trained on 400M tokens.","title":"Strategies for training large scale neural network language models","venue":"ieee automatic speech recognition and understanding workshop","year":2011,"__v":0,"citationCount":95},{"authors":["Tomas Mikolov","Kai Chen","Greg Corrado","Jeffrey Dean"],"references":["033f5f9b-d487-49dc-b4a0-aef9b9433d19","0ab80338-6f6b-4322-b7a1-c90bd7eaa5e8","0df95054-6f57-4e89-9c50-1b9dd870a263","19c0e5d2-d5f3-4bd4-aba1-e9e975a9b580","2ef8d7bb-3451-49fe-ba1d-70dc6a9786ab","31b724c0-ae79-4477-ab75-3b62e2133bdb","3ba1f3f1-7616-46bf-8857-1f5dbafd45d5","47e20669-55b1-4e50-9ef2-e9f0496ce79a","54554fcd-dd8c-457a-8f80-33dd5a0a5648","6666464e-18c5-4fa6-95f7-b8fa84a097a3","77b79c16-03f5-4c75-994e-38a9e0cc7bfe","7aa454b2-47c6-4117-b823-1df65289e8e7","88103971-d06c-4f2b-9338-e16c51ff5632","967cfa49-e7cc-420c-be14-8f6ac66e1655","998e48b9-7d74-42c5-ac15-a0cd80c345b0","9ae57829-6d27-49e0-92bf-32e43c35f2e0","a28cc94c-15a1-4c90-866c-f97f3f86cb20","cfc571c4-574d-4835-ac41-ead585c71d29","d0bbf973-4708-42b7-a2a0-04b564023015","d34584d4-44fd-4172-a54b-ec903cbe1584","e45a03a2-923b-40d7-8ad9-f60b0fe9c5f8","f26a8a8a-9ad6-4dc1-8ae2-a59be1f80267","f8af71de-30f9-4288-a169-13ab19bf89fb","fec1b0f3-30d2-4877-8db9-2844eb9f8e2e"],"_id":"12f40b38-cd99-4801-8074-d765a29a2101","abstract":"We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.","title":"Efficient Estimation of Word Representations in Vector Space","venue":"arXiv: Computation and Language","year":2013,"__v":0,"citationCount":1585},{"authors":["Tomas Mikolov","Wen-tau Yih","Geoffrey Zweig"],"references":["033f5f9b-d487-49dc-b4a0-aef9b9433d19","0ab80338-6f6b-4322-b7a1-c90bd7eaa5e8","0df95054-6f57-4e89-9c50-1b9dd870a263","1035d56c-06b3-40bb-93c7-6306b24bac93","312c1b21-3869-482d-92e9-a1fa7f32d871","51f1493d-ce3b-4589-8373-55940026fecd","6666464e-18c5-4fa6-95f7-b8fa84a097a3","68d3ca1d-f8f5-4910-a55e-19c384a4ab03","7aa454b2-47c6-4117-b823-1df65289e8e7","903c64fd-faea-4997-b1d4-2598fe4f9446","967cfa49-e7cc-420c-be14-8f6ac66e1655","a0a2060c-3c21-42c8-bab4-044a1c3461ad","ac14afe6-de4d-4056-b2ac-0f6e36f369a2","cfc571c4-574d-4835-ac41-ead585c71d29","e8528559-d600-4dcb-8438-4e291b93fbb4","f130610a-d6d8-4001-964b-8d4e5333b65f"],"_id":"998e48b9-7d74-42c5-ac15-a0cd80c345b0","abstract":"Continuous space language models have recently demonstrated outstanding results across a variety of tasks. In this paper, we examine the vector-space word representations that are implicitly learned by the input-layer weights. We find that these representations are surprisingly good at capturing syntactic and semantic regularities in language, and that each relationship is characterized by a relation-specific vector offset. This allows vector-oriented reasoning based on the offsets between words. For example, the male/female relationship is automatically learned, and with the induced vector representations, “King Man + Woman” results in a vector very close to “Queen.” We demonstrate that the word vectors capture syntactic regularities by means of syntactic analogy questions (provided with this paper), and are able to correctly answer almost 40% of the questions. We demonstrate that the word vectors capture semantic regularities by using the vector offset method to answer SemEval-2012 Task 2 questions. Remarkably, this method outperforms the best previous systems.","title":"Linguistic Regularities in Continuous Space Word Representations","venue":"north american chapter of the association for computational linguistics","year":2013,"__v":0,"citationCount":438},{"authors":["Joseph P. Turian","Lev-Arie Ratinov","Yoshua Bengio"],"references":["017a5844-664a-410a-9adf-50c1fdae5895","0b1f5092-4b64-4d5e-8bf7-15295db41f4f","131f2b3b-adf0-41af-a84f-b0941e93ffeb","1e6f4b1f-7bfe-4b8c-9a60-c9f0bea232f7","281f79f4-729c-4cbb-9793-18b21a4b4315","47e20669-55b1-4e50-9ef2-e9f0496ce79a","4a29e0cd-d551-48f2-9cc3-193f9b7c4cfa","4ffd7d10-c575-40e6-a814-0bb4590c8ecb","5347be4c-bbac-4674-83b8-60dd8175588c","558dee29-ba49-4949-bbb8-ac8bb76541fd","58bb3a79-ab62-4d7d-ba89-2be701314cfc","5f4627e0-5d97-43b2-bce3-1ee1f3e2edc9","6666464e-18c5-4fa6-95f7-b8fa84a097a3","69df0789-a06f-4166-9c34-93047de2673d","6e476858-35d3-49b4-a164-a578b30a1a4a","77b79c16-03f5-4c75-994e-38a9e0cc7bfe","7aa454b2-47c6-4117-b823-1df65289e8e7","967cfa49-e7cc-420c-be14-8f6ac66e1655","9cb3b11c-4d43-4cce-92cb-a886510c94bd","b46fdfbf-a80e-407d-b2b0-ad6872b0ac77","bc1cf646-43d9-4fb8-a1ce-c8f5ea5c18b9","c4042c31-dc3f-41c4-94d9-61e00c4e5b1b","c8949213-75b6-4238-a17c-a5b13597b5d2","cb52a956-2990-4c3d-8cd0-d6a5a581a124","d0d18692-434c-4c7a-b4d8-33ff328f3e3e","d338cf1b-865d-4ed3-b430-3bfa393eddfd","d6180de9-bf4c-4a20-ac58-bba3c01353bc","f06e7fdb-8cbf-4b3f-aaca-807af12c0d70","f3a20c90-cedd-48a9-b773-52170b398931","f8af71de-30f9-4288-a169-13ab19bf89fb","ffd59f06-8287-49cc-8dd6-d1e0a4cadb3a"],"_id":"d0bbf973-4708-42b7-a2a0-04b564023015","abstract":"If we take an existing supervised NLP system, a simple and general way to improve accuracy is to use unsupervised word representations as extra word features. We evaluate Brown clusters, Collobert and Weston (2008) embeddings, and HLBL (Mnih & Hinton, 2009) embeddings of words on both NER and chunking. We use near state-of-the-art supervised baselines, and find that each of the three word representations improves the accuracy of these baselines. We find further improvements by combining different word representations. You can download our word features, for off-the-shelf use in existing NLP systems, as well as our code, here: http://metaoptimize.com/projects/wordreprs/","title":"Word Representations: A Simple and General Method for Semi-Supervised Learning","venue":"meeting of the association for computational linguistics","year":2010,"__v":0,"citationCount":565},{"authors":["Andriy Mnih","Yee Whye Teh"],"references":["01f443e7-ea4c-48a7-8081-745c3fa62769","17c02aa7-8aab-435a-8a86-7c0762fa1f41","357628ef-a0a2-4821-b2f8-d8f47b46cb1e","47e20669-55b1-4e50-9ef2-e9f0496ce79a","4eec767c-9f1d-49e4-a329-8f8c57a1421a","5317fbe4-f12c-414c-93e3-2bb094131ddd","6666464e-18c5-4fa6-95f7-b8fa84a097a3","77b79c16-03f5-4c75-994e-38a9e0cc7bfe","7aa454b2-47c6-4117-b823-1df65289e8e7","88103971-d06c-4f2b-9338-e16c51ff5632","8e39b3d3-dda8-4f1f-98bd-5d6b5141ad23","967cfa49-e7cc-420c-be14-8f6ac66e1655","9cb3b11c-4d43-4cce-92cb-a886510c94bd","b241b294-4de6-4424-affc-f5fa268939fd","bee4b074-8873-423a-8351-996134b99621","bef405c3-0ed8-476e-890f-d7d8603535cf","cfc571c4-574d-4835-ac41-ead585c71d29","d0bbf973-4708-42b7-a2a0-04b564023015","e1d4b584-e576-484f-a17c-36918cd19162","f8af71de-30f9-4288-a169-13ab19bf89fb"],"_id":"54554fcd-dd8c-457a-8f80-33dd5a0a5648","abstract":"In spite of their superior performance, neural probabilistic language models (NPLMs) remain far less widely used than n-gram models due to their notoriously long training times, which are measured in weeks even for moderately-sized datasets. Training NPLMs is computationally expensive because they are explicitly normalized, which leads to having to consider all words in the vocabulary when computing the log-likelihood gradients.#R##N##R##N#We propose a fast and simple algorithm for training NPLMs based on noise-contrastive estimation, a newly introduced procedure for estimating unnormalized continuous distributions. We investigate the behaviour of the algorithm on the Penn Treebank corpus and show that it reduces the training times by more than an order of magnitude without affecting the quality of the resulting models. The algorithm is also more efficient and much more stable than importance sampling because it requires far fewer noise samples to perform well.#R##N##R##N#We demonstrate the scalability of the proposed approach by training several neural language models on a 47M-word corpus with a 80K-word vocabulary, obtaining state-of-the-art results on the Microsoft Research Sentence Completion Challenge dataset.","title":"A fast and simple algorithm for training neural probabilistic language models","venue":"international conference on machine learning","year":2012,"__v":0,"citationCount":123}],"offsprings":[]},"c1b6b493-01ef-420f-be44-7bacfe34e846":{"authors":["Chih-Chung Chang","Chih-Jen Lin"],"references":["50dd56db-151d-4d62-8576-65f0ef6f381b","feff8862-f47d-4591-a7cb-b62d7efc81a2"],"_id":"c1b6b493-01ef-420f-be44-7bacfe34e846","abstract":"LIBSVM is a library for Support Vector Machines (SVMs). We have been actively developing this package since the year 2000. The goal is to help users to easily apply SVM to their applications. LIBSVM has gained wide popularity in machine learning and many other areas. In this article, we present all implementation details of LIBSVM. Issues such as solving SVM optimization problems theoretical convergence multiclass classification probability estimates and parameter selection are discussed in detail.","title":"LIBSVM: A library for support vector machines","venue":"ACM Transactions on Intelligent Systems and Technology","year":2011,"__v":0,"citationCount":13475,"parents":{"036a2a1b-8729-431d-b260-3d6b33c6c6a4":20.689655172413794,"078b095c-7687-43f2-a0bf-30ea78f787db":0,"11f27d27-6bd9-4691-834e-9864871a65f4":17.24137931034483,"1f556c88-b553-4c75-b243-92d8200f8149":0,"2d768672-0070-4a38-87c8-f0cce1dd2f44":0,"33184e74-4574-4856-a969-e497fdc2fec8":10.344827586206897,"41087d29-5163-4a9f-b55a-3f407b8a040d":17.24137931034483,"4317334f-595f-45be-a095-efe8f258b558":31.03448275862069,"50dd56db-151d-4d62-8576-65f0ef6f381b":3.4482758620689653,"5ffac6f9-2456-42cf-830c-9049ce37c899":6.896551724137931,"633e2247-d487-4ae7-b6ab-a17a075b83aa":17.24137931034483,"7c6a970a-0d6f-4e4b-b50e-6c6fbd23a9ab":10.344827586206897,"7f03746d-ba06-4b34-828e-683192e9ee42":10.344827586206897,"8b26f4a9-380f-432d-aea1-66a86ce407e8":3.4482758620689653,"8c0ec27c-e654-4e0e-8c49-9b427117a98e":3.4482758620689653,"90925435-d33a-4abd-892d-abbe52e547c4":13.793103448275861,"92a420a1-f54b-4cdd-b5a4-2669ac2e7c5d":37.93103448275862,"962d4022-ff67-4067-a544-828604d8db52":17.24137931034483,"9764de87-e34e-4ea1-8de3-12d9bffc4f55":17.24137931034483,"97bfd03c-335a-4f39-89d3-cf0a22769383":44.827586206896555,"a2e5c222-c380-42d7-8846-cbc232f46a69":27.586206896551722,"a5d347a7-9984-45f4-821e-df7356477185":24.137931034482758,"b532d930-ad51-4a05-9c5c-9a75d6b021a2":0,"b90f9310-726f-4116-9322-6fc01ab598fd":0,"bb693c93-e418-46ea-8b38-9c53df27bdf2":0,"cdbd2ef9-d4b1-4dff-9037-3ea84627424d":0,"dd5a3ef5-9d44-4dde-bcdb-dc4d17c69073":13.793103448275861,"f006e236-59ad-4647-a59f-4f46dc2c85be":0,"feff8862-f47d-4591-a7cb-b62d7efc81a2":13.793103448275861},"keyword":{"036a2a1b-8729-431d-b260-3d6b33c6c6a4":9.28111111111111,"078b095c-7687-43f2-a0bf-30ea78f787db":8.478174603174603,"11f27d27-6bd9-4691-834e-9864871a65f4":9.118518518518517,"1f556c88-b553-4c75-b243-92d8200f8149":10.02111111111111,"2d768672-0070-4a38-87c8-f0cce1dd2f44":0,"33184e74-4574-4856-a969-e497fdc2fec8":7.679999999999999,"41087d29-5163-4a9f-b55a-3f407b8a040d":8.011904761904761,"4317334f-595f-45be-a095-efe8f258b558":7.838888888888889,"50dd56db-151d-4d62-8576-65f0ef6f381b":10.326117216117215,"5ffac6f9-2456-42cf-830c-9049ce37c899":8.537698412698411,"633e2247-d487-4ae7-b6ab-a17a075b83aa":0,"7c6a970a-0d6f-4e4b-b50e-6c6fbd23a9ab":9.070185185185185,"7f03746d-ba06-4b34-828e-683192e9ee42":7.694444444444445,"8b26f4a9-380f-432d-aea1-66a86ce407e8":7.46547619047619,"8c0ec27c-e654-4e0e-8c49-9b427117a98e":9.826666666666664,"90925435-d33a-4abd-892d-abbe52e547c4":6.368121693121693,"92a420a1-f54b-4cdd-b5a4-2669ac2e7c5d":7.751587301587302,"962d4022-ff67-4067-a544-828604d8db52":9.043253968253968,"9764de87-e34e-4ea1-8de3-12d9bffc4f55":8.568994708994708,"97bfd03c-335a-4f39-89d3-cf0a22769383":7.54047619047619,"a2e5c222-c380-42d7-8846-cbc232f46a69":7.143253968253969,"a5d347a7-9984-45f4-821e-df7356477185":8.353809523809524,"b532d930-ad51-4a05-9c5c-9a75d6b021a2":7.85968253968254,"b90f9310-726f-4116-9322-6fc01ab598fd":7.958888888888889,"bb693c93-e418-46ea-8b38-9c53df27bdf2":8.173492063492063,"cdbd2ef9-d4b1-4dff-9037-3ea84627424d":10.17574074074074,"dd5a3ef5-9d44-4dde-bcdb-dc4d17c69073":9.616931216931215,"f006e236-59ad-4647-a59f-4f46dc2c85be":7.362301587301587,"feff8862-f47d-4591-a7cb-b62d7efc81a2":9.84753968253968},"topic":["libsvm","svm","machin","detail","year"],"groups":[{"authors":["Rong-En Fan","P. Chen","Chih-Jen Lin"],"references":["4aa6fe33-d146-4e6f-ac35-cbeb43c65866","50dd56db-151d-4d62-8576-65f0ef6f381b","5ffac6f9-2456-42cf-830c-9049ce37c899","90925435-d33a-4abd-892d-abbe52e547c4","9764de87-e34e-4ea1-8de3-12d9bffc4f55","97bfd03c-335a-4f39-89d3-cf0a22769383","9c01a502-04f3-4adb-9bde-f06253818cb9","a2e5c222-c380-42d7-8846-cbc232f46a69","b90f9310-726f-4116-9322-6fc01ab598fd","c1b6b493-01ef-420f-be44-7bacfe34e846","dd5a3ef5-9d44-4dde-bcdb-dc4d17c69073","f006e236-59ad-4647-a59f-4f46dc2c85be","fb6acee9-6dfe-47ef-a8c3-20bbbbb3ff8a"],"_id":"4317334f-595f-45be-a095-efe8f258b558","abstract":"Working set selection is an important step in decomposition methods for training support vector machines (SVMs). This paper develops a new technique for working set selection in SMO-type decomposition methods. It uses second order information to achieve fast convergence. Theoretical properties such as linear convergence are established. Experiments demonstrate that the proposed method is faster than existing selection methods using first order information.","title":"Working Set Selection Using Second Order Information for Training Support Vector Machines","venue":"Journal of Machine Learning Research","year":2005,"__v":0,"citationCount":510},{"authors":["Nikolas List","Hans Ulrich Simon"],"references":["0ed949f7-7118-45fa-8a4c-63fcf9f4bd8f","1258d930-e21d-4214-b635-6c50c7c37512","1f77802a-50d5-4520-9a1a-07b3b2aceca0","33184e74-4574-4856-a969-e497fdc2fec8","394fcdc7-5d9b-4180-9c32-1be37a0c7061","402c1d45-5bf6-4f7a-806b-10df639f81c6","591548b3-16de-485d-9ee2-8074c767a0eb","5ffac6f9-2456-42cf-830c-9049ce37c899","7f03746d-ba06-4b34-828e-683192e9ee42","90925435-d33a-4abd-892d-abbe52e547c4","962d4022-ff67-4067-a544-828604d8db52","9764de87-e34e-4ea1-8de3-12d9bffc4f55","97bfd03c-335a-4f39-89d3-cf0a22769383","a2e5c222-c380-42d7-8846-cbc232f46a69","a5d347a7-9984-45f4-821e-df7356477185","b90f9310-726f-4116-9322-6fc01ab598fd","bcd9b3de-3f73-457d-a000-0776ddf2f9c1","be003015-ba80-4492-ab82-76b91a70c71e","c1b6b493-01ef-420f-be44-7bacfe34e846","f006e236-59ad-4647-a59f-4f46dc2c85be","f39b7a92-faec-4ecb-8007-e2b53fddee74","fabaa590-549f-4046-8c32-1650392af7da","fb6acee9-6dfe-47ef-a8c3-20bbbbb3ff8a"],"_id":"92a420a1-f54b-4cdd-b5a4-2669ac2e7c5d","abstract":"We present a general decomposition algorithm that is uniformly applicable to every (suitably normalized) instance of Convex Quadratic Optimization and efficiently approaches an optimal solution. The number of iterations required to be within e of optimality grows linearly with 1/e and quadratically with the number m of variables. The working set selection can be performed in polynomial time. If we restrict our considerations to instances of Convex Quadratic Optimization with at most k0 equality constraints for some fixed constant k0 plus some so-called box-constraints (conditions that hold for most variants of SVM-optimization), the working set is found in linear time. Our analysis builds on a generalization of the concept of rate certifying pairs that was introduced by Hush and Scovel. In order to extend their results to arbitrary instances of Convex Quadratic Optimization, we introduce the general notion of a rate certifying q-set. We improve on the results by Hush and Scovel (2003) in several ways. First our result holds for Convex Quadratic Optimization whereas the results by Hush and Scovel are specialized to SVM-optimization. Second, we achieve a higher rate of convergence even for the special case of SVM-optimization (despite the generality of our approach). Third, our analysis is technically simpler.#R##N##R##N#We prove furthermore that the strategy for working set selection which is based on rate certifying sets coincides with a strategy which is based on a so-called \"sparse witness of sub-optimality\". Viewed from this perspective, our main result improves on convergence results by List and Simon (2004) and Simon (2004) by providing convergence rates (and by holding under more general conditions).","title":"General Polynomial Time Decomposition Algorithms","venue":"computational learning theory","year":2007,"__v":0,"citationCount":14},{"authors":["Chih-Jen Lin"],"references":["01b486c4-8955-403b-a0c6-1de74298b215","05fce530-0e1b-48a4-bf15-7c804c753640","0cba8ef9-d3db-4ce1-9933-463ed71f5153","0ed949f7-7118-45fa-8a4c-63fcf9f4bd8f","2190c590-c037-4170-9a93-a9d0c4468077","33184e74-4574-4856-a969-e497fdc2fec8","402c1d45-5bf6-4f7a-806b-10df639f81c6","50dd56db-151d-4d62-8576-65f0ef6f381b","591548b3-16de-485d-9ee2-8074c767a0eb","5ffac6f9-2456-42cf-830c-9049ce37c899","7c6a970a-0d6f-4e4b-b50e-6c6fbd23a9ab","7f03746d-ba06-4b34-828e-683192e9ee42","962d4022-ff67-4067-a544-828604d8db52","b90f9310-726f-4116-9322-6fc01ab598fd","c1b6b493-01ef-420f-be44-7bacfe34e846","dd5a3ef5-9d44-4dde-bcdb-dc4d17c69073","ef3d9941-f114-416a-8691-ea739d62ea68"],"_id":"a2e5c222-c380-42d7-8846-cbc232f46a69","abstract":"The decomposition method is currently one of the major methods for solving support vector machines (SVM). Its convergence properties have not been fully understood. The general asymptotic convergence was first proposed by Chang et al. However, their working set selection does not coincide with existing implementation. A later breakthrough by Keerthi and Gilbert (2000, 2002) proved the convergence finite termination for practical cases while the size of the working set is restricted to two. In this paper, we prove the asymptotic convergence of the algorithm used by the software SVM/sup light/ and other later implementation. The size of the working set can be any even number. Extensions to other SVM formulations are also discussed.","title":"On the convergence of the decomposition method for support vector machines","venue":"IEEE Transactions on Neural Networks","year":2001,"__v":0,"citationCount":95},{"authors":["Chih-Jen Lin"],"references":["50dd56db-151d-4d62-8576-65f0ef6f381b","5ffac6f9-2456-42cf-830c-9049ce37c899","90925435-d33a-4abd-892d-abbe52e547c4","962d4022-ff67-4067-a544-828604d8db52","a2e5c222-c380-42d7-8846-cbc232f46a69","c1b6b493-01ef-420f-be44-7bacfe34e846","cf93558f-c1b2-4292-8284-1be8d4316af1","dd5a3ef5-9d44-4dde-bcdb-dc4d17c69073","feff8862-f47d-4591-a7cb-b62d7efc81a2"],"_id":"a5d347a7-9984-45f4-821e-df7356477185","abstract":"In a previous paper, the author (2001) proved the convergence of a commonly used decomposition method for support vector machines (SVMs). However, there is no theoretical justification about its stopping criterion, which is based on the gap of the violation of the optimality condition. It is essential to have the gap asymptotically approach zero, so we are sure that existing implementations stop in a finite number of iterations after reaching a specified tolerance. Here, we prove this result and illustrate it by two extensions: /spl nu/-SVM and a multiclass SVM by Crammer and Singer (2001). A further result shows that, in final iterations of the decomposition method, only a particular set of variables are still being modified. This supports the use of the shrinking and caching techniques in some existing implementations. Finally, we prove the asymptotic convergence of a decomposition method for this multiclass SVM. Discussions on the difference between this convergence proof and the one in another paper by Lin are also included.","title":"A formal analysis of stopping criteria of decomposition methods for support vector machines","venue":"IEEE Transactions on Neural Networks","year":2002,"__v":0,"citationCount":44},{"authors":["P. Chen","Rong-En Fan","Chih-Jen Lin"],"references":["1f77802a-50d5-4520-9a1a-07b3b2aceca0","33184e74-4574-4856-a969-e497fdc2fec8","4317334f-595f-45be-a095-efe8f258b558","4b9b83f6-c076-4545-ad56-0bb0d0b95509","4bbd7777-9751-415d-bb7a-6ce26f6d9271","50dd56db-151d-4d62-8576-65f0ef6f381b","5ffac6f9-2456-42cf-830c-9049ce37c899","7c6a970a-0d6f-4e4b-b50e-6c6fbd23a9ab","90925435-d33a-4abd-892d-abbe52e547c4","93b5a3ee-a59b-42f1-9b62-8811c4a64c74","962d4022-ff67-4067-a544-828604d8db52","9764de87-e34e-4ea1-8de3-12d9bffc4f55","a2e5c222-c380-42d7-8846-cbc232f46a69","a5d347a7-9984-45f4-821e-df7356477185","b90f9310-726f-4116-9322-6fc01ab598fd","c1b6b493-01ef-420f-be44-7bacfe34e846","dd5a3ef5-9d44-4dde-bcdb-dc4d17c69073","f006e236-59ad-4647-a59f-4f46dc2c85be"],"_id":"97bfd03c-335a-4f39-89d3-cf0a22769383","abstract":"Decomposition methods are currently one of the major methods for training support vector machines. They vary mainly according to different working set selections. Existing implementations and analysis usually consider some specific selection rules. This paper studies sequential minimal optimization type decomposition methods under a general and flexible way of choosing the two-element working set. The main results include: 1) a simple asymptotic convergence proof, 2) a general explanation of the shrinking and caching techniques, and 3) the linear convergence of the methods. Extensions to some support vector machine variants are also discussed.","title":"A study on SMO-type decomposition methods for support vector machines","venue":"IEEE Transactions on Neural Networks","year":2006,"__v":0,"citationCount":91}],"offsprings":["4cbd7765-c47a-4004-a5f8-c2da7c7d1c7b","8026f56a-a93e-4933-8ead-c9aa9e3f0498","12d6aa75-3066-4e5f-a73d-f0d56c9d99f5","01b486c4-8955-403b-a0c6-1de74298b215"]},"c28cf51b-79cf-4b24-9234-8b304f11e6ca":{"authors":["Martin Fowler"],"references":[],"_id":"c28cf51b-79cf-4b24-9234-8b304f11e6ca","abstract":"Almost every expert in Object-Oriented Development stresses the importance of iterative development. As you proceed with the iterative development, you need to add function to the existing code base. If you are really lucky that code base is structured just right to support the new function while still preserving its design integrity. Of course most of the time we are not lucky, the code does not quite fit what we want to do. You could just add the function on top of the code base. But soon this leads to applying patch upon patch making your system more complex than it needs to be. This complexity leads to bugs, and cripples your productivity.","title":"Refactoring: Improving the Design of Existing Code","venue":"","year":2002,"__v":0,"citationCount":2179,"parents":{"7ba63bd0-be52-4311-831a-532f1554b1d6":33.33333333333333,"834ebcdf-ba30-4aaa-ad45-fdd4dfb3c169":16.666666666666664,"a60f5b27-99de-4929-af9e-12e767026d60":0,"a8e9ece1-977d-4a0b-bf9f-9158478c24e7":0,"bcfa87fb-47c7-43c2-94c4-ffda08ecc9b7":0,"ff8ef2b7-6bb3-43eb-9c48-d3d35a173e3f":50},"keyword":{"7ba63bd0-be52-4311-831a-532f1554b1d6":0,"834ebcdf-ba30-4aaa-ad45-fdd4dfb3c169":9.919126984126985,"a60f5b27-99de-4929-af9e-12e767026d60":10.398544973544974,"a8e9ece1-977d-4a0b-bf9f-9158478c24e7":8.469642857142855,"bcfa87fb-47c7-43c2-94c4-ffda08ecc9b7":11.164285714285711,"ff8ef2b7-6bb3-43eb-9c48-d3d35a173e3f":8.198492063492063},"topic":["code","function","develop","base","patch"],"groups":[{"authors":["Ralph E. Johnson","William F. Opdyke"],"references":["254e1e95-9d17-477c-8be0-b07228bee8f9","41f467ce-6d48-4750-8522-414d68f697fc","5b55e079-5a57-4f49-b9a9-e328f3049d7e","631b6e0c-d048-40ba-bb79-75f92679948b","79b15730-feb1-4d01-9d19-98af0a324e32","834ebcdf-ba30-4aaa-ad45-fdd4dfb3c169","8780915a-cf08-4b7e-8336-27470235c93d","97f5044f-91f4-4cf8-be59-5f2ebf1d8335","9d84acca-20f2-41d1-844c-1b223a7f2eda","b6cfbe21-5bf7-4a0b-bf42-5d66ab566518","bcfa87fb-47c7-43c2-94c4-ffda08ecc9b7","c03f7308-b4ec-45d2-97a5-eb639f417b09","c540b2df-6ebe-4314-b5aa-7acc96044ef9","e65d1b23-a595-4a2e-acb1-57a138d08ef1"],"_id":"7ba63bd0-be52-4311-831a-532f1554b1d6","title":"Refactoring and Aggregation","venue":"","year":1993,"abstract":"","__v":0,"citationCount":41},{"authors":["Don Roberts","John Brant","Ralph E. Johnson"],"references":["1bbae953-0819-4353-9640-9a0855a1fc3f","4061e35e-77bd-4c1e-b6ad-c8af83b193a7","7ba63bd0-be52-4311-831a-532f1554b1d6","834ebcdf-ba30-4aaa-ad45-fdd4dfb3c169","9d84acca-20f2-41d1-844c-1b223a7f2eda","a60f5b27-99de-4929-af9e-12e767026d60","e65d1b23-a595-4a2e-acb1-57a138d08ef1"],"_id":"ff8ef2b7-6bb3-43eb-9c48-d3d35a173e3f","abstract":"Abstract#R##N##R##N#Refactoring is an important part of the evolution of reusable software and frameworks. Its uses range from the seemingly trivial, such as renaming program elements, to the profound, such as retrofitting design patterns into an existing system. Despite its importance, lack of tool support forces programmers to refactor programs by hand, which can be tedious and error-prone. The Smalltalk Refactoring Browser is a tool that carries out many refactorings automatically, and provides an environment for improving the structure of Smalltalk programs. It makes refactoring safe and simple, and so reduces the cost of making reusable software. © 1997 John Wiley & Sons, Inc.","title":"A refactoring tool for Smalltalk","venue":"Theory and Practice of Object Systems","year":1997,"__v":0,"citationCount":183}],"offsprings":[]},"c2f67467-3138-4d37-a743-10340dc3ea44":{"authors":["Ian T. Foster","Carl Kesselman","Steven Tuecke"],"references":[],"_id":"c2f67467-3138-4d37-a743-10340dc3ea44","abstract":"\"Grid\" computing has emerged as an important new field, distinguished from conventional distributed computing by its focus on large-scale resource sharing, innovative applications, and, in some cases, high performance orientation. In this article, the authors define this new field. First, they review the \"Grid problem,\" which is defined as flexible, secure, coordinated resource sharing among dynamic collections of individuals, institutions, and resources--what is referred to as virtual organizations. In such settings, unique authentication, authorization, resource access, resource discovery, and other challenges are encountered. It is this class of problem that is addressed by Grid technologies. Next, the authors present an extensible and open Grid architecture, in which protocols, services, application programming interfaces, and software development kits are categorized according to their roles in enabling resource sharing. The authors describe requirements that they believe any such mechanisms must satisfy and discuss the importance of defining a compact set of intergrid protocols to enable interoperability among different Grid systems. Finally, the authors discuss how Grid technologies relate to other contemporary technologies, including enterprise integration, application service provider, storage service provider, and peer-to-peer computing. They maintain that Grid concepts and technologies complement and have much to contribute to these other approaches.","title":"The Anatomy of the Grid: Enabling Scalable Virtual Organizations","venue":"ieee international conference on high performance computing data and analytics","year":2001,"__v":0,"citationCount":3203,"parents":{"00231608-2174-4478-8bc4-5e8705c6a104":3.3333333333333335,"08e02aa6-3ef9-4b25-8de6-a42ca9a60577":30,"0e99f68d-e44d-4108-8ddb-1df090a2aaae":3.3333333333333335,"0f267b92-aac1-476b-be8f-cdd929149783":0,"18831dc8-e399-499d-8da1-a7befe5d7055":10,"30fe84b9-cc5e-4951-a21b-662ab3291aec":0,"3f7f755b-cc31-437d-8e73-9d7ce711d33a":0,"432a75f0-4a68-4700-954b-56a8eb920dab":10,"441d7697-8548-4ee5-8f6d-2765c8492b7a":0,"522a0bfa-5b9d-42dd-a0fb-86743493a164":0,"68414a1e-11d6-4d1e-bff0-eef3f924a691":3.3333333333333335,"698fc1a5-7700-4108-9957-530e0da64595":0,"6cec07de-4318-4168-954f-38246a885091":3.3333333333333335,"73443d97-5346-428a-847c-7a9e05b12ce7":0,"740d054f-67e6-4e6e-a54d-f09e4ab41bb7":10,"8dedecd2-47b1-4229-a0b4-7d26d6561921":0,"9553fde5-7523-4944-abb2-ce12a6d02afc":0,"9cdc54f0-f1a0-4422-ac16-d9164d9371ee":6.666666666666667,"9e7f1ba6-2e03-49ee-9c8f-8accc6473d3d":3.3333333333333335,"acb72100-1da2-4585-aa35-df61f39014e0":0,"b6457b57-76f8-4d6e-afdd-594864aef737":0,"bf4c5985-8390-434e-945d-c02f65e688da":3.3333333333333335,"c0ea675b-2479-48ae-817e-3ecedd175ecf":0,"c8311815-4163-4e5c-8a25-c4a3205cb6d9":13.333333333333334,"d0811c1c-0eb1-4112-8dc1-1e33e795f7af":0,"db413eda-50e9-479a-9dd1-033f4e1d5ab8":0,"e593759c-0dd4-4e2f-9fde-40d6a64a521c":3.3333333333333335,"e9065010-fc6a-4170-8087-7c99eaa84b4c":10,"eaa13a22-26c7-4b6c-bd02-2fe23a5f62a4":0,"fd48b87f-50a1-40c0-95e5-749fa5022bb9":16.666666666666664},"keyword":{"00231608-2174-4478-8bc4-5e8705c6a104":11.795502645502644,"08e02aa6-3ef9-4b25-8de6-a42ca9a60577":11.848968253968252,"0e99f68d-e44d-4108-8ddb-1df090a2aaae":9.302539682539681,"0f267b92-aac1-476b-be8f-cdd929149783":9.659523809523808,"18831dc8-e399-499d-8da1-a7befe5d7055":11.80957671957672,"30fe84b9-cc5e-4951-a21b-662ab3291aec":0,"3f7f755b-cc31-437d-8e73-9d7ce711d33a":10.654126984126986,"432a75f0-4a68-4700-954b-56a8eb920dab":8.649814814814816,"441d7697-8548-4ee5-8f6d-2765c8492b7a":12.636772486772486,"522a0bfa-5b9d-42dd-a0fb-86743493a164":9.494312169312167,"68414a1e-11d6-4d1e-bff0-eef3f924a691":11.522751322751324,"698fc1a5-7700-4108-9957-530e0da64595":11.254589947089947,"6cec07de-4318-4168-954f-38246a885091":10.262433862433861,"73443d97-5346-428a-847c-7a9e05b12ce7":11.487460317460318,"740d054f-67e6-4e6e-a54d-f09e4ab41bb7":10.22878306878307,"8dedecd2-47b1-4229-a0b4-7d26d6561921":9.689312169312167,"9553fde5-7523-4944-abb2-ce12a6d02afc":9.570396825396823,"9cdc54f0-f1a0-4422-ac16-d9164d9371ee":11.007566137566137,"9e7f1ba6-2e03-49ee-9c8f-8accc6473d3d":8.046031746031746,"acb72100-1da2-4585-aa35-df61f39014e0":10.173597883597886,"b6457b57-76f8-4d6e-afdd-594864aef737":7.269312169312169,"bf4c5985-8390-434e-945d-c02f65e688da":11.166402116402114,"c0ea675b-2479-48ae-817e-3ecedd175ecf":0,"c8311815-4163-4e5c-8a25-c4a3205cb6d9":0,"d0811c1c-0eb1-4112-8dc1-1e33e795f7af":12.282612433862433,"db413eda-50e9-479a-9dd1-033f4e1d5ab8":6.841216931216931,"e593759c-0dd4-4e2f-9fde-40d6a64a521c":10.455661375661373,"e9065010-fc6a-4170-8087-7c99eaa84b4c":9.188888888888888,"eaa13a22-26c7-4b6c-bd02-2fe23a5f62a4":10.144603174603173,"fd48b87f-50a1-40c0-95e5-749fa5022bb9":9.822513227513227},"topic":["grid","resourc","author","technolog","share"],"groups":[{"authors":["James S. Frey","Todd Tannenbaum","Miron Livny","Ian T. Foster","Steven Tuecke"],"references":["02010d4e-8bd5-48f0-be44-44e71c35f8ed","18831dc8-e399-499d-8da1-a7befe5d7055","32302597-c054-4beb-b0fe-64128eca4d8e","493fd722-ed06-4a05-a44d-0fd76cfcacbd","522a0bfa-5b9d-42dd-a0fb-86743493a164","740d054f-67e6-4e6e-a54d-f09e4ab41bb7","8691f268-70fe-471d-9745-b2a07b222af8","9553fde5-7523-4944-abb2-ce12a6d02afc","9810d6f5-6935-43fb-8438-282ef53b3a5b","9cdc54f0-f1a0-4422-ac16-d9164d9371ee","b6457b57-76f8-4d6e-afdd-594864aef737","c2616a84-7e61-4805-a038-be2817406a42","c2f67467-3138-4d37-a743-10340dc3ea44","c49a3831-68ed-4800-8cfa-88baa6f15df3","c8311815-4163-4e5c-8a25-c4a3205cb6d9","d0811c1c-0eb1-4112-8dc1-1e33e795f7af","fd48b87f-50a1-40c0-95e5-749fa5022bb9"],"_id":"08e02aa6-3ef9-4b25-8de6-a42ca9a60577","abstract":"In recent years, there has been a dramatic increase in the number of available computing and storage resources. Yet few tools exist that allow these resources to be exploited effectively in an aggregated form. We present the Condor-G system, which leverages software from Globus and Condor to enable users to harness multi-domain resources as if they all belong to one personal domain. We describe the structure of Condor-G and how it handles job management, resource selection, security, and fault tolerance. We also present results from application experiments with the Condor-G system. We assert that Condor-G can serve as a general-purpose interface to Grid resources, for use by both end users and higher-level program development tools.","title":"Condor-G: A Computation Management Agent for Multi-Institutional Grids","venue":"Cluster Computing","year":2002,"__v":0,"citationCount":661}],"offsprings":[]},"c472bfe1-9ef6-43c6-89b5-a86b22c9f5df":{"authors":["Dengyong Zhou","Olivier Bousquet","Thomas Navin Lal","Jason Weston","Bernhard Schölkopf"],"references":["ea8cd3d8-17ae-4a1e-8f83-1609469087af"],"_id":"c472bfe1-9ef6-43c6-89b5-a86b22c9f5df","abstract":"We consider the general problem of learning from labeled and unlabeled data, which is often called semi-supervised learning or transductive inference. A principled approach to semi-supervised learning is to design a classifying function which is sufficiently smooth with respect to the intrinsic structure collectively revealed by known labeled and unlabeled points. We present a simple algorithm to obtain such a smooth solution. Our method yields encouraging experimental results on a number of classification problems and demonstrates effective use of unlabeled data.","title":"Learning with Local and Global Consistency","venue":"neural information processing systems","year":2004,"__v":0,"citationCount":1541,"parents":{"06ba5345-fa5d-417a-92b8-11879854f1f5":63.63636363636363,"3549c862-c615-4f80-ac53-f562d3e2b846":36.36363636363637,"3c13a267-57c7-4079-bb10-1078184e8c64":18.181818181818183,"3e5fd33f-1fd0-4815-a47a-3c41a26a538a":9.090909090909092,"5aed5d4c-77c0-480e-878a-9b76e410d02e":9.090909090909092,"5fc7c376-5895-490a-8ea2-989442940c7b":0,"93a14c23-d227-41fd-ad18-7de38817cb52":45.45454545454545,"9db5c445-2caa-4129-a277-368dc375689b":9.090909090909092,"d158edc8-c996-4141-b56b-d54344f635cf":0,"d6104d9a-faaa-4db4-8c4e-748176157ef2":0,"ea8cd3d8-17ae-4a1e-8f83-1609469087af":0},"keyword":{"06ba5345-fa5d-417a-92b8-11879854f1f5":10.870927128427127,"3549c862-c615-4f80-ac53-f562d3e2b846":10.448544973544974,"3c13a267-57c7-4079-bb10-1078184e8c64":11.053174603174604,"3e5fd33f-1fd0-4815-a47a-3c41a26a538a":0,"5aed5d4c-77c0-480e-878a-9b76e410d02e":9.898412698412699,"5fc7c376-5895-490a-8ea2-989442940c7b":10.571031746031746,"93a14c23-d227-41fd-ad18-7de38817cb52":10.827380952380953,"9db5c445-2caa-4129-a277-368dc375689b":10.95611111111111,"d158edc8-c996-4141-b56b-d54344f635cf":0,"d6104d9a-faaa-4db4-8c4e-748176157ef2":9.920238095238094,"ea8cd3d8-17ae-4a1e-8f83-1609469087af":10.930820105820105},"topic":["unlabel","learn","smooth","semisupervis","problem"],"groups":[{"authors":["Xiaojin Zhu","Zoubin Ghahramani","John D. Lafferty"],"references":["06df372e-5e18-44e1-81b5-84f65aea2816","0cdb081e-f2db-49d9-8c65-45cbcc948265","10ebbda8-d881-4c11-9d71-a7448d3b384e","1638b262-5ed5-4b95-bcbd-fd0f536de6ed","1f73723c-b904-4d93-8045-d8de3772fb27","3a93a291-d083-4939-9c52-8ab19590a389","3c13a267-57c7-4079-bb10-1078184e8c64","3e5fd33f-1fd0-4815-a47a-3c41a26a538a","5aed5d4c-77c0-480e-878a-9b76e410d02e","c4dc7b46-01d3-44f5-91ca-0cc063d38c8c","d0ad8d69-b4fa-44ec-ae7b-2f36351becaf","d158edc8-c996-4141-b56b-d54344f635cf","ea8cd3d8-17ae-4a1e-8f83-1609469087af","f1b80f20-5db2-4a73-9113-ab20176f5152"],"_id":"93a14c23-d227-41fd-ad18-7de38817cb52","abstract":"An approach to semi-supervised learning is proposed that is based on a Gaussian random field model. Labeled and unlabeled data are represented as vertices in a weighted graph, with edge weights encoding the similarity between instances. The learning problem is then formulated in terms of a Gaussian random field on this graph, where the mean of the field is characterized in terms of harmonic functions, and is efficiently obtained using matrix methods or belief propagation. The resulting learning algorithms have intimate connections with random walks, electric networks, and spectral graph theory. We discuss methods to incorporate class priors and the predictions of classifiers obtained by supervised learning. We also propose a method of parameter learning by entropy minimization, and show the algorithm's ability to perform feature selection. Promising experimental results are presented for synthetic data, digit classification, and text classification tasks.","title":"Semi-supervised learning using Gaussian fields and harmonic functions","venue":"international conference on machine learning","year":2003,"__v":0,"citationCount":1394},{"authors":["Mikhail Belkin","Partha Niyogi"],"references":["0500ddbe-e274-477b-bb6b-54a7269e4577","05bbaec3-7980-4941-8638-2bbfa4ac8be0","3549c862-c615-4f80-ac53-f562d3e2b846","3c13a267-57c7-4079-bb10-1078184e8c64","3e5fd33f-1fd0-4815-a47a-3c41a26a538a","5aed5d4c-77c0-480e-878a-9b76e410d02e","5fc7c376-5895-490a-8ea2-989442940c7b","75d0cdfa-44cd-4fc3-ae56-72e982cb383b","7e6793c0-346f-41af-b8e8-7a710171726e","92031bfe-7728-41ae-a9f9-f323b522ef7f","93a14c23-d227-41fd-ad18-7de38817cb52","94898e1d-1e50-41ab-9dcc-2c2e030cddd0","c472bfe1-9ef6-43c6-89b5-a86b22c9f5df","d158edc8-c996-4141-b56b-d54344f635cf","e89a739f-120a-4a4a-a8af-ced66ce482c9"],"_id":"06ba5345-fa5d-417a-92b8-11879854f1f5","abstract":"We consider the general problem of utilizing both labeled and unlabeled data to improve classification accuracy. Under the assumption that the data lie on a submanifold in a high dimensional space, we develop an algorithmic framework to classify a partially labeled data set in a principled manner. The central idea of our approach is that classification functions are naturally defined only on the submanifold in question rather than the total ambient space. Using the Laplace-Beltrami operator one produces a basis (the Laplacian Eigenmaps) for a Hilbert space of square integrable functions on the submanifold. To recover such a basis, only unlabeled examples are required. Once such a basis is obtained, training can be performed using the labeled data set.#R##N##R##N#Our algorithm models the manifold using the adjacency graph for the data and approximates the Laplace-Beltrami operator by the graph Laplacian. We provide details of the algorithm, its theoretical justification, and several practical applications for image, speech, and text classification.","title":"Semi-Supervised Learning on Riemannian Manifolds","venue":"Machine Learning","year":2004,"__v":0,"citationCount":326},{"authors":["Thorsten Joachims"],"references":["0500ddbe-e274-477b-bb6b-54a7269e4577","06ba5345-fa5d-417a-92b8-11879854f1f5","0cdb081e-f2db-49d9-8c65-45cbcc948265","261aefde-fbe5-494f-afd7-c771aff03127","3c13a267-57c7-4079-bb10-1078184e8c64","5aed5d4c-77c0-480e-878a-9b76e410d02e","63ec4f55-8f3b-431e-88e5-87c04caa7e9f","7ec5f06e-2fe3-495a-84a0-94fcfe08bb7b","886b2cdb-61e7-417b-b95f-c8dfc492d64b","9438a773-c15c-4ef2-a97c-54f643ce6082","a61fb870-d70c-4f4e-a359-914d613fc3c5","bd3a3a31-46b2-420d-ba03-057ac8ead4b2","d158edc8-c996-4141-b56b-d54344f635cf"],"_id":"3549c862-c615-4f80-ac53-f562d3e2b846","abstract":"We present a new method for transductive learning, which can be seen as a transductive version of the k nearest-neighbor classifier. Unlike for many other transductive learning methods, the training problem has a meaningful relaxation that can be solved globally optimally using spectral methods. We propose an algorithm that robustly achieves good generalization performance and that can be trained efficiently. A key advantage of the algorithm is that it does not require additional heuristics to avoid unbalanced splits. Furthermore, we show a connection to transductive Support Vector Machines, and that an effective Co-Training algorithm arises as a special case.","title":"Transductive learning via spectral graph partitioning","venue":"international conference on machine learning","year":2003,"__v":0,"citationCount":308}],"offsprings":["d28acb36-5766-4c1e-8d57-a55c2630bd90"]},"c6082f75-3e21-463c-8368-988c9012e54c":{"authors":["Marco Dorigo","Luca Maria Gambardella"],"references":["288106a6-f48d-44c2-98fb-bd4c257d6ff5","293971a9-15e0-4a32-9c76-8a9704e304c2"],"_id":"c6082f75-3e21-463c-8368-988c9012e54c","abstract":"This paper introduces the ant colony system (ACS), a distributed algorithm that is applied to the traveling salesman problem (TSP). In the ACS, a set of cooperating agents called ants cooperate to find good solutions to TSPs. Ants cooperate using an indirect form of communication mediated by a pheromone they deposit on the edges of the TSP graph while building solutions. We study the ACS by running experiments to understand its operation. The results show that the ACS outperforms other nature-inspired algorithms such as simulated annealing and evolutionary computation, and we conclude comparing ACS-3-opt, a version of the ACS augmented with a local search procedure, to some of the best performing algorithms for symmetric and asymmetric TSPs.","title":"Ant colony system: a cooperative learning approach to the traveling salesman problem","venue":"IEEE Transactions on Evolutionary Computation","year":1997,"__v":0,"citationCount":1961,"parents":{"03888318-cd9c-4541-ae94-d38c4741a3fa":22.22222222222222,"288106a6-f48d-44c2-98fb-bd4c257d6ff5":0,"293971a9-15e0-4a32-9c76-8a9704e304c2":16.666666666666664,"5fff9a52-b624-48fe-bf88-ac96ed74e44b":0,"71bc82f9-8b37-4977-80bf-2beaea600656":5.555555555555555,"7cad61d2-ea22-4563-b2dd-f416a62af47a":22.22222222222222,"86ff03a0-ab8a-4f8a-9ca5-de26263a2d72":0,"8bb5fc55-b518-41b3-8a2f-df490391c180":0,"95d33a82-8050-4ca0-a34e-1053b7d28672":11.11111111111111,"9a116e60-b816-413a-a801-b234c3d81a46":0,"9bb6e260-bdb9-46dc-abfa-fbeea07d86e1":11.11111111111111,"ac4106cb-d717-4de7-a841-bbc95f34514d":22.22222222222222,"b43f8a10-4a5e-4558-8c19-730859575203":5.555555555555555,"d03bf8ed-f5eb-4c4b-b019-45c1f2db39e0":27.77777777777778,"ddbd2064-d409-4f2c-92b6-f934fbf2ff01":0,"e52e4d9f-ad0e-46e2-a7bf-838559aa2b7e":27.77777777777778,"f4881874-e5c5-49a9-a19f-606affcd0171":11.11111111111111,"f86ac5ed-6f45-4151-802b-7189f3df9233":5.555555555555555},"keyword":{"03888318-cd9c-4541-ae94-d38c4741a3fa":8.574074074074074,"288106a6-f48d-44c2-98fb-bd4c257d6ff5":5.793518518518518,"293971a9-15e0-4a32-9c76-8a9704e304c2":10.151851851851854,"5fff9a52-b624-48fe-bf88-ac96ed74e44b":0,"71bc82f9-8b37-4977-80bf-2beaea600656":8.841666666666665,"7cad61d2-ea22-4563-b2dd-f416a62af47a":0,"86ff03a0-ab8a-4f8a-9ca5-de26263a2d72":7.7824074074074066,"8bb5fc55-b518-41b3-8a2f-df490391c180":7.648148148148148,"95d33a82-8050-4ca0-a34e-1053b7d28672":8.064814814814813,"9a116e60-b816-413a-a801-b234c3d81a46":9.059656084656085,"9bb6e260-bdb9-46dc-abfa-fbeea07d86e1":9.288888888888888,"ac4106cb-d717-4de7-a841-bbc95f34514d":9.71547619047619,"b43f8a10-4a5e-4558-8c19-730859575203":0,"d03bf8ed-f5eb-4c4b-b019-45c1f2db39e0":0,"ddbd2064-d409-4f2c-92b6-f934fbf2ff01":5.083333333333333,"e52e4d9f-ad0e-46e2-a7bf-838559aa2b7e":9.67883597883598,"f4881874-e5c5-49a9-a19f-606affcd0171":8.519444444444442,"f86ac5ed-6f45-4151-802b-7189f3df9233":6.987962962962963},"topic":["ac","cooper","ant","algorithm","tsp"],"groups":[{"authors":["Luca Maria Gambardella","Marco Dorigo"],"references":["293971a9-15e0-4a32-9c76-8a9704e304c2","8bb5fc55-b518-41b3-8a2f-df490391c180","95d33a82-8050-4ca0-a34e-1053b7d28672","ac4106cb-d717-4de7-a841-bbc95f34514d","b43f8a10-4a5e-4558-8c19-730859575203"],"_id":"e52e4d9f-ad0e-46e2-a7bf-838559aa2b7e","abstract":"We present ACS, a distributed algorithm for the solution of combinatorial optimization problems which was inspired by the observation of real colonies of ants. We apply ACS to both symmetric and asymmetric traveling salesman problems. Results show that ACS is able to find good solutions to these problems.","title":"Solving symmetric and asymmetric TSPs by ant colonies","venue":"","year":1996,"__v":0,"citationCount":100}],"offsprings":[]},"c75c7b08-7264-4daa-a133-59bea66db0c7":{"authors":["Peter D. Turney"],"references":[],"_id":"c75c7b08-7264-4daa-a133-59bea66db0c7","abstract":"This paper presents a simple unsupervised learning algorithm for classifying reviews as recommended (thumbs up) or not recommended (thumbs down). The classification of a review is predicted by the average semantic orientation of the phrases in the review that contain adjectives or adverbs. A phrase has a positive semantic orientation when it has good associations (e.g., \"subtle nuances\") and a negative semantic orientation when it has bad associations (e.g., \"very cavalier\"). In this paper, the semantic orientation of a phrase is calculated as the mutual information between the given phrase and the word \"excellent\" minus the mutual information between the given phrase and the word \"poor\". A review is classified as recommended if the average semantic orientation of its phrases is positive. The algorithm achieves an average accuracy of 74% when evaluated on 410 reviews from Epinions, sampled from four different domains (reviews of automobiles, banks, movies, and travel destinations). The accuracy ranges from 84% for automobile reviews to 66% for movie reviews.","title":"Thumbs Up or Thumbs Down? Semantic Orientation Applied to Unsupervised Classification of Reviews","venue":"meeting of the association for computational linguistics","year":2002,"__v":0,"citationCount":1549,"parents":{"21421f14-af9c-4c95-9aad-b7bece9fb7d9":0,"4299e3db-c1dd-486a-9ff2-7f5b5f8aa402":0,"43bcc79f-1316-4a3c-81ba-69e6c3afbcbb":11.11111111111111,"691983e4-67cb-4456-9462-42b22c620c64":0,"aab1a31b-5b8b-42af-8300-f1da4dc67827":33.33333333333333,"adaaafab-aa7a-4b1e-842d-e29c8c2f049b":11.11111111111111,"d5bb0ee8-60da-462c-af12-406e978cfb36":0,"d72e4002-82ec-483a-b381-9fc4dc56186b":22.22222222222222,"f998a503-422a-46ef-adf3-8c23579d7be5":0},"keyword":{"21421f14-af9c-4c95-9aad-b7bece9fb7d9":12.873703703703702,"4299e3db-c1dd-486a-9ff2-7f5b5f8aa402":8.417724867724868,"43bcc79f-1316-4a3c-81ba-69e6c3afbcbb":12.050661375661377,"691983e4-67cb-4456-9462-42b22c620c64":11.679629629629627,"aab1a31b-5b8b-42af-8300-f1da4dc67827":9.851587301587303,"adaaafab-aa7a-4b1e-842d-e29c8c2f049b":11.621190476190476,"d5bb0ee8-60da-462c-af12-406e978cfb36":10.56111111111111,"d72e4002-82ec-483a-b381-9fc4dc56186b":9.466349206349205,"f998a503-422a-46ef-adf3-8c23579d7be5":10.255621693121693},"topic":["review","phrase","semant","orient","recommend"],"groups":[{"authors":["Janyce Wiebe"],"references":["0210c7ec-b4ba-4c4c-bdda-2d55b9a16b4d","21421f14-af9c-4c95-9aad-b7bece9fb7d9","2256cad0-cf03-42da-bcf3-4a89be0ebf8e","43bcc79f-1316-4a3c-81ba-69e6c3afbcbb","5028da72-cb92-4df8-abb4-f7dd104c603a","51bd8299-2450-4387-aa6f-bfff35b61db2","51f1493d-ce3b-4589-8373-55940026fecd","691983e4-67cb-4456-9462-42b22c620c64","6e6518a0-01a9-46ac-b4ca-0cf34155ae55","b5ea191d-2c02-4c4a-b887-0c6d3c958ce9","ccd5b8e1-152a-40fb-ae6d-5b9575212d73","ed8f96b0-dd29-4a5d-8af6-dc1d3ae400a6","f9e65391-0e1c-4995-9d73-d9d3cfd72630"],"_id":"aab1a31b-5b8b-42af-8300-f1da4dc67827","abstract":"Subjectivity tagging is distinguishing sentences used to present opinions and evaluations from sentences used to objectively present factual information. There are numerous applications for which subjectivity tagging is relevant, including information extraction and information retrieval. This paper identifies strong clues of subjectivity using the results of a method for clustering words according to distributional similarity (Lin 1998), seeded by a small amount of detailed manual annotation. These features are then further refined with the addition of lexical semantic features of adjectives, specifically polarity and gradability (Hatzivassiloglou & McKeown 1997), which can be automatically learned from corpora. In 10-fold cross validation experiments, features based on both similarity clusters and the lexical semantic features are shown to have higher precision than features based on each alone.","title":"Learning Subjective Adjectives from Corpora","venue":"national conference on artificial intelligence","year":2000,"__v":0,"citationCount":210}],"offsprings":["d924ecc1-ce71-4250-ae5d-570769554f74","ed543a19-85d9-427a-a2d3-88e7c59a100e"]},"c93eac1a-7d9a-48ab-9fb4-389c85bea00e":{"authors":["Yangqing Jia","Evan Shelhamer","Jeff Donahue","Sergey Karayev","Jonathan Long","Ross B. Girshick","Sergio Guadarrama","Trevor Darrell"],"references":["176a7436-78ea-4c2a-82e6-7930ab023bd1","e2f7a74a-8430-4463-94ce-fe85dfd309f9"],"_id":"c93eac1a-7d9a-48ab-9fb4-389c85bea00e","abstract":"Caffe provides multimedia scientists and practitioners with a clean and modifiable framework for state-of-the-art deep learning algorithms and a collection of reference models. The framework is a BSD-licensed C++ library with Python and MATLAB bindings for training and deploying general-purpose convolutional neural networks and other deep models efficiently on commodity architectures. Caffe fits industry and internet-scale media needs by CUDA GPU computation, processing over 40 million images a day on a single K40 or Titan GPU (approx 2 ms per image). By separating model representation from actual implementation, Caffe allows experimentation and seamless switching among platforms for ease of development and deployment from prototyping machines to cloud environments.   Caffe is maintained and developed by the Berkeley Vision and Learning Center (BVLC) with the help of an active community of contributors on GitHub. It powers ongoing research projects, large-scale industrial applications, and startup prototypes in vision, speech, and multimedia.","title":"Caffe: Convolutional Architecture for Fast Feature Embedding","venue":"acm multimedia","year":2014,"__v":0,"citationCount":2101,"parents":{"0fb0a842-cb06-4b37-9738-a4d18a55ec23":22.22222222222222,"16ebaec4-79d6-4c4a-bc44-50c79204faf2":0,"176a7436-78ea-4c2a-82e6-7930ab023bd1":33.33333333333333,"acf46750-428a-4f63-95b2-aabf1d40b6b6":22.22222222222222,"bc9dae46-1c04-47bb-b93a-9c830f06f1bf":11.11111111111111,"c812244d-0de8-4e3c-8133-1e834bc9dbd0":11.11111111111111,"e2f7a74a-8430-4463-94ce-fe85dfd309f9":0,"ebc82bdd-1afb-419d-983c-a313713c6367":22.22222222222222,"f1639cc6-356f-4170-9dea-9be79c84f899":0},"keyword":{"0fb0a842-cb06-4b37-9738-a4d18a55ec23":8.338888888888889,"16ebaec4-79d6-4c4a-bc44-50c79204faf2":0,"176a7436-78ea-4c2a-82e6-7930ab023bd1":9.433333333333332,"acf46750-428a-4f63-95b2-aabf1d40b6b6":10.011984126984125,"bc9dae46-1c04-47bb-b93a-9c830f06f1bf":9.70531746031746,"c812244d-0de8-4e3c-8133-1e834bc9dbd0":9.124999999999998,"e2f7a74a-8430-4463-94ce-fe85dfd309f9":9.876388888888888,"ebc82bdd-1afb-419d-983c-a313713c6367":9.542658730158731,"f1639cc6-356f-4170-9dea-9be79c84f899":8.944444444444443},"topic":["caff","model","vision","prototyp","multimedia"],"groups":[{"authors":["Ross B. Girshick","Jeff Donahue","Trevor Darrell","Jitendra Malik"],"references":["0105e97e-ef22-402e-8ba6-5de027d57dbe","1bbaae78-1bb8-4184-b01c-4216e6879c56","2b6a3d0f-368f-45bb-be23-4e82f62fbbf7","2f4bbdb0-55cc-48e9-a986-71fc20a69a5c","30d96b63-ab8b-4a93-904d-65e87ba32327","3609ce2c-c21e-4e94-a17e-de31443ecb90","414732f4-8fd6-4fdb-9039-553367150535","493f502b-b1b8-412c-95fd-3c1103480f1d","589efc91-a3df-4c70-a613-67f249d7b33f","6e1c18af-5c7f-4915-a611-702a3d4b9c53","725ff5fd-76fe-41b4-b50d-00405a51ac27","73dbdf1f-da95-4b8c-9109-c966e08c6f13","83c737b8-e084-4766-ba6e-131e6a1c017c","86c0687e-74fb-44b1-a467-7f469a1486b9","95f28b74-9e22-4dc0-8acc-9cdf7e716b61","983a2eff-22fe-40d2-bb87-fea35e63db6c","9be390e8-c4e6-41a2-b9b2-74de449f0768","9d24b0a5-fc3e-486e-9706-da560154b63c","a0a69af2-8b51-455e-bbac-a1aa5b24bd8b","a13418d7-3585-4888-a027-85e441bfd354","a4382b8f-f7fd-4d84-93ba-04c068c9abf0","ab3afb93-8ca0-4556-ae60-11199dc263c2","ae3e7593-586f-495f-9416-4b50ed1fcd10","b916e575-9eba-4989-ad10-00b615e358a6","b944f77f-113b-4a02-ae5e-d4a124b8fd5b","c7def717-ad62-4168-9ae3-5484a67399c1","c812244d-0de8-4e3c-8133-1e834bc9dbd0","d5e5a24d-f80e-4f1a-b48b-22403b653276","d6e37fb1-5f7e-448e-847b-7d1f1271c574","daa22c50-e3a3-42f0-85b5-4cad99989511","dd83785a-dd19-41e3-9b25-ebabbd48d336","e016d598-1090-4b61-98ab-f47c8650dfa7","e2f7a74a-8430-4463-94ce-fe85dfd309f9","e407acd7-dfcf-4ee8-9140-6726c01abf4e","e7f6e82d-380c-427b-98bc-5c79471a7336","f1639cc6-356f-4170-9dea-9be79c84f899","f2d49150-35de-4fd5-ac46-eb071d1cc73e"],"_id":"176a7436-78ea-4c2a-82e6-7930ab023bd1","abstract":"Object detection performance, as measured on the canonical PASCAL VOC dataset, has plateaued in the last few years. The best-performing methods are complex ensemble systems that typically combine multiple low-level image features with high-level context. In this paper, we propose a simple and scalable detection algorithm that improves mean average precision (mAP) by more than 30% relative to the previous best result on VOC 2012 -- achieving a mAP of 53.3%. Our approach combines two key insights: (1) one can apply high-capacity convolutional neural networks (CNNs) to bottom-up region proposals in order to localize and segment objects and (2) when labeled training data is scarce, supervised pre-training for an auxiliary task, followed by domain-specific fine-tuning, yields a significant performance boost. Since we combine region proposals with CNNs, we call our method R-CNN: Regions with CNN features. We also present experiments that provide insight into what the network learns, revealing a rich hierarchy of image features. Source code for the complete system is available at http://www.cs.berkeley.edu/~rbg/rcnn.","title":"Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation","venue":"computer vision and pattern recognition","year":2014,"__v":0,"citationCount":1815},{"authors":["Ning Zhang","Manohar Paluri","Marc'Aurelio Ranzato","Trevor Darrell","Lubomir D. Bourdev"],"references":["06546bec-4d27-4ecf-a0ff-c96571dfec5f","096b2319-7282-4964-9136-52bc12348bc3","125e92b0-d879-43ac-bf56-9408a6fea183","17d870e0-2fd7-4878-af7d-e6f81fa9ae44","32a643b0-7334-4553-adb4-459ad560654e","3daf5a32-5275-4c48-ae25-cd47cfec0f33","4bbacb77-1097-4cc5-b001-6554ea01fb75","4e20f374-db4e-4c9e-ba2b-6b1af2a4b9c3","614adea0-684f-4711-84fa-8cb6cc7d49db","6e083300-a74c-43f0-8a56-4e7c015e3892","81163e27-8feb-48e0-b21b-a69d8555e64c","86c0687e-74fb-44b1-a467-7f469a1486b9","8fb49bff-96c8-47ce-8b2f-f2ba16801621","924fe569-7b4c-4968-bcc9-35aa73dbb587","a04310cc-9dda-4137-a187-0891b0569005","ae3e7593-586f-495f-9416-4b50ed1fcd10","c812244d-0de8-4e3c-8133-1e834bc9dbd0","e016d598-1090-4b61-98ab-f47c8650dfa7","e0ac4812-7729-4a2d-8a1f-74b1b7c8eb5d","e16196fc-ad79-42a7-a19c-92256a179a78","e2f7a74a-8430-4463-94ce-fe85dfd309f9","e4de3243-9d16-4fef-ad76-c388fe41240e","e850c4c4-203c-4e23-8ac8-a9b9067432b5","f2d49150-35de-4fd5-ac46-eb071d1cc73e"],"_id":"acf46750-428a-4f63-95b2-aabf1d40b6b6","abstract":"We propose a method for inferring human attributes (such as gender, hair style, clothes style, expression, action) from images of people under large variation of viewpoint, pose, appearance, articulation and occlusion. Convolutional Neural Nets (CNN) have been shown to perform very well on large scale object recognition problems. In the context of attribute classification, however, the signal is often subtle and it may cover only a small part of the image, while the image is dominated by the effects of pose and viewpoint. Discounting for pose variation would require training on very large labeled datasets which are not presently available. Part-based models, such as poselets [4] and DPM [12] have been shown to perform well for this problem but they are limited by shallow low-level features. We propose a new method which combines part-based models and deep learning by training pose-normalized CNNs. We show substantial improvement vs. state-of-the-art methods on challenging attribute classification tasks in unconstrained settings. Experiments confirm that our method outperforms both the best part-based methods on this problem and conventional CNNs trained on the full bounding box of the person.","title":"PANDA: Pose Aligned Networks for Deep Attribute Modeling","venue":"computer vision and pattern recognition","year":2014,"__v":0,"citationCount":116}],"offsprings":[]},"cb5922c5-575b-4b50-8d58-809f8256e948":{"authors":["Sepandar D. Kamvar","Mario T. Schlosser","Hector Garcia-Molina"],"references":["4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4","51af4708-b81c-4362-b4ee-7bdf7ace609f","d06f8723-1b89-4684-99c9-c1045ddfb85c","e1263ada-afda-498c-a37d-9b545293118a"],"_id":"cb5922c5-575b-4b50-8d58-809f8256e948","abstract":"Peer-to-peer file-sharing networks are currently receiving much attention as a means of sharing and distributing information. However, as recent experience shows, the anonymous, open nature of these networks offers an almost ideal environment for the spread of self-replicating inauthentic files.We describe an algorithm to decrease the number of downloads of inauthentic files in a peer-to-peer file-sharing network that assigns each peer a unique global trust value, based on the peer's history of uploads. We present a distributed and secure method to compute global trust values, based on Power iteration. By having peers use these global trust values to choose the peers from whom they download, the network effectively identifies malicious peers and isolates them from the network.In simulations, this reputation system, called EigenTrust, has been shown to significantly decrease the number of inauthentic files on the network, even under a variety of conditions where malicious peers cooperate in an attempt to deliberately subvert the system.","title":"The Eigentrust algorithm for reputation management in P2P networks","venue":"international world wide web conferences","year":2003,"__v":0,"citationCount":1551,"parents":{"326d37c8-fadc-46a9-bd62-9024015e2563":0,"4778899b-0dfd-4f84-8644-305dde06d66e":22.22222222222222,"4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4":11.11111111111111,"4d44e017-2597-44f9-b1c3-3c96cade56bd":0,"51af4708-b81c-4362-b4ee-7bdf7ace609f":11.11111111111111,"801484ee-8bc9-4b19-bcbc-0a8c10c35ee0":0,"ccc96384-6f47-49ab-8694-5b0240c32c26":0,"d06f8723-1b89-4684-99c9-c1045ddfb85c":22.22222222222222,"e1263ada-afda-498c-a37d-9b545293118a":22.22222222222222},"keyword":{"326d37c8-fadc-46a9-bd62-9024015e2563":0,"4778899b-0dfd-4f84-8644-305dde06d66e":9.760449735449734,"4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4":8.69973544973545,"4d44e017-2597-44f9-b1c3-3c96cade56bd":11.230158730158731,"51af4708-b81c-4362-b4ee-7bdf7ace609f":9.486455026455026,"801484ee-8bc9-4b19-bcbc-0a8c10c35ee0":9.42031746031746,"ccc96384-6f47-49ab-8694-5b0240c32c26":10.911904761904763,"d06f8723-1b89-4684-99c9-c1045ddfb85c":8.723280423280423,"e1263ada-afda-498c-a37d-9b545293118a":8.233068783068783},"topic":["peer","network","trust","inauthent","global"],"offsprings":[]},"cce3336d-27a2-4737-b4df-133d8db7dd71":{"authors":["Franz Josef Och","Hermann Ney"],"references":[],"_id":"cce3336d-27a2-4737-b4df-133d8db7dd71","abstract":"We present and compare various methods for computing word alignments using statistical or heuristic models. We consider the five alignment models presented in Brown, Della Pietra, Della Pietra, and Mercer (1993), the hidden Markov alignment model, smoothing techniques, and refinements. These statistical models are compared with two heuristic models based on the Dice coefficient. We present different methods for combining word alignments to perform a symmetrization of directed statistical alignment models. As evaluation criterion, we use the quality of the resulting Viterbi alignment compared to a manually produced reference alignment. We evaluate the models on the German-English Verbmobil task and the French-English Hansards task. We perform a detailed analysis of various design decisions of our statistical alignment system and evaluate these on training corpora of various sizes. An important result is that refined alignment models with a first-order dependence and a fertility model yield significantly better results than simple heuristic models. In the Appendix, we present an efficient training algorithm for the alignment models presented.","title":"A systematic comparison of various statistical alignment models","venue":"Computational Linguistics","year":2003,"__v":0,"citationCount":1567,"parents":{"00a4190a-1cab-4a69-b9fc-1fbdc915ae3d":4.3478260869565215,"00c30fb6-e977-4cef-ac0b-00e7223b2bc9":4.3478260869565215,"01b26291-a389-40b7-a3a9-53f38a3884ec":8.695652173913043,"13a6706a-f4e6-4631-8374-dbe2937998af":0,"1e460c7f-8b3b-4920-b060-61ebdc40ad47":13.043478260869565,"27ebd924-13e6-492c-baf6-89fb5fd90d35":17.391304347826086,"452afc43-c279-4073-a560-11e917e9d8bf":13.043478260869565,"4a378909-2f5e-428f-b3e5-31a07683bb63":13.043478260869565,"4ab5e4bd-08e2-4007-825c-d34ce7cb231f":4.3478260869565215,"4eaf5bba-9100-4330-a7d8-91d527cc3c9d":39.130434782608695,"5443ee2f-a083-4829-bfd3-b92e50b6d78e":0,"6289c912-719d-40b6-8923-de5309a28e73":8.695652173913043,"900e5fb7-ec32-4c3e-b78a-d2a619a41b77":13.043478260869565,"91c127fc-af90-40c3-8a69-8410a8f7e984":4.3478260869565215,"923b100a-54e0-47f5-bcce-8226c0c8cc95":13.043478260869565,"95c045c1-8cb8-4e1b-a998-54f8148a8647":4.3478260869565215,"96fd2c01-1218-42b9-9cd2-7f517242aceb":30.434782608695656,"a30459a5-94f5-45ff-b3cb-5f8c12298e59":0,"a9a1fe46-7b55-4e97-a25e-ce59b3227e6c":4.3478260869565215,"baacb10c-dd8e-4fdf-8b5b-4b789243bf2b":8.695652173913043,"d2470b0c-b356-45b9-bedf-aabb0f71ceb9":17.391304347826086,"d29e32f9-d152-4112-88fe-fa30622e9409":13.043478260869565,"e46f3003-d66c-490e-9faf-5c63c7fb95d0":4.3478260869565215},"keyword":{"00a4190a-1cab-4a69-b9fc-1fbdc915ae3d":11.593095238095236,"00c30fb6-e977-4cef-ac0b-00e7223b2bc9":0,"01b26291-a389-40b7-a3a9-53f38a3884ec":12.02694805194805,"13a6706a-f4e6-4631-8374-dbe2937998af":0,"1e460c7f-8b3b-4920-b060-61ebdc40ad47":10.59722222222222,"27ebd924-13e6-492c-baf6-89fb5fd90d35":12.122301587301587,"452afc43-c279-4073-a560-11e917e9d8bf":9.365873015873015,"4a378909-2f5e-428f-b3e5-31a07683bb63":11.003055555555553,"4ab5e4bd-08e2-4007-825c-d34ce7cb231f":10.39829365079365,"4eaf5bba-9100-4330-a7d8-91d527cc3c9d":10.88083333333333,"5443ee2f-a083-4829-bfd3-b92e50b6d78e":10.464391534391535,"6289c912-719d-40b6-8923-de5309a28e73":0,"900e5fb7-ec32-4c3e-b78a-d2a619a41b77":10.902777777777775,"91c127fc-af90-40c3-8a69-8410a8f7e984":9.77222222222222,"923b100a-54e0-47f5-bcce-8226c0c8cc95":9.09415343915344,"95c045c1-8cb8-4e1b-a998-54f8148a8647":11.339285714285714,"96fd2c01-1218-42b9-9cd2-7f517242aceb":12.515753968253968,"a30459a5-94f5-45ff-b3cb-5f8c12298e59":9.260939153439155,"a9a1fe46-7b55-4e97-a25e-ce59b3227e6c":12.669153439153437,"baacb10c-dd8e-4fdf-8b5b-4b789243bf2b":11.095634920634918,"d2470b0c-b356-45b9-bedf-aabb0f71ceb9":11.054761904761905,"d29e32f9-d152-4112-88fe-fa30622e9409":9.491269841269842,"e46f3003-d66c-490e-9faf-5c63c7fb95d0":11.648611111111112},"topic":["model","align","present","statist","result"],"groups":[{"authors":["Franz Josef Och","Hermann Ney"],"references":["0084c826-9869-48ff-a9af-340511b62a37","00c30fb6-e977-4cef-ac0b-00e7223b2bc9","01f443e7-ea4c-48a7-8081-745c3fa62769","05d0ec98-5acc-4675-b1eb-59a960f106e3","1268112c-a3a5-411d-9469-c9937aed533e","2134b0c5-7513-412c-8086-dd0ab2617359","27ebd924-13e6-492c-baf6-89fb5fd90d35","3ee33159-9045-4fd5-bf09-69bc05aea12d","452afc43-c279-4073-a560-11e917e9d8bf","46cf5621-f85c-485b-9c03-71906518223b","48e1124a-9df4-4b56-88df-74b2513fdf9f","4c9df9cf-99ab-4c22-88d4-f1440332377c","4d1371ec-867d-498c-89b7-0b556ef32910","5443ee2f-a083-4829-bfd3-b92e50b6d78e","569e288d-47cf-4f56-8596-95de1a779526","5f0085cf-8e40-43df-97be-3012f3288b9e","5faf992e-2f58-40c8-a9e2-ef2de4bb2262","6289c912-719d-40b6-8923-de5309a28e73","62e7ebd7-10f7-499a-afe0-4e276842ba5e","88c9fe36-7c07-42ec-bd48-d94ae3c114b9","91c127fc-af90-40c3-8a69-8410a8f7e984","923b100a-54e0-47f5-bcce-8226c0c8cc95","95c045c1-8cb8-4e1b-a998-54f8148a8647","9e1c8c0e-3e4d-470d-ab51-dcf55e5c08b5","aa27b71c-ff8e-44ba-9931-dcde5f99b337","c1c634fa-13aa-4e6e-8273-f1365b43b246","c3575d4a-31ba-4089-abbc-0d47a81929dd","c51035c2-81f7-4871-b1bd-b10ac2b60b51","cce3336d-27a2-4737-b4df-133d8db7dd71","d0d102c9-355c-4fa9-9078-2050917bb2dd","d2470b0c-b356-45b9-bedf-aabb0f71ceb9","e77475ea-0bc9-435a-a509-673b5ae099fc","e87f7d81-e2de-42e8-ae7e-084e453c7607","f8aa969e-8a07-471f-87c1-e7face412f2b"],"_id":"4eaf5bba-9100-4330-a7d8-91d527cc3c9d","abstract":"A phrase-based statistical machine translation approach — the alignment template approach — is described. This translation approach allows for general many-to-many relations between words. Thereby, the context of words is taken into account in the translation model, and local changes in word order from source to target language can be learned explicitly. The model is described using a log-linear modeling approach, which is a generalization of the often used source–channel approach. Thereby, the model is easier to extend than classical statistical machine translation systems. We describe in detail the process for learning phrasal translations, the feature functions used, and the search algorithm. The evaluation of this approach is performed on three different tasks. For the German–English speech VERBMOBIL task, we analyze the effect of various system components. On the French–English Canadian HANSARDS task, the alignment template system obtains significantly better results than a single-word-based translation model. In the Chinese–English 2002 National Institute of Standards and Technology (NIST) machine translation evaluation it yields statistically significantly better NIST scores than all competing research and commercial translation systems.","title":"The Alignment Template Approach to Statistical Machine Translation","venue":"Computational Linguistics","year":2004,"__v":0,"citationCount":422},{"authors":["Hermann Ney","S. Niessen","Franz Josef Och","Hassan Sawaf","C. Tillmann","Stephan Vogel"],"references":["00c30fb6-e977-4cef-ac0b-00e7223b2bc9","27ebd924-13e6-492c-baf6-89fb5fd90d35","3a74e461-4d4b-485c-9b0b-65866bbd6ad8","4a378909-2f5e-428f-b3e5-31a07683bb63","5443ee2f-a083-4829-bfd3-b92e50b6d78e","6289c912-719d-40b6-8923-de5309a28e73","8f7f3488-46ba-438b-aac7-fc432c8b4839","91c127fc-af90-40c3-8a69-8410a8f7e984","a43460d4-07b8-4647-bc39-602e42e46c01","a469efe9-4938-4576-aae6-c02413696035","a9a1fe46-7b55-4e97-a25e-ce59b3227e6c","c5f091b9-47ff-4eb1-b701-848788b2f24a","d0d102c9-355c-4fa9-9078-2050917bb2dd","e87f7d81-e2de-42e8-ae7e-084e453c7607","f53dc945-12f6-426f-9394-96aa5bb1a0f1"],"_id":"96fd2c01-1218-42b9-9cd2-7f517242aceb","abstract":"We describe three approaches to statistical translation and present experimental results. The statistical translation approach uses two types of information: a translation model and a language model. The language model used is a bigram or general m-gram model. The translation model is decomposed into a lexical model and an alignment model. There are three approaches that are presented and tested in detail: the quasi-monotone alignment approach, the inverted alignment approach, and the alignment template approach. For each of these three approaches, a suitable search method is presented. The system has been tested on a limited-domain spoken-language task for which a bilingual corpus is available: the Verbmobil task (German-English, 7000-word vocabulary). We present experimental results for each of the three approaches. The experimental tests were performed on both the text transcription and the speech recognizer output.","title":"Algorithms for statistical translation of spoken language","venue":"IEEE Transactions on Speech and Audio Processing","year":2000,"__v":0,"citationCount":39}],"offsprings":[]},"d06f8723-1b89-4684-99c9-c1045ddfb85c":{"authors":["Ion Stoica","Robert Morris","David R. Karger","M. Frans Kaashoek","Hari Balakrishnan"],"references":["4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4","e1263ada-afda-498c-a37d-9b545293118a"],"_id":"d06f8723-1b89-4684-99c9-c1045ddfb85c","abstract":"A fundamental problem that confronts peer-to-peer applications is to efficiently locate the node that stores a particular data item. This paper presents  Chord , a distributed lookup protocol that addresses this problem. Chord provides support for just one operation: given a key, it maps the key onto a node. Data location can be easily implemented on top of Chord by associating a key with each data item, and storing the key/data item pair at the node to which the key maps. Chord adapts efficiently as nodes join and leave the system, and can answer queries even if the system is continuously changing. Results from theoretical analysis, simulations, and experiments show that Chord is scalable, with communication cost and the state maintained by each node scaling logarithmically with the number of Chord nodes.","title":"Chord: A scalable peer-to-peer lookup service for internet applications","venue":"acm special interest group on data communication","year":2001,"__v":0,"citationCount":2568,"parents":{"1c729f22-9928-4703-92a0-8819569a1bbb":0,"1cc64868-4f72-4939-aed4-fc8fb0b45118":11.76470588235294,"48740ddd-afd1-4331-8af7-224ef5d19ed7":5.88235294117647,"4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4":70.58823529411765,"59084791-6ebd-4d0d-8f93-2c1da8d47490":0,"6500989e-b1e1-4b02-a921-21ec25685b73":5.88235294117647,"6aac8d9c-34bd-42d9-b887-b0a3bd697ee6":0,"6eff83a4-db80-40ea-8c9f-8bda5f506c29":0,"7502e770-12f7-4fd1-8cd6-f54f456f7aa8":47.05882352941176,"a1b950a0-345b-4471-ba60-872e4f8cc058":0,"a369afee-a619-4e9a-9250-5fd2b06e8a05":0,"aa89fd2a-319e-48b1-b0ab-099acbe37617":0,"b7d7ec53-f079-4bd7-a795-8b6fe77f2db6":47.05882352941176,"c0ea675b-2479-48ae-817e-3ecedd175ecf":5.88235294117647,"c37c70cb-3956-4249-934d-848845f2f444":0,"e1263ada-afda-498c-a37d-9b545293118a":29.411764705882355,"e4ee2d81-7629-4445-b4f3-55ef57bd42fd":5.88235294117647},"keyword":{"1c729f22-9928-4703-92a0-8819569a1bbb":5.55,"1cc64868-4f72-4939-aed4-fc8fb0b45118":9.161660561660561,"48740ddd-afd1-4331-8af7-224ef5d19ed7":10.11206349206349,"4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4":8.188888888888888,"59084791-6ebd-4d0d-8f93-2c1da8d47490":9.747222222222222,"6500989e-b1e1-4b02-a921-21ec25685b73":9.635714285714284,"6aac8d9c-34bd-42d9-b887-b0a3bd697ee6":9.160185185185187,"6eff83a4-db80-40ea-8c9f-8bda5f506c29":0,"7502e770-12f7-4fd1-8cd6-f54f456f7aa8":8.853373015873014,"a1b950a0-345b-4471-ba60-872e4f8cc058":8.694444444444445,"a369afee-a619-4e9a-9250-5fd2b06e8a05":7.943055555555555,"aa89fd2a-319e-48b1-b0ab-099acbe37617":8.521296296296297,"b7d7ec53-f079-4bd7-a795-8b6fe77f2db6":6.848888888888889,"c0ea675b-2479-48ae-817e-3ecedd175ecf":0,"c37c70cb-3956-4249-934d-848845f2f444":0,"e1263ada-afda-498c-a37d-9b545293118a":8.58637566137566,"e4ee2d81-7629-4445-b4f3-55ef57bd42fd":7.4603174603174605},"topic":["node","chord","kei","item","data"],"groups":[{"authors":["Frank Dabek","Emma Brunskill","M.F. Kaashoek","David R. Karger","Robert Morris","Ion Stoica","Hamsa Balakrishnan"],"references":["1c729f22-9928-4703-92a0-8819569a1bbb","1cc64868-4f72-4939-aed4-fc8fb0b45118","48740ddd-afd1-4331-8af7-224ef5d19ed7","4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4","6eff83a4-db80-40ea-8c9f-8bda5f506c29","9f65fe84-a2e3-420a-8fe4-7253e4605422","c0ea675b-2479-48ae-817e-3ecedd175ecf","e1263ada-afda-498c-a37d-9b545293118a","e4ee2d81-7629-4445-b4f3-55ef57bd42fd"],"_id":"7502e770-12f7-4fd1-8cd6-f54f456f7aa8","abstract":"We argue that the core problem facing peer-to-peer Systems is locating documents in a decentralized network and propose Chord, a distributed lookup primitive. Chord provides an efficient method of locating documents while placing few constraints on the applications that use it. As proof that Chord's functionality is useful in the development of peer-to-peer applications, we outline the implementation of a peer-to-peer file sharing system based on Chord.","title":"Building peer-to-peer systems with chord, a distributed lookup service","venue":"ieee international conference on requirements engineering","year":2001,"__v":0,"citationCount":108},{"authors":["Frank Dabek","M. Frans Kaashoek","David R. Karger","Robert Morris","Ion Stoica"],"references":["1c729f22-9928-4703-92a0-8819569a1bbb","1cc64868-4f72-4939-aed4-fc8fb0b45118","1dda408f-2203-4793-bfa8-2fab15bce7cf","48740ddd-afd1-4331-8af7-224ef5d19ed7","4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4","5e354aca-2d93-43f7-8e80-6bc4eb96e7d9","5fa0709f-7330-417f-8da7-3ab31d91da5b","6eff83a4-db80-40ea-8c9f-8bda5f506c29","786e7d9f-6e9a-47e5-8482-7ee37809b922","9f65fe84-a2e3-420a-8fe4-7253e4605422","a369afee-a619-4e9a-9250-5fd2b06e8a05","b1ab8eee-7043-4f04-b440-5765752d4845","b90c5640-8e10-4f65-9193-c28af80f45e2","bd61df44-c80e-406c-8c4e-9c13635ce4f5","c0ea675b-2479-48ae-817e-3ecedd175ecf","cb0dcdc4-3c84-4301-891b-42535ac74f8c","cf67f4c1-ff76-4210-ba80-0356733c5be7","e1263ada-afda-498c-a37d-9b545293118a","f14df1ed-e3e9-4348-9040-fc06e3411b95"],"_id":"b7d7ec53-f079-4bd7-a795-8b6fe77f2db6","abstract":"The Cooperative File System (CFS) is a new peer-to-peer read-only storage system that provides provable guarantees for the efficiency, robustness, and load-balance of file storage and retrieval. CFS does this with a completely decentralized architecture that can scale to large systems. CFS servers provide a distributed hash table (DHash) for block storage. CFS clients interpret DHash blocks as a file system. DHash distributes and caches blocks at a fine granularity to achieve load balance, uses replication for robustness, and decreases latency with server selection. DHash finds blocks using the Chord location protocol, which operates in time logarithmic in the number of servers.CFS is implemented using the SFS file system toolkit and runs on Linux, OpenBSD, and FreeBSD. Experience on a globally deployed prototype shows that CFS delivers data to clients as fast as FTP. Controlled tests show that CFS is scalable: with 4,096 servers, looking up a block of data involves contacting only seven servers. The tests also demonstrate nearly perfect robustness and unimpaired performance even when as many as half the servers fail.","title":"Wide-area cooperative storage with CFS","venue":"symposium on operating systems principles","year":2001,"__v":0,"citationCount":784},{"authors":["Ion Stoica","Robert Morris","David Liben-Nowell","David R. Karger","M. Frans Kaashoek","Frank Dabek","Hari Balakrishnan"],"references":["1cc64868-4f72-4939-aed4-fc8fb0b45118","48740ddd-afd1-4331-8af7-224ef5d19ed7","59084791-6ebd-4d0d-8f93-2c1da8d47490","6aac8d9c-34bd-42d9-b887-b0a3bd697ee6","6eff83a4-db80-40ea-8c9f-8bda5f506c29","a369afee-a619-4e9a-9250-5fd2b06e8a05","aa89fd2a-319e-48b1-b0ab-099acbe37617","abf003a2-6485-41f0-a111-88b80412d539","b7d7ec53-f079-4bd7-a795-8b6fe77f2db6","b948f5db-4dc3-4151-a9bd-62a3f5be739e","c0ea675b-2479-48ae-817e-3ecedd175ecf","c37c70cb-3956-4249-934d-848845f2f444","e1263ada-afda-498c-a37d-9b545293118a","e4ee2d81-7629-4445-b4f3-55ef57bd42fd","ea44a1ae-ddfe-4694-8df1-0ec69182ec11","f14df1ed-e3e9-4348-9040-fc06e3411b95","f49921e2-fb25-48d1-aaf2-1afcfeb8b268","fad8fc34-ff78-45ac-bc30-ca9e4173740f"],"_id":"4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4","abstract":"A fundamental problem that confronts peer-to-peer applications is the efficient location of the node that stores a desired data item. This paper presents  Chord , a distributed lookup protocol that addresses this problem. Chord provides support for just one operation: given a key, it maps the key onto a node. Data location can be easily implemented on top of Chord by associating a key with each data item, and storing the key/data pair at the node to which the key maps. Chord adapts efficiently as nodes join and leave the system, and can answer queries even if the system is continuously changing. Results from theoretical analysis and simulations show that Chord is scalable: Communication cost and the state maintained by each node scale logarithmically with the number of Chord nodes.","title":"Chord: a scalable peer-to-peer lookup protocol for Internet applications","venue":"IEEE\\/ACM Transactions on Networking","year":2003,"__v":0,"citationCount":5975},{"authors":["Sylvia Ratnasamy","Paul Francis","Mark Handley","Richard M. Karp","Scott Shenker"],"references":["00ade209-5974-42c1-9089-a3741481d9c7","0695070f-320e-4d26-9c68-2c8faa20c944","0a094924-1b25-43cc-ac8b-dd8cf90a8f78","1545dfd3-2c25-4ff1-b43c-df4a2a501d06","1cc64868-4f72-4939-aed4-fc8fb0b45118","31c5e39a-3f24-4d20-bf8c-3d00036baf95","39adcd6c-0b60-430c-99ab-21cd9e98b385","42c70869-0dad-4629-93b5-a2d9e29071a7","4743d708-b82d-42ec-adaa-a8bf2f23cc38","483cb980-c968-48e6-b848-714ed2937f98","48740ddd-afd1-4331-8af7-224ef5d19ed7","4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4","88c35cd8-dd49-44f8-9674-96974c8f3650","c0ea675b-2479-48ae-817e-3ecedd175ecf","c8771a57-de9c-44b7-966c-1ff156d3091f","d06f8723-1b89-4684-99c9-c1045ddfb85c","e4ee2d81-7629-4445-b4f3-55ef57bd42fd","ec7d1720-3285-4729-b819-b4c58a826ec8","f6fc4443-7a98-4f9f-92e8-e4e5d94521a7"],"_id":"e1263ada-afda-498c-a37d-9b545293118a","abstract":"Hash tables - which map \"keys\" onto \"values\" - are an essential building block in modern software systems. We believe a similar functionality would be equally valuable to large distributed systems. In this paper, we introduce the concept of a Content-Addressable Network (CAN) as a distributed infrastructure that provides hash table-like functionality on Internet-like scales. The CAN is scalable, fault-tolerant and completely self-organizing, and we demonstrate its scalability, robustness and low-latency properties through simulation.","title":"A scalable content-addressable network","venue":"acm special interest group on data communication","year":2001,"__v":0,"citationCount":3635}],"offsprings":["cb5922c5-575b-4b50-8d58-809f8256e948","e1263ada-afda-498c-a37d-9b545293118a"]},"d130ecec-e5cf-4f59-b4f8-1cbda4b0c307":{"authors":["Josef Kittler","Mohamad Hatef","Robert P. W. Duin","Jiri Matas"],"references":["3704f939-09a2-4e9f-b851-1261bcd310df"],"_id":"d130ecec-e5cf-4f59-b4f8-1cbda4b0c307","abstract":"We develop a common theoretical framework for combining classifiers which use distinct pattern representations and show that many existing schemes can be considered as special cases of compound classification where all the pattern representations are used jointly to make a decision. An experimental comparison of various classifier combination schemes demonstrates that the combination rule developed under the most restrictive assumptions-the sum rule-outperforms other classifier combinations schemes. A sensitivity analysis of the various schemes to estimation errors is carried out to show that this finding can be justified theoretically.","title":"On combining classifiers","venue":"IEEE Transactions on Pattern Analysis and Machine Intelligence","year":1998,"__v":0,"citationCount":2464,"parents":{"04f57ccb-910a-480c-bcae-04da0e346e6d":13.333333333333334,"0c74037a-2723-4134-b0a6-3ddef3bc15c8":0,"0f115eea-2272-431f-9f21-6d6789b2bbc9":0,"1043e892-3837-4aa4-85ef-c40bbb0b5e4b":0,"17d88dfa-a5b8-47dd-9fb6-8779e5091c85":6.666666666666667,"17f811d8-8607-4270-bbec-1cc7883edd68":6.666666666666667,"1b544060-6e98-4c59-97a3-8d436694526f":0,"1baf30f2-9168-4f20-8630-d28ce7b422e9":0,"26696685-4c15-4781-8785-30f4ac8ce2be":0,"3704f939-09a2-4e9f-b851-1261bcd310df":3.3333333333333335,"3a12bd7c-5d08-4b77-a31d-93801f655f51":3.3333333333333335,"5206bed9-d48d-44ab-b0cd-4731dfe5679c":0,"55630672-8044-451c-a2e6-6b79e54217b8":0,"580cb16b-97bf-43ed-8850-85b5918bdb83":3.3333333333333335,"6679e3d1-e19f-4a48-8a86-8538631e364e":6.666666666666667,"69847e37-f690-42ab-869f-eb317129f32c":0,"6c68311c-2745-446f-9c09-df4632392a78":3.3333333333333335,"7ad9e2a1-79e0-40d0-b45b-37bfa77b29af":10,"80b153d5-1b0d-4d12-8571-f0d6a6a9a5c8":3.3333333333333335,"84806dbe-fa0e-47c0-b1f2-00fb2eed25a7":0,"8839d828-c957-41b0-81c8-060e159482f9":13.333333333333334,"90358faa-154d-4f30-b15c-c125eb1b08b7":0,"a8818c16-0aae-452a-b8c2-f2c7dd19a85b":0,"a9b505ce-b5a3-47bc-9a57-d492e2441a86":3.3333333333333335,"b393b876-6833-4388-b9b9-8089c6c718d6":0,"bb08006d-9062-471e-b357-36ce7574b3bc":0,"d3b865bc-69e2-4426-9e7a-d01f0180a3ec":6.666666666666667,"e62ff43e-b9cf-4db3-91ad-8e1e74384a7c":0,"e6c03ded-e92c-4a46-b647-f9011b04eb71":0,"f8662e28-d012-4855-9dc7-5b5aa832f11f":23.333333333333332},"keyword":{"04f57ccb-910a-480c-bcae-04da0e346e6d":12.506732804232803,"0c74037a-2723-4134-b0a6-3ddef3bc15c8":11.009126984126981,"0f115eea-2272-431f-9f21-6d6789b2bbc9":0,"1043e892-3837-4aa4-85ef-c40bbb0b5e4b":10.5765873015873,"17d88dfa-a5b8-47dd-9fb6-8779e5091c85":9.05404761904762,"17f811d8-8607-4270-bbec-1cc7883edd68":9.945317460317458,"1b544060-6e98-4c59-97a3-8d436694526f":9.439484126984127,"1baf30f2-9168-4f20-8630-d28ce7b422e9":0,"26696685-4c15-4781-8785-30f4ac8ce2be":6.7936507936507935,"3704f939-09a2-4e9f-b851-1261bcd310df":10.119444444444442,"3a12bd7c-5d08-4b77-a31d-93801f655f51":11.048849206349207,"5206bed9-d48d-44ab-b0cd-4731dfe5679c":7.509920634920635,"55630672-8044-451c-a2e6-6b79e54217b8":10.444285714285714,"580cb16b-97bf-43ed-8850-85b5918bdb83":7.667460317460318,"6679e3d1-e19f-4a48-8a86-8538631e364e":10.173989898989898,"69847e37-f690-42ab-869f-eb317129f32c":10.873425925925927,"6c68311c-2745-446f-9c09-df4632392a78":9.099206349206346,"7ad9e2a1-79e0-40d0-b45b-37bfa77b29af":11.346428571428568,"80b153d5-1b0d-4d12-8571-f0d6a6a9a5c8":8.81706349206349,"84806dbe-fa0e-47c0-b1f2-00fb2eed25a7":10.949920634920634,"8839d828-c957-41b0-81c8-060e159482f9":9.47281746031746,"90358faa-154d-4f30-b15c-c125eb1b08b7":7.2153174603174595,"a8818c16-0aae-452a-b8c2-f2c7dd19a85b":9.985912698412697,"a9b505ce-b5a3-47bc-9a57-d492e2441a86":7.247301587301587,"b393b876-6833-4388-b9b9-8089c6c718d6":11.08578042328042,"bb08006d-9062-471e-b357-36ce7574b3bc":8.503968253968255,"d3b865bc-69e2-4426-9e7a-d01f0180a3ec":10.20535714285714,"e62ff43e-b9cf-4db3-91ad-8e1e74384a7c":10.060317460317458,"e6c03ded-e92c-4a46-b647-f9011b04eb71":11.009126984126981,"f8662e28-d012-4855-9dc7-5b5aa832f11f":14.493650793650792},"topic":["scheme","combin","classifi","theoret","show"],"groups":[{"authors":["Josef Kittler","M. Hater","R.P.W. Duin"],"references":["1043e892-3837-4aa4-85ef-c40bbb0b5e4b","17d88dfa-a5b8-47dd-9fb6-8779e5091c85","1b544060-6e98-4c59-97a3-8d436694526f","84806dbe-fa0e-47c0-b1f2-00fb2eed25a7","a9b505ce-b5a3-47bc-9a57-d492e2441a86","bb08006d-9062-471e-b357-36ce7574b3bc","e62ff43e-b9cf-4db3-91ad-8e1e74384a7c"],"_id":"f8662e28-d012-4855-9dc7-5b5aa832f11f","abstract":"We develop a common theoretical framework for combining classifiers which use distinct pattern representations and show that many existing schemes can be considered as special cases of compound classification where all the pattern representations are used jointly to make a decision. An experimental comparison of various classifier combination schemes demonstrates that the combination rule developed under the most restrictive assumptions-the sum rule-and its derivatives consistently outperform other classifier combinations schemes. A sensitivity analysis of the various schemes to estimation errors is carried out to show that this finding can be justified theoretically.","title":"Combining classifiers","venue":"international conference on pattern recognition","year":1996,"__v":0,"citationCount":61}],"offsprings":["7b57db11-7c4d-4d1e-aa62-3a5d7d1f7987"]},"d1c93534-82a5-41fa-a5fa-9d18f5c2577f":{"authors":["Rakesh Agrawal","Ramakrishnan Srikant"],"references":[],"_id":"d1c93534-82a5-41fa-a5fa-9d18f5c2577f","abstract":"We are given a large database of customer transactions, where each transaction consists of customer-id, transaction time, and the items bought in the transaction. We introduce the problem of mining sequential patterns over such databases. We present three algorithms to solve this problem, and empirically evaluate their performance using synthetic data. Two of the proposed algorithms, AprioriSome and AprioriAll, have comparable performance, albeit AprioriSome performs a little better when the minimum number of customers that must support a sequential pattern is low. Scale-up experiments show that both AprioriSome and AprioriAll scale linearly with the number of customer transactions. They also have excellent scale-up properties with respect to the number of transactions per customer and the number of items in a transaction. >","title":"Mining sequential patterns","venue":"international conference on data engineering","year":1995,"__v":0,"citationCount":2195,"parents":{"028d6483-da3d-4b53-bf89-d8360253d1df":0,"4b49ef32-8ff4-4e26-92a2-49ec8df4d182":0,"5fec7ec9-a6ad-4793-89a7-f834305b4e4f":0,"9f9034e7-bb14-4c9e-ba49-ec6205d4b998":0,"c57b94b1-c16a-4c6c-b11a-cc8c31c9a60d":75,"d4110879-6468-4ad1-89b0-e996886a8296":0,"e0c59c5a-9e4f-4ede-9b6c-3cc066a1f4ed":0,"ecd6a845-8439-49b0-abe8-f71fff81da23":0},"keyword":{"028d6483-da3d-4b53-bf89-d8360253d1df":10.223055555555558,"4b49ef32-8ff4-4e26-92a2-49ec8df4d182":0,"5fec7ec9-a6ad-4793-89a7-f834305b4e4f":0,"9f9034e7-bb14-4c9e-ba49-ec6205d4b998":0,"c57b94b1-c16a-4c6c-b11a-cc8c31c9a60d":12.314021164021163,"d4110879-6468-4ad1-89b0-e996886a8296":10.538492063492066,"e0c59c5a-9e4f-4ede-9b6c-3cc066a1f4ed":0,"ecd6a845-8439-49b0-abe8-f71fff81da23":11.637910052910051},"topic":["transact","number","custom","perform","apriorisom"],"groups":[{"authors":["Jason Tsong-li Wang","Gung-Wei Chirn","Thomas G. Marr","Bruce A. Shapiro","Dennis E. Shasha","Kaizhong Zhang"],"references":["028d6483-da3d-4b53-bf89-d8360253d1df","070e1f87-cdaa-4247-a63f-6ef45d4fc851","0a5e664b-b745-42dd-9f1d-513c4eafe841","0cb06ffe-08d6-4163-b5c7-ca2953b8b3b6","101f322b-98e8-4f11-af4f-aefa1be52b26","18fcee90-9582-4e29-b6de-e2c21d3b5166","23a28597-5676-4f25-8e14-b5ba8248f4fc","24e6ebc0-f597-4ca2-9df9-aa8117b94207","2bcfee98-c043-4b2a-9f8d-c12ceb11aa13","4236e567-7091-4af1-8e29-accd48c585ff","4b49ef32-8ff4-4e26-92a2-49ec8df4d182","55a3a0e0-c8b2-4d61-b9b8-9f203aa7f199","56cc7433-2d37-4cec-83fd-62f33698c3d4","5ab0756f-b081-4fc0-aa3d-de810e502a01","5fec7ec9-a6ad-4793-89a7-f834305b4e4f","6aeddde6-4ea1-408c-9a94-dcb62da186c9","8f2e1a56-39e9-4ca5-92ac-7effd48f0906","9596409f-0b6d-47b2-9873-51ce2f2802e7","9f9034e7-bb14-4c9e-ba49-ec6205d4b998","a41e63ef-df38-4327-b82b-b15a856cbfd4","a797b9a0-f494-43a6-8872-8642982b42c8","ad471af1-9da3-479b-a189-b39cf580bd95","c7f9bfa8-3e86-4404-970f-a84f2575dd8a","e0398fde-a5f7-4720-91a7-6316c7f0db06","e0c59c5a-9e4f-4ede-9b6c-3cc066a1f4ed","ecd6a845-8439-49b0-abe8-f71fff81da23","f250de0e-28d6-4832-9a50-4dfd10d4d36b"],"_id":"c57b94b1-c16a-4c6c-b11a-cc8c31c9a60d","abstract":"Suppose you are given a set of natural entities (e.g., proteins, organisms, weather patterns, etc.) that possess some important common externally observable properties. You also have a structural description of the entities (e.g., sequence, topological, or geometrical data) and a distance metric. Combinatorial pattern discovery is the activity of finding patterns in the structural data that might explain these common properties based on the metric.  This paper presents an example of combinatorial pattern discovery: the discovery of patterns in protein databases. The structural representation we consider are strings and the distance metric is string edit distance permitting variable length don't cares. Our techniques incorporate string matching algorithms and novel heuristics for discovery and optimization, most of which generalize to other combinatorial structures. Experimental results of applying the techniques to both generated data and functionally related protein families obtained from the Cold Spring Harbor Laboratory show the effectiveness of the proposed techniques. When we apply the discovered patterns to perform protein classification, they give information that is complementary to the best protein classifier available today.","title":"Combinatorial pattern discovery for scientific data: some preliminary results","venue":"international conference on management of data","year":1994,"__v":0,"citationCount":103}],"offsprings":["5a4a1b04-b36f-402c-a87f-0779098ef050"]},"d3b0635e-5447-435d-9975-a2582d19fc37":{"authors":["Latanya Sweeney"],"references":[],"_id":"d3b0635e-5447-435d-9975-a2582d19fc37","abstract":"Consider a data holder, such as a hospital or a bank, that has a privately held collection of person-specific, field structured data. Suppose the data holder wants to share a version of the data with researchers. How can a data holder release a version of its private data with scientific guarantees that the individuals who are the subjects of the data cannot be re-identified while the data remain practically useful? The solution provided in this paper includes a formal protection model named k-anonymity and a set of accompanying policies for deployment. A release provides k-anonymity protection if the information for each person contained in the release cannot be distinguished from at least k-1 individuals whose information also appears in the release. This paper also examines re-identification attacks that can be realized on releases that adhere to k- anonymity unless accompanying policies are respected. The k-anonymity protection model is important because it forms the basis on which the real-world systems known as Datafly, µ-Argus and k-Similar provide guarantees of privacy protection.","title":"k -anonymity: a model for protecting privacy","venue":"International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems","year":2002,"__v":0,"citationCount":2258,"parents":{"0209f687-94ed-4db7-8ae4-67544a5c5db7":36.36363636363637,"51a45f4f-73ab-4b4f-bbb8-706a227fada2":18.181818181818183,"5667dd20-726f-4c54-9cae-3707e5dbf524":0,"81e0014b-324f-4591-bbd7-4df76f4ff3cd":18.181818181818183,"8f481941-6df4-4777-9fbb-489c02b185f5":0,"c84bdc51-9901-4d62-9c9b-5a48394ad4bc":0,"df4b9319-db76-4f7f-b9b2-74f04347269d":0,"e2f4b493-660e-4a12-98c2-eea39795f758":27.27272727272727,"efe2dd1d-706c-4ab6-bd9b-90d35a81d04f":0,"fb733d35-ff61-449f-aa05-d8614cbc761b":9.090909090909092,"ff6cef9f-eb6b-4767-bcbe-6ad0b4c6045d":27.27272727272727},"keyword":{"0209f687-94ed-4db7-8ae4-67544a5c5db7":9.886904761904763,"51a45f4f-73ab-4b4f-bbb8-706a227fada2":10.473571428571429,"5667dd20-726f-4c54-9cae-3707e5dbf524":11.966825396825396,"81e0014b-324f-4591-bbd7-4df76f4ff3cd":8.300661375661374,"8f481941-6df4-4777-9fbb-489c02b185f5":9.356349206349208,"c84bdc51-9901-4d62-9c9b-5a48394ad4bc":10.123809523809523,"df4b9319-db76-4f7f-b9b2-74f04347269d":10.155555555555555,"e2f4b493-660e-4a12-98c2-eea39795f758":8.92936507936508,"efe2dd1d-706c-4ab6-bd9b-90d35a81d04f":11.320952380952383,"fb733d35-ff61-449f-aa05-d8614cbc761b":9.094444444444445,"ff6cef9f-eb6b-4767-bcbe-6ad0b4c6045d":9.466666666666665},"topic":["data","releas","protect","kanonym","holder"],"groups":[{"authors":["Xiaolei Qian","Mark E. Stickel","Peter D. Karp","Teresa F. Lunt","Thomas D. Garvey"],"references":["0209f687-94ed-4db7-8ae4-67544a5c5db7","1e41711b-949a-4109-986c-f213f9830bee","24290f50-77cf-4935-89ea-919661b26586","74a50e84-8cd8-4bd3-8163-27ec4e577f67","c84bdc51-9901-4d62-9c9b-5a48394ad4bc","d5035f5a-5063-4de8-855f-4a61b92c6bbd","fb733d35-ff61-449f-aa05-d8614cbc761b"],"_id":"e2f4b493-660e-4a12-98c2-eea39795f758","abstract":"Multilevel relational database systems store information at different security classifications. An inference problem exists if it is possible for a user with a low-level clearance to draw conclusions about information at higher classifications. The authors are developing DISSECT, a tool for analyzing multilevel relational database schemas to assist in the detection and elimination of inference problems. A translation is defined from schemas to an equivalent graph representation, which can be presented graphically in DISSECT. The initial focus is on detection of inference problems that depend only on information all of which is stored in the database. In particular, potential inference problems are identified as different sequences of foreign key relationships that connect the same entities. Inferences can be blocked by upgrading the security classification of some of foreign key relationships. A global optimization approach to upgrading is suggested to block a set of inference problems that allows upgrade costs to be considered, and supports security categories as well as levels. >","title":"Detection and elimination of inference channels in multilevel relational database systems","venue":"ieee symposium on security and privacy","year":1993,"__v":0,"citationCount":26},{"authors":["Teresa F. Lunt"],"references":["24290f50-77cf-4935-89ea-919661b26586","3356c6f8-6a10-4ebd-894b-eceece1da867","894a8e14-edf6-4321-93b8-337a466adb62","c84bdc51-9901-4d62-9c9b-5a48394ad4bc","df4b9319-db76-4f7f-b9b2-74f04347269d","fb733d35-ff61-449f-aa05-d8614cbc761b"],"_id":"ff6cef9f-eb6b-4767-bcbe-6ad0b4c6045d","abstract":"The author examines inference and aggregation problems that can arise in multilevel relational database systems and points out some fallacies in current thinking about these problems that may hinder real progress from being made toward their solution. She distinguishes several different types of aggregation and inference problems and shows that the different types of problems are best addressed by different approaches. In particular, it is shown that sensitive associations among entities of different types are best treated by representing the sensitive association separately and classifying the individual entities low and the relationship high. Sensitive associations among the various properties of an entity are best treated by determining those properties that contribute most to the inference and by storing those separately at a higher classification. Sensitive associations among entities of the same type are best treated by storing the individual data items comprising the aggregate at the aggregate-high classification; they must be sanitized for release to lower-level users. The suggested approaches allow the mandatory reference monitor to protect the sensitive associations, with no additional trusted mechanism needed. >","title":"Aggregation and inference: facts and fallacies","venue":"ieee symposium on security and privacy","year":1989,"__v":0,"citationCount":37},{"authors":["Thomas D. Garvey","Teresa F. Lunt","Mark E. Stickel"],"references":["1acbb25a-3d1d-4948-a5cb-3274a87f6f76","24290f50-77cf-4935-89ea-919661b26586","2a73f987-98cc-4d8b-bf27-9d8d0834c57c","35375ee8-7dcc-4aec-9681-da295f24f969","3c36cf62-5101-4658-ba45-1301367c2a05","52dbdaf9-3754-4ee1-9a0a-4bda0029584d","9454ef50-a153-42b1-bb0c-606fac619396","c84bdc51-9901-4d62-9c9b-5a48394ad4bc","df4b9319-db76-4f7f-b9b2-74f04347269d","fb733d35-ff61-449f-aa05-d8614cbc761b","fd49e58a-e24d-44a4-9b4d-613195282174","ff6cef9f-eb6b-4767-bcbe-6ad0b4c6045d"],"_id":"0209f687-94ed-4db7-8ae4-67544a5c5db7","abstract":"A serious problem in computer database and knowledge base security is detecting and eliminating so-called inference channels. The existence of such channels enables a user with access to information classified at a low level to infer information classified at a high level, and through the transformation of low level data to high level data may provide an unacceptable information flow. In order to estimate the presence of inference channels, determine the degree of risk which they present, and find ways to eliminate them, one needs a formal model to describe them. The authors introduce abductive reasoning. Abduction provides both the basis for a formal model for the inference problem and a computational mechanism for detecting inference channels. Abduction additionally provides a framework for reasoning with approximate and uncertain information, which enables them to extend the model for inference channels by taking into account the likelihood that a person might believe some statement of interest. >","title":"Abductive and approximate reasoning models for characterizing inference channels","venue":"","year":1991,"__v":0,"citationCount":8}],"offsprings":[]},"d8116977-0962-4d4d-832d-f9b0a095c75c":{"authors":["M.S. Arulampalam","Simon Maskell","Neil J. Gordon","T. Clapp"],"references":[],"_id":"d8116977-0962-4d4d-832d-f9b0a095c75c","abstract":"Increasingly, for many application areas, it is becoming important to include elements of nonlinearity and non-Gaussianity in order to model accurately the underlying dynamics of a physical system. Moreover, it is typically crucial to process data on-line as it arrives, both from the point of view of storage costs as well as for rapid adaptation to changing signal characteristics. In this paper, we review both optimal and suboptimal Bayesian algorithms for nonlinear/non-Gaussian tracking problems, with a focus on particle filters. Particle filters are sequential Monte Carlo methods based on point mass (or \"particle\") representations of probability densities, which can be applied to any state-space model and which generalize the traditional Kalman filtering methods. Several variants of the particle filter such as SIR, ASIR, and RPF are introduced within a generic framework of the sequential importance sampling (SIS) algorithm. These are discussed and compared with the standard EKF through an illustrative example.","title":"A tutorial on particle filters for online nonlinear/non-Gaussian Bayesian tracking","venue":"IEEE Transactions on Signal Processing","year":2002,"__v":0,"citationCount":2793,"parents":{"31548231-500c-4604-b6a5-529d00d691dd":0,"5f54fdf9-4d11-4f33-945a-db3caa7fabce":14.285714285714285,"67efeb3a-56bb-4bd8-bc0b-dca8f84fa3d3":14.285714285714285,"8b5a79a9-8c51-4a30-9be2-f4ee63af7949":28.57142857142857,"ab421de9-79db-4fa2-97a5-f2437bc3cc46":0,"c2542b2b-306a-41a7-b774-be7cd5f3f186":0,"c4140a7e-f036-4816-a82f-9035ca99ed97":0},"keyword":{"31548231-500c-4604-b6a5-529d00d691dd":9.725436507936507,"5f54fdf9-4d11-4f33-945a-db3caa7fabce":12.787566137566136,"67efeb3a-56bb-4bd8-bc0b-dca8f84fa3d3":12.596587301587302,"8b5a79a9-8c51-4a30-9be2-f4ee63af7949":12.250383597883598,"ab421de9-79db-4fa2-97a5-f2437bc3cc46":0,"c2542b2b-306a-41a7-b774-be7cd5f3f186":6.8678968253968256,"c4140a7e-f036-4816-a82f-9035ca99ed97":11.483756613756613},"topic":["particl","filter","sequenti","point","model"],"groups":[{"authors":["Arnaud Doucet","Neil J. Gordon","Vikram Krishnamurthy"],"references":["2f0ec052-dd23-4a10-8156-22e4aa068cb3","440c82f4-7a7d-42c6-a492-1863625f556b","5feefedf-772a-4f41-a4b9-592a1d5f5811","67efeb3a-56bb-4bd8-bc0b-dca8f84fa3d3","9d853d1d-6f01-4a82-8014-edf45572f5a2","ab421de9-79db-4fa2-97a5-f2437bc3cc46","b1367519-5742-468f-834f-19421b79b2e3","be85d125-170b-41b8-8182-4f5680ac30c2","d5742d92-f727-4443-af9e-3d1e5165cb4d","ed4b475e-cacc-44a4-b929-bba692b4d24c"],"_id":"8b5a79a9-8c51-4a30-9be2-f4ee63af7949","abstract":"Jump Markov linear systems (JMLS) are linear systems whose parameters evolve with time according to a finite state Markov chain. In this paper, our aim is to recursively compute optimal state estimates for this class of systems. We present efficient simulation-based algorithms called particle filters to solve the optimal filtering problem as well as the optimal fixed-lag smoothing problem. Our algorithms combine sequential importance sampling, a selection scheme, and Markov chain Monte Carlo methods. They use several variance reduction methods to make the most of the statistical structure of JMLS. Computer simulations are carried out to evaluate the performance of the proposed algorithms. The problems of on-line deconvolution of impulsive processes and of tracking a maneuvering target are considered. It is shown that our algorithms outperform the current methods.","title":"Particle filters for state estimation of jump Markov linear systems","venue":"IEEE Transactions on Signal Processing","year":2001,"__v":0,"citationCount":221}],"offsprings":["79da913e-c4d6-4d89-831c-f68f7976dcfc"]},"d9154445-dd71-4815-8918-812ea39dbaaa":{"authors":["L. Benini","G. De Micheli"],"references":[],"_id":"d9154445-dd71-4815-8918-812ea39dbaaa","abstract":"On-chip micronetworks, designed with a layered methodology, will meet the distinctive challenges of providing functionally correct, reliable operation of interacting system-on-chip components. A system on chip (SoC) can provide an integrated solution to challenging design problems in the telecommunications, multimedia, and consumer electronics domains. Much of the progress in these fields hinges on the designers' ability to conceive complex electronic engines under strong time-to-market pressure. Success will require using appropriate design and process technologies, as well as interconnecting existing components reliably in a plug-and-play fashion. Focusing on using probabilistic metrics such as average values or variance to quantify design objectives such as performance and power will lead to a major change in SoC design methodologies. Overall, these designs will be based on both deterministic and stochastic models. Creating complex SoCs requires a modular, component-based approach to both hardware and software design. Despite numerous challenges, the authors believe that developers will solve the problems of designing SoC networks. At the same time, they believe that a layered micronetwork design methodology will likely be the only path to mastering the complexity of future SoC designs.","title":"Networks on chips: a new SoC paradigm","venue":"IEEE Computer","year":2002,"__v":0,"citationCount":1646,"parents":{"5cdb380b-9541-41f2-937d-744dab642af6":0,"609a72bc-0a5e-4e49-87f3-f5bc07533d24":0,"6912db40-9734-45cc-acfb-28333681ee4a":14.285714285714285,"89f3421f-cb5f-4fdf-b1a0-305efe9ace3b":14.285714285714285,"a9ae8126-6b7d-4ad4-b81a-fb0a2f401a0c":0,"b8bd5088-dff9-4cfc-958e-f9c2ec1eb5a1":0,"e9169bea-08b9-49d2-891c-ab65c4a7e4c4":0},"keyword":{"5cdb380b-9541-41f2-937d-744dab642af6":8.36031746031746,"609a72bc-0a5e-4e49-87f3-f5bc07533d24":8.624867724867725,"6912db40-9734-45cc-acfb-28333681ee4a":9.918001443001442,"89f3421f-cb5f-4fdf-b1a0-305efe9ace3b":9.737063492063493,"a9ae8126-6b7d-4ad4-b81a-fb0a2f401a0c":10.513280423280424,"b8bd5088-dff9-4cfc-958e-f9c2ec1eb5a1":10.379365079365082,"e9169bea-08b9-49d2-891c-ab65c4a7e4c4":10.44224867724868},"topic":["design","soc","methodolog","complex","challeng"],"offsprings":[]},"d9162547-fd7f-4605-855d-0a3173c4b08e":{"authors":["Reza Olfati-Saber","J.A. Fax","Robin M. Murray"],"references":["2768199c-b9d6-4001-94d3-e6429c93bc5f","b0ef6e4d-4c86-4b10-9e0a-7b630ca8d7f7","ea1d5c21-fba6-4fae-9fdc-ee7679ee46c9"],"_id":"d9162547-fd7f-4605-855d-0a3173c4b08e","abstract":"This paper provides a theoretical framework for analysis of consensus algorithms for multi-agent networked systems with an emphasis on the role of directed information flow, robustness to changes in network topology due to link/node failures, time-delays, and performance guarantees. An overview of basic concepts of information consensus in networks and methods of convergence and performance analysis for the algorithms are provided. Our analysis framework is based on tools from matrix theory, algebraic graph theory, and control theory. We discuss the connections between consensus problems in networked dynamic systems and diverse applications including synchronization of coupled oscillators, flocking, formation control, fast consensus in small-world networks, Markov processes and gossip-based algorithms, load balancing in networks, rendezvous in space, distributed sensor fusion in sensor networks, and belief propagation. We establish direct connections between spectral and structural properties of complex networks and the speed of information diffusion of consensus algorithms. A brief introduction is provided on networked systems with nonlocal information flow that are considerably faster than distributed systems with lattice-type nearest neighbor interactions. Simulation results are presented that demonstrate the role of small-world effects on the speed of consensus algorithms and cooperative control of multivehicle formations","title":"Consensus and Cooperation in Networked Multi-Agent Systems","venue":"Proceedings of the IEEE","year":2007,"__v":0,"citationCount":2275,"parents":{"069aa4a5-017b-49e3-ba71-20bcade4d634":0,"0aed8a11-15e1-4915-9563-f672e773dac6":25.806451612903224,"0bf829c3-d555-4745-b1a5-7c5ce8acbff6":16.129032258064516,"0cb61dc0-15c5-4592-a5fb-fd76d75f03ac":0,"13c9856f-e4f8-4c1c-b728-c8ccff9b7b4b":12.903225806451612,"223edc15-f2f7-4796-8b91-9fab63eda279":25.806451612903224,"2768199c-b9d6-4001-94d3-e6429c93bc5f":12.903225806451612,"306dfd3e-4a33-4c46-93d5-9d85acbf7503":0,"3c70f9d5-7190-4f0b-8fee-259bd8b94bca":0,"423548af-857e-4063-88b5-14cd2d7f2155":19.35483870967742,"6460eee0-033e-4185-8b7c-dbcb931e1b2c":22.58064516129032,"6fc28283-44d9-4329-8724-2fe71234bb4c":9.67741935483871,"83d84ff1-d492-4e05-9576-a32bcff7401e":16.129032258064516,"860a3efc-800e-4e62-8200-7acf3f8d2b8d":0,"888171fc-10d9-4230-a916-b9ab6d1910f5":6.451612903225806,"89253643-14dd-4793-b95a-a54bc59e72ff":0,"8c581627-0fe3-46cf-99cf-c5e3c9af272e":16.129032258064516,"a139ef6c-e79b-4f63-a37d-21f4b2eeb2e2":3.225806451612903,"ab35dc68-62bd-4c54-81d3-9a8406827489":0,"aca928ab-a742-4ff7-bf7c-7ee7f5df4866":12.903225806451612,"b0ef6e4d-4c86-4b10-9e0a-7b630ca8d7f7":0,"bfdd519a-0bb8-4ea6-b0ce-2ad0cb05dfe0":16.129032258064516,"c3b374ba-8057-4dce-8510-cc83c5be2e00":0,"cc259597-c637-451f-96ae-dd92d7f697c9":9.67741935483871,"d63017ca-4753-4a83-92df-7b18c5fc3a2e":3.225806451612903,"d63aeb27-62f3-4d6e-a6df-aed1f6a74609":16.129032258064516,"d7b5aadf-ec30-4fb7-9224-7474169d3744":9.67741935483871,"ea1d5c21-fba6-4fae-9fdc-ee7679ee46c9":0,"ec5cea52-381b-4263-ac39-5f59db9b0f91":0,"efed0c9f-6b90-4c0a-ba67-65d4b2bee0de":16.129032258064516,"fb3683fe-a6d4-4918-b96e-595abd299183":3.225806451612903},"keyword":{"069aa4a5-017b-49e3-ba71-20bcade4d634":12.854497354497353,"0aed8a11-15e1-4915-9563-f672e773dac6":11.21388888888889,"0bf829c3-d555-4745-b1a5-7c5ce8acbff6":13.266269841269839,"0cb61dc0-15c5-4592-a5fb-fd76d75f03ac":10.553835978835977,"13c9856f-e4f8-4c1c-b728-c8ccff9b7b4b":13.125396825396827,"223edc15-f2f7-4796-8b91-9fab63eda279":10.95542328042328,"2768199c-b9d6-4001-94d3-e6429c93bc5f":12.01984126984127,"306dfd3e-4a33-4c46-93d5-9d85acbf7503":9.42357142857143,"3c70f9d5-7190-4f0b-8fee-259bd8b94bca":9.369444444444445,"423548af-857e-4063-88b5-14cd2d7f2155":12.783068783068783,"6460eee0-033e-4185-8b7c-dbcb931e1b2c":11.66537037037037,"6fc28283-44d9-4329-8724-2fe71234bb4c":11.683730158730159,"83d84ff1-d492-4e05-9576-a32bcff7401e":10.87931216931217,"860a3efc-800e-4e62-8200-7acf3f8d2b8d":8.334788359788359,"888171fc-10d9-4230-a916-b9ab6d1910f5":11.204973544973544,"89253643-14dd-4793-b95a-a54bc59e72ff":0,"8c581627-0fe3-46cf-99cf-c5e3c9af272e":11.647989417989418,"a139ef6c-e79b-4f63-a37d-21f4b2eeb2e2":11.147883597883597,"ab35dc68-62bd-4c54-81d3-9a8406827489":8.247089947089945,"aca928ab-a742-4ff7-bf7c-7ee7f5df4866":9.85452380952381,"b0ef6e4d-4c86-4b10-9e0a-7b630ca8d7f7":13.120767195767195,"bfdd519a-0bb8-4ea6-b0ce-2ad0cb05dfe0":10.645674603174605,"c3b374ba-8057-4dce-8510-cc83c5be2e00":11.443597883597883,"cc259597-c637-451f-96ae-dd92d7f697c9":12.248941798941798,"d63017ca-4753-4a83-92df-7b18c5fc3a2e":9.814113756613757,"d63aeb27-62f3-4d6e-a6df-aed1f6a74609":8.928042328042327,"d7b5aadf-ec30-4fb7-9224-7474169d3744":13.034788359788362,"ea1d5c21-fba6-4fae-9fdc-ee7679ee46c9":11.094550264550264,"ec5cea52-381b-4263-ac39-5f59db9b0f91":10.38531746031746,"efed0c9f-6b90-4c0a-ba67-65d4b2bee0de":8.996164021164022,"fb3683fe-a6d4-4918-b96e-595abd299183":0},"topic":["network","consensu","system","inform","algorithm"],"groups":[{"authors":["Lin Xiao","Stephen P. Boyd","Sanjay Lall"],"references":["0bf829c3-d555-4745-b1a5-7c5ce8acbff6","13c9856f-e4f8-4c1c-b728-c8ccff9b7b4b","2768199c-b9d6-4001-94d3-e6429c93bc5f","3e0215ac-0077-4b4a-b8eb-f8cfafe2e22e","48d356c2-09ec-4d5d-a812-094c5f673ee4","639941aa-1dad-4dbf-8514-f66954dff570","6460eee0-033e-4185-8b7c-dbcb931e1b2c","7f902672-aa10-49f5-9058-c58a4a4c7fa4","828ef5ed-7429-4d2f-8f11-20aaacf3eeb6","839602ef-a406-4282-9aa2-29ef2231e281","9e063b41-0ada-4db8-8846-6e5153a0de55","cb4ad0c9-1d94-4646-9480-9268704a85b6","cc259597-c637-451f-96ae-dd92d7f697c9","d7b5aadf-ec30-4fb7-9224-7474169d3744","ea1d5c21-fba6-4fae-9fdc-ee7679ee46c9","ec5cea52-381b-4263-ac39-5f59db9b0f91"],"_id":"0aed8a11-15e1-4915-9563-f672e773dac6","abstract":"We consider a network of distributed sensors, where where each sensor takes a linear measurement of some unknown parameters, corrupted by independent Gaussian noises. We propose a simple distributed iterative scheme, based on distributed average consensus in the network, to compute the maximum-likelihood estimate of the parameters. This scheme doesn't involve explicit point-to-point message passing or routing; instead, it diffuses information across the network by updating each node's data with a weighted average of its neighbors' data (they maintain the same data structure). At each step, every node can compute a local weighted least-squares estimate, which converges to the global maximum-likelihood solution. This scheme is robust to unreliable communication links. We show that it works in a network with dynamically changing topology, provided that the infinitely occurring communication graphs are jointly connected.","title":"A scheme for robust distributed sensor fusion based on average consensus","venue":"information processing in sensor networks","year":2005,"__v":0,"citationCount":478},{"authors":["Yuko Hatano","Mehran Mesbahi"],"references":["07dbc8df-6347-4dc5-a9ae-a4d8ab334fc2","0bb130dc-8e44-4bd2-a8e8-73bcd6603770","2768199c-b9d6-4001-94d3-e6429c93bc5f","6460eee0-033e-4185-8b7c-dbcb931e1b2c","6fc28283-44d9-4329-8724-2fe71234bb4c","ab35dc68-62bd-4c54-81d3-9a8406827489","cd857a7e-2e80-4fb9-b80a-a29474b23e0f","d7b5aadf-ec30-4fb7-9224-7474169d3744","ea1d5c21-fba6-4fae-9fdc-ee7679ee46c9"],"_id":"423548af-857e-4063-88b5-14cd2d7f2155","abstract":"We consider the agreement problem over random information networks. In a random network, the existence of an information channel between a pair of elements at each time instance is probabilistic and independent of other channels; hence, the topology of the network varies over time. In such a framework, we address the asymptotic agreement for the networked elements via notions from stochastic stability. Furthermore, we delineate on the rate of convergence as it relates to the algebraic connectivity of random graphs.","title":"Agreement over random networks","venue":"conference on decision and control","year":2004,"__v":0,"citationCount":228},{"authors":["Luc Moreau"],"references":["223edc15-f2f7-4796-8b91-9fab63eda279","2768199c-b9d6-4001-94d3-e6429c93bc5f","51a16a30-666c-4b4a-8962-ec187c59c399","551b0ff9-7423-4376-a3a0-dd6a352c4079","6dacf711-539e-4a41-b10a-0732f548bc57","ab35dc68-62bd-4c54-81d3-9a8406827489","aca928ab-a742-4ff7-bf7c-7ee7f5df4866","b8c3411b-4b2b-439c-b000-c4031758b377","d7b5aadf-ec30-4fb7-9224-7474169d3744","ea1d5c21-fba6-4fae-9fdc-ee7679ee46c9","efed0c9f-6b90-4c0a-ba67-65d4b2bee0de","f4a2e7f5-981d-4b4c-a70c-797e2c72f36c"],"_id":"6460eee0-033e-4185-8b7c-dbcb931e1b2c","abstract":"We study a simple but compelling model of network of agents interacting via time-dependent communication links. The model finds application in a variety of fields including synchronization, swarming and distributed decision making. In the model, each agent updates his current state based upon the current information received from neighboring agents. Necessary and/or sufficient conditions for the convergence of the individual agents' states to a common value are presented, thereby extending recent results reported in the literature. The stability analysis is based upon a blend of graph-theoretic and system-theoretic tools with the notion of convexity playing a central role. The analysis is integrated within a formal framework of set-valued Lyapunov theory, which may be of independent interest. Among others, it is observed that more communication does not necessarily lead to faster convergence and may eventually even lead to a loss of convergence, even for the simple models discussed in the present paper.","title":"Stability of multiagent systems with time-dependent communication links","venue":"IEEE Transactions on Automatic Control","year":2005,"__v":0,"citationCount":855},{"authors":["Reza Olfati-Saber"],"references":["0bf829c3-d555-4745-b1a5-7c5ce8acbff6","2768199c-b9d6-4001-94d3-e6429c93bc5f","30932642-fd17-4ae9-9a5b-90e67adcfe41","51a16a30-666c-4b4a-8962-ec187c59c399","551b0ff9-7423-4376-a3a0-dd6a352c4079","6460eee0-033e-4185-8b7c-dbcb931e1b2c","6fc28283-44d9-4329-8724-2fe71234bb4c","9e063b41-0ada-4db8-8846-6e5153a0de55","ab35dc68-62bd-4c54-81d3-9a8406827489","ad5e3f89-61b7-4e90-9d02-f6df3ab7d927","b6a0562d-91b9-4b65-a395-0e705e24f3ba","bf96410c-8b91-41bf-aff4-ed144c1b6e8c","d65d26b4-a0e0-4112-ae22-2f3a4b51d7b3","ea1d5c21-fba6-4fae-9fdc-ee7679ee46c9","efed0c9f-6b90-4c0a-ba67-65d4b2bee0de","f8ece2c5-c8b1-4a1e-8528-c09357ec23a4","fb3683fe-a6d4-4918-b96e-595abd299183"],"_id":"223edc15-f2f7-4796-8b91-9fab63eda279","abstract":"In this paper, we present a theoretical framework for design and analysis of distributed flocking algorithms. Two cases of flocking in free-space and presence of multiple obstacles are considered. We present three flocking algorithms: two for free-flocking and one for constrained flocking. A comprehensive analysis of the first two algorithms is provided. We demonstrate the first algorithm embodies all three rules of Reynolds. This is a formal approach to extraction of interaction rules that lead to the emergence of collective behavior. We show that the first algorithm generically leads to regular fragmentation, whereas the second and third algorithms both lead to flocking. A systematic method is provided for construction of cost functions (or collective potentials) for flocking. These collective potentials penalize deviation from a class of lattice-shape objects called /spl alpha/-lattices. We use a multi-species framework for construction of collective potentials that consist of flock-members, or /spl alpha/-agents, and virtual agents associated with /spl alpha/-agents called /spl beta/- and /spl gamma/-agents. We show that migration of flocks can be performed using a peer-to-peer network of agents, i.e., \"flocks need no leaders.\" A \"universal\" definition of flocking for particle systems with similarities to Lyapunov stability is given. Several simulation results are provided that demonstrate performing 2-D and 3-D flocking, split/rejoin maneuver, and squeezing maneuver for hundreds of agents using the proposed algorithms.","title":"Flocking for multi-agent dynamic systems: algorithms and theory","venue":"IEEE Transactions on Automatic Control","year":2006,"__v":0,"citationCount":1026}],"offsprings":[]},"d924ecc1-ce71-4250-ae5d-570769554f74":{"authors":["Minqing Hu","Bing Liu"],"references":["c75c7b08-7264-4daa-a133-59bea66db0c7","ed543a19-85d9-427a-a2d3-88e7c59a100e"],"_id":"d924ecc1-ce71-4250-ae5d-570769554f74","abstract":"Merchants selling products on the Web often ask their customers to review the products that they have purchased and the associated services. As e-commerce is becoming more and more popular, the number of customer reviews that a product receives grows rapidly. For a popular product, the number of reviews can be in hundreds or even thousands. This makes it difficult for a potential customer to read them to make an informed decision on whether to purchase the product. It also makes it difficult for the manufacturer of the product to keep track and to manage customer opinions. For the manufacturer, there are additional difficulties because many merchant sites may sell the same product and the manufacturer normally produces many kinds of products. In this research, we aim to mine and to summarize all the customer reviews of a product. This summarization task is different from traditional text summarization because we only mine the features of the product on which the customers have expressed their opinions and whether the opinions are positive or negative. We do not summarize the reviews by selecting a subset or rewrite some of the original sentences from the reviews to capture the main points as in the classic text summarization. Our task is performed in three steps: (1) mining product features that have been commented on by customers; (2) identifying opinion sentences in each review and deciding whether each opinion sentence is positive or negative; (3) summarizing the results. This paper proposes several novel techniques to perform these tasks. Our experimental results using reviews of a number of products sold online demonstrate the effectiveness of the techniques.","title":"Mining and summarizing customer reviews","venue":"knowledge discovery and data mining","year":2004,"__v":0,"citationCount":1685,"parents":{"003ea2d8-91f5-404e-908a-a71ff39694af":0,"0247c082-ca1e-4745-acc0-7404940e4adc":3.7037037037037033,"135c7d8b-578a-462d-98d0-0288eec3a9fc":3.7037037037037033,"1370199f-0419-440b-8802-76ac08105669":0,"21421f14-af9c-4c95-9aad-b7bece9fb7d9":0,"23b2db98-6897-497b-8b90-67b591016a5e":0,"300213b7-c3c6-4cd6-b025-455ae16bd151":0,"34b7e270-80d7-46d5-a6f1-e50087a8d045":0,"40daa31a-d807-4f6a-9f22-021febf46e98":22.22222222222222,"43bcc79f-1316-4a3c-81ba-69e6c3afbcbb":11.11111111111111,"56b692e8-5737-4006-ad56-793cb41ee44e":0,"6e6518a0-01a9-46ac-b4ca-0cf34155ae55":3.7037037037037033,"71ecd1d2-c656-489d-95a6-503e31e3e05f":0,"8a241aa9-efd5-4ad4-9dcf-8116edb1e349":3.7037037037037033,"90ca3ecc-702a-45ab-af75-8c5851ce7bb9":0,"9c2be164-0b3f-4a94-9c98-9a6c0d77c367":0,"aab1a31b-5b8b-42af-8300-f1da4dc67827":14.814814814814813,"ab339474-ea21-443b-893f-96ae09e65a2e":3.7037037037037033,"b5ea191d-2c02-4c4a-b887-0c6d3c958ce9":7.4074074074074066,"c512fe3b-b9c4-40a1-a205-8ca01effdeb0":3.7037037037037033,"c75c7b08-7264-4daa-a133-59bea66db0c7":11.11111111111111,"c8a1eae3-e8ea-41de-a471-a2539c9cfa9c":3.7037037037037033,"c99f13bd-28d1-41dd-9ac8-0b8688118611":29.629629629629626,"cf111a55-139a-4108-bf05-a8e25ec7874f":3.7037037037037033,"d0d1fa34-c4a1-4e6d-bc58-a5cf5012c11f":11.11111111111111,"ed543a19-85d9-427a-a2d3-88e7c59a100e":25.925925925925924,"f2d9455d-9f46-4cd9-993e-25bab1ce4792":0},"keyword":{"003ea2d8-91f5-404e-908a-a71ff39694af":11.001719576719578,"0247c082-ca1e-4745-acc0-7404940e4adc":9.305873015873017,"135c7d8b-578a-462d-98d0-0288eec3a9fc":9.957936507936507,"1370199f-0419-440b-8802-76ac08105669":11.954497354497354,"21421f14-af9c-4c95-9aad-b7bece9fb7d9":11.374603174603175,"23b2db98-6897-497b-8b90-67b591016a5e":9.926216931216931,"300213b7-c3c6-4cd6-b025-455ae16bd151":10.032936507936508,"34b7e270-80d7-46d5-a6f1-e50087a8d045":0,"40daa31a-d807-4f6a-9f22-021febf46e98":9.244444444444442,"43bcc79f-1316-4a3c-81ba-69e6c3afbcbb":9.127777777777778,"56b692e8-5737-4006-ad56-793cb41ee44e":0,"6e6518a0-01a9-46ac-b4ca-0cf34155ae55":6.84984126984127,"71ecd1d2-c656-489d-95a6-503e31e3e05f":0,"8a241aa9-efd5-4ad4-9dcf-8116edb1e349":0,"90ca3ecc-702a-45ab-af75-8c5851ce7bb9":9.392592592592592,"9c2be164-0b3f-4a94-9c98-9a6c0d77c367":0,"aab1a31b-5b8b-42af-8300-f1da4dc67827":8.03809523809524,"ab339474-ea21-443b-893f-96ae09e65a2e":9.39424603174603,"b5ea191d-2c02-4c4a-b887-0c6d3c958ce9":8.423174603174601,"c512fe3b-b9c4-40a1-a205-8ca01effdeb0":10.054761904761907,"c75c7b08-7264-4daa-a133-59bea66db0c7":11.920370370370371,"c8a1eae3-e8ea-41de-a471-a2539c9cfa9c":10.410238095238094,"c99f13bd-28d1-41dd-9ac8-0b8688118611":9.642857142857144,"cf111a55-139a-4108-bf05-a8e25ec7874f":10.924206349206347,"d0d1fa34-c4a1-4e6d-bc58-a5cf5012c11f":9.412936507936507,"ed543a19-85d9-427a-a2d3-88e7c59a100e":10.486243386243386,"f2d9455d-9f46-4cd9-993e-25bab1ce4792":8.158412698412699},"topic":["product","review","custom","summar","opinion"],"groups":[{"authors":["Minqing Hu","Bing Liu"],"references":["135c7d8b-578a-462d-98d0-0288eec3a9fc","22c1058d-2d1b-4b59-abbe-736df99ceb72","34b7e270-80d7-46d5-a6f1-e50087a8d045","40daa31a-d807-4f6a-9f22-021febf46e98","71ecd1d2-c656-489d-95a6-503e31e3e05f","9c2be164-0b3f-4a94-9c98-9a6c0d77c367","bc95970b-34c5-4860-a832-41bc04a50889","c512fe3b-b9c4-40a1-a205-8ca01effdeb0","c8a1eae3-e8ea-41de-a471-a2539c9cfa9c","f2d9455d-9f46-4cd9-993e-25bab1ce4792"],"_id":"c99f13bd-28d1-41dd-9ac8-0b8688118611","abstract":"It is a common practice that merchants selling products on the Web ask their customers to review the products and associated services. As e-commerce is becoming more and more popular, the number of customer reviews that a product receives grows rapidly. For a popular product, the number of reviews can be in hundreds. This makes it difficult for a potential customer to read them in order to make a decision on whether to buy the product. In this project, we aim to summarize all the customer reviews of a product. This summarization task is different from traditional text summarization because we are only interested in the specific features of the product that customers have opinions on and also whether the opinions are positive or negative. We do not summarize the reviews by selecting or rewriting a subset of the original sentences from the reviews to capture their main points as in the classic text summarization. In this paper, we only focus on mining opinion/product features that the reviewers have commented on. A number of techniques are presented to mine such features. Our experimental results show that these techniques are highly effective.","title":"Mining opinion features in customer reviews","venue":"national conference on artificial intelligence","year":2004,"__v":0,"citationCount":435},{"authors":["Bo Pang","Lillian Lee","Shivakumar Vaithyanathan"],"references":["01f443e7-ea4c-48a7-8081-745c3fa62769","21421f14-af9c-4c95-9aad-b7bece9fb7d9","23b2db98-6897-497b-8b90-67b591016a5e","3b20d6fb-4f2c-4eab-b5a3-82746b83f1f1","43bcc79f-1316-4a3c-81ba-69e6c3afbcbb","691983e4-67cb-4456-9462-42b22c620c64","75ec0b95-65c5-48c9-ae1b-a44c6c378bec","90ca3ecc-702a-45ab-af75-8c5851ce7bb9","96d6d9b9-6d69-4c9a-b3f5-c8083966d55c","a4830914-2189-4c4b-bfa4-adc5b45b7c23","ab339474-ea21-443b-893f-96ae09e65a2e","c75c7b08-7264-4daa-a133-59bea66db0c7","c7ce0fc7-4d38-4355-aa19-ab35527d2519","cf111a55-139a-4108-bf05-a8e25ec7874f","ddef8d03-46e5-4df7-ac2d-ce48d54ba742","e1f8e6f0-eee8-4e01-ace1-cbc47ac3880a","ed8013b0-9bdd-4bc6-b31a-70fca6d15aa9"],"_id":"ed543a19-85d9-427a-a2d3-88e7c59a100e","abstract":"We consider the problem of classifying documents not by topic, but by overall sentiment, e.g., determining whether a review is positive or negative. Using movie reviews as data, we find that standard machine learning techniques definitively outperform human-produced baselines. However, the three machine learning methods we employed (Naive Bayes, maximum entropy classification, and support vector machines) do not perform as well on sentiment classification as on traditional topic-based categorization. We conclude by examining factors that make the sentiment classification problem more challenging.","title":"Thumbs up? Sentiment Classification using Machine Learning Techniques","venue":"empirical methods in natural language processing","year":2002,"__v":0,"citationCount":2142}],"offsprings":[]},"dd83785a-dd19-41e3-9b25-ebabbd48d336":{"authors":["Navneet Dalal","Bill Triggs"],"references":["8d8e7d51-3223-4776-bf6a-40306774b8a1","b944f77f-113b-4a02-ae5e-d4a124b8fd5b","ffa029cf-7240-4723-8339-51fac57f9f28"],"_id":"dd83785a-dd19-41e3-9b25-ebabbd48d336","abstract":"We study the question of feature sets for robust visual object recognition; adopting linear SVM based human detection as a test case. After reviewing existing edge and gradient based descriptors, we show experimentally that grids of histograms of oriented gradient (HOG) descriptors significantly outperform existing feature sets for human detection. We study the influence of each stage of the computation on performance, concluding that fine-scale gradients, fine orientation binning, relatively coarse spatial binning, and high-quality local contrast normalization in overlapping descriptor blocks are all important for good results. The new approach gives near-perfect separation on the original MIT pedestrian database, so we introduce a more challenging dataset containing over 1800 annotated human images with a large range of pose variations and backgrounds.","title":"Histograms of oriented gradients for human detection","venue":"computer vision and pattern recognition","year":2005,"__v":0,"citationCount":8477,"parents":{"04d8a9cb-a14d-4ccf-8b19-da1327e86b91":0,"3e812129-beeb-415e-b6f7-ae255695cec7":0,"6f6fe122-6003-498c-a584-b27b3f7a6be3":7.142857142857142,"8d8e7d51-3223-4776-bf6a-40306774b8a1":21.428571428571427,"8fc9506c-3603-4af2-b0c8-02b368863fcb":7.142857142857142,"a5254ae0-1ce1-4390-b9f8-8d5a3dcb1e62":7.142857142857142,"b944f77f-113b-4a02-ae5e-d4a124b8fd5b":0,"bdd58d4a-2e0e-4fb2-8049-cfa50dda7b0d":7.142857142857142,"cb66e49d-077b-4adf-873c-2bc39f78fca6":35.714285714285715,"ed8a9624-3abe-4b5e-bffe-5b3ecc34e841":0,"f200d16f-8e1a-4a51-be50-4eeaafbb4a2f":21.428571428571427,"f3959783-a9aa-48a2-9fcc-978879de365e":0,"ff0d990e-90f3-4973-8541-5f7e595710aa":0,"ffa029cf-7240-4723-8339-51fac57f9f28":0},"keyword":{"04d8a9cb-a14d-4ccf-8b19-da1327e86b91":9.446904761904763,"3e812129-beeb-415e-b6f7-ae255695cec7":10.616865079365079,"6f6fe122-6003-498c-a584-b27b3f7a6be3":7.159206349206349,"8d8e7d51-3223-4776-bf6a-40306774b8a1":11.523492063492062,"8fc9506c-3603-4af2-b0c8-02b368863fcb":11.527645502645502,"a5254ae0-1ce1-4390-b9f8-8d5a3dcb1e62":9.996111111111112,"b944f77f-113b-4a02-ae5e-d4a124b8fd5b":10.232936507936508,"bdd58d4a-2e0e-4fb2-8049-cfa50dda7b0d":9.087857142857143,"cb66e49d-077b-4adf-873c-2bc39f78fca6":11.011111111111111,"ed8a9624-3abe-4b5e-bffe-5b3ecc34e841":8.979444444444445,"f200d16f-8e1a-4a51-be50-4eeaafbb4a2f":7.851666666666665,"f3959783-a9aa-48a2-9fcc-978879de365e":12.757407407407406,"ff0d990e-90f3-4973-8541-5f7e595710aa":10.590820105820104,"ffa029cf-7240-4723-8339-51fac57f9f28":10.548333333333334},"topic":["human","gradient","descriptor","studi","set"],"groups":[{"authors":["Krystian Mikolajczyk","Cordelia Schmid"],"references":["00a4e16f-6b65-4ad2-bedc-b19d9cbc2cfe","09346dc3-f4d0-43a4-8f0b-27e02bcd336e","0aae4e44-abdb-4948-9462-61f6e52162ba","0d287faa-99bb-42df-98a7-24fcd601b9a4","19195bc1-7aff-4dd3-91cc-25402c343a19","21a8e8fd-0172-4e9a-8474-7024eb0bf979","21c67dad-f0eb-4479-afe7-fdf4a71eef01","2d6c9f60-ea78-44a8-b5f9-6964575dd196","33711daf-2a44-4f42-8466-c7801f29959b","34758e0a-3def-447b-9c5e-e82a206426b5","36800655-b2ff-4eb7-9070-c6be304c4baa","37031566-2033-44cb-a87e-91a9bb37996f","3b744649-d7a0-46c3-b242-9e0060d8ecfa","4e58f9b5-8562-4f17-830f-f055449867fc","509e1ae2-768b-4417-bebe-d90cf1e0fdae","5149d3c0-5ac9-47ba-9fb0-3d2ef757b0e8","568f1994-f91e-413e-92fd-87dbbb9642a8","5f1992df-975f-49e7-bd88-aee0740317cf","6018a516-8149-4bce-bc33-5449d86e58c2","60285266-7da2-474e-b05a-b380c836f665","608a581a-0e03-435a-9067-c0e0982567af","683dd26d-5c59-4feb-9fbd-2bcf3cc1942f","6fe37c18-8dc5-4baa-b6e0-5546353907bb","72c27d5a-23c5-4d1b-a000-280b87b368ee","7ab7b36d-baae-4b21-89fc-69389fcabc44","853b29ea-c6d1-497e-bad3-b608d370e7e2","a5254ae0-1ce1-4390-b9f8-8d5a3dcb1e62","a8c6ead3-d61a-4f6a-a702-08743f19eec9","b4685927-0ad9-466b-b2c6-2e1764475726","b592576f-ff29-4a68-9b2f-8a8ad02e9c70","b944f77f-113b-4a02-ae5e-d4a124b8fd5b","c455fb04-4566-4648-ad6f-3cf2245e507c","e2204e92-e6dc-4884-9bbc-200029491fc7","e927dff1-6ed4-45fd-8852-eb804e11e665","ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d","fc9638b8-572c-4b23-aab2-92e2dd3b79f8","ffa029cf-7240-4723-8339-51fac57f9f28"],"_id":"8d8e7d51-3223-4776-bf6a-40306774b8a1","abstract":"In this paper, we compare the performance of descriptors computed for local interest regions, as, for example, extracted by the Harris-Affine detector [Mikolajczyk, K and Schmid, C, 2004]. Many different descriptors have been proposed in the literature. It is unclear which descriptors are more appropriate and how their performance depends on the interest region detector. The descriptors should be distinctive and at the same time robust to changes in viewing conditions as well as to errors of the detector. Our evaluation uses as criterion recall with respect to precision and is carried out for different image transformations. We compare shape context [Belongie, S, et al., April 2002], steerable filters [Freeman, W and Adelson, E, Setp. 1991], PCA-SIFT [Ke, Y and Sukthankar, R, 2004], differential invariants [Koenderink, J and van Doorn, A, 1987], spin images [Lazebnik, S, et al., 2003], SIFT [Lowe, D. G., 1999], complex filters [Schaffalitzky, F and Zisserman, A, 2002], moment invariants [Van Gool, L, et al., 1996], and cross-correlation for different types of interest regions. We also propose an extension of the SIFT descriptor and show that it outperforms the original method. Furthermore, we observe that the ranking of the descriptors is mostly independent of the interest region detector and that the SIFT-based descriptors perform best. Moments and steerable filters show the best performance among the low dimensional descriptors.","title":"A performance evaluation of local descriptors","venue":"IEEE Transactions on Pattern Analysis and Machine Intelligence","year":2005,"__v":0,"citationCount":2762},{"authors":["Krystian Mikolajczyk","Cordelia Schmid","Andrew Zisserman"],"references":["04d8a9cb-a14d-4ccf-8b19-da1327e86b91","3ba1e680-b3cc-40e6-bc90-2af6c781f9bc","4a5d1ed7-1161-4d67-a229-15f98b62a2fd","6018a516-8149-4bce-bc33-5449d86e58c2","67e377ae-20a7-4cc8-9513-cb2665216915","6f6fe122-6003-498c-a584-b27b3f7a6be3","6fe37c18-8dc5-4baa-b6e0-5546353907bb","7237f6e7-205d-4b80-9fe5-4d8fb91b127a","733eea21-9c61-4935-8ffd-5b8e56dd947d","899de8c7-9cd9-4dd5-82f1-ad9acb801f8e","964cd0ae-7afc-42ee-bafd-f7c631fd51cb","a3257b67-d63c-4256-964c-8225a6d4ce1e","b5e72744-0105-48bf-95ea-753f52280f48","bdd58d4a-2e0e-4fb2-8049-cfa50dda7b0d","c29b523d-e6e8-466c-adf1-0ffef7080029","c455fb04-4566-4648-ad6f-3cf2245e507c","c7f93552-c1ef-4ae4-b1f5-2317e1c9d904","dd096bb0-7c91-4c01-93a2-e9ffeb89705c","e1f50832-764f-4f22-b3b8-e2dec38c0413","e3ee2bff-94de-4bd3-8524-af41b9668403","e649a9fd-f6d9-4aac-b428-29b82c20a484","f200d16f-8e1a-4a51-be50-4eeaafbb4a2f","ff0d990e-90f3-4973-8541-5f7e595710aa"],"_id":"cb66e49d-077b-4adf-873c-2bc39f78fca6","abstract":"We describe a novel method for human detection in single images which can detect full bodies as well as close-up views in the pres- ence of clutter and occlusion. Humans are modeled as flexible assemblies of parts, and robust part detection is the key to the approach. The parts are represented by co-occurrences of local features which captures the spatial layout of the part's appearance. Feature selection and the part detectors are learnt from training images using AdaBoost. The detection algorithm is very efficient as (i) all part detectors use the same initial features, (ii) a coarse-to-fine cascade approach is used for part detection, (iii) a part assembly strategy reduces the number of spurious detections and the search space. The results outperform existing human detectors.","title":"Human Detection Based on a Probabilistic Assembly of Robust Part Detectors","venue":"european conference on computer vision","year":2004,"__v":0,"citationCount":291}],"offsprings":["f2d49150-35de-4fd5-ac46-eb071d1cc73e","83c737b8-e084-4766-ba6e-131e6a1c017c","176a7436-78ea-4c2a-82e6-7930ab023bd1"]},"df9da54d-7e74-472d-a5fa-19f5edd8e935":{"authors":["Giuseppe Bianchi"],"references":[],"_id":"df9da54d-7e74-472d-a5fa-19f5edd8e935","abstract":"The IEEE has standardized the 802.11 protocol for wireless local area networks. The primary medium access control (MAC) technique of 802.11 is called the distributed coordination function (DCF). The DCF is a carrier sense multiple access with collision avoidance (CSMA/CA) scheme with binary slotted exponential backoff. This paper provides a simple, but nevertheless extremely accurate, analytical model to compute the 802.11 DCF throughput, in the assumption of finite number of terminals and ideal channel conditions. The proposed analysis applies to both the packet transmission schemes employed by DCF, namely, the basic access and the RTS/CTS access mechanisms. In addition, it also applies to a combination of the two schemes, in which packets longer than a given threshold are transmitted according to the RTS/CTS mechanism. By means of the proposed model, we provide an extensive throughput performance evaluation of both access mechanisms of the 802.11 protocol.","title":"Performance analysis of the IEEE 802.11 distributed coordination function","venue":"IEEE Journal on Selected Areas in Communications","year":2000,"__v":0,"citationCount":3895,"parents":{"4344b09d-9bba-4fca-a581-a79c0c3da896":0,"c91ba025-6804-4efa-9d7f-3b5df7066357":25,"cb239f1b-663f-4337-a224-22c42a1f70d0":0,"e292b472-7d2c-4edb-b73e-c40a81f828e2":0},"keyword":{"4344b09d-9bba-4fca-a581-a79c0c3da896":5.485185185185184,"c91ba025-6804-4efa-9d7f-3b5df7066357":3.8347222222222217,"cb239f1b-663f-4337-a224-22c42a1f70d0":6.160714285714286,"e292b472-7d2c-4edb-b73e-c40a81f828e2":4.526587301587301},"topic":["access","dcf","802","11","scheme"],"offsprings":[]},"e0ac4812-7729-4a2d-8a1f-74b1b7c8eb5d":{"authors":["Svetlana Lazebnik","Cordelia Schmid","Jean Ponce"],"references":["26316adf-569e-49bc-a289-c1ba311624f6","ab3afb93-8ca0-4556-ae60-11199dc263c2"],"_id":"e0ac4812-7729-4a2d-8a1f-74b1b7c8eb5d","abstract":"This paper presents a method for recognizing scene categories based on approximate global geometric correspondence. This technique works by partitioning the image into increasingly fine sub-regions and computing histograms of local features found inside each sub-region. The resulting \"spatial pyramid\" is a simple and computationally efficient extension of an orderless bag-of-features image representation, and it shows significantly improved performance on challenging scene categorization tasks. Specifically, our proposed method exceeds the state of the art on the Caltech-101 database and achieves high accuracy on a large database of fifteen natural scene categories. The spatial pyramid framework also offers insights into the success of several recently proposed image descriptions, including Torralbas \"gist\" and Lowes SIFT descriptors.","title":"Beyond Bags of Features: Spatial Pyramid Matching for Recognizing Natural Scene Categories","venue":"computer vision and pattern recognition","year":2006,"__v":0,"citationCount":3815,"parents":{"1ed2cc94-3d0b-4718-80b6-2528e814c921":0,"1f556c88-b553-4c75-b243-92d8200f8149":13.333333333333334,"21a8e8fd-0172-4e9a-8474-7024eb0bf979":6.666666666666667,"26316adf-569e-49bc-a289-c1ba311624f6":13.333333333333334,"2d5181cd-cf99-4afd-afe7-4e37839ea50d":0,"829f9b1f-d04f-49e8-aab7-2c278dff5427":0,"a06e231e-3682-4270-b36a-397d119f504a":0,"ab3afb93-8ca0-4556-ae60-11199dc263c2":6.666666666666667,"ae4a15da-5aec-4876-bec6-7c8ce40761b1":0,"c14bcc73-3061-46a5-9b1e-648faf08f7cf":6.666666666666667,"c2d3dd5b-6fd3-403f-9a03-e1751360e226":0,"c3eee093-b3ff-47ae-a5ac-e005bb060e4a":33.33333333333333,"c455fb04-4566-4648-ad6f-3cf2245e507c":0,"c9482f1f-6600-44a7-a69a-e63ef13cdff8":6.666666666666667,"ea64f6ce-6ad4-4e2d-ad18-24c25ff99870":6.666666666666667},"keyword":{"1ed2cc94-3d0b-4718-80b6-2528e814c921":10.175780423280425,"1f556c88-b553-4c75-b243-92d8200f8149":10.75029100529101,"21a8e8fd-0172-4e9a-8474-7024eb0bf979":9.746825396825397,"26316adf-569e-49bc-a289-c1ba311624f6":8.864814814814814,"2d5181cd-cf99-4afd-afe7-4e37839ea50d":11.48904761904762,"829f9b1f-d04f-49e8-aab7-2c278dff5427":11.995271765271765,"a06e231e-3682-4270-b36a-397d119f504a":10.576190476190472,"ab3afb93-8ca0-4556-ae60-11199dc263c2":10.57010582010582,"ae4a15da-5aec-4876-bec6-7c8ce40761b1":0,"c14bcc73-3061-46a5-9b1e-648faf08f7cf":9.307804232804235,"c2d3dd5b-6fd3-403f-9a03-e1751360e226":11.16920634920635,"c3eee093-b3ff-47ae-a5ac-e005bb060e4a":11.259761904761904,"c455fb04-4566-4648-ad6f-3cf2245e507c":10.222962962962965,"c9482f1f-6600-44a7-a69a-e63ef13cdff8":11.435978835978835,"ea64f6ce-6ad4-4e2d-ad18-24c25ff99870":10.602089947089945},"topic":["scene","imag","subregion","spatial","pyramid"],"groups":[{"authors":["Pedro Quelhas","Florent Monay","J.-M. Odobez","Daniel Gatica-Perez","Tinne Tuytelaars","L. Van Gool"],"references":["1ed2cc94-3d0b-4718-80b6-2528e814c921","21a8e8fd-0172-4e9a-8474-7024eb0bf979","26316adf-569e-49bc-a289-c1ba311624f6","2beaa150-6293-4f05-ba04-8e001993e766","5f70f18c-5f9c-442e-ae2c-ee6aadecab95","60e77fab-98d4-438b-a664-753b70e98709","6fe37c18-8dc5-4baa-b6e0-5546353907bb","750b0ac1-2ac9-4273-a9c8-baad11e26fcd","829f9b1f-d04f-49e8-aab7-2c278dff5427","8bc5f80f-af26-47b4-aa0a-aab3a2e6c503","904cbad5-94b6-4992-b1fa-4e68c56f18ab","b944f77f-113b-4a02-ae5e-d4a124b8fd5b","c455fb04-4566-4648-ad6f-3cf2245e507c","cd0d43d4-0be6-4458-a966-118fabbcc90f","ffa029cf-7240-4723-8339-51fac57f9f28"],"_id":"c3eee093-b3ff-47ae-a5ac-e005bb060e4a","abstract":"We present a new approach to model visual scenes in image collections, based on local invariant features and probabilistic latent space models. Our formulation provides answers to three open questions:(l) whether the invariant local features are suitable for scene (rather than object) classification; (2) whether unsupennsed latent space models can be used for feature extraction in the classification task; and (3) whether the latent space formulation can discover visual co-occurrence patterns, motivating novel approaches for image organization and segmentation. Using a 9500-image dataset, our approach is validated on each of these issues. First, we show with extensive experiments on binary and multi-class scene classification tasks, that a bag-of-visterm representation, derived from local invariant descriptors, consistently outperforms state-of-the-art approaches. Second, we show that probabilistic latent semantic analysis (PLSA) generates a compact scene representation, discriminative for accurate classification, and significantly more robust when less training data are available. Third, we have exploited the ability of PLSA to automatically extract visually meaningful aspects, to propose new algorithms for aspect-based image ranking and context-sensitive image segmentation.","title":"Modeling scenes with local descriptors and latent aspects","venue":"international conference on computer vision","year":2005,"__v":0,"citationCount":221}],"offsprings":["9b8a49b5-a5cb-4c61-8c60-3bde6d310009","83c737b8-e084-4766-ba6e-131e6a1c017c"]},"e1263ada-afda-498c-a37d-9b545293118a":{"authors":["Sylvia Ratnasamy","Paul Francis","Mark Handley","Richard M. Karp","Scott Shenker"],"references":["1545dfd3-2c25-4ff1-b43c-df4a2a501d06","4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4","d06f8723-1b89-4684-99c9-c1045ddfb85c"],"_id":"e1263ada-afda-498c-a37d-9b545293118a","abstract":"Hash tables - which map \"keys\" onto \"values\" - are an essential building block in modern software systems. We believe a similar functionality would be equally valuable to large distributed systems. In this paper, we introduce the concept of a Content-Addressable Network (CAN) as a distributed infrastructure that provides hash table-like functionality on Internet-like scales. The CAN is scalable, fault-tolerant and completely self-organizing, and we demonstrate its scalability, robustness and low-latency properties through simulation.","title":"A scalable content-addressable network","venue":"acm special interest group on data communication","year":2001,"__v":0,"citationCount":3635,"parents":{"00ade209-5974-42c1-9089-a3741481d9c7":10.526315789473683,"0695070f-320e-4d26-9c68-2c8faa20c944":0,"0a094924-1b25-43cc-ac8b-dd8cf90a8f78":10.526315789473683,"1545dfd3-2c25-4ff1-b43c-df4a2a501d06":5.263157894736842,"1cc64868-4f72-4939-aed4-fc8fb0b45118":10.526315789473683,"31c5e39a-3f24-4d20-bf8c-3d00036baf95":0,"39adcd6c-0b60-430c-99ab-21cd9e98b385":0,"42c70869-0dad-4629-93b5-a2d9e29071a7":0,"4743d708-b82d-42ec-adaa-a8bf2f23cc38":0,"483cb980-c968-48e6-b848-714ed2937f98":0,"48740ddd-afd1-4331-8af7-224ef5d19ed7":0,"4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4":21.052631578947366,"88c35cd8-dd49-44f8-9674-96974c8f3650":0,"c0ea675b-2479-48ae-817e-3ecedd175ecf":0,"c8771a57-de9c-44b7-966c-1ff156d3091f":0,"d06f8723-1b89-4684-99c9-c1045ddfb85c":26.31578947368421,"e4ee2d81-7629-4445-b4f3-55ef57bd42fd":10.526315789473683,"ec7d1720-3285-4729-b819-b4c58a826ec8":15.789473684210526,"f6fc4443-7a98-4f9f-92e8-e4e5d94521a7":5.263157894736842},"keyword":{"00ade209-5974-42c1-9089-a3741481d9c7":9.427248677248677,"0695070f-320e-4d26-9c68-2c8faa20c944":9.587566137566137,"0a094924-1b25-43cc-ac8b-dd8cf90a8f78":10.651653439153437,"1545dfd3-2c25-4ff1-b43c-df4a2a501d06":7.6732804232804215,"1cc64868-4f72-4939-aed4-fc8fb0b45118":10.155891330891329,"31c5e39a-3f24-4d20-bf8c-3d00036baf95":0,"39adcd6c-0b60-430c-99ab-21cd9e98b385":10.585,"42c70869-0dad-4629-93b5-a2d9e29071a7":11.110515873015874,"4743d708-b82d-42ec-adaa-a8bf2f23cc38":6.535317460317461,"483cb980-c968-48e6-b848-714ed2937f98":0,"48740ddd-afd1-4331-8af7-224ef5d19ed7":8.064814814814815,"4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4":9.718121693121692,"88c35cd8-dd49-44f8-9674-96974c8f3650":9.471031746031747,"c0ea675b-2479-48ae-817e-3ecedd175ecf":0,"c8771a57-de9c-44b7-966c-1ff156d3091f":7.068121693121691,"d06f8723-1b89-4684-99c9-c1045ddfb85c":8.58637566137566,"e4ee2d81-7629-4445-b4f3-55ef57bd42fd":6.803042328042328,"ec7d1720-3285-4729-b819-b4c58a826ec8":10.103293650793649,"f6fc4443-7a98-4f9f-92e8-e4e5d94521a7":9.96984126984127},"topic":["system","scalabl","hash","function","distribut"],"groups":[{"authors":["Ion Stoica","Robert Morris","David R. Karger","M. Frans Kaashoek","Hari Balakrishnan"],"references":["1c729f22-9928-4703-92a0-8819569a1bbb","1cc64868-4f72-4939-aed4-fc8fb0b45118","48740ddd-afd1-4331-8af7-224ef5d19ed7","4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4","59084791-6ebd-4d0d-8f93-2c1da8d47490","6500989e-b1e1-4b02-a921-21ec25685b73","6aac8d9c-34bd-42d9-b887-b0a3bd697ee6","6eff83a4-db80-40ea-8c9f-8bda5f506c29","7502e770-12f7-4fd1-8cd6-f54f456f7aa8","a1b950a0-345b-4471-ba60-872e4f8cc058","a369afee-a619-4e9a-9250-5fd2b06e8a05","aa89fd2a-319e-48b1-b0ab-099acbe37617","b7d7ec53-f079-4bd7-a795-8b6fe77f2db6","c0ea675b-2479-48ae-817e-3ecedd175ecf","c37c70cb-3956-4249-934d-848845f2f444","e1263ada-afda-498c-a37d-9b545293118a","e4ee2d81-7629-4445-b4f3-55ef57bd42fd"],"_id":"d06f8723-1b89-4684-99c9-c1045ddfb85c","abstract":"A fundamental problem that confronts peer-to-peer applications is to efficiently locate the node that stores a particular data item. This paper presents  Chord , a distributed lookup protocol that addresses this problem. Chord provides support for just one operation: given a key, it maps the key onto a node. Data location can be easily implemented on top of Chord by associating a key with each data item, and storing the key/data item pair at the node to which the key maps. Chord adapts efficiently as nodes join and leave the system, and can answer queries even if the system is continuously changing. Results from theoretical analysis, simulations, and experiments show that Chord is scalable, with communication cost and the state maintained by each node scaling logarithmically with the number of Chord nodes.","title":"Chord: A scalable peer-to-peer lookup service for internet applications","venue":"acm special interest group on data communication","year":2001,"__v":0,"citationCount":2568}],"offsprings":["4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4","cb5922c5-575b-4b50-8d58-809f8256e948","d06f8723-1b89-4684-99c9-c1045ddfb85c","f14df1ed-e3e9-4348-9040-fc06e3411b95"]},"e2204e92-e6dc-4884-9bbc-200029491fc7":{"authors":["Timo Ojala","Matti Pietikäinen","Topi Mäenpää"],"references":["9270a9b5-940a-4394-814f-433c6440f286"],"_id":"e2204e92-e6dc-4884-9bbc-200029491fc7","abstract":"Presents a theoretically very simple, yet efficient, multiresolution approach to gray-scale and rotation invariant texture classification based on local binary patterns and nonparametric discrimination of sample and prototype distributions. The method is based on recognizing that certain local binary patterns, termed \"uniform,\" are fundamental properties of local image texture and their occurrence histogram is proven to be a very powerful texture feature. We derive a generalized gray-scale and rotation invariant operator presentation that allows for detecting the \"uniform\" patterns for any quantization of the angular space and for any spatial resolution and presents a method for combining multiple operators for multiresolution analysis. The proposed approach is very robust in terms of gray-scale variations since the operator is, by definition, invariant against any monotonic transformation of the gray scale. Another advantage is computational simplicity as the operator can be realized with a few operations in a small neighborhood and a lookup table. Experimental results demonstrate that good discrimination can be achieved with the occurrence statistics of simple rotation invariant local binary patterns.","title":"Multiresolution gray-scale and rotation invariant texture classification with local binary patterns","venue":"IEEE Transactions on Pattern Analysis and Machine Intelligence","year":2002,"__v":0,"citationCount":3941,"parents":{"0647fc30-735a-4d45-bf63-433216d5a014":6.896551724137931,"087735a7-1cb9-4911-a88b-158cf3ebde87":0,"09346dc3-f4d0-43a4-8f0b-27e02bcd336e":6.896551724137931,"0af9a421-ca6a-4f1e-acef-d77082a7cf0c":6.896551724137931,"0da4dd98-2681-4d42-ae54-9347e8dfed97":0,"11eebfa1-436a-4203-a39a-0d1c02bda34f":0,"233a5884-312b-4003-855f-c75f3f7c90ea":6.896551724137931,"30614910-26a5-495c-8bb7-0f723c47db69":0,"3a770bd2-20c6-45e1-b98e-46d6f31f1966":27.586206896551722,"3c4e8d07-47e2-4942-8197-59b613634ce4":10.344827586206897,"4d92607c-d2ca-48fa-9a55-8e7eff5a71d3":3.4482758620689653,"5ffd13e9-177c-45f9-8f77-40e6e8f8378d":10.344827586206897,"606f8ecd-75f5-40fa-a70d-d6665cd2990e":6.896551724137931,"70e86498-0a19-465c-8b73-49c2769b1a53":3.4482758620689653,"746415d7-a412-4a66-8752-ce90b405fc94":6.896551724137931,"76d48657-1eba-43d5-a642-f6f553331633":13.793103448275861,"79aaae90-c329-4f9f-86fb-31ae2ea58ae8":6.896551724137931,"813a6153-f889-4801-ac2a-233be07e5df7":0,"8573e55d-619d-425c-bbdf-4a0dbfe8f862":0,"9270a9b5-940a-4394-814f-433c6440f286":0,"a8d582af-d7f0-4a20-aba5-5b49f43e990a":0,"b1fbed62-1a39-48d6-8eb5-ea103ad6423e":0,"b9d5d8e9-ea08-4a60-a1fe-2164382647b8":13.793103448275861,"ba03a3a9-4acc-4fdb-a95f-75c76861b620":0,"be4205fb-27a0-4449-9ba2-d311dfd393a2":0,"d6e78be6-6ad4-4ea2-8076-911d015644e3":13.793103448275861,"d6e93459-39bb-4c2a-8018-cf9437c0ea06":0,"d70539c8-d4d5-4d3d-8333-6e6b210ff641":6.896551724137931,"e7209bb1-d240-48c1-866a-3fdcce8fa558":6.896551724137931},"keyword":{"0647fc30-735a-4d45-bf63-433216d5a014":9.462777777777777,"087735a7-1cb9-4911-a88b-158cf3ebde87":8.55079365079365,"09346dc3-f4d0-43a4-8f0b-27e02bcd336e":13.100793650793651,"0af9a421-ca6a-4f1e-acef-d77082a7cf0c":10.846031746031747,"0da4dd98-2681-4d42-ae54-9347e8dfed97":10.45,"11eebfa1-436a-4203-a39a-0d1c02bda34f":8.021428571428572,"233a5884-312b-4003-855f-c75f3f7c90ea":8.610317460317459,"30614910-26a5-495c-8bb7-0f723c47db69":12.782936507936506,"3a770bd2-20c6-45e1-b98e-46d6f31f1966":11.02142857142857,"3c4e8d07-47e2-4942-8197-59b613634ce4":10.520238095238096,"4d92607c-d2ca-48fa-9a55-8e7eff5a71d3":11.08484126984127,"5ffd13e9-177c-45f9-8f77-40e6e8f8378d":9.98968253968254,"606f8ecd-75f5-40fa-a70d-d6665cd2990e":10.571031746031746,"70e86498-0a19-465c-8b73-49c2769b1a53":10.835714285714285,"746415d7-a412-4a66-8752-ce90b405fc94":9.25873015873016,"76d48657-1eba-43d5-a642-f6f553331633":9.552380952380952,"79aaae90-c329-4f9f-86fb-31ae2ea58ae8":9.313756613756615,"813a6153-f889-4801-ac2a-233be07e5df7":11.56005291005291,"8573e55d-619d-425c-bbdf-4a0dbfe8f862":8.81468253968254,"9270a9b5-940a-4394-814f-433c6440f286":9.891468253968256,"a8d582af-d7f0-4a20-aba5-5b49f43e990a":10.680687830687829,"b1fbed62-1a39-48d6-8eb5-ea103ad6423e":7.1017989417989416,"b9d5d8e9-ea08-4a60-a1fe-2164382647b8":12.122222222222222,"ba03a3a9-4acc-4fdb-a95f-75c76861b620":11.531105006105006,"be4205fb-27a0-4449-9ba2-d311dfd393a2":8.021428571428572,"d6e78be6-6ad4-4ea2-8076-911d015644e3":10.52195767195767,"d6e93459-39bb-4c2a-8018-cf9437c0ea06":12.578835978835977,"d70539c8-d4d5-4d3d-8333-6e6b210ff641":11.251190476190475,"e7209bb1-d240-48c1-866a-3fdcce8fa558":10.287301587301588},"topic":["oper","pattern","local","invari","textur"],"groups":[{"authors":["Matti Pietikäinen","Timo Ojala","Zelin Xu"],"references":["087735a7-1cb9-4911-a88b-158cf3ebde87","0af9a421-ca6a-4f1e-acef-d77082a7cf0c","3c4e8d07-47e2-4942-8197-59b613634ce4","4d92607c-d2ca-48fa-9a55-8e7eff5a71d3","606f8ecd-75f5-40fa-a70d-d6665cd2990e","70e86498-0a19-465c-8b73-49c2769b1a53","9270a9b5-940a-4394-814f-433c6440f286","bd6cbbaa-f2f2-49c1-b672-ecc9a1c626f9","d2930486-5812-4750-b650-dfd17d917226","e7209bb1-d240-48c1-866a-3fdcce8fa558"],"_id":"3a770bd2-20c6-45e1-b98e-46d6f31f1966","abstract":"A distribution-based classification approach and a set of recently developed texture measures are applied to rotation-invariant texture classification. The performance is compared to that obtained with the well-known circular-symmetric autoregressive random field (CSAR) model approach. A difficult classification problem of 15 different Brodatz textures and seven rotation angles is used in experiments. The results show much better performance for our approach than for the CSAR features. A detailed analysis of the confusion matrices and the rotation angles of misclassified samples produces several interesting observations about the classification problem and the features used in this study.","title":"Rotation-invariant texture classification using feature distributions","venue":"Pattern Recognition","year":2000,"__v":0,"citationCount":112}],"offsprings":["e3a5cec9-7e82-4c14-86ab-0d95a92712a7","8d8e7d51-3223-4776-bf6a-40306774b8a1"]},"e2f7a74a-8430-4463-94ce-fe85dfd309f9":{"authors":["Alex Krizhevsky","Ilya Sutskever","Geoffrey E. Hinton"],"references":["2b6a3d0f-368f-45bb-be23-4e82f62fbbf7","f6bd8b64-684d-429a-aab5-8ff3a2c23cd6"],"_id":"e2f7a74a-8430-4463-94ce-fe85dfd309f9","abstract":"We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0% which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully-connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overriding in the fully-connected layers we employed a recently-developed regularization method called \"dropout\" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry.","title":"ImageNet Classification with Deep Convolutional Neural Networks","venue":"neural information processing systems","year":2012,"__v":0,"citationCount":5094,"parents":{"2b6a3d0f-368f-45bb-be23-4e82f62fbbf7":6.25,"2caf053c-09a4-4536-b303-6d4c834e429a":0,"2d94566b-ac2d-49b0-a867-2392c41a2172":18.75,"32a53bab-1ede-4869-98ad-d2ff0c1e3367":12.5,"4bbacb77-1097-4cc5-b001-6554ea01fb75":18.75,"657e0ce9-3a0c-4cc3-ac69-0f60aaf955f1":18.75,"73ec9d29-4fc5-4019-97d3-c496c8509f37":6.25,"820b9eee-e009-4dc1-b464-f5fd4485d6b3":0,"a21b42c9-dff1-4cf2-becd-0bc9f922ea72":12.5,"adea0a98-d74d-43be-a238-a1ef027c6a58":6.25,"bd62aacb-5037-43d3-926a-af4d38ec3bfc":0,"c700dc12-7eac-4091-8462-527773668dfa":12.5,"c9482f1f-6600-44a7-a69a-e63ef13cdff8":0,"ca250ca4-70fd-411f-8cc7-fb17be31cd9e":0,"f6bd8b64-684d-429a-aab5-8ff3a2c23cd6":0,"f7ac19b7-daaf-4dc1-bbb9-7f4ffd7385ba":0},"keyword":{"2b6a3d0f-368f-45bb-be23-4e82f62fbbf7":9.214682539682538,"2caf053c-09a4-4536-b303-6d4c834e429a":0,"2d94566b-ac2d-49b0-a867-2392c41a2172":9.546111111111111,"32a53bab-1ede-4869-98ad-d2ff0c1e3367":9.519285714285713,"4bbacb77-1097-4cc5-b001-6554ea01fb75":9.777777777777777,"657e0ce9-3a0c-4cc3-ac69-0f60aaf955f1":10.566349206349205,"73ec9d29-4fc5-4019-97d3-c496c8509f37":8.80530303030303,"820b9eee-e009-4dc1-b464-f5fd4485d6b3":7.836190476190476,"a21b42c9-dff1-4cf2-becd-0bc9f922ea72":9.963293650793648,"adea0a98-d74d-43be-a238-a1ef027c6a58":10.105555555555554,"bd62aacb-5037-43d3-926a-af4d38ec3bfc":8.895,"c700dc12-7eac-4091-8462-527773668dfa":0,"c9482f1f-6600-44a7-a69a-e63ef13cdff8":11.552407407407406,"ca250ca4-70fd-411f-8cc7-fb17be31cd9e":8.205916305916306,"f6bd8b64-684d-429a-aab5-8ff3a2c23cd6":10.362222222222222,"f7ac19b7-daaf-4dc1-bbb9-7f4ffd7385ba":10.116428571428571},"topic":["layer","convolut","achiev","train","top5"],"offsprings":["c93eac1a-7d9a-48ab-9fb4-389c85bea00e","051956bb-f64b-4fdb-87f8-3e2868b8b5d8","176a7436-78ea-4c2a-82e6-7930ab023bd1","153c5014-dc7a-44a8-a93f-5cd27f1193df"]},"e3a5cec9-7e82-4c14-86ab-0d95a92712a7":{"authors":["Timo Ahonen","Abdenour Hadid","Matti Pietikäinen"],"references":["32d158dc-6f9f-426a-973b-8edc5e4c5dad","8d8e7d51-3223-4776-bf6a-40306774b8a1","9270a9b5-940a-4394-814f-433c6440f286","e2204e92-e6dc-4884-9bbc-200029491fc7"],"_id":"e3a5cec9-7e82-4c14-86ab-0d95a92712a7","abstract":"This paper presents a novel and efficient facial image representation based on local binary pattern (LBP) texture features. The face image is divided into several regions from which the LBP feature distributions are extracted and concatenated into an enhanced feature vector to be used as a face descriptor. The performance of the proposed method is assessed in the face recognition problem under different challenges. Other applications and several extensions are also discussed","title":"Face Description with Local Binary Patterns: Application to Face Recognition","venue":"IEEE Transactions on Pattern Analysis and Machine Intelligence","year":2006,"__v":0,"citationCount":1744,"parents":{"17373dba-934f-4ae0-bb50-8cc00dd7c19f":4.761904761904762,"1a461d15-582e-4b71-b98c-1b85902ee011":14.285714285714285,"29cd43e2-b893-40a5-883e-bbddf5b60a66":14.285714285714285,"2e71fa79-72e8-41ac-9b84-ea04720d7255":0,"32d158dc-6f9f-426a-973b-8edc5e4c5dad":14.285714285714285,"3dadbfa5-c6e3-4f19-899b-2294bc6660da":9.523809523809524,"3f28cca1-f895-4b34-9eb2-2afba6dad338":14.285714285714285,"40ea9b15-e3ff-4e65-b8b7-dd8b8e564931":14.285714285714285,"40f728c0-55b3-423b-aff5-a9b3ff27b7d5":0,"47b09a19-0c16-452b-8459-4348cde02256":14.285714285714285,"4bd3fdd6-d3df-4ee7-9bfa-92e2293d484d":4.761904761904762,"54a5822c-e405-44ad-84e3-cea51e7349c2":4.761904761904762,"72c27d5a-23c5-4d1b-a000-280b87b368ee":0,"853b9534-32ab-4bf8-a328-1f4c18cf3a1b":0,"8d8e7d51-3223-4776-bf6a-40306774b8a1":9.523809523809524,"9270a9b5-940a-4394-814f-433c6440f286":0,"971a895a-1c02-4631-8b0d-2b2f12b8083a":4.761904761904762,"9b7139da-fbd5-42d0-ade2-8cfdb4fa4cf1":0,"bd18a75e-3c40-4f53-b0e2-b4a9c6d49fae":33.33333333333333,"e2204e92-e6dc-4884-9bbc-200029491fc7":4.761904761904762,"ea8b1ce5-aad8-4502-8ef9-f4f314cd2b80":4.761904761904762},"keyword":{"17373dba-934f-4ae0-bb50-8cc00dd7c19f":10.503174603174601,"1a461d15-582e-4b71-b98c-1b85902ee011":10.102991452991452,"29cd43e2-b893-40a5-883e-bbddf5b60a66":10.163492063492061,"2e71fa79-72e8-41ac-9b84-ea04720d7255":8.961111111111112,"32d158dc-6f9f-426a-973b-8edc5e4c5dad":8.272222222222222,"3dadbfa5-c6e3-4f19-899b-2294bc6660da":10.933333333333334,"3f28cca1-f895-4b34-9eb2-2afba6dad338":10.27111111111111,"40ea9b15-e3ff-4e65-b8b7-dd8b8e564931":11.773888888888887,"40f728c0-55b3-423b-aff5-a9b3ff27b7d5":9.694179894179895,"47b09a19-0c16-452b-8459-4348cde02256":9.997037037037035,"4bd3fdd6-d3df-4ee7-9bfa-92e2293d484d":10.341666666666667,"54a5822c-e405-44ad-84e3-cea51e7349c2":10.1,"72c27d5a-23c5-4d1b-a000-280b87b368ee":11.246825396825393,"853b9534-32ab-4bf8-a328-1f4c18cf3a1b":9.61111111111111,"8d8e7d51-3223-4776-bf6a-40306774b8a1":9.920833333333334,"9270a9b5-940a-4394-814f-433c6440f286":7.277777777777777,"971a895a-1c02-4631-8b0d-2b2f12b8083a":9.624338624338627,"9b7139da-fbd5-42d0-ade2-8cfdb4fa4cf1":9.81111111111111,"bd18a75e-3c40-4f53-b0e2-b4a9c6d49fae":9.96111111111111,"e2204e92-e6dc-4884-9bbc-200029491fc7":11.57190476190476,"ea8b1ce5-aad8-4502-8ef9-f4f314cd2b80":10.327116402116403},"topic":["featur","face","lbp","imag","vector"],"groups":[{"authors":["Timo Ahonen","Matti Pietikäinen","Abdenour Hadid","Topi Mäenpää"],"references":["27505f5b-d81f-4b85-b85e-bd357aaa8468","2e71fa79-72e8-41ac-9b84-ea04720d7255","32d158dc-6f9f-426a-973b-8edc5e4c5dad","4bd3fdd6-d3df-4ee7-9bfa-92e2293d484d","54a5822c-e405-44ad-84e3-cea51e7349c2","72c27d5a-23c5-4d1b-a000-280b87b368ee","8fbd241e-236d-4a82-9471-0d854326e3cb","912aabff-def4-4026-9eb9-9d04cb8fabb1","e2204e92-e6dc-4884-9bbc-200029491fc7","ea8b1ce5-aad8-4502-8ef9-f4f314cd2b80"],"_id":"bd18a75e-3c40-4f53-b0e2-b4a9c6d49fae","abstract":"Recently, we proposed a novel facial representation for face recognition based on the local binary pattern (LBP) features. We obtained excellent results when dividing the face images into several regions from which the LBP features are extracted and concatenated into an enhanced feature vector as a face descriptor. However, it was unclear whether the obtained results were due to the use of local regions (instead of a holistic approach) or to the discriminative power of LBP. In this work, we investigated this issue by adopting and comparing four different texture features when using the appearances of local regions. The experimental results clearly showed and confirmed the validity of using LBP for face description.","title":"Face recognition based on the appearance of local regions","venue":"international conference on pattern recognition","year":2004,"__v":0,"citationCount":18}],"offsprings":["7236dbb7-f0b2-4e28-bb7c-6de187c32d64"]},"e537d143-155e-4ca0-8ae8-66b777a77fea":{"authors":["Stephen P. Boyd","Neal Parikh","Eric Chu","Borja Peleato","Jonathan Eckstein"],"references":["109367fa-db04-4db0-8777-d6ca7e9e78fd","5002dd27-9ce6-4abb-a3d0-2ac112f58c37","71a18de9-e543-4337-ab7a-3db31d9f8c00","839e59b8-b356-4329-ba79-97f981cf6768","a53a3dda-b003-4d5c-96b1-e9afd8e35692","ab0bfa8d-80b6-47ef-8a91-febce2ce65c5","f56b877b-4060-4754-b303-e8140968544c"],"_id":"e537d143-155e-4ca0-8ae8-66b777a77fea","abstract":"Many problems of recent interest in statistics and machine learning can be posed in the framework of convex optimization. Due to the explosion in size and complexity of modern datasets, it is increasingly important to be able to solve problems with a very large number of features or training examples. As a result, both the decentralized collection or storage of these datasets as well as accompanying distributed solution methods are either necessary or at least highly desirable. In this review, we argue that the alternating direction method of multipliers is well suited to distributed convex optimization, and in particular to large-scale problems arising in statistics, machine learning, and related areas. The method was developed in the 1970s, with roots in the 1950s, and is equivalent or closely related to many other algorithms, such as dual decomposition, the method of multipliers, Douglas–Rachford splitting, Spingarn's method of partial inverses, Dykstra's alternating projections, Bregman iterative algorithms for l1 problems, proximal methods, and others. After briefly surveying the theory and history of the algorithm, we discuss applications to a wide variety of statistical and machine learning problems of recent interest, including the lasso, sparse logistic regression, basis pursuit, covariance selection, support vector machines, and many others. We also discuss general distributed optimization, extensions to the nonconvex setting, and efficient implementation, including some details on distributed MPI and Hadoop MapReduce implementations.","title":"Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers","venue":"","year":2011,"__v":0,"citationCount":2516,"parents":{"01f025f9-3cc1-41d4-9424-363c290fe765":1.3513513513513513,"02629ee1-0ac3-4f22-a725-f59e6b5e6170":2.7027027027027026,"0435b723-134f-4036-ab7e-f3c21ce63e24":5.405405405405405,"0ab6d92b-44d2-44da-b029-39e138eb1216":1.3513513513513513,"109367fa-db04-4db0-8777-d6ca7e9e78fd":1.3513513513513513,"1112d936-cb10-4c0c-9eec-b4fd8f5a5c7f":9.45945945945946,"18cb68a7-8f1c-46f5-a854-7465070c1913":0,"19a42cd3-c8ae-4f71-8c8c-4eae6ca48345":5.405405405405405,"257b41f6-d411-4029-b551-4483e7c5cf3e":4.054054054054054,"26467b42-3e2f-4794-bbfa-6420a096257b":4.054054054054054,"2684fb9b-5b4d-400c-91fb-27fd5c083879":9.45945945945946,"2c58f129-ff63-4afe-ab63-b10d03da1779":1.3513513513513513,"2ca8a212-1179-4f68-bc20-8f2d8848585a":1.3513513513513513,"30577785-43de-4a11-b5f8-d460cd2944ec":0,"36430fd0-a383-4f6d-ae8a-6048eaf9fe08":2.7027027027027026,"3a0a2f46-50e6-46c8-872e-35744fe66738":1.3513513513513513,"3f90046c-1c24-4a11-abc5-831c4d30f660":4.054054054054054,"400299f5-6b73-4ea9-b1cc-c4460f8b60c4":0,"41fde063-16ea-4520-900d-3b935c8c53f0":1.3513513513513513,"4773f066-c0ab-4ed4-9a02-7fe97871fea8":0,"4b94b764-ede9-42ab-97c2-43700b728d69":2.7027027027027026,"5002dd27-9ce6-4abb-a3d0-2ac112f58c37":0,"5270bc6c-a24f-40d9-8d96-50c31f9d0bfb":2.7027027027027026,"52981273-36dc-429f-a12d-bada6edee02e":1.3513513513513513,"52e55346-2fb4-45a8-9e50-db06f3343982":0,"5b92842e-1023-4c80-99a2-23b15a78c58c":10.81081081081081,"5bbc1a90-621e-4b83-be68-d6fe2eb7c6c2":4.054054054054054,"5fa58e5b-3d77-4aee-905b-99aec0711748":0,"609d17f8-e650-4754-96eb-5c5a3769a50c":1.3513513513513513,"6e1947dd-2997-481b-9726-2921960e677f":1.3513513513513513,"71a18de9-e543-4337-ab7a-3db31d9f8c00":2.7027027027027026,"7298a617-55f9-4bdb-be57-7e83349bb530":4.054054054054054,"74b9aa5f-e5e4-4789-a5ca-254030320eca":10.81081081081081,"7a7b52f0-82db-4e16-9df0-d3f5b5c7b5c5":2.7027027027027026,"7b7510c9-1506-4153-b2df-6aa1242e22ef":0,"81a60c6f-2102-4b93-b991-00814ab480f4":2.7027027027027026,"839e59b8-b356-4329-ba79-97f981cf6768":0,"860a3efc-800e-4e62-8200-7acf3f8d2b8d":0,"861e877e-3903-4aed-827a-5a501858f17b":0,"87b16469-4b10-41e5-8dfc-2381a6592bfb":0,"92a22c32-9559-496a-b35c-813407edd134":6.756756756756757,"94e82a1e-656e-45d6-8b4e-1315c2e94fba":2.7027027027027026,"9b166075-5b89-4ec5-91db-47e5ca47c7ec":4.054054054054054,"9c7174a1-3c73-4a2e-a78b-b23816830420":1.3513513513513513,"9e7f3a14-e586-4bad-aab9-0c36173e441d":0,"a012a24d-aa95-4049-b628-e606a0d007e9":2.7027027027027026,"a06aef17-2b53-4dbd-ba4b-d15fdd44ba51":2.7027027027027026,"a083a1b9-8dfb-45d6-99a9-fa30c4a6e9f5":0,"a53a3dda-b003-4d5c-96b1-e9afd8e35692":0,"a7b474ca-c1f6-45c6-bc77-534d90c30764":1.3513513513513513,"aa70d058-ba2d-409f-a20e-fcf8239a069e":0,"ab0bfa8d-80b6-47ef-8a91-febce2ce65c5":0,"b18e236f-aa78-452c-a85a-240e5e5d69fb":8.108108108108109,"b220c1dd-7184-4e8b-a835-cce5504d95d1":0,"b22ae921-bc95-40ad-9a6e-af0d73790adc":5.405405405405405,"b2425f3b-5b13-483a-8fd1-fdf13fa238fd":0,"b8321e4f-ccae-433a-984e-7567535ff293":4.054054054054054,"b959ad94-9d47-418a-a145-e719bb379203":0,"bacedd4e-2e09-4ec8-8d9a-0f77e1e3816f":8.108108108108109,"bc40dd83-5f7a-435c-8275-73f36c3c6c49":4.054054054054054,"c18bd8c2-a8ab-431e-8d13-621efa0864de":9.45945945945946,"c9ef3dc8-4117-4dc4-8aa5-19d8af78766c":0,"d7b5aadf-ec30-4fb7-9224-7474169d3744":0,"db26488d-78be-44b1-a343-e896f43c5d29":0,"de4fea1d-2739-4e0f-b5a3-08f0df58d787":0,"e05c0e3a-edab-4cc4-af71-9ea53378e364":5.405405405405405,"e5b8523a-bc81-4389-8569-741e2c590dd3":2.7027027027027026,"ea082c34-f979-4fdc-9e13-a74e93cadebc":2.7027027027027026,"eb3c9554-d529-42df-ba9a-5665ffa2b2d1":0,"f3478418-696c-42da-a11d-a654e4aba79e":1.3513513513513513,"f56b877b-4060-4754-b303-e8140968544c":2.7027027027027026,"fa619312-6a30-40c5-bd8e-f09dffce0543":2.7027027027027026,"fb0a382c-a1f1-4f0c-8e80-36fe5fbbfb86":0,"fbea2899-47c7-41de-b0e7-af93e8889537":4.054054054054054},"keyword":{"01f025f9-3cc1-41d4-9424-363c290fe765":9.380026455026455,"02629ee1-0ac3-4f22-a725-f59e6b5e6170":9.722513227513225,"0435b723-134f-4036-ab7e-f3c21ce63e24":9.787671957671957,"0ab6d92b-44d2-44da-b029-39e138eb1216":8.516838624338623,"109367fa-db04-4db0-8777-d6ca7e9e78fd":11.126375661375661,"1112d936-cb10-4c0c-9eec-b4fd8f5a5c7f":9.708465608465607,"18cb68a7-8f1c-46f5-a854-7465070c1913":8.81058201058201,"19a42cd3-c8ae-4f71-8c8c-4eae6ca48345":10.625925925925927,"257b41f6-d411-4029-b551-4483e7c5cf3e":10.907619047619047,"26467b42-3e2f-4794-bbfa-6420a096257b":11.197222222222221,"2684fb9b-5b4d-400c-91fb-27fd5c083879":11.393492063492065,"2c58f129-ff63-4afe-ab63-b10d03da1779":11.894603174603176,"2ca8a212-1179-4f68-bc20-8f2d8848585a":11.774735449735449,"30577785-43de-4a11-b5f8-d460cd2944ec":0,"36430fd0-a383-4f6d-ae8a-6048eaf9fe08":8.557407407407407,"3a0a2f46-50e6-46c8-872e-35744fe66738":12.328174603174604,"3f90046c-1c24-4a11-abc5-831c4d30f660":9.257407407407406,"400299f5-6b73-4ea9-b1cc-c4460f8b60c4":9.641556036556034,"41fde063-16ea-4520-900d-3b935c8c53f0":8.784788359788358,"4773f066-c0ab-4ed4-9a02-7fe97871fea8":11.25410052910053,"4b94b764-ede9-42ab-97c2-43700b728d69":8.707539682539682,"5002dd27-9ce6-4abb-a3d0-2ac112f58c37":10.854629629629628,"5270bc6c-a24f-40d9-8d96-50c31f9d0bfb":10.694338624338624,"52981273-36dc-429f-a12d-bada6edee02e":10.837804232804231,"52e55346-2fb4-45a8-9e50-db06f3343982":9.706084656084654,"5b92842e-1023-4c80-99a2-23b15a78c58c":9.699735449735448,"5bbc1a90-621e-4b83-be68-d6fe2eb7c6c2":10.993227513227513,"5fa58e5b-3d77-4aee-905b-99aec0711748":11.102116402116403,"609d17f8-e650-4754-96eb-5c5a3769a50c":10.988955026455026,"6e1947dd-2997-481b-9726-2921960e677f":10.252579365079365,"71a18de9-e543-4337-ab7a-3db31d9f8c00":11.578835978835977,"7298a617-55f9-4bdb-be57-7e83349bb530":11.638756613756613,"74b9aa5f-e5e4-4789-a5ca-254030320eca":9.932599807599807,"7a7b52f0-82db-4e16-9df0-d3f5b5c7b5c5":11.440343915343915,"7b7510c9-1506-4153-b2df-6aa1242e22ef":10.039814814814815,"81a60c6f-2102-4b93-b991-00814ab480f4":8.934338624338624,"839e59b8-b356-4329-ba79-97f981cf6768":11.152857142857144,"860a3efc-800e-4e62-8200-7acf3f8d2b8d":11.729629629629628,"861e877e-3903-4aed-827a-5a501858f17b":13.135052910052911,"87b16469-4b10-41e5-8dfc-2381a6592bfb":10.073544973544973,"92a22c32-9559-496a-b35c-813407edd134":7.867724867724866,"94e82a1e-656e-45d6-8b4e-1315c2e94fba":7.398809523809524,"9b166075-5b89-4ec5-91db-47e5ca47c7ec":9.124999999999998,"9c7174a1-3c73-4a2e-a78b-b23816830420":11.260780423280423,"9e7f3a14-e586-4bad-aab9-0c36173e441d":10.61888888888889,"a012a24d-aa95-4049-b628-e606a0d007e9":10.636878306878307,"a06aef17-2b53-4dbd-ba4b-d15fdd44ba51":10.803042328042327,"a083a1b9-8dfb-45d6-99a9-fa30c4a6e9f5":11.868386243386242,"a53a3dda-b003-4d5c-96b1-e9afd8e35692":10.360033670033667,"a7b474ca-c1f6-45c6-bc77-534d90c30764":10.589417989417989,"aa70d058-ba2d-409f-a20e-fcf8239a069e":8.668783068783066,"ab0bfa8d-80b6-47ef-8a91-febce2ce65c5":12.06513949013949,"b18e236f-aa78-452c-a85a-240e5e5d69fb":10.985714285714284,"b220c1dd-7184-4e8b-a835-cce5504d95d1":9.665343915343914,"b22ae921-bc95-40ad-9a6e-af0d73790adc":10.692883597883597,"b2425f3b-5b13-483a-8fd1-fdf13fa238fd":11.268783068783067,"b8321e4f-ccae-433a-984e-7567535ff293":10.612592592592593,"b959ad94-9d47-418a-a145-e719bb379203":11.069814814814814,"bacedd4e-2e09-4ec8-8d9a-0f77e1e3816f":11.749338624338623,"bc40dd83-5f7a-435c-8275-73f36c3c6c49":9.39179894179894,"c18bd8c2-a8ab-431e-8d13-621efa0864de":10.73867724867725,"c9ef3dc8-4117-4dc4-8aa5-19d8af78766c":10.763359788359786,"d7b5aadf-ec30-4fb7-9224-7474169d3744":9.412037037037036,"db26488d-78be-44b1-a343-e896f43c5d29":0,"de4fea1d-2739-4e0f-b5a3-08f0df58d787":11.554603174603175,"e05c0e3a-edab-4cc4-af71-9ea53378e364":10.643227513227513,"e5b8523a-bc81-4389-8569-741e2c590dd3":10.839497354497352,"ea082c34-f979-4fdc-9e13-a74e93cadebc":10.08079365079365,"eb3c9554-d529-42df-ba9a-5665ffa2b2d1":11.661904761904761,"f3478418-696c-42da-a11d-a654e4aba79e":12.15830687830688,"f56b877b-4060-4754-b303-e8140968544c":10.584319384319382,"fa619312-6a30-40c5-bd8e-f09dffce0543":10.374603174603175,"fb0a382c-a1f1-4f0c-8e80-36fe5fbbfb86":10.76206349206349,"fbea2899-47c7-41de-b0e7-af93e8889537":0},"topic":["method","problem","machin","distribut","statist"],"offsprings":[]},"e649a9fd-f6d9-4aac-b428-29b82c20a484":{"authors":["Paul A. Viola","Michael J. Jones"],"references":["310cbba4-d88d-4bf4-a4f2-738f91b5f8c8","6d121e97-e351-4cf9-8c44-d7ab3ce9d9fe"],"_id":"e649a9fd-f6d9-4aac-b428-29b82c20a484","abstract":"This paper describes a machine learning approach for visual object detection which is capable of processing images extremely rapidly and achieving high detection rates. This work is distinguished by three key contributions. The first is the introduction of a new image representation called the \"integral image\" which allows the features used by our detector to be computed very quickly. The second is a learning algorithm, based on AdaBoost, which selects a small number of critical visual features from a larger set and yields extremely efficient classifiers. The third contribution is a method for combining increasingly more complex classifiers in a \"cascade\" which allows background regions of the image to be quickly discarded while spending more computation on promising object-like regions. The cascade can be viewed as an object specific focus-of-attention mechanism which unlike previous approaches provides statistical guarantees that discarded regions are unlikely to contain the object of interest. In the domain of face detection the system yields detection rates comparable to the best previous systems. Used in real-time applications, the detector runs at 15 frames per second without resorting to image differencing or skin color detection.","title":"Rapid object detection using a boosted cascade of simple features","venue":"computer vision and pattern recognition","year":2001,"__v":0,"citationCount":5200,"parents":{"13cd743f-beb9-43a1-8e08-2ef08f0d8b3f":0,"17f811d8-8607-4270-bbec-1cc7883edd68":7.142857142857142,"310cbba4-d88d-4bf4-a4f2-738f91b5f8c8":0,"36800655-b2ff-4eb7-9070-c6be304c4baa":0,"43530fe4-10a9-4ddf-b61d-8844f0ff3f04":7.142857142857142,"5ffac6f9-2456-42cf-830c-9049ce37c899":7.142857142857142,"6d121e97-e351-4cf9-8c44-d7ab3ce9d9fe":7.142857142857142,"9fa55b0f-eaa6-4c59-b6e5-77e5f1a406f0":0,"c7f93552-c1ef-4ae4-b1f5-2317e1c9d904":28.57142857142857,"d5e5a24d-f80e-4f1a-b48b-22403b653276":0,"d6e37fb1-5f7e-448e-847b-7d1f1271c574":7.142857142857142,"db26488d-78be-44b1-a343-e896f43c5d29":0,"f1bd37c4-d033-4cd1-af44-4df9f11c71e4":21.428571428571427,"f4642ffc-3571-4d02-8b94-142f2448023a":0},"keyword":{"13cd743f-beb9-43a1-8e08-2ef08f0d8b3f":9.727777777777776,"17f811d8-8607-4270-bbec-1cc7883edd68":7.166666666666666,"310cbba4-d88d-4bf4-a4f2-738f91b5f8c8":11.629365079365078,"36800655-b2ff-4eb7-9070-c6be304c4baa":11.908333333333331,"43530fe4-10a9-4ddf-b61d-8844f0ff3f04":10.145238095238096,"5ffac6f9-2456-42cf-830c-9049ce37c899":6.804444444444445,"6d121e97-e351-4cf9-8c44-d7ab3ce9d9fe":9.809523809523808,"9fa55b0f-eaa6-4c59-b6e5-77e5f1a406f0":8.366666666666665,"c7f93552-c1ef-4ae4-b1f5-2317e1c9d904":11.417724867724868,"d5e5a24d-f80e-4f1a-b48b-22403b653276":10.82222222222222,"d6e37fb1-5f7e-448e-847b-7d1f1271c574":10.345238095238097,"db26488d-78be-44b1-a343-e896f43c5d29":0,"f1bd37c4-d033-4cd1-af44-4df9f11c71e4":8.96111111111111,"f4642ffc-3571-4d02-8b94-142f2448023a":10.408730158730158},"topic":["imag","detect","region","object","yield"],"groups":[{"authors":["Henry Schneiderman","Takeo Kanade"],"references":["310cbba4-d88d-4bf4-a4f2-738f91b5f8c8","4a29b56b-b74e-4945-9017-61a7ab844fd9","8f6a657e-e387-4572-bb88-91aee042e8da","96d6d9b9-6d69-4c9a-b3f5-c8083966d55c","bb83383f-0de9-408b-9ba2-aa902c63f14a","d5e5a24d-f80e-4f1a-b48b-22403b653276","d6e37fb1-5f7e-448e-847b-7d1f1271c574","db26488d-78be-44b1-a343-e896f43c5d29","ed59a2e5-7330-4e07-9edf-cc80872135d0"],"_id":"c7f93552-c1ef-4ae4-b1f5-2317e1c9d904","abstract":"In this paper, we describe a statistical method for 3D object detection. We represent the statistics of both object appearance and \"non-object\" appearance using a product of histograms. Each histogram represents the joint statistics of a subset of wavelet coefficients and their position on the object. Our approach is to use many such histograms representing a wide variety of visual attributes. Using this method, we have developed the first algorithm that can reliably detect human faces with out-of-plane rotation and the first algorithm that can reliably detect passenger cars over a wide range of viewpoints.","title":"A statistical method for 3D object detection applied to faces and cars","venue":"computer vision and pattern recognition","year":2000,"__v":0,"citationCount":525}],"offsprings":["50252efa-a843-4cc6-a591-22f527ee3d6c","f225f439-4389-4312-a503-f8c1b0aa02de","32d158dc-6f9f-426a-973b-8edc5e4c5dad"]},"ea1d5c21-fba6-4fae-9fdc-ee7679ee46c9":{"authors":["Ali Jadbabaie","Jie Lin","A.S. Morse"],"references":[],"_id":"ea1d5c21-fba6-4fae-9fdc-ee7679ee46c9","abstract":"In a recent Physical Review Letters article, Vicsek et al. propose a simple but compelling discrete-time model of n autonomous agents (i.e., points or particles) all moving in the plane with the same speed but with different headings. Each agent's heading is updated using a local rule based on the average of its own heading plus the headings of its \"neighbors.\" In their paper, Vicsek et al. provide simulation results which demonstrate that the nearest neighbor rule they are studying can cause all agents to eventually move in the same direction despite the absence of centralized coordination and despite the fact that each agent's set of nearest neighbors change with time as the system evolves. This paper provides a theoretical explanation for this observed behavior. In addition, convergence results are derived for several other similarly inspired models. The Vicsek model proves to be a graphic example of a switched linear system which is stable, but for which there does not exist a common quadratic Lyapunov function.","title":"Coordination of groups of mobile autonomous agents using nearest neighbor rules","venue":"IEEE Transactions on Automatic Control","year":2003,"__v":0,"citationCount":2265,"parents":{"aeabc622-720d-44d0-888c-787e7d377f54":0,"b6a0562d-91b9-4b65-a395-0e705e24f3ba":0,"cf772fd2-26e1-49d5-b59c-5854b276ab0d":25,"ee265d03-1a69-4425-b248-bd68bc9ed6e0":0},"keyword":{"aeabc622-720d-44d0-888c-787e7d377f54":8.829365079365079,"b6a0562d-91b9-4b65-a395-0e705e24f3ba":8.90388888888889,"cf772fd2-26e1-49d5-b59c-5854b276ab0d":8.991666666666665,"ee265d03-1a69-4425-b248-bd68bc9ed6e0":7.279761904761904},"topic":["head","agent","vicsek","neighbor","model"],"groups":[{"authors":["Yang Liu","Kevin M. Passino","Marios M. Polycarpou"],"references":["47aa8f65-89ee-425a-a10f-ea923b73db63","675525e3-866a-4414-b4f6-4a77bfcc4054","b6a0562d-91b9-4b65-a395-0e705e24f3ba","baf403cc-eaa6-4aa3-8a43-50d63ab45774","dba09d73-450f-4780-8b27-0b0eea033856"],"_id":"cf772fd2-26e1-49d5-b59c-5854b276ab0d","abstract":"Coordinated dynamical swarm behavior occurs when certain types of animals forage for food or try to avoid predators. Analogous behaviors can occur in engineering systems such as in groups of autonomous mobile robots or air vehicles. In this paper we characterize swarm \"cohesiveness\" as a stability property and provide conditions under which convergence can be achieved for an asynchronous swarm with swarm members that have proximity sensors and neighbor position sensors that only provide delayed position information. Such stability analysis is fundamental to understand the coordination mechanisms for groups of autonomous vehicles or robots where inter-member communication channels are less than perfect.","title":"Stability analysis of one-dimensional asynchronous swarms","venue":"american control conference","year":2001,"__v":0,"citationCount":7}],"offsprings":["d9162547-fd7f-4605-855d-0a3173c4b08e","2768199c-b9d6-4001-94d3-e6429c93bc5f"]},"ea8cd3d8-17ae-4a1e-8f83-1609469087af":{"authors":["Andrew Y. Ng","Michael I. Jordan","Yair Weiss"],"references":["94898e1d-1e50-41ab-9dcc-2c2e030cddd0"],"_id":"ea8cd3d8-17ae-4a1e-8f83-1609469087af","abstract":"Despite many empirical successes of spectral clustering methods— algorithms that cluster points using eigenvectors of matrices derived from the data—there are several unresolved issues. First. there are a wide variety of algorithms that use the eigenvectors in slightly different ways. Second, many of these algorithms have no proof that they will actually compute a reasonable clustering. In this paper, we present a simple spectral clustering algorithm that can be implemented using a few lines of Matlab. Using tools from matrix perturbation theory, we analyze the algorithm, and give conditions under which it can be expected to do well. We also show surprisingly good experimental results on a number of challenging clustering problems.","title":"On Spectral Clustering: Analysis and an algorithm","venue":"neural information processing systems","year":2002,"__v":0,"citationCount":2537,"parents":{"52b8747c-6eef-43bc-8e11-aa3c4aae1111":0,"5c89ee50-d7f5-4cd6-8eed-19a08efd6f90":0,"75d0cdfa-44cd-4fc3-ae56-72e982cb383b":28.57142857142857,"94898e1d-1e50-41ab-9dcc-2c2e030cddd0":0,"98cfeac3-9abb-4f5b-9705-158c3b7b9d3a":14.285714285714285,"d78003db-ad8a-48d2-be57-1c50e95cef72":0,"fbb1d0f0-290f-490d-baab-63d29bc5f794":42.857142857142854},"keyword":{"52b8747c-6eef-43bc-8e11-aa3c4aae1111":11.756433381433379,"5c89ee50-d7f5-4cd6-8eed-19a08efd6f90":10.5259139009139,"75d0cdfa-44cd-4fc3-ae56-72e982cb383b":12.611399711399708,"94898e1d-1e50-41ab-9dcc-2c2e030cddd0":11.758571428571424,"98cfeac3-9abb-4f5b-9705-158c3b7b9d3a":10.387289562289563,"d78003db-ad8a-48d2-be57-1c50e95cef72":12.280156325156321,"fbb1d0f0-290f-490d-baab-63d29bc5f794":11.706848244348242},"topic":["cluster","algorithm","spectral","eigenvector","wide"],"groups":[{"authors":["Marina Meila","Jianbo Shi"],"references":["0cdb081e-f2db-49d9-8c65-45cbcc948265","2256cad0-cf03-42da-bcf3-4a89be0ebf8e","6e184d1b-925b-4918-b354-a2647e8fd945","75d0cdfa-44cd-4fc3-ae56-72e982cb383b","98cfeac3-9abb-4f5b-9705-158c3b7b9d3a","d78003db-ad8a-48d2-be57-1c50e95cef72"],"_id":"fbb1d0f0-290f-490d-baab-63d29bc5f794","abstract":"We present a new view of image segmentation by pairwise similarities. We interpret the similarities as edge flows in a Markov random walk and study the eigenvalues and eigenvectors of the walk's transition matrix. This interpretation shows that spectral methods for clustering and segmentation have a probabilistic foundation. In particular, we prove that the Normalized Cut method arises naturally from our framework. Finally, the framework provides a principled method for learning the similarity function as a combination of features.","title":"Learning Segmentation by Random Walks","venue":"neural information processing systems","year":2001,"__v":0,"citationCount":145},{"authors":["Ravi Kannan","Santosh Vempala","Andre Mia Veta"],"references":["52b8747c-6eef-43bc-8e11-aa3c4aae1111","63139dcf-11e2-4b8e-bcbd-ebd1f0511389","6c4b0829-01d8-407a-8cab-53cd38080c2f","70c53433-0357-4957-9089-6e59a06282c3","7ec5f06e-2fe3-495a-84a0-94fcfe08bb7b","93b14f9a-884c-441a-b91d-66a659248c0d","9438a773-c15c-4ef2-a97c-54f643ce6082","b613fdc9-9f3c-484c-aac3-2d55eadf7cbb","c19c233b-6b1d-40a9-b553-a6efbe11932c","c4d758e3-eadb-4d0f-828f-323ff3a1dd8c","d78003db-ad8a-48d2-be57-1c50e95cef72","d7953b97-e51b-45e2-b0f7-5e2eed1f9bd3","e1ebee81-dfa4-4fe0-b0e1-c00df9ada4d4","ecefe0b5-db61-490b-8a4b-56abf2a8e5ab","fec44afc-ba10-4d57-a898-4208e83890eb"],"_id":"75d0cdfa-44cd-4fc3-ae56-72e982cb383b","abstract":"We propose a new measure for assessing the quality of a clustering. A simple heuristic is shown to give worst-case guarantees under the new measure. Then we present two results regarding the quality of the clustering found by a popular spectral algorithm. One proffers worst case guarantees whilst the other shows that if there exists a \"good\" clustering then the spectral algorithm will find one close to it.","title":"On clusterings-good, bad and spectral","venue":"foundations of computer science","year":2000,"__v":0,"citationCount":172}],"offsprings":["68faab18-b537-4f62-85cf-ddc9ef352362","7c90045b-63b9-4f29-82a0-bf7c914a6ef6","c472bfe1-9ef6-43c6-89b5-a86b22c9f5df","05bbaec3-7980-4941-8638-2bbfa4ac8be0"]},"ecfb2022-e18c-4e5e-8733-d8bc6f4c8fc9":{"authors":["Ravi S. Sandhu","Edward J. Coyne","Hal L. Feinstein","Charles E. Youman"],"references":[],"_id":"ecfb2022-e18c-4e5e-8733-d8bc6f4c8fc9","abstract":"Security administration of large systems is complex, but it can be simplified by a role-based access control approach. This article explains why RBAC is receiving renewed attention as a method of security administration and review, describes a framework of four reference models developed to better understand RBAC and categorizes different implementations, and discusses the use of RBAC to manage itself.","title":"Role-based access control models","venue":"IEEE Computer","year":1996,"__v":0,"citationCount":2624,"parents":{"35f0ebdf-46b0-4dcd-a2d8-434037c708c9":0,"56428856-7a68-4b14-af11-f3cb042d2980":12.5,"79fc0389-d85c-4ff1-a5eb-ee4ef3111b83":12.5,"9e08ab3b-3582-42b4-91bd-fdd7c33384a0":0,"b1b8023c-43aa-4df5-9099-895a5587d465":12.5,"b491d50b-5661-4b0e-a6c7-b4584bb4d2a3":0,"c2b503c3-2888-4cb7-9f24-51ecd8487c0d":0,"fb1724a9-bfb2-4c58-a73e-66c50f4256ec":0},"keyword":{"35f0ebdf-46b0-4dcd-a2d8-434037c708c9":9.855476190476189,"56428856-7a68-4b14-af11-f3cb042d2980":8.133333333333333,"79fc0389-d85c-4ff1-a5eb-ee4ef3111b83":10.822962962962961,"9e08ab3b-3582-42b4-91bd-fdd7c33384a0":0,"b1b8023c-43aa-4df5-9099-895a5587d465":8.379722222222222,"b491d50b-5661-4b0e-a6c7-b4584bb4d2a3":11.422433862433861,"c2b503c3-2888-4cb7-9f24-51ecd8487c0d":0,"fb1724a9-bfb2-4c58-a73e-66c50f4256ec":9.63111111111111},"topic":["rbac","secur","administr","understand","system"],"offsprings":[]},"ed543a19-85d9-427a-a2d3-88e7c59a100e":{"authors":["Bo Pang","Lillian Lee","Shivakumar Vaithyanathan"],"references":["c75c7b08-7264-4daa-a133-59bea66db0c7"],"_id":"ed543a19-85d9-427a-a2d3-88e7c59a100e","abstract":"We consider the problem of classifying documents not by topic, but by overall sentiment, e.g., determining whether a review is positive or negative. Using movie reviews as data, we find that standard machine learning techniques definitively outperform human-produced baselines. However, the three machine learning methods we employed (Naive Bayes, maximum entropy classification, and support vector machines) do not perform as well on sentiment classification as on traditional topic-based categorization. We conclude by examining factors that make the sentiment classification problem more challenging.","title":"Thumbs up? Sentiment Classification using Machine Learning Techniques","venue":"empirical methods in natural language processing","year":2002,"__v":0,"citationCount":2142,"parents":{"01f443e7-ea4c-48a7-8081-745c3fa62769":0,"21421f14-af9c-4c95-9aad-b7bece9fb7d9":0,"23b2db98-6897-497b-8b90-67b591016a5e":0,"3b20d6fb-4f2c-4eab-b5a3-82746b83f1f1":0,"43bcc79f-1316-4a3c-81ba-69e6c3afbcbb":5.88235294117647,"691983e4-67cb-4456-9462-42b22c620c64":0,"75ec0b95-65c5-48c9-ae1b-a44c6c378bec":5.88235294117647,"90ca3ecc-702a-45ab-af75-8c5851ce7bb9":0,"96d6d9b9-6d69-4c9a-b3f5-c8083966d55c":0,"a4830914-2189-4c4b-bfa4-adc5b45b7c23":0,"ab339474-ea21-443b-893f-96ae09e65a2e":5.88235294117647,"c75c7b08-7264-4daa-a133-59bea66db0c7":17.647058823529413,"c7ce0fc7-4d38-4355-aa19-ab35527d2519":0,"cf111a55-139a-4108-bf05-a8e25ec7874f":0,"ddef8d03-46e5-4df7-ac2d-ce48d54ba742":11.76470588235294,"e1f8e6f0-eee8-4e01-ace1-cbc47ac3880a":5.88235294117647,"ed8013b0-9bdd-4bc6-b31a-70fca6d15aa9":0},"keyword":{"01f443e7-ea4c-48a7-8081-745c3fa62769":11.135396825396827,"21421f14-af9c-4c95-9aad-b7bece9fb7d9":11.739801587301587,"23b2db98-6897-497b-8b90-67b591016a5e":9.953148148148149,"3b20d6fb-4f2c-4eab-b5a3-82746b83f1f1":8.710185185185185,"43bcc79f-1316-4a3c-81ba-69e6c3afbcbb":9.13915343915344,"691983e4-67cb-4456-9462-42b22c620c64":10.893121693121692,"75ec0b95-65c5-48c9-ae1b-a44c6c378bec":9.283597883597885,"90ca3ecc-702a-45ab-af75-8c5851ce7bb9":8.75515873015873,"96d6d9b9-6d69-4c9a-b3f5-c8083966d55c":12.802248677248675,"a4830914-2189-4c4b-bfa4-adc5b45b7c23":8.663359788359788,"ab339474-ea21-443b-893f-96ae09e65a2e":9.79477513227513,"c75c7b08-7264-4daa-a133-59bea66db0c7":12.948571428571427,"c7ce0fc7-4d38-4355-aa19-ab35527d2519":0,"cf111a55-139a-4108-bf05-a8e25ec7874f":10.25595238095238,"ddef8d03-46e5-4df7-ac2d-ce48d54ba742":9.312592592592592,"e1f8e6f0-eee8-4e01-ace1-cbc47ac3880a":9.605767195767195,"ed8013b0-9bdd-4bc6-b31a-70fca6d15aa9":10.819047619047616},"topic":["sentiment","machin","classif","review","problem"],"offsprings":["d924ecc1-ce71-4250-ae5d-570769554f74"]},"f0887f29-b2e1-4971-a369-4df8b83b8996":{"authors":["Zhengyou Zhang"],"references":[],"_id":"f0887f29-b2e1-4971-a369-4df8b83b8996","abstract":"We propose a flexible technique to easily calibrate a camera. It only requires the camera to observe a planar pattern shown at a few (at least two) different orientations. Either the camera or the planar pattern can be freely moved. The motion need not be known. Radial lens distortion is modeled. The proposed procedure consists of a closed-form solution, followed by a nonlinear refinement based on the maximum likelihood criterion. Both computer simulation and real data have been used to test the proposed technique and very good results have been obtained. Compared with classical techniques which use expensive equipment such as two or three orthogonal planes, the proposed technique is easy to use and flexible. It advances 3D computer vision one more step from laboratory environments to real world use.","title":"A flexible new technique for camera calibration","venue":"IEEE Transactions on Pattern Analysis and Machine Intelligence","year":2000,"__v":0,"citationCount":2240,"parents":{"1aba91b5-6a0e-4ef2-82d7-81e5a9148073":14.285714285714285,"4acbc4da-25d9-4183-a386-7628dbb37bcb":14.285714285714285,"5b3acbaa-b46e-4d2b-8cf8-ef4f5a1c490b":0,"60985c9a-ca14-4324-882d-95cedabefdeb":7.142857142857142,"8f9d2434-c08a-43e5-8152-d41f2784ddc2":0,"9cdf6433-1372-43cc-bcb9-32274c5897e9":7.142857142857142,"a67fc652-c0d0-4fe0-adc2-7651c4470600":14.285714285714285,"b73280d5-1e86-4fd4-86fb-2b7b670d7eb4":14.285714285714285,"ba090582-262b-4640-a5b3-714c472736ba":7.142857142857142,"c5df7d5d-c642-4943-9b2b-f26b735eb345":7.142857142857142,"ea918d26-cd76-4aa3-9064-de9bb7247ecd":28.57142857142857,"eede97e6-1365-4fe4-91fe-8a1fa9608eca":0,"f3f304d9-dcc9-431e-b913-f7f6b02e4fdc":21.428571428571427,"f7a42517-180e-4724-ac12-7c6d4380e2d0":21.428571428571427},"keyword":{"1aba91b5-6a0e-4ef2-82d7-81e5a9148073":10.100396825396825,"4acbc4da-25d9-4183-a386-7628dbb37bcb":12.029444444444442,"5b3acbaa-b46e-4d2b-8cf8-ef4f5a1c490b":10.956084656084656,"60985c9a-ca14-4324-882d-95cedabefdeb":10.172222222222222,"8f9d2434-c08a-43e5-8152-d41f2784ddc2":9.97425925925926,"9cdf6433-1372-43cc-bcb9-32274c5897e9":10.23484126984127,"a67fc652-c0d0-4fe0-adc2-7651c4470600":0,"b73280d5-1e86-4fd4-86fb-2b7b670d7eb4":11.885666185666185,"ba090582-262b-4640-a5b3-714c472736ba":0,"c5df7d5d-c642-4943-9b2b-f26b735eb345":11.684259259259258,"ea918d26-cd76-4aa3-9064-de9bb7247ecd":11.131666666666668,"eede97e6-1365-4fe4-91fe-8a1fa9608eca":9.311111111111112,"f3f304d9-dcc9-431e-b913-f7f6b02e4fdc":9.736666666666666,"f7a42517-180e-4724-ac12-7c6d4380e2d0":11.23373015873016},"topic":["techniqu","propos","camera","real","planar"],"groups":[{"authors":["Bill Triggs"],"references":["0e09e890-51f5-4b3e-82af-544dddbe681f","1a596bea-9cb3-4905-a48b-0e390282b804","475ed267-e5d7-464f-b67e-d55e8b4e2fa7","47ba28ee-c56e-4d18-98dd-15fd0959ca60","4887e883-7135-42bf-a61e-93e4f6506941","500cbd14-47ae-4e42-9ce0-3c0828c49478","5d5ea28a-b533-4dc0-b314-19d4d4e60418","61d61e7c-17d3-496d-a105-7cf8ee1b5a2f","75b00318-ea33-4477-8b21-94ee19351a87","8f9d2434-c08a-43e5-8152-d41f2784ddc2","a135294f-d8d7-4332-a1b8-077cf1720201","a67fc652-c0d0-4fe0-adc2-7651c4470600","b78ba4db-4361-443c-9863-93708688adf2","ba090582-262b-4640-a5b3-714c472736ba","c5df7d5d-c642-4943-9b2b-f26b735eb345","f6779f97-9495-4387-b68c-e5fd5cf3462f"],"_id":"ea918d26-cd76-4aa3-9064-de9bb7247ecd","abstract":"This paper describes the theory and a practical algorithm for the autocalibration of a moving projective camera, from m > 5 views of a planar scene. The unknown camera calibration, motion and scene geometry are recovered up to scale, from constraints encoding the motion-invariance of the camera's internal parameters. This extends the domain of autocalibration from the classical non-planar case to the practically common planar one, in which the solution can not be bootstrapped from an intermediate projective reconstruction. It also generalizes Hartley's method for the internal calibration of a rotating camera, to allow camera translation and to provide 3D as well as calibration information. The basic constraint is that orthogonal directions (points at infinity) in the plane must project to orthogonal directions in the calibrated images. ly, the plane's two circular points (representing its Euclidean structure) lie on the 3D absolute conic, so their projections must lie on the absolute image conic (representing the camera calibration). The resulting algorithm optimizes this constraint numerically over all circular points and all projective calibration parameters, using the inter-image homographies as a projective scene representation.","title":"Autocalibration from Planar Scenes","venue":"european conference on computer vision","year":1998,"__v":0,"citationCount":179},{"authors":["Peter F. Sturm","Stephen J. Maybank"],"references":["2340a3b7-155f-4c9d-80de-fa5b211e617c","42c5d6b1-061c-4f5c-bcac-dcdf866c774c","60985c9a-ca14-4324-882d-95cedabefdeb","7a996b37-aa13-4aac-a3cf-d0c6fe36d43f","88f45ffc-d70a-4903-b69f-2b7b5abc0e63","936bcefc-41e4-4f7b-9009-5bbb2cc4b4d6","9cdf6433-1372-43cc-bcb9-32274c5897e9","ba075c20-553a-45ed-95dc-42523b2b5b90","d389a566-eac3-45b9-9d38-a5c5290542d2","e96aa488-c9e7-4b1c-8b81-b90df53a3692","ea918d26-cd76-4aa3-9064-de9bb7247ecd"],"_id":"f7a42517-180e-4724-ac12-7c6d4380e2d0","abstract":"We present a general algorithm for plane-based calibration that can deal with arbitrary numbers of views and calibration planes. The algorithm can simultaneously calibrate different views from a camera with variable intrinsic parameters and it is easy to incorporate known values of intrinsic parameters. For some minimal cases, we describe all singularities, naming the parameters that can not be estimated. Experimental results of our method are shown that exhibit the singularities while revealing good performance in non-singular conditions. Several applications of plane-based 3D geometry inference are discussed as well.","title":"On plane-based camera calibration: A general algorithm, singularities, applications","venue":"computer vision and pattern recognition","year":1999,"__v":0,"citationCount":205}],"offsprings":["1f520d1a-5870-477d-85d7-0f50be690ea7"]},"f14df1ed-e3e9-4348-9040-fc06e3411b95":{"authors":["Antony I. T. Rowstron","Peter Druschel"],"references":["4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4","e1263ada-afda-498c-a37d-9b545293118a"],"_id":"f14df1ed-e3e9-4348-9040-fc06e3411b95","abstract":"This paper presents the design and evaluation of Pastry, a scalable, distributed object location and routing substrate for wide-area peer-to-peer ap- plications. Pastry performs application-level routing and object location in a po- tentially very large overlay network of nodes connected via the Internet. It can be used to support a variety of peer-to-peer applications, including global data storage, data sharing, group communication and naming. Each node in the Pastry network has a unique identifier (nodeId). When presented with a message and a key, a Pastry node efficiently routes the message to the node with a nodeId that is numerically closest to the key, among all currently live Pastry nodes. Each Pastry node keeps track of its immediate neighbors in the nodeId space, and notifies applications of new node arrivals, node failures and recoveries. Pastry takes into account network locality; it seeks to minimize the distance messages travel, according to a to scalar proximity metric like the number of IP routing hops. Pastry is completely decentralized, scalable, and self-organizing; it automatically adapts to the arrival, departure and failure of nodes. Experimental results obtained with a prototype implementation on an emulated network of up to 100,000 nodes confirm Pastry's scalability and efficiency, its ability to self-organize and adapt to node failures, and its good network locality properties.","title":"Pastry: Scalable, Decentralized Object Location, and Routing for Large-Scale Peer-to-Peer Systems","venue":"Lecture Notes in Computer Science","year":2001,"__v":0,"citationCount":4022,"parents":{"0f290b24-96ae-48f7-9304-9209bba8db17":0,"1cc64868-4f72-4939-aed4-fc8fb0b45118":9.523809523809524,"309f5d34-0bb0-4ffc-aa87-fdffb67dddf6":19.047619047619047,"39adcd6c-0b60-430c-99ab-21cd9e98b385":0,"40fb7878-7a6e-4fc1-af74-a73c1261c20b":0,"42c70869-0dad-4629-93b5-a2d9e29071a7":0,"48740ddd-afd1-4331-8af7-224ef5d19ed7":0,"4ae3d80b-ce75-4c33-8abb-c5358ec01a6d":0,"4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4":28.57142857142857,"4ff9d356-904f-4ad9-835a-bc3ccf6febd9":0,"5e354aca-2d93-43f7-8e80-6bc4eb96e7d9":80.95238095238095,"5e43bfa1-e1fa-428f-847f-b1b575380d14":4.761904761904762,"6500989e-b1e1-4b02-a921-21ec25685b73":9.523809523809524,"747c0c4a-1e59-4af3-a9a6-ad0d081a49ce":0,"b7d7ec53-f079-4bd7-a795-8b6fe77f2db6":28.57142857142857,"c0ea675b-2479-48ae-817e-3ecedd175ecf":0,"c8771a57-de9c-44b7-966c-1ff156d3091f":0,"d81c71d5-dd57-46e3-92e0-daf7a7bbb065":0,"e1263ada-afda-498c-a37d-9b545293118a":38.095238095238095,"e4ee2d81-7629-4445-b4f3-55ef57bd42fd":4.761904761904762,"eb02194b-fa72-4f3e-a259-1dd36cd4839d":33.33333333333333},"keyword":{"0f290b24-96ae-48f7-9304-9209bba8db17":10.74537037037037,"1cc64868-4f72-4939-aed4-fc8fb0b45118":10.24047619047619,"309f5d34-0bb0-4ffc-aa87-fdffb67dddf6":11.227579365079363,"39adcd6c-0b60-430c-99ab-21cd9e98b385":10.929497354497355,"40fb7878-7a6e-4fc1-af74-a73c1261c20b":10.921428571428574,"42c70869-0dad-4629-93b5-a2d9e29071a7":9.738888888888889,"48740ddd-afd1-4331-8af7-224ef5d19ed7":10.184126984126983,"4ae3d80b-ce75-4c33-8abb-c5358ec01a6d":8.86595238095238,"4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4":9.659523809523808,"4ff9d356-904f-4ad9-835a-bc3ccf6febd9":9.23015873015873,"5e354aca-2d93-43f7-8e80-6bc4eb96e7d9":8.530952380952382,"5e43bfa1-e1fa-428f-847f-b1b575380d14":10.273174603174601,"6500989e-b1e1-4b02-a921-21ec25685b73":11.199735449735448,"747c0c4a-1e59-4af3-a9a6-ad0d081a49ce":11.020767195767199,"b7d7ec53-f079-4bd7-a795-8b6fe77f2db6":8.86190476190476,"c0ea675b-2479-48ae-817e-3ecedd175ecf":0,"c8771a57-de9c-44b7-966c-1ff156d3091f":9.473015873015873,"d81c71d5-dd57-46e3-92e0-daf7a7bbb065":9.726984126984126,"e1263ada-afda-498c-a37d-9b545293118a":10.051719576719575,"e4ee2d81-7629-4445-b4f3-55ef57bd42fd":9.896825396825397,"eb02194b-fa72-4f3e-a259-1dd36cd4839d":12.178571428571429},"topic":["node","pastri","network","rout","scalabl"],"groups":[{"authors":["Ion Stoica","Robert Morris","David Liben-Nowell","David R. Karger","M. Frans Kaashoek","Frank Dabek","Hari Balakrishnan"],"references":["1cc64868-4f72-4939-aed4-fc8fb0b45118","48740ddd-afd1-4331-8af7-224ef5d19ed7","59084791-6ebd-4d0d-8f93-2c1da8d47490","6aac8d9c-34bd-42d9-b887-b0a3bd697ee6","6eff83a4-db80-40ea-8c9f-8bda5f506c29","a369afee-a619-4e9a-9250-5fd2b06e8a05","aa89fd2a-319e-48b1-b0ab-099acbe37617","abf003a2-6485-41f0-a111-88b80412d539","b7d7ec53-f079-4bd7-a795-8b6fe77f2db6","b948f5db-4dc3-4151-a9bd-62a3f5be739e","c0ea675b-2479-48ae-817e-3ecedd175ecf","c37c70cb-3956-4249-934d-848845f2f444","e1263ada-afda-498c-a37d-9b545293118a","e4ee2d81-7629-4445-b4f3-55ef57bd42fd","ea44a1ae-ddfe-4694-8df1-0ec69182ec11","f14df1ed-e3e9-4348-9040-fc06e3411b95","f49921e2-fb25-48d1-aaf2-1afcfeb8b268","fad8fc34-ff78-45ac-bc30-ca9e4173740f"],"_id":"4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4","abstract":"A fundamental problem that confronts peer-to-peer applications is the efficient location of the node that stores a desired data item. This paper presents  Chord , a distributed lookup protocol that addresses this problem. Chord provides support for just one operation: given a key, it maps the key onto a node. Data location can be easily implemented on top of Chord by associating a key with each data item, and storing the key/data pair at the node to which the key maps. Chord adapts efficiently as nodes join and leave the system, and can answer queries even if the system is continuously changing. Results from theoretical analysis and simulations show that Chord is scalable: Communication cost and the state maintained by each node scale logarithmically with the number of Chord nodes.","title":"Chord: a scalable peer-to-peer lookup protocol for Internet applications","venue":"IEEE\\/ACM Transactions on Networking","year":2003,"__v":0,"citationCount":5975},{"authors":["Antony I. T. Rowstron","Peter Druschel"],"references":["0f290b24-96ae-48f7-9304-9209bba8db17","152b8a68-f115-4173-a262-45aa2c9046b5","1c729f22-9928-4703-92a0-8819569a1bbb","1cc64868-4f72-4939-aed4-fc8fb0b45118","36f0f3cb-6b32-4284-8e08-0972ee67074f","40fb7878-7a6e-4fc1-af74-a73c1261c20b","42c70869-0dad-4629-93b5-a2d9e29071a7","48740ddd-afd1-4331-8af7-224ef5d19ed7","4ae3d80b-ce75-4c33-8abb-c5358ec01a6d","4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4","4f60dbc7-9647-4b91-b96f-9f77d07fea7c","4ff9d356-904f-4ad9-835a-bc3ccf6febd9","5e43bfa1-e1fa-428f-847f-b1b575380d14","5fa79bc6-4203-442f-a3e8-99abe8bd542a","6500989e-b1e1-4b02-a921-21ec25685b73","747c0c4a-1e59-4af3-a9a6-ad0d081a49ce","78001675-2215-4b4e-8a92-cd30f6409d70","9f65fe84-a2e3-420a-8fe4-7253e4605422","b7d7ec53-f079-4bd7-a795-8b6fe77f2db6","c0ea675b-2479-48ae-817e-3ecedd175ecf","d06f8723-1b89-4684-99c9-c1045ddfb85c","d81c71d5-dd57-46e3-92e0-daf7a7bbb065","e1263ada-afda-498c-a37d-9b545293118a","e4ee2d81-7629-4445-b4f3-55ef57bd42fd","eb02194b-fa72-4f3e-a259-1dd36cd4839d","f14df1ed-e3e9-4348-9040-fc06e3411b95"],"_id":"5e354aca-2d93-43f7-8e80-6bc4eb96e7d9","abstract":"This paper presents and evaluates the storage management and caching in PAST, a large-scale peer-to-peer persistent storage utility. PAST is based on a self-organizing, Internet-based overlay network of storage nodes that cooperatively route file queries, store multiple replicas of files, and cache additional copies of popular files.In the PAST system, storage nodes and files are each assigned uniformly distributed identifiers, and replicas of a file are stored at nodes whose identifier matches most closely the file's identifier. This statistical assignment of files to storage nodes approximately balances the number of files stored on each node. However, non-uniform storage node capacities and file sizes require more explicit storage load balancing to permit graceful behavior under high global storage utilization; likewise, non-uniform popularity of files requires caching to minimize fetch distance and to balance the query load.We present and evaluate PAST, with an emphasis on its storage management and caching system. Extensive trace-driven experiments show that the system minimizes fetch distance, that it balances the query load for popular files, and that it displays graceful degradation of performance as the global storage utilization increases beyond 95%.","title":"Storage management and caching in PAST, a large-scale, persistent peer-to-peer storage utility","venue":"symposium on operating systems principles","year":2001,"__v":0,"citationCount":657},{"authors":["Sylvia Ratnasamy","Paul Francis","Mark Handley","Richard M. Karp","Scott Shenker"],"references":["00ade209-5974-42c1-9089-a3741481d9c7","0695070f-320e-4d26-9c68-2c8faa20c944","0a094924-1b25-43cc-ac8b-dd8cf90a8f78","1545dfd3-2c25-4ff1-b43c-df4a2a501d06","1cc64868-4f72-4939-aed4-fc8fb0b45118","31c5e39a-3f24-4d20-bf8c-3d00036baf95","39adcd6c-0b60-430c-99ab-21cd9e98b385","42c70869-0dad-4629-93b5-a2d9e29071a7","4743d708-b82d-42ec-adaa-a8bf2f23cc38","483cb980-c968-48e6-b848-714ed2937f98","48740ddd-afd1-4331-8af7-224ef5d19ed7","4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4","88c35cd8-dd49-44f8-9674-96974c8f3650","c0ea675b-2479-48ae-817e-3ecedd175ecf","c8771a57-de9c-44b7-966c-1ff156d3091f","d06f8723-1b89-4684-99c9-c1045ddfb85c","e4ee2d81-7629-4445-b4f3-55ef57bd42fd","ec7d1720-3285-4729-b819-b4c58a826ec8","f6fc4443-7a98-4f9f-92e8-e4e5d94521a7"],"_id":"e1263ada-afda-498c-a37d-9b545293118a","abstract":"Hash tables - which map \"keys\" onto \"values\" - are an essential building block in modern software systems. We believe a similar functionality would be equally valuable to large distributed systems. In this paper, we introduce the concept of a Content-Addressable Network (CAN) as a distributed infrastructure that provides hash table-like functionality on Internet-like scales. The CAN is scalable, fault-tolerant and completely self-organizing, and we demonstrate its scalability, robustness and low-latency properties through simulation.","title":"A scalable content-addressable network","venue":"acm special interest group on data communication","year":2001,"__v":0,"citationCount":3635},{"authors":["Peter Druschel","Antony I. T. Rowstron"],"references":["1cc64868-4f72-4939-aed4-fc8fb0b45118","42c70869-0dad-4629-93b5-a2d9e29071a7","48740ddd-afd1-4331-8af7-224ef5d19ed7","4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4","5e354aca-2d93-43f7-8e80-6bc4eb96e7d9","9ba85cd6-22c7-487d-828d-5d8c092d1280","ad88020d-b7d4-40c7-adae-1014e51f3a2f","c0ea675b-2479-48ae-817e-3ecedd175ecf","e1263ada-afda-498c-a37d-9b545293118a","f14df1ed-e3e9-4348-9040-fc06e3411b95"],"_id":"eb02194b-fa72-4f3e-a259-1dd36cd4839d","abstract":"This paper sketches the design of PAST, a large-scale, Internet-based, global storage utility that provides scalability, high availability, persistence and security. PAST is a peer-to-peer Internet application and is entirely self-organizing. PAST nodes serve as access points for clients, participate in the routing of client requests, and contribute storage to the system. Nodes are not trusted, they may join the system at any time and may silently leave the system without warning. Yet, the system is able to provide strong assurances, efficient storage access, load balancing and scalability. Among the most interesting aspects of PAST's design are (1) the Pastry location and routing scheme, which reliably and efficiently routes client requests among the PAST nodes, has good network locality properties and automatically resolves node failures and node additions; (2) the use of randomization to ensure diversity in the set of nodes that store a file's replicas and to provide load balancing; and (3) the optional use of smartcards, which are held by each PAST user and issued by a third party called a broker The smartcards support a quota system that balances supply and demand of storage in the system.","title":"PAST: a large-scale, persistent peer-to-peer storage utility","venue":"ieee international conference on requirements engineering","year":2001,"__v":0,"citationCount":247},{"authors":["Frank Dabek","M. Frans Kaashoek","David R. Karger","Robert Morris","Ion Stoica"],"references":["1c729f22-9928-4703-92a0-8819569a1bbb","1cc64868-4f72-4939-aed4-fc8fb0b45118","1dda408f-2203-4793-bfa8-2fab15bce7cf","48740ddd-afd1-4331-8af7-224ef5d19ed7","4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4","5e354aca-2d93-43f7-8e80-6bc4eb96e7d9","5fa0709f-7330-417f-8da7-3ab31d91da5b","6eff83a4-db80-40ea-8c9f-8bda5f506c29","786e7d9f-6e9a-47e5-8482-7ee37809b922","9f65fe84-a2e3-420a-8fe4-7253e4605422","a369afee-a619-4e9a-9250-5fd2b06e8a05","b1ab8eee-7043-4f04-b440-5765752d4845","b90c5640-8e10-4f65-9193-c28af80f45e2","bd61df44-c80e-406c-8c4e-9c13635ce4f5","c0ea675b-2479-48ae-817e-3ecedd175ecf","cb0dcdc4-3c84-4301-891b-42535ac74f8c","cf67f4c1-ff76-4210-ba80-0356733c5be7","e1263ada-afda-498c-a37d-9b545293118a","f14df1ed-e3e9-4348-9040-fc06e3411b95"],"_id":"b7d7ec53-f079-4bd7-a795-8b6fe77f2db6","abstract":"The Cooperative File System (CFS) is a new peer-to-peer read-only storage system that provides provable guarantees for the efficiency, robustness, and load-balance of file storage and retrieval. CFS does this with a completely decentralized architecture that can scale to large systems. CFS servers provide a distributed hash table (DHash) for block storage. CFS clients interpret DHash blocks as a file system. DHash distributes and caches blocks at a fine granularity to achieve load balance, uses replication for robustness, and decreases latency with server selection. DHash finds blocks using the Chord location protocol, which operates in time logarithmic in the number of servers.CFS is implemented using the SFS file system toolkit and runs on Linux, OpenBSD, and FreeBSD. Experience on a globally deployed prototype shows that CFS delivers data to clients as fast as FTP. Controlled tests show that CFS is scalable: with 4,096 servers, looking up a block of data involves contacting only seven servers. The tests also demonstrate nearly perfect robustness and unimpaired performance even when as many as half the servers fail.","title":"Wide-area cooperative storage with CFS","venue":"symposium on operating systems principles","year":2001,"__v":0,"citationCount":784}],"offsprings":["4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4"]},"f1e74152-3f7c-4c44-b628-cdf47a17587f":{"authors":["Joseph Mitola","Gerald Q. Maguire"],"references":[],"_id":"f1e74152-3f7c-4c44-b628-cdf47a17587f","abstract":"Software radios are emerging as platforms for multiband multimode personal communications systems. Radio etiquette is the set of RF bands, air interfaces, protocols, and spatial and temporal patterns that moderate the use of the radio spectrum. Cognitive radio extends the software radio with radio-domain model-based reasoning about such etiquettes. Cognitive radio enhances the flexibility of personal services through a radio knowledge representation language. This language represents knowledge of radio etiquette, devices, software modules, propagation, networks, user needs, and application scenarios in a way that supports automated reasoning about the needs of the user. This empowers software radios to conduct expressive negotiations among peers about the use of radio spectrum across fluents of space, time, and user context. With RKRL, cognitive radio agents may actively manipulate the protocol stack to adapt known etiquettes to better satisfy the user's needs. This transforms radio nodes from blind executors of predefined protocols to radio-domain-aware intelligent agents that search out ways to deliver the services the user wants even if that user does not know how to obtain them. Software radio provides an ideal platform for the realization of cognitive radio.","title":"Cognitive radio: making software radios more personal","venue":"IEEE Personal Communications","year":1999,"__v":0,"citationCount":3057,"parents":{"bba1e045-9ab2-4f35-a507-b41edf454837":0,"c0ba3ea5-3988-4fca-9c41-6cd8ef0765f1":0},"keyword":{"bba1e045-9ab2-4f35-a507-b41edf454837":10.439285714285713,"c0ba3ea5-3988-4fca-9c41-6cd8ef0765f1":0},"topic":["radio","user","softwar","etiquett","cognit"],"offsprings":["d1ba534e-3f80-4366-bb83-be16006f9e18"]},"f2d49150-35de-4fd5-ac46-eb071d1cc73e":{"authors":["Pedro F. Felzenszwalb","Ross B. Girshick","David A. McAllester","Deva Ramanan"],"references":["83c737b8-e084-4766-ba6e-131e6a1c017c","8b8a2247-bd77-4736-b493-449734f56b9a","b944f77f-113b-4a02-ae5e-d4a124b8fd5b","bf03f268-de9d-4a80-aee1-200990056503","dd83785a-dd19-41e3-9b25-ebabbd48d336"],"_id":"f2d49150-35de-4fd5-ac46-eb071d1cc73e","abstract":"We describe an object detection system based on mixtures of multiscale deformable part models. Our system is able to represent highly variable object classes and achieves state-of-the-art results in the PASCAL object detection challenges. While deformable part models have become quite popular, their value had not been demonstrated on difficult benchmarks such as the PASCAL data sets. Our system relies on new methods for discriminative training with partially labeled data. We combine a margin-sensitive approach for data-mining hard negative examples with a formalism we call latent SVM. A latent SVM is a reformulation of MI--SVM in terms of latent variables. A latent SVM is semiconvex, and the training problem becomes convex once latent information is specified for the positive examples. This leads to an iterative training algorithm that alternates between fixing latent values for positive examples and optimizing the latent SVM objective function.","title":"Object Detection with Discriminatively Trained Part-Based Models","venue":"IEEE Transactions on Pattern Analysis and Machine Intelligence","year":2010,"__v":0,"citationCount":3149,"parents":{"0149d4d7-6775-4387-9098-d02ddb7dbc58":18.91891891891892,"0d21b163-cce6-4dc5-bb12-1f6c7e709436":16.216216216216218,"0ea0c1c5-e42b-4843-90b7-3cef138e4327":8.108108108108109,"13d83701-8e72-482a-882e-fc1450146d6e":2.7027027027027026,"1ed718cd-ab43-47e4-a97f-e68d0f7fb216":2.7027027027027026,"202da7f7-a7fc-4026-b535-b2c938c5567a":5.405405405405405,"21094c3c-478e-4d91-8ae6-9ff240ebfc6f":13.513513513513514,"2be85cbb-5df3-42f0-99db-3bb427412cea":0,"325664f0-77db-4ab7-8e85-1f79e70df4cf":0,"3c49df6f-3b50-450f-aa93-4c715cfd05af":10.81081081081081,"3dedfe96-bf8c-47fb-ad4e-075e54b48ec6":27.027027027027028,"43530fe4-10a9-4ddf-b61d-8844f0ff3f04":2.7027027027027026,"52dbf565-81ab-439e-a9af-6c4d6ae302f8":37.83783783783784,"648675c6-6ea7-4fa5-a91d-9d3156d09692":2.7027027027027026,"64fa74e8-db02-4190-87d7-bf23e9859a7c":2.7027027027027026,"651454cb-eb8b-4f08-8f7a-b40f6b55b998":2.7027027027027026,"67f92163-023b-4655-8abe-acf23dc38aea":5.405405405405405,"7f367932-20d6-425d-b207-9869b1c277cf":8.108108108108109,"81eec382-cc0a-4381-91df-a90054925734":5.405405405405405,"83c737b8-e084-4766-ba6e-131e6a1c017c":18.91891891891892,"8b8a2247-bd77-4736-b493-449734f56b9a":8.108108108108109,"9f84e529-87a3-42f1-9d63-9af710f40925":0,"a5254ae0-1ce1-4390-b9f8-8d5a3dcb1e62":5.405405405405405,"a96a19b9-2924-4231-9da7-ad1860d23480":5.405405405405405,"ab2669d7-eed4-41db-abe8-46d91db31747":2.7027027027027026,"b944f77f-113b-4a02-ae5e-d4a124b8fd5b":2.7027027027027026,"bf03f268-de9d-4a80-aee1-200990056503":0,"c455fb04-4566-4648-ad6f-3cf2245e507c":10.81081081081081,"c7f93552-c1ef-4ae4-b1f5-2317e1c9d904":2.7027027027027026,"d5e5a24d-f80e-4f1a-b48b-22403b653276":2.7027027027027026,"dd83785a-dd19-41e3-9b25-ebabbd48d336":5.405405405405405,"e44ae1a0-12a2-4838-a42f-fdade39c81a5":8.108108108108109,"eb017324-3c9c-4ffb-b5bd-81833b925af6":5.405405405405405,"ed835ca3-7120-4646-afaf-20c04a57c698":2.7027027027027026,"ef35a024-f5f3-4a7b-b6f6-61d9167385e6":2.7027027027027026,"f111ff97-89a3-4df6-8f02-962d7b4fe985":2.7027027027027026,"fc780759-4533-4b33-9774-746ca210842f":13.513513513513514},"keyword":{"0149d4d7-6775-4387-9098-d02ddb7dbc58":9.839682539682538,"0d21b163-cce6-4dc5-bb12-1f6c7e709436":7.922222222222223,"0ea0c1c5-e42b-4843-90b7-3cef138e4327":9.304761904761904,"13d83701-8e72-482a-882e-fc1450146d6e":10.058095238095238,"1ed718cd-ab43-47e4-a97f-e68d0f7fb216":8.36079365079365,"202da7f7-a7fc-4026-b535-b2c938c5567a":8.311111111111112,"21094c3c-478e-4d91-8ae6-9ff240ebfc6f":8.769444444444446,"2be85cbb-5df3-42f0-99db-3bb427412cea":9.749166666666667,"325664f0-77db-4ab7-8e85-1f79e70df4cf":9.736111111111112,"3c49df6f-3b50-450f-aa93-4c715cfd05af":10.318055555555555,"3dedfe96-bf8c-47fb-ad4e-075e54b48ec6":10.811111111111112,"43530fe4-10a9-4ddf-b61d-8844f0ff3f04":9.817460317460316,"52dbf565-81ab-439e-a9af-6c4d6ae302f8":9.822222222222223,"648675c6-6ea7-4fa5-a91d-9d3156d09692":10.02142857142857,"64fa74e8-db02-4190-87d7-bf23e9859a7c":8.405238095238095,"651454cb-eb8b-4f08-8f7a-b40f6b55b998":10.13425925925926,"67f92163-023b-4655-8abe-acf23dc38aea":11.14642857142857,"7f367932-20d6-425d-b207-9869b1c277cf":8.071428571428571,"81eec382-cc0a-4381-91df-a90054925734":9.311111111111112,"83c737b8-e084-4766-ba6e-131e6a1c017c":10.057142857142857,"8b8a2247-bd77-4736-b493-449734f56b9a":10.177777777777777,"9f84e529-87a3-42f1-9d63-9af710f40925":10.522222222222222,"a5254ae0-1ce1-4390-b9f8-8d5a3dcb1e62":10.495,"a96a19b9-2924-4231-9da7-ad1860d23480":8.222222222222223,"ab2669d7-eed4-41db-abe8-46d91db31747":8.171904761904763,"b944f77f-113b-4a02-ae5e-d4a124b8fd5b":9.812698412698413,"bf03f268-de9d-4a80-aee1-200990056503":10.007857142857144,"c455fb04-4566-4648-ad6f-3cf2245e507c":10.495873015873018,"c7f93552-c1ef-4ae4-b1f5-2317e1c9d904":11.058201058201059,"d5e5a24d-f80e-4f1a-b48b-22403b653276":9.335555555555556,"dd83785a-dd19-41e3-9b25-ebabbd48d336":11.22722222222222,"e44ae1a0-12a2-4838-a42f-fdade39c81a5":10.582142857142857,"eb017324-3c9c-4ffb-b5bd-81833b925af6":9.93611111111111,"ed835ca3-7120-4646-afaf-20c04a57c698":8.596798941798943,"ef35a024-f5f3-4a7b-b6f6-61d9167385e6":10.01833333333333,"f111ff97-89a3-4df6-8f02-962d7b4fe985":8.311111111111112,"fc780759-4533-4b33-9774-746ca210842f":9.561587301587302},"topic":["latent","svm","object","train","system"],"groups":[{"authors":["Bastian Leibe","Ales Leonardis","Bernt Schiele"],"references":["0289a1a7-579b-42a8-8795-45bb59850e67","05c99d31-32c1-431d-99ce-0dfcd6ca805c","0aae4e44-abdb-4948-9462-61f6e52162ba","16340e43-b1cd-4c5f-8b9a-44384a0a6123","177b7083-bfca-472b-833a-515f1ad77735","1b2ca840-c231-4d15-b1d5-09fd8d61400c","20f52431-62f1-4670-ba81-d19ef3c04204","21094c3c-478e-4d91-8ae6-9ff240ebfc6f","21a8e8fd-0172-4e9a-8474-7024eb0bf979","21c67dad-f0eb-4479-afe7-fdf4a71eef01","229c6b00-6eaf-4302-b843-09167f8082c5","2d6c9f60-ea78-44a8-b5f9-6964575dd196","307b5053-ee01-4dc6-8969-7efa7379e416","34758e0a-3def-447b-9c5e-e82a206426b5","34ab16ee-97db-4520-992e-f92aca3386d8","473cf1a4-9f42-4e6d-b34f-77787f329079","49e8d454-99f4-4cde-9ff8-6f50c33eaa48","526860a6-aea8-4f8d-b7f9-e01d3629a6a9","54a5822c-e405-44ad-84e3-cea51e7349c2","552d8ea6-1cb0-44db-ba2c-eec5016ef5df","5ea6e082-6427-4ac3-ac85-95f9232c8213","6018a516-8149-4bce-bc33-5449d86e58c2","60285266-7da2-474e-b05a-b380c836f665","64fa74e8-db02-4190-87d7-bf23e9859a7c","8028b8ab-06c2-41f8-b833-88ba9248fd15","81eec382-cc0a-4381-91df-a90054925734","853b29ea-c6d1-497e-bad3-b608d370e7e2","873c9c21-6bfd-484c-95ed-c4831ec8e00a","8b8a2247-bd77-4736-b493-449734f56b9a","8d8e7d51-3223-4776-bf6a-40306774b8a1","9298ec73-f02d-4ee5-9fab-1ac3f188a910","9438a773-c15c-4ef2-a97c-54f643ce6082","98cfeac3-9abb-4f5b-9705-158c3b7b9d3a","a74b3c2b-0710-4648-afb1-298f23b47030","b29cb808-1f59-40e9-8afa-26a3701b6284","b592576f-ff29-4a68-9b2f-8a8ad02e9c70","b944f77f-113b-4a02-ae5e-d4a124b8fd5b","bdd58d4a-2e0e-4fb2-8049-cfa50dda7b0d","c455fb04-4566-4648-ad6f-3cf2245e507c","c591c440-b19b-4d7b-b067-cd8c366b7d6d","c69bfded-9ea9-4a1c-84f9-1e230e30ceed","c8f80ea6-4602-458c-9a70-daf1c646c89b","cb66e49d-077b-4adf-873c-2bc39f78fca6","cf545f57-5abd-4a15-888f-a674b99391ed","d486ab6f-98b8-46a1-8ae2-521ebd7391d6","d4d98193-fa86-445e-a140-959c646323a7","d6e37fb1-5f7e-448e-847b-7d1f1271c574","dd83785a-dd19-41e3-9b25-ebabbd48d336","e1f2a353-af70-48c2-aba6-a0e0a71fdffc","e46bb6ea-7b67-4edf-8cd4-a51ce64cff19","ed8a9624-3abe-4b5e-bffe-5b3ecc34e841","ee9b186c-b7f0-4323-8f28-a55bbbd62b71","ef35a024-f5f3-4a7b-b6f6-61d9167385e6","f111ff97-89a3-4df6-8f02-962d7b4fe985","f200d16f-8e1a-4a51-be50-4eeaafbb4a2f","fc4a70a7-80c5-43c8-a68f-0a72a46ecce8","fc780759-4533-4b33-9774-746ca210842f","ff0d990e-90f3-4973-8541-5f7e595710aa"],"_id":"3dedfe96-bf8c-47fb-ad4e-075e54b48ec6","abstract":"This paper presents a novel method for detecting and localizing objects of a visual category in cluttered real-world scenes. Our approach considers object categorization and figure-ground segmentation as two interleaved processes that closely collaborate towards a common goal. As shown in our work, the tight coupling between those two processes allows them to benefit from each other and improve the combined performance. #R##N##R##N#The core part of our approach is a highly flexible learned representation for object shape that can combine the information observed on different training examples in a probabilistic extension of the Generalized Hough Transform. The resulting approach can detect categorical objects in novel images and automatically infer a probabilistic segmentation from the recognition result. This segmentation is then in turn used to again improve recognition by allowing the system to focus its efforts on object pixels and to discard misleading influences from the background. Moreover, the information from where in the image a hypothesis draws its support is employed in an MDL based hypothesis verification stage to resolve ambiguities between overlapping hypotheses and factor out the effects of partial occlusion. #R##N##R##N#An extensive evaluation on several large data sets shows that the proposed system is applicable to a range of different object categories, including both rigid and articulated objects. In addition, its flexible representation allows it to achieve competitive object detection performance already from training sets that are between one and two orders of magnitude smaller than those used in comparable systems.","title":"Robust Object Detection with Interleaved Categorization and Segmentation","venue":"International Journal of Computer Vision","year":2008,"__v":0,"citationCount":501},{"authors":["Pedro F. Felzenszwalb","David A. McAllester","Deva Ramanan"],"references":["0149d4d7-6775-4387-9098-d02ddb7dbc58","0d21b163-cce6-4dc5-bb12-1f6c7e709436","13d83701-8e72-482a-882e-fc1450146d6e","202da7f7-a7fc-4026-b535-b2c938c5567a","3c49df6f-3b50-450f-aa93-4c715cfd05af","651454cb-eb8b-4f08-8f7a-b40f6b55b998","67f92163-023b-4655-8abe-acf23dc38aea","6f6fe122-6003-498c-a584-b27b3f7a6be3","81eec382-cc0a-4381-91df-a90054925734","83c737b8-e084-4766-ba6e-131e6a1c017c","8f5cecf7-c1dc-4400-8af3-739409424dac","9f84e529-87a3-42f1-9d63-9af710f40925","c455fb04-4566-4648-ad6f-3cf2245e507c","c45e6f71-1ad4-4971-b22f-12f3af34379f","dbc47800-7dc3-46da-94d3-70120f07f13a","dd83785a-dd19-41e3-9b25-ebabbd48d336","ed8a9624-3abe-4b5e-bffe-5b3ecc34e841","ef35a024-f5f3-4a7b-b6f6-61d9167385e6","fc780759-4533-4b33-9774-746ca210842f"],"_id":"52dbf565-81ab-439e-a9af-6c4d6ae302f8","abstract":"This paper describes a discriminatively trained, multiscale, deformable part model for object detection. Our system achieves a two-fold improvement in average precision over the best performance in the 2006 PASCAL person detection challenge. It also outperforms the best results in the 2007 challenge in ten out of twenty categories. The system relies heavily on deformable parts. While deformable part models have become quite popular, their value had not been demonstrated on difficult benchmarks such as the PASCAL challenge. Our system also relies heavily on new methods for discriminative training. We combine a margin-sensitive approach for data mining hard negative examples with a formalism we call latent SVM. A latent SVM, like a hidden CRF, leads to a non-convex training problem. However, a latent SVM is semi-convex and the training problem becomes convex once latent information is specified for the positive examples. We believe that our training methods will eventually make possible the effective use of more latent information such as hierarchical (grammar) models and models involving latent three dimensional pose.","title":"A discriminatively trained, multiscale, deformable part model","venue":"computer vision and pattern recognition","year":2008,"__v":0,"citationCount":916}],"offsprings":["176a7436-78ea-4c2a-82e6-7930ab023bd1"]},"f3267c01-b670-4b7a-a3a5-79088c0d90ab":{"authors":["Ian F. Akyildiz","Weilian Su","Yogesh Sankarasubramaniam","Erdal Cayirci"],"references":["23dd7fc0-1ebd-43ce-ab3e-43896512c209","3939cb96-d8c8-4ec4-8102-bbce2976aeee","8828d2f5-0b50-4715-863d-66c787fc40e0","afc06b7c-7fb3-4f88-942b-3076ed77920e"],"_id":"f3267c01-b670-4b7a-a3a5-79088c0d90ab","abstract":"This paper describes the concept of sensor networks which has been made viable by the convergence of micro-electro-mechanical systems technology, wireless communications and digital electronics. First, the sensing tasks and the potential sensor networks applications are explored, and a review of factors influencing the design of sensor networks is provided. Then, the communication architecture for sensor networks is outlined, and the algorithms and protocols developed for each layer in the literature are explored. Open research issues for the realization of sensor networks are also discussed.","title":"Wireless sensor networks: a survey","venue":"Computer Networks","year":2002,"__v":0,"citationCount":5060,"parents":{"05e77df0-5ecd-435f-943d-9a5be09e969d":2.0408163265306123,"05fb3436-276f-43ca-979b-0a3323240c19":0,"0f1d0353-2c63-49e9-b29c-4d258cf2a445":2.0408163265306123,"10f58ff9-c14e-4bf5-9c44-0a3f14626d3f":0,"2088d2fd-d0ed-477f-b350-5d342624e91e":16.3265306122449,"23dd7fc0-1ebd-43ce-ab3e-43896512c209":2.0408163265306123,"282f60bc-e000-420c-b8f7-6d52d645e2b9":0,"28f9f004-7356-4bb4-85e1-275330adeb32":2.0408163265306123,"30e4f067-742f-4ad5-b8b0-66d3e8b6303f":2.0408163265306123,"32b7988a-f873-44c9-bacb-0d660fe12f01":4.081632653061225,"35f43b14-7174-4eb7-ab99-ce32d08af1a4":6.122448979591836,"3657876a-6f24-47e3-bbba-62e4b3f7ab05":6.122448979591836,"38f54b84-5272-43df-8cde-a3e755b17dee":0,"3939cb96-d8c8-4ec4-8102-bbce2976aeee":0,"436c164e-783e-46c1-a03c-4c7473c8c2df":0,"47cc806c-a905-4355-9bfa-d1a49bf7034b":0,"4ac80067-bbea-4eaf-8b7a-89c97db7ecfe":0,"4ce4d734-c29c-4097-9ca9-314feaccc642":0,"553db688-bb98-4ed0-a2a4-42f1e5678559":0,"55a6413a-4a9c-4e8d-957b-8c1a4e5d5f0b":0,"653c2aa8-cf50-451c-8877-f397ffd07fb5":0,"6b527e7d-50c4-42f5-b3d2-b688d23b8138":28.57142857142857,"73574f5f-bf4f-44fb-b13f-d5eaa8c96619":4.081632653061225,"776f8406-6b10-4397-a1b6-5c8b9b0e1927":0,"81074e3c-5e19-4dd5-9b64-52e97111b919":0,"84dc5aaa-7b2c-4f15-97f4-aa867b4328e2":8.16326530612245,"869b266e-e607-4f60-92d8-d8726d0c97da":0,"8828d2f5-0b50-4715-863d-66c787fc40e0":0,"97612810-668b-4ed2-87d8-38eada1f6377":2.0408163265306123,"988d1185-0dd2-4da9-9f47-2be897e90836":4.081632653061225,"9b531247-bb38-4d26-94e8-dab8c453e3ca":2.0408163265306123,"9e063b41-0ada-4db8-8846-6e5153a0de55":2.0408163265306123,"9e52b6a5-e70c-437f-a30d-8d544132c939":0,"9eafc226-1312-41de-a492-2835f4d04b13":10.204081632653061,"a0d62424-8f60-46e7-aa92-4fd3c26f472e":10.204081632653061,"afc06b7c-7fb3-4f88-942b-3076ed77920e":4.081632653061225,"b2ccb628-0c27-48cf-8b5e-291ab25b9117":2.0408163265306123,"b7c9f36d-9c92-4a6d-a3d8-3d81d5c839de":0,"ba0c3ecd-ee31-400a-9125-b1df96a998a6":0,"bd9d3ea6-7749-4f91-bee0-1a953d6d1eb9":2.0408163265306123,"c4ebd69b-bb41-4715-bed3-9ea35e246db0":0,"cabe73d6-d410-47fc-8604-02ec6d37b57c":4.081632653061225,"d844e86f-758a-4c98-b896-1a972a90df97":4.081632653061225,"dfc9f1b0-a952-42e2-bc5e-c5d78c053d2d":6.122448979591836,"e4ae164f-53b7-4a17-a850-bcd5ed2308e0":0,"e9b312ab-fead-4b3f-a5a6-bf19e6b50fab":2.0408163265306123,"f699578c-c859-4e95-9e8c-5a56629a3a09":10.204081632653061,"f8ece2c5-c8b1-4a1e-8528-c09357ec23a4":2.0408163265306123,"fdc216a2-018d-467f-b463-5c051c352111":4.081632653061225},"keyword":{"05e77df0-5ecd-435f-943d-9a5be09e969d":10.965873015873015,"05fb3436-276f-43ca-979b-0a3323240c19":7.8738095238095225,"0f1d0353-2c63-49e9-b29c-4d258cf2a445":11.887830687830688,"10f58ff9-c14e-4bf5-9c44-0a3f14626d3f":9.717063492063494,"2088d2fd-d0ed-477f-b350-5d342624e91e":12.486772486772487,"23dd7fc0-1ebd-43ce-ab3e-43896512c209":11.874603174603175,"282f60bc-e000-420c-b8f7-6d52d645e2b9":11.692063492063493,"28f9f004-7356-4bb4-85e1-275330adeb32":0,"30e4f067-742f-4ad5-b8b0-66d3e8b6303f":9.147222222222222,"32b7988a-f873-44c9-bacb-0d660fe12f01":10.726984126984128,"35f43b14-7174-4eb7-ab99-ce32d08af1a4":11.564285714285717,"3657876a-6f24-47e3-bbba-62e4b3f7ab05":12.169047619047618,"38f54b84-5272-43df-8cde-a3e755b17dee":0,"3939cb96-d8c8-4ec4-8102-bbce2976aeee":9.544444444444444,"436c164e-783e-46c1-a03c-4c7473c8c2df":12.062976190476194,"47cc806c-a905-4355-9bfa-d1a49bf7034b":0,"4ac80067-bbea-4eaf-8b7a-89c97db7ecfe":0,"4ce4d734-c29c-4097-9ca9-314feaccc642":11.153571428571428,"553db688-bb98-4ed0-a2a4-42f1e5678559":8.029761904761905,"55a6413a-4a9c-4e8d-957b-8c1a4e5d5f0b":0,"653c2aa8-cf50-451c-8877-f397ffd07fb5":0,"6b527e7d-50c4-42f5-b3d2-b688d23b8138":10.317460317460316,"73574f5f-bf4f-44fb-b13f-d5eaa8c96619":12.825396825396828,"776f8406-6b10-4397-a1b6-5c8b9b0e1927":12.069576719576718,"81074e3c-5e19-4dd5-9b64-52e97111b919":11.672771672771676,"84dc5aaa-7b2c-4f15-97f4-aa867b4328e2":8.431349206349205,"869b266e-e607-4f60-92d8-d8726d0c97da":0,"8828d2f5-0b50-4715-863d-66c787fc40e0":9.746904761904762,"97612810-668b-4ed2-87d8-38eada1f6377":11.295634920634923,"988d1185-0dd2-4da9-9f47-2be897e90836":12.65793650793651,"9b531247-bb38-4d26-94e8-dab8c453e3ca":10.82531746031746,"9e063b41-0ada-4db8-8846-6e5153a0de55":0,"9e52b6a5-e70c-437f-a30d-8d544132c939":12.997222222222222,"9eafc226-1312-41de-a492-2835f4d04b13":11.801190476190477,"a0d62424-8f60-46e7-aa92-4fd3c26f472e":10.301587301587304,"afc06b7c-7fb3-4f88-942b-3076ed77920e":10.090873015873019,"b2ccb628-0c27-48cf-8b5e-291ab25b9117":10.028121693121694,"b7c9f36d-9c92-4a6d-a3d8-3d81d5c839de":0,"ba0c3ecd-ee31-400a-9125-b1df96a998a6":6.8162698412698415,"bd9d3ea6-7749-4f91-bee0-1a953d6d1eb9":9.684126984126985,"c4ebd69b-bb41-4715-bed3-9ea35e246db0":11.245793650793653,"cabe73d6-d410-47fc-8604-02ec6d37b57c":6.840873015873016,"d844e86f-758a-4c98-b896-1a972a90df97":5.8011904761904765,"dfc9f1b0-a952-42e2-bc5e-c5d78c053d2d":9.038492063492063,"e4ae164f-53b7-4a17-a850-bcd5ed2308e0":11.616031746031746,"e9b312ab-fead-4b3f-a5a6-bf19e6b50fab":10.768650793650796,"f699578c-c859-4e95-9e8c-5a56629a3a09":12.3,"f8ece2c5-c8b1-4a1e-8528-c09357ec23a4":0,"fdc216a2-018d-467f-b463-5c051c352111":12.572222222222223},"topic":["sensor","network","explor","commun","wireless"],"groups":[{"authors":["Eugene Shih","SeongHwan Cho","Nathan Ickes","Rex Min","Amit Sinha","Alice Wang","Anantha P. Chandrakasan"],"references":["0b9c4010-5c06-4bd0-bbdb-b4b9b1319937","0f1d0353-2c63-49e9-b29c-4d258cf2a445","1081ae4c-2a85-4b47-a903-b5518ee62334","23dd7fc0-1ebd-43ce-ab3e-43896512c209","28f9f004-7356-4bb4-85e1-275330adeb32","38f54b84-5272-43df-8cde-a3e755b17dee","3939cb96-d8c8-4ec4-8102-bbce2976aeee","4934742a-77f3-41c6-a7da-99aea0eecfb3","4ac80067-bbea-4eaf-8b7a-89c97db7ecfe","776f8406-6b10-4397-a1b6-5c8b9b0e1927","869b266e-e607-4f60-92d8-d8726d0c97da","90b80d6a-d4e1-445a-a42e-cf37ccc650b7","9e063b41-0ada-4db8-8846-6e5153a0de55","afc06b7c-7fb3-4f88-942b-3076ed77920e","ba0c3ecd-ee31-400a-9125-b1df96a998a6","bd9d3ea6-7749-4f91-bee0-1a953d6d1eb9","c4ebd69b-bb41-4715-bed3-9ea35e246db0","d837e24c-026d-4dcd-91b7-21e7364d863d","d844e86f-758a-4c98-b896-1a972a90df97","e4b25d27-0214-4921-a88d-b2c8b37d3515","ee1062a6-21fd-4ce8-9dde-60f37a92a26c"],"_id":"6b527e7d-50c4-42f5-b3d2-b688d23b8138","abstract":"The potential for collaborative, robust networks of microsensors has attracted a great deal of research attention. For the most part, this is due to the compelling applications that will be enabled once wireless microsensor networks are in place; location-sensing, environmental sensing, medical monitoring and similar applications are all gaining interest. However, wireless microsensor networks pose numerous design challenges. For applications requiring long-term, robust sensing, such as military reconnaissance, one important challenge is to design sensor networks that have long system lifetimes. This challenge is especially difficult due to the energy-constrained nature of the devices. In order to design networks that have extremely long lifetimes, we propose a physical layer driven approach to designing protocols and algorithms. We first present a hardware model for our wireless sensor node and then introduce the design of physical layer aware protocols, algorithms, and applications that minimize energy consumption of the system. Our approach prescribes methods that can be used at all levels of the hierarchy to take advantage of the underlying hardware. We also show how to reduce energy consumption of non-ideal hardware through physical layer aware algorithms and protocols.","title":"Physical layer driven protocol and algorithm design for energy-efficient wireless sensor networks","venue":"acm ieee international conference on mobile computing and networking","year":2001,"__v":0,"citationCount":378}],"offsprings":["b857298c-92c9-4f05-a704-3b9fc6be06e3"]},"f8a9df79-9be7-4333-a71c-327040f67fcd":{"authors":["Paramvir Bahl","Venkata N. Padmanabhan"],"references":[],"_id":"f8a9df79-9be7-4333-a71c-327040f67fcd","abstract":"The proliferation of mobile computing devices and local-area wireless networks has fostered a growing interest in location-aware systems and services. In this paper we present RADAR, a radio-frequency (RF)-based system for locating and tracking users inside buildings. RADAR operates by recording and processing signal strength information at multiple base stations positioned to provide overlapping coverage in the area of interest. It combines empirical measurements with signal propagation modeling to determine user location and thereby enable location-aware services and applications. We present experimental results that demonstrate the ability of RADAR to estimate user location with a high degree of accuracy.","title":"RADAR: an in-building RF-based user location and tracking system","venue":"international conference on computer communications","year":2000,"__v":0,"citationCount":3097,"parents":{"0dfae840-8097-499f-969a-620bcd169f91":0,"790f7fbe-a259-4472-9a61-32985370c53d":0,"815396f0-0de6-4784-9014-30467e295cdb":0,"8246c21e-ac98-4860-a32e-e596c5ccb971":0,"c5a8a54f-0040-4aa4-9044-00e30dc64951":0,"fd51d78a-e2f5-46b6-b041-4dae9aebdc76":0},"keyword":{"0dfae840-8097-499f-969a-620bcd169f91":9.26984126984127,"790f7fbe-a259-4472-9a61-32985370c53d":10.294444444444444,"815396f0-0de6-4784-9014-30467e295cdb":0,"8246c21e-ac98-4860-a32e-e596c5ccb971":8.587301587301589,"c5a8a54f-0040-4aa4-9044-00e30dc64951":8.423809523809524,"fd51d78a-e2f5-46b6-b041-4dae9aebdc76":11.147222222222222},"topic":["user","radar","locat","system","signal"],"offsprings":["3939cb96-d8c8-4ec4-8102-bbce2976aeee"]},"feddae21-3c05-4743-80fa-b8e101f1b93f":{"authors":["Gediminas Adomavicius","Alexander Tuzhilin"],"references":["0ea745c7-58b2-48e8-9115-42e9b0d20f2a","312e54ca-e7e9-4129-99f4-36f3aeff827e"],"_id":"feddae21-3c05-4743-80fa-b8e101f1b93f","abstract":"This paper presents an overview of the field of recommender systems and describes the current generation of recommendation methods that are usually classified into the following three main categories: content-based, collaborative, and hybrid recommendation approaches. This paper also describes various limitations of current recommendation methods and discusses possible extensions that can improve recommendation capabilities and make recommender systems applicable to an even broader range of applications. These extensions include, among others, an improvement of understanding of users and items, incorporation of the contextual information into the recommendation process, support for multicriteria ratings, and a provision of more flexible and less intrusive types of recommendations.","title":"Toward the next generation of recommender systems: a survey of the state-of-the-art and possible extensions","venue":"IEEE Transactions on Knowledge and Data Engineering","year":2005,"__v":0,"citationCount":3038,"parents":{"05234ed3-29a1-4a96-970c-44ebdf1a2fe6":15.492957746478872,"05f5fba9-e7ca-4c46-be79-df57944a8b41":0,"06f4b95e-9242-4408-b9cc-114357d88fe7":5.633802816901409,"09880ee2-8770-4f53-96d0-90eaa4d3133d":0,"0ad38f3e-8131-4287-9e62-2b2ae77f47f7":0,"0e00f9b2-a002-465a-baa8-e167aa0fbeac":2.8169014084507045,"0ea745c7-58b2-48e8-9115-42e9b0d20f2a":25.352112676056336,"1406f119-82cd-4cbb-9231-f885212a724e":4.225352112676056,"1a9d8939-2919-4d50-8f2b-12b4aeb25aa1":5.633802816901409,"1b7418af-1aba-4090-bad4-0dd0e900f5aa":1.4084507042253522,"238bfbbc-91cc-407b-8f37-b7942b09410a":2.8169014084507045,"23f66d97-4abf-479f-8af5-ec833d850a24":0,"290e0375-d2ad-4bec-a94f-f05e1580125b":5.633802816901409,"2d741908-7f21-4984-89b3-53e34ebbd3e7":4.225352112676056,"2e34c4e7-7c2a-4172-af48-f32834865655":5.633802816901409,"312e54ca-e7e9-4129-99f4-36f3aeff827e":2.8169014084507045,"3730ca24-81f0-456e-a7f3-5c0987e05147":0,"38332469-d318-4976-a49e-9613695cac08":38.028169014084504,"3cf667e4-b285-48e6-9816-085ce9c56f8c":12.676056338028168,"44e91111-b413-4143-85a9-81872a97fa9d":5.633802816901409,"47197c38-6c68-4fb5-9dd3-5b083262bd22":0,"48632bf4-3e9f-4e98-b8f6-c08aaf7f2b58":5.633802816901409,"48a1dbbd-b496-4b37-b3ba-db144c654d23":12.676056338028168,"57bd2d58-8b2c-4783-9bd0-445de23e5e76":4.225352112676056,"5d134b15-3e3f-402e-a4cd-d5022aef1305":1.4084507042253522,"5ee83a3b-d5f8-4532-97dd-c0579bed0d17":5.633802816901409,"60c814e2-c4d1-47d7-9a5a-68f4141505ae":2.8169014084507045,"67fa583a-da81-4338-8349-e9a7f19f6fe2":12.676056338028168,"694f475e-f6c4-4105-b645-84c7d592db30":14.084507042253522,"6a6d14f3-83d4-4df4-bd27-94455c216c4f":11.267605633802818,"6acfaeb4-5d94-4245-9a0a-dd0e8de54c6c":11.267605633802818,"6b700ee7-1b54-4aa7-8cdb-d6a9a08592aa":0,"7b960c31-7b3c-456f-9352-80380e2be085":0,"7f2e92f7-6a67-491c-9546-cfd9b8a3b348":0,"7f2f7b7d-3e6c-4196-9056-a943b3e96c2f":8.450704225352112,"812c314c-9742-46fa-b1e8-5c7d640f1322":1.4084507042253522,"822235e6-6abe-442b-b761-b51795df418a":7.042253521126761,"8735c7ea-f5c6-4310-b250-bc0d1bf5e834":1.4084507042253522,"8afd1b1d-7e34-43ac-8f93-654be568e61c":15.492957746478872,"8c3149bc-5c9e-44bc-a58a-1ce8d92208d5":0,"8ca1fc15-957a-4b80-9988-3c8cae85a4f6":7.042253521126761,"8de6e50f-dde3-40ad-99fa-83fcbce40b76":7.042253521126761,"92bd56e3-08b9-4c30-8539-5a8b8c042933":19.718309859154928,"962a941e-d2b0-4ba7-8698-0257b7ebe695":9.859154929577464,"98b23182-8f51-428a-a4af-a91d280471ca":16.901408450704224,"9a7e4c43-690d-432d-b9a5-b519bf377646":1.4084507042253522,"9ad74e9b-de27-4f5a-8108-08043eb6d544":0,"9ae0142d-b12f-42b1-ac48-d655fdec233f":5.633802816901409,"9b602954-f960-46fe-87ae-41f06c486efc":19.718309859154928,"a214c450-50cc-4210-acd9-480a2a7e8eb4":0,"a3d4a2d1-d9dd-4f4d-9d8e-bcc056135d21":0,"a69adad1-7efb-4204-93de-97aaeed2424a":14.084507042253522,"b3321db8-4600-4969-ae23-336c36669dae":14.084507042253522,"b9009e04-394c-4bcb-ab04-adc4365e0fe1":0,"b919b53b-591a-4046-bda3-fe16340939d5":2.8169014084507045,"bc288dd8-9104-456a-9edf-f0526b0f8633":5.633802816901409,"c12af7c5-ea9e-41b8-8d0a-eab301f8d270":0,"c69ef004-087e-486c-97c9-9b4587d0b10a":2.8169014084507045,"c7ce0fc7-4d38-4355-aa19-ab35527d2519":4.225352112676056,"cb512b89-7b86-4565-92c7-81599f1b1ca2":2.8169014084507045,"d1fcfcd1-faa8-4ba3-a0d2-50fb53a9f47f":19.718309859154928,"d3c5fc62-2f5b-4ab2-a321-564ef9232643":0,"d3ec5b39-7147-440d-82b0-4c4d05e671c9":8.450704225352112,"d4e20fdf-beec-410c-a9b4-1ded047b320b":9.859154929577464,"e09ac4da-c7fb-4a9d-9c77-cc41c6f74621":4.225352112676056,"e5e1e41c-774c-4bb4-a087-bcd02fd37b0f":4.225352112676056,"ed4c0d5d-5152-4915-b9bd-d0bd25f82674":14.084507042253522,"f782a72e-eeca-4757-ace9-670012f961a8":22.535211267605636,"f9571f5e-7bf7-427f-a512-b6979338ff31":4.225352112676056,"fada1cc8-d343-45fb-9040-22795f1ca833":0,"fe7f2770-ddca-4716-a7d9-545e68f691fe":8.450704225352112},"keyword":{"05234ed3-29a1-4a96-970c-44ebdf1a2fe6":10.821440596440597,"05f5fba9-e7ca-4c46-be79-df57944a8b41":0,"06f4b95e-9242-4408-b9cc-114357d88fe7":12.96111111111111,"09880ee2-8770-4f53-96d0-90eaa4d3133d":0,"0ad38f3e-8131-4287-9e62-2b2ae77f47f7":8.663386243386244,"0e00f9b2-a002-465a-baa8-e167aa0fbeac":9.89153439153439,"0ea745c7-58b2-48e8-9115-42e9b0d20f2a":9.272486772486772,"1406f119-82cd-4cbb-9231-f885212a724e":0,"1a9d8939-2919-4d50-8f2b-12b4aeb25aa1":12.96111111111111,"1b7418af-1aba-4090-bad4-0dd0e900f5aa":10.481944444444443,"238bfbbc-91cc-407b-8f37-b7942b09410a":11.608703703703702,"23f66d97-4abf-479f-8af5-ec833d850a24":0,"290e0375-d2ad-4bec-a94f-f05e1580125b":10.501719576719577,"2d741908-7f21-4984-89b3-53e34ebbd3e7":10.948544973544971,"2e34c4e7-7c2a-4172-af48-f32834865655":13.323756613756615,"312e54ca-e7e9-4129-99f4-36f3aeff827e":12.194074074074074,"3730ca24-81f0-456e-a7f3-5c0987e05147":0,"38332469-d318-4976-a49e-9613695cac08":12.242857142857144,"3cf667e4-b285-48e6-9816-085ce9c56f8c":12.884259259259258,"44e91111-b413-4143-85a9-81872a97fa9d":0,"47197c38-6c68-4fb5-9dd3-5b083262bd22":0,"48632bf4-3e9f-4e98-b8f6-c08aaf7f2b58":12.980555555555553,"48a1dbbd-b496-4b37-b3ba-db144c654d23":12.71296296296296,"57bd2d58-8b2c-4783-9bd0-445de23e5e76":0,"5d134b15-3e3f-402e-a4cd-d5022aef1305":12.430925925925926,"5ee83a3b-d5f8-4532-97dd-c0579bed0d17":12.309259259259257,"60c814e2-c4d1-47d7-9a5a-68f4141505ae":0,"67fa583a-da81-4338-8349-e9a7f19f6fe2":11.374074074074072,"694f475e-f6c4-4105-b645-84c7d592db30":9.31111111111111,"6a6d14f3-83d4-4df4-bd27-94455c216c4f":11.806878306878307,"6acfaeb4-5d94-4245-9a0a-dd0e8de54c6c":11.856969696969697,"6b700ee7-1b54-4aa7-8cdb-d6a9a08592aa":12.046613756613757,"7b960c31-7b3c-456f-9352-80380e2be085":10.117037037037036,"7f2e92f7-6a67-491c-9546-cfd9b8a3b348":0,"7f2f7b7d-3e6c-4196-9056-a943b3e96c2f":11.734444444444444,"812c314c-9742-46fa-b1e8-5c7d640f1322":0,"822235e6-6abe-442b-b761-b51795df418a":12.373915343915344,"8735c7ea-f5c6-4310-b250-bc0d1bf5e834":10.302777777777777,"8afd1b1d-7e34-43ac-8f93-654be568e61c":12.475026455026454,"8c3149bc-5c9e-44bc-a58a-1ce8d92208d5":0,"8ca1fc15-957a-4b80-9988-3c8cae85a4f6":13.072962962962958,"8de6e50f-dde3-40ad-99fa-83fcbce40b76":13.036164021164021,"92bd56e3-08b9-4c30-8539-5a8b8c042933":10.311228956228957,"962a941e-d2b0-4ba7-8698-0257b7ebe695":12.325873015873015,"98b23182-8f51-428a-a4af-a91d280471ca":0,"9a7e4c43-690d-432d-b9a5-b519bf377646":12.419285714285714,"9ad74e9b-de27-4f5a-8108-08043eb6d544":11.330555555555552,"9ae0142d-b12f-42b1-ac48-d655fdec233f":0,"9b602954-f960-46fe-87ae-41f06c486efc":13.177248677248679,"a214c450-50cc-4210-acd9-480a2a7e8eb4":9.120185185185186,"a3d4a2d1-d9dd-4f4d-9d8e-bcc056135d21":8.914444444444445,"a69adad1-7efb-4204-93de-97aaeed2424a":11.222883597883598,"b3321db8-4600-4969-ae23-336c36669dae":11.386587301587301,"b9009e04-394c-4bcb-ab04-adc4365e0fe1":10.811111111111112,"b919b53b-591a-4046-bda3-fe16340939d5":11.668148148148147,"bc288dd8-9104-456a-9edf-f0526b0f8633":10.74259259259259,"c12af7c5-ea9e-41b8-8d0a-eab301f8d270":0,"c69ef004-087e-486c-97c9-9b4587d0b10a":12.159629629629631,"c7ce0fc7-4d38-4355-aa19-ab35527d2519":0,"cb512b89-7b86-4565-92c7-81599f1b1ca2":10.770793650793651,"d1fcfcd1-faa8-4ba3-a0d2-50fb53a9f47f":13.405132275132274,"d3c5fc62-2f5b-4ab2-a321-564ef9232643":8.554920634920634,"d3ec5b39-7147-440d-82b0-4c4d05e671c9":13.471296296296295,"d4e20fdf-beec-410c-a9b4-1ded047b320b":0,"e09ac4da-c7fb-4a9d-9c77-cc41c6f74621":10.761296296296296,"e5e1e41c-774c-4bb4-a087-bcd02fd37b0f":0,"ed4c0d5d-5152-4915-b9bd-d0bd25f82674":0,"f782a72e-eeca-4757-ace9-670012f961a8":10.977777777777776,"f9571f5e-7bf7-427f-a512-b6979338ff31":12.277777777777775,"fada1cc8-d343-45fb-9040-22795f1ca833":12.176969696969696,"fe7f2770-ddca-4716-a7d9-545e68f691fe":11.575396825396824},"topic":["recommend","system","paper","method","improv"],"groups":[{"authors":["Mukund Deshpande","George Karypis"],"references":["05f5fba9-e7ca-4c46-be79-df57944a8b41","11c3cd75-00cf-45ef-9efc-ad503b531e48","1406f119-82cd-4cbb-9231-f885212a724e","312e54ca-e7e9-4129-99f4-36f3aeff827e","33d6dabd-c086-4a6e-939a-c322b6ada724","34b7e270-80d7-46d5-a6f1-e50087a8d045","3f8e14d5-4655-4c61-8636-99eb5cc99411","41350086-4320-45bb-a93c-be68975bfff5","41e7c40d-5250-47e3-bb57-720bc30cbdca","44e91111-b413-4143-85a9-81872a97fa9d","5ee83a3b-d5f8-4532-97dd-c0579bed0d17","60c814e2-c4d1-47d7-9a5a-68f4141505ae","694f475e-f6c4-4105-b645-84c7d592db30","6e425bce-a497-4c63-9eb0-b038e660a54f","812c314c-9742-46fa-b1e8-5c7d640f1322","929abc46-4b62-459b-a972-caa1d09e0fcc","93fbc138-713f-402a-a554-89f111ddfcd8","98b23182-8f51-428a-a4af-a91d280471ca","9ae0142d-b12f-42b1-ac48-d655fdec233f","c4710c73-497d-44f0-ae10-64613eca18d4","c69ef004-087e-486c-97c9-9b4587d0b10a","c7ce0fc7-4d38-4355-aa19-ab35527d2519","cbc55d1f-5b03-4102-a37d-2608e100ff47","e3a14094-d98f-425a-a764-ca44f297489c","e5e1e41c-774c-4bb4-a087-bcd02fd37b0f","ecd6a845-8439-49b0-abe8-f71fff81da23","ed4c0d5d-5152-4915-b9bd-d0bd25f82674"],"_id":"9b602954-f960-46fe-87ae-41f06c486efc","abstract":"The explosive growth of the world-wide-web and the emergence of e-commerce has led to the development of  recommender systems ---a personalized information filtering technology used to identify a set of items that will be of interest to a certain user. User-based collaborative filtering is the most successful technology for building recommender systems to date and is extensively used in many commercial recommender systems. Unfortunately, the computational complexity of these methods grows linearly with the number of customers, which in typical commercial applications can be several millions. To address these scalability concerns model-based recommendation techniques have been developed. These techniques analyze the user--item matrix to discover relations between the different items and use these relations to compute the list of recommendations.In this article, we present one such class of model-based recommendation algorithms that first determines the similarities between the various items and then uses them to identify the set of items to be recommended. The key steps in this class of algorithms are (i) the method used to compute the similarity between the items, and (ii) the method used to combine these similarities in order to compute the similarity between a  basket  of items and a candidate recommender item. Our experimental evaluation on eight real datasets shows that these  item-based  algorithms are up to two orders of magnitude faster than the traditional user-neighborhood based recommender systems and provide recommendations with comparable or better quality.","title":"Item-based top- N recommendation algorithms","venue":"ACM Transactions on Information Systems","year":2004,"__v":0,"citationCount":723},{"authors":["Andrew I. Schein","Alexandrin Popescul","Lyle H. Ungar","David M. Pennock"],"references":["05234ed3-29a1-4a96-970c-44ebdf1a2fe6","28903e7b-aa3b-4840-b634-916029ed6c77","290e0375-d2ad-4bec-a94f-f05e1580125b","30119eca-9d54-4d87-88b0-04cadda25ea0","312e54ca-e7e9-4129-99f4-36f3aeff827e","3f8e14d5-4655-4c61-8636-99eb5cc99411","44e91111-b413-4143-85a9-81872a97fa9d","5ee83a3b-d5f8-4532-97dd-c0579bed0d17","60c814e2-c4d1-47d7-9a5a-68f4141505ae","694f475e-f6c4-4105-b645-84c7d592db30","6a6d14f3-83d4-4df4-bd27-94455c216c4f","812c314c-9742-46fa-b1e8-5c7d640f1322","8c3149bc-5c9e-44bc-a58a-1ce8d92208d5","8fb19592-ccce-4deb-a158-45dd7bba6d5a","8fda5d41-ef91-4e72-848f-7da042d1f9aa","98b23182-8f51-428a-a4af-a91d280471ca","b99db203-5c26-4182-bdc1-df188456f9f9","c69ef004-087e-486c-97c9-9b4587d0b10a","e5e1e41c-774c-4bb4-a087-bcd02fd37b0f","e75d8e62-a86d-4241-953f-1b315005d920","ed4c0d5d-5152-4915-b9bd-d0bd25f82674"],"_id":"d1fcfcd1-faa8-4ba3-a0d2-50fb53a9f47f","abstract":"We have developed a method for recommending items that combines content and collaborative data under a single probabilistic framework. We benchmark our algorithm against a naive Bayes classifier on the   cold-start  problem, where we wish to recommend items that no one in the community has yet rated. We systematically explore three testing methodologies using a publicly available data set, and explain how these methods apply to specific real-world applications. We advocate heuristic recommenders when benchmarking to give competent baseline performance. We introduce a new performance metric, the CROC curve, and demonstrate empirically that the various components of our testing strategy combine to obtain deeper understanding of the performance characteristics of recommender systems. Though the emphasis of our testing is on  cold-start  recommending, our methods for recommending and evaluation are general.","title":"Methods and metrics for cold-start recommendations","venue":"international acm sigir conference on research and development in information retrieval","year":2002,"__v":0,"citationCount":538},{"authors":["Jonathan L. Herlocker","Joseph A. Konstan","Loren G. Terveen","John Riedl"],"references":["05f5fba9-e7ca-4c46-be79-df57944a8b41","126f597c-4efc-49f4-9758-086b767f9fe3","1406f119-82cd-4cbb-9231-f885212a724e","2ac8fe14-27ce-4e39-b256-08fd95887484","30119eca-9d54-4d87-88b0-04cadda25ea0","312e54ca-e7e9-4129-99f4-36f3aeff827e","3f8e14d5-4655-4c61-8636-99eb5cc99411","44e91111-b413-4143-85a9-81872a97fa9d","454b7a62-ff47-4263-822b-2a1a938b489f","464c5e0a-2de4-4aa6-a0f6-56cb5ef6740d","48632bf4-3e9f-4e98-b8f6-c08aaf7f2b58","48a1dbbd-b496-4b37-b3ba-db144c654d23","4a2b8b20-c8bc-4e0a-b7db-9dec439951d5","5ee83a3b-d5f8-4532-97dd-c0579bed0d17","60c814e2-c4d1-47d7-9a5a-68f4141505ae","694f475e-f6c4-4105-b645-84c7d592db30","749790a4-8bdf-4ad8-8ae9-9e9e8f57a898","78113af6-9abc-46e5-bb78-80049f5770b5","7d15ffdf-ec35-4498-b794-c186147b39eb","7f2f7b7d-3e6c-4196-9056-a943b3e96c2f","812c314c-9742-46fa-b1e8-5c7d640f1322","822235e6-6abe-442b-b761-b51795df418a","93fbc138-713f-402a-a554-89f111ddfcd8","9863baf6-d69f-495a-8d5a-71442adea84e","98b23182-8f51-428a-a4af-a91d280471ca","9ae0142d-b12f-42b1-ac48-d655fdec233f","a04df34d-8c30-4d8a-89fc-781660703e95","bb237c57-3c58-492f-af1e-3e19a35115a6","c69ef004-087e-486c-97c9-9b4587d0b10a","ca25acbc-7ec2-453c-911f-077a06d76ebf","cff1b7c3-dc60-4ac0-a016-0e4b5070310a","d1fcfcd1-faa8-4ba3-a0d2-50fb53a9f47f","d69f9422-3d82-4095-aa7c-b7f3513778ba","daca38ab-f534-42d6-956c-130a321cd40d","df338255-a225-4c0e-931d-4a011d141184","e5e1e41c-774c-4bb4-a087-bcd02fd37b0f","e9f47fc0-2e5e-4d5f-a7a9-3650e65a1722","ed4c0d5d-5152-4915-b9bd-d0bd25f82674","f454a778-621e-4e96-8501-7d72fb0d6103","f68eb690-34df-4271-acc4-802cb273de83"],"_id":"0ea745c7-58b2-48e8-9115-42e9b0d20f2a","abstract":"Recommender systems have been evaluated in many, often incomparable, ways. In this article, we review the key decisions in evaluating collaborative filtering recommender systems: the user tasks being evaluated, the types of analysis and datasets being used, the ways in which prediction quality is measured, the evaluation of prediction attributes other than quality, and the user-based evaluation of the system as a whole. In addition to reviewing the evaluation strategies used by prior researchers, we present empirical results from the analysis of various accuracy metrics on one content domain where all the tested metrics collapsed roughly into three equivalence classes. Metrics within each equivalency class were strongly correlated, while metrics from different equivalency classes were uncorrelated.","title":"Evaluating collaborative filtering recommender systems","venue":"ACM Transactions on Information Systems","year":2004,"__v":0,"citationCount":1987},{"authors":["Gediminas Adomavicius","Ramesh Sankaranarayanan","Shahana Sen","Alexander Tuzhilin"],"references":["1406f119-82cd-4cbb-9231-f885212a724e","15fa2620-5dc8-4d32-97a7-294afe3c61c3","1b7418af-1aba-4090-bad4-0dd0e900f5aa","1f6caa35-3d3f-481f-a820-a5d6e6b130d1","312e54ca-e7e9-4129-99f4-36f3aeff827e","3730ca24-81f0-456e-a7f3-5c0987e05147","44e91111-b413-4143-85a9-81872a97fa9d","47d1e055-7dc7-44ee-8a02-c33aaf7e23a3","48a1dbbd-b496-4b37-b3ba-db144c654d23","57bd2d58-8b2c-4783-9bd0-445de23e5e76","5ee83a3b-d5f8-4532-97dd-c0579bed0d17","60c814e2-c4d1-47d7-9a5a-68f4141505ae","67fa583a-da81-4338-8349-e9a7f19f6fe2","6a6d14f3-83d4-4df4-bd27-94455c216c4f","6c2fee35-a596-416a-bd8a-a7966324f71e","6c871065-76b8-44f3-97d5-ac3bce951421","7b960c31-7b3c-456f-9352-80380e2be085","812c314c-9742-46fa-b1e8-5c7d640f1322","8a8e532b-9b51-4ef3-b2ec-69b05191f758","8afd1b1d-7e34-43ac-8f93-654be568e61c","8c3149bc-5c9e-44bc-a58a-1ce8d92208d5","8ca1fc15-957a-4b80-9988-3c8cae85a4f6","9751ec02-fb0a-4b00-8296-dacb01928335","98b23182-8f51-428a-a4af-a91d280471ca","9ae0142d-b12f-42b1-ac48-d655fdec233f","a214c450-50cc-4210-acd9-480a2a7e8eb4","bc288dd8-9104-456a-9edf-f0526b0f8633","bdf2f8ec-db4e-41b9-996e-4299685b33b0","c69ef004-087e-486c-97c9-9b4587d0b10a","c7ce0fc7-4d38-4355-aa19-ab35527d2519","cb512b89-7b86-4565-92c7-81599f1b1ca2","d3c5fc62-2f5b-4ab2-a321-564ef9232643","e5e1e41c-774c-4bb4-a087-bcd02fd37b0f","ed4c0d5d-5152-4915-b9bd-d0bd25f82674","f1788b85-208f-41aa-a66f-f44220a6a5da","f782a72e-eeca-4757-ace9-670012f961a8"],"_id":"38332469-d318-4976-a49e-9613695cac08","abstract":"The article presents a multidimensional (MD) approach to recommender systems that can provide recommendations based on additional contextual information besides the typical information on users and items used in most of the current recommender systems. This approach supports multiple dimensions, profiling information, and hierarchical aggregation of recommendations. The article also presents a multidimensional rating estimation method capable of selecting two-dimensional segments of ratings pertinent to the recommendation context and applying standard collaborative filtering or other traditional two-dimensional rating estimation techniques to these segments. A comparison of the multidimensional and two-dimensional rating estimation approaches is made, and the tradeoffs between the two are studied. Moreover, the article introduces a combined rating estimation method, which identifies the situations where the MD approach outperforms the standard two-dimensional approach and uses the MD approach in those situations and the standard two-dimensional approach elsewhere. Finally, the article presents a pilot empirical study of the combined approach, using a multidimensional movie recommender system that was developed for implementing this approach and testing its performance.","title":"Incorporating contextual information in recommender systems using a multidimensional approach","venue":"ACM Transactions on Information Systems","year":2005,"__v":0,"citationCount":431},{"authors":["Zan Huang","Hsinchun Chen","Daniel Dajun Zeng"],"references":["04427dfc-6714-4008-98f3-b5507018ead0","1406f119-82cd-4cbb-9231-f885212a724e","1d33c6e4-1baf-4ef3-8068-b626a6ad5a49","28617842-e696-4a7c-8a9c-e4dcf09f3759","2c2dbdbf-d6db-4019-94a4-4084337eb6e0","312e54ca-e7e9-4129-99f4-36f3aeff827e","3f8e14d5-4655-4c61-8636-99eb5cc99411","41350086-4320-45bb-a93c-be68975bfff5","44e91111-b413-4143-85a9-81872a97fa9d","48a1dbbd-b496-4b37-b3ba-db144c654d23","5aa0fb6f-0b06-48df-8cf2-ee180c85c738","5ee83a3b-d5f8-4532-97dd-c0579bed0d17","60c814e2-c4d1-47d7-9a5a-68f4141505ae","60ef3852-fa16-44bf-9434-9909268ba5d8","694f475e-f6c4-4105-b645-84c7d592db30","6e425bce-a497-4c63-9eb0-b038e660a54f","7c4dfd37-fa37-4a43-a3e1-898b98e0b48d","7d15ffdf-ec35-4498-b794-c186147b39eb","812c314c-9742-46fa-b1e8-5c7d640f1322","8aa326d5-2a3d-4c30-8d56-06bb275f079c","8ca1fc15-957a-4b80-9988-3c8cae85a4f6","8f6cafa9-28c3-424e-87bd-c28c8e57a44f","98b23182-8f51-428a-a4af-a91d280471ca","9ae0142d-b12f-42b1-ac48-d655fdec233f","abe38dcd-53ce-48b3-8e3d-4702ddd4e4c0","b3321db8-4600-4969-ae23-336c36669dae","bb471afa-e600-483d-92a5-7a36c9135155","bed2c8c8-1dc3-4631-b8e2-746ba766a9ae","c69ef004-087e-486c-97c9-9b4587d0b10a","c7ce0fc7-4d38-4355-aa19-ab35527d2519","d16cb7ae-ae7c-4b37-8667-93a57b025d5a","d1fcfcd1-faa8-4ba3-a0d2-50fb53a9f47f","dacf855f-a7d2-42bf-89a7-fabe9b003150","e5e1e41c-774c-4bb4-a087-bcd02fd37b0f"],"_id":"f782a72e-eeca-4757-ace9-670012f961a8","abstract":"Recommender systems are being widely applied in many application settings to suggest products, services, and information items to potential consumers. Collaborative filtering, the most successful recommendation approach, makes recommendations based on past transactions and feedback from consumers sharing similar interests. A major problem limiting the usefulness of collaborative filtering is the sparsity problem, which refers to a situation in which transactional or feedback data is sparse and insufficient to identify similarities in consumer interests. In this article, we propose to deal with this sparsity problem by applying an associative retrieval framework and related spreading activation algorithms to explore transitive associations among consumers through their past transactions and feedback. Such transitive associations are a valuable source of information to help infer consumer interests and can be explored to deal with the sparsity problem. To evaluate the effectiveness of our approach, we have conducted an experimental study using a data set from an online bookstore. We experimented with three spreading activation algorithms including a constrained Leaky Capacitor algorithm, a branch-and-bound serial symbolic search algorithm, and a Hopfield net parallel relaxation search algorithm. These algorithms were compared with several collaborative filtering approaches that do not consider the transitive associations: a simple graph search approach, two variations of the user-based approach, and an item-based approach. Our experimental results indicate that spreading activation-based approaches significantly outperformed the other collaborative filtering methods as measured by recommendation precision, recall, the F-measure, and the rank score. We also observed the over-activation effect of the spreading activation approach, that is, incorporating transitive associations with past transactional data that is not sparse may \"dilute\" the data used to infer user preferences and lead to degradation in recommendation performance.","title":"Applying associative retrieval techniques to alleviate the sparsity problem in collaborative filtering","venue":"ACM Transactions on Information Systems","year":2004,"__v":0,"citationCount":249}],"offsprings":["68faab18-b537-4f62-85cf-ddc9ef352362"]},"feff8862-f47d-4591-a7cb-b62d7efc81a2":{"authors":["Chih-Wei Hsu","Chih-Jen Lin"],"references":["50dd56db-151d-4d62-8576-65f0ef6f381b"],"_id":"feff8862-f47d-4591-a7cb-b62d7efc81a2","abstract":"Support vector machines (SVMs) were originally designed for binary classification. How to effectively extend it for multiclass classification is still an ongoing research issue. Several methods have been proposed where typically we construct a multiclass classifier by combining several binary classifiers. Some authors also proposed methods that consider all classes at once. As it is computationally more expensive to solve multiclass problems, comparisons of these methods using large-scale problems have not been seriously conducted. Especially for methods solving multiclass SVM in one step, a much larger optimization problem is required so up to now experiments are limited to small data sets. In this paper we give decomposition implementations for two such \"all-together\" methods. We then compare their performance with three methods based on binary classifications: \"one-against-all,\" \"one-against-one,\" and directed acyclic graph SVM (DAGSVM). Our experiments indicate that the \"one-against-one\" and DAG methods are more suitable for practical use than the other methods. Results also show that for large problems methods by considering all data at once in general need fewer support vectors.","title":"A comparison of methods for multiclass support vector machines","venue":"IEEE Transactions on Neural Networks","year":2002,"__v":0,"citationCount":1836,"parents":{"0ed949f7-7118-45fa-8a4c-63fcf9f4bd8f":11.11111111111111,"1e37aa02-2911-45db-867f-bc2043492c08":11.11111111111111,"2190c590-c037-4170-9a93-a9d0c4468077":0,"50dd56db-151d-4d62-8576-65f0ef6f381b":0,"5ffac6f9-2456-42cf-830c-9049ce37c899":11.11111111111111,"7f03746d-ba06-4b34-828e-683192e9ee42":33.33333333333333,"a5d347a7-9984-45f4-821e-df7356477185":22.22222222222222,"c5d59aca-dd59-4640-a80b-e7e585430b54":11.11111111111111,"f33acc76-f25e-446f-a834-9d898907b326":11.11111111111111},"keyword":{"0ed949f7-7118-45fa-8a4c-63fcf9f4bd8f":9.675555555555555,"1e37aa02-2911-45db-867f-bc2043492c08":10.001746031746032,"2190c590-c037-4170-9a93-a9d0c4468077":0,"50dd56db-151d-4d62-8576-65f0ef6f381b":11.41967032967033,"5ffac6f9-2456-42cf-830c-9049ce37c899":9.726190476190476,"7f03746d-ba06-4b34-828e-683192e9ee42":8.004444444444445,"a5d347a7-9984-45f4-821e-df7356477185":8.162539682539682,"c5d59aca-dd59-4640-a80b-e7e585430b54":8.62952380952381,"f33acc76-f25e-446f-a834-9d898907b326":9.288174603174603},"topic":["method","problem","multiclass","classif","binari"],"groups":[{"authors":["Chih-Wei Hsu","Chih-Jen Lin"],"references":["0ed949f7-7118-45fa-8a4c-63fcf9f4bd8f","1ed12644-d4b8-4ee3-8c55-0a78a831a1dc","2190c590-c037-4170-9a93-a9d0c4468077","33184e74-4574-4856-a969-e497fdc2fec8","402c1d45-5bf6-4f7a-806b-10df639f81c6","4aa6fe33-d146-4e6f-ac35-cbeb43c65866","5ffac6f9-2456-42cf-830c-9049ce37c899","9c01a502-04f3-4adb-9bde-f06253818cb9","a2e5c222-c380-42d7-8846-cbc232f46a69"],"_id":"7f03746d-ba06-4b34-828e-683192e9ee42","abstract":"The decomposition method is currently one of the major methods for solving support vector machines. An important issue of this method is the selection of working sets. In this paper through the design of decomposition methods for bound-constrained SVM formulations we demonstrate that the working set selection is not a trivial task. Then from the experimental analysis we propose a simple selection of the working set which leads to faster convergences for difficult cases. Numerical experiments on different types of problems are conducted to demonstrate the viability of the proposed method.","title":"A Simple Decomposition Method for Support Vector Machines","venue":"Machine Learning","year":2002,"__v":0,"citationCount":108}],"offsprings":["c1b6b493-01ef-420f-be44-7bacfe34e846","33abc1fc-50ea-4837-a4a0-65c1d4c0e0b7"]},"ff3e8103-1378-408b-adc2-c42b1c25b065":{"authors":["Heiko Schwarz","Detlev Marpe","Thomas Wiegand"],"references":["237a87ca-d393-4173-a89d-fd2c5c1f3d37","94e25efe-d596-4767-99f0-d87f8c950f0c"],"_id":"ff3e8103-1378-408b-adc2-c42b1c25b065","abstract":"With the introduction of the H.264/AVC video coding standard, significant improvements have recently been demonstrated in video compression capability. The Joint Video Team of the ITU-T VCEG and the ISO/IEC MPEG has now also standardized a Scalable Video Coding (SVC) extension of the H.264/AVC standard. SVC enables the transmission and decoding of partial bit streams to provide video services with lower temporal or spatial resolutions or reduced fidelity while retaining a reconstruction quality that is high relative to the rate of the partial bit streams. Hence, SVC provides functionalities such as graceful degradation in lossy transmission environments as well as bit rate, format, and power adaptation. These functionalities provide enhancements to transmission and storage applications. SVC has achieved significant improvements in coding efficiency with an increased degree of supported scalability relative to the scalable profiles of prior video coding standards. This paper provides an overview of the basic concepts for extending H.264/AVC towards SVC. Moreover, the basic tools for providing temporal, spatial, and quality scalability are described in detail and experimentally analyzed regarding their efficiency and complexity.","title":"Overview of the Scalable Video Coding Extension of the H.264/AVC Standard","venue":"IEEE Transactions on Circuits and Systems for Video Technology","year":2007,"__v":0,"citationCount":1693,"parents":{"06247cad-380a-4909-953e-7b9c834c69bb":0,"1ea5125c-2c09-47c7-ba82-913bda694a3f":0,"237a87ca-d393-4173-a89d-fd2c5c1f3d37":8.695652173913043,"2c276c75-639e-41b9-a3c4-5347e2fe9804":4.3478260869565215,"2fea9a72-0171-4635-be8b-a189a52be390":0,"401e7bf8-8cce-417e-81ce-48fc7578e087":0,"4f4564bd-e868-4f7f-88bb-46fb813bf595":8.695652173913043,"57f1e331-791e-4666-b886-1c2f89c3aa29":4.3478260869565215,"5be16126-0bbc-401a-81ea-aabe5da46ad9":0,"67b2b3cd-7c5d-4b5f-b301-d6e1bd857ec1":4.3478260869565215,"752ff6af-824b-41ea-9712-c8185f5490d9":17.391304347826086,"756de6c7-3d2d-44fc-a722-7d16d54cb35f":21.73913043478261,"7ed7b5da-c666-4dc0-8243-a1d3ce0456d7":13.043478260869565,"94e25efe-d596-4767-99f0-d87f8c950f0c":13.043478260869565,"ab9331ee-c31d-48eb-a55e-1f03dfdce30c":21.73913043478261,"b1504997-e07a-4d68-8215-38e34e4baf70":0,"b28cb69b-2d4e-45ad-a484-1e550599a65b":21.73913043478261,"c09f2e4d-0fef-4e5d-ab5f-e56a55a5202c":8.695652173913043,"d02a4255-dff3-4cdf-ba69-41bd09a48ead":21.73913043478261,"d324af1d-63cb-4e2d-ae98-38fffb28ea16":0,"d5327892-4102-4cd1-b8e2-87e3d0a3d279":0,"e415a34f-803c-413e-9d1c-eb0ad68aa0ab":13.043478260869565,"f38e78a5-878d-499d-86c8-0a02ba099f22":21.73913043478261},"keyword":{"06247cad-380a-4909-953e-7b9c834c69bb":11.86130952380952,"1ea5125c-2c09-47c7-ba82-913bda694a3f":6.756746031746032,"237a87ca-d393-4173-a89d-fd2c5c1f3d37":11.06031746031746,"2c276c75-639e-41b9-a3c4-5347e2fe9804":10.328373015873012,"2fea9a72-0171-4635-be8b-a189a52be390":12.461785714285712,"401e7bf8-8cce-417e-81ce-48fc7578e087":9.070436507936506,"4f4564bd-e868-4f7f-88bb-46fb813bf595":9.105158730158731,"57f1e331-791e-4666-b886-1c2f89c3aa29":9.385912698412696,"5be16126-0bbc-401a-81ea-aabe5da46ad9":9.752857142857142,"67b2b3cd-7c5d-4b5f-b301-d6e1bd857ec1":10.640079365079364,"752ff6af-824b-41ea-9712-c8185f5490d9":11.264484126984126,"756de6c7-3d2d-44fc-a722-7d16d54cb35f":10.782341269841268,"7ed7b5da-c666-4dc0-8243-a1d3ce0456d7":8.226190476190478,"94e25efe-d596-4767-99f0-d87f8c950f0c":8.373412698412698,"ab9331ee-c31d-48eb-a55e-1f03dfdce30c":11.856349206349206,"b1504997-e07a-4d68-8215-38e34e4baf70":11.552380952380952,"b28cb69b-2d4e-45ad-a484-1e550599a65b":11.636706349206346,"c09f2e4d-0fef-4e5d-ab5f-e56a55a5202c":8.389285714285714,"d02a4255-dff3-4cdf-ba69-41bd09a48ead":10.039682539682538,"d324af1d-63cb-4e2d-ae98-38fffb28ea16":9.7922619047619,"d5327892-4102-4cd1-b8e2-87e3d0a3d279":8.002777777777778,"e415a34f-803c-413e-9d1c-eb0ad68aa0ab":10.58115079365079,"f38e78a5-878d-499d-86c8-0a02ba099f22":10.666865079365076},"topic":["video","svc","standard","scalabl","code"],"groups":[{"authors":["Gary J. Sullivan","Thomas Wiegand"],"references":["0f36b3f2-30de-4b61-b8b9-4a9223c58f19","1ea5125c-2c09-47c7-ba82-913bda694a3f","21528d31-71fa-4244-a272-1df8a0492107","237a87ca-d393-4173-a89d-fd2c5c1f3d37","260a8eb0-9e62-4156-b89b-bb8c9a48e962","31907507-643d-4bf0-a6f2-8cec94d9d779","32e67a88-4535-4734-8e1b-b79d04ce064d","37708b6d-80cd-4d60-bc32-9255c830032a","41a49620-754b-48b6-87fb-07c7de6409ed","4aa6d2f8-2633-4e06-849f-f81badaac3d6","4c099e1c-451a-4822-ae08-b0177786e324","55ac55cc-c6ea-4f37-ad4a-e8d8322202d1","586b90e7-e84c-4129-8d7b-8c14cdf2ce78","5be16126-0bbc-401a-81ea-aabe5da46ad9","5e29c1d4-2a4a-4b28-8835-a9dea9bb185d","6879da4f-8478-49eb-b62f-ab5b35d68930","696bf9e4-eb9d-4d3a-96b3-b41e18d4ac6f","7210fb5d-2d76-4639-9365-e3fe830307b4","781a6016-9ed4-4ebf-95c6-dc3c72f4457e","7b88373c-de8f-420b-ab8f-94c4da5753f8","7ddd1b00-19c3-4b04-b002-6156433b9af0","84054583-75fa-41e5-8de0-2ac1bc102b39","9145432e-f4db-4f77-9e1f-7f14e2645694","94e25efe-d596-4767-99f0-d87f8c950f0c","a0582c2f-2516-4a51-b227-8f2f8b41b5e0","a91a087d-a74d-4f4f-86ae-453bf7b74d30","acb1f139-20f8-4d9f-8cb9-1e92f92d8665","cb43e76e-caeb-403d-b1d5-96503a362e3d","d5327892-4102-4cd1-b8e2-87e3d0a3d279","dbfb0dd3-5bea-4064-98e8-03c977f40873","ddf2ac17-6aa5-4341-8c7b-ffaa0016d812","fa72ee30-f4e1-4173-b2fa-8723df31a7cd"],"_id":"ab9331ee-c31d-48eb-a55e-1f03dfdce30c","abstract":"Over the last one and a half decades, digital video compression technologies have become an integral part of the way we create, communicate, and consume visual information. In this paper, techniques for video compression are reviewed, starting from basic concepts. The rate-distortion performance of modern video compression schemes is the result of an interaction between motion representation techniques, intra-picture prediction techniques, waveform coding of differences, and waveform coding of various refreshed regions. The paper starts with an explanation of the basic concepts of video codec design and then explains how these various features have been integrated into international standards, up to and including the most recent such standard, known as H.264/AVC.","title":"Video Compression - From Concepts to the H.264/AVC Standard","venue":"Proceedings of the IEEE","year":2005,"__v":0,"citationCount":186},{"authors":["Edouard Francois","Jerome Vieron","Vincent Bottreau"],"references":["237a87ca-d393-4173-a89d-fd2c5c1f3d37","2edda56d-33a9-4df4-9e12-cf8202c15f12","756de6c7-3d2d-44fc-a722-7d16d54cb35f","7b88373c-de8f-420b-ab8f-94c4da5753f8","7ed7b5da-c666-4dc0-8243-a1d3ce0456d7","81765532-5a4a-4546-ae7b-bb6a83ae2914","94e25efe-d596-4767-99f0-d87f8c950f0c","c09f2e4d-0fef-4e5d-ab5f-e56a55a5202c","c324f1d7-fb30-48ee-9211-66513ef6d027","dd2d4845-0a9e-40ab-9c60-84d56423b855","ff3e8103-1378-408b-adc2-c42b1c25b065"],"_id":"b28cb69b-2d4e-45ad-a484-1e550599a65b","abstract":"The scalable extension of AVC scalable video coding (SVC) is a current standardization project of the joint video team (JVT) of the ITU-T video coding experts group (VCEG) and the ISO/IEC moving picture experts group (MPEG). SVC has been initially designed for progressive video. However, even if progressive material is becoming the favorite format for production, broadcasting and consumers equipments, interlaced material is still widely used in the video world and will not disappear in the next few years. The specification of SVC should be finalized in 2007. Thanks to its AVC-based design and its AVC base-layer compatibility, migration from AVC to SVC equipments can be considered in a near future. In this context, interlaced support becomes an important requirement for SVC. This paper presents the main concepts for supporting interlaced coding in SVC. After a brief description of the basics of SVC, the generalizations of AVC interlaced tools are first described. Then main issues related to interlaced video scalable encoding are identified and the new mechanisms introduced in the SVC specification for raising these issues are presented. The paper also discusses related applications side and identifies several use cases illustrating the interest of interlaced support in SVC.","title":"Interlaced Coding in SVC","venue":"IEEE Transactions on Circuits and Systems for Video Technology","year":2007,"__v":0,"citationCount":6},{"authors":["Mathias Wien","Heiko Schwarz","Tobias Oelbaum"],"references":["237a87ca-d393-4173-a89d-fd2c5c1f3d37","401e7bf8-8cce-417e-81ce-48fc7578e087","4f4564bd-e868-4f7f-88bb-46fb813bf595","7ed7b5da-c666-4dc0-8243-a1d3ce0456d7","d324af1d-63cb-4e2d-ae98-38fffb28ea16","ece50cd5-9deb-4216-9c35-480b8de7cfe1","ff3e8103-1378-408b-adc2-c42b1c25b065"],"_id":"756de6c7-3d2d-44fc-a722-7d16d54cb35f","abstract":"This paper provides a performance analysis of the scalable video coding (SVC) extension of H.264/AVC. A short overview presenting the main functionalities of SVC is given and main issues in encoder control and bit stream extraction are outlined. Some aspects of rate-distortion optimization in the context of SVC are discussed and strategies for derivation of optimized configurations relative to the investigated scalability scenarios are presented. Based on these methods, rate-distortion results for several SVC configurations are presented and compared to rate-distortion optimized H.264/AVC single layer coding. For reference, a comparison to rate-distortion optimized MPEG-4 visual (advanced simple profile) coding results is provided. The results show that the performance gap between single layer coding and scalable video coding can be very small and that SVC clearly outperforms previous video coding technology such as MPEG-4 ASP.","title":"Performance Analysis of SVC","venue":"IEEE Transactions on Circuits and Systems for Video Technology","year":2007,"__v":0,"citationCount":150},{"authors":["Mathias Wien","Renaud Cazoulat","Andreas Graffunder","Andreas Hutter","Peter Amon"],"references":["237a87ca-d393-4173-a89d-fd2c5c1f3d37","2eb82ba0-d2dd-46a8-8fbd-6872c3abe1a5","324d200c-c128-4ee4-9de9-4364af0cab7f","401e7bf8-8cce-417e-81ce-48fc7578e087","756de6c7-3d2d-44fc-a722-7d16d54cb35f","84005731-a535-491b-afea-e23f69e95881","94e25efe-d596-4767-99f0-d87f8c950f0c","c82d58b5-41ae-47b8-a35f-5db3ed997846","d324af1d-63cb-4e2d-ae98-38fffb28ea16","ff3e8103-1378-408b-adc2-c42b1c25b065"],"_id":"f38e78a5-878d-499d-86c8-0a02ba099f22","abstract":"This paper presents the integration of scalable video coding (SVC) into a generic platform for multimedia adaptation. The platform provides a full MPEG-21 chain including server, adaptation nodes, and clients. An efficient adaptation framework using SVC and MPEG-21 digital item adaptation (DIA) is integrated and it is shown that SVC can seamlessly be adapted using DIA. For protection of packet losses in an error prone environment an unequal erasure protection scheme for SVC is provided. The platform includes a real-time SVC encoder capable of encoding CIF video with a QCIF base layer and fine grain scalable quality refinement at 12.5 fps on off-the-shelf high-end PCs. The reported quality degradation due to the optimization of the encoding algorithm is below 0.6 dB for the tested sequences.","title":"Real-Time System for Adaptive Video Streaming Based on SVC","venue":"IEEE Transactions on Circuits and Systems for Video Technology","year":2007,"__v":0,"citationCount":70}],"offsprings":[]},"ffa029cf-7240-4723-8339-51fac57f9f28":{"authors":["Krystian Mikolajczyk","Cordelia Schmid"],"references":["6018a516-8149-4bce-bc33-5449d86e58c2","60285266-7da2-474e-b05a-b380c836f665"],"_id":"ffa029cf-7240-4723-8339-51fac57f9f28","abstract":"In this paper we propose a novel approach for detecting interest points invariant to scale and affine transformations. Our scale and affine invariant detectors are based on the following recent results: (1) Interest points extracted with the Harris detector can be adapted to affine transformations and give repeatable results (geometrically stable). (2) The characteristic scale of a local structure is indicated by a local extremum over scale of normalized derivatives (the Laplacian). (3) The affine shape of a point neighborhood is estimated based on the second moment matrix.#R##N##R##N#Our scale invariant detector computes a multi-scale representation for the Harris interest point detector and then selects points at which a local measure (the Laplacian) is maximal over scales. This provides a set of distinctive points which are invariant to scale, rotation and translation as well as robust to illumination changes and limited changes of viewpoint. The characteristic scale determines a scale invariant region for each point. We extend the scale invariant detector to affine invariance by estimating the affine shape of a point neighborhood. An iterative algorithm modifies location, scale and neighborhood of each point and converges to affine invariant points. This method can deal with significant affine transformations including large scale changes. The characteristic scale and the affine shape of neighborhood determine an affine invariant region for each point.#R##N##R##N#We present a comparative evaluation of different detectors and show that our approach provides better results than existing methods. The performance of our detector is also confirmed by excellent matching resultss the image is described by a set of scale/affine invariant descriptors computed on the regions associated with our points.","title":"Scale & Affine Invariant Interest Point Detectors","venue":"International Journal of Computer Vision","year":2004,"__v":0,"citationCount":1525,"parents":{"0d287faa-99bb-42df-98a7-24fcd601b9a4":5.88235294117647,"1c016f4a-20fb-44b5-84ad-96c10cb8e61b":0,"2beaa150-6293-4f05-ba04-8e001993e766":0,"2d6c9f60-ea78-44a8-b5f9-6964575dd196":8.823529411764707,"33711daf-2a44-4f42-8466-c7801f29959b":11.76470588235294,"34758e0a-3def-447b-9c5e-e82a206426b5":0,"36800655-b2ff-4eb7-9070-c6be304c4baa":0,"457f15ab-c8e1-461d-b768-e044d88f1917":8.823529411764707,"473cf1a4-9f42-4e6d-b34f-77787f329079":14.705882352941178,"509e1ae2-768b-4417-bebe-d90cf1e0fdae":26.47058823529412,"5149d3c0-5ac9-47ba-9fb0-3d2ef757b0e8":5.88235294117647,"58d0cc4d-9deb-4188-98d2-7ca475ca7221":0,"5f1992df-975f-49e7-bd88-aee0740317cf":5.88235294117647,"5f84f09f-7644-447c-89e1-8dc9ee334197":17.647058823529413,"6018a516-8149-4bce-bc33-5449d86e58c2":8.823529411764707,"60285266-7da2-474e-b05a-b380c836f665":26.47058823529412,"643913d9-b72a-4ee3-9c3f-63c1249e9a3c":5.88235294117647,"64ea9dde-3bd8-4868-9c0b-f15556e67ad5":0,"7283fa2b-1f6a-4138-a3da-4bf69809a1a9":5.88235294117647,"79050acb-3012-4d4b-af60-66040a28043d":0,"7a9f04e3-2883-4204-8fb3-7db1ce5ddc09":14.705882352941178,"7ab7b36d-baae-4b21-89fc-69389fcabc44":20.588235294117645,"899de8c7-9cd9-4dd5-82f1-ad9acb801f8e":2.941176470588235,"8ab773a4-49b4-4755-a070-4ab1b1710690":20.588235294117645,"a00704dc-a2fa-4267-b7a6-427167d99521":0,"a0be9da4-c423-4f87-a387-822fe304aa03":2.941176470588235,"a72802aa-e1ab-4f52-bae8-703d68f9b220":5.88235294117647,"b3e60214-b54c-4e8f-9315-a6975c760f4c":32.35294117647059,"c591c440-b19b-4d7b-b067-cd8c366b7d6d":0,"cc6caca8-1564-4cf8-88a3-f0733c46e0dd":8.823529411764707,"d4e9734a-a4e7-4c19-be20-c32f55d4d26f":0,"e86ce68d-0d77-4f44-a212-518e7d8f394b":20.588235294117645,"eeb31134-612a-42bf-a6c2-8b7d7c17e694":0,"ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d":38.23529411764706},"keyword":{"0d287faa-99bb-42df-98a7-24fcd601b9a4":8.743148148148148,"1c016f4a-20fb-44b5-84ad-96c10cb8e61b":7.428174603174603,"2beaa150-6293-4f05-ba04-8e001993e766":8.65968253968254,"2d6c9f60-ea78-44a8-b5f9-6964575dd196":8.359682539682542,"33711daf-2a44-4f42-8466-c7801f29959b":10.355555555555553,"34758e0a-3def-447b-9c5e-e82a206426b5":0,"36800655-b2ff-4eb7-9070-c6be304c4baa":12.745833333333335,"457f15ab-c8e1-461d-b768-e044d88f1917":10.312777777777779,"473cf1a4-9f42-4e6d-b34f-77787f329079":9.97579365079365,"509e1ae2-768b-4417-bebe-d90cf1e0fdae":10.019444444444444,"5149d3c0-5ac9-47ba-9fb0-3d2ef757b0e8":9.556111111111113,"58d0cc4d-9deb-4188-98d2-7ca475ca7221":0,"5f1992df-975f-49e7-bd88-aee0740317cf":9.804761904761904,"5f84f09f-7644-447c-89e1-8dc9ee334197":9.911507936507938,"6018a516-8149-4bce-bc33-5449d86e58c2":9.461111111111112,"60285266-7da2-474e-b05a-b380c836f665":8.538888888888888,"643913d9-b72a-4ee3-9c3f-63c1249e9a3c":11.203452380952381,"64ea9dde-3bd8-4868-9c0b-f15556e67ad5":8.739444444444443,"7283fa2b-1f6a-4138-a3da-4bf69809a1a9":12.871851851851853,"79050acb-3012-4d4b-af60-66040a28043d":10.880555555555555,"7a9f04e3-2883-4204-8fb3-7db1ce5ddc09":9.187794612794614,"7ab7b36d-baae-4b21-89fc-69389fcabc44":8.019444444444444,"899de8c7-9cd9-4dd5-82f1-ad9acb801f8e":10.40574074074074,"8ab773a4-49b4-4755-a070-4ab1b1710690":11.833068783068784,"a00704dc-a2fa-4267-b7a6-427167d99521":7.94361111111111,"a0be9da4-c423-4f87-a387-822fe304aa03":10.032380952380953,"a72802aa-e1ab-4f52-bae8-703d68f9b220":9.908888888888889,"b3e60214-b54c-4e8f-9315-a6975c760f4c":10.538247863247864,"c591c440-b19b-4d7b-b067-cd8c366b7d6d":9.943095238095237,"cc6caca8-1564-4cf8-88a3-f0733c46e0dd":9.552777777777775,"d4e9734a-a4e7-4c19-be20-c32f55d4d26f":8.38388888888889,"e86ce68d-0d77-4f44-a212-518e7d8f394b":10.11888888888889,"eeb31134-612a-42bf-a6c2-8b7d7c17e694":9.912976190476192,"ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d":11.910185185185185},"topic":["scale","point","invari","affin","detector"],"groups":[{"authors":["Fredrick H. Rothganger","Svetlana Lazebnik","Cordelia Schmid","Jean Ponce"],"references":["1dc84769-ff4c-4de6-a1c9-8d3af9299701","34758e0a-3def-447b-9c5e-e82a206426b5","509e1ae2-768b-4417-bebe-d90cf1e0fdae","5bf79dad-2d36-4137-b074-62851e9952e0","5ebbd1f5-dfe5-4eec-9883-b8b5efea366c","5f1992df-975f-49e7-bd88-aee0740317cf","6018a516-8149-4bce-bc33-5449d86e58c2","7ab7b36d-baae-4b21-89fc-69389fcabc44","905461e4-643b-4da0-a669-f52318b9e126","a0be9da4-c423-4f87-a387-822fe304aa03","a0fa7ae2-61e5-48a9-be10-86440416129f","c7f93552-c1ef-4ae4-b1f5-2317e1c9d904","ccdefe89-9b16-4c22-8bb8-bd314ccad6e1","df9fe96c-752e-49be-a8c4-8b098ab51e22","ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d","ef7a0c74-9af2-4fae-b882-862cb0013bbf"],"_id":"8ab773a4-49b4-4755-a070-4ab1b1710690","abstract":"This paper presents a representation for three-dimensional objects in terms of affine-invariant image patches and their spatial relationships. Multi-view constraints associated with groups of patches are combined with a normalized representation of their appearance to guide matching and reconstruction, allowing the acquisition of true three-dimensional affine and Euclidean models from multiple images and their recognition in a single photograph taken from an arbitrary viewpoint. The proposed approach does not require a separate segmentation stage and is applicable to cluttered scenes. Preliminary modeling and recognition results are presented.","title":"3D object modeling and recognition using affine-invariant patches and multi-view spatial constraints","venue":"computer vision and pattern recognition","year":2003,"__v":0,"citationCount":68},{"authors":["Krystian Mikolajczyk","Andrew Zisserman","Cordelia Schmid"],"references":["27dfa95c-90d4-4d56-b987-0d2721b4b9b0","2958fc5c-15e8-45e7-8da8-d2e0fa46f0c7","34758e0a-3def-447b-9c5e-e82a206426b5","509e1ae2-768b-4417-bebe-d90cf1e0fdae","5149d3c0-5ac9-47ba-9fb0-3d2ef757b0e8","5ebbd1f5-dfe5-4eec-9883-b8b5efea366c","5f1992df-975f-49e7-bd88-aee0740317cf","5f84f09f-7644-447c-89e1-8dc9ee334197","6018a516-8149-4bce-bc33-5449d86e58c2","60285266-7da2-474e-b05a-b380c836f665","613841ae-c925-4aee-9c2e-8675213e4bbf","6fe37c18-8dc5-4baa-b6e0-5546353907bb","7283fa2b-1f6a-4138-a3da-4bf69809a1a9","75c6e7ad-f17c-40e1-8c39-965534096b2b","937cc256-e6e2-4bfa-928b-52f01cd416f4","97df7134-9cbf-43ea-9809-472115004999","a0be9da4-c423-4f87-a387-822fe304aa03","b1a8637d-9b27-4128-8c10-364a38230afc","b592576f-ff29-4a68-9b2f-8a8ad02e9c70","c591c440-b19b-4d7b-b067-cd8c366b7d6d","ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d"],"_id":"b3e60214-b54c-4e8f-9315-a6975c760f4c","abstract":"In this paper we describe an approach to recognizing poorly textured objects, that may contain holes and tubular parts, in cluttered scenes under arbitrary viewing conditions. To this end we develop a number of novel components. First, we introduce a new edge-based local feature detector that is invariant to similarity transformations. The features are localized on edges and a neighbourhood is estimated in a scale invariant manner. Second, the neighbourhood descriptor computed for foreground features is not affected by background clutter, even if the feature is on an object boundary. Third, the descriptor generalizes Lowe's SIFT method to edges. An object model is learnt from a single training image. The object is then recognized in new images in a series of steps which apply progressively tighter geometric restrictions. A final contribution of this work is to allow sufficient flexibility in the geometric representation that objects in the same visual class can be recognized. Results are demonstrated for various object classes including bikes and rackets.","title":"Shape recognition with edge-based features.","venue":"british machine vision conference","year":2003,"__v":0,"citationCount":91},{"authors":["Krystian Mikolajczyk","Cordelia Schmid"],"references":["1c016f4a-20fb-44b5-84ad-96c10cb8e61b","1dc84769-ff4c-4de6-a1c9-8d3af9299701","2beaa150-6293-4f05-ba04-8e001993e766","2d6c9f60-ea78-44a8-b5f9-6964575dd196","2fa2e5ba-11d3-4691-91e1-807b8ef7d8a5","36800655-b2ff-4eb7-9070-c6be304c4baa","457f15ab-c8e1-461d-b768-e044d88f1917","5c179e67-426d-402e-bfbf-1893059ab7cf","5f1992df-975f-49e7-bd88-aee0740317cf","6018a516-8149-4bce-bc33-5449d86e58c2","6b98de8f-f857-417c-9667-de061bd05872","7a9f04e3-2883-4204-8fb3-7db1ce5ddc09","a0be9da4-c423-4f87-a387-822fe304aa03"],"_id":"509e1ae2-768b-4417-bebe-d90cf1e0fdae","abstract":"This paper presents a new method for detecting scale invariant interest points. The method is based on two recent results on scale space: (1) Interest points can be adapted to scale and give repeatable results (geometrically stable). (2) Local extrema over scale of normalized derivatives indicate the presence of characteristic local structures. Our method first computes a multi-scale representation for the Harris interest point detector. We then select points at which a local measure (the Laplacian) is maximal over scales. This allows a selection of distinctive points for which the characteristic scale is known. These points are invariant to scale, rotation and translation as well as robust to illumination changes and limited changes of viewpoint. For indexing, the image is characterized by a set of scale invariant points; the scale associated with each point allows the computation of a scale invariant descriptor. Our descriptors are, in addition, invariant to image rotation, of affine illumination changes and robust to small perspective deformations. Experimental results for indexing show an excellent performance up to a scale factor of 4 for a database with more than 5000 images.","title":"Indexing based on scale invariant interest points","venue":"international conference on computer vision","year":2001,"__v":0,"citationCount":444},{"authors":["Jiri Matas","Ondrej Chum","M. Urban","Tomas Pajdla"],"references":["1dc84769-ff4c-4de6-a1c9-8d3af9299701","2beaa150-6293-4f05-ba04-8e001993e766","509e1ae2-768b-4417-bebe-d90cf1e0fdae","5f1992df-975f-49e7-bd88-aee0740317cf","5fadd790-4d5c-4a63-9d0c-39661713cf69","6018a516-8149-4bce-bc33-5449d86e58c2","63dbad19-24d8-4646-8e6a-65d85a5c2af3","7a9f04e3-2883-4204-8fb3-7db1ce5ddc09","7ab7b36d-baae-4b21-89fc-69389fcabc44","8f9d2434-c08a-43e5-8152-d41f2784ddc2","a0be9da4-c423-4f87-a387-822fe304aa03","beb947f3-b954-4bb9-8379-e33474f07c6d","ceb9e934-951e-47d6-a256-9ed1bb44b4b6","e86ce68d-0d77-4f44-a212-518e7d8f394b","ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d"],"_id":"60285266-7da2-474e-b05a-b380c836f665","abstract":"The wide-baseline stereo problem, i.e. the problem of establishing correspondences between a pair of images taken from different viewpoints is studied.#R##N##R##N#A new set of image elements that are put into correspondence, the so called extremal regions, is introduced. Extremal regions possess highly desirable properties: the set is closed under (1) continuous (and thus projective) transformation of image coordinates and (2) monotonic transformation of image intensities. An efficient (near linear complexity) and practically fast detection algorithm (near frame rate) is presented for an affinely invariant stable subset of extremal regions, the maximally stable extremal regions (MSER).#R##N##R##N#A new robust similarity measure for establishing tentative correspondences is proposed. The robustness ensures that invariants from multiple measurement regions (regions obtained by invariant constructions from extremal regions), some that are significantly larger (and hence discriminative) than the MSERs, may be used to establish tentative correspondences.#R##N##R##N#The high utility of MSERs, multiple measurement regions and the robust metric is demonstrated in wide-baseline experiments on image pairs from both indoor and outdoor scenes. Significant change of scale (3.5×), illumination conditions, out-of-plane rotation, occlusion, locally anisotropic scale change and 3D translation of the viewpoint are all present in the test problems. Good estimates of epipolar geometry (average distance from corresponding points to the epipolar line below 0.09 of the inter-pixel distance) are obtained.","title":"Robust wide-baseline stereo from maximally stable extremal regions","venue":"Image and Vision Computing","year":2004,"__v":0,"citationCount":1575},{"authors":["Krystian Mikolajczyk","Cordelia Schmid"],"references":["0d287faa-99bb-42df-98a7-24fcd601b9a4","1c016f4a-20fb-44b5-84ad-96c10cb8e61b","1dc84769-ff4c-4de6-a1c9-8d3af9299701","2d6c9f60-ea78-44a8-b5f9-6964575dd196","34758e0a-3def-447b-9c5e-e82a206426b5","36800655-b2ff-4eb7-9070-c6be304c4baa","509e1ae2-768b-4417-bebe-d90cf1e0fdae","5149d3c0-5ac9-47ba-9fb0-3d2ef757b0e8","5f1992df-975f-49e7-bd88-aee0740317cf","6018a516-8149-4bce-bc33-5449d86e58c2","7a9f04e3-2883-4204-8fb3-7db1ce5ddc09","a0be9da4-c423-4f87-a387-822fe304aa03","cc6caca8-1564-4cf8-88a3-f0733c46e0dd","e86ce68d-0d77-4f44-a212-518e7d8f394b"],"_id":"ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d","abstract":"This paper presents a novel approach for detecting affine invariant interest points. Our method can deal with significant affine transformations including large scale changes. Such transformations introduce significant changes in the point location as well as in the scale and the shape of the neighbourhood of an interest point. Our approach allows to solve for these problems simultaneously. It is based on three key ideas : 1) The second moment matrix computed in a point can be used to normalize a region in an affine invariant way (skew and stretch). 2) The scale of the local structure is indicated by local extrema of normalized derivatives over scale. 3) An affine-adapted Harris detector determines the location of interest points. A multi-scale version of this detector is used for initialization. An iterative algorithm then modifies location, scale and neighbourhood of each point and converges to affine invariant points. For matching and recognition, the image is characterized by a set of affine invariant points; the affine transformation associated with each point allows the computation of an affine invariant descriptor which is also invariant to affine illumination changes. A quantitative comparison of our detector with existing ones shows a significant improvement in the presence of large affine deformations. Experimental results for wide baseline matching show an excellent performance in the presence of large perspective transformations including significant scale changes. Results for recognition are very good for a database with more than 5000 images.","title":"An Affine Invariant Interest Point Detector","venue":"european conference on computer vision","year":2002,"__v":0,"citationCount":560}],"offsprings":["50252efa-a843-4cc6-a591-22f527ee3d6c","6c38b3b4-7562-493d-a40c-fe70abf039a7","dd83785a-dd19-41e3-9b25-ebabbd48d336","8d8e7d51-3223-4776-bf6a-40306774b8a1","f225f439-4389-4312-a503-f8c1b0aa02de"]},"8d8e7d51-3223-4776-bf6a-40306774b8a1":{"authors":["Krystian Mikolajczyk","Cordelia Schmid"],"references":["6018a516-8149-4bce-bc33-5449d86e58c2","60285266-7da2-474e-b05a-b380c836f665","b592576f-ff29-4a68-9b2f-8a8ad02e9c70","b944f77f-113b-4a02-ae5e-d4a124b8fd5b","e2204e92-e6dc-4884-9bbc-200029491fc7","ffa029cf-7240-4723-8339-51fac57f9f28"],"_id":"8d8e7d51-3223-4776-bf6a-40306774b8a1","abstract":"In this paper, we compare the performance of descriptors computed for local interest regions, as, for example, extracted by the Harris-Affine detector [Mikolajczyk, K and Schmid, C, 2004]. Many different descriptors have been proposed in the literature. It is unclear which descriptors are more appropriate and how their performance depends on the interest region detector. The descriptors should be distinctive and at the same time robust to changes in viewing conditions as well as to errors of the detector. Our evaluation uses as criterion recall with respect to precision and is carried out for different image transformations. We compare shape context [Belongie, S, et al., April 2002], steerable filters [Freeman, W and Adelson, E, Setp. 1991], PCA-SIFT [Ke, Y and Sukthankar, R, 2004], differential invariants [Koenderink, J and van Doorn, A, 1987], spin images [Lazebnik, S, et al., 2003], SIFT [Lowe, D. G., 1999], complex filters [Schaffalitzky, F and Zisserman, A, 2002], moment invariants [Van Gool, L, et al., 1996], and cross-correlation for different types of interest regions. We also propose an extension of the SIFT descriptor and show that it outperforms the original method. Furthermore, we observe that the ranking of the descriptors is mostly independent of the interest region detector and that the SIFT-based descriptors perform best. Moments and steerable filters show the best performance among the low dimensional descriptors.","title":"A performance evaluation of local descriptors","venue":"IEEE Transactions on Pattern Analysis and Machine Intelligence","year":2005,"__v":0,"citationCount":2762,"parents":{"00a4e16f-6b65-4ad2-bedc-b19d9cbc2cfe":10.81081081081081,"09346dc3-f4d0-43a4-8f0b-27e02bcd336e":0,"0aae4e44-abdb-4948-9462-61f6e52162ba":10.81081081081081,"0d287faa-99bb-42df-98a7-24fcd601b9a4":2.7027027027027026,"19195bc1-7aff-4dd3-91cc-25402c343a19":0,"21a8e8fd-0172-4e9a-8474-7024eb0bf979":29.72972972972973,"21c67dad-f0eb-4479-afe7-fdf4a71eef01":48.64864864864865,"2d6c9f60-ea78-44a8-b5f9-6964575dd196":0,"33711daf-2a44-4f42-8466-c7801f29959b":2.7027027027027026,"34758e0a-3def-447b-9c5e-e82a206426b5":0,"36800655-b2ff-4eb7-9070-c6be304c4baa":0,"37031566-2033-44cb-a87e-91a9bb37996f":2.7027027027027026,"3b744649-d7a0-46c3-b242-9e0060d8ecfa":0,"4e58f9b5-8562-4f17-830f-f055449867fc":10.81081081081081,"509e1ae2-768b-4417-bebe-d90cf1e0fdae":10.81081081081081,"5149d3c0-5ac9-47ba-9fb0-3d2ef757b0e8":2.7027027027027026,"568f1994-f91e-413e-92fd-87dbbb9642a8":2.7027027027027026,"5f1992df-975f-49e7-bd88-aee0740317cf":2.7027027027027026,"6018a516-8149-4bce-bc33-5449d86e58c2":2.7027027027027026,"60285266-7da2-474e-b05a-b380c836f665":13.513513513513514,"608a581a-0e03-435a-9067-c0e0982567af":0,"683dd26d-5c59-4feb-9fbd-2bcf3cc1942f":13.513513513513514,"6fe37c18-8dc5-4baa-b6e0-5546353907bb":75.67567567567568,"72c27d5a-23c5-4d1b-a000-280b87b368ee":0,"7ab7b36d-baae-4b21-89fc-69389fcabc44":10.81081081081081,"853b29ea-c6d1-497e-bad3-b608d370e7e2":8.108108108108109,"a5254ae0-1ce1-4390-b9f8-8d5a3dcb1e62":24.324324324324326,"a8c6ead3-d61a-4f6a-a702-08743f19eec9":0,"b4685927-0ad9-466b-b2c6-2e1764475726":5.405405405405405,"b592576f-ff29-4a68-9b2f-8a8ad02e9c70":8.108108108108109,"b944f77f-113b-4a02-ae5e-d4a124b8fd5b":24.324324324324326,"c455fb04-4566-4648-ad6f-3cf2245e507c":5.405405405405405,"e2204e92-e6dc-4884-9bbc-200029491fc7":2.7027027027027026,"e927dff1-6ed4-45fd-8852-eb804e11e665":0,"ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d":21.62162162162162,"fc9638b8-572c-4b23-aab2-92e2dd3b79f8":18.91891891891892,"ffa029cf-7240-4723-8339-51fac57f9f28":32.432432432432435},"keyword":{"00a4e16f-6b65-4ad2-bedc-b19d9cbc2cfe":10.352896825396828,"09346dc3-f4d0-43a4-8f0b-27e02bcd336e":13.081878306878309,"0aae4e44-abdb-4948-9462-61f6e52162ba":10.924404761904764,"0d287faa-99bb-42df-98a7-24fcd601b9a4":9.53723544973545,"19195bc1-7aff-4dd3-91cc-25402c343a19":9.00410052910053,"21a8e8fd-0172-4e9a-8474-7024eb0bf979":10.56626984126984,"21c67dad-f0eb-4479-afe7-fdf4a71eef01":10.785198412698412,"2d6c9f60-ea78-44a8-b5f9-6964575dd196":9.857936507936506,"33711daf-2a44-4f42-8466-c7801f29959b":13.600873015873017,"34758e0a-3def-447b-9c5e-e82a206426b5":0,"36800655-b2ff-4eb7-9070-c6be304c4baa":12.529047619047622,"37031566-2033-44cb-a87e-91a9bb37996f":11.528968253968257,"3b744649-d7a0-46c3-b242-9e0060d8ecfa":13.085119047619047,"4e58f9b5-8562-4f17-830f-f055449867fc":11.884060846560846,"509e1ae2-768b-4417-bebe-d90cf1e0fdae":11.590952380952379,"5149d3c0-5ac9-47ba-9fb0-3d2ef757b0e8":9.717261904761905,"568f1994-f91e-413e-92fd-87dbbb9642a8":6.304365079365079,"5f1992df-975f-49e7-bd88-aee0740317cf":9.104642857142855,"6018a516-8149-4bce-bc33-5449d86e58c2":10.270436507936507,"60285266-7da2-474e-b05a-b380c836f665":11.722420634920637,"608a581a-0e03-435a-9067-c0e0982567af":0,"683dd26d-5c59-4feb-9fbd-2bcf3cc1942f":11.118253968253972,"6fe37c18-8dc5-4baa-b6e0-5546353907bb":15.234285714285713,"72c27d5a-23c5-4d1b-a000-280b87b368ee":9.402182539682542,"7ab7b36d-baae-4b21-89fc-69389fcabc44":9.452579365079366,"853b29ea-c6d1-497e-bad3-b608d370e7e2":13.236111111111112,"a5254ae0-1ce1-4390-b9f8-8d5a3dcb1e62":10.564166666666669,"a8c6ead3-d61a-4f6a-a702-08743f19eec9":10.975277777777778,"b4685927-0ad9-466b-b2c6-2e1764475726":8.16047619047619,"b592576f-ff29-4a68-9b2f-8a8ad02e9c70":11.841481481481484,"b944f77f-113b-4a02-ae5e-d4a124b8fd5b":12.721031746031748,"c455fb04-4566-4648-ad6f-3cf2245e507c":10.92936507936508,"e2204e92-e6dc-4884-9bbc-200029491fc7":11.567063492063493,"e927dff1-6ed4-45fd-8852-eb804e11e665":0,"ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d":11.417671957671956,"fc9638b8-572c-4b23-aab2-92e2dd3b79f8":11.687962962962963,"ffa029cf-7240-4723-8339-51fac57f9f28":12.009285714285713},"topic":["descriptor","region","perform","interest","detector"],"groups":[{"authors":["Andreas Opelt","Michael Fussenegger","Axel Pinz","Peter Auer"],"references":["01a03531-eb3c-4b9e-a41f-2ef531e3cac2","2d6c9f60-ea78-44a8-b5f9-6964575dd196","33711daf-2a44-4f42-8466-c7801f29959b","34758e0a-3def-447b-9c5e-e82a206426b5","36800655-b2ff-4eb7-9070-c6be304c4baa","3ba1e680-b3cc-40e6-bc90-2af6c781f9bc","49e8d454-99f4-4cde-9ff8-6f50c33eaa48","509e1ae2-768b-4417-bebe-d90cf1e0fdae","5f1992df-975f-49e7-bd88-aee0740317cf","6018a516-8149-4bce-bc33-5449d86e58c2","608a581a-0e03-435a-9067-c0e0982567af","6fe37c18-8dc5-4baa-b6e0-5546353907bb","733eea21-9c61-4935-8ffd-5b8e56dd947d","84ba5bee-f8ac-4c66-8e81-858a888be0b8","8d8e7d51-3223-4776-bf6a-40306774b8a1","90ebc6d7-108e-4698-a147-76ac4e67c036","c455fb04-4566-4648-ad6f-3cf2245e507c","ccdefe89-9b16-4c22-8bb8-bd314ccad6e1","d7b1fba1-b5f8-4377-88a8-d2fc69f723b7","da8cc675-ae9d-40a0-abe2-f08e7df3fc3a","e649a9fd-f6d9-4aac-b428-29b82c20a484","ed8a9624-3abe-4b5e-bffe-5b3ecc34e841","ee554ae0-03a8-4976-9d09-0d2a885d79d6","ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d"],"_id":"21a8e8fd-0172-4e9a-8474-7024eb0bf979","abstract":"In this paper we describe the first stage of a new learning system for object detection and recognition. For our system we propose Boosting (5) as the underlying learning technique. This allows the use of very diverse sets of visual features in the learning process within a com- mon framework: Boosting — together with a weak hypotheses finder — may choose very inhomogeneous features as most relevant for combina- tion into a final hypothesis. As another advantage the weak hypotheses finder may search the weak hypotheses space without explicit calculation of all available hypotheses, reducing computation time. This contrasts the related work of Agarwal and Roth (1) where Winnow was used as learning algorithm and all weak hypotheses were calculated explicitly. In our first empirical evaluation we use four types of local descriptors: two basic ones consisting of a set of grayvalues and intensity moments and two high level descriptors: moment invariants (8) and SIFTs (12). The descriptors are calculated from local patches detected by an inter- est point operator. The weak hypotheses finder selects one of the local patches and one type of local descriptor and efficiently searches for the most discriminative similarity threshold. This differs from other work on Boosting for object recognition where simple rectangular hypotheses (22) or complex classifiers (20) have been used. In relatively simple images, where the objects are prominent, our approach yields results comparable to the state-of-the-art (3). But we also obtain very good results on more complex images, where the objects are located in arbitrary positions, poses, and scales in the images. These results indicate that our flexible approach, which also allows the inclusion of features from segmented re- gions and even spatial relationships, leads us a significant step towards generic object recognition.","title":"Weak Hypotheses and Boosting for Generic Object Detection and Recognition","venue":"european conference on computer vision","year":2004,"__v":0,"citationCount":150},{"authors":["Krystian Mikolajczyk","Cordelia Schmid"],"references":["0d287faa-99bb-42df-98a7-24fcd601b9a4","1c016f4a-20fb-44b5-84ad-96c10cb8e61b","1dc84769-ff4c-4de6-a1c9-8d3af9299701","2d6c9f60-ea78-44a8-b5f9-6964575dd196","34758e0a-3def-447b-9c5e-e82a206426b5","36800655-b2ff-4eb7-9070-c6be304c4baa","509e1ae2-768b-4417-bebe-d90cf1e0fdae","5149d3c0-5ac9-47ba-9fb0-3d2ef757b0e8","5f1992df-975f-49e7-bd88-aee0740317cf","6018a516-8149-4bce-bc33-5449d86e58c2","7a9f04e3-2883-4204-8fb3-7db1ce5ddc09","a0be9da4-c423-4f87-a387-822fe304aa03","cc6caca8-1564-4cf8-88a3-f0733c46e0dd","e86ce68d-0d77-4f44-a212-518e7d8f394b"],"_id":"ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d","abstract":"This paper presents a novel approach for detecting affine invariant interest points. Our method can deal with significant affine transformations including large scale changes. Such transformations introduce significant changes in the point location as well as in the scale and the shape of the neighbourhood of an interest point. Our approach allows to solve for these problems simultaneously. It is based on three key ideas : 1) The second moment matrix computed in a point can be used to normalize a region in an affine invariant way (skew and stretch). 2) The scale of the local structure is indicated by local extrema of normalized derivatives over scale. 3) An affine-adapted Harris detector determines the location of interest points. A multi-scale version of this detector is used for initialization. An iterative algorithm then modifies location, scale and neighbourhood of each point and converges to affine invariant points. For matching and recognition, the image is characterized by a set of affine invariant points; the affine transformation associated with each point allows the computation of an affine invariant descriptor which is also invariant to affine illumination changes. A quantitative comparison of our detector with existing ones shows a significant improvement in the presence of large affine deformations. Experimental results for wide baseline matching show an excellent performance in the presence of large perspective transformations including significant scale changes. Results for recognition are very good for a database with more than 5000 images.","title":"An Affine Invariant Interest Point Detector","venue":"european conference on computer vision","year":2002,"__v":0,"citationCount":560},{"authors":["Krystian Mikolajczyk","Tinne Tuytelaars","C. Schmid","Andrew Zisserman","Jir i Matas","Frederik Schaffalitzky","Timor Kadir","L. Van Gool"],"references":["085204a8-62ca-4a3c-8098-4f75d62d1ae4","0aae4e44-abdb-4948-9462-61f6e52162ba","0bc5747a-2caf-4996-a55b-6ec5e7273636","0d287faa-99bb-42df-98a7-24fcd601b9a4","1dc84769-ff4c-4de6-a1c9-8d3af9299701","21a8e8fd-0172-4e9a-8474-7024eb0bf979","2beaa150-6293-4f05-ba04-8e001993e766","2d6c9f60-ea78-44a8-b5f9-6964575dd196","2dfac644-329c-46f4-a508-749ccb2d7c85","34758e0a-3def-447b-9c5e-e82a206426b5","4e58f9b5-8562-4f17-830f-f055449867fc","50212652-4999-4f13-82d6-a37eb2862a73","509e1ae2-768b-4417-bebe-d90cf1e0fdae","5149d3c0-5ac9-47ba-9fb0-3d2ef757b0e8","5172d9aa-41cc-40dc-949a-cde3d9f05f31","5f1992df-975f-49e7-bd88-aee0740317cf","6018a516-8149-4bce-bc33-5449d86e58c2","60285266-7da2-474e-b05a-b380c836f665","6842d04f-2b92-4298-aee8-92babc53f7c4","6fe37c18-8dc5-4baa-b6e0-5546353907bb","7283fa2b-1f6a-4138-a3da-4bf69809a1a9","776d4b4d-d49f-439f-9db5-7c5c3ce68db3","7ab7b36d-baae-4b21-89fc-69389fcabc44","8ab773a4-49b4-4755-a070-4ab1b1710690","8d8e7d51-3223-4776-bf6a-40306774b8a1","9b480902-c7fd-4d9f-ac9c-3c2fe3aa9c2c","a0be9da4-c423-4f87-a387-822fe304aa03","ab7b7857-e48d-4b94-8bfa-bc9ed61d5853","b25e7392-e9f9-4600-8ab0-a76252f1633a","b3e60214-b54c-4e8f-9315-a6975c760f4c","b944f77f-113b-4a02-ae5e-d4a124b8fd5b","b9e63aeb-aa46-40a0-9b06-01e2270cea70","c455fb04-4566-4648-ad6f-3cf2245e507c","cf9198ae-7e03-401f-a52b-94689ba30a36","ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d","fc9638b8-572c-4b23-aab2-92e2dd3b79f8","ffa029cf-7240-4723-8339-51fac57f9f28"],"_id":"21c67dad-f0eb-4479-afe7-fdf4a71eef01","abstract":"The paper gives a snapshot of the state of the art in affine covariant region detectors, and compares their performance on a set of test images under varying imaging conditions. Six types of detectors are included: detectors based on affine normalization around Harris (Mikolajczyk and Schmid, 2002; Schaffalitzky and Zisserman, 2002) and Hessian points (Mikolajczyk and Schmid, 2002), a detector of `maximally stable extremal regions', proposed by Matas et al. (2002); an edge-based region detector (Tuytelaars and Van Gool, 1999) and a detector based on intensity extrema (Tuytelaars and Van Gool, 2000), and a detector of `salient regions', proposed by Kadir, Zisserman and Brady (2004). The performance is measured against changes in viewpoint, scale, illumination, defocus and image compression.#R##N##R##N#The objective of this paper is also to establish a reference test set of images and performance software, so that future detectors can be evaluated in the same framework.","title":"A Comparison of Affine Region Detectors","venue":"International Journal of Computer Vision","year":2005,"__v":0,"citationCount":1317},{"authors":["Krystian Mikolajczyk","Cordelia Schmid"],"references":["0d287faa-99bb-42df-98a7-24fcd601b9a4","1c016f4a-20fb-44b5-84ad-96c10cb8e61b","2beaa150-6293-4f05-ba04-8e001993e766","2d6c9f60-ea78-44a8-b5f9-6964575dd196","33711daf-2a44-4f42-8466-c7801f29959b","34758e0a-3def-447b-9c5e-e82a206426b5","36800655-b2ff-4eb7-9070-c6be304c4baa","457f15ab-c8e1-461d-b768-e044d88f1917","473cf1a4-9f42-4e6d-b34f-77787f329079","509e1ae2-768b-4417-bebe-d90cf1e0fdae","5149d3c0-5ac9-47ba-9fb0-3d2ef757b0e8","58d0cc4d-9deb-4188-98d2-7ca475ca7221","5f1992df-975f-49e7-bd88-aee0740317cf","5f84f09f-7644-447c-89e1-8dc9ee334197","6018a516-8149-4bce-bc33-5449d86e58c2","60285266-7da2-474e-b05a-b380c836f665","643913d9-b72a-4ee3-9c3f-63c1249e9a3c","64ea9dde-3bd8-4868-9c0b-f15556e67ad5","7283fa2b-1f6a-4138-a3da-4bf69809a1a9","79050acb-3012-4d4b-af60-66040a28043d","7a9f04e3-2883-4204-8fb3-7db1ce5ddc09","7ab7b36d-baae-4b21-89fc-69389fcabc44","899de8c7-9cd9-4dd5-82f1-ad9acb801f8e","8ab773a4-49b4-4755-a070-4ab1b1710690","a00704dc-a2fa-4267-b7a6-427167d99521","a0be9da4-c423-4f87-a387-822fe304aa03","a72802aa-e1ab-4f52-bae8-703d68f9b220","b3e60214-b54c-4e8f-9315-a6975c760f4c","c591c440-b19b-4d7b-b067-cd8c366b7d6d","cc6caca8-1564-4cf8-88a3-f0733c46e0dd","d4e9734a-a4e7-4c19-be20-c32f55d4d26f","e86ce68d-0d77-4f44-a212-518e7d8f394b","eeb31134-612a-42bf-a6c2-8b7d7c17e694","ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d"],"_id":"ffa029cf-7240-4723-8339-51fac57f9f28","abstract":"In this paper we propose a novel approach for detecting interest points invariant to scale and affine transformations. Our scale and affine invariant detectors are based on the following recent results: (1) Interest points extracted with the Harris detector can be adapted to affine transformations and give repeatable results (geometrically stable). (2) The characteristic scale of a local structure is indicated by a local extremum over scale of normalized derivatives (the Laplacian). (3) The affine shape of a point neighborhood is estimated based on the second moment matrix.#R##N##R##N#Our scale invariant detector computes a multi-scale representation for the Harris interest point detector and then selects points at which a local measure (the Laplacian) is maximal over scales. This provides a set of distinctive points which are invariant to scale, rotation and translation as well as robust to illumination changes and limited changes of viewpoint. The characteristic scale determines a scale invariant region for each point. We extend the scale invariant detector to affine invariance by estimating the affine shape of a point neighborhood. An iterative algorithm modifies location, scale and neighborhood of each point and converges to affine invariant points. This method can deal with significant affine transformations including large scale changes. The characteristic scale and the affine shape of neighborhood determine an affine invariant region for each point.#R##N##R##N#We present a comparative evaluation of different detectors and show that our approach provides better results than existing methods. The performance of our detector is also confirmed by excellent matching resultss the image is described by a set of scale/affine invariant descriptors computed on the regions associated with our points.","title":"Scale & Affine Invariant Interest Point Detectors","venue":"International Journal of Computer Vision","year":2004,"__v":0,"citationCount":1525},{"authors":["Yan Ke","Rahul Sukthankar"],"references":["28005624-c0e8-4c62-b585-6e362c3dc8d5","34758e0a-3def-447b-9c5e-e82a206426b5","36800655-b2ff-4eb7-9070-c6be304c4baa","509e1ae2-768b-4417-bebe-d90cf1e0fdae","6018a516-8149-4bce-bc33-5449d86e58c2","608a581a-0e03-435a-9067-c0e0982567af","6fe37c18-8dc5-4baa-b6e0-5546353907bb","7ab7b36d-baae-4b21-89fc-69389fcabc44","aec2ffaf-e691-4884-9304-7d7e14733b2e","b944f77f-113b-4a02-ae5e-d4a124b8fd5b","c455fb04-4566-4648-ad6f-3cf2245e507c","d7b1fba1-b5f8-4377-88a8-d2fc69f723b7"],"_id":"a5254ae0-1ce1-4390-b9f8-8d5a3dcb1e62","abstract":"Stable local feature detection and representation is a fundamental component of many image registration and object recognition algorithms. Mikolajczyk and Schmid (June 2003) recently evaluated a variety of approaches and identified the SIFT [D. G. Lowe, 1999] algorithm as being the most resistant to common image deformations. This paper examines (and improves upon) the local image descriptor used by SIFT. Like SIFT, our descriptors encode the salient aspects of the image gradient in the feature point's neighborhood; however, instead of using SIFT's smoothed weighted histograms, we apply principal components analysis (PCA) to the normalized gradient patch. Our experiments demonstrate that the PCA-based local descriptors are more distinctive, more robust to image deformations, and more compact than the standard SIFT representation. We also present results showing that using these descriptors in an image retrieval application results in increased accuracy and faster matching.","title":"PCA-SIFT: a more distinctive representation for local image descriptors","venue":"computer vision and pattern recognition","year":2004,"__v":0,"citationCount":1138},{"authors":["David G. Lowe"],"references":["00a4e16f-6b65-4ad2-bedc-b19d9cbc2cfe","01a0f825-a308-455b-93fc-e62defc0e3b0","035f8537-61a7-4c4f-b9fe-120f913a38b0","03a42efa-a19c-4b19-a881-9c7ff63865ce","05c3e696-6add-4b0d-b867-e6f1c98deb9b","2fa2e5ba-11d3-4691-91e1-807b8ef7d8a5","32d9eaee-c68f-4479-aa67-837d3cc91a05","34758e0a-3def-447b-9c5e-e82a206426b5","5437c0a0-8f20-49c3-86e5-9d860f3e4f04","5dcd5949-faa9-4af3-8c6f-b285dd3b6566","5f1992df-975f-49e7-bd88-aee0740317cf","5f84f09f-7644-447c-89e1-8dc9ee334197","6018a516-8149-4bce-bc33-5449d86e58c2","60285266-7da2-474e-b05a-b380c836f665","768eea6d-8e82-4bbf-8bdd-1f2338ded29f","791e9257-d7a0-41fe-b471-bde48f3c4a04","7ab7b36d-baae-4b21-89fc-69389fcabc44","7b3f5f5b-a965-4656-9a6f-2f9740625176","899de8c7-9cd9-4dd5-82f1-ad9acb801f8e","a00704dc-a2fa-4267-b7a6-427167d99521","a0fa7ae2-61e5-48a9-be10-86440416129f","a748e0f4-ee6f-41ad-a2a5-1a5a6751086d","b3e60214-b54c-4e8f-9315-a6975c760f4c","b4685927-0ad9-466b-b2c6-2e1764475726","c455fb04-4566-4648-ad6f-3cf2245e507c","ccdefe89-9b16-4c22-8bb8-bd314ccad6e1","d20995f6-529c-41c6-b75e-a169b005fb5c","d9b9f667-9d8a-4723-a6c4-c19b941acd46","df9fe96c-752e-49be-a8c4-8b098ab51e22","ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d","f6272ea9-0360-47ed-90a5-651ea958143f"],"_id":"b944f77f-113b-4a02-ae5e-d4a124b8fd5b","abstract":"This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance.","title":"Distinctive Image Features from Scale-Invariant Keypoints","venue":"International Journal of Computer Vision","year":2004,"__v":0,"citationCount":16229},{"authors":["Krystian Mikolajczyk","Cordelia Schmid"],"references":["00a4e16f-6b65-4ad2-bedc-b19d9cbc2cfe","09346dc3-f4d0-43a4-8f0b-27e02bcd336e","0aae4e44-abdb-4948-9462-61f6e52162ba","0d287faa-99bb-42df-98a7-24fcd601b9a4","19195bc1-7aff-4dd3-91cc-25402c343a19","21a8e8fd-0172-4e9a-8474-7024eb0bf979","21c67dad-f0eb-4479-afe7-fdf4a71eef01","2d6c9f60-ea78-44a8-b5f9-6964575dd196","33711daf-2a44-4f42-8466-c7801f29959b","34758e0a-3def-447b-9c5e-e82a206426b5","36800655-b2ff-4eb7-9070-c6be304c4baa","509e1ae2-768b-4417-bebe-d90cf1e0fdae","5149d3c0-5ac9-47ba-9fb0-3d2ef757b0e8","5f1992df-975f-49e7-bd88-aee0740317cf","6018a516-8149-4bce-bc33-5449d86e58c2","60285266-7da2-474e-b05a-b380c836f665","608a581a-0e03-435a-9067-c0e0982567af","683dd26d-5c59-4feb-9fbd-2bcf3cc1942f","853b29ea-c6d1-497e-bad3-b608d370e7e2","a5254ae0-1ce1-4390-b9f8-8d5a3dcb1e62","b4685927-0ad9-466b-b2c6-2e1764475726","b592576f-ff29-4a68-9b2f-8a8ad02e9c70","b944f77f-113b-4a02-ae5e-d4a124b8fd5b","c455fb04-4566-4648-ad6f-3cf2245e507c","e2204e92-e6dc-4884-9bbc-200029491fc7","e927dff1-6ed4-45fd-8852-eb804e11e665","ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d","fc9638b8-572c-4b23-aab2-92e2dd3b79f8"],"_id":"6fe37c18-8dc5-4baa-b6e0-5546353907bb","abstract":"In this paper we compare the performance of interest point descriptors. Many different descriptors have been proposed in the literature. However, it is unclear which descriptors are more appropriate and how their performance depends on the interest point detector. The descriptors should be distinctive and at the same time robust to changes in viewing conditions as well as to errors of the point detector. Our evaluation uses as criterion detection rate with respect to false positive rate and is carried out for different image transformations. We compare SIFT descriptors (Lowe, 1999), steerable filters (Freeman and Adelson, 1991), differential invariants (Koenderink ad van Doorn, 1987), complex filters (Schaffalitzky and Zisserman, 2002), moment invariants (Van Gool et al., 1996) and cross-correlation for different types of interest points. In this evaluation, we observe that the ranking of the descriptors does not depend on the point detector and that SIFT descriptors perform best. Steerable filters come second ; they can be considered a good choice given the low dimensionality.","title":"A performance evaluation of local descriptors","venue":"computer vision and pattern recognition","year":2003,"__v":0,"citationCount":683}],"offsprings":["50252efa-a843-4cc6-a591-22f527ee3d6c","6c38b3b4-7562-493d-a40c-fe70abf039a7","dd83785a-dd19-41e3-9b25-ebabbd48d336","e3a5cec9-7e82-4c14-86ab-0d95a92712a7","f225f439-4389-4312-a503-f8c1b0aa02de","3ed17ffd-b416-470a-973a-77d7085a3503"]},"f56b877b-4060-4754-b303-e8140968544c":{"authors":["David L. Donoho"],"references":["71a18de9-e543-4337-ab7a-3db31d9f8c00","a53a3dda-b003-4d5c-96b1-e9afd8e35692"],"_id":"f56b877b-4060-4754-b303-e8140968544c","abstract":"Suppose x is an unknown vector in Ropf m  (a digital image or signal); we plan to measure n general linear functionals of x and then reconstruct. If x is known to be compressible by transform coding with a known transform, and we reconstruct via the nonlinear procedure defined here, the number of measurements n can be dramatically smaller than the size m. Thus, certain natural classes of images with m pixels need only n=O(m 1/4 log 5/2 (m)) nonadaptive nonpixel samples for faithful recovery, as opposed to the usual m pixel samples. More specifically, suppose x has a sparse representation in some orthonormal basis (e.g., wavelet, Fourier) or tight frame (e.g., curvelet, Gabor)-so the coefficients belong to an lscr p  ball for 0 2  error O(N 1/2-1 p/). It is possible to design n=O(Nlog(m)) nonadaptive measurements allowing reconstruction with accuracy comparable to that attainable with direct knowledge of the N most important coefficients. Moreover, a good approximation to those N important coefficients is extracted from the n measurements by solving a linear program-Basis Pursuit in signal processing. The nonadaptive measurements have the character of \"random\" linear combinations of basis/frame elements. Our results use the notions of optimal recovery, of n-widths, and information-based complexity. We estimate the Gel'fand n-widths of lscr p  balls in high-dimensional Euclidean space in the case 0<ples1, and give a criterion identifying near- optimal subspaces for Gel'fand n-widths. We show that \"most\" subspaces are near-optimal, and show that convex optimization (Basis Pursuit) is a near-optimal way to extract information derived from these near-optimal subspaces","title":"Compressed sensing","venue":"IEEE Transactions on Information Theory","year":2006,"__v":0,"citationCount":6079,"parents":{"036a19f8-fdca-4e84-a237-e54f2108dcb4":2.941176470588235,"05c85ace-c998-47cd-a285-f6ecfd72004d":14.705882352941178,"0bb77e7f-bfc4-4d0d-873a-3d6d3c28b316":8.823529411764707,"0ed39048-dd26-467a-bcd5-7017fcccddb5":2.941176470588235,"225591b8-1c1a-4854-81d4-5b5f364c20a9":11.76470588235294,"2862ec34-58f4-41c0-8790-1740130f1814":8.823529411764707,"2a15f947-2402-4979-94b8-53de9ceef26e":0,"3d414a5e-b97a-498e-8a75-920997235c6b":5.88235294117647,"3dd913b8-e22d-434e-9015-bf68fbbb7bef":8.823529411764707,"3ddea798-1e4f-408a-86db-a611c7bbcdcf":14.705882352941178,"449bfdfc-f916-422c-ac0d-ebfdd2ab773a":8.823529411764707,"4c9f2bac-2f23-4170-a0f1-a3001f63a7b9":5.88235294117647,"5eb8608d-d0a1-4f14-af98-8a26bab51fae":2.941176470588235,"71a18de9-e543-4337-ab7a-3db31d9f8c00":14.705882352941178,"7291a02d-1d94-48b7-a4e2-35406c0e52ad":0,"834863b2-34f0-40dc-b4d2-f4189eaa262a":2.941176470588235,"87a4faed-c1a5-45c8-81eb-3bf19ae19011":2.941176470588235,"8dd4158a-bbc4-40cf-a4d5-14e0fe630387":0,"9b021b12-2e59-42bc-9e29-86e480e652b7":0,"9e65914c-bfef-45e7-9fd7-85c39ed13ac4":0,"a53a3dda-b003-4d5c-96b1-e9afd8e35692":17.647058823529413,"adc31a96-1f8e-4793-8ee9-ecef04a16ac6":20.588235294117645,"ae4ab999-5078-4348-9a3d-94c019952bcc":2.941176470588235,"aecf8a08-eff7-4182-8bbb-a7b29de2f281":0,"bb3c38fa-c2b0-4d4f-8c9d-ca1884343474":0,"c380b798-6583-4821-9613-0a9731b1ced1":0,"c9bf7235-7aad-4e6d-a9a6-e4a6bbddc327":0,"ca546a51-ffda-46b1-b783-ff512ec9c4bd":0,"cd9bd50b-d672-43a9-b0c2-0b332cf0b88e":0,"d2104367-6389-4b06-8dbe-bab7e05b903b":0,"d6457de8-9f03-4671-91da-f557a0ec20e0":11.76470588235294,"defc112d-f91d-4b34-9d44-bd7f702c2391":8.823529411764707,"f11bfae2-e272-4acc-b231-a9619f1e4d6c":2.941176470588235,"ff44599f-5e74-4d9b-94d3-286592973471":2.941176470588235},"keyword":{"036a19f8-fdca-4e84-a237-e54f2108dcb4":10.801779701779703,"05c85ace-c998-47cd-a285-f6ecfd72004d":10.8760101010101,"0bb77e7f-bfc4-4d0d-873a-3d6d3c28b316":11.837193362193362,"0ed39048-dd26-467a-bcd5-7017fcccddb5":7.234307359307359,"225591b8-1c1a-4854-81d4-5b5f364c20a9":11.466666666666667,"2862ec34-58f4-41c0-8790-1740130f1814":12.988383838383838,"2a15f947-2402-4979-94b8-53de9ceef26e":9.263506493506494,"3d414a5e-b97a-498e-8a75-920997235c6b":11.617222222222225,"3dd913b8-e22d-434e-9015-bf68fbbb7bef":11.00050505050505,"3ddea798-1e4f-408a-86db-a611c7bbcdcf":10.249206349206347,"449bfdfc-f916-422c-ac0d-ebfdd2ab773a":10.56111111111111,"4c9f2bac-2f23-4170-a0f1-a3001f63a7b9":8.426378066378067,"5eb8608d-d0a1-4f14-af98-8a26bab51fae":9.04688552188552,"71a18de9-e543-4337-ab7a-3db31d9f8c00":11.45631313131313,"7291a02d-1d94-48b7-a4e2-35406c0e52ad":11.347113997113997,"834863b2-34f0-40dc-b4d2-f4189eaa262a":9.889644244644245,"87a4faed-c1a5-45c8-81eb-3bf19ae19011":10.664393939393939,"8dd4158a-bbc4-40cf-a4d5-14e0fe630387":0,"9b021b12-2e59-42bc-9e29-86e480e652b7":11.398319735819733,"9e65914c-bfef-45e7-9fd7-85c39ed13ac4":11.476493506493506,"a53a3dda-b003-4d5c-96b1-e9afd8e35692":7.526010101010101,"adc31a96-1f8e-4793-8ee9-ecef04a16ac6":9.88794372294372,"ae4ab999-5078-4348-9a3d-94c019952bcc":12.492261904761905,"aecf8a08-eff7-4182-8bbb-a7b29de2f281":10.565824915824916,"bb3c38fa-c2b0-4d4f-8c9d-ca1884343474":11.580497835497834,"c380b798-6583-4821-9613-0a9731b1ced1":10.966835016835017,"c9bf7235-7aad-4e6d-a9a6-e4a6bbddc327":10.850204425204424,"ca546a51-ffda-46b1-b783-ff512ec9c4bd":12.078234728234726,"cd9bd50b-d672-43a9-b0c2-0b332cf0b88e":0,"d2104367-6389-4b06-8dbe-bab7e05b903b":8.481565656565655,"d6457de8-9f03-4671-91da-f557a0ec20e0":9.935569985569986,"defc112d-f91d-4b34-9d44-bd7f702c2391":11.268037518037518,"f11bfae2-e272-4acc-b231-a9619f1e4d6c":12.112373737373737,"ff44599f-5e74-4d9b-94d3-286592973471":11.384977152477148},"topic":["measur","reconstruct","nwidth","nonadapt","linear"],"offsprings":["69b9ef96-11d5-49b0-9ae3-492763e02ca8","6ff01654-66d1-49c7-b526-1c8ed7fa893a","71a18de9-e543-4337-ab7a-3db31d9f8c00","e537d143-155e-4ca0-8ae8-66b777a77fea","d28acb36-5766-4c1e-8d57-a55c2630bd90"]},"18b17dbd-4f51-411e-a099-efadf521f0d8":{"authors":["Sebastian Thrun"],"references":[],"_id":"18b17dbd-4f51-411e-a099-efadf521f0d8","abstract":"Planning and navigation algorithms exploit statistics gleaned from uncertain, imperfect real-world environments to guide robots toward their goals and around obstacles.","title":"Probabilistic robotics","venue":"Communications of The ACM","year":2002,"__v":0,"citationCount":1763,"parents":{"23899f66-b427-4812-a5f2-2560bf61a021":0,"2cac4975-4818-4298-b305-17fde77e1468":0,"2f6aab3a-b918-4352-b62a-95ef59820db7":0,"fb56fd49-66d7-4be9-bba4-fa68c22ac036":20,"fde4b4fa-da54-47b6-a633-546e06279007":0},"keyword":{"23899f66-b427-4812-a5f2-2560bf61a021":12.15667869167869,"2cac4975-4818-4298-b305-17fde77e1468":8.994603174603176,"2f6aab3a-b918-4352-b62a-95ef59820db7":0,"fb56fd49-66d7-4be9-bba4-fa68c22ac036":8.974398749398748,"fde4b4fa-da54-47b6-a633-546e06279007":10.509550264550263},"topic":["uncertain","statist","robot","realworld","plan"],"offsprings":[]},"a4589cfe-15e7-4c34-9349-d002d1d2c9df":{"authors":["Zdzisław Pawlak","Jerzy W. Grzymala-Busse","Roman Słowiński","Wojciech Ziarko"],"references":[],"_id":"a4589cfe-15e7-4c34-9349-d002d1d2c9df","abstract":"Rough set theory, introduced by Zdzislaw Pawlak in the early 1980s [11, 12], is a new mathematical tool to deal with vagueness and uncertainty. This approach seems to be of fundamental importance to artificial intelligence (AI) and cognitive sciences, especially in the areas of machine learning, knowledge acquisition, decision analysis, knowledge discovery from databases, expert systems, decision support systems, inductive reasoning, and pattern recognition.","title":"Rough sets","venue":"Communications of The ACM","year":1995,"__v":0,"citationCount":4230,"parents":{"009f5e3c-0563-4b9e-8043-699830d26bef":0,"2e7e7fab-d46d-41bc-b25d-7606e3e0d06a":0,"2f3a8585-9b54-4626-a850-85203001833d":0,"443d32e3-8a72-4e5b-9cb0-556634c2ee20":0,"48ebd80e-73f7-4f62-8649-a4f34c847942":0,"5f649893-202d-4c96-bcc8-46478a4b66a3":0,"5fa93210-d338-41f6-8f02-a0f138a795d0":0,"66b473fd-99ff-4726-8d3b-3d361c946af0":4,"75646af2-b6bc-4b6f-be00-ac6021efc8f8":0,"82cce1e6-f9e7-4e9f-99cd-ee0dd11af6b7":0,"889d1db1-bdd0-44c9-ba08-ae6189cfb816":4,"8dfb162a-4ddd-4ba0-bc87-85e655de63f7":0,"8e84b14b-1884-43cb-9875-13a36dfd8f96":0,"95a0cbd5-91d5-4f59-baa6-a8a686b00b3d":0,"ab3a5eac-a819-4d55-92ef-340384f684f0":0,"b2452c3b-1101-4269-a1c8-3b18c799ff33":0,"ba1c3e5a-4a9d-4e3b-a896-f4441617ef9d":0,"c4149669-25fd-43bb-8ab7-fa36774e6c08":0,"c79577d9-915c-493f-a8c1-b6f3830385ff":20,"d2458f99-de48-479f-889e-5182c9894e24":0,"d6b62ece-74f2-4226-b642-8f1548cb22c2":4,"ddb20465-555c-4898-92f6-8121b99085b3":0,"ddd99439-c889-4774-bc99-eda0560c0d32":0,"f22188fc-46e5-456d-bdde-16173d45a450":4,"fb142274-fb51-4995-9e18-f9d9223bf2a5":0},"keyword":{"009f5e3c-0563-4b9e-8043-699830d26bef":0,"2e7e7fab-d46d-41bc-b25d-7606e3e0d06a":0,"2f3a8585-9b54-4626-a850-85203001833d":0,"443d32e3-8a72-4e5b-9cb0-556634c2ee20":0,"48ebd80e-73f7-4f62-8649-a4f34c847942":0,"5f649893-202d-4c96-bcc8-46478a4b66a3":8.334126984126984,"5fa93210-d338-41f6-8f02-a0f138a795d0":9.824999999999996,"66b473fd-99ff-4726-8d3b-3d361c946af0":8.988492063492062,"75646af2-b6bc-4b6f-be00-ac6021efc8f8":8.562676767676768,"82cce1e6-f9e7-4e9f-99cd-ee0dd11af6b7":6.94563492063492,"889d1db1-bdd0-44c9-ba08-ae6189cfb816":8.480555555555553,"8dfb162a-4ddd-4ba0-bc87-85e655de63f7":0,"8e84b14b-1884-43cb-9875-13a36dfd8f96":8.336363636363636,"95a0cbd5-91d5-4f59-baa6-a8a686b00b3d":0,"ab3a5eac-a819-4d55-92ef-340384f684f0":7.594444444444443,"b2452c3b-1101-4269-a1c8-3b18c799ff33":9.077275132275131,"ba1c3e5a-4a9d-4e3b-a896-f4441617ef9d":0,"c4149669-25fd-43bb-8ab7-fa36774e6c08":8.571693121693121,"c79577d9-915c-493f-a8c1-b6f3830385ff":9.160648148148146,"d2458f99-de48-479f-889e-5182c9894e24":8.59126984126984,"d6b62ece-74f2-4226-b642-8f1548cb22c2":0,"ddb20465-555c-4898-92f6-8121b99085b3":9.76222222222222,"ddd99439-c889-4774-bc99-eda0560c0d32":0,"f22188fc-46e5-456d-bdde-16173d45a450":0,"fb142274-fb51-4995-9e18-f9d9223bf2a5":8.149603174603174},"topic":["system","knowledg","decis","zdzislaw","vagu"],"offsprings":["685b313d-8a77-481e-9456-e405a1d29549"]},"f6bd8b64-684d-429a-aab5-8ff3a2c23cd6":{"authors":["Leo Breiman"],"references":["3704f939-09a2-4e9f-b851-1261bcd310df"],"_id":"f6bd8b64-684d-429a-aab5-8ff3a2c23cd6","abstract":"Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund & R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, aaa, 148–156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.","title":"Random Forests","venue":"Machine Learning","year":2001,"__v":0,"citationCount":7968,"parents":{"0e9dc5ee-f078-4894-8f90-c3b1272da979":14.285714285714285,"0f115eea-2272-431f-9f21-6d6789b2bbc9":0,"17f811d8-8607-4270-bbec-1cc7883edd68":14.285714285714285,"3704f939-09a2-4e9f-b851-1261bcd310df":4.761904761904762,"3ae9664a-bf6f-45d2-852f-bba9b47e2b8a":9.523809523809524,"504ab3f2-f826-411f-b3fd-02d2019c3844":9.523809523809524,"5242f101-1511-4660-9a4c-4eb597aaa3c6":4.761904761904762,"64abe8f5-cc63-4666-a4fe-d9c3c88db207":0,"67046388-ae78-4aa4-ad8a-4f012858f6fb":23.809523809523807,"7cd3d1bf-4df0-46c8-9e75-701534e5d93c":0,"9e1ac4ec-85bf-4b41-b3f1-d12264b9352b":0,"bd34fa58-2c96-4101-a068-2ef6368e2c6a":0,"becc43bc-a7b6-46e1-817e-553c84a4a6dd":14.285714285714285,"c88edc45-936d-4cda-9d12-1a7a21cdb651":14.285714285714285,"d3b865bc-69e2-4426-9e7a-d01f0180a3ec":0,"d9809d9a-ccf7-44a2-9073-3ed158f9057f":4.761904761904762,"dc5dbb29-71b6-42e7-9e6b-8a1afdeeaee4":14.285714285714285,"ebbbb0e3-5789-4dd0-b5f3-a911e59df314":4.761904761904762,"f780a374-9a90-4ce3-951d-071db1e0ba9e":0,"f98f3e2b-d93b-4c34-bb55-f2acc0cddab6":14.285714285714285,"ffe77764-a254-4316-887e-c65bd4da6185":0},"keyword":{"0e9dc5ee-f078-4894-8f90-c3b1272da979":10.102513227513224,"0f115eea-2272-431f-9f21-6d6789b2bbc9":0,"17f811d8-8607-4270-bbec-1cc7883edd68":11.30111111111111,"3704f939-09a2-4e9f-b851-1261bcd310df":12.005714285714284,"3ae9664a-bf6f-45d2-852f-bba9b47e2b8a":10.39074074074074,"504ab3f2-f826-411f-b3fd-02d2019c3844":8.059126984126983,"5242f101-1511-4660-9a4c-4eb597aaa3c6":12.194444444444443,"64abe8f5-cc63-4666-a4fe-d9c3c88db207":11.961428571428574,"67046388-ae78-4aa4-ad8a-4f012858f6fb":9.765476190476189,"7cd3d1bf-4df0-46c8-9e75-701534e5d93c":10.113809523809525,"9e1ac4ec-85bf-4b41-b3f1-d12264b9352b":11.030555555555553,"bd34fa58-2c96-4101-a068-2ef6368e2c6a":13.47190476190476,"becc43bc-a7b6-46e1-817e-553c84a4a6dd":10.950396825396824,"c88edc45-936d-4cda-9d12-1a7a21cdb651":9.466984126984126,"d3b865bc-69e2-4426-9e7a-d01f0180a3ec":11.157539682539682,"d9809d9a-ccf7-44a2-9073-3ed158f9057f":5.800952380952381,"dc5dbb29-71b6-42e7-9e6b-8a1afdeeaee4":10.319047619047618,"ebbbb0e3-5789-4dd0-b5f3-a911e59df314":10.882222222222222,"f780a374-9a90-4ce3-951d-071db1e0ba9e":10.293939393939395,"f98f3e2b-d93b-4c34-bb55-f2acc0cddab6":9.88148148148148,"ffe77764-a254-4316-887e-c65bd4da6185":11.279259259259257},"topic":["tree","forest","error","random","intern"],"groups":[{"authors":["Ludmila I. Kuncheva","James C. Bezdek","Robert P. W. Duin"],"references":["380e23c7-5122-4f33-81ae-0242742150a9","434a52fb-6f63-453d-a035-534a8aa6ae30","46510028-2e6e-4ac6-a306-b63fdac85019","5206bed9-d48d-44ab-b0cd-4731dfe5679c","6679e3d1-e19f-4a48-8a86-8538631e364e","702936e6-7107-428b-b3ca-2bc64e785519","7d1ebe05-c398-4d42-878f-a318fc5a0f57","98ba2286-da81-41ca-9050-ede2e94e550d","9e1ac4ec-85bf-4b41-b3f1-d12264b9352b","b889d6ec-330d-406f-87b6-ea34804fadfd","c3b374ba-8057-4dce-8510-cc83c5be2e00","cdef6e1d-a973-49dc-9548-147c231c061f","d130ecec-e5cf-4f59-b4f8-1cbda4b0c307","d3b865bc-69e2-4426-9e7a-d01f0180a3ec","d44f2bdb-efce-4435-91e3-e7d8b6972604","e62ff43e-b9cf-4db3-91ad-8e1e74384a7c","ea3e7ab3-e7c2-4007-93db-5c459bf3f42e","ebbbb0e3-5789-4dd0-b5f3-a911e59df314","f780a374-9a90-4ce3-951d-071db1e0ba9e","ffe77764-a254-4316-887e-c65bd4da6185"],"_id":"67046388-ae78-4aa4-ad8a-4f012858f6fb","abstract":"Multiple classifier fusion may generate more accurate classification than each of the constituent classifiers. Fusion is often based on fixed combination rules like the product and average. Only under strict probabilistic conditions can these rules be justified. We present here a simple rule for adapting the class combiner to the application.  c  decision templates (one per class) are estimated with the same training set that is used for the set of classifiers. These templates are then matched to the decision profile of new incoming objects by some similarity measure. We compare 11 versions of our model with 14 other techniques for classifier fusion on the Satimage and Phoneme datasets from the database ELENA. Our results show that decision templates based on  integral  type measures of similarity are superior to the other schemes on both data sets.","title":"Decision templates for multiple classifier fusion: an experimental comparison","venue":"Pattern Recognition","year":2001,"__v":0,"citationCount":413}],"offsprings":["e2f7a74a-8430-4463-94ce-fe85dfd309f9","d28acb36-5766-4c1e-8d57-a55c2630bd90"]},"57ffaea2-7fcc-4245-b9a9-59cfc77ee358":{"authors":["Erhard Rahm","Philip A. Bernstein"],"references":[],"_id":"57ffaea2-7fcc-4245-b9a9-59cfc77ee358","abstract":"Schema matching is a basic problem in many database application domains, such as data integration, E-business, data warehousing, and semantic query processing. In current implementations, schema matching is typically performed manually, which has significant limitations. On the other hand, previous research papers have proposed many techniques to achieve a partial automation of the match operation for specific application domains. We present a taxonomy that covers many of these existing approaches, and we describe the approaches in some detail. In particular, we distinguish between schema-level and instance-level, element-level and structure-level, and language-based and constraint-based matchers. Based on our classification we review some previous match implementations thereby indicating which part of the solution space they cover. We intend our taxonomy and review of past work to be useful when comparing different approaches to schema matching, when developing a new match algorithm, and when implementing a schema matching component.","title":"A survey of approaches to automatic schema matching","venue":"very large data bases","year":2001,"__v":0,"citationCount":1716,"parents":{"04de8552-8154-4a21-b654-40631a9f58ff":0,"13adaec3-7c30-484b-a395-582d82d93d06":5.263157894736842,"18fcee90-9582-4e29-b6de-e2c21d3b5166":0,"1cd1c40b-dacc-4619-ba48-65b96cd65ecb":0,"3f3410a6-8e3b-4ea9-a73a-e32147c2fce8":10.526315789473683,"4d8d76d9-803a-4c50-8806-5317a5507fc9":2.631578947368421,"56f783da-5096-4052-95fd-b2f51b28dc6c":0,"6b62c91b-0448-4e50-9499-4e8725a355da":0,"6e7e72cf-74cd-4cf9-9534-189f0f419c43":2.631578947368421,"71699228-335d-4a7c-b04f-8ac234641f99":10.526315789473683,"7252d052-0d44-4396-905d-f9715765dffc":0,"7fc5bab5-fcbd-4b2c-8df2-0a5dcbae1a2a":0,"815fad3f-ee6f-4c73-8487-79f8b3c1269c":0,"855165b7-42e7-4fbe-924d-b4d04d1a7d7c":5.263157894736842,"85b83c70-d58e-4ff7-bc75-999312715d9a":2.631578947368421,"8d6e8fd5-6bca-4862-ad26-4dfa7448dc57":0,"8ddc2cfc-5943-4148-848b-4ab81036e07c":7.894736842105263,"9007e237-158a-4afb-9b1c-80e2a8274d02":5.263157894736842,"90f1fc54-bc22-4cbf-90b0-0b220f507b37":0,"913a7082-f2c2-421f-a493-ecdca4aa7e22":0,"91556b20-c53e-4687-82e2-7c3c1e893f0b":26.31578947368421,"92cfc188-132d-4f65-97bd-bf41ac28eac8":0,"957e9b71-d9ea-4e3c-ae8d-2804acf102f9":5.263157894736842,"975107a3-98ae-4f72-9354-1836fb105ea5":7.894736842105263,"9b3dc074-a9c0-4ee5-bbfd-4c2c82ca3524":5.263157894736842,"a69a01e7-1b99-4857-8def-3db7473fad1a":5.263157894736842,"a797b9a0-f494-43a6-8872-8642982b42c8":5.263157894736842,"b6ce43fa-0269-4351-a480-3918f49c3337":13.157894736842104,"bc98fd4d-1ef3-41d3-8123-7b5df2ff7dce":2.631578947368421,"c45bbd4d-7a5a-47e2-a381-188c58888227":5.263157894736842,"cb6a58fe-c8b8-4797-bdf7-3ab41c6df918":13.157894736842104,"d82fd0ba-ab68-4524-b2b1-9e406a166d01":2.631578947368421,"da9b3e85-367a-4b26-9757-4be26af76bfc":7.894736842105263,"dc8d7f56-3f1d-4dfd-8399-aea4b7d2ec7b":7.894736842105263,"de99c993-9093-460a-add1-ec4b68eb1506":5.263157894736842,"e26f74ef-22e7-41ac-a3b1-900a9c7aa3fb":0,"eb56cb3c-fd5f-482a-93d8-db29dfae051d":0,"f47687ef-397f-4414-96e1-97d0b5cd43b0":0},"keyword":{"04de8552-8154-4a21-b654-40631a9f58ff":0,"13adaec3-7c30-484b-a395-582d82d93d06":11.476058201058201,"18fcee90-9582-4e29-b6de-e2c21d3b5166":7.015277777777777,"1cd1c40b-dacc-4619-ba48-65b96cd65ecb":11.5075,"3f3410a6-8e3b-4ea9-a73a-e32147c2fce8":8.63962962962963,"4d8d76d9-803a-4c50-8806-5317a5507fc9":10.479259259259257,"56f783da-5096-4052-95fd-b2f51b28dc6c":0,"6b62c91b-0448-4e50-9499-4e8725a355da":10.446560846560844,"6e7e72cf-74cd-4cf9-9534-189f0f419c43":12.9,"71699228-335d-4a7c-b04f-8ac234641f99":10.891481481481481,"7252d052-0d44-4396-905d-f9715765dffc":0,"7fc5bab5-fcbd-4b2c-8df2-0a5dcbae1a2a":0,"815fad3f-ee6f-4c73-8487-79f8b3c1269c":10.636111111111108,"855165b7-42e7-4fbe-924d-b4d04d1a7d7c":0,"85b83c70-d58e-4ff7-bc75-999312715d9a":10.425304232804233,"8d6e8fd5-6bca-4862-ad26-4dfa7448dc57":11.207222222222223,"8ddc2cfc-5943-4148-848b-4ab81036e07c":11.573875661375663,"9007e237-158a-4afb-9b1c-80e2a8274d02":11.902777777777779,"90f1fc54-bc22-4cbf-90b0-0b220f507b37":9.41574074074074,"913a7082-f2c2-421f-a493-ecdca4aa7e22":11.419444444444444,"91556b20-c53e-4687-82e2-7c3c1e893f0b":12.564814814814813,"92cfc188-132d-4f65-97bd-bf41ac28eac8":11.41074074074074,"957e9b71-d9ea-4e3c-ae8d-2804acf102f9":0,"975107a3-98ae-4f72-9354-1836fb105ea5":0,"9b3dc074-a9c0-4ee5-bbfd-4c2c82ca3524":11.465555555555556,"a69a01e7-1b99-4857-8def-3db7473fad1a":0,"a797b9a0-f494-43a6-8872-8642982b42c8":10.321560846560846,"b6ce43fa-0269-4351-a480-3918f49c3337":10.905820105820105,"bc98fd4d-1ef3-41d3-8123-7b5df2ff7dce":10.005026455026453,"c45bbd4d-7a5a-47e2-a381-188c58888227":0,"cb6a58fe-c8b8-4797-bdf7-3ab41c6df918":11.34925925925926,"d82fd0ba-ab68-4524-b2b1-9e406a166d01":9.904999999999998,"da9b3e85-367a-4b26-9757-4be26af76bfc":10.483148148148146,"dc8d7f56-3f1d-4dfd-8399-aea4b7d2ec7b":11.849907407407407,"de99c993-9093-460a-add1-ec4b68eb1506":11.061997354497354,"e26f74ef-22e7-41ac-a3b1-900a9c7aa3fb":0,"eb56cb3c-fd5f-482a-93d8-db29dfae051d":10.522619047619045,"f47687ef-397f-4414-96e1-97d0b5cd43b0":10.358888888888888},"topic":["match","schema","implement","approach","taxonomi"],"groups":[{"authors":["Jayant Madhavan","Philip A. Bernstein","Erhard Rahm"],"references":["4d8d76d9-803a-4c50-8806-5317a5507fc9","56f783da-5096-4052-95fd-b2f51b28dc6c","6e7e72cf-74cd-4cf9-9534-189f0f419c43","85b83c70-d58e-4ff7-bc75-999312715d9a","8d6e8fd5-6bca-4862-ad26-4dfa7448dc57","8ddc2cfc-5943-4148-848b-4ab81036e07c","9007e237-158a-4afb-9b1c-80e2a8274d02","975107a3-98ae-4f72-9354-1836fb105ea5","9b3dc074-a9c0-4ee5-bbfd-4c2c82ca3524","b6ce43fa-0269-4351-a480-3918f49c3337"],"_id":"91556b20-c53e-4687-82e2-7c3c1e893f0b","abstract":"Schema matching is a critical step in many applications, such as XML message mapping, data warehouse loading, and schema integration. In this paper, we investigate algorithms for generic schema matching, outside of any particular data model or application. We first present a taxonomy for past solutions, showing that a rich range of techniques is available. We then propose a new algorithm, Cupid, that discovers mappings between schema elements based on their names, data types, constraints, and schema structure, using a broader set of techniques than past approaches. Some of our innovations are the integrated use of linguistic and structural matching, context-dependent matching of shared types, and a bias toward leaf structure where much of the schema content resides. After describing our algorithm, we present experimental results that compare Cupid to two other schema matching systems.","title":"Generic Schema Matching with Cupid","venue":"very large data bases","year":2001,"__v":0,"citationCount":689}],"offsprings":[]},"64316b39-e0c7-493d-8d84-b93cc5cb291c":{"authors":["Christian Bizer","Tom Heath","Tim Berners-Lee"],"references":["c7e4e04b-45da-4bae-8c8a-d17ca0087361"],"_id":"64316b39-e0c7-493d-8d84-b93cc5cb291c","abstract":"The term “Linked Data” refers to a set of best practices for publishing and connecting structured data on the Web. These best practices have been adopted by an increasing number of data providers over the last three years, leading to the creation of a global data space containing billions of assertions— the Web of Data. In this article, the authors present the concept and technical principles of Linked Data, and situate these within the broader context of related technological developments. They describe progress to date in publishing Linked Data on the Web, review applications that have been developed to exploit the Web of Data, and map out a research agenda for the Linked Data community as it moves forward.","title":"Linked Data - The Story So Far","venue":"International Journal on Semantic Web and Information Systems","year":2009,"__v":0,"citationCount":1774,"parents":{"072f21f2-80fe-4d61-b92d-6df0baed1c5f":0,"148fa79e-c2f5-43eb-a6b2-c800fe4043dc":0,"16fbe51f-8a05-4f17-92c0-6f9e77e68dc4":9.090909090909092,"25fc71f6-f2b7-4b23-b041-5c5c2f9e85ff":0,"28994c1f-f220-4156-a6da-17cff4a55a61":0,"2cba753f-24b1-4b6c-8d36-b9bf66bd1477":0,"2ec64d23-a043-4fb2-a009-5bc118799dea":4.545454545454546,"32ecf97c-6c56-4da0-9ccc-ea0283a986a7":2.272727272727273,"34ef9da0-1299-4b2e-a8bb-812785c1e82f":0,"3e144fbb-e31c-4abc-a401-c3aa691426af":0,"42061e33-34a0-4e22-bf83-e363df6b6af6":4.545454545454546,"4790f56b-6a02-4a46-9d36-92a12c5e2c68":0,"5f5d6ff5-c2e0-48e0-88e2-db3b35cefdd9":0,"63d6a7df-2664-4d48-b509-a93e246bc3a2":0,"698b261e-6c56-4b79-b76c-aad50baad381":9.090909090909092,"760cff06-6d50-4e32-8e8b-2e98cb7e8a8c":0,"77abe687-a569-45ac-b44c-69c23c8a78e2":0,"798b4551-17eb-4879-8ff6-2e2ae7ff4711":4.545454545454546,"7bf3b490-2540-476e-bcb1-0856e651d39f":2.272727272727273,"7cbc5993-3315-4068-b3e4-89ee61442e2a":6.8181818181818175,"8007c978-178b-48c9-a50a-3e2285e4f5f4":2.272727272727273,"8a69b759-d2e2-4a66-bf7f-2daa527e817b":6.8181818181818175,"9625e8f6-1024-4c44-a4ce-636f60a0a6d4":0,"98c1a237-f76c-4f09-85d0-973a30d9817f":0,"99a31d4a-dfce-4e2c-ba93-416cd5d4fe57":0,"9b9db0e1-5192-4fe7-8b3b-6de5527b2e11":0,"9d846edf-96ea-4276-b16e-7633f54111e1":9.090909090909092,"a8a89f5e-8861-4b4f-95ed-922920bcfe3e":4.545454545454546,"aa8790a3-ed79-4e91-a9d3-cf2cfcb6aa22":2.272727272727273,"b99ef803-0012-42c3-bc08-4ce6e54cbbff":0,"bd95982d-8667-4528-ade9-a0c5c07f22c9":0,"c2a66f69-3b81-47f9-9f8e-ef36f182db8c":2.272727272727273,"c7e4e04b-45da-4bae-8c8a-d17ca0087361":0,"cb978e00-398c-467a-a21d-b9529cb52baa":4.545454545454546,"cbdc240d-1118-4412-88a4-d41e2ab99263":4.545454545454546,"cceeb27b-55b4-4117-a3d2-ecfc66dac0fe":0,"d031f5ca-ab53-4cd7-bc71-083d653839fb":0,"ddaec79c-d9ff-4ae3-8dcb-2370f18e38fc":9.090909090909092,"e022bd60-1922-492c-a2db-70b5b301918d":0,"e7c25c9e-4bce-4c76-927a-803cd1ddbe16":0,"e90e991b-2c18-4b04-bb76-10e1de372e89":0,"f02008eb-9c90-4cdf-bcd6-cd8a4847efba":0,"fc8962d5-95e5-4f97-a42f-ff62ebc6bf7a":2.272727272727273,"fe988391-7cd6-4ba9-9b2c-0ef1ff7efd00":0},"keyword":{"072f21f2-80fe-4d61-b92d-6df0baed1c5f":0,"148fa79e-c2f5-43eb-a6b2-c800fe4043dc":7.4452380952380945,"16fbe51f-8a05-4f17-92c0-6f9e77e68dc4":6.779365079365079,"25fc71f6-f2b7-4b23-b041-5c5c2f9e85ff":0,"28994c1f-f220-4156-a6da-17cff4a55a61":7.946957671957671,"2cba753f-24b1-4b6c-8d36-b9bf66bd1477":6.955158730158731,"2ec64d23-a043-4fb2-a009-5bc118799dea":0,"32ecf97c-6c56-4da0-9ccc-ea0283a986a7":7.644841269841269,"34ef9da0-1299-4b2e-a8bb-812785c1e82f":5.787301587301586,"3e144fbb-e31c-4abc-a401-c3aa691426af":8.202380952380954,"42061e33-34a0-4e22-bf83-e363df6b6af6":5.65952380952381,"4790f56b-6a02-4a46-9d36-92a12c5e2c68":7.705952380952381,"5f5d6ff5-c2e0-48e0-88e2-db3b35cefdd9":7.026719576719576,"63d6a7df-2664-4d48-b509-a93e246bc3a2":5.0968253968253965,"698b261e-6c56-4b79-b76c-aad50baad381":7.102777777777778,"760cff06-6d50-4e32-8e8b-2e98cb7e8a8c":9.612830687830687,"77abe687-a569-45ac-b44c-69c23c8a78e2":8.387301587301588,"798b4551-17eb-4879-8ff6-2e2ae7ff4711":8.173809523809524,"7bf3b490-2540-476e-bcb1-0856e651d39f":9.054761904761904,"7cbc5993-3315-4068-b3e4-89ee61442e2a":6.055555555555555,"8007c978-178b-48c9-a50a-3e2285e4f5f4":7.653174603174603,"8a69b759-d2e2-4a66-bf7f-2daa527e817b":7.065873015873016,"9625e8f6-1024-4c44-a4ce-636f60a0a6d4":6.828571428571428,"98c1a237-f76c-4f09-85d0-973a30d9817f":6.583333333333333,"99a31d4a-dfce-4e2c-ba93-416cd5d4fe57":6.624603174603174,"9b9db0e1-5192-4fe7-8b3b-6de5527b2e11":7.6912698412698415,"9d846edf-96ea-4276-b16e-7633f54111e1":5.755555555555555,"a8a89f5e-8861-4b4f-95ed-922920bcfe3e":0,"aa8790a3-ed79-4e91-a9d3-cf2cfcb6aa22":6.81031746031746,"b99ef803-0012-42c3-bc08-4ce6e54cbbff":7.5809523809523816,"bd95982d-8667-4528-ade9-a0c5c07f22c9":8.942857142857143,"c2a66f69-3b81-47f9-9f8e-ef36f182db8c":8.880952380952381,"c7e4e04b-45da-4bae-8c8a-d17ca0087361":9.503306878306876,"cb978e00-398c-467a-a21d-b9529cb52baa":8.992063492063492,"cbdc240d-1118-4412-88a4-d41e2ab99263":6.76904761904762,"cceeb27b-55b4-4117-a3d2-ecfc66dac0fe":7.502380952380952,"d031f5ca-ab53-4cd7-bc71-083d653839fb":7.683730158730159,"ddaec79c-d9ff-4ae3-8dcb-2370f18e38fc":7.382936507936508,"e022bd60-1922-492c-a2db-70b5b301918d":7.636904761904762,"e7c25c9e-4bce-4c76-927a-803cd1ddbe16":7.93095238095238,"e90e991b-2c18-4b04-bb76-10e1de372e89":9.40959595959596,"f02008eb-9c90-4cdf-bcd6-cd8a4847efba":0,"fc8962d5-95e5-4f97-a42f-ff62ebc6bf7a":6.942063492063492,"fe988391-7cd6-4ba9-9b2c-0ef1ff7efd00":8.751785714285713},"topic":["data","web","link","publish","practic"],"offsprings":[]},"685b313d-8a77-481e-9456-e405a1d29549":{"authors":["Ron Kohavi","George H. John"],"references":["a4589cfe-15e7-4c34-9349-d002d1d2c9df","fcb41378-32f7-4aab-8458-fc5a99d74f92"],"_id":"685b313d-8a77-481e-9456-e405a1d29549","abstract":"Copyright (c) 1997 Elsevier Science B.V. All rights reserved. In the feature subset selection problem, a learning algorithm is faced with the problem of selecting a relevant subset of features upon which to focus its attention, while ignoring the rest. To achieve the best possible performance with a particular learning algorithm on a particular training set, a feature subset selection method should consider how the algorithm and the training set interact. We explore the relation between optimal feature subset selection and relevance. Our wrapper method searches for an optimal feature subset tailored to a particular algorithm and a domain. We study the strengths and weaknesses of the wrapper approach and show a series of improved designs. We compare the wrapper approach to induction without feature subset selection and to Relief, a filter approach to feature subset selection. Significant improvement in accuracy is achieved for some datasets for the two families of induction algorithms used: decision trees and Naive-Bayes.","title":"Wrappers for feature subset selection","venue":"Artificial Intelligence","year":1997,"__v":0,"citationCount":2579,"parents":{"0587052d-9988-4c3f-8f82-3ffcf8da7c86":1.6129032258064515,"0cc7f81d-3960-4e11-ab65-5406091a49d8":0,"0f115eea-2272-431f-9f21-6d6789b2bbc9":1.6129032258064515,"0f240e79-dd13-4510-a19a-64586438f8d5":14.516129032258066,"119792fb-54c1-49f5-8648-13d24b19ecf5":4.838709677419355,"1570e0c2-bcf6-4f5a-92db-d1b0936d68d3":0,"245e4043-ccdb-457a-9be1-e120c7a94753":19.35483870967742,"34ea7fc5-8b5a-46d6-aa41-155442792ab0":0,"36313bb8-e0c2-4900-a399-3e772f9f51dc":0,"36338d50-6305-4d9f-9065-cde919913bfb":17.741935483870968,"3a90b5d2-3377-4ffa-9545-9ef332679370":0,"3b85426c-08c7-4299-af41-3d0140325e56":4.838709677419355,"43e502f4-87f2-4672-9217-823cf6c56e56":3.225806451612903,"485598b2-ed73-4670-a44d-b0844f923fa4":0,"4b0df874-c029-4993-9c36-50e795192cfb":3.225806451612903,"4de0dbe7-3582-4125-94be-d0c36ea097fc":17.741935483870968,"522e1bb9-8ec7-448b-a6ea-7e08b3b6b205":0,"60ac157b-ad14-49c3-a901-6673c71cdb9d":8.064516129032258,"62549bc2-e0b3-46e8-8d32-390dded105d5":0,"6a6b9aa6-683f-4c7c-b06e-9c3018d10fd3":0,"6aae8997-db46-40ef-a668-78ba5736c756":8.064516129032258,"6b991684-bcc5-42ea-b160-fe79470d112b":3.225806451612903,"6c68311c-2745-446f-9c09-df4632392a78":1.6129032258064515,"755fce0d-fa7f-438e-b0b7-aa21f0a74458":0,"7a4f827a-aced-46e7-987d-5ad7f3016c32":0,"7e4a176e-5c7c-475a-b9fa-c1a5c5635a27":1.6129032258064515,"7ef53f8d-34c3-4e75-ac28-d3b86ae8fa3a":4.838709677419355,"80bcd4d1-c1cd-43a7-bc4d-42e274324933":6.451612903225806,"91b55919-de45-4ecb-8de2-7405faea114e":9.67741935483871,"9263339a-c88a-4151-baff-0e3a562420ff":6.451612903225806,"936187f8-f6c2-412c-bdd2-0b4f5d60f8df":3.225806451612903,"9c01a502-04f3-4adb-9bde-f06253818cb9":0,"9eee3b9a-cd39-4db4-8b35-151667483add":11.29032258064516,"9f1396bc-5579-40ca-abcd-17771eaba7b6":3.225806451612903,"a4589cfe-15e7-4c34-9349-d002d1d2c9df":0,"a9a79a49-3063-4d7f-a353-34df2a8175a1":1.6129032258064515,"ac237969-3fd5-4303-83b7-a67e02afe976":1.6129032258064515,"adab43f8-fd25-46c6-960d-54bd988c5aaa":1.6129032258064515,"b2159ee7-ace1-4e4d-982e-e6c9eb554a3e":4.838709677419355,"b49c1e2b-0cd0-4950-a724-00c698e5b49d":0,"b4fb7dd0-46d6-4db0-825d-0c01fa3e44ba":9.67741935483871,"b9214a76-78e7-484b-83ae-939f30e58583":1.6129032258064515,"bdba5fe6-dc9e-4e25-b49a-1bff29f3f0c8":1.6129032258064515,"c8ca0fbb-6cf7-4678-bdbc-d52a93446d31":3.225806451612903,"ca3e323a-57d3-4d3d-835f-c5d9c0c1001a":3.225806451612903,"ce028c76-6040-4f87-b8e7-d6741ce9d1c4":4.838709677419355,"cf740e2c-f5bf-4e0c-8375-2948d6dff2c7":0,"d584301a-e949-47a8-ae15-232ec53aa62b":0,"d7c2d469-53c2-4216-9af3-22dc6b4ccb1c":3.225806451612903,"da4534a6-897c-4431-89ef-cd326bfaf9a8":0,"da9219cb-fa1c-4241-a9eb-108c6699a80f":3.225806451612903,"db26488d-78be-44b1-a343-e896f43c5d29":3.225806451612903,"e1662082-8ddd-4df1-90a9-c1f30382b3d0":0,"e899cb89-58db-44be-99d7-1d318183ffc1":0,"ead81f2f-a99d-4e65-a0aa-735699199454":0,"ed748247-965b-4857-a004-7531209fa975":16.129032258064516,"eef1ec6d-1aed-47a3-831d-b0feb5432851":0,"f17bdf85-6dc4-48ec-8946-c2613678abfb":0,"f6ea2106-9ff3-4a2b-a195-6f81979f942d":1.6129032258064515,"f76331c6-7be5-4f61-bbb1-25ea462536e6":0,"fc603eb6-d237-4584-842c-c80805f31370":0,"fcb41378-32f7-4aab-8458-fc5a99d74f92":1.6129032258064515},"keyword":{"0587052d-9988-4c3f-8f82-3ffcf8da7c86":11.86084656084656,"0cc7f81d-3960-4e11-ab65-5406091a49d8":0,"0f115eea-2272-431f-9f21-6d6789b2bbc9":0,"0f240e79-dd13-4510-a19a-64586438f8d5":0,"119792fb-54c1-49f5-8648-13d24b19ecf5":12.481613756613756,"1570e0c2-bcf6-4f5a-92db-d1b0936d68d3":13.83994708994709,"245e4043-ccdb-457a-9be1-e120c7a94753":14.647619047619047,"34ea7fc5-8b5a-46d6-aa41-155442792ab0":11.343121693121692,"36313bb8-e0c2-4900-a399-3e772f9f51dc":0,"36338d50-6305-4d9f-9065-cde919913bfb":10.52116402116402,"3a90b5d2-3377-4ffa-9545-9ef332679370":11.717328042328042,"3b85426c-08c7-4299-af41-3d0140325e56":9.792857142857143,"43e502f4-87f2-4672-9217-823cf6c56e56":12.195634920634921,"485598b2-ed73-4670-a44d-b0844f923fa4":0,"4b0df874-c029-4993-9c36-50e795192cfb":0,"4de0dbe7-3582-4125-94be-d0c36ea097fc":0,"522e1bb9-8ec7-448b-a6ea-7e08b3b6b205":12.458597883597884,"60ac157b-ad14-49c3-a901-6673c71cdb9d":8.922619047619047,"62549bc2-e0b3-46e8-8d32-390dded105d5":8.40568783068783,"6a6b9aa6-683f-4c7c-b06e-9c3018d10fd3":11.395502645502646,"6aae8997-db46-40ef-a668-78ba5736c756":10.898412698412699,"6b991684-bcc5-42ea-b160-fe79470d112b":13.410714285714285,"6c68311c-2745-446f-9c09-df4632392a78":10.100529100529101,"755fce0d-fa7f-438e-b0b7-aa21f0a74458":13.283201058201058,"7a4f827a-aced-46e7-987d-5ad7f3016c32":7.505291005291003,"7e4a176e-5c7c-475a-b9fa-c1a5c5635a27":5.262626262626263,"7ef53f8d-34c3-4e75-ac28-d3b86ae8fa3a":11.30806878306878,"80bcd4d1-c1cd-43a7-bc4d-42e274324933":13.628571428571428,"91b55919-de45-4ecb-8de2-7405faea114e":11.289285714285713,"9263339a-c88a-4151-baff-0e3a562420ff":10.54457671957672,"936187f8-f6c2-412c-bdd2-0b4f5d60f8df":13.24074074074074,"9c01a502-04f3-4adb-9bde-f06253818cb9":10.207407407407409,"9eee3b9a-cd39-4db4-8b35-151667483add":12.636904761904765,"9f1396bc-5579-40ca-abcd-17771eaba7b6":11.437698412698412,"a4589cfe-15e7-4c34-9349-d002d1d2c9df":9.839550264550263,"a9a79a49-3063-4d7f-a353-34df2a8175a1":13.123412698412698,"ac237969-3fd5-4303-83b7-a67e02afe976":11.694179894179895,"adab43f8-fd25-46c6-960d-54bd988c5aaa":12.654232804232803,"b2159ee7-ace1-4e4d-982e-e6c9eb554a3e":11.56574074074074,"b49c1e2b-0cd0-4950-a724-00c698e5b49d":12.66283068783069,"b4fb7dd0-46d6-4db0-825d-0c01fa3e44ba":12.097883597883595,"b9214a76-78e7-484b-83ae-939f30e58583":12.797063492063492,"bdba5fe6-dc9e-4e25-b49a-1bff29f3f0c8":9.187301587301587,"c8ca0fbb-6cf7-4678-bdbc-d52a93446d31":12.892328042328042,"ca3e323a-57d3-4d3d-835f-c5d9c0c1001a":11.233597883597882,"ce028c76-6040-4f87-b8e7-d6741ce9d1c4":12.834920634920637,"cf740e2c-f5bf-4e0c-8375-2948d6dff2c7":11.34920634920635,"d584301a-e949-47a8-ae15-232ec53aa62b":12.815343915343917,"d7c2d469-53c2-4216-9af3-22dc6b4ccb1c":10.42089947089947,"da4534a6-897c-4431-89ef-cd326bfaf9a8":11.57484126984127,"da9219cb-fa1c-4241-a9eb-108c6699a80f":0,"db26488d-78be-44b1-a343-e896f43c5d29":0,"e1662082-8ddd-4df1-90a9-c1f30382b3d0":0,"e899cb89-58db-44be-99d7-1d318183ffc1":11.398148148148147,"ead81f2f-a99d-4e65-a0aa-735699199454":12.292724867724868,"ed748247-965b-4857-a004-7531209fa975":11.240343915343912,"eef1ec6d-1aed-47a3-831d-b0feb5432851":6.602116402116403,"f17bdf85-6dc4-48ec-8946-c2613678abfb":10.173756613756614,"f6ea2106-9ff3-4a2b-a195-6f81979f942d":13.115079365079364,"f76331c6-7be5-4f61-bbb1-25ea462536e6":11.83805453805454,"fc603eb6-d237-4584-842c-c80805f31370":11.10846560846561,"fcb41378-32f7-4aab-8458-fc5a99d74f92":10.476587301587301},"topic":["subset","featur","select","algorithm","wrapper"],"groups":[{"authors":["George H. John","Ron Kohavi","Karl Pfleger"],"references":["08c9b9dd-d9e1-4bd0-90f6-75d2b5c36a5b","0e778e62-0487-4458-965b-2320e46cc7b9","114ec450-b6e6-45b5-8269-bc8e736a1bfb","522e1bb9-8ec7-448b-a6ea-7e08b3b6b205","6aae8997-db46-40ef-a668-78ba5736c756","6fe13464-786c-4668-8c16-5b0461042e78","755fce0d-fa7f-438e-b0b7-aa21f0a74458","75d19502-167e-4873-9da7-e18968122adb","7a10be82-6113-4f60-9e37-f35f2d9423c5","7e4a176e-5c7c-475a-b9fa-c1a5c5635a27","80bcd4d1-c1cd-43a7-bc4d-42e274324933","91b55919-de45-4ecb-8de2-7405faea114e","b2159ee7-ace1-4e4d-982e-e6c9eb554a3e","b49c1e2b-0cd0-4950-a724-00c698e5b49d","b4fb7dd0-46d6-4db0-825d-0c01fa3e44ba","ce028c76-6040-4f87-b8e7-d6741ce9d1c4","da9219cb-fa1c-4241-a9eb-108c6699a80f","f51b782d-815b-4b0d-b9d6-8e676b413969","f6ea2106-9ff3-4a2b-a195-6f81979f942d"],"_id":"245e4043-ccdb-457a-9be1-e120c7a94753","abstract":"We address the problem of finding a subset of features that allows a supervised induction algorithm to induce small high-accuracy concepts. We examine notions of relevance and irrelevance, and show that the definitions used in the machine learning literature do not adequately partition the features into useful categories of relevance. We present definitions for irrelevance and for two degrees of relevance. These definitions improve our understanding of the behavior of previous subset selection algorithms, and help define the subset of features that should be sought. The features selected should depend not only on the features and the target concept, but also on the induction algorithm. We describe a method for feature subset selection using cross-validation that is applicable to any induction algorithm, and discuss experiments conducted with ID3 and C4.5 on artificial and real datasets.","title":"Irrelevant Features and the Subset Selection Problem","venue":"international conference on machine learning","year":1994,"__v":0,"citationCount":833}],"offsprings":["4fb87930-7f6c-4f03-ae22-32445138ec83","9fa61eb1-0984-4492-955a-4f7aedbdc368"]},"7ae0e791-2e2b-4504-a2fe-caa9b0589c44":{"authors":["J.N. Laneman","Gregory W. Wornell"],"references":["2659531e-eb9d-4dd5-b46f-10f66a4819c6","324c0cc6-829c-4b4f-8ef4-5f2d9b34bf58","720f59d2-acc3-4d5a-91c2-258d137d9647"],"_id":"7ae0e791-2e2b-4504-a2fe-caa9b0589c44","abstract":"We develop and analyze space-time coded cooperative diversity protocols for combating multipath fading across multiple protocol layers in a wireless network. The protocols exploit spatial diversity available among a collection of distributed terminals that relay messages for one another in such a manner that the destination terminal can average the fading, even though it is unknown a priori which terminals will be involved. In particular, a source initiates transmission to its destination, and many relays potentially receive the transmission. Those terminals that can fully decode the transmission utilize a space-time code to cooperatively relay to the destination. We demonstrate that these protocols achieve full spatial diversity in the number of cooperating terminals, not just the number of decoding relays, and can be used effectively for higher spectral efficiencies than repetition-based schemes. We discuss issues related to space-time code design for these protocols, emphasizing codes that readily allow for appealing distributed versions.","title":"Distributed space-time-coded protocols for exploiting cooperative diversity in wireless networks","venue":"IEEE Transactions on Information Theory","year":2003,"__v":0,"citationCount":2191,"parents":{"064005b0-00e1-40c6-888b-a5c7314b6c68":28.57142857142857,"2659531e-eb9d-4dd5-b46f-10f66a4819c6":0,"324c0cc6-829c-4b4f-8ef4-5f2d9b34bf58":14.285714285714285,"48a5daf3-5217-4b07-8f66-82dd2934cba6":28.57142857142857,"720f59d2-acc3-4d5a-91c2-258d137d9647":42.857142857142854,"89925ea3-ffcc-406f-9b38-432275ce2bd9":14.285714285714285,"efcbfcea-e8b0-4ca9-a883-92f42f862307":0},"keyword":{"064005b0-00e1-40c6-888b-a5c7314b6c68":11.371164021164024,"2659531e-eb9d-4dd5-b46f-10f66a4819c6":12.493478835978836,"324c0cc6-829c-4b4f-8ef4-5f2d9b34bf58":11.08718253968254,"48a5daf3-5217-4b07-8f66-82dd2934cba6":11.114034391534393,"720f59d2-acc3-4d5a-91c2-258d137d9647":11.712566137566139,"89925ea3-ffcc-406f-9b38-432275ce2bd9":12.110132275132274,"efcbfcea-e8b0-4ca9-a883-92f42f862307":5.12010582010582},"topic":["termin","protocol","relai","code","transmiss"],"groups":[{"authors":["Michael Gastpar","Martin Vetterli"],"references":["748a2ab3-8b5f-4d0a-9e2d-af685089843a","89925ea3-ffcc-406f-9b38-432275ce2bd9","8cc9ea80-563f-4e62-bda9-8ff6d71cf6ae","b5741c8a-84a5-4b8d-9e5e-29d97732b48f","efcbfcea-e8b0-4ca9-a883-92f42f862307"],"_id":"064005b0-00e1-40c6-888b-a5c7314b6c68","abstract":"Gupta and Kumar (see IEEE Transactions an Information Theory, vol.46, no.2, p.388-404, 2000) determined the capacity of wireless networks under certain assumptions, among them point-to-point coding, which excludes for example multi-access and broadcast codes. We consider essentially the same physical model of a wireless network under a different traffic pattern, namely the relay traffic pattern, but we allow for arbitrarily complex network coding. In our model, there is only one active source/destination pair, while all other nodes assist this transmission. We show code constructions leading to achievable rates and derive upper bounds from the max-flow min-cut theorem. It is shown that lower and upper bounds meet asymptotically as the number of nodes in the network goes to infinity, thus proving that the capacity of the wireless network with n nodes under the relay traffic pattern behaves like log n bits per second. This demonstrates also that network coding is essential: under the point-to-point coding assumption considered by Gupta et al., the achievable rate is constant, independent of the number of nodes. Moreover, the result of this paper has implications' and extensions to fading channels and to sensor networks.","title":"On the capacity of wireless networks: the relay case","venue":"international conference on computer communications","year":2002,"__v":0,"citationCount":246},{"authors":["Lizhong Zheng","David Tse"],"references":["03eca440-3c16-4758-9706-c853469f7d71","25d7ce16-e254-4d4c-97f4-1b575c0d3e24","2659531e-eb9d-4dd5-b46f-10f66a4819c6","324c0cc6-829c-4b4f-8ef4-5f2d9b34bf58","48a5daf3-5217-4b07-8f66-82dd2934cba6","748a2ab3-8b5f-4d0a-9e2d-af685089843a"],"_id":"720f59d2-acc3-4d5a-91c2-258d137d9647","abstract":"Multiple antennas can be used for increasing the amount of diversity or the number of degrees of freedom in wireless communication systems. We propose the point of view that both types of gains can be simultaneously obtained for a given multiple-antenna channel, but there is a fundamental tradeoff between how much of each any coding scheme can get. For the richly scattered Rayleigh-fading channel, we give a simple characterization of the optimal tradeoff curve and use it to evaluate the performance of existing multiple antenna schemes.","title":"Diversity and multiplexing: a fundamental tradeoff in multiple-antenna channels","venue":"IEEE Transactions on Information Theory","year":2003,"__v":0,"citationCount":1901},{"authors":["Babak Hassibi","Bertrand M. Hochwald"],"references":["03eca440-3c16-4758-9706-c853469f7d71","18c098e6-53d8-46a6-a5df-ec51e2c2336f","1ea643f1-3820-4ca3-9297-9ac9ee3c6be6","25d7ce16-e254-4d4c-97f4-1b575c0d3e24","2659531e-eb9d-4dd5-b46f-10f66a4819c6","2a69f973-4ad7-4d6c-bd17-27c13e58768c","2cf70f2e-9996-477e-9ba1-d02ec769c507","324c0cc6-829c-4b4f-8ef4-5f2d9b34bf58","4eec044b-7d46-4ebd-b387-4adca987ad43","748a2ab3-8b5f-4d0a-9e2d-af685089843a","7e78d227-bc04-4fa3-a38b-079ca5f71368","85bd9cc6-e41a-4fd4-8f3b-e776329efc4b","9b17227e-8fa9-4c0e-8487-4b05df9064eb","b99e567e-a281-41cb-a6ec-de5d0ec08063","cab91964-4e8d-4211-8d32-455cfd690b60","ebac2b26-3187-4435-88a2-049cb5463806","fbc50327-e90c-4509-a450-b9942f5b20d4"],"_id":"48a5daf3-5217-4b07-8f66-82dd2934cba6","abstract":"Multiple-antenna systems that operate at high rates require simple yet effective space-time transmission schemes to handle the large traffic volume in real time. At rates of tens of bits per second per hertz, Vertical Bell Labs Layered Space-Time (V-BLAST), where every antenna transmits its own independent substream of data, has been shown to have good performance and simple encoding and decoding. Yet V-BLAST suffers from its inability to work with fewer receive antennas than transmit antennas-this deficiency is especially important for modern cellular systems, where a base station typically has more antennas than the mobile handsets. Furthermore, because V-BLAST transmits independent data streams on its antennas there is no built-in spatial coding to guard against deep fades from any given transmit antenna. On the other hand, there are many previously proposed space-time codes that have good fading resistance and simple decoding, but these codes generally have poor performance at high data rates or with many antennas. We propose a high-rate coding scheme that can handle any configuration of transmit and receive antennas and that subsumes both V-BLAST and many proposed space-time block codes as special cases. The scheme transmits substreams of data in linear combinations over space and time. The codes are designed to optimize the mutual information between the transmitted and received signals. Because of their linear structure, the codes retain the decoding simplicity of V-BLAST, and because of their information-theoretic optimality, they possess many coding advantages. We give examples of the codes and show that their performance is generally superior to earlier proposed methods over a wide range of rates and signal-to-noise ratios (SNRs).","title":"High-rate codes that are linear in space and time","venue":"IEEE Transactions on Information Theory","year":2002,"__v":0,"citationCount":669}],"offsprings":["6d25cd6f-4a67-41ed-9b6d-467c739f531e"]},"83c737b8-e084-4766-ba6e-131e6a1c017c":{"authors":["Mark Everingham","Luc J. Van Gool","Christopher K. I. Williams","John Winn","Andrew Zisserman"],"references":["1f520d1a-5870-477d-85d7-0f50be690ea7","8b8a2247-bd77-4736-b493-449734f56b9a","aa767a83-de19-4421-bfb4-f63808992758","b944f77f-113b-4a02-ae5e-d4a124b8fd5b","dd83785a-dd19-41e3-9b25-ebabbd48d336","e0ac4812-7729-4a2d-8a1f-74b1b7c8eb5d"],"_id":"83c737b8-e084-4766-ba6e-131e6a1c017c","abstract":"The Pascal Visual Object Classes (VOC) challenge is a benchmark in visual object category recognition and detection, providing the vision and machine learning communities with a standard dataset of images and annotation, and standard evaluation procedures. Organised annually from 2005 to present, the challenge and its associated dataset has become accepted as the benchmark for object detection.#R##N##R##N#This paper describes the dataset and evaluation procedure. We review the state-of-the-art in evaluated methods for both classification and detection, analyse whether the methods are statistically different, what they are learning from the images (e.g. the object or its context), and what the methods find easy or confuse. The paper concludes with lessons learnt in the three year history of the challenge, and proposes directions for future improvement and extension.","title":"The Pascal Visual Object Classes (VOC) Challenge","venue":"International Journal of Computer Vision","year":2010,"__v":0,"citationCount":2425,"parents":{"08877f4f-6266-44d8-83d6-6fa9070e0729":0,"1f520d1a-5870-477d-85d7-0f50be690ea7":0,"1f556c88-b553-4c75-b243-92d8200f8149":2.083333333333333,"23120ec2-cd0d-48ed-abef-567a3f9ea103":6.25,"319f5c0d-b3f1-4f4e-a553-03c887f50e3c":0,"32a53bab-1ede-4869-98ad-d2ff0c1e3367":12.5,"364d2f61-6575-464a-9be2-1138b3b64c4a":12.5,"3ac62b27-10f6-41a7-9489-20c68399d826":12.5,"433969bb-d29f-4cac-83a5-ccfb5c6c7b4e":0,"470a4f23-7661-44a2-b1fe-a370995631d1":2.083333333333333,"52b16eb0-053c-42d3-9713-d4b631dac23a":6.25,"52dbf565-81ab-439e-a9af-6c4d6ae302f8":4.166666666666666,"61447020-9a4b-4742-affd-fb5cde9d84ae":2.083333333333333,"7af6585a-b797-47ad-84f3-a8fec553f67a":6.25,"80c70167-d4e9-46e5-aeb9-a2d91df48db1":0,"86ba72ef-465f-44dc-8068-cdd6a64f0b40":10.416666666666668,"8b8a2247-bd77-4736-b493-449734f56b9a":0,"98801e79-fc9d-4c6a-a383-10e937c9d008":2.083333333333333,"99a51496-fcec-4bf4-aa14-0f548bc20a57":4.166666666666666,"9aea2ad1-64c1-4e32-b991-1333e5b60a13":4.166666666666666,"a1e856ee-3e21-4efd-bc25-86201dd71737":6.25,"a96a19b9-2924-4231-9da7-ad1860d23480":6.25,"aa767a83-de19-4421-bfb4-f63808992758":0,"ac5e3fe4-3b1d-412d-a03b-3247d39f62d5":2.083333333333333,"ad4f81d3-cba5-4db2-9044-93962e883865":0,"b3e241a6-126f-40fb-a063-8ed7d0223a3c":8.333333333333332,"b624c279-af53-46e8-97ef-cc7e8a1c2d55":2.083333333333333,"b944f77f-113b-4a02-ae5e-d4a124b8fd5b":0,"c0a960bd-3739-41ed-9b84-f1e12f28795d":2.083333333333333,"c31657cb-cc9b-4947-b9dd-5a40de643bbe":8.333333333333332,"c70a5a06-395e-452e-bec8-01807cf4be7e":10.416666666666668,"c7ffa962-3c2c-4298-b32a-745510e8ef9f":12.5,"cb5e3b2d-a97e-461f-b99e-d4593d0ef2d7":0,"cfbc794e-0fa7-4d5b-be73-f5f03c5a1f9d":0,"d5e01b64-7902-4df0-a768-43c2a8e1739e":8.333333333333332,"d8da60d2-11fb-4c95-ad08-d077828e994d":4.166666666666666,"dc2c4901-c7cd-405f-b549-fad267d3f5bd":8.333333333333332,"dd83785a-dd19-41e3-9b25-ebabbd48d336":2.083333333333333,"e0ac4812-7729-4a2d-8a1f-74b1b7c8eb5d":2.083333333333333,"e75d8e62-a86d-4241-953f-1b315005d920":0,"e8736260-dc56-4097-a88c-24c9e189e91c":4.166666666666666,"e88433aa-0835-4c0e-88d0-1165ab4ac4f8":2.083333333333333,"eba773db-f6b9-4fb3-9112-61cd10e0c754":4.166666666666666,"ed835ca3-7120-4646-afaf-20c04a57c698":0,"ee9b186c-b7f0-4323-8f28-a55bbbd62b71":4.166666666666666,"fc780759-4533-4b33-9774-746ca210842f":6.25,"ffa31d0c-ff37-4bf3-b213-6d8a968e6636":0,"ffc56f7f-1295-4647-a1f7-e44ea58f93f2":2.083333333333333},"keyword":{"08877f4f-6266-44d8-83d6-6fa9070e0729":12.450396825396826,"1f520d1a-5870-477d-85d7-0f50be690ea7":12.84047619047619,"1f556c88-b553-4c75-b243-92d8200f8149":12.303703703703702,"23120ec2-cd0d-48ed-abef-567a3f9ea103":12.15079365079365,"319f5c0d-b3f1-4f4e-a553-03c887f50e3c":8.409523809523808,"32a53bab-1ede-4869-98ad-d2ff0c1e3367":11.80079365079365,"364d2f61-6575-464a-9be2-1138b3b64c4a":11.859656084656084,"3ac62b27-10f6-41a7-9489-20c68399d826":9.004761904761905,"433969bb-d29f-4cac-83a5-ccfb5c6c7b4e":12.677671957671956,"470a4f23-7661-44a2-b1fe-a370995631d1":11.134285714285715,"52b16eb0-053c-42d3-9713-d4b631dac23a":9.676349206349206,"52dbf565-81ab-439e-a9af-6c4d6ae302f8":10.210476190476191,"61447020-9a4b-4742-affd-fb5cde9d84ae":12.906190476190474,"7af6585a-b797-47ad-84f3-a8fec553f67a":10.614285714285712,"80c70167-d4e9-46e5-aeb9-a2d91df48db1":13.514179894179895,"86ba72ef-465f-44dc-8068-cdd6a64f0b40":11.744338624338623,"8b8a2247-bd77-4736-b493-449734f56b9a":12.135714285714284,"98801e79-fc9d-4c6a-a383-10e937c9d008":9.188095238095238,"99a51496-fcec-4bf4-aa14-0f548bc20a57":0,"9aea2ad1-64c1-4e32-b991-1333e5b60a13":10.482936507936508,"a1e856ee-3e21-4efd-bc25-86201dd71737":11.02936507936508,"a96a19b9-2924-4231-9da7-ad1860d23480":9.745238095238095,"aa767a83-de19-4421-bfb4-f63808992758":11.064285714285717,"ac5e3fe4-3b1d-412d-a03b-3247d39f62d5":11.461269841269841,"ad4f81d3-cba5-4db2-9044-93962e883865":11.943809523809524,"b3e241a6-126f-40fb-a063-8ed7d0223a3c":10.056349206349207,"b624c279-af53-46e8-97ef-cc7e8a1c2d55":8.154761904761905,"b944f77f-113b-4a02-ae5e-d4a124b8fd5b":12.823650793650794,"c0a960bd-3739-41ed-9b84-f1e12f28795d":11.988888888888889,"c31657cb-cc9b-4947-b9dd-5a40de643bbe":9.427525252525253,"c70a5a06-395e-452e-bec8-01807cf4be7e":13.172857142857142,"c7ffa962-3c2c-4298-b32a-745510e8ef9f":9.338174603174602,"cb5e3b2d-a97e-461f-b99e-d4593d0ef2d7":9.85793650793651,"cfbc794e-0fa7-4d5b-be73-f5f03c5a1f9d":9.149603174603175,"d5e01b64-7902-4df0-a768-43c2a8e1739e":9.500000000000002,"d8da60d2-11fb-4c95-ad08-d077828e994d":13.266666666666667,"dc2c4901-c7cd-405f-b549-fad267d3f5bd":8.242857142857142,"dd83785a-dd19-41e3-9b25-ebabbd48d336":11.231428571428573,"e0ac4812-7729-4a2d-8a1f-74b1b7c8eb5d":9.363227513227514,"e75d8e62-a86d-4241-953f-1b315005d920":0,"e8736260-dc56-4097-a88c-24c9e189e91c":12.500793650793652,"e88433aa-0835-4c0e-88d0-1165ab4ac4f8":10.584404761904763,"eba773db-f6b9-4fb3-9112-61cd10e0c754":9.631349206349206,"ed835ca3-7120-4646-afaf-20c04a57c698":9.266666666666666,"ee9b186c-b7f0-4323-8f28-a55bbbd62b71":9.526190476190477,"fc780759-4533-4b33-9774-746ca210842f":11.05952380952381,"ffa31d0c-ff37-4bf3-b213-6d8a968e6636":10.427936507936506,"ffc56f7f-1295-4647-a1f7-e44ea58f93f2":11.059523809523808},"topic":["object","method","evalu","detect","dataset"],"offsprings":["f2d49150-35de-4fd5-ac46-eb071d1cc73e","176a7436-78ea-4c2a-82e6-7930ab023bd1"]},"8828d2f5-0b50-4715-863d-66c787fc40e0":{"authors":["Adrian Perrig","Robert Szewczyk","Victor Wen","David E. Culler","J. D. Tygar"],"references":[],"_id":"8828d2f5-0b50-4715-863d-66c787fc40e0","abstract":"As sensor networks edge closer towards wide-spread deployment, security issues become a central concern. So far, much research has focused on making sensor networks feasible and useful, and has not concentrated on security.  We present a suite of security building blocks optimized for resource-constrained environments and wireless communication. SPINS has two secure building blocks: SNEP and μTESLA SNEP provides the following important baseline security primitives: Data confidentiality, two-party data authentication, and data freshness. A particularly hard problem is to provide efficient broadcast authentication, which is an important mechanism for sensor networks. μTESLA is a new protocol which provides authenticated broadcast for severely resource-constrained environments. We implemented the above protocols, and show that they are practical even on minimal hardware: the performance of the protocol suite easily matches the data rate of our network. Additionally, we demonstrate that the suite can be used for building higher level protocols.","title":"SPINS: security protocols for sensor networks","venue":"acm ieee international conference on mobile computing and networking","year":2001,"__v":0,"citationCount":1514,"parents":{"09756c4e-2414-4dd1-8e35-c1410d3511b6":0,"0ab8c0f9-fdba-428d-81a3-da79d759598e":3.4482758620689653,"0b868c0b-2b01-4732-abfb-06a8773783cb":3.4482758620689653,"0d4d0363-07b5-43b6-976d-955e96044709":0,"0e1c9c62-343a-447a-9b47-9b3012656cdb":13.793103448275861,"1dd8c68d-3b20-4171-9245-3a12c64c2838":0,"28fa59f0-eca3-4c79-a2e8-2a60a9180b1c":0,"2ee9a087-6188-4ebd-95b9-6561cba0584c":0,"2f814545-7696-433e-b8fd-e680a9cc5a1f":3.4482758620689653,"31c5e39a-3f24-4d20-bf8c-3d00036baf95":0,"3fb43b00-905c-4a08-934d-198ea4eb66c3":3.4482758620689653,"48a829fd-7c8f-4bb7-b481-ae23d55570a2":6.896551724137931,"4c4597ec-30be-4738-b3d6-95dda4722250":3.4482758620689653,"51da4901-311e-46ba-a066-0656779980c6":3.4482758620689653,"59054202-3dbe-424a-bd0a-b70986faf2ed":3.4482758620689653,"5fd22977-137c-4b3b-904c-f05e02f4fb31":0,"60fb0dc2-bde3-4714-948e-de0ed12ab460":0,"668f4a29-4f19-4f95-8051-ad912a1b7de9":3.4482758620689653,"6b2923c7-0b03-4070-be88-9214369dfd53":6.896551724137931,"745f0f29-0489-4906-b625-fd0efa9f85aa":10.344827586206897,"83a2eb55-b330-4e0c-8dc9-05e9466d5028":3.4482758620689653,"a76086c3-fd36-4c8d-8a98-619ac62a3d5c":3.4482758620689653,"b68fc787-7817-421e-8e66-8a98ab9db1ad":0,"bdd9387e-ed5f-4208-acd2-37e2e033827c":0,"bf2e4bc7-c465-43c7-85ca-80cd98efe735":10.344827586206897,"ca394e6a-59e0-466c-a66a-d976555db689":0,"cd7b4b1f-8614-4fab-8c33-a89394f0d6f9":13.793103448275861,"d782ce32-3afb-4683-a07b-2e68cd540c6a":3.4482758620689653,"f7268eda-b392-44cd-bcd8-134cbb9032ff":6.896551724137931},"keyword":{"09756c4e-2414-4dd1-8e35-c1410d3511b6":9.683412698412697,"0ab8c0f9-fdba-428d-81a3-da79d759598e":8.901984126984127,"0b868c0b-2b01-4732-abfb-06a8773783cb":10.898835978835981,"0d4d0363-07b5-43b6-976d-955e96044709":10.58174603174603,"0e1c9c62-343a-447a-9b47-9b3012656cdb":10.482420634920635,"1dd8c68d-3b20-4171-9245-3a12c64c2838":9.125079365079365,"28fa59f0-eca3-4c79-a2e8-2a60a9180b1c":0,"2ee9a087-6188-4ebd-95b9-6561cba0584c":0,"2f814545-7696-433e-b8fd-e680a9cc5a1f":8.926904761904764,"31c5e39a-3f24-4d20-bf8c-3d00036baf95":0,"3fb43b00-905c-4a08-934d-198ea4eb66c3":8.425396825396826,"48a829fd-7c8f-4bb7-b481-ae23d55570a2":9.594871794871793,"4c4597ec-30be-4738-b3d6-95dda4722250":0,"51da4901-311e-46ba-a066-0656779980c6":9.729365079365076,"59054202-3dbe-424a-bd0a-b70986faf2ed":11.46404761904762,"5fd22977-137c-4b3b-904c-f05e02f4fb31":0,"60fb0dc2-bde3-4714-948e-de0ed12ab460":10.147619047619045,"668f4a29-4f19-4f95-8051-ad912a1b7de9":10.979841269841268,"6b2923c7-0b03-4070-be88-9214369dfd53":10.795238095238096,"745f0f29-0489-4906-b625-fd0efa9f85aa":7.989920634920634,"83a2eb55-b330-4e0c-8dc9-05e9466d5028":11.563888888888888,"a76086c3-fd36-4c8d-8a98-619ac62a3d5c":9.417619047619048,"b68fc787-7817-421e-8e66-8a98ab9db1ad":7.403968253968253,"bdd9387e-ed5f-4208-acd2-37e2e033827c":10.638492063492063,"bf2e4bc7-c465-43c7-85ca-80cd98efe735":8.477460317460316,"ca394e6a-59e0-466c-a66a-d976555db689":7.962380952380952,"cd7b4b1f-8614-4fab-8c33-a89394f0d6f9":10.573968253968252,"d782ce32-3afb-4683-a07b-2e68cd540c6a":12.122142857142858,"f7268eda-b392-44cd-bcd8-134cbb9032ff":11.36626984126984},"topic":["secur","protocol","network","data","suit"],"offsprings":["f3267c01-b670-4b7a-a3a5-79088c0d90ab"]},"923f5d0a-23a3-4fb1-bee7-ec72122709a4":{"authors":["Timothy F. Cootes","Christopher J. Taylor","David H. Cooper","Jim Graham"],"references":[],"_id":"923f5d0a-23a3-4fb1-bee7-ec72122709a4","abstract":"!, Model-based vision is firmly established as a robust approach to recognizing and locating known rigid objects in the presence of noise, clutter, and occlusion. It is more problematic to apply modelbased methods to images of objects whose appearance can vary, though a number of approaches based on the use of flexible templates have been proposed. The problem with existing methods is that they sacrifice model specificity in order to accommodate variability, thereby compromising robustness during image interpretation. We argue that a model should only be able to deform in ways characteristic of the class of objects it represents. We describe a method for building models by learning patterns of variability from a training set of correctly annotated images. These models can be used for image search in an iterative refinement algorithm analogous to that employed by Active Contour Models (Snakes). The key difference is that our Active Shape Models can only deform to fit the data in ways consistent with the training set. We show several practical examples where we have built such models and used them to locate partially occluded objects in noisy, cluttered images. Q 199s A&& prrss, IN.","title":"Active shape models—their training and application","venue":"Computer Vision and Image Understanding","year":1995,"__v":0,"citationCount":2999,"parents":{"035f8537-61a7-4c4f-b9fe-120f913a38b0":0,"250f917f-a84e-4018-9e6b-43995d0c2bc6":0,"560f44a5-d696-449d-9163-662c4cf2a538":14.285714285714285,"6d24a893-dbf9-4baf-9a3d-2b7b6951ac37":0,"9980a8c8-2c38-437f-b269-2a5bb1c976cb":14.285714285714285,"9be82f37-3656-4bb8-bfea-b9f399593807":0,"b9466c12-f15f-46d1-845b-a6abb14d2d35":0},"keyword":{"035f8537-61a7-4c4f-b9fe-120f913a38b0":8.80888888888889,"250f917f-a84e-4018-9e6b-43995d0c2bc6":0,"560f44a5-d696-449d-9163-662c4cf2a538":11.426746031746033,"6d24a893-dbf9-4baf-9a3d-2b7b6951ac37":0,"9980a8c8-2c38-437f-b269-2a5bb1c976cb":0,"9be82f37-3656-4bb8-bfea-b9f399593807":10.474761904761905,"b9466c12-f15f-46d1-845b-a6abb14d2d35":10.279523809523809},"topic":["model","imag","object","method","variabl"],"offsprings":["bf03f268-de9d-4a80-aee1-200990056503","b592576f-ff29-4a68-9b2f-8a8ad02e9c70","32d158dc-6f9f-426a-973b-8edc5e4c5dad"]},"9270a9b5-940a-4394-814f-433c6440f286":{"authors":["Timo Ojala","Matti Pietikäinen","David Harwood"],"references":[],"_id":"9270a9b5-940a-4394-814f-433c6440f286","abstract":"This paper evaluates the performance both of some texture measures which have been successfully used in various applications and of some new promising approaches proposed recently. For classification a method based on Kullback discrimination of sample and prototype distributions is used. The classification results for single features with one-dimensional feature value distributions and for pairs of complementary features with two-dimensional distributions are presented","title":"A comparative study of texture measures with classification based on featured distributions","venue":"Pattern Recognition","year":1996,"__v":0,"citationCount":1718,"parents":{"48c4df8b-249a-4ca2-bf93-4df44200b7a6":0,"66ef956f-ea06-4527-8cb1-a71a9e00f9b5":28.57142857142857,"689ead95-6fb0-43d0-8c49-e255a20ae09d":0,"8831d80b-0ec8-4d25-a609-7746251a0f54":28.57142857142857,"9205abb2-a53a-4d16-b3d5-ebb3c6a6640b":14.285714285714285,"b43507d2-72e1-4f55-ac87-72dd87e321ad":28.57142857142857,"d2930486-5812-4750-b650-dfd17d917226":42.857142857142854},"keyword":{"48c4df8b-249a-4ca2-bf93-4df44200b7a6":9.681190476190475,"66ef956f-ea06-4527-8cb1-a71a9e00f9b5":10.353333333333333,"689ead95-6fb0-43d0-8c49-e255a20ae09d":9.778888888888888,"8831d80b-0ec8-4d25-a609-7746251a0f54":8.144074074074075,"9205abb2-a53a-4d16-b3d5-ebb3c6a6640b":8.69126984126984,"b43507d2-72e1-4f55-ac87-72dd87e321ad":10.90436507936508,"d2930486-5812-4750-b650-dfd17d917226":8.915384615384616},"topic":["textur","successfulli","sampl","prototyp","propos"],"groups":[{"authors":["J. M. H. du Buf","M. Kardan","M. Spann"],"references":["0ccb131b-88a3-45f1-bfc5-34a77ffeea3e","3c4e8d07-47e2-4942-8197-59b613634ce4","48c4df8b-249a-4ca2-bf93-4df44200b7a6","536bae3c-3a30-4855-ac10-411930bd11ad","5ebc8117-0e62-4b17-8dd6-abf0248d07a9","61960382-eb74-4fbf-81c8-cc22ffcecc19","69b6d290-efca-43dc-85b2-5b11f86c7ab7","9205abb2-a53a-4d16-b3d5-ebb3c6a6640b","988e51d5-75de-4102-8659-b2d9a87db947","9cef868f-eb6d-4189-acd1-43eac87cf81e"],"_id":"66ef956f-ea06-4527-8cb1-a71a9e00f9b5","abstract":"This paper describes a comparative study of texture features, with particular emphasis on the applicability to unsupervised image segmentation. A benchmark test is introduced in which a set of 20 simple bipartite images, combining different stochastic textures separated by a stochastic boundary, is used for feature extraction and segmentation. The accuracy of the segmentation result, expressed in the mean boundary error, is used as an evaluation criterion. From the seven feature extraction methods tested, the Haralick, Laws and Unser methods gave best overall results. Results obtained also show that direct feature statistics such as the Bhattacharyya distance are not appropriate evaluation criteria if texture features are used for image segmentation. A small experiment on visual boundary tracking revealed that boundary error obtained here are similar to those obtained by machine segmentation.","title":"Texture feature performance for image segmentation","venue":"Pattern Recognition","year":1990,"__v":0,"citationCount":81},{"authors":["Philippe P. Ohanian","Richard C. Dubes"],"references":["30614910-26a5-495c-8bb7-0f723c47db69","48c4df8b-249a-4ca2-bf93-4df44200b7a6","536bae3c-3a30-4855-ac10-411930bd11ad","575ccd66-0e74-4c7a-9c06-92bbb75686be","66ef956f-ea06-4527-8cb1-a71a9e00f9b5","80ef7b7f-ba85-4932-95ac-8f9a66a336c8","842c30d5-98b6-463d-9a23-4841a3e07eb9","93869064-218b-475d-909d-abf02329ba38","9cef868f-eb6d-4189-acd1-43eac87cf81e","b4e55602-784e-4c65-acc0-babd1f943463","cd8df7ee-a457-47c4-bd7d-3f4187daaf10","d12c8fca-a82c-45db-b29c-8fc7a47fce2e","d9215ef1-ba4b-4a59-bd6f-b6900dbf8ae3","fc443443-416f-4fd5-ba46-17a06046711d"],"_id":"b43507d2-72e1-4f55-ac87-72dd87e321ad","abstract":"Abstract   Textural features for pattern recognition are compared. The problem addressed is to determine which features optimize classification rate. Such features may be used in image segmentation, compression, inspection, and other problems in computer vision. Many textural features have been proposed in the literature. No large-scale objective comparative study has appeared. The goal is comparing and evaluating in a quantitative manner four types of features, namely Markov Random Field parameters, multi-channel filtering features, fractal based features, and co-occurrence features. Performance is assessed by the criterion of classification error rate with a Nearest Neighbor classifier and the Leave-One-Out estimation method using forward selection. Four types of texture are studied, two synthetic (fractal and Gaussian Markov Random Fields) and two natural (leather and painted surfaces). The results show that co-occurrence features perform best followed by the fractal features. However, there is no universally best subset of features. The feature selection task has to be performed for each specific problem to decide which feature of which type one should use.","title":"Performance evaluation for four classes of textural features","venue":"Pattern Recognition","year":1992,"__v":0,"citationCount":126},{"authors":["David Harwood","Timo Ojala","Matti Pietikäinen","Shalom E. Kelman","Larry S. Davis"],"references":["5ec2635e-60f1-4be7-92a8-46e3a2714f4e","66ef956f-ea06-4527-8cb1-a71a9e00f9b5","689ead95-6fb0-43d0-8c49-e255a20ae09d","9205abb2-a53a-4d16-b3d5-ebb3c6a6640b","a40eb7b1-9ff4-444c-a6b5-773e40b15427","c951d453-095e-4822-a5e2-b16ac908ab2d"],"_id":"d2930486-5812-4750-b650-dfd17d917226","abstract":"Abstract   We propose a new method of texture analysis and classification based on a local center-symmetric covariance analysis, using Kullback (log-likelihood) discrimination of sample and prototype distributions. Features of our analysis are generalized, invariant, local measures of texture having center-symmetric patterns, which is characteristic of many natural and artificial textures. We introduce two local center-symmetric auto-correlations, with linear and rank-order versions (SAC and SRAC), together with a related covariance measure (SCOV) and variance ratio (SVR). All of these are rotation-invariant, and three are locally greyscale invariant, robust measures. In classification experiments, we compare their discriminant information to that of Laws' well-known convolutions, which have specific center-symmetric masks. We find that our new covariance measures, which can be regarded as generalizations of Laws' measures, perform better than Laws' approach despite their measure of texture pattern and grey-scale.","title":"Texture classification by center-symmetric auto-correlation, using Kullback discrimination of distributions","venue":"Pattern Recognition Letters","year":1995,"__v":0,"citationCount":36},{"authors":["Michael Unser"],"references":["1325fe65-6240-4f2f-8f4a-7ca12035551b","48c4df8b-249a-4ca2-bf93-4df44200b7a6","536bae3c-3a30-4855-ac10-411930bd11ad","623d2a5e-3e87-4c96-a86d-7d450bc10d06","689ead95-6fb0-43d0-8c49-e255a20ae09d","9cef868f-eb6d-4189-acd1-43eac87cf81e","db5e774e-4fdf-4823-8a41-cb4cebd0055c"],"_id":"8831d80b-0ec8-4d25-a609-7746251a0f54","abstract":"The sum and difference of two random variables with same variances are decorrelated and define the principal axes of their associated joint probability function. Therefore, sum and difference histograms are introduced as an alternative to the usual co-occurrence matrices used for texture analysis. Two maximum likelihood texture classifiers are presented depending on the type of object used for texture characterization (sum and difference histograms or some associated global measures). Experimental results indicate that sum and difference histograms used conjointly are nearly as powerful as cooccurrence matrices for texture discrimination. The advantage of the proposed texture analysis method over the conventional spatial gray level dependence method is the decrease in computation time and memory storage.","title":"Sum and Difference Histograms for Texture Classification","venue":"IEEE Transactions on Pattern Analysis and Machine Intelligence","year":1986,"__v":0,"citationCount":152}],"offsprings":["e2204e92-e6dc-4884-9bbc-200029491fc7","e3a5cec9-7e82-4c14-86ab-0d95a92712a7"]},"96b245c2-47a5-4aec-89f0-d2a362124845":{"authors":["Douglas S. J. De Couto","Daniel Aguayo","John Bicket","Robert Morris"],"references":["23dd7fc0-1ebd-43ce-ab3e-43896512c209","7c9f8cd8-d0ef-4954-b4db-4a6c803459c2"],"_id":"96b245c2-47a5-4aec-89f0-d2a362124845","abstract":"This paper presents the  expected transmission count  metric (ETX), which finds high-throughput paths on multi-hop wireless networks. ETX minimizes the expected total number of packet transmissions (including retransmissions) required to successfully deliver a packet to the ultimate destination. The ETX metric incorporates the effects of link loss ratios, asymmetry in the loss ratios between the two directions of each link, and interference among the successive links of a path. In contrast, the minimum hop-count metric chooses arbitrarily among the different paths of the same minimum length, regardless of the often large differences in throughput among those paths, and ignoring the possibility that a longer path might offer higher throughput.This paper describes the design and implementation of ETX as a metric for the DSDV and DSR routing protocols, as well as modifications to DSDV and DSR which allow them to use ETX. Measurements taken from a 29-node 802.11b test-bed demonstrate the poor performance of minimum hop-count, illustrate the causes of that poor performance, and confirm that ETX improves performance. For long paths the throughput improvement is often a factor of two or more, suggesting that ETX will become more useful as networks grow larger and paths become longer.","title":"A high-throughput path metric for multi-hop wireless routing","venue":"acm ieee international conference on mobile computing and networking","year":2003,"__v":0,"citationCount":1551,"parents":{"0c840814-6118-477b-a129-6707976643cb":4.761904761904762,"0d4d0363-07b5-43b6-976d-955e96044709":0,"1c458029-5bab-4d15-b83b-98f2b7b87c17":9.523809523809524,"23dd7fc0-1ebd-43ce-ab3e-43896512c209":0,"2ec37cbd-e1ef-46bb-9fd4-6a46506f4d5b":4.761904761904762,"5a2400bf-9fac-4b95-aa5b-ef1e2f151433":19.047619047619047,"5ad83b9b-6ae3-42ea-9b5f-e2fabe669c74":0,"60fb0dc2-bde3-4714-948e-de0ed12ab460":0,"6f543c73-0ebc-49c3-a1a3-5340f7afc2c1":0,"7b0f326e-7e4a-4978-897f-fa3a9b10ddc4":4.761904761904762,"7c9f8cd8-d0ef-4954-b4db-4a6c803459c2":4.761904761904762,"7d37e9db-58d1-4c41-8a7c-397eebb5fd79":9.523809523809524,"94b8b73c-42f3-476c-9d4d-ea4ac7a4b78e":4.761904761904762,"954ba3bf-67d5-468c-9c34-015754d49459":19.047619047619047,"9663d55a-65e5-4e52-86ac-971e273c974d":0,"9dfc2115-597c-48eb-aefb-f8578b6081ff":0,"bada95d5-3ef8-4310-b6d7-418d843efeba":9.523809523809524,"bf395817-ab2b-4290-b6e8-f823702a465b":0,"d1bb6fa0-934c-4435-bcdc-609e1e288b1c":14.285714285714285,"db1032d8-c01e-4211-9732-f33feda045f0":14.285714285714285,"f65a4365-2696-47f3-849b-501792da7e23":4.761904761904762},"keyword":{"0c840814-6118-477b-a129-6707976643cb":11.313888888888888,"0d4d0363-07b5-43b6-976d-955e96044709":10.035343915343915,"1c458029-5bab-4d15-b83b-98f2b7b87c17":9.76309523809524,"23dd7fc0-1ebd-43ce-ab3e-43896512c209":12.41329365079365,"2ec37cbd-e1ef-46bb-9fd4-6a46506f4d5b":9.91626984126984,"5a2400bf-9fac-4b95-aa5b-ef1e2f151433":10.87361111111111,"5ad83b9b-6ae3-42ea-9b5f-e2fabe669c74":7.961507936507937,"60fb0dc2-bde3-4714-948e-de0ed12ab460":8.515238095238095,"6f543c73-0ebc-49c3-a1a3-5340f7afc2c1":8.997976190476189,"7b0f326e-7e4a-4978-897f-fa3a9b10ddc4":8.349126984126984,"7c9f8cd8-d0ef-4954-b4db-4a6c803459c2":9.528769841269842,"7d37e9db-58d1-4c41-8a7c-397eebb5fd79":10.384484126984127,"94b8b73c-42f3-476c-9d4d-ea4ac7a4b78e":8.62297619047619,"954ba3bf-67d5-468c-9c34-015754d49459":11.754761904761903,"9663d55a-65e5-4e52-86ac-971e273c974d":11.155952380952382,"9dfc2115-597c-48eb-aefb-f8578b6081ff":11.933968253968253,"bada95d5-3ef8-4310-b6d7-418d843efeba":6.665079365079366,"bf395817-ab2b-4290-b6e8-f823702a465b":11.206349206349206,"d1bb6fa0-934c-4435-bcdc-609e1e288b1c":11.749126984126983,"db1032d8-c01e-4211-9732-f33feda045f0":11.474854497354496,"f65a4365-2696-47f3-849b-501792da7e23":8.170317460317461},"topic":["path","etx","metric","throughput","perform"],"offsprings":["b857298c-92c9-4f05-a704-3b9fc6be06e3"]},"97cf7f10-646e-48d0-b408-c7339aa514fc":{"authors":["Douglas A. Reynolds","Thomas F. Quatieri","Robert B. Dunn"],"references":[],"_id":"97cf7f10-646e-48d0-b408-c7339aa514fc","abstract":"Reynolds, Douglas A., Quatieri, Thomas F., and Dunn, Robert B., Speaker Verification Using Adapted Gaussian Mixture Models, Digital Signal Processing10(2000), 19?41.In this paper we describe the major elements of MIT Lincoln Laboratory's Gaussian mixture model (GMM)-based speaker verification system used successfully in several NIST Speaker Recognition Evaluations (SREs). The system is built around the likelihood ratio test for verification, using simple but effective GMMs for likelihood functions, a universal background model (UBM) for alternative speaker representation, and a form of Bayesian adaptation to derive speaker models from the UBM. The development and use of a handset detector and score normalization to greatly improve verification performance is also described and discussed. Finally, representative performance benchmarks and system behavior experiments on NIST SRE corpora are presented.","title":"Speaker Verification Using Adapted Gaussian Mixture Models","venue":"Digital Signal Processing","year":2000,"__v":0,"citationCount":1639,"parents":{"0e7117bc-a0a4-473c-87c3-3b97741b5891":9.090909090909092,"11f3a6b6-a992-42db-b42f-981c945cd38b":0,"2cb67a98-9c03-48c1-b330-e6838d269ac6":4.545454545454546,"2edd5397-4309-433f-9848-d47b586c9682":27.27272727272727,"39d6e4da-cfd9-4d59-ad3e-b2432129d621":18.181818181818183,"3f3adccb-bbbe-48ac-a881-1ecdc1770b65":4.545454545454546,"42a298b5-7a7c-470e-a2df-17776909dc85":13.636363636363635,"4578e174-a765-4b93-a79d-4ccf79b89bd3":9.090909090909092,"5563dcc9-253b-46ea-84e0-dfd66abaa8a8":0,"74f76d15-cdcd-4b55-a203-4e994eb0c288":9.090909090909092,"85bfd47e-b43a-429d-8b29-91fa85ab3b67":13.636363636363635,"9142ab86-c325-4141-a2a4-2544d076c33d":4.545454545454546,"b0599338-dfb3-4436-b3cc-d37d9f7a7b43":9.090909090909092,"bb810b28-cd8f-4f24-a5b2-ae89bd2ea1b1":40.909090909090914,"c2c44a03-93ad-4572-9aed-987d290bc80c":9.090909090909092,"ce30f337-3881-42ca-beb3-ed57a4d5d21d":22.727272727272727,"d35e2e75-c60d-48cf-b240-a0909fbecea2":0,"de08e62d-3f4a-44e7-95f3-bd88856843a9":13.636363636363635,"e074bb9e-81b1-4e3f-b5b1-49c7663aef60":0,"e12c14c2-cc18-4f47-91de-48bdf42c93e5":0,"e6d75cd5-f580-4225-a323-ecfba2ee2753":0,"ea9215da-5e81-440a-a49a-540a4ab8e318":0},"keyword":{"0e7117bc-a0a4-473c-87c3-3b97741b5891":0,"11f3a6b6-a992-42db-b42f-981c945cd38b":7.06,"2cb67a98-9c03-48c1-b330-e6838d269ac6":6.996031746031746,"2edd5397-4309-433f-9848-d47b586c9682":9.052777777777777,"39d6e4da-cfd9-4d59-ad3e-b2432129d621":10.064457671957669,"3f3adccb-bbbe-48ac-a881-1ecdc1770b65":9.809391534391533,"42a298b5-7a7c-470e-a2df-17776909dc85":7.48968253968254,"4578e174-a765-4b93-a79d-4ccf79b89bd3":8.627380952380951,"5563dcc9-253b-46ea-84e0-dfd66abaa8a8":9.475396825396826,"74f76d15-cdcd-4b55-a203-4e994eb0c288":4.851984126984126,"85bfd47e-b43a-429d-8b29-91fa85ab3b67":8.225238095238096,"9142ab86-c325-4141-a2a4-2544d076c33d":9.114285714285714,"b0599338-dfb3-4436-b3cc-d37d9f7a7b43":9.644444444444444,"bb810b28-cd8f-4f24-a5b2-ae89bd2ea1b1":0,"c2c44a03-93ad-4572-9aed-987d290bc80c":11.242857142857144,"ce30f337-3881-42ca-beb3-ed57a4d5d21d":5.5019841269841265,"d35e2e75-c60d-48cf-b240-a0909fbecea2":8.369047619047619,"de08e62d-3f4a-44e7-95f3-bd88856843a9":9.36984126984127,"e074bb9e-81b1-4e3f-b5b1-49c7663aef60":0,"e12c14c2-cc18-4f47-91de-48bdf42c93e5":0,"e6d75cd5-f580-4225-a323-ecfba2ee2753":8.473412698412698,"ea9215da-5e81-440a-a49a-540a4ab8e318":10.527777777777779},"topic":["speaker","verif","model","system","ubm"],"groups":[{"authors":["Robert B. Dunn","Douglas A. Reynolds","Thomas F. Quatieri"],"references":["198d9d2e-1b0f-4164-8fae-a84983fee825","3f3adccb-bbbe-48ac-a881-1ecdc1770b65","42a298b5-7a7c-470e-a2df-17776909dc85","97cf7f10-646e-48d0-b408-c7339aa514fc","bb810b28-cd8f-4f24-a5b2-ae89bd2ea1b1","bca9e6a4-efca-43fd-8fb9-c10f14b51122","d35e2e75-c60d-48cf-b240-a0909fbecea2","de08e62d-3f4a-44e7-95f3-bd88856843a9","e6d75cd5-f580-4225-a323-ecfba2ee2753","fc764d6c-d27c-45de-b63a-c78a1a5cc029"],"_id":"2edd5397-4309-433f-9848-d47b586c9682","abstract":"Dunn, Robert B., Reynolds, Douglas A., and Quatieri, Thomas F., Approaches to Speaker Detection and Tracking in Conversational Speech, Digital Signal Processing10(2000), 93?112.Two approaches to detecting and tracking speakers in multispeaker audio are described. Both approaches use an adapted Gaussian mixture model, universal background model (GMM-UBM) speaker detection system as the core speaker recognition engine. In one approach, the individual log-likelihood ratio scores, which are produced on a frame-by-frame basis by the GMM-UBM system, are used to first partition the speech file into speaker homogenous regions and then to create scores for these regions. We refer to this approach as internal segmentation. Another approach uses an external segmentationalgorithm, based on blind clustering, to partition the speech file into speaker homogenous regions. The adapted GMM-UBM system then scores each of these regions as in the single-speaker recognition case. We show that the external segmentation system outperforms the internal segmentation system for both detection and tracking. In addition, we show how different components of the detection and tracking algorithms contribute to the overall system performance.","title":"Approaches to Speaker Detection and Tracking in Conversational Speech","venue":"Digital Signal Processing","year":2000,"__v":0,"citationCount":19},{"authors":["Douglas A. Reynolds"],"references":["11f3a6b6-a992-42db-b42f-981c945cd38b","4578e174-a765-4b93-a79d-4ccf79b89bd3","74f76d15-cdcd-4b55-a203-4e994eb0c288","85bfd47e-b43a-429d-8b29-91fa85ab3b67","b0599338-dfb3-4436-b3cc-d37d9f7a7b43","c2c44a03-93ad-4572-9aed-987d290bc80c","ce30f337-3881-42ca-beb3-ed57a4d5d21d","e074bb9e-81b1-4e3f-b5b1-49c7663aef60","e12c14c2-cc18-4f47-91de-48bdf42c93e5"],"_id":"bb810b28-cd8f-4f24-a5b2-ae89bd2ea1b1","title":"Comparison of background normalization methods for text-independent speaker verification.","venue":"","year":1997,"abstract":"","__v":0,"citationCount":146}],"offsprings":[]},"a246e432-612a-4481-95b5-29ba3db6369b":{"authors":["Thorsten Joachims"],"references":["50dd56db-151d-4d62-8576-65f0ef6f381b"],"_id":"a246e432-612a-4481-95b5-29ba3db6369b","abstract":"This paper presents an approach to automatically optimizing the retrieval quality of search engines using clickthrough data. Intuitively, a good information retrieval system should present relevant documents high in the ranking, with less relevant documents following below. While previous approaches to learning retrieval functions from examples exist, they typically require training data generated from relevance judgments by experts. This makes them difficult and expensive to apply. The goal of this paper is to develop a method that utilizes clickthrough data for training, namely the query-log of the search engine in connection with the log of links the users clicked on in the presented ranking. Such clickthrough data is available in abundance and can be recorded at very low cost. Taking a Support Vector Machine (SVM) approach, this paper presents a method for learning retrieval functions. From a theoretical perspective, this method is shown to be well-founded in a risk minimization framework. Furthermore, it is shown to be feasible even for large sets of queries and features. The theoretical results are verified in a controlled experiment. It shows that the method can effectively adapt the retrieval function of a meta-search engine to a particular group of users, outperforming Google in terms of retrieval quality after only a couple of hundred training examples.","title":"Optimizing search engines using clickthrough data","venue":"knowledge discovery and data mining","year":2002,"__v":0,"citationCount":1806,"parents":{"11c3cd75-00cf-45ef-9efc-ad503b531e48":0,"1ce7a9a3-91c4-45d6-984a-e1d240fd81aa":0,"290e0375-d2ad-4bec-a94f-f05e1580125b":18.181818181818183,"50dd56db-151d-4d62-8576-65f0ef6f381b":9.090909090909092,"51c8135d-1673-4fa8-9842-a65c4183ac73":0,"5f02e7c1-95dd-4c9b-b977-2f8bf079c296":0,"6df92a4c-0939-4cf7-895b-cca53196712f":0,"97684b69-4da6-4fb3-b40c-32c58752f708":0,"dddfbe50-c5c7-4fe7-8f92-02e8f10db47f":0,"f006e236-59ad-4647-a59f-4f46dc2c85be":0,"fd777cc0-12bb-4e9e-b9da-a5680e4ba653":9.090909090909092},"keyword":{"11c3cd75-00cf-45ef-9efc-ad503b531e48":0,"1ce7a9a3-91c4-45d6-984a-e1d240fd81aa":8.355714285714285,"290e0375-d2ad-4bec-a94f-f05e1580125b":10.917063492063491,"50dd56db-151d-4d62-8576-65f0ef6f381b":13.252380952380948,"51c8135d-1673-4fa8-9842-a65c4183ac73":0,"5f02e7c1-95dd-4c9b-b977-2f8bf079c296":0,"6df92a4c-0939-4cf7-895b-cca53196712f":0,"97684b69-4da6-4fb3-b40c-32c58752f708":9.326984126984126,"dddfbe50-c5c7-4fe7-8f92-02e8f10db47f":10.537301587301588,"f006e236-59ad-4647-a59f-4f46dc2c85be":11.90674603174603,"fd777cc0-12bb-4e9e-b9da-a5680e4ba653":10.627380952380951},"topic":["retriev","present","method","data","train"],"offsprings":[]},"afaee3cb-390a-4b89-9dbf-c053399f906a":{"authors":["Yehuda Koren","Robert M. Bell","Chris Volinsky"],"references":[],"_id":"afaee3cb-390a-4b89-9dbf-c053399f906a","abstract":"As the Netflix Prize competition has demonstrated, matrix factorization models are superior to classic nearest neighbor techniques for producing product recommendations, allowing the incorporation of additional information such as implicit feedback, temporal effects, and confidence levels.","title":"Matrix Factorization Techniques for Recommender Systems","venue":"IEEE Computer","year":2009,"__v":0,"citationCount":1682,"parents":{"05f5fba9-e7ca-4c46-be79-df57944a8b41":0,"136c8788-4516-4eb1-9685-e18c0fb9825f":50,"3be2ed7e-9c26-45f9-82aa-5ce8bdaae4c0":50,"3fab2153-d83b-447d-bdfd-59855c8701ad":0,"8b04d095-b24f-495a-a706-6356f19d6176":0,"b4c3fd79-8c11-4582-be79-d96685212312":0,"e268c20a-da6e-4708-bf8e-583dc013aae2":37.5,"ffd46ed3-82a0-4b1f-b85c-b13663d9a34b":12.5},"keyword":{"05f5fba9-e7ca-4c46-be79-df57944a8b41":0,"136c8788-4516-4eb1-9685-e18c0fb9825f":12.404497354497352,"3be2ed7e-9c26-45f9-82aa-5ce8bdaae4c0":11.185449735449733,"3fab2153-d83b-447d-bdfd-59855c8701ad":9.283597883597881,"8b04d095-b24f-495a-a706-6356f19d6176":11.587103174603172,"b4c3fd79-8c11-4582-be79-d96685212312":10.448994708994707,"e268c20a-da6e-4708-bf8e-583dc013aae2":9.834920634920634,"ffd46ed3-82a0-4b1f-b85c-b13663d9a34b":13.263095238095234},"topic":["tempor","techniqu","superior","recommend","product"],"groups":[{"authors":["Yehuda Koren"],"references":["05f5fba9-e7ca-4c46-be79-df57944a8b41","37c97bee-d5e0-43e1-abf2-c2ade9573199","6603866b-a9e7-4046-9662-0c8a30bc8f74","6abfbe97-fbe9-4bb3-8f21-823d5788a094","822235e6-6abe-442b-b761-b51795df418a","8b04d095-b24f-495a-a706-6356f19d6176","8f9d1aa4-7169-47c3-94de-7ca5ce7f7531","98b23182-8f51-428a-a4af-a91d280471ca","a69adad1-7efb-4204-93de-97aaeed2424a","ac14afe6-de4d-4056-b2ac-0f6e36f369a2","b4c3fd79-8c11-4582-be79-d96685212312","bd62aacb-5037-43d3-926a-af4d38ec3bfc","cff1b7c3-dc60-4ac0-a016-0e4b5070310a","d3ec5b39-7147-440d-82b0-4c4d05e671c9","ed4c0d5d-5152-4915-b9bd-d0bd25f82674","feddae21-3c05-4743-80fa-b8e101f1b93f","ffd46ed3-82a0-4b1f-b85c-b13663d9a34b"],"_id":"3be2ed7e-9c26-45f9-82aa-5ce8bdaae4c0","abstract":"Recommender systems provide users with personalized suggestions for products or services. These systems often rely on Collaborating Filtering (CF), where past transactions are analyzed in order to establish connections between users and products. The two more successful approaches to CF are latent factor models, which directly profile both users and products, and neighborhood models, which analyze similarities between products or users. In this work we introduce some innovations to both approaches. The factor and neighborhood models can now be smoothly merged, thereby building a more accurate combined model. Further accuracy improvements are achieved by extending the models to exploit both explicit and implicit feedback by the users. The methods are tested on the Netflix data. Results are better than those previously published on that dataset. In addition, we suggest a new evaluation metric, which highlights the differences among methods, based on their performance at a top-K recommendation task.","title":"Factorization meets the neighborhood: a multifaceted collaborative filtering model","venue":"knowledge discovery and data mining","year":2008,"__v":0,"citationCount":924},{"authors":["Yehuda Koren"],"references":["014b7429-189f-4d55-8aed-df212bd82152","160b76d7-75b3-445a-b9ed-30a00a56a8be","30d5d2ba-452e-47c9-9683-be3cc93a856b","338bc031-7663-4220-931a-70fb1cb5aecd","37c97bee-d5e0-43e1-abf2-c2ade9573199","3be2ed7e-9c26-45f9-82aa-5ce8bdaae4c0","599bcbd7-64ae-4bb7-97bf-452c88486893","72e4926f-5b3c-47f8-9702-12c489542c57","98b23182-8f51-428a-a4af-a91d280471ca","b4c3fd79-8c11-4582-be79-d96685212312","b726550c-3e6a-4f57-8cd6-d17cc0656b0b","bddda2b0-5c17-4e49-889a-b0237bcbacd6","cff1b7c3-dc60-4ac0-a016-0e4b5070310a","d3ec5b39-7147-440d-82b0-4c4d05e671c9","ffd46ed3-82a0-4b1f-b85c-b13663d9a34b"],"_id":"e268c20a-da6e-4708-bf8e-583dc013aae2","abstract":"Customer preferences for products are drifting over time. Product perception and popularity are constantly changing as new selection emerges. Similarly, customer inclinations are evolving, leading them to ever redefine their taste. Thus, modeling temporal dynamics should be a key when designing recommender systems or general customer preference models. However, this raises unique challenges. Within the eco-system intersecting multiple products and customers, many different characteristics are shifting simultaneously, while many of them influence each other and often those shifts are delicate and associated with a few data instances. This distinguishes the problem from concept drift explorations, where mostly a single concept is tracked. Classical time-window or instance-decay approaches cannot work, as they lose too much signal when discarding data instances. A more sensitive approach is required, which can make better distinctions between transient effects and long term patterns. The paradigm we offer is creating a model tracking the time changing behavior throughout the life span of the data. This allows us to exploit the relevant components of all data instances, while discarding only what is modeled as being irrelevant. Accordingly, we revamp two leading collaborative filtering recommendation approaches. Evaluation is made on a large movie rating dataset by Netflix. Results are encouraging and better than those previously reported on this dataset.","title":"Collaborative filtering with temporal dynamics","venue":"knowledge discovery and data mining","year":2009,"__v":0,"citationCount":332},{"authors":["Yifan Hu","Yehuda Koren","Chris Volinsky"],"references":["05f5fba9-e7ca-4c46-be79-df57944a8b41","37c97bee-d5e0-43e1-abf2-c2ade9573199","822235e6-6abe-442b-b761-b51795df418a","8b04d095-b24f-495a-a706-6356f19d6176","8f9d1aa4-7169-47c3-94de-7ca5ce7f7531","98b23182-8f51-428a-a4af-a91d280471ca","9b602954-f960-46fe-87ae-41f06c486efc","a453bfd8-97be-421b-8242-27f4b6c49092","a69adad1-7efb-4204-93de-97aaeed2424a","b4c3fd79-8c11-4582-be79-d96685212312","d3ec5b39-7147-440d-82b0-4c4d05e671c9","ed4c0d5d-5152-4915-b9bd-d0bd25f82674","feddae21-3c05-4743-80fa-b8e101f1b93f","ffd46ed3-82a0-4b1f-b85c-b13663d9a34b"],"_id":"136c8788-4516-4eb1-9685-e18c0fb9825f","abstract":"A common task of recommender systems is to improve customer experience through personalized recommendations based on prior implicit feedback. These systems passively track different sorts of user behavior, such as purchase history, watching habits and browsing activity, in order to model user preferences. Unlike the much more extensively researched explicit feedback, we do not have any direct input from the users regarding their preferences. In particular, we lack substantial evidence on which products consumer dislike. In this work we identify unique properties of implicit feedback datasets. We propose treating the data as indication of positive and negative preference associated with vastly varying confidence levels. This leads to a factor model which is especially tailored for implicit feedback recommenders. We also suggest a scalable optimization procedure, which scales linearly with the data size. The algorithm is used successfully within a recommender system for television shows. It compares favorably with well tuned implementations of other known methods. In addition, we offer a novel way to give explanations to recommendations given by this factor model.","title":"Collaborative Filtering for Implicit Feedback Datasets","venue":"international conference on data mining","year":2008,"__v":0,"citationCount":525}],"offsprings":[]},"b592576f-ff29-4a68-9b2f-8a8ad02e9c70":{"authors":["Serge J. Belongie","Jitendra Malik","Jan Puzicha"],"references":["50dd56db-151d-4d62-8576-65f0ef6f381b","6018a516-8149-4bce-bc33-5449d86e58c2","923f5d0a-23a3-4fb1-bee7-ec72122709a4"],"_id":"b592576f-ff29-4a68-9b2f-8a8ad02e9c70","abstract":"We present a novel approach to measuring similarity between shapes and exploit it for object recognition. In our framework, the measurement of similarity is preceded by: (1) solving for correspondences between points on the two shapes; (2) using the correspondences to estimate an aligning transform. In order to solve the correspondence problem, we attach a descriptor, the shape context, to each point. The shape context at a reference point captures the distribution of the remaining points relative to it, thus offering a globally discriminative characterization. Corresponding points on two similar shapes will have similar shape contexts, enabling us to solve for correspondences as an optimal assignment problem. Given the point correspondences, we estimate the transformation that best aligns the two shapes; regularized thin-plate splines provide a flexible class of transformation maps for this purpose. The dissimilarity between the two shapes is computed as a sum of matching errors between corresponding points, together with a term measuring the magnitude of the aligning transform. We treat recognition in a nearest-neighbor classification framework as the problem of finding the stored prototype shape that is maximally similar to that in the image. Results are presented for silhouettes, trademarks, handwritten digits, and the COIL data set.","title":"Shape matching and object recognition using shape contexts","venue":"IEEE Transactions on Pattern Analysis and Machine Intelligence","year":2002,"__v":0,"citationCount":2839,"parents":{"00909251-9935-44f3-94a1-629023b5015b":0,"042d18d1-aed3-4a9d-ba8b-fb7f3e14f568":14.285714285714285,"0fc7a847-923c-4742-9b05-2b46eda24b2e":8.571428571428571,"110d4ac1-9abd-4678-882c-56933790933c":0,"13cd743f-beb9-43a1-8e08-2ef08f0d8b3f":0,"1e4f4b5c-55e0-4d5b-b7cc-9e7fada3e341":0,"1ef607fe-5348-4658-8964-25a57fc49270":2.857142857142857,"23c61d04-333b-42c1-b8f8-a93cc33f4411":8.571428571428571,"24187b9b-fe6b-484d-9a0e-0b849362fa18":2.857142857142857,"25b0c9f9-0c8a-4f2a-b075-90d339b6faa3":0,"2a082569-b03f-474a-8e45-dfd713557277":0,"2ae7a9b5-6231-45ca-9813-afc3a6b5f5ff":34.285714285714285,"31d3bf4a-4175-414e-84c4-0eb8e42fc66e":0,"37032748-43bb-410a-8349-d2808bb6f7fa":11.428571428571429,"4a29b56b-b74e-4945-9017-61a7ab844fd9":2.857142857142857,"50dd56db-151d-4d62-8576-65f0ef6f381b":0,"59ade036-678c-42ad-bce8-7aa9301103e1":5.714285714285714,"5ae4ef7f-b13a-4e78-8afd-1e2d22259b87":0,"5ebbd1f5-dfe5-4eec-9883-b8b5efea366c":0,"5f1992df-975f-49e7-bd88-aee0740317cf":5.714285714285714,"6018a516-8149-4bce-bc33-5449d86e58c2":5.714285714285714,"6d86ad90-fe62-40e5-b917-7e3f31350523":0,"772654a7-a951-4327-aca5-ba5da8dfec7c":0,"88f85c71-d474-4d12-9c74-43ac3b7c7ee6":8.571428571428571,"8fc9506c-3603-4af2-b0c8-02b368863fcb":54.285714285714285,"923f5d0a-23a3-4fb1-bee7-ec72122709a4":0,"932ef745-7197-4b00-bcd4-781bd048938f":0,"9f84e529-87a3-42f1-9d63-9af710f40925":0,"a8c6ead3-d61a-4f6a-a702-08743f19eec9":0,"bf1d8c69-aefb-4a7a-8b02-f815b754833c":2.857142857142857,"d5f8e154-e8c9-45e8-a3a0-fd705f00ced4":0,"d6104d9a-faaa-4db4-8c4e-748176157ef2":5.714285714285714,"d9752a5a-1603-45cc-9a21-7997750d429f":0,"f1268507-d7ad-40be-a33a-083131f0ca8c":0,"f3959783-a9aa-48a2-9fcc-978879de365e":5.714285714285714},"keyword":{"00909251-9935-44f3-94a1-629023b5015b":8.808862433862435,"042d18d1-aed3-4a9d-ba8b-fb7f3e14f568":11.707936507936509,"0fc7a847-923c-4742-9b05-2b46eda24b2e":0,"110d4ac1-9abd-4678-882c-56933790933c":11.859060846560842,"13cd743f-beb9-43a1-8e08-2ef08f0d8b3f":9.837619047619047,"1e4f4b5c-55e0-4d5b-b7cc-9e7fada3e341":9.298201058201059,"1ef607fe-5348-4658-8964-25a57fc49270":12.039470899470903,"23c61d04-333b-42c1-b8f8-a93cc33f4411":10.167804232804233,"24187b9b-fe6b-484d-9a0e-0b849362fa18":12.225423280423279,"25b0c9f9-0c8a-4f2a-b075-90d339b6faa3":9.76931216931217,"2a082569-b03f-474a-8e45-dfd713557277":10.630582010582012,"2ae7a9b5-6231-45ca-9813-afc3a6b5f5ff":12.392592592592592,"31d3bf4a-4175-414e-84c4-0eb8e42fc66e":11.764669312169316,"37032748-43bb-410a-8349-d2808bb6f7fa":9.06410052910053,"4a29b56b-b74e-4945-9017-61a7ab844fd9":7.236798941798942,"50dd56db-151d-4d62-8576-65f0ef6f381b":12.091442816442816,"59ade036-678c-42ad-bce8-7aa9301103e1":10.8755291005291,"5ae4ef7f-b13a-4e78-8afd-1e2d22259b87":10.662076719576719,"5ebbd1f5-dfe5-4eec-9883-b8b5efea366c":9.854894179894181,"5f1992df-975f-49e7-bd88-aee0740317cf":10.22804232804233,"6018a516-8149-4bce-bc33-5449d86e58c2":10.083042328042328,"6d86ad90-fe62-40e5-b917-7e3f31350523":11.654179894179894,"772654a7-a951-4327-aca5-ba5da8dfec7c":10.157447089947093,"88f85c71-d474-4d12-9c74-43ac3b7c7ee6":10.593095238095238,"8fc9506c-3603-4af2-b0c8-02b368863fcb":13.062592592592594,"923f5d0a-23a3-4fb1-bee7-ec72122709a4":9.535978835978836,"932ef745-7197-4b00-bcd4-781bd048938f":11.660502645502646,"9f84e529-87a3-42f1-9d63-9af710f40925":11.397751322751324,"a8c6ead3-d61a-4f6a-a702-08743f19eec9":10.024761904761904,"bf1d8c69-aefb-4a7a-8b02-f815b754833c":10.378121693121692,"d5f8e154-e8c9-45e8-a3a0-fd705f00ced4":11.244074074074076,"d6104d9a-faaa-4db4-8c4e-748176157ef2":11.719828042328043,"d9752a5a-1603-45cc-9a21-7997750d429f":10.513227513227514,"f1268507-d7ad-40be-a33a-083131f0ca8c":0,"f3959783-a9aa-48a2-9fcc-978879de365e":11.390687830687833},"topic":["shape","point","similar","correspond","transform"],"groups":[{"authors":["Serge J. Belongie","Jitendra Malik","Jan Puzicha"],"references":["00909251-9935-44f3-94a1-629023b5015b","042d18d1-aed3-4a9d-ba8b-fb7f3e14f568","0fc7a847-923c-4742-9b05-2b46eda24b2e","13cd743f-beb9-43a1-8e08-2ef08f0d8b3f","1ef607fe-5348-4658-8964-25a57fc49270","24187b9b-fe6b-484d-9a0e-0b849362fa18","2ae7a9b5-6231-45ca-9813-afc3a6b5f5ff","37032748-43bb-410a-8349-d2808bb6f7fa","59ade036-678c-42ad-bce8-7aa9301103e1","5ae4ef7f-b13a-4e78-8afd-1e2d22259b87","5ebbd1f5-dfe5-4eec-9883-b8b5efea366c","772654a7-a951-4327-aca5-ba5da8dfec7c","88f85c71-d474-4d12-9c74-43ac3b7c7ee6","923f5d0a-23a3-4fb1-bee7-ec72122709a4","932ef745-7197-4b00-bcd4-781bd048938f","9f84e529-87a3-42f1-9d63-9af710f40925","a8c6ead3-d61a-4f6a-a702-08743f19eec9","b592576f-ff29-4a68-9b2f-8a8ad02e9c70","bf1d8c69-aefb-4a7a-8b02-f815b754833c","f3959783-a9aa-48a2-9fcc-978879de365e"],"_id":"8fc9506c-3603-4af2-b0c8-02b368863fcb","abstract":"We present a novel approach to measuring similarity between shapes and exploit it for object recognition. In our framework, the measurement of similarity is preceded by (1) solving for correspondences between points on the two shapes, (2) using the correspondences to estimate an aligning transform. In order to solve the correspondence problem, we attach a descriptor, the shape context, to each point. The shape context at a reference point captures the distribution of the remaining points relative to it, thus offering a globally discriminative characterization. Corresponding points on two similar shapes will have similar shape contexts, enabling us to solve for correspondences as an optimal assignment problem. Given the point correspondences, we estimate the transformation that best aligns the two shapes; regularized thin-plate splines provide a flexible class of transformation maps for this purpose. Dis-similarity between two shapes is computed as a sum of matching errors between corresponding points, together with a term measuring the magnitude of the aligning transform. We treat recognition in a nearest-neighbor classification framework. Results are presented for silhouettes, trademarks, handwritten digits and the COIL dataset.","title":"Matching shapes","venue":"international conference on computer vision","year":2001,"__v":0,"citationCount":155},{"authors":["Serge J. Belongie","Jitendra Malik","Jan Puzicha"],"references":["00909251-9935-44f3-94a1-629023b5015b","042d18d1-aed3-4a9d-ba8b-fb7f3e14f568","0fc7a847-923c-4742-9b05-2b46eda24b2e","13cd743f-beb9-43a1-8e08-2ef08f0d8b3f","1e4f4b5c-55e0-4d5b-b7cc-9e7fada3e341","1ef607fe-5348-4658-8964-25a57fc49270","59ade036-678c-42ad-bce8-7aa9301103e1","5ebbd1f5-dfe5-4eec-9883-b8b5efea366c","6d86ad90-fe62-40e5-b917-7e3f31350523","88f85c71-d474-4d12-9c74-43ac3b7c7ee6","932ef745-7197-4b00-bcd4-781bd048938f","a8c6ead3-d61a-4f6a-a702-08743f19eec9","b592576f-ff29-4a68-9b2f-8a8ad02e9c70"],"_id":"2ae7a9b5-6231-45ca-9813-afc3a6b5f5ff","abstract":"We develop an approach to object recognition based on matching shapes and using a resulting measure of similarity in a nearest neighbor classifier. The key algorithmic problem here is that of finding pointwise correspondences between an image shape and a stored prototype shape. We introduce a new shape descriptor, the shape context, which makes this possible, using a simple and robust algorithm. The shape context at a point captures the distribution over relative positions of other shape points and thus summarizes global shape in a rich, local descriptor. We demonstrate that shape contexts greatly simplify recovery of correspondences between points of two given shapes. Once shapes are aligned, shape contexts are used to define a robust score for measuring shape similarity. We have used this score in a nearest-neighbor classifier for recognition of hand written digits as well as 3D objects, using exactly the same distance function. On the benchmark MNIST dataset of handwritten digits, this yields an error rate of 0.63%, outperforming other published techniques.","title":"Shape Context: A New Descriptor for Shape Matching and Object Recognition","venue":"neural information processing systems","year":2001,"__v":0,"citationCount":190}],"offsprings":["89f10062-acf1-4171-b882-f3222c3a357e","8d8e7d51-3223-4776-bf6a-40306774b8a1"]},"c4710c73-497d-44f0-ae10-64613eca18d4":{"authors":["Jiawei Han","Jian Pei","Yiwen Yin"],"references":[],"_id":"c4710c73-497d-44f0-ae10-64613eca18d4","abstract":"Mining frequent patterns in transaction databases, time-series databases, and many other kinds of databases has been studied popularly in data mining research. Most of the previous studies adopt an Apriori-like candidate set generation-and-test approach. However, candidate set generation is still costly, especially when there exist prolific patterns and/or long patterns.  In this study, we propose a novel frequent pattern tree (FP-tree) structure, which is an extended prefix-tree structure for storing compressed, crucial information about frequent patterns, and develop an efficient FP-tree-based mining method, FP-growth, for mining  the complete set of frequent patterns  by pattern fragment growth. Efficiency of mining is achieved with three techniques: (1) a large database is compressed into a highly condensed, much smaller data structure, which avoids costly, repeated database scans, (2) our FP-tree-based mining adopts a pattern fragment growth method to avoid the costly generation of a large number of candidate sets, and (3) a partitioning-based, divide-and-conquer method is used to decompose the mining task into a set of smaller tasks for mining confined patterns in conditional databases, which dramatically reduces the search space. Our performance study shows that the FP-growth method is efficient and scalable for mining both long and short frequent patterns, and is about an order of magnitude faster than the Apriori algorithm and also faster than some recently reported new frequent pattern mining methods.","title":"Mining frequent patterns without candidate generation","venue":"international conference on management of data","year":2000,"__v":0,"citationCount":2400,"parents":{"075ff7fd-4935-4326-bcb5-b9f9db9ba23e":7.142857142857142,"1ce3d85e-68eb-4058-beae-59725276d6fc":7.142857142857142,"34b7e270-80d7-46d5-a6f1-e50087a8d045":0,"668495d0-628d-42d9-8b8e-66f5369c2cb8":7.142857142857142,"82c534c6-c89d-4856-b6fc-e1cad5be4482":7.142857142857142,"8534e0ef-abd5-4143-aeae-fe98091cbebb":14.285714285714285,"8a6a4c08-fdc8-49c4-8e73-23e7fdb466d6":28.57142857142857,"91f98247-ab9a-459c-ac7c-309ee51f62bd":28.57142857142857,"97f0f520-6175-409f-8a18-6878fa620ed4":14.285714285714285,"c457e6d6-8e92-4938-bed0-3fd6b90dc58b":7.142857142857142,"c9b05538-7ed2-48a2-b969-62f1adbb04b2":0,"e8ab235f-d709-4d84-87d4-c2dba5b73d32":7.142857142857142,"f5147c9a-4029-4e34-a95c-77e2aa34ccc5":42.857142857142854,"f7346369-949a-4d6d-9f20-261d5fb51a89":7.142857142857142},"keyword":{"075ff7fd-4935-4326-bcb5-b9f9db9ba23e":9.603571428571428,"1ce3d85e-68eb-4058-beae-59725276d6fc":9.703968253968254,"34b7e270-80d7-46d5-a6f1-e50087a8d045":0,"668495d0-628d-42d9-8b8e-66f5369c2cb8":11.791071428571426,"82c534c6-c89d-4856-b6fc-e1cad5be4482":10.95436507936508,"8534e0ef-abd5-4143-aeae-fe98091cbebb":12.482888407888408,"8a6a4c08-fdc8-49c4-8e73-23e7fdb466d6":10.457539682539682,"91f98247-ab9a-459c-ac7c-309ee51f62bd":0,"97f0f520-6175-409f-8a18-6878fa620ed4":10.889497354497355,"c457e6d6-8e92-4938-bed0-3fd6b90dc58b":11.015357142857141,"c9b05538-7ed2-48a2-b969-62f1adbb04b2":10.45238095238095,"e8ab235f-d709-4d84-87d4-c2dba5b73d32":0,"f5147c9a-4029-4e34-a95c-77e2aa34ccc5":10.08373015873016,"f7346369-949a-4d6d-9f20-261d5fb51a89":11.361111111111112},"topic":["pattern","frequent","databas","set","method"],"groups":[{"authors":["Sergey Brin","Rajeev Motwani","Craig Silverstein"],"references":["1012cd0d-9eaf-423b-875e-f82f94628434","196803d1-e419-4897-9dc9-b760208c802e","1ce3d85e-68eb-4058-beae-59725276d6fc","24188611-1420-4eb7-8ca3-3466ef9b7f0a","2af2b6e8-d7aa-477a-abee-2e304c5164e9","34b7e270-80d7-46d5-a6f1-e50087a8d045","3f00f5e4-42c3-4cca-9ee5-44312a55c6d3","51a2a139-ff14-4e03-9ee7-4a3806385a31","5ce19dd6-2045-4c4d-b2a9-5d65a2ba822f","5ffb3cc3-7e36-46d3-aeb7-3f23ac9d9951","82c534c6-c89d-4856-b6fc-e1cad5be4482","929abc46-4b62-459b-a972-caa1d09e0fcc","c49e6979-a8e3-4d37-b515-b2a5400e9522","c99baeec-d70e-4cc0-aa54-cf39fb18cf9b","e8ab235f-d709-4d84-87d4-c2dba5b73d32","e97695ef-712a-43d7-b685-5ead1dce1139","e9b4081d-d54d-4bfd-8c83-238d1be7401d","ecd6a845-8439-49b0-abe8-f71fff81da23"],"_id":"8a6a4c08-fdc8-49c4-8e73-23e7fdb466d6","abstract":"One of the most well-studied problems in data mining is mining for association rules in market basket data. Association rules, whose significance is measured via support and confidence, are intended to identify rules of the type, “A customer purchasing item A often also purchases item B.” Motivated by the goal of generalizing beyond market baskets and the association rules used with them, we develop the notion of mining rules that identify correlations (generalizing associations), and we consider both the absence and presence of items as a basis for generating rules. We propose measuring significance of associations via the chi-squared test for correlation from classical statistics. This leads to a measure that is upward closed in the itemset lattice, enabling us to reduce the mining problem to the search for a border between correlated and uncorrelated itemsets in the lattice. We develop pruning strategies and devise an efficient algorithm for the resulting problem. We demonstrate its effectiveness by testing it on census data and finding term dependence in a corpus of text documents, as well as on synthetic data.","title":"Beyond market baskets: generalizing association rules to correlations","venue":"international conference on management of data","year":1997,"__v":0,"citationCount":617},{"authors":["Gösta Grahne","Laks V. S. Lakshmanan","Xiaohong Wang"],"references":["1ce3d85e-68eb-4058-beae-59725276d6fc","1e7d8f60-05e0-4515-822d-0ca2fa9c1029","66569d9a-07d1-4946-842a-80edcc26b15b","70d22077-68e8-4eb1-a955-5b1c5b59cb4a","74124cdf-4269-4256-a3a6-04e14437e201","82c534c6-c89d-4856-b6fc-e1cad5be4482","84bd94db-7c6f-428d-af86-4e6904a44d79","86dafb65-1d2e-42d9-8982-4d520b6da774","8a6a4c08-fdc8-49c4-8e73-23e7fdb466d6","acc12e1e-3e1d-4f9e-b24b-20cd3dae38ce","c457e6d6-8e92-4938-bed0-3fd6b90dc58b","d1c93534-82a5-41fa-a5fa-9d18f5c2577f","d1fffed2-0e98-498d-8e63-29237655adb9","e8ab235f-d709-4d84-87d4-c2dba5b73d32","e97695ef-712a-43d7-b685-5ead1dce1139","ecd6a845-8439-49b0-abe8-f71fff81da23","f7346369-949a-4d6d-9f20-261d5fb51a89"],"_id":"f5147c9a-4029-4e34-a95c-77e2aa34ccc5","abstract":"Studies the problem of efficiently computing correlated item sets satisfying given constraints. We call them valid correlated item sets. It turns out that constraints can have subtle interactions with correlated item sets, depending on their underlying properties. We show that, in general, the set of minimal valid correlated item sets does not coincide with that of minimal correlated item sets that are valid, and we characterize classes of constraints for which these sets coincide. We delineate the meaning of these two spaces and give algorithms for computing them. We also give an analytical evaluation of their performance and validate our analysis with a detailed experimental evaluation.","title":"Efficient mining of constrained correlated sets","venue":"international conference on data engineering","year":2000,"__v":0,"citationCount":89}],"offsprings":[]},"c7e4e04b-45da-4bae-8c8a-d17ca0087361":{"authors":["Sergey Brin","Lawrence Page"],"references":[],"_id":"c7e4e04b-45da-4bae-8c8a-d17ca0087361","abstract":"In this paper, we present Google, a prototype of a large-scale search engine which makes heavy use of the structure present in hypertext. Google is designed to crawl and index the Web efficiently and produce much more satisfying search results than existing systems. The  prototype with a full text and hyperlink database of at least 24 million pages is available at http://google.stanford.edu/. To engineer a search  engine is a challenging task. Search engines index tens to hundreds of millions of web pages involving a comparable number of distinct terms. They answer tens of millions of queries every day. Despite the importance of large-scale search engines on the web, very little academic research has been done on them. Furthermore, due to rapid advance in technology and web proliferation, creating a web search  engine today is very different from three years ago. This paper provides an in-depth description of our large-scale web search engine -- the first such detailed public description we know of to date. Apart from the problems of scaling traditional search techniques to data of this magnitude, there are new technical challenges involved with using the additional information present in hypertext to produce better search results. This paper addresses this question of how to build a practical large-scale system which can exploit the additional information present in hypertext. Also we look at the problem of how to effectively deal with uncontrolled hypertext collections where anyone can publish anything they want.","title":"The anatomy of a large-scale hypertextual Web search engine","venue":"international world wide web conferences","year":1998,"__v":0,"citationCount":5333,"parents":{"2256cad0-cf03-42da-bcf3-4a89be0ebf8e":50,"3c3ca791-aff2-4212-8b20-ae0657d4e6b6":0,"529f0775-01b2-4f1e-9d89-fc5227058019":37.5,"7f9d5474-f731-4939-95e3-156e2cfc42a4":12.5,"a5f0deb7-ce61-46d5-8cc2-b8362fd63db3":0,"afa3a972-e82d-49fb-ad16-be307431134f":0,"d88f4bfe-042e-4d15-a2e3-de57c499b388":0,"ff269dbf-6570-4409-8cab-6ac142450d05":0},"keyword":{"2256cad0-cf03-42da-bcf3-4a89be0ebf8e":9.540383597883595,"3c3ca791-aff2-4212-8b20-ae0657d4e6b6":10.692460317460318,"529f0775-01b2-4f1e-9d89-fc5227058019":9.713650793650794,"7f9d5474-f731-4939-95e3-156e2cfc42a4":9.632010582010581,"a5f0deb7-ce61-46d5-8cc2-b8362fd63db3":8.785052910052912,"afa3a972-e82d-49fb-ad16-be307431134f":11.697222222222221,"d88f4bfe-042e-4d15-a2e3-de57c499b388":9.820370370370371,"ff269dbf-6570-4409-8cab-6ac142450d05":0},"topic":["search","engin","web","present","largescal"],"groups":[{"authors":["Jon M. Kleinberg"],"references":["0c23971f-2165-4a9b-83b1-00b08556d421","18b76b58-2d45-4dae-9f1f-0f4f7aae043c","27e4ec4d-0ce3-437b-9511-db610b7ba805","2cb58ea7-0b7c-4428-ac1e-aa2f7e434d1a","373b4f77-3e42-4683-9ae4-0378241e7325","3ed1f08a-a411-4078-b187-d95da5a38c4f","407ceb18-464f-4ab3-b731-68f7681fb26d","50d9a0e1-00a5-4445-b8b2-9f1405cbe6e1","529f0775-01b2-4f1e-9d89-fc5227058019","5a7d936d-b433-47c4-8955-a529c23e1498","5cc06390-77b7-4589-b42b-8b3254d755ad","6e551a7c-6769-49c1-93c5-037a06f4aaef","7dce00bc-8d45-4886-a341-63b5039217a7","8f6cafa9-28c3-424e-87bd-c28c8e57a44f","96dc598a-fd41-420f-adc7-5498bc4830de","9785caef-a673-488d-9eaf-cf6d24108013","9cbb490c-d8e9-4dc9-84a7-8238ca21d0a5","a5f0deb7-ce61-46d5-8cc2-b8362fd63db3","ac14afe6-de4d-4056-b2ac-0f6e36f369a2","afa37e9f-2a18-4d29-bae1-ba93edd2a163","afa3a972-e82d-49fb-ad16-be307431134f","b84a20e0-0f9a-4a1c-82d3-1a940ffc4163","b9a25393-edf2-4e39-8252-64d332f225dd","c19c233b-6b1d-40a9-b553-a6efbe11932c","c7e4e04b-45da-4bae-8c8a-d17ca0087361","d7953b97-e51b-45e2-b0f7-5e2eed1f9bd3","e127b1a6-04b4-4a24-9caf-59738ad3ee4b","ed52603b-0cce-4606-a75c-a700bc4305bf","f1011b3e-1a8f-4cd2-bdb8-d5b6dce8f77a","ff269dbf-6570-4409-8cab-6ac142450d05"],"_id":"2256cad0-cf03-42da-bcf3-4a89be0ebf8e","abstract":"The network structure of a hyperlinked environment can be a rich source of information about the content of the environment, provided we have eective means for understanding it. We develop a set of algorithmic tools for extracting information from the link structures of such environments, and report on experiments that demonstrate their eectiveness in a variety of contexts on the World Wide Web. The central issue we address within our framework is the distillation of broad search topics, through the discovery of \\authoritative\" information sources on such topics. We propose and test an algorithmic formulation of the notion of authority, based on the relationship between a set of relevant authoritative pages and the set of \\hub pages\" that join them together in the link structure. Our formulation has connections to the eigenvectors of certain matrices associated with the link graph; these connections in turn motivate additional heuristics for link-based analysis.","title":"Authoritative sources in a hyperlinked environment","venue":"symposium on discrete algorithms","year":1998,"__v":0,"citationCount":1155},{"authors":["Soumen Chakrabarti","Byron Dom","Prabhakar Raghavan","Sridhar Rajagopalan","David Gibson","Jon M. Kleinberg"],"references":["2256cad0-cf03-42da-bcf3-4a89be0ebf8e","7dce00bc-8d45-4886-a341-63b5039217a7","8f6cafa9-28c3-424e-87bd-c28c8e57a44f","96dc598a-fd41-420f-adc7-5498bc4830de","a5f0deb7-ce61-46d5-8cc2-b8362fd63db3","b9a25393-edf2-4e39-8252-64d332f225dd","c7e4e04b-45da-4bae-8c8a-d17ca0087361","ff269dbf-6570-4409-8cab-6ac142450d05"],"_id":"529f0775-01b2-4f1e-9d89-fc5227058019","abstract":"We describe the design, prototyping and evaluation of ARC, a system for automatically compiling a list of authoritative Web resources on any (sufficiently broad) topic. The goal of ARC is to compile resource lists similar to those provided by Yahoo! or Infoseek. The fundamental difference is that these services construct lists either manually or through a combination of human and automated effort, while ARC operates fully automatically. We describe the evaluation of ARC, Yahoo!, and Infoseek resource lists by a panel of human users. This evaluation suggests that the resources found by ARC frequently fare almost as well as, and sometimes better than, lists of resources that are manually compiled or classified into a topic. We also provide examples of ARC resource lists for the reader to examine.","title":"Automatic resource compilation by analyzing hyperlink structure and associated text","venue":"international world wide web conferences","year":1998,"__v":0,"citationCount":387}],"offsprings":["68faab18-b537-4f62-85cf-ddc9ef352362","8f9e92cf-f266-4e51-807f-c098a260a0dc","b0ef6e4d-4c86-4b10-9e0a-7b630ca8d7f7","64316b39-e0c7-493d-8d84-b93cc5cb291c"]},"c8f80ea6-4602-458c-9a70-daf1c646c89b":{"authors":["Dorin Comaniciu","Peter Meer"],"references":["0c32535a-72bb-4fda-b12b-627147f8b358","7b57db11-7c4d-4d1e-aa62-3a5d7d1f7987"],"_id":"c8f80ea6-4602-458c-9a70-daf1c646c89b","abstract":"A general non-parametric technique is proposed for the analysis of a complex multimodal feature space and to delineate arbitrarily shaped clusters in it. The basic computational module of the technique is an old pattern recognition procedure: the mean shift. For discrete data, we prove the convergence of a recursive mean shift procedure to the nearest stationary point of the underlying density function and, thus, its utility in detecting the modes of the density. The relation of the mean shift procedure to the Nadaraya-Watson estimator from kernel regression and the robust M-estimators; of location is also established. Algorithms for two low-level vision tasks discontinuity-preserving smoothing and image segmentation - are described as applications. In these algorithms, the only user-set parameter is the resolution of the analysis, and either gray-level or color images are accepted as input. Extensive experimental results illustrate their excellent performance.","title":"Mean shift: a robust approach toward feature space analysis","venue":"IEEE Transactions on Pattern Analysis and Machine Intelligence","year":2002,"__v":0,"citationCount":3903,"parents":{"01df6660-e54b-4cab-a20e-179393feb854":24.390243902439025,"088d00cf-ed12-4552-8958-8b550401f355":0,"0c32535a-72bb-4fda-b12b-627147f8b358":2.4390243902439024,"1017d9d4-9a4c-423d-ad40-6d9bebbd6b31":0,"1192f1a1-7265-4886-a8f5-abed536b07b2":9.75609756097561,"1f55baf9-4f9a-4c9c-99ff-75e85a560c52":0,"209f46d1-66c6-496c-ba83-6a0a7e03db6a":2.4390243902439024,"21c9f688-56e7-4018-8bd0-3995f086598d":2.4390243902439024,"2807e6ff-b9a5-49ec-8b9f-892aee014156":0,"35426f5d-4886-4c49-b752-aec497760038":0,"3544f26c-7ca1-458c-9c28-24ac9612597c":2.4390243902439024,"3da61fff-399e-4c16-83e1-39f805b34464":4.878048780487805,"3fef39b1-5391-4424-9847-bfe85c9802f2":0,"42609520-598f-421d-8f8c-3dbb26081d95":0,"48b2f9f3-f780-4f6b-95b9-b650bb93ef65":2.4390243902439024,"4ef71595-df33-4849-aafd-7092328d04a7":2.4390243902439024,"540e185e-4473-4e4a-aef3-b624d0fbf25a":0,"54c6dc5e-b647-4ac3-a31a-afab59c8b4fa":2.4390243902439024,"57958425-17fa-46de-a93e-e72f38d481f8":2.4390243902439024,"5824891b-fe0c-404b-9365-085843b11f26":0,"6dfd9077-2f59-4692-9fcc-f9e336591a15":0,"70b17c09-d19a-451b-acc4-b3747ffa96d9":0,"756a08c5-b7e8-4dee-a019-cba0f0fe482b":2.4390243902439024,"795b3efb-a6e8-479a-81f6-91328002dc03":0,"79ee46f3-5808-4687-bec9-7b35c9e51fe6":0,"7b57db11-7c4d-4d1e-aa62-3a5d7d1f7987":2.4390243902439024,"84d43d53-4371-44e7-9cfd-c4be7cc48483":0,"904be517-8954-4149-87ce-889b629463df":4.878048780487805,"970d3cf0-11a6-4c04-b8e1-7eaca9dbc757":2.4390243902439024,"9a5c5874-2877-4b08-87cc-cc61ce9b7653":2.4390243902439024,"a4f0f562-bbfb-43ac-a175-fa17ca2ff0fb":4.878048780487805,"a77c2879-23b2-476f-884d-20b591a20b1d":0,"b29cb808-1f59-40e9-8afa-26a3701b6284":17.073170731707318,"b3a4feeb-0d9c-4a10-89d3-8ca0852d04e7":0,"b608af66-6368-44dc-a670-2a3e42561ee1":0,"d4096c82-a4ad-41c8-a3c6-4aa2924dfcbb":2.4390243902439024,"d69429ef-c8d6-4074-b1b2-73a7bc5e2fa6":2.4390243902439024,"e5f5cacc-f6da-458e-b8cb-bcfbd753e611":0,"ee8ff75d-caec-42e9-aa07-cbe4fdd7541b":4.878048780487805,"f2c49442-eed0-4e05-bb94-9fdaa0312e9f":2.4390243902439024,"f9c4a94d-c1e6-494f-bff9-1bb96f9ccb33":2.4390243902439024},"keyword":{"01df6660-e54b-4cab-a20e-179393feb854":10.72142857142857,"088d00cf-ed12-4552-8958-8b550401f355":10.792222222222222,"0c32535a-72bb-4fda-b12b-627147f8b358":6.987301587301587,"1017d9d4-9a4c-423d-ad40-6d9bebbd6b31":0,"1192f1a1-7265-4886-a8f5-abed536b07b2":10.526349206349206,"1f55baf9-4f9a-4c9c-99ff-75e85a560c52":11.487248677248674,"209f46d1-66c6-496c-ba83-6a0a7e03db6a":11.209047619047617,"21c9f688-56e7-4018-8bd0-3995f086598d":9.680873015873017,"2807e6ff-b9a5-49ec-8b9f-892aee014156":8.771984126984126,"35426f5d-4886-4c49-b752-aec497760038":10.42218253968254,"3544f26c-7ca1-458c-9c28-24ac9612597c":8.229563492063491,"3da61fff-399e-4c16-83e1-39f805b34464":10.005793650793649,"3fef39b1-5391-4424-9847-bfe85c9802f2":9.667407407407406,"42609520-598f-421d-8f8c-3dbb26081d95":9.49563492063492,"48b2f9f3-f780-4f6b-95b9-b650bb93ef65":10.841164021164019,"4ef71595-df33-4849-aafd-7092328d04a7":8.827619047619047,"540e185e-4473-4e4a-aef3-b624d0fbf25a":6.352142857142857,"54c6dc5e-b647-4ac3-a31a-afab59c8b4fa":10.688095238095237,"57958425-17fa-46de-a93e-e72f38d481f8":10.047103174603174,"5824891b-fe0c-404b-9365-085843b11f26":9.579126984126985,"6dfd9077-2f59-4692-9fcc-f9e336591a15":8.198571428571428,"70b17c09-d19a-451b-acc4-b3747ffa96d9":8.554603174603175,"756a08c5-b7e8-4dee-a019-cba0f0fe482b":10.030674603174603,"795b3efb-a6e8-479a-81f6-91328002dc03":8.631825396825397,"79ee46f3-5808-4687-bec9-7b35c9e51fe6":7.043809523809524,"7b57db11-7c4d-4d1e-aa62-3a5d7d1f7987":5.423214285714287,"84d43d53-4371-44e7-9cfd-c4be7cc48483":8.205039682539683,"904be517-8954-4149-87ce-889b629463df":10.103015873015872,"970d3cf0-11a6-4c04-b8e1-7eaca9dbc757":10.295595238095238,"9a5c5874-2877-4b08-87cc-cc61ce9b7653":9.227579365079364,"a4f0f562-bbfb-43ac-a175-fa17ca2ff0fb":7.043809523809524,"a77c2879-23b2-476f-884d-20b591a20b1d":9.779365079365078,"b29cb808-1f59-40e9-8afa-26a3701b6284":9.766560846560846,"b3a4feeb-0d9c-4a10-89d3-8ca0852d04e7":9.399960317460318,"b608af66-6368-44dc-a670-2a3e42561ee1":10.258809523809523,"d4096c82-a4ad-41c8-a3c6-4aa2924dfcbb":7.309523809523809,"d69429ef-c8d6-4074-b1b2-73a7bc5e2fa6":9.564550264550265,"e5f5cacc-f6da-458e-b8cb-bcfbd753e611":7.903968253968253,"ee8ff75d-caec-42e9-aa07-cbe4fdd7541b":9.446230158730158,"f2c49442-eed0-4e05-bb94-9fdaa0312e9f":10.638412698412695,"f9c4a94d-c1e6-494f-bff9-1bb96f9ccb33":7.37718253968254},"topic":["shift","procedur","techniqu","imag","densiti"],"groups":[{"authors":["Dorin Comaniciu","Peter Meer"],"references":["088d00cf-ed12-4552-8958-8b550401f355","0c32535a-72bb-4fda-b12b-627147f8b358","209f46d1-66c6-496c-ba83-6a0a7e03db6a","21c9f688-56e7-4018-8bd0-3995f086598d","2ea16f6a-9fb7-4cbb-b632-4297abca8665","57958425-17fa-46de-a93e-e72f38d481f8","70b17c09-d19a-451b-acc4-b3747ffa96d9","79ee46f3-5808-4687-bec9-7b35c9e51fe6","b608af66-6368-44dc-a670-2a3e42561ee1","e5f5cacc-f6da-458e-b8cb-bcfbd753e611","ee8ff75d-caec-42e9-aa07-cbe4fdd7541b"],"_id":"01df6660-e54b-4cab-a20e-179393feb854","abstract":"A nonparametric estimator of density gradient, the mean shift, is employed in the joint, spatial-range (value) domain of gray level and color images for discontinuity preserving filtering and image segmentation. Properties of the mean shift are reviewed and its convergence on lattices is proven. The proposed filtering method associates with each pixel in the image the closest local mode in the density distribution of the joint domain. Segmentation into a piecewise constant structure requires only one more step, fusion of the regions associated with nearby modes. The proposed technique has two parameters controlling the resolution in the spatial and range domains. Since convergence is guaranteed, the technique does not require the intervention of the user to stop the filtering at the desired image quality. Several examples, for gray and color images, show the versatility of the method and compare favorably with results described in the literature for the same images.","title":"Mean shift analysis and applications","venue":"international conference on computer vision","year":1999,"__v":0,"citationCount":360}],"offsprings":["79da913e-c4d6-4d89-831c-f68f7976dcfc","3ed17ffd-b416-470a-973a-77d7085a3503"]},"d1ba534e-3f80-4366-bb83-be16006f9e18":{"authors":["Simon Haykin"],"references":["310cbba4-d88d-4bf4-a4f2-738f91b5f8c8","720f59d2-acc3-4d5a-91c2-258d137d9647","8cc9ea80-563f-4e62-bda9-8ff6d71cf6ae","f1e74152-3f7c-4c44-b628-cdf47a17587f"],"_id":"d1ba534e-3f80-4366-bb83-be16006f9e18","abstract":"Cognitive radio is viewed as a novel approach for improving the utilization of a precious natural resource: the radio electromagnetic spectrum. The cognitive radio, built on a software-defined radio, is defined as an intelligent wireless communication system that is aware of its environment and uses the methodology of understanding-by-building to learn from the environment and adapt to statistical variations in the input stimuli, with two primary objectives in mind: /spl middot/ highly reliable communication whenever and wherever needed; /spl middot/ efficient utilization of the radio spectrum. Following the discussion of interference temperature as a new metric for the quantification and management of interference, the paper addresses three fundamental cognitive tasks. 1) Radio-scene analysis. 2) Channel-state estimation and predictive modeling. 3) Transmit-power control and dynamic spectrum management. This work also discusses the emergent behavior of cognitive radio.","title":"Cognitive radio: brain-empowered wireless communications","venue":"IEEE Journal on Selected Areas in Communications","year":2005,"__v":0,"citationCount":4644,"parents":{"0eab603a-3623-4ed4-b9e6-18e7f38b9057":0,"0f2cb38e-b8ec-426f-ab8a-453c4ef98413":0,"310cbba4-d88d-4bf4-a4f2-738f91b5f8c8":0,"3b4570fa-e660-4909-b9ee-4b8f78d25dfe":0,"5697e140-af9e-4d63-87be-99b357d59e3a":0,"720f59d2-acc3-4d5a-91c2-258d137d9647":0,"7d3bff12-8413-4c3e-9bbd-af96df0405d7":0,"8cc9ea80-563f-4e62-bda9-8ff6d71cf6ae":0,"db26488d-78be-44b1-a343-e896f43c5d29":0,"f1e74152-3f7c-4c44-b628-cdf47a17587f":0},"keyword":{"0eab603a-3623-4ed4-b9e6-18e7f38b9057":8.04722222222222,"0f2cb38e-b8ec-426f-ab8a-453c4ef98413":6.181060606060606,"310cbba4-d88d-4bf4-a4f2-738f91b5f8c8":11.490806878306877,"3b4570fa-e660-4909-b9ee-4b8f78d25dfe":9.780423280423278,"5697e140-af9e-4d63-87be-99b357d59e3a":10.900555555555552,"720f59d2-acc3-4d5a-91c2-258d137d9647":8.85079365079365,"7d3bff12-8413-4c3e-9bbd-af96df0405d7":9.998973063973063,"8cc9ea80-563f-4e62-bda9-8ff6d71cf6ae":10.377777777777778,"db26488d-78be-44b1-a343-e896f43c5d29":0,"f1e74152-3f7c-4c44-b628-cdf47a17587f":10.504563492063491},"topic":["radio","cognit","spectrum","util","spl"],"offsprings":["a2cd0e23-f184-441d-b90e-d4492a9ef508"]},"d28acb36-5766-4c1e-8d57-a55c2630bd90":{"authors":["Yoshua Bengio"],"references":["3704f939-09a2-4e9f-b851-1261bcd310df","50dd56db-151d-4d62-8576-65f0ef6f381b","6ff01654-66d1-49c7-b526-1c8ed7fa893a","89f10062-acf1-4171-b882-f3222c3a357e","94898e1d-1e50-41ab-9dcc-2c2e030cddd0","c472bfe1-9ef6-43c6-89b5-a86b22c9f5df","f56b877b-4060-4754-b303-e8140968544c","f6bd8b64-684d-429a-aab5-8ff3a2c23cd6"],"_id":"d28acb36-5766-4c1e-8d57-a55c2630bd90","abstract":"Can machine learning deliver AI? Theoretical results, inspiration from the brain and cognition, as well as machine learning experiments suggest that in order to learn the kind of complicated functions that can represent high-level abstractions (e.g. in vision, language, and other AI-level tasks), one would need deep architectures. Deep architectures are composed of multiple levels of non-linear operations, such as in neural nets with many hidden layers, graphical models with many levels of latent variables, or in complicated propositional formulae re-using many sub-formulae. Each level of the architecture represents features at a different level of abstraction, defined as a composition of lower-level features. Searching the parameter space of deep architectures is a difficult task, but new algorithms have been discovered and a new sub-area has emerged in the machine learning community since 2006, following these discoveries. Learning algorithms such as those for Deep Belief Networks and other related unsupervised learning algorithms have recently been proposed to train deep architectures, yielding exciting results and beating the state-of-the-art in certain areas. Learning Deep Architectures for AI discusses the motivations for and principles of learning algorithms for deep architectures. By analyzing and comparing recent results with different learning algorithms for deep architectures, explanations for their success are proposed and discussed, highlighting challenges and suggesting avenues for future explorations in this area.","title":"Learning Deep Architectures for AI","venue":"","year":2009,"__v":0,"citationCount":1513,"parents":{"015086f3-b9a3-45ad-9551-93a4655b20f5":10.44776119402985,"0202b0aa-9a2e-4430-8a6c-fb40cf4b14f5":4.477611940298507,"0202d3b0-955e-4d19-a0f8-7f2fbdb832e4":0.7462686567164178,"04bd372d-bfb9-48ce-a4f6-337ea52be9d9":0,"061d43fb-e3af-4700-bdc2-2e34dfbace26":1.4925373134328357,"0d052d1b-8be4-497f-bf53-f81aee173fad":0,"1035d56c-06b3-40bb-93c7-6306b24bac93":0.7462686567164178,"16866e9f-b4f1-493e-93ab-8bd6fedb1547":0.7462686567164178,"16c37100-0533-42e1-aebd-a3805a7c3dde":0,"170c42d8-d872-4bc9-8932-59d27915cbbd":1.4925373134328357,"1a6b2fe9-5547-4464-a1c4-db73e5d67d81":0.7462686567164178,"1ce0d29c-25ee-411d-91a6-8abb3082f9cb":0,"2141b3e7-6627-4bf1-a42f-6d95050c053f":0,"22c23d0b-ffd3-4679-9297-0ca70e909b65":11.194029850746269,"29042545-4ddf-4bf9-ae8b-d65876c9eb41":0,"296a0ad4-dc5f-4158-ac11-64ffda60a439":0,"2b5b8950-10c8-4ced-b4f8-38ebbf373b56":0.7462686567164178,"2ba41db5-ac76-4805-a904-67ff0361f528":5.970149253731343,"2cd6f789-de0b-4d5d-b3d0-60962bd31d41":1.4925373134328357,"2d700d61-baaf-401f-a9bf-00c62059c03e":1.4925373134328357,"2e1b83e3-68a2-4e1a-8437-d808613f2e1b":2.2388059701492535,"30ae6b9d-ec18-466f-8481-914954a20bfb":2.2388059701492535,"32c1bdf2-cea7-4d60-8289-2207eaa41a77":4.477611940298507,"33e9cfdc-c769-43d3-9b9f-6a1cc22ecff5":2.2388059701492535,"3704f939-09a2-4e9f-b851-1261bcd310df":0.7462686567164178,"374196c1-6e90-4dd7-93fd-93a65dd8ea59":0.7462686567164178,"39797d9d-193a-4b30-96f3-cc3ffbabd9b5":0,"3b83c815-532d-4122-811f-2b57e8b80c5d":5.223880597014925,"3c1f9893-1a32-4afb-9f40-5d4856b7f886":0.7462686567164178,"40d17f93-11dd-4ddd-9bbd-3278339cb1fb":2.2388059701492535,"4119077e-f77a-4056-8f3f-36fd86a668de":7.462686567164178,"4453fa3b-308f-472a-be61-65d1ce5c3de2":1.4925373134328357,"46ddddd5-83b4-42aa-98b1-5c87a09f77d9":6.7164179104477615,"47e20669-55b1-4e50-9ef2-e9f0496ce79a":1.4925373134328357,"491d9171-c4d7-4ae1-bc19-5956c2904fc2":8.955223880597014,"49e15f5d-44e6-47e9-b94b-db0291609b30":5.970149253731343,"4b1722c2-0bff-4224-8e37-0fa6455ae487":0,"4c5ed508-b6e5-4db5-a59f-00e1d88dc221":3.731343283582089,"4fa6167f-3737-4793-a013-d1218ae53fa2":0,"4ff8f4fa-f1e0-468b-935f-ae5550e84022":1.4925373134328357,"503a985c-48d3-40c1-8690-2b21d8a92137":0.7462686567164178,"50c2b314-1596-4444-ae9a-606df9899372":1.4925373134328357,"50dd56db-151d-4d62-8576-65f0ef6f381b":0.7462686567164178,"5217d97c-5256-4bb7-b501-faf36a474ca6":1.4925373134328357,"531585eb-47e5-44b1-9efe-9901f83148c7":0.7462686567164178,"5b35e6b8-3077-4ca4-aa34-5e211cace1b9":2.9850746268656714,"60d06cf5-2360-4a3b-8bb3-a5f211f84861":2.2388059701492535,"60d19f35-5655-4774-a0ee-219230499471":3.731343283582089,"61dcad2b-ef68-4240-95e2-79c12c6bfda9":1.4925373134328357,"640bfef8-3c8b-4f57-8db8-5184529ffe1b":8.955223880597014,"69f00f82-45eb-4e2b-b239-5526d80f11ea":0,"6c6a4dc9-6224-471c-b159-a4b3d8ac96b8":0,"6e4a6bd8-16c8-4523-9f12-d64fd8ff00fe":3.731343283582089,"6ff01654-66d1-49c7-b526-1c8ed7fa893a":0.7462686567164178,"73ec9d29-4fc5-4019-97d3-c496c8509f37":5.970149253731343,"77b79c16-03f5-4c75-994e-38a9e0cc7bfe":2.2388059701492535,"77c60bee-51be-4e3f-86e5-086f7a6c8531":1.4925373134328357,"78b0ba4b-b8a0-4689-9972-cabab721ab40":5.970149253731343,"7a74bdb1-93cf-4234-b152-bd413efed591":2.9850746268656714,"7aa454b2-47c6-4117-b823-1df65289e8e7":3.731343283582089,"7ce4a38d-0732-48b8-b72a-6f5d87c5782d":0.7462686567164178,"7db5b031-03e2-4051-9049-e0cc7b0a4f11":5.970149253731343,"800c39c6-36d9-4e11-a337-c0b69c05e60d":1.4925373134328357,"80cb67a5-0117-46f2-8553-671faa21f208":0,"814db119-52fd-47a9-846a-e1d56c8f680d":1.4925373134328357,"820b9eee-e009-4dc1-b464-f5fd4485d6b3":0,"825d95f7-21af-478f-b76e-455431bad7a9":3.731343283582089,"842af4d1-b82a-4dc1-955f-6fdfc099b20d":0,"86ba72ef-465f-44dc-8068-cdd6a64f0b40":1.4925373134328357,"8735c7ea-f5c6-4310-b250-bc0d1bf5e834":0,"89f10062-acf1-4171-b882-f3222c3a357e":4.477611940298507,"8b2c0aff-4589-4e0f-aae4-4f84a4413406":0,"8d7477d3-f3cf-4db0-83eb-e2f5e22b0dc8":2.2388059701492535,"8f9df368-a9cd-4933-91fe-5d727d98da51":1.4925373134328357,"90518198-f3d5-4583-85cf-7d5bbec3ab58":0.7462686567164178,"924fe569-7b4c-4968-bcc9-35aa73dbb587":2.9850746268656714,"93a14c23-d227-41fd-ad18-7de38817cb52":0,"94898e1d-1e50-41ab-9dcc-2c2e030cddd0":2.9850746268656714,"95e314d8-096a-4130-b34e-0454dcdf9147":0,"964bf666-0a88-4d01-bc30-16c440f2b526":0.7462686567164178,"967cfa49-e7cc-420c-be14-8f6ac66e1655":3.731343283582089,"97005b64-515f-48d2-82cf-3065887be860":20.8955223880597,"991bb85a-f14e-418e-9155-305684f02c77":0,"9c2ed18d-2a96-48f2-ab3c-49b67a88f218":0,"a5084ea3-25bd-4cc7-8c79-29034e9a9c7c":1.4925373134328357,"a5e3c7d4-bdc9-46e9-9ebd-044328488842":0.7462686567164178,"a9b88757-1121-473c-9e2a-7023c1843884":0.7462686567164178,"a9e121b1-26b0-430d-97c1-19f25a59331a":2.2388059701492535,"ab9ba74d-28b2-4003-95e4-a1c71daaf484":2.2388059701492535,"ac14afe6-de4d-4056-b2ac-0f6e36f369a2":0,"ae3e7593-586f-495f-9416-4b50ed1fcd10":0,"b1ab16c4-7c50-4dfd-90e6-82a9fb00b262":0.7462686567164178,"b30cc6be-bdab-472c-a5ed-95c63237fb05":0,"b36102cf-1655-4dbf-a5f5-b6bed8c3048e":0.7462686567164178,"b46fdfbf-a80e-407d-b2b0-ad6872b0ac77":1.4925373134328357,"b5a7c221-a58f-48d7-9f03-37f28511d372":0,"b658c306-7958-481d-9559-cd3baec9edf0":2.2388059701492535,"b75abe04-6fdf-42b7-8b71-e7b05e6991da":4.477611940298507,"c10f400c-dcd6-4690-95ae-3d880660bac2":0,"c2b9beb2-7ce9-42d7-bfc3-060ab60b5139":0.7462686567164178,"c4024860-8d55-47c1-bab0-6c53f90831ee":6.7164179104477615,"c414c2ad-81f0-4af9-b63a-9e40c8233cdb":1.4925373134328357,"c472bfe1-9ef6-43c6-89b5-a86b22c9f5df":0.7462686567164178,"c920d990-8391-48a1-b6b8-0df62ba7ff47":0,"ca250ca4-70fd-411f-8cc7-fb17be31cd9e":0,"cac1601e-4f3f-4ccc-ab2e-cec922028ce4":1.4925373134328357,"cc12695a-b4f4-4d04-9ace-bf15028c7827":10.44776119402985,"ccdefe89-9b16-4c22-8bb8-bd314ccad6e1":0,"ccf1edb3-fc5d-4936-b8c5-5d9879c73b91":2.2388059701492535,"d0d13c7a-308c-4138-9802-8e7c0260bb90":2.9850746268656714,"d0d18692-434c-4c7a-b4d8-33ff328f3e3e":10.44776119402985,"d329bbfd-d0ce-452a-870b-e696a964f799":3.731343283582089,"d78003db-ad8a-48d2-be57-1c50e95cef72":0,"daee7e59-3e4d-45b2-9625-495a0167b02a":1.4925373134328357,"dcd6762a-ff44-46aa-ab12-6b951955199c":0,"de7e534b-6d80-46c7-bf2a-2b2b4112a42b":5.223880597014925,"e00917f7-1629-48db-baa5-7cc0d179de17":3.731343283582089,"e0f3a738-4ab2-40d1-ba44-506d81c1d230":0,"e30006aa-a666-4d31-a6e5-9464797811a6":0,"e4b24072-5789-4601-8088-f895f47476de":0,"e7f24795-7810-436e-832b-de1728ffd00b":0.7462686567164178,"e8571238-943e-46d2-920b-63013e5dd5cd":0.7462686567164178,"e89bb9fb-4b26-4e7a-aaf7-84c3bb498836":0,"ec8c9e00-d026-4d33-b102-ffd5389234cd":0,"f006e236-59ad-4647-a59f-4f46dc2c85be":0,"f15b056f-a577-4391-9724-a5be885e2bd2":2.2388059701492535,"f188df3f-a910-45af-9644-a7961451c999":0.7462686567164178,"f2cbb6cd-cee3-4423-bc52-f7b0a750216d":6.7164179104477615,"f56b877b-4060-4754-b303-e8140968544c":0,"f6bd8b64-684d-429a-aab5-8ff3a2c23cd6":0.7462686567164178,"f8af71de-30f9-4288-a169-13ab19bf89fb":2.9850746268656714,"fa4f4c43-9111-490f-aa0d-2a0161f8565c":2.2388059701492535,"fd4c2dc1-317b-41f0-8469-2896b2768fbb":3.731343283582089,"ff948282-ac63-40ea-821b-e32f748e1e3f":4.477611940298507},"keyword":{"015086f3-b9a3-45ad-9551-93a4655b20f5":9.423638768638769,"0202b0aa-9a2e-4430-8a6c-fb40cf4b14f5":6.464646464646464,"0202d3b0-955e-4d19-a0f8-7f2fbdb832e4":10.780925925925924,"04bd372d-bfb9-48ce-a4f6-337ea52be9d9":9.271693121693124,"061d43fb-e3af-4700-bdc2-2e34dfbace26":0,"0d052d1b-8be4-497f-bf53-f81aee173fad":8.039393939393939,"1035d56c-06b3-40bb-93c7-6306b24bac93":11.995839345839345,"16866e9f-b4f1-493e-93ab-8bd6fedb1547":10.192352092352092,"16c37100-0533-42e1-aebd-a3805a7c3dde":11.198484848484847,"170c42d8-d872-4bc9-8932-59d27915cbbd":11.918285233285234,"1a6b2fe9-5547-4464-a1c4-db73e5d67d81":12.522424242424242,"1ce0d29c-25ee-411d-91a6-8abb3082f9cb":8.052356902356902,"2141b3e7-6627-4bf1-a42f-6d95050c053f":0,"22c23d0b-ffd3-4679-9297-0ca70e909b65":13.774377104377105,"29042545-4ddf-4bf9-ae8b-d65876c9eb41":11.56087061087061,"296a0ad4-dc5f-4158-ac11-64ffda60a439":0,"2b5b8950-10c8-4ced-b4f8-38ebbf373b56":9.463787878787878,"2ba41db5-ac76-4805-a904-67ff0361f528":10.392472342472342,"2cd6f789-de0b-4d5d-b3d0-60962bd31d41":12.615185185185187,"2d700d61-baaf-401f-a9bf-00c62059c03e":9.26388888888889,"2e1b83e3-68a2-4e1a-8437-d808613f2e1b":11.928403078403079,"30ae6b9d-ec18-466f-8481-914954a20bfb":9.952417027417027,"32c1bdf2-cea7-4d60-8289-2207eaa41a77":7.211592111592111,"33e9cfdc-c769-43d3-9b9f-6a1cc22ecff5":10.762234247234247,"3704f939-09a2-4e9f-b851-1261bcd310df":12.494790764790764,"374196c1-6e90-4dd7-93fd-93a65dd8ea59":11.127356902356901,"39797d9d-193a-4b30-96f3-cc3ffbabd9b5":8.35117845117845,"3b83c815-532d-4122-811f-2b57e8b80c5d":11.388773448773447,"3c1f9893-1a32-4afb-9f40-5d4856b7f886":9.837729677729678,"40d17f93-11dd-4ddd-9bbd-3278339cb1fb":0,"4119077e-f77a-4056-8f3f-36fd86a668de":9.168434343434344,"4453fa3b-308f-472a-be61-65d1ce5c3de2":10.657912457912456,"46ddddd5-83b4-42aa-98b1-5c87a09f77d9":10.60445646945647,"47e20669-55b1-4e50-9ef2-e9f0496ce79a":10.973655603655606,"491d9171-c4d7-4ae1-bc19-5956c2904fc2":12.070353535353535,"49e15f5d-44e6-47e9-b94b-db0291609b30":0,"4b1722c2-0bff-4224-8e37-0fa6455ae487":8.05547138047138,"4c5ed508-b6e5-4db5-a59f-00e1d88dc221":11.001635401635403,"4fa6167f-3737-4793-a013-d1218ae53fa2":11.052946127946129,"4ff8f4fa-f1e0-468b-935f-ae5550e84022":10.100084175084175,"503a985c-48d3-40c1-8690-2b21d8a92137":0,"50c2b314-1596-4444-ae9a-606df9899372":11.398184223184222,"50dd56db-151d-4d62-8576-65f0ef6f381b":11.51869648869649,"5217d97c-5256-4bb7-b501-faf36a474ca6":7.831734006734008,"531585eb-47e5-44b1-9efe-9901f83148c7":11.250743145743145,"5b35e6b8-3077-4ca4-aa34-5e211cace1b9":11.573001443001441,"60d06cf5-2360-4a3b-8bb3-a5f211f84861":8.954389129389128,"60d19f35-5655-4774-a0ee-219230499471":11.49946127946128,"61dcad2b-ef68-4240-95e2-79c12c6bfda9":10.26070226070226,"640bfef8-3c8b-4f57-8db8-5184529ffe1b":11.677659932659934,"69f00f82-45eb-4e2b-b239-5526d80f11ea":0,"6c6a4dc9-6224-471c-b159-a4b3d8ac96b8":12.910952380952383,"6e4a6bd8-16c8-4523-9f12-d64fd8ff00fe":10.995824915824915,"6ff01654-66d1-49c7-b526-1c8ed7fa893a":8.617291967291969,"73ec9d29-4fc5-4019-97d3-c496c8509f37":9.580892255892254,"77b79c16-03f5-4c75-994e-38a9e0cc7bfe":10.712510822510824,"77c60bee-51be-4e3f-86e5-086f7a6c8531":10.578282828282829,"78b0ba4b-b8a0-4689-9972-cabab721ab40":11.853695286195286,"7a74bdb1-93cf-4234-b152-bd413efed591":8.552910052910052,"7aa454b2-47c6-4117-b823-1df65289e8e7":9.643241943241945,"7ce4a38d-0732-48b8-b72a-6f5d87c5782d":10.916599326599327,"7db5b031-03e2-4051-9049-e0cc7b0a4f11":12.008427128427131,"800c39c6-36d9-4e11-a337-c0b69c05e60d":6.308177008177008,"80cb67a5-0117-46f2-8553-671faa21f208":0,"814db119-52fd-47a9-846a-e1d56c8f680d":0,"820b9eee-e009-4dc1-b464-f5fd4485d6b3":9.523569023569024,"825d95f7-21af-478f-b76e-455431bad7a9":12.106022126022125,"842af4d1-b82a-4dc1-955f-6fdfc099b20d":10.343807118807119,"86ba72ef-465f-44dc-8068-cdd6a64f0b40":9.888636363636362,"8735c7ea-f5c6-4310-b250-bc0d1bf5e834":10.386279461279461,"89f10062-acf1-4171-b882-f3222c3a357e":13.246565656565657,"8b2c0aff-4589-4e0f-aae4-4f84a4413406":11.211123136123135,"8d7477d3-f3cf-4db0-83eb-e2f5e22b0dc8":0,"8f9df368-a9cd-4933-91fe-5d727d98da51":10.774949494949494,"90518198-f3d5-4583-85cf-7d5bbec3ab58":10.597239057239056,"924fe569-7b4c-4968-bcc9-35aa73dbb587":11.289983164983168,"93a14c23-d227-41fd-ad18-7de38817cb52":11.499444444444444,"94898e1d-1e50-41ab-9dcc-2c2e030cddd0":10.164983164983166,"95e314d8-096a-4130-b34e-0454dcdf9147":11.472198172198171,"964bf666-0a88-4d01-bc30-16c440f2b526":10.078872053872054,"967cfa49-e7cc-420c-be14-8f6ac66e1655":8.08423520923521,"97005b64-515f-48d2-82cf-3065887be860":9.993814333814333,"991bb85a-f14e-418e-9155-305684f02c77":12.143698893698893,"9c2ed18d-2a96-48f2-ab3c-49b67a88f218":12.796642616642616,"a5084ea3-25bd-4cc7-8c79-29034e9a9c7c":9.968638768638769,"a5e3c7d4-bdc9-46e9-9ebd-044328488842":10.780925925925924,"a9b88757-1121-473c-9e2a-7023c1843884":10.99851851851852,"a9e121b1-26b0-430d-97c1-19f25a59331a":9.935690235690236,"ab9ba74d-28b2-4003-95e4-a1c71daaf484":0,"ac14afe6-de4d-4056-b2ac-0f6e36f369a2":11.298737373737373,"ae3e7593-586f-495f-9416-4b50ed1fcd10":10.68889850889851,"b1ab16c4-7c50-4dfd-90e6-82a9fb00b262":10.833189033189033,"b30cc6be-bdab-472c-a5ed-95c63237fb05":10.31422558922559,"b36102cf-1655-4dbf-a5f5-b6bed8c3048e":9.356445406445406,"b46fdfbf-a80e-407d-b2b0-ad6872b0ac77":8.958109668109667,"b5a7c221-a58f-48d7-9f03-37f28511d372":9.178583453583451,"b658c306-7958-481d-9559-cd3baec9edf0":9.185069745069747,"b75abe04-6fdf-42b7-8b71-e7b05e6991da":9.14234006734007,"c10f400c-dcd6-4690-95ae-3d880660bac2":7.704858104858103,"c2b9beb2-7ce9-42d7-bfc3-060ab60b5139":10.241666666666665,"c4024860-8d55-47c1-bab0-6c53f90831ee":10.827946127946129,"c414c2ad-81f0-4af9-b63a-9e40c8233cdb":9.742592592592594,"c472bfe1-9ef6-43c6-89b5-a86b22c9f5df":10.535964405964405,"c920d990-8391-48a1-b6b8-0df62ba7ff47":0,"ca250ca4-70fd-411f-8cc7-fb17be31cd9e":12.18169312169312,"cac1601e-4f3f-4ccc-ab2e-cec922028ce4":10.290776815776814,"cc12695a-b4f4-4d04-9ace-bf15028c7827":8.577356902356902,"ccdefe89-9b16-4c22-8bb8-bd314ccad6e1":10.73030303030303,"ccf1edb3-fc5d-4936-b8c5-5d9879c73b91":8.634764309764309,"d0d13c7a-308c-4138-9802-8e7c0260bb90":8.33157768157768,"d0d18692-434c-4c7a-b4d8-33ff328f3e3e":10.625454545454545,"d329bbfd-d0ce-452a-870b-e696a964f799":12.370096200096201,"d78003db-ad8a-48d2-be57-1c50e95cef72":11.708581048581047,"daee7e59-3e4d-45b2-9625-495a0167b02a":10.377104377104375,"dcd6762a-ff44-46aa-ab12-6b951955199c":9.445971620971621,"de7e534b-6d80-46c7-bf2a-2b2b4112a42b":10.518518518518519,"e00917f7-1629-48db-baa5-7cc0d179de17":10.851921596921594,"e0f3a738-4ab2-40d1-ba44-506d81c1d230":0,"e30006aa-a666-4d31-a6e5-9464797811a6":12.126296296296296,"e4b24072-5789-4601-8088-f895f47476de":10.652213804713806,"e7f24795-7810-436e-832b-de1728ffd00b":8.55547138047138,"e8571238-943e-46d2-920b-63013e5dd5cd":11.855396825396824,"e89bb9fb-4b26-4e7a-aaf7-84c3bb498836":0,"ec8c9e00-d026-4d33-b102-ffd5389234cd":9.726575276575277,"f006e236-59ad-4647-a59f-4f46dc2c85be":10.224242424242425,"f15b056f-a577-4391-9724-a5be885e2bd2":9.558585858585857,"f188df3f-a910-45af-9644-a7961451c999":10.25974987974988,"f2cbb6cd-cee3-4423-bc52-f7b0a750216d":11.632744107744108,"f56b877b-4060-4754-b303-e8140968544c":10.891798941798942,"f6bd8b64-684d-429a-aab5-8ff3a2c23cd6":11.672895622895622,"f8af71de-30f9-4288-a169-13ab19bf89fb":10.546717171717173,"fa4f4c43-9111-490f-aa0d-2a0161f8565c":12.817205387205387,"fd4c2dc1-317b-41f0-8469-2896b2768fbb":9.570269360269359,"ff948282-ac63-40ea-821b-e32f748e1e3f":11.983030303030302},"topic":["learn","deep","architectur","algorithm","level"],"offsprings":[]},"ed804c0f-dad5-4ce5-9da3-f69da43f137a":{"authors":["Dan Boneh","Matthew K. Franklin"],"references":[],"_id":"ed804c0f-dad5-4ce5-9da3-f69da43f137a","abstract":"We propose a fully functional identity-based encryption (IBE) scheme. The scheme has chosen ciphertext security in the random oracle model assuming a variant of the computational Diffie--Hellman problem. Our system is based on bilinear maps between groups. The Weil pairing on elliptic curves is an example of such a map. We give precise definitions for secure IBE schemes and give several applications for such systems.","title":"Identity-Based Encryption from the Weil Pairing","venue":"SIAM Journal on Computing","year":2003,"__v":0,"citationCount":2784,"parents":{"062d5c6a-6725-4603-b49c-fb92c4bd0f5a":23.809523809523807,"16f8967e-daa0-40fa-9a66-6f3ee9e78cac":14.285714285714285,"1ae39de8-3d73-4ab1-a158-6acbc17754fe":9.523809523809524,"1e7e39e3-3221-46e0-a63d-46c5a68a2508":0,"22985d1d-f524-4b7b-bb09-f0144488d66a":4.761904761904762,"3d933ed4-75b8-4631-a7a6-6eb5043122d8":9.523809523809524,"45d56db9-7547-4c37-98be-5da5546144dd":28.57142857142857,"49ba0a53-1c29-4515-a592-84fb5dc6e7bc":9.523809523809524,"4da2fc3d-e476-4bc6-9cd4-1dba96e81dbf":19.047619047619047,"5e888611-e345-41ed-8195-3156c3069779":0,"6947b732-592a-48fd-a6fc-cd39c0f758e0":0,"a0254949-6d9c-498c-8022-8d96836c36a0":9.523809523809524,"ac0db18c-141b-499a-9499-bc11ed2a61bc":9.523809523809524,"b10fd24d-6a42-4821-9517-da6d1e14b17b":0,"b68fc787-7817-421e-8e66-8a98ab9db1ad":0,"c14ef99e-1e94-49ca-9fca-8c753aceef73":4.761904761904762,"d21dc479-0ead-4873-b622-c444d1603161":0,"d8dc0d21-c4d7-4408-9417-f300a7aeb4a7":0,"da2fb9dd-8971-49b7-858c-44581348f019":9.523809523809524,"e796f5bf-73b8-4473-9e9c-716887059a92":0,"f81652de-d97b-4935-a1ba-5c290c7695a3":4.761904761904762},"keyword":{"062d5c6a-6725-4603-b49c-fb92c4bd0f5a":10.81388888888889,"16f8967e-daa0-40fa-9a66-6f3ee9e78cac":8.627433862433863,"1ae39de8-3d73-4ab1-a158-6acbc17754fe":0,"1e7e39e3-3221-46e0-a63d-46c5a68a2508":0,"22985d1d-f524-4b7b-bb09-f0144488d66a":9.448095238095238,"3d933ed4-75b8-4631-a7a6-6eb5043122d8":9.26047619047619,"45d56db9-7547-4c37-98be-5da5546144dd":0,"49ba0a53-1c29-4515-a592-84fb5dc6e7bc":7.207701465201465,"4da2fc3d-e476-4bc6-9cd4-1dba96e81dbf":6.472222222222221,"5e888611-e345-41ed-8195-3156c3069779":9.504074074074074,"6947b732-592a-48fd-a6fc-cd39c0f758e0":8.762433862433863,"a0254949-6d9c-498c-8022-8d96836c36a0":7.78037037037037,"ac0db18c-141b-499a-9499-bc11ed2a61bc":7.701984126984126,"b10fd24d-6a42-4821-9517-da6d1e14b17b":0,"b68fc787-7817-421e-8e66-8a98ab9db1ad":6.139682539682539,"c14ef99e-1e94-49ca-9fca-8c753aceef73":7.11005291005291,"d21dc479-0ead-4873-b622-c444d1603161":5.796825396825397,"d8dc0d21-c4d7-4408-9417-f300a7aeb4a7":5.584848484848485,"da2fb9dd-8971-49b7-858c-44581348f019":8.092222222222222,"e796f5bf-73b8-4473-9e9c-716887059a92":7.317195767195767,"f81652de-d97b-4935-a1ba-5c290c7695a3":9.477592592592593},"topic":["scheme","system","secur","map","ib"],"groups":[{"authors":["Dan Boneh","Ben Lynn","Hovav Shacham"],"references":["106eeab0-645b-4aab-a392-00a2f34e9683","16f8967e-daa0-40fa-9a66-6f3ee9e78cac","28886493-2fa4-4f99-8332-ed2fbd38f1d8","3476d9f9-f276-434d-a09c-ccfca9208d1a","39b0a663-a520-4845-b722-537bf6c63ac5","4da2fc3d-e476-4bc6-9cd4-1dba96e81dbf","561501c7-e89b-4e43-a9fb-7d6b8eb468f1","893a5aed-c5c0-459e-94ee-4dd3ae3a96b6","92b8e0ae-077b-4423-b27d-4232d372a518","ac0db18c-141b-499a-9499-bc11ed2a61bc","b50357bc-0c4f-4f55-9b68-71ce797ea660","b68fc787-7817-421e-8e66-8a98ab9db1ad","ba4d1a67-fbc8-4ad7-8091-f286c105aa28","c03d2f84-d383-4ba9-a430-c943bf1f9de4","d1ad1dce-aa4a-4e83-9ee9-b45e446dd44a","d21dc479-0ead-4873-b622-c444d1603161","dfcc6791-e93d-4034-9390-5491a542718c","e26009a0-1e86-4459-bb68-0e027da16332","eb299a7d-a37f-412c-a885-e22926d78456","ed804c0f-dad5-4ce5-9da3-f69da43f137a","f13fe55e-8757-42cc-ae9c-fba6939034cc","f5a0a1dc-4927-477f-aad8-872ec0d2851b","f79da521-cc8d-4a8d-a0f4-9478e1836fec","fd325993-2a5c-42ba-b2c4-701336f75f80"],"_id":"062d5c6a-6725-4603-b49c-fb92c4bd0f5a","abstract":"We introduce a short signature scheme based on the Computational Diffie-Hellman assumption on certain elliptic and hyperelliptic curves. The signature length is half the size of a DSA signature for a similar level of security. Our short signature scheme is designed for systems where signatures are typed in by a human or signatures are sent over a low-bandwidth channel.","title":"Short Signatures from the Weil Pairing","venue":"international conference on the theory and application of cryptology and information security","year":2001,"__v":0,"citationCount":879}],"offsprings":[]},"010793c8-fedb-49ee-88bc-1e20f8bae870":{"authors":["Tian Zhang","Raghu Ramakrishnan","Miron Livny"],"references":[],"_id":"010793c8-fedb-49ee-88bc-1e20f8bae870","abstract":"Finding useful patterns in large datasets has attracted considerable interest recently, and one of the most widely studied problems in this area is the identification of  clusters,  or densely populated regions, in a multi-dimensional dataset. Prior work does not adequately address the problem of large datasets and minimization of I/O costs.This paper presents a data clustering method named  BIRCH  (Balanced Iterative Reducing and Clustering using Hierarchies), and demonstrates that it is especially suitable for very large databases.  BIRCH  incrementally and dynamically clusters incoming multi-dimensional metric data points to try to produce the best quality clustering with the available resources (i.e., available memory and time constraints).  BIRCH  can typically find a good clustering with a single scan of the data, and improve the quality further with a few additional scans.  BIRCH  is also the first clustering algorithm proposed in the database area to handle \"noise\" (data points that are not part of the underlying pattern) effectively.We evaluate  BIRCH 's time/space efficiency, data input order sensitivity, and clustering quality through several experiments. We also present a performance comparisons of  BIRCH  versus  CLARANS,  a clustering method proposed recently for large datasets, and show that  BIRCH  is consistently superior.","title":"BIRCH: an efficient data clustering method for very large databases","venue":"international conference on management of data","year":1996,"__v":0,"citationCount":1547,"parents":{"141da6cb-d099-409c-8f2e-d5690bcc05db":16.666666666666664,"76f221bf-6a1c-449f-b365-e6d5a2feff67":16.666666666666664,"a6f1dabc-c76e-4508-af5f-a45ac4287f49":0,"bdb8d83d-1771-4399-b593-d43be5a9f892":0,"c0e18827-07f1-486f-981f-86d1a798eb31":16.666666666666664,"d4d4286f-609d-42cb-a3a5-47f057ff4a7e":0},"keyword":{"141da6cb-d099-409c-8f2e-d5690bcc05db":12.080158730158729,"76f221bf-6a1c-449f-b365-e6d5a2feff67":9.899444444444445,"a6f1dabc-c76e-4508-af5f-a45ac4287f49":10.031746031746033,"bdb8d83d-1771-4399-b593-d43be5a9f892":0,"c0e18827-07f1-486f-981f-86d1a798eb31":0,"d4d4286f-609d-42cb-a3a5-47f057ff4a7e":9.685119047619049},"topic":["cluster","birch","data","larg","dataset"],"offsprings":["38135245-8eff-4078-af6a-ea559ffa660b"]},"051956bb-f64b-4fdb-87f8-3e2868b8b5d8":{"authors":["Christian Szegedy","Wei Liu","Yangqing Jia","Pierre Sermanet","Scott E. Reed","Dragomir Anguelov","Dumitru Erhan","Vincent Vanhoucke","Andrew Rabinovich"],"references":["176a7436-78ea-4c2a-82e6-7930ab023bd1","e2f7a74a-8430-4463-94ce-fe85dfd309f9"],"_id":"051956bb-f64b-4fdb-87f8-3e2868b8b5d8","abstract":"We propose a deep convolutional neural network architecture codenamed Inception that achieves the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC14). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. By a carefully crafted design, we increased the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation used in our submission for ILSVRC14 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classification and detection.","title":"Going deeper with convolutions","venue":"computer vision and pattern recognition","year":2015,"__v":0,"citationCount":1580,"parents":{"0fb0a842-cb06-4b37-9738-a4d18a55ec23":11.11111111111111,"176a7436-78ea-4c2a-82e6-7930ab023bd1":16.666666666666664,"2d94566b-ac2d-49b0-a867-2392c41a2172":0,"3b2f341e-55fc-48ff-ab91-a26e0f8ce761":11.11111111111111,"5913b912-d090-4aa7-8e5b-9e7e59076119":0,"6a97a03d-7337-4f4a-a8db-714d81cff194":27.77777777777778,"6d324aa1-fcc4-4808-ae21-472982517e5e":22.22222222222222,"708441ca-fc5d-41ca-8ab2-c7b705d451b9":0,"73dbdf1f-da95-4b8c-9109-c966e08c6f13":5.555555555555555,"88d1f7c7-bec0-4e01-a7c2-e2a895ee36d4":5.555555555555555,"a1494dfe-ca52-4757-9a07-d0a0df32490e":5.555555555555555,"a4d9008a-d15b-4d87-a173-bef2f4b0d453":0,"ae3e7593-586f-495f-9416-4b50ed1fcd10":0,"b9632516-3e2e-4cf7-a6d8-43f317d43488":11.11111111111111,"cbf3ea5c-fa19-43b7-96ae-2fce79cca09b":27.77777777777778,"cd035d3b-0a73-4c0d-b813-0632409612ad":0,"e2f7a74a-8430-4463-94ce-fe85dfd309f9":5.555555555555555,"f26a8a8a-9ad6-4dc1-8ae2-a59be1f80267":0},"keyword":{"0fb0a842-cb06-4b37-9738-a4d18a55ec23":11.068903318903319,"176a7436-78ea-4c2a-82e6-7930ab023bd1":8.776695526695526,"2d94566b-ac2d-49b0-a867-2392c41a2172":12.259704184704182,"3b2f341e-55fc-48ff-ab91-a26e0f8ce761":8.18553391053391,"5913b912-d090-4aa7-8e5b-9e7e59076119":10.873556998556996,"6a97a03d-7337-4f4a-a8db-714d81cff194":10.691269841269841,"6d324aa1-fcc4-4808-ae21-472982517e5e":8.440488215488214,"708441ca-fc5d-41ca-8ab2-c7b705d451b9":12.611166611166613,"73dbdf1f-da95-4b8c-9109-c966e08c6f13":10.637698412698413,"88d1f7c7-bec0-4e01-a7c2-e2a895ee36d4":11.585739538239539,"a1494dfe-ca52-4757-9a07-d0a0df32490e":11.025800865800864,"a4d9008a-d15b-4d87-a173-bef2f4b0d453":10.661796536796537,"ae3e7593-586f-495f-9416-4b50ed1fcd10":10.906782106782106,"b9632516-3e2e-4cf7-a6d8-43f317d43488":11.141847041847042,"cbf3ea5c-fa19-43b7-96ae-2fce79cca09b":10.630609668109667,"cd035d3b-0a73-4c0d-b813-0632409612ad":10.593434343434343,"e2f7a74a-8430-4463-94ce-fe85dfd309f9":10.267027417027416,"f26a8a8a-9ad6-4dc1-8ae2-a59be1f80267":9.855266955266956},"topic":["network","architectur","qualiti","ilsvrc14","detect"],"groups":[{"authors":["Dumitru Erhan","Christian Szegedy","Alexander Toshev","Dragomir Anguelov"],"references":["0fb0a842-cb06-4b37-9738-a4d18a55ec23","176a7436-78ea-4c2a-82e6-7930ab023bd1","1bbaae78-1bb8-4184-b01c-4216e6879c56","3ac62b27-10f6-41a7-9489-20c68399d826","589efc91-a3df-4c70-a613-67f249d7b33f","690a5e66-a7d5-44a0-b64e-4d7c04fce1b5","708441ca-fc5d-41ca-8ab2-c7b705d451b9","73dbdf1f-da95-4b8c-9109-c966e08c6f13","83c737b8-e084-4766-ba6e-131e6a1c017c","8fca7729-59f4-43c5-8d23-95071d9adf8e","95f28b74-9e22-4dc0-8acc-9cdf7e716b61","98bf28d7-6c0d-406c-aa8b-9a0f4aeb2a05","9f84e529-87a3-42f1-9d63-9af710f40925","e2f7a74a-8430-4463-94ce-fe85dfd309f9","f1639cc6-356f-4170-9dea-9be79c84f899","f2d49150-35de-4fd5-ac46-eb071d1cc73e"],"_id":"cbf3ea5c-fa19-43b7-96ae-2fce79cca09b","abstract":"Deep convolutional neural networks have recently achieved state-of-the-art performance on a number of image recognition benchmarks, including the ImageNet Large-Scale Visual Recognition Challenge (ILSVRC-2012). The winning model on the localization sub-task was a network that predicts a single bounding box and a confidence score for each object category in the image. Such a model captures the whole-image context around the objects but cannot handle multiple instances of the same object in the image without naively replicating the number of outputs for each instance. In this work, we propose a saliency-inspired neural network model for detection, which predicts a set of class-agnostic bounding boxes along with a single score for each box, corresponding to its likelihood of containing any object of interest. The model naturally handles a variable number of instances for each class and allows for cross-class generalization at the highest levels of the network. We are able to obtain competitive recognition performance on VOC2007 and ILSVRC2012, while using only the top few predicted locations in each image and a small number of neural network evaluations.","title":"Scalable Object Detection Using Deep Neural Networks","venue":"computer vision and pattern recognition","year":2014,"__v":0,"citationCount":151},{"authors":["Matthew D. Zeiler","Rob Fergus"],"references":["04c47f14-8533-41ff-bafd-affc1eb52287","176a7436-78ea-4c2a-82e6-7930ab023bd1","195ac389-5a07-4fd4-9c12-be42420720bc","1d4f35b8-af72-4b23-b999-74de292d696b","2a28e4be-93ec-4d51-8399-cd9d9fdee560","2b6a3d0f-368f-45bb-be23-4e82f62fbbf7","2d94566b-ac2d-49b0-a867-2392c41a2172","32c1bdf2-cea7-4d60-8289-2207eaa41a77","39ca24c1-da5a-42fc-888c-d75069728d5e","433969bb-d29f-4cac-83a5-ccfb5c6c7b4e","483ca5b5-59c1-46f2-8cc3-cfa197377206","4bbacb77-1097-4cc5-b001-6554ea01fb75","4dba26db-f090-4ac6-90dd-091680676a81","5c4e8000-7daa-4665-a85d-9e4071b6fa19","5fbd2ca9-c4fa-4087-aa39-42dc03acd8ae","6d324aa1-fcc4-4808-ae21-472982517e5e","78b0ba4b-b8a0-4689-9972-cabab721ab40","7936f72d-c9e4-4e3d-af8e-5df00782eb95","837e056f-ea71-4be1-bde0-e3166cfee2fd","88af66e6-c531-4f6a-a952-9dbdbcd28a67","89f10062-acf1-4171-b882-f3222c3a357e","8b3efecd-c21c-4d30-8eb3-dc721aad3bdd","8fa0a362-6522-48fc-bd5e-24de00ed6511","97fa1c18-05bf-47c9-b72d-5d712b186ccd","983a2eff-22fe-40d2-bb87-fea35e63db6c","9cf78907-bf80-49bd-96c3-fdf5f91383ee","a4786a29-ac24-40f1-815d-5fa12f7f86cc","ae3e7593-586f-495f-9416-4b50ed1fcd10","ae71e737-e28a-4e5d-8446-78c53b6d4fbd","aff1fa6e-bac4-4e55-8450-5bc014634855","b23e0c5f-62cd-4555-acfd-90cb73d16fab","c01540df-7322-4824-beea-7c716be7f3ed","c46d7dde-33df-4406-8df8-2c70e13cc5d2","c812244d-0de8-4e3c-8133-1e834bc9dbd0","d35b5e50-db29-4ef8-aa29-37a3dd451b80","db8d3f57-09f9-4b09-a057-3e97e2a2b7fc","e1a24833-9195-46f6-831f-f4c19189fb3a","e2f7a74a-8430-4463-94ce-fe85dfd309f9","ee289120-5e7f-4cde-98a0-a523e5150994","f64b5ccd-849a-4ac1-97ff-f34842543115"],"_id":"6a97a03d-7337-4f4a-a8db-714d81cff194","abstract":"Large Convolutional Network models have recently demon- strated impressive classification performance on the ImageNet bench- mark Krizhevsky et al. (18). However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we explore both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the oper- ation of the classifier. Used in a diagnostic role, these visualizations allow us to find model architectures that outperform Krizhevsky et al. on the ImageNet classification benchmark. We also perform an ablation study to discover the performance contribution from different model layers. We show our ImageNet model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-of- the-art results on Caltech-101 and Caltech-256 datasets.","title":"Visualizing and Understanding Convolutional Networks","venue":"european conference on computer vision","year":2013,"__v":0,"citationCount":925}],"offsprings":["153c5014-dc7a-44a8-a93f-5cd27f1193df"]},"05bbaec3-7980-4941-8638-2bbfa4ac8be0":{"authors":["Mikhail Belkin","Partha Niyogi"],"references":["94898e1d-1e50-41ab-9dcc-2c2e030cddd0","ea8cd3d8-17ae-4a1e-8f83-1609469087af"],"_id":"05bbaec3-7980-4941-8638-2bbfa4ac8be0","abstract":"One of the central problems in machine learning and pattern recognition is to develop appropriate representations for complex data. We consider the problem of constructing a representation for data lying on a low-dimensional manifold embedded in a high-dimensional space. Drawing on the correspondence between the graph Laplacian, the Laplace Beltrami operator on the manifold, and the connections to the heat equation, we propose a geometrically motivated algorithm for representing the high-dimensional data. The algorithm provides a computationally efficient approach to nonlinear dimensionality reduction that has locality-preserving properties and a natural connection to clustering. Some potential applications and illustrative examples are discussed.","title":"Laplacian Eigenmaps for dimensionality reduction and data representation","venue":"Neural Computation","year":2003,"__v":0,"citationCount":2308,"parents":{"0f74fecb-75c8-4089-9d96-9f95f134a1a4":9.090909090909092,"2cd6f789-de0b-4d5d-b3d0-60962bd31d41":27.27272727272727,"3e5fd33f-1fd0-4815-a47a-3c41a26a538a":0,"9438a773-c15c-4ef2-a97c-54f643ce6082":0,"94898e1d-1e50-41ab-9dcc-2c2e030cddd0":0,"a004b495-c45e-483b-ba58-0267bdc8659c":0,"c2812488-7d34-48a7-8916-d4d4bdd89a03":0,"c980c937-f30c-4593-a4a3-a7e85c0e83bc":0,"cbff2ff2-6b8f-425d-a5ef-aff0de9be3e5":0,"dd7b3cc4-02a8-4082-a0a1-4f6d05785841":9.090909090909092,"ea8cd3d8-17ae-4a1e-8f83-1609469087af":9.090909090909092},"keyword":{"0f74fecb-75c8-4089-9d96-9f95f134a1a4":9.656781644281642,"2cd6f789-de0b-4d5d-b3d0-60962bd31d41":11.318666056166057,"3e5fd33f-1fd0-4815-a47a-3c41a26a538a":0,"9438a773-c15c-4ef2-a97c-54f643ce6082":10.690964590964592,"94898e1d-1e50-41ab-9dcc-2c2e030cddd0":9.852660765160765,"a004b495-c45e-483b-ba58-0267bdc8659c":0,"c2812488-7d34-48a7-8916-d4d4bdd89a03":11.135398860398858,"c980c937-f30c-4593-a4a3-a7e85c0e83bc":9.837037037037037,"cbff2ff2-6b8f-425d-a5ef-aff0de9be3e5":11.631644281644283,"dd7b3cc4-02a8-4082-a0a1-4f6d05785841":11.052336182336182,"ea8cd3d8-17ae-4a1e-8f83-1609469087af":10.709936359936362},"topic":["data","represent","problem","manifold","highdimension"],"groups":[{"authors":["Yoshua Bengio","Olivier Delalleau","Nicolas Le Roux","Jean-François Paiement","Pascal Vincent","Marie Ouimet"],"references":["058fb9ea-3e34-48f3-9d12-1d5793d51582","05bbaec3-7980-4941-8638-2bbfa4ac8be0","0c25eb5d-61f8-4592-ada8-05ba634db750","0ec31645-608f-4341-8e5e-cae7eb7eec4f","2c774924-96a2-4ac8-80fc-a4cdfeb8eaa5","3404a00d-693a-4fc7-9d83-12a3a984e373","38950e26-505a-4d95-850d-b855a16e21e9","3bb51b56-3f75-4533-8965-ee9f6554e378","9438a773-c15c-4ef2-a97c-54f643ce6082","94898e1d-1e50-41ab-9dcc-2c2e030cddd0","c2b54856-8361-4454-a3da-c23586f270b4","ca8f28b1-c0e9-4140-8217-7898e3502d6f","d5f85eee-3a50-4534-a1db-7f230a68102f","d78003db-ad8a-48d2-be57-1c50e95cef72","ea8cd3d8-17ae-4a1e-8f83-1609469087af"],"_id":"2cd6f789-de0b-4d5d-b3d0-60962bd31d41","abstract":"In this letter, we show a direct relation between spectral embedding methods and kernel principal components analysis and how both are special cases of a more general learning problem: learning the principal eigenfunctions of an operator defined from a kernel and the unknown data-generating density. Whereas spectral embedding methods provided only coordinates for the training points, the analysis justifies a simple extension to out-of-sample examples (the Nystrom formula) for multidimensional scaling (MDS), spectral clustering, Laplacian eigenmaps, locally linear embedding (LLE), and Isomap. The analysis provides, for all such spectral embedding methods, the definition of a loss function, whose empirical average is minimized by the traditional algorithms. The asymptotic expected value of that loss defines a generalization performance and clarifies what these algorithms are trying to learn. Experiments with LLE, Isomap, spectral clustering, and MDS show that this out-of-sample embedding formula generalizes well, with a level of error comparable to the effect of small perturbations of the training set on the embedding.","title":"Learning Eigenfunctions Links Spectral Embedding and Kernel PCA","venue":"Neural Computation","year":2004,"__v":0,"citationCount":104}],"offsprings":["7c90045b-63b9-4f29-82a0-bf7c914a6ef6","a81d35e6-d5cd-4eef-9144-b0755ef268d1"]},"08704b8d-70a1-44b7-b7a6-ad47c0df57c1":{"authors":["Maryam Alavi","Dorothy E. Leidner"],"references":[],"_id":"08704b8d-70a1-44b7-b7a6-ad47c0df57c1","abstract":"Knowledge is a broad and abstract notion that has defined epistemological debate in western philosophy since the classical Greek era. In the past few years, however, there has been a growing interest in treating knowledge as a significant organizational resource. Consistent with the interest in organizational knowledge and knowledge management (KM), IS researchers have begun promoting a class of information systems, referred to as knowledge management systems (KMS). The objective of KMS is to support creation, transfer, and application of knowledge in organizations. Knowledge and knowledge management are complex and multi-faceted concepts. Thus, effective development and implementation of KMS requires a foundation in several rich literatures.","title":"Review: Knowledge management and knowledge management systems: conceptual foundations and research issues","venue":"Management Information Systems Quarterly","year":2001,"__v":0,"citationCount":1707,"parents":{"18b75110-8da0-42cb-8ce6-54212040530c":0,"33bc57f2-bab1-4482-8f43-2f8745ca9c4d":0,"38bdaacc-f709-4be1-b9d1-fba5ca4ed654":12.5,"39a4d823-1bf7-4a1b-8eb1-c285d82d4a18":12.5,"502d0059-e458-46a1-a1b4-45f5152ac7b9":0,"58324ee2-0d86-497a-9715-04668a8eb01d":0,"58e82047-ff87-4984-b337-f5dfaf3daa6f":0,"59048088-65c4-4ee1-b3ee-7d032f31b41c":6.25,"70279e8d-ab9f-4138-a3ec-53bc5950a8d4":6.25,"7a6fcabc-b08f-4289-a8f1-45522d0e13da":6.25,"841849a5-fa9f-474e-8230-d9178efad5f5":0,"96f5fbc6-f2ea-4483-b52a-5557ebf31c8f":0,"9a15ca8c-f724-4d8f-875f-8d7da3db2940":0,"b541380f-8e36-4fd8-91b3-04cf1f8d2736":0,"d502007a-17bf-4e7c-9129-ff3e9bbb7e45":12.5,"fa4efe1f-b911-45cb-a58d-182829b52e73":0},"keyword":{"18b75110-8da0-42cb-8ce6-54212040530c":0,"33bc57f2-bab1-4482-8f43-2f8745ca9c4d":6.930952380952382,"38bdaacc-f709-4be1-b9d1-fba5ca4ed654":9.231190476190475,"39a4d823-1bf7-4a1b-8eb1-c285d82d4a18":7.42031746031746,"502d0059-e458-46a1-a1b4-45f5152ac7b9":8.292936507936508,"58324ee2-0d86-497a-9715-04668a8eb01d":0,"58e82047-ff87-4984-b337-f5dfaf3daa6f":6.330238095238095,"59048088-65c4-4ee1-b3ee-7d032f31b41c":8.009391534391533,"70279e8d-ab9f-4138-a3ec-53bc5950a8d4":5.696031746031746,"7a6fcabc-b08f-4289-a8f1-45522d0e13da":8.583015873015873,"841849a5-fa9f-474e-8230-d9178efad5f5":0,"96f5fbc6-f2ea-4483-b52a-5557ebf31c8f":8.113474025974027,"9a15ca8c-f724-4d8f-875f-8d7da3db2940":6.601984126984127,"b541380f-8e36-4fd8-91b3-04cf1f8d2736":8.642619047619046,"d502007a-17bf-4e7c-9129-ff3e9bbb7e45":0,"fa4efe1f-b911-45cb-a58d-182829b52e73":0},"topic":["knowledg","manag","km","system","organiz"],"offsprings":[]},"0c32535a-72bb-4fda-b12b-627147f8b358":{"authors":["Carlo Tomasi","Roberto Manduchi"],"references":[],"_id":"0c32535a-72bb-4fda-b12b-627147f8b358","abstract":"Bilateral filtering smooths images while preserving edges, by means of a nonlinear combination of nearby image values. The method is noniterative, local, and simple. It combines gray levels or colors based on both their geometric closeness and their photometric similarity, and prefers near values to distant values in both domain and range. In contrast with filters that operate on the three bands of a color image separately, a bilateral filter can enforce the perceptual metric underlying the CIE-Lab color space, and smooth colors and preserve edges in a way that is tuned to human perception. Also, in contrast with standard filtering, bilateral filtering produces no phantom colors along edges in color images, and reduces phantom colors where they appear in the original image.","title":"Bilateral filtering for gray and color images","venue":"international conference on computer vision","year":1998,"__v":0,"citationCount":2363,"parents":{"1e9dc3ef-4c20-47b9-8277-efd5b895183d":0,"60022cbc-0151-4268-a862-65480f5b91d0":0,"87d50e09-10e8-4b33-b854-800fa53f3f2c":0,"b608af66-6368-44dc-a670-2a3e42561ee1":0,"c3762939-a0ed-4989-845a-6a2c56afb26e":0,"eb1ed26a-b6fc-4cf3-9cbc-f20e1aa6f0d6":28.57142857142857,"f358227a-1401-4776-8c54-edb47ce67574":0},"keyword":{"1e9dc3ef-4c20-47b9-8277-efd5b895183d":7.436507936507937,"60022cbc-0151-4268-a862-65480f5b91d0":9.583333333333334,"87d50e09-10e8-4b33-b854-800fa53f3f2c":8.842857142857143,"b608af66-6368-44dc-a670-2a3e42561ee1":8.455555555555556,"c3762939-a0ed-4989-845a-6a2c56afb26e":9.366666666666667,"eb1ed26a-b6fc-4cf3-9cbc-f20e1aa6f0d6":8.191746031746032,"f358227a-1401-4776-8c54-edb47ce67574":8.972222222222223},"topic":["color","imag","filter","valu","edg"],"groups":[{"authors":["Roland T. Chin","Chia-Lung Yeh"],"references":["1e9dc3ef-4c20-47b9-8277-efd5b895183d","60022cbc-0151-4268-a862-65480f5b91d0","66879673-e5dd-4c5e-8e58-2631dcc272d0","e15d0bd0-0d4d-4dd3-b8da-ffad69885450"],"_id":"eb1ed26a-b6fc-4cf3-9cbc-f20e1aa6f0d6","abstract":"A quantitative evaluation of several edge-preserving noise-smoothing techniques is presented. All of the techniques evaluated are devised to preserve edge sharpness while achieving some degree of noise cleaning. They are based on local operations on neighboring points and all of them can be iterated. They are unweighted neighbor averaging (AVE), K-nearest neighbor averaging (KAVE), the edge and line weights method (EDLN), gradient inverse weighted smoothing (GRADIN), maximum homogeneity smoothing (MAXH), slope facet model smoothing (FACET), and median filtering (MEDIAN). The evaluation procedure involves two steps. First, the image is partitioned into regions based on the amount of spatial activity in a neighborhood of a pixel, where spatial activity is defined as local gradient. In the second part of the procedure an objective measure, the mean-square error, for each region of the partitioned image is obtained to evaluate the performance of the smoothing scheme at the corresponding level of spatial activity content. This evaluation procedure provides a convenient way to compare both the edge-preserving and noise-smoothing abilities of different schemes. The smoothing schemes were tested on a specially generated image with varying degrees of added noise and different edge slopes. The results of the comparison study are presented.","title":"Quantitative evaluation of some edge-preserving noise-smoothing techniques","venue":"Graphical Models \\/graphical Models and Image Processing \\/computer Vision, Graphics, and Image Processing","year":1983,"__v":0,"citationCount":40}],"offsprings":["c8f80ea6-4602-458c-9a70-daf1c646c89b"]},"0ffbba6a-4711-4e10-ad37-358bd8cb6873":{"authors":["Viswanath Venkatesh","Michael G. Morris","Gordon B. Davis","Fred D. Davis"],"references":[],"_id":"0ffbba6a-4711-4e10-ad37-358bd8cb6873","abstract":"Information technology (IT) acceptance research has yielded many competing models, each with different sets of acceptance determinants. In this paper, we (1) review user acceptance literature and discuss eight prominent models, (2) empirically compare the eight models and their extensions, (3) formulate a unified model that integrates elements across the eight models, and (4) empirically validate the unified model. The eight models reviewed are the theory of reasoned action, the technology acceptance model, the motivational model, the theory of planned behavior, a model combining the technology acceptance model and the theory of planned behavior, the model of PC utilization, the innovation diffusion theory, and the social cognitive theory. Using data from four organizations over a six-month period with three points of measurement, the eight models explained between 17 percent and 53 percent of the variance in user intentions to use information technology. Next, a unified model, called the Unified Theory of Acceptance and Use of Technology (UTAUT), was formulated, with four core determinants of intention and usage, and up to four moderators of key relationships. UTAUT was then tested using the original data and found to outperform the eight individual models (adjusted R2 of 69 percent). UTAUT was then confirmed with data from two new organizations with similar results (adjusted R2 of 70 percent). UTAUT thus provides a useful tool for managers needing to assess the likelihood of success for new technology introductions and helps them understand the drivers of acceptance in order to proactively design interventions (including training, marketing, etc.) targeted at populations of users that may be less inclined to adopt and use new systems. The paper also makes several recommendations for future research including developing a deeper understanding of the dynamic influences studied here, refining measurement of the core constructs used in UTAUT, and understanding the organizational outcomes associated with new technology use.","title":"User acceptance of information technology: toward a unified view","venue":"Management Information Systems Quarterly","year":2003,"__v":0,"citationCount":3776,"parents":{"017d7159-547c-4627-9a45-d98331ed2892":30.434782608695656,"0a5567c5-7a18-4e16-9f53-a79c9f21e32d":17.391304347826086,"1014c457-be27-4c1b-b460-f83e82bff2fb":4.3478260869565215,"22c866d0-81fe-4011-8149-676ac1fa02b8":0,"2df731d1-37e4-4afb-a9b0-60a5361a79ff":17.391304347826086,"39bd75e5-c40b-474f-85f3-c8ed63c11765":17.391304347826086,"3bac5d08-74d8-4776-b976-c80acffe44d7":8.695652173913043,"54f4f461-e519-492f-aa4e-4aa1286987c4":4.3478260869565215,"571de123-77aa-4b08-a25e-7f80cf5a2e5b":4.3478260869565215,"662db3d8-b707-420c-9727-42e9f12a5479":13.043478260869565,"67316eeb-77f8-43f4-b0bd-d604387e80f1":13.043478260869565,"7583b6d0-44bd-444e-a311-4c537015a77d":43.47826086956522,"7e304910-1805-4537-9f54-1a96f4023ffd":21.73913043478261,"860c9110-1a3c-416c-87ee-98edd0565a62":17.391304347826086,"881edf4e-5fbe-4f6c-9251-662c115ad0b4":30.434782608695656,"9d912297-e52f-4ab6-add4-633e0f263933":0,"9da2f3bb-2b7f-48e1-86af-7e45c808bc49":4.3478260869565215,"b1ba90ca-3599-4363-8703-5acce9f7f3f5":0,"d5707c9f-323b-4336-8c0f-fa28062045b3":17.391304347826086,"ddd277ef-ea52-4d62-ae5b-9dcaec41627f":8.695652173913043,"e1820b51-0c91-47d4-9c66-911b05a2936a":30.434782608695656,"ecc57291-ecac-4ca6-b39a-d68c9d8f2aa6":26.08695652173913,"ee3f66e5-6921-4320-9125-944eb33a04f1":52.17391304347826},"keyword":{"017d7159-547c-4627-9a45-d98331ed2892":9.596455026455027,"0a5567c5-7a18-4e16-9f53-a79c9f21e32d":11.571296296296296,"1014c457-be27-4c1b-b460-f83e82bff2fb":9.476296296296296,"22c866d0-81fe-4011-8149-676ac1fa02b8":12.36931216931217,"2df731d1-37e4-4afb-a9b0-60a5361a79ff":11.69574074074074,"39bd75e5-c40b-474f-85f3-c8ed63c11765":0,"3bac5d08-74d8-4776-b976-c80acffe44d7":10.956666666666667,"54f4f461-e519-492f-aa4e-4aa1286987c4":11.652592592592592,"571de123-77aa-4b08-a25e-7f80cf5a2e5b":10.066666666666665,"662db3d8-b707-420c-9727-42e9f12a5479":10.529074074074074,"67316eeb-77f8-43f4-b0bd-d604387e80f1":9.812037037037037,"7583b6d0-44bd-444e-a311-4c537015a77d":10.554074074074075,"7e304910-1805-4537-9f54-1a96f4023ffd":13.142845117845118,"860c9110-1a3c-416c-87ee-98edd0565a62":13.321005291005292,"881edf4e-5fbe-4f6c-9251-662c115ad0b4":12.75441798941799,"9d912297-e52f-4ab6-add4-633e0f263933":8.989841269841271,"9da2f3bb-2b7f-48e1-86af-7e45c808bc49":11.311296296296296,"b1ba90ca-3599-4363-8703-5acce9f7f3f5":10.697037037037036,"d5707c9f-323b-4336-8c0f-fa28062045b3":10.462962962962964,"ddd277ef-ea52-4d62-ae5b-9dcaec41627f":10.417592592592595,"e1820b51-0c91-47d4-9c66-911b05a2936a":12.362037037037036,"ecc57291-ecac-4ca6-b39a-d68c9d8f2aa6":11.666798941798941,"ee3f66e5-6921-4320-9125-944eb33a04f1":11.13835978835979},"topic":["model","technolog","accept","theori","utaut"],"groups":[{"authors":["Deborah R. Compeau","Christopher A. Higgins","Sid L. Huff"],"references":["1014c457-be27-4c1b-b460-f83e82bff2fb","22c866d0-81fe-4011-8149-676ac1fa02b8","2df731d1-37e4-4afb-a9b0-60a5361a79ff","3bac5d08-74d8-4776-b976-c80acffe44d7","571de123-77aa-4b08-a25e-7f80cf5a2e5b","67316eeb-77f8-43f4-b0bd-d604387e80f1","991da7a2-041f-47d8-af04-d6caaf0fd142","9d912297-e52f-4ab6-add4-633e0f263933","d2f8e7b6-6290-486c-981b-44db12bce30e"],"_id":"e1820b51-0c91-47d4-9c66-911b05a2936a","abstract":"A model, based on Bandura's Social Cognitive Theory, was developed to test the influence of computer self-efficacy, outcome expectations, affect, and anxiety on computer usage. The model was tested using longitudinal data gathered from 394 end users over a one-year interval. Significant relationships were found between computer self-efficacy and outcome expectations, and between self-efficacy and affect and anxiety and use. Performance outcomes were found to influence affect and use, while affect was significantly related to use. Overall, the findings provide strong confirmation that both self-efficacy and outcome expectations impact on an individual's affective and behavioral reactions to information technology.","title":"Social cognitive theory and individual reactions to computing technology: a longitudinal study","venue":"Management Information Systems Quarterly","year":1999,"__v":0,"citationCount":485},{"authors":["Viswanath Venkatesh"],"references":["123c0f7a-4341-4a95-bb80-824a969eda20","2df731d1-37e4-4afb-a9b0-60a5361a79ff","3bac5d08-74d8-4776-b976-c80acffe44d7","46c466a0-4c5f-4184-808a-4a28bebb3504","54f4f461-e519-492f-aa4e-4aa1286987c4","571de123-77aa-4b08-a25e-7f80cf5a2e5b","67316eeb-77f8-43f4-b0bd-d604387e80f1","7583b6d0-44bd-444e-a311-4c537015a77d","767eacbf-fb87-44f8-bd87-9a4440413602","848815a8-f456-4dd7-8196-6a585c2d8599","8fa9255b-4f7d-4fd8-94a2-13dc971c4236","9d912297-e52f-4ab6-add4-633e0f263933","be9335dd-d15f-4a2e-8d96-62dbf2cf9e2e","c5b280d6-5047-4296-99f2-724efbd7808c","cf6802fe-c0b2-45c7-92cd-d1187f8986b1","d87d183f-2cf7-4587-a128-3219e3c31265","e2a46555-6ca9-4cd4-a815-f4715ae04253","f98cc304-5a77-49f4-9bd6-3af076bc83d9"],"_id":"017d7159-547c-4627-9a45-d98331ed2892","abstract":"A key issue facing information systems researchers and practitioners has been the difficulty in creating favorable user reactions to new technologies. Insufficient or ineffective training has been identified as one of the key factors underlying this disappointing reality. Among the various enhancements to training being examined in research, the role of intrinsic motivation as a lever to create favorable user perceptions has not been sufficiently exploited. In this research, two studies were conducted to compare a traditional training method with a training method that included a component aimed at enhancing intrinsic motivation. The results strongly favored the use of an intrinsic motivator during training. Key implications for theory and practice are discussed.","title":"Creation of favorable user perceptions: exploring the role of intrinsic motivation","venue":"Management Information Systems Quarterly","year":1999,"__v":0,"citationCount":374},{"authors":["Christopher R. Plouffe","John Hulland","Mark Vandenbosch"],"references":["1014c457-be27-4c1b-b460-f83e82bff2fb","1d5570d4-4056-450c-a4c5-0f0ac5239f60","2df731d1-37e4-4afb-a9b0-60a5361a79ff","571de123-77aa-4b08-a25e-7f80cf5a2e5b","67316eeb-77f8-43f4-b0bd-d604387e80f1","767eacbf-fb87-44f8-bd87-9a4440413602","9d912297-e52f-4ab6-add4-633e0f263933","cf6802fe-c0b2-45c7-92cd-d1187f8986b1","ddd277ef-ea52-4d62-ae5b-9dcaec41627f","e7b12517-7cc9-40a3-81a9-3cc253675012"],"_id":"ecc57291-ecac-4ca6-b39a-d68c9d8f2aa6","abstract":"The Technology Acceptance Model (TAM) has received considerable research attention in the IS field over the past decade, placing an emphasis on the roles played by perceived ease-of-use and perceived usefulness in influencing technology adoption decisions. Meanwhile, alternative sets of antecedents to adoption have received less attention. In this paper, sets of antecedent constructs drawn from both TAM and the Perceived Characteristics of Innovating (PCI) inventory are tested and subsequently compared with one another. The comparison is done in the context of a large-scale market trial of a smart card-based electronic payment system being evaluated by a group of retailers and merchants. The PCI set of antecedents explains substantially more variance than does TAM, while also providing managers with more detailed information regarding the antecedents driving technology innovation adoption.","title":"Research Report: Richness Versus Parsimony in Modeling Technology Adoption Decisions--Understanding Merchant Adoption of a Smart Card-Based Payment System","venue":"Information Systems Research","year":2001,"__v":0,"citationCount":161},{"authors":["Paul Jen-Hwa Hu","Patrick Y. K. Chau","Olivia R. Liu Sheng","Kar Yan Tam"],"references":["035f2ecf-023c-4880-9e55-483a597d9d48","1014c457-be27-4c1b-b460-f83e82bff2fb","2df731d1-37e4-4afb-a9b0-60a5361a79ff","36043649-f823-4acd-a99a-c92a2e13985e","46c466a0-4c5f-4184-808a-4a28bebb3504","571de123-77aa-4b08-a25e-7f80cf5a2e5b","662db3d8-b707-420c-9727-42e9f12a5479","6af69412-22dc-431b-8bc7-4f0fecc39424","71ab9aee-3063-4ca2-bbed-7034865c6570","767eacbf-fb87-44f8-bd87-9a4440413602","84f09d5d-1599-4dc0-9930-9b295ecf7f49","9bb88477-84e4-4204-b262-d0482016f43d","9d912297-e52f-4ab6-add4-633e0f263933","aa037fa6-dbc5-483f-b385-f1cadc88882d","baf69b45-c704-4b5b-8365-4d65783b7a7b","c5b280d6-5047-4296-99f2-724efbd7808c","c8a77118-2518-4b98-85cc-f6024215f2de","d03c4298-8063-46ed-9108-cf3a635187ed","d8676578-bec7-4a00-8484-bf87a79ab171","e587c26f-19b1-414b-881a-2e0d4d9eb731","e77d8c8a-882a-43a0-9b50-e153e40871fd"],"_id":"7e304910-1805-4537-9f54-1a96f4023ffd","abstract":"The rapid growth of investment in information technology (IT) by organizations worldwide has made user acceptance an increasingly critical technology implementation and management issue. While such acceptance has received fairly extensive attention from previous research, additional efforts are needed to examine or validate existing research results, particularly those involving different technologies, user populations, and/or organizational contexts. In response, this paper reports a research work that examined the applicability of the Technology Acceptance Model (TAM) in explaining physicians' decisions to accept telemedicine technology in the health-care context. The technology, the user group, and the organizational context are all new to IT acceptance/adoption research. The study also addressed a pragmatic technology management need resulting from millions of dollars invested by health-care organizations in developing and implementing telemedicine programs in recent years. The model's overall fit, explanatory power, and the individual causal links that it postulates were evaluated by examining the acceptance of telemedicine technology among physicians practicing at public tertiary hospitals in Hong Kong. Our results suggested that TAM was able to provide a reasonable depiction of physicians' intention to use telemedicine technology. Perceived usefulness was found to be a significant determinant of attitude and intention but perceived ease of use was not. The relatively low R-square of the model suggests both the limitations of the parsimonious model and the need for incorporating additional factors or integrating with other IT acceptance models in order to improve its specificity and explanatory utility in a health-care context. Based on the study findings, implications for user technology acceptance research and telemedicine management are discussed.","title":"Examining the technology acceptance model using physician acceptance of telemedicine technology","venue":"Journal of Management Information Systems","year":1999,"__v":0,"citationCount":380},{"authors":["Elena Karahanna","Detmar W. Straub","Norman L. Chervany"],"references":["0048281f-12a3-4b9f-9cbd-2c35a3d269fa","1014c457-be27-4c1b-b460-f83e82bff2fb","22c866d0-81fe-4011-8149-676ac1fa02b8","2df731d1-37e4-4afb-a9b0-60a5361a79ff","46c466a0-4c5f-4184-808a-4a28bebb3504","571de123-77aa-4b08-a25e-7f80cf5a2e5b","80618898-9cd2-4fbb-88d7-efc8d752e765","9d912297-e52f-4ab6-add4-633e0f263933","9da2f3bb-2b7f-48e1-86af-7e45c808bc49","b541380f-8e36-4fd8-91b3-04cf1f8d2736","be9335dd-d15f-4a2e-8d96-62dbf2cf9e2e","c5b280d6-5047-4296-99f2-724efbd7808c","c7050b88-eef5-4eca-be04-0555d4e68e73","d5707c9f-323b-4336-8c0f-fa28062045b3","e7b12517-7cc9-40a3-81a9-3cc253675012","e9f43a54-1e31-41e3-88a8-0d8fdd37c500","f16d7731-b9ce-4aba-a28a-3b95438a608d","f71034fd-8a00-46da-8bf9-af99041430bf","fe2cf63c-b3ba-4580-a7b3-9995d9610c67"],"_id":"881edf4e-5fbe-4f6c-9251-662c115ad0b4","abstract":"The process of information technology adoption and use is critical to deriving the benefits of information technology. Yet from a conceptual standpoint, few empirical studies have made a distinction between individuals' pre-adoption and post-adoption (continued use) beliefs and attitudes. This distinction is crucial in understanding and managing this process over time. The current study combines innovation diffusion and attitude theories in a theoretical framework to examine differences in pre-adoption and post-adoption beliefs and attitudes. The examination of Windows technology in a single organization indicates that users and potential adopters of information technology differ on their determinants of behavioral intention, attitude, and subjective norm. Potential adopter intention to adopt is solely determined by normative pressures, whereas user intention is solely determined by attitude. In addition, potential adopters base their attitude on a richer set of innovation characteristics than users. Whereas pre-adoption attitude is based on perceptions of usefulness, ease-of-use, result demonstrability, visibility, and trialability, post-adoption attitude is only based on instrumentality beliefs of usefulness and perceptions of image enhancements.","title":"Information technology adoption across time: a cross-sectional comparison of pre-adoption and post-adoption beliefs","venue":"Management Information Systems Quarterly","year":1999,"__v":0,"citationCount":806},{"authors":["Viswanath Venkatesh","Michael G. Morris"],"references":["017d7159-547c-4627-9a45-d98331ed2892","0a5567c5-7a18-4e16-9f53-a79c9f21e32d","2df731d1-37e4-4afb-a9b0-60a5361a79ff","39bd75e5-c40b-474f-85f3-c8ed63c11765","3bac5d08-74d8-4776-b976-c80acffe44d7","46c466a0-4c5f-4184-808a-4a28bebb3504","571de123-77aa-4b08-a25e-7f80cf5a2e5b","67316eeb-77f8-43f4-b0bd-d604387e80f1","767eacbf-fb87-44f8-bd87-9a4440413602","968281aa-1128-4459-815a-f7aa0b3e61c7","9d912297-e52f-4ab6-add4-633e0f263933","b1ba90ca-3599-4363-8703-5acce9f7f3f5","b97c62a1-8d95-4ada-a438-a1a9b78f7c68","c5b280d6-5047-4296-99f2-724efbd7808c","cf6802fe-c0b2-45c7-92cd-d1187f8986b1","e2a46555-6ca9-4cd4-a815-f4715ae04253","ee3f66e5-6921-4320-9125-944eb33a04f1","f98cc304-5a77-49f4-9bd6-3af076bc83d9"],"_id":"7583b6d0-44bd-444e-a311-4c537015a77d","abstract":"Using the Technology Acceptance Model (TAM), this research investigated gender differences in the overlooked context of individual adoption and sustained usage of technology in the workplace. User reactions and technology usage behavior were studied over a five-month period among 342 workers being introduced to a new software system. At all three points of measurement, compared to women, men's technology usage deci","title":"Why don't men ever stop to ask for directions? Gender, social influence, and their role in technology acceptance and usage behavior","venue":"Management Information Systems Quarterly","year":2000,"__v":0,"citationCount":771},{"authors":["Viswanath Venkatesh"],"references":["017d7159-547c-4627-9a45-d98331ed2892","05057282-4831-4793-adda-7abb31e3f0f1","0a5567c5-7a18-4e16-9f53-a79c9f21e32d","1014c457-be27-4c1b-b460-f83e82bff2fb","123c0f7a-4341-4a95-bb80-824a969eda20","22c866d0-81fe-4011-8149-676ac1fa02b8","2df731d1-37e4-4afb-a9b0-60a5361a79ff","35db08aa-da18-443d-a17f-bbfdefd6097a","3bac5d08-74d8-4776-b976-c80acffe44d7","42d8e3d9-b3ce-430d-8361-a8a5225311eb","46c466a0-4c5f-4184-808a-4a28bebb3504","571de123-77aa-4b08-a25e-7f80cf5a2e5b","662db3d8-b707-420c-9727-42e9f12a5479","67316eeb-77f8-43f4-b0bd-d604387e80f1","7583b6d0-44bd-444e-a311-4c537015a77d","767eacbf-fb87-44f8-bd87-9a4440413602","9d912297-e52f-4ab6-add4-633e0f263933","a536637e-ef3d-4dab-aa8c-fd86e575c002","a6489c44-f0a4-474a-97c0-eba9c62bcd67","b1ba90ca-3599-4363-8703-5acce9f7f3f5","c5b280d6-5047-4296-99f2-724efbd7808c","c6c47e96-4768-473b-853a-e33dd56a9688","cf6802fe-c0b2-45c7-92cd-d1187f8986b1","e05b1c8c-557d-498a-a425-40a99c2c9146","e2a46555-6ca9-4cd4-a815-f4715ae04253","f98cc304-5a77-49f4-9bd6-3af076bc83d9"],"_id":"ee3f66e5-6921-4320-9125-944eb33a04f1","abstract":"Much previous research has established that perceived ease of use is an important factor influencing user acceptance and usage behavior of information technologies. However, very little research has been conducted to understand how that perception forms and changes over time. The current work presents and tests an anchoring and adjustment-based theoretical model of the determinants of system-specific perceived ease of use. The model proposes control (internal and external--conceptualized as computer self-efficacy and facilitating conditions, respectively), intrinsic motivation (conceptualized as computer playfulness), and emotion (conceptualized as computer anxiety) as anchors that determine early perceptions about the ease of use of a new system. With increasing experience, it is expected that system-specific perceived ease of use, while still anchored to the general beliefs regarding computers and computer use, will adjust to reflect objective usability, perceptions of external control specific to the new system environment, and system-specific perceived enjoyment. The proposed model was tested in three different organizations among 246 employees using three measurements taken over a three-month period. The proposed model was strongly supported at all points of measurement, and explained up to 60% of the variance in system-specific perceived ease of use, which is twice as much as our current understanding. Important theoretical and practical implications of these findings are discussed.","title":"Determinants of Perceived Ease of Use: Integrating Control, Intrinsic Motivation, and Emotion into the Technology Acceptance Model","venue":"Information Systems Research","year":2000,"__v":0,"citationCount":1029}],"offsprings":[]},"109367fa-db04-4db0-8777-d6ca7e9e78fd":{"authors":["Amir Beck","Marc Teboulle"],"references":[],"_id":"109367fa-db04-4db0-8777-d6ca7e9e78fd","abstract":"We consider the class of iterative shrinkage-thresholding algorithms (ISTA) for solving linear inverse problems arising in signal/image processing. This class of methods, which can be viewed as an extension of the classical gradient algorithm, is attractive due to its simplicity and thus is adequate for solving large-scale problems even with dense matrix data. However, such methods are also known to converge quite slowly. In this paper we present a new fast iterative shrinkage-thresholding algorithm (FISTA) which preserves the computational simplicity of ISTA but with a global rate of convergence which is proven to be significantly better, both theoretically and practically. Initial promising numerical results for wavelet-based image deblurring demonstrate the capabilities of FISTA which is shown to be faster than ISTA by several orders of magnitude.","title":"A Fast Iterative Shrinkage-Thresholding Algorithm for Linear Inverse Problems","venue":"Siam Journal on Imaging Sciences","year":2009,"__v":0,"citationCount":1905,"parents":{"0a2fba85-4491-44c3-b0f2-eb7e75656e97":0,"31c883b9-75b1-4ea6-b9e2-776cc33a287f":11.11111111111111,"5165eeb8-d32d-4b9d-8344-d6488a1f2bd0":11.11111111111111,"52e55346-2fb4-45a8-9e50-db06f3343982":22.22222222222222,"5fedb8b5-e278-447d-931a-c0557216a939":0,"7db1957b-66a4-439f-a9bd-ca89aea58642":44.44444444444444,"872cc404-e3b9-4bed-a7a4-2994eb4f6353":11.11111111111111,"9431eeba-3bc3-4e65-bf62-639f7a6306de":44.44444444444444,"d11c6a56-fc23-4642-b394-99fd3aec953a":0},"keyword":{"0a2fba85-4491-44c3-b0f2-eb7e75656e97":11.179814814814819,"31c883b9-75b1-4ea6-b9e2-776cc33a287f":12.086772486772487,"5165eeb8-d32d-4b9d-8344-d6488a1f2bd0":11.621693121693124,"52e55346-2fb4-45a8-9e50-db06f3343982":9.40462962962963,"5fedb8b5-e278-447d-931a-c0557216a939":11.184193121693122,"7db1957b-66a4-439f-a9bd-ca89aea58642":9.838624338624339,"872cc404-e3b9-4bed-a7a4-2994eb4f6353":11.73994708994709,"9431eeba-3bc3-4e65-bf62-639f7a6306de":9.575661375661376,"d11c6a56-fc23-4642-b394-99fd3aec953a":11.870171957671959},"topic":["ista","algorithm","solv","simplic","shrinkagethreshold"],"groups":[{"authors":["José M. Bioucas-Dias","Mário A. T. Figueiredo"],"references":["040e2e80-fc91-4acc-915c-2981051b8948","0e0c2782-f8f6-4d9a-aaf0-c37dc9d6b920","170f3ee6-769a-4e7e-acc2-5ceb02492e93","1e46bd4c-ad0c-4742-b42c-b876161d9c97","2131c96b-7724-48f3-a53e-49c2d6e5065d","31c883b9-75b1-4ea6-b9e2-776cc33a287f","38643016-384b-4141-838e-0c9d2a6ce00c","3d414a5e-b97a-498e-8a75-920997235c6b","4b00142e-0e50-4245-9094-8d0108a68582","5281cbb0-780e-4ce5-bbd4-7a468b22dae2","52e55346-2fb4-45a8-9e50-db06f3343982","5fedb8b5-e278-447d-931a-c0557216a939","683334d9-f3d8-4f67-a8ca-7c881c3d8c79","686d066f-0d06-44b6-9716-7888fa679b50","6aebafce-f4c0-4a34-8a36-b9ede925fb8e","7d2f7f63-b763-4b4e-b501-6b3c389906f5","84bee1b3-94c1-4c5e-be80-7215b62480fb","9359a605-8a2a-4611-aec8-8605c91a04ee","a16b23f3-768b-4803-a909-cbbd591dd3c4","aa24e310-630a-4a59-81cc-f25421aa7fc0","ab0bfa8d-80b6-47ef-8a91-febce2ce65c5","b0c48cb4-68f1-4b0d-8cfa-b5031dc36858","ce62a18e-ad18-4cc3-a011-c434a1b91097","d11c6a56-fc23-4642-b394-99fd3aec953a","e150fc0f-42a7-4de9-a8f2-0b29d4304623","e6b4b4b8-6ed2-4be1-9463-dcd516752044"],"_id":"7db1957b-66a4-439f-a9bd-ca89aea58642","abstract":"Iterative shrinkage/thresholding (1ST) algorithms have been recently proposed to handle a class of convex unconstrained optimization problems arising in image restoration and other linear inverse problems. This class of problems results from combining a linear observation model with a nonquadratic regularizer (e.g., total variation or wavelet-based regularization). It happens that the convergence rate of these 1ST algorithms depends heavily on the linear observation operator, becoming very slow when this operator is ill-conditioned or ill-posed. In this paper, we introduce two-step 1ST (TwIST) algorithms, exhibiting much faster convergence rate than 1ST for ill-conditioned problems. For a vast class of nonquadratic convex regularizers (lscr P  norms, some Besov norms, and total variation), we show that TwIST converges to a minimizer of the objective function, for a given range of values of its parameters. For noninvertible observation operators, we introduce a monotonic version of TwIST (MTwIST); although the convergence proof does not apply to this scenario, we give experimental evidence that MTwIST exhibits similar speed gains over IST. The effectiveness of the new methods are experimentally confirmed on problems of image deconvolution and of restoration with missing samples.","title":"A New TwIST: Two-Step Iterative Shrinkage/Thresholding Algorithms for Image Restoration","venue":"IEEE Transactions on Image Processing","year":2007,"__v":0,"citationCount":315},{"authors":["Stephen J. Wright","Robert D. Nowak","Mário A. T. Figueiredo"],"references":["05c85ace-c998-47cd-a285-f6ecfd72004d","13e032c3-94bb-4e3e-abea-63934bf9715e","170f3ee6-769a-4e7e-acc2-5ceb02492e93","1760c31c-bb1f-4423-be5c-54855cf82498","1a77aa56-c4f8-466f-a1e6-e6b538199858","1c491f42-dbb1-4f9c-afd5-e921b54b45c1","1ca459f3-22c0-4de2-8edd-ea779a5b6c04","31c883b9-75b1-4ea6-b9e2-776cc33a287f","3f90046c-1c24-4a11-abc5-831c4d30f660","449bfdfc-f916-422c-ac0d-ebfdd2ab773a","4b00142e-0e50-4245-9094-8d0108a68582","4b09cdc3-989f-43d0-9a47-152bcfbac867","52e55346-2fb4-45a8-9e50-db06f3343982","592f4278-aa82-4c43-9026-c4e180500dcb","5fedb8b5-e278-447d-931a-c0557216a939","7db1957b-66a4-439f-a9bd-ca89aea58642","83139082-89a4-4393-9180-318885316118","9359a605-8a2a-4611-aec8-8605c91a04ee","9e65914c-bfef-45e7-9fd7-85c39ed13ac4","a53a3dda-b003-4d5c-96b1-e9afd8e35692","aa72891d-193b-414f-899f-da98c73d8488","ab0bfa8d-80b6-47ef-8a91-febce2ce65c5","adc31a96-1f8e-4793-8ee9-ecef04a16ac6","b0c48cb4-68f1-4b0d-8cfa-b5031dc36858","c3b999d0-4be5-48b3-82f7-272e4961d0de","c3f0fabd-810c-45d2-9b74-4f1b56e1078b","cbf4f48f-10c5-439c-af0f-9e626b22c908","ce62a18e-ad18-4cc3-a011-c434a1b91097","dfc05529-2956-4535-a242-1bc3af8a4737","f3e11502-4641-4ef9-af5c-0171802109ab","f56b877b-4060-4754-b303-e8140968544c","fb3eb505-20cf-4163-b5f9-c95dae0ff98f","fd7205d5-656f-4fda-a9dc-3851a2c1da6f"],"_id":"9431eeba-3bc3-4e65-bf62-639f7a6306de","abstract":"Finding sparse approximate solutions to large underdetermined linear systems of equations is a common problem in signal/image processing and statistics. Basis pursuit, the least absolute shrinkage and selection operator (LASSO), wavelet-based deconvolution and reconstruction, and compressed sensing (CS) are a few well-known areas in which problems of this type appear. One standard approach is to minimize an objective function that includes a quadratic ( pound   2 ) error term added to a sparsity-inducing (usually  pound   1 ) regularizer. We present an algorithmic framework for the more general problem of minimizing the sum of a smooth convex function and a nonsmooth, possibly nonconvex, sparsity-inducing function. We propose iterative methods in which each step is an optimization subproblem involving a separable quadratic term (diagonal Hessian) plus the original sparsity-inducing term. Our approach is suitable for cases in which this subproblem can be solved much more rapidly than the original problem. In addition to solving the standard  pound   2  -  pound   1  case, our approach handles other problems, e.g.,  pound   p  regularizers with p ne 1, or group-separable (GS) regularizers. Experiments with CS problems show that our approach provides state-of-the-art speed for the standard  pound   2  -  pound   1  problem, and is also efficient on problems with GS regularizers.","title":"Sparse reconstruction by separable approximation","venue":"international conference on acoustics, speech, and signal processing","year":2008,"__v":0,"citationCount":102}],"offsprings":["a81d35e6-d5cd-4eef-9144-b0755ef268d1","e537d143-155e-4ca0-8ae8-66b777a77fea"]},"12b5f05e-19e3-42ba-82e5-030ad311e3ae":{"authors":["Haewoon Kwak","Changhyun Lee","Hosung Park","Sue Moon"],"references":[],"_id":"12b5f05e-19e3-42ba-82e5-030ad311e3ae","abstract":"Twitter, a microblogging service less than three years old, commands more than 41 million users as of July 2009 and is growing fast. Twitter users tweet about any topic within the 140-character limit and follow others to receive their tweets. The goal of this paper is to study the topological characteristics of Twitter and its power as a new medium of information sharing.   We have crawled the entire Twitter site and obtained 41.7 million user profiles, 1.47 billion social relations, 4,262 trending topics, and 106 million tweets. In its follower-following topology analysis we have found a non-power-law follower distribution, a short effective diameter, and low reciprocity, which all mark a deviation from known characteristics of human social networks [28]. In order to identify influentials on Twitter, we have ranked users by the number of followers and by PageRank and found two rankings to be similar. Ranking by retweets differs from the previous two rankings, indicating a gap in influence inferred from the number of followers and that from the popularity of one's tweets. We have analyzed the tweets of top trending topics and reported on their temporal behavior and user participation. We have classified the trending topics based on the active period and the tweets and show that the majority (over 85%) of topics are headline news or persistent news in nature. A closer look at retweets reveals that any retweeted tweet is to reach an average of 1,000 users no matter what the number of followers is of the original tweet. Once retweeted, a tweet gets retweeted almost instantly on next hops, signifying fast diffusion of information after the 1st retweet.   To the best of our knowledge this work is the first quantitative study on the entire Twittersphere and information diffusion on it.","title":"What is Twitter, a social network or a news media?","venue":"international world wide web conferences","year":2010,"__v":0,"citationCount":1942,"parents":{"02b1f38f-522f-4948-93f3-c832e2b7123e":15.789473684210526,"2131b26d-48b9-4414-83a1-506e48eacadd":10.526315789473683,"35cad820-9f36-41ac-86e7-b14bf90e75ba":0,"3d11074d-a91c-4dba-bbca-2797badbc00a":0,"4725458c-f1c3-4c96-ad12-1c0f1e2fe198":0,"48d1fd6b-a2c0-4427-a353-85adef51fa62":36.84210526315789,"57566634-e617-4180-993f-0388e441c7cc":5.263157894736842,"609581f6-cf93-4762-9c81-51fec2b8339d":10.526315789473683,"6174fffa-55f5-4bd6-b887-dd6980064305":10.526315789473683,"6a769ef6-b720-4bb2-bdf8-9a74d5f35fb0":10.526315789473683,"700fe5e3-36d0-47a5-b35f-8b0419086576":0,"82acbd44-88af-4a63-9021-dcd3799a453f":0,"9bd3b8dd-728e-4476-a3b8-f7b08f51bb78":0,"a2b4e930-1be1-4b91-8122-aacb6ec72fab":15.789473684210526,"b6b76a9a-302d-45e4-9560-cea75172aaba":5.263157894736842,"cedeec09-9378-42b0-807f-d1425b1775b3":0,"da773e14-5247-4600-8da8-2452699899d9":0,"f0a4cde6-4c55-4f81-ace0-5bfec3bf5de8":0,"fc9e5217-51fd-457d-9d09-680925082f56":0},"keyword":{"02b1f38f-522f-4948-93f3-c832e2b7123e":9.601587301587303,"2131b26d-48b9-4414-83a1-506e48eacadd":11.169576719576721,"35cad820-9f36-41ac-86e7-b14bf90e75ba":10.937936507936508,"3d11074d-a91c-4dba-bbca-2797badbc00a":11.240000000000002,"4725458c-f1c3-4c96-ad12-1c0f1e2fe198":9.886507936507936,"48d1fd6b-a2c0-4427-a353-85adef51fa62":10.056349206349207,"57566634-e617-4180-993f-0388e441c7cc":9.89047619047619,"609581f6-cf93-4762-9c81-51fec2b8339d":8.76468253968254,"6174fffa-55f5-4bd6-b887-dd6980064305":11.884126984126985,"6a769ef6-b720-4bb2-bdf8-9a74d5f35fb0":10.961904761904764,"700fe5e3-36d0-47a5-b35f-8b0419086576":11.240000000000002,"82acbd44-88af-4a63-9021-dcd3799a453f":11.94047619047619,"9bd3b8dd-728e-4476-a3b8-f7b08f51bb78":11.717460317460317,"a2b4e930-1be1-4b91-8122-aacb6ec72fab":9.230952380952381,"b6b76a9a-302d-45e4-9560-cea75172aaba":5.8003968253968266,"cedeec09-9378-42b0-807f-d1425b1775b3":6.274603174603175,"da773e14-5247-4600-8da8-2452699899d9":11.494336219336219,"f0a4cde6-4c55-4f81-ace0-5bfec3bf5de8":10.423809523809522,"fc9e5217-51fd-457d-9d09-680925082f56":8.165608465608466},"topic":["tweet","user","retweet","twitter","topic"],"groups":[{"authors":["Fabrício Benevenuto","Tiago Rodrigues","Meeyoung Cha","Virgílio A. F. Almeida"],"references":["02b1f38f-522f-4948-93f3-c832e2b7123e","1c03ddd6-a80b-4272-bb1c-62636b73b9ec","2131b26d-48b9-4414-83a1-506e48eacadd","3c0c7536-7f11-4e63-bf6d-32d67050d8ef","40d9a6c9-b99e-43cc-90eb-5259cf4416a0","4542fec4-a3d0-4780-bca6-04d50fe9a486","4725458c-f1c3-4c96-ad12-1c0f1e2fe198","57566634-e617-4180-993f-0388e441c7cc","58ffb14c-c145-44a0-9d5d-adf58643804f","6174fffa-55f5-4bd6-b887-dd6980064305","66ae463b-2689-48ef-b53f-7f1fbfda43fe","72ce156c-4b13-4586-9d73-f974cf75fc5f","82acbd44-88af-4a63-9021-dcd3799a453f","8f8c339c-0c40-4640-9139-b292179bd7ff","a2b4e930-1be1-4b91-8122-aacb6ec72fab","ad9d7fab-8425-437b-addf-c7d66ec105bc","bad502e2-69d9-416e-b38d-080208bf2af2","c0473d19-6897-410b-8b7a-0af42d31cb68","cde64367-18fe-4ab9-9f4d-7d4d14bf996f"],"_id":"48d1fd6b-a2c0-4427-a353-85adef51fa62","abstract":"Understanding how users behave when they connect to social networking sites creates opportunities for better interface design, richer studies of social interactions, and improved design of content distribution systems. In this paper, we present a first of a kind analysis of user workloads in online social networks. Our study is based on detailed clickstream data, collected over a 12-day period, summarizing HTTP sessions of 37,024 users who accessed four popular social networks: Orkut, MySpace, Hi5, and LinkedIn. The data were collected from a social network aggregator website in Brazil, which enables users to connect to multiple social networks with a single authentication. Our analysis of the clickstream data reveals key features of the social network workloads, such as how frequently people connect to social networks and for how long, as well as the types and sequences of activities that users conduct on these sites. Additionally, we crawled the social network topology of Orkut, so that we could analyze user interaction data in light of the social graph. Our data analysis suggests insights into how users interact with friends in Orkut, such as how frequently users visit their friends' or non-immediate friends' pages. In summary, our analysis demonstrates the power of using clickstream data in identifying patterns in social network workloads and social interactions. Our analysis shows that browsing, which cannot be inferred from crawling publicly available data, accounts for 92% of all user activities. Consequently, compared to using only crawled data, considering silent interactions like browsing friends' pages increases the measured level of interaction among users.","title":"Characterizing user behavior in online social networks","venue":"internet measurement conference","year":2009,"__v":0,"citationCount":302}],"offsprings":[]},"12d6aa75-3066-4e5f-a73d-f0d56c9d99f5":{"authors":["Fabian Pedregosa","Gaël Varoquaux","Alexandre Gramfort","Vincent Michel","Bertrand Thirion","Olivier Grisel","Mathieu Blondel","Peter Prettenhofer","Ron J. Weiss","Vincent Dubourg","Jake Vanderplas","Alexandre Passos","David Cournapeau","Matthieu Brucher","Matthieu Perrot","Edouard Duchesnay"],"references":["4cbd7765-c47a-4004-a5f8-c2da7c7d1c7b","c1b6b493-01ef-420f-be44-7bacfe34e846"],"_id":"12d6aa75-3066-4e5f-a73d-f0d56c9d99f5","abstract":"Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language. Emphasis is put on ease of use, performance, documentation, and API consistency. It has minimal dependencies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings. Source code, binaries, and documentation can be downloaded from http://scikit-learn.sourceforge.net.","title":"Scikit-learn: Machine Learning in Python","venue":"Journal of Machine Learning Research","year":2011,"__v":0,"citationCount":1855,"parents":{"078b095c-7687-43f2-a0bf-30ea78f787db":10,"4cbd7765-c47a-4004-a5f8-c2da7c7d1c7b":10,"771248c8-819b-4329-b212-e352622cb516":10,"8c16c4bb-365a-4ffe-8a79-69624194fc70":0,"9507814f-1623-46bb-8f71-1a659c89773d":0,"a3680867-e634-4e58-8cf3-1d8888bd2f74":0,"a936b865-4733-4094-82c1-c813b0ef5dce":0,"b4e9025d-fb30-4eba-bb96-7d16ed387d4e":0,"beecb1f5-221e-45d6-a2e8-a8b640ddf94b":0,"c1b6b493-01ef-420f-be44-7bacfe34e846":10},"keyword":{"078b095c-7687-43f2-a0bf-30ea78f787db":10.622063492063491,"4cbd7765-c47a-4004-a5f8-c2da7c7d1c7b":10.975925925925925,"771248c8-819b-4329-b212-e352622cb516":11.87142857142857,"8c16c4bb-365a-4ffe-8a79-69624194fc70":7.726984126984126,"9507814f-1623-46bb-8f71-1a659c89773d":10.711111111111109,"a3680867-e634-4e58-8cf3-1d8888bd2f74":10.092023809523809,"a936b865-4733-4094-82c1-c813b0ef5dce":10.203055555555556,"b4e9025d-fb30-4eba-bb96-7d16ed387d4e":9.552063492063493,"beecb1f5-221e-45d6-a2e8-a8b640ddf94b":8.094444444444445,"c1b6b493-01ef-420f-be44-7bacfe34e846":10.403055555555556},"topic":["machin","learn","document","wide","unsupervis"],"offsprings":[]},"1317365d-c46d-4c09-8261-9d07404e4908":{"authors":["Vladimir Kolmogorov","R. Zabin"],"references":["1f520d1a-5870-477d-85d7-0f50be690ea7","3a8fbc53-3805-4e6f-9f45-6881b640eb5e"],"_id":"1317365d-c46d-4c09-8261-9d07404e4908","abstract":"In the last few years, several new algorithms based on graph cuts have been developed to solve energy minimization problems in computer vision. Each of these techniques constructs a graph such that the minimum cut on the graph also minimizes the energy. Yet, because these graph constructions are complex and highly specific to a particular energy function, graph cuts have seen limited application to date. In this paper, we give a characterization of the energy functions that can be minimized by graph cuts. Our results are restricted to functions of binary variables. However, our work generalizes many previous constructions and is easily applicable to vision problems that involve large numbers of labels, such as stereo, motion, image restoration, and scene reconstruction. We give a precise characterization of what energy functions can be minimized using graph cuts, among the energy functions that can be written as a sum of terms containing three or fewer binary variables. We also provide a general-purpose construction to minimize such an energy function. Finally, we give a necessary condition for any energy function of binary variables to be minimized by graph cuts. Researchers who are considering the use of graph cuts to optimize a particular energy function can use our results to determine if this is possible and then follow our construction to create the appropriate graph. A software implementation is freely available.","title":"What energy functions can be minimized via graph cuts","venue":"european conference on computer vision","year":2004,"__v":0,"citationCount":1574,"parents":{"004aa844-c144-4f34-b328-e054848d2c82":9.090909090909092,"01d5bd72-becb-4055-8874-f7c07244b763":12.121212121212121,"19d21680-6bc5-4f6c-960e-d4788a6d1940":3.0303030303030303,"1b41d9a0-3857-4fb6-b7ba-d39da73c04dd":0,"1f520d1a-5870-477d-85d7-0f50be690ea7":27.27272727272727,"21cc7ac4-8d2a-4777-934a-fa1069ed73e1":27.27272727272727,"28a2d956-0a04-4141-96d5-4f687ffb49ce":0,"3630ebbb-a82a-435e-a5eb-b33d9fad26c9":0,"37e76afb-f79f-41f8-b75d-28dadd7d5cd7":0,"3a8fbc53-3805-4e6f-9f45-6881b640eb5e":36.36363636363637,"6c5c8a75-af91-4f49-a9d7-b483a1fbe977":3.0303030303030303,"76845b3d-e45f-443c-a181-b1b75f17d47b":12.121212121212121,"78ee5ccf-613d-4a4b-8858-33c1cf0ef461":30.303030303030305,"78f0682e-5ec4-47e5-b77a-6842fb2f3c10":0,"79359cb0-3770-480a-943b-fabb0f8da236":0,"85471950-c85d-4494-ac99-30b5450ad095":3.0303030303030303,"8bb2c446-0081-4404-a944-56a0d5dc2f15":0,"8f4f3015-c03d-46e1-90fb-2c42ea2cb91f":0,"942ceea1-92aa-4e72-94a7-bb65bb5889ed":9.090909090909092,"95aa9aa5-0113-491a-9440-2e538b844a7d":6.0606060606060606,"95e54ec2-04d3-4558-bbcd-69cd0c44f58a":15.151515151515152,"a57c6dbb-09d2-4c2e-86ba-02e47e78f5af":15.151515151515152,"aca296a6-e562-4234-9d5d-62093dbc2910":0,"b1c2251e-7b54-41e5-8130-10d9646e02da":24.242424242424242,"c2dd1e3a-e1d4-456c-b1b8-6ddc2d66f1ee":9.090909090909092,"c521b560-aaae-4d30-9007-8eeeafd83966":3.0303030303030303,"cdd6b1f4-012f-4678-be03-b58ef5d7f710":3.0303030303030303,"d17921a4-9dbf-4708-b55e-23b35cd54544":12.121212121212121,"d389a332-89d1-4565-afd5-349296debb2e":3.0303030303030303,"dd8087bb-bde1-4b8e-8ef0-3f8d0aabce9b":6.0606060606060606,"e4add357-1166-4eb9-9d37-ebd77264ce41":15.151515151515152,"f5de6b41-0df8-4270-8211-a67a081dad45":0,"ff1de60e-c014-4436-a163-f1b7aacf5301":3.0303030303030303},"keyword":{"004aa844-c144-4f34-b328-e054848d2c82":9.454629629629629,"01d5bd72-becb-4055-8874-f7c07244b763":9.6634126984127,"19d21680-6bc5-4f6c-960e-d4788a6d1940":9.149074074074072,"1b41d9a0-3857-4fb6-b7ba-d39da73c04dd":7.47824074074074,"1f520d1a-5870-477d-85d7-0f50be690ea7":7.840555555555554,"21cc7ac4-8d2a-4777-934a-fa1069ed73e1":8.816666666666666,"28a2d956-0a04-4141-96d5-4f687ffb49ce":9.825793650793651,"3630ebbb-a82a-435e-a5eb-b33d9fad26c9":6.629999999999999,"37e76afb-f79f-41f8-b75d-28dadd7d5cd7":8.103333333333333,"3a8fbc53-3805-4e6f-9f45-6881b640eb5e":7.854629629629629,"6c5c8a75-af91-4f49-a9d7-b483a1fbe977":9.265740740740739,"76845b3d-e45f-443c-a181-b1b75f17d47b":10.327962962962962,"78ee5ccf-613d-4a4b-8858-33c1cf0ef461":10.12063492063492,"78f0682e-5ec4-47e5-b77a-6842fb2f3c10":6.336402116402116,"79359cb0-3770-480a-943b-fabb0f8da236":5.280555555555555,"85471950-c85d-4494-ac99-30b5450ad095":8.490079365079364,"8bb2c446-0081-4404-a944-56a0d5dc2f15":10.431296296296296,"8f4f3015-c03d-46e1-90fb-2c42ea2cb91f":7.038888888888889,"942ceea1-92aa-4e72-94a7-bb65bb5889ed":7.92462962962963,"95aa9aa5-0113-491a-9440-2e538b844a7d":0,"95e54ec2-04d3-4558-bbcd-69cd0c44f58a":8.163968253968253,"a57c6dbb-09d2-4c2e-86ba-02e47e78f5af":8.036111111111111,"aca296a6-e562-4234-9d5d-62093dbc2910":0,"b1c2251e-7b54-41e5-8130-10d9646e02da":6.032222222222221,"c2dd1e3a-e1d4-456c-b1b8-6ddc2d66f1ee":6.229444444444444,"c521b560-aaae-4d30-9007-8eeeafd83966":7.52473544973545,"cdd6b1f4-012f-4678-be03-b58ef5d7f710":7.965079365079365,"d17921a4-9dbf-4708-b55e-23b35cd54544":6.3999999999999995,"d389a332-89d1-4565-afd5-349296debb2e":10.007063492063489,"dd8087bb-bde1-4b8e-8ef0-3f8d0aabce9b":8.958333333333334,"e4add357-1166-4eb9-9d37-ebd77264ce41":9.163968253968253,"f5de6b41-0df8-4270-8211-a67a081dad45":8.486851851851851,"ff1de60e-c014-4436-a163-f1b7aacf5301":8.576190476190476},"topic":["graph","energi","function","cut","minim"],"groups":[{"authors":["Daniel Scharstein","Richard Szeliski","Ramin Zabih"],"references":["0047b2cf-bd19-4f8a-979e-ef5cc5b4a43f","004aa844-c144-4f34-b328-e054848d2c82","019da994-fd26-4a39-a1a5-f6e52a18933a","07c8a80e-0892-408f-9e56-4e77d9441a64","0c3cac6b-305e-4f1c-8ab8-72c6a3a551fe","0f9cfb03-c1f3-4a60-886e-08b07d5e005c","11666f79-0a9d-49a3-b327-d194e202c94f","15a2345f-3667-4fde-b64e-30471b6ae9ee","16ccd666-4632-42fa-9e92-8cd740177e6b","1b5dfcf4-8c22-4438-901c-5bed88fdda29","1c09ef91-f69a-43e4-aaa7-571f3a143ea9","1c9d9c56-5ae9-4d13-a4b2-9c0833676f70","200c1972-9f6c-4e1b-9dbe-a1d29c7641cb","239a71ea-70f9-450c-9b3c-658faab40d9d","25b0c9f9-0c8a-4f2a-b075-90d339b6faa3","2bb7edd0-987a-4b75-916f-957764d7d0e0","32148a0b-6ce4-4a1e-a1d2-98a96b27b24f","37e76afb-f79f-41f8-b75d-28dadd7d5cd7","3a8fbc53-3805-4e6f-9f45-6881b640eb5e","3b1b6ffe-75aa-45d1-9f3e-dadd4479a272","3f4cc95c-5f47-4031-8671-e23ff4fe2ed2","4383b14b-805b-43d4-84a3-b70181605b18","45ef6717-ea63-4be0-bb43-26747479ccbb","48e25c19-07a0-46c9-a659-e76db6e72d74","4d6cc0b7-557d-4594-8bc8-ab1ce0ac251e","54b8ad0d-2246-4650-a09b-5f5b9705e0e6","558f4de5-92d8-4e29-a667-3159dd43262a","55df9539-92c1-4080-b4b6-154771405001","598627d0-d01d-4398-a45e-1440d21fe4f2","5be0f6b3-82ef-4371-99eb-f72853a7e1f3","62aa6ba4-1331-4c57-99f5-978d580c9573","6c9927be-dd3f-4a48-8ed6-b969a66e5c91","6e0d7a60-4787-4348-84a5-5b94664a5777","70d6f58b-91bb-4c01-9f18-e62dc01d087d","712f3c82-078f-42a8-9f90-da62b4175b17","76845b3d-e45f-443c-a181-b1b75f17d47b","7781665f-ef39-4237-9857-63477d05f5ac","78bbab5f-b63b-40cc-9c8a-2c146191d833","7e130624-dee1-4b3d-bd66-c6febab5a5a0","7e598ce4-7739-42dd-8761-eb8984ed2b19","850e99fb-725d-4f54-8e01-4791bfffb283","85471950-c85d-4494-ac99-30b5450ad095","8a4274f4-8925-4724-aca5-4f9c3455dc3e","8f4f3015-c03d-46e1-90fb-2c42ea2cb91f","900c927f-8e6e-4290-8eac-63fef682460d","90483bd3-a6a7-4799-93cf-af14e991335c","936e0ae4-e6e1-4b3b-9d0a-a6bff589fc7b","942ceea1-92aa-4e72-94a7-bb65bb5889ed","94acc1d1-4b4e-4796-9b58-8cf91b031e7e","97fcbcf5-3e50-4d78-bbe3-18660872b887","a36cd635-6811-4a18-a424-46fd4719ae31","a57c6dbb-09d2-4c2e-86ba-02e47e78f5af","a7da5f11-1302-4305-a67a-9503dea05eb7","a872c04a-47c6-4f4b-b0b9-3afbaa3538cf","a8eade43-4ee6-4165-a08e-c92d0d748343","b00ef6b5-66d3-480a-ae96-03c3ddf2e26e","b1139559-cdb8-4b39-b8a1-f2125166a223","b1c2251e-7b54-41e5-8130-10d9646e02da","b2ced9a5-3457-48b8-8d4c-66badd866d75","bb138fb8-d3a9-497a-879d-b21aa7347b53","be0f6fa3-438a-4d3e-b809-2a31857642fd","be7fa5a9-6fc4-4aea-8e18-6c206ab42d14","bfeeb55f-4b90-4886-aa57-817ba8de7988","c258aec7-ba1b-4228-b47b-a0900a1bcfe2","c3ec3b14-75be-4b18-af66-195537226585","c6977873-accf-4edd-a522-ad649fc8295a","c7423207-f332-480d-b5d1-7e96279e574c","cae374ce-5b99-482e-950a-0b9e304eb498","d1538940-ff7f-4b82-9f1d-8972c0bdb4ef","d46a67de-c591-4872-a836-47165538b63c","d6edad4f-53c7-4a29-b484-05872a3cc82a","d8229968-5440-4e12-ae6e-d7ba4f8eb389","df847368-a372-4190-aac2-98c4bb9d0ddb","e8a7d5ab-2a86-4f90-a193-c62c686d5ea7","e927dff1-6ed4-45fd-8852-eb804e11e665","e9939b8b-6fcb-4ded-ac64-43c7fdfb52d6","f0887f29-b2e1-4971-a369-4df8b83b8996","f27cb993-16cd-44f9-b0c8-6bbeb3ecf297","f37628db-beac-4a64-ab7b-cd0ce4f943a9","f3868715-abb3-4115-b57b-dc6d874f02d1","f39486db-a4d9-49b4-a659-44c63900a7d5","f45d6bd0-f1a4-4f80-b6af-5e3b12bbac3a","f4d90d70-135a-4d1c-bd61-693a2bf04253","f6326193-ef92-4e64-8a4e-7439f8692fa1","f6706f16-c997-4b7f-a044-1d1a9f85dd51","f7037864-4b92-437b-a90e-509d4ec350c8","fd99a7a7-0aa2-4607-91bd-975285af5ad1"],"_id":"1f520d1a-5870-477d-85d7-0f50be690ea7","abstract":"Stereo matching is one of the most active research areas in computer vision. While a large number of algorithms for stereo correspondence have been developed, relatively little work has been done on characterizing their performance. In this paper, we present a taxonomy of dense, two-frame stereo methods designed to assess the different components and design decisions made in individual stereo algorithms. Using this taxonomy, we compare existing stereo methods and present experiments evaluating the performance of many different variants. In order to establish a common software platform and a collection of data sets for easy evaluation, we have designed a stand-alone, flexible C++ implementation that enables the evaluation of individual components and that can be easily extended to include new algorithms. We have also produced several new multiframe stereo data sets with ground truth, and are making both the code and data sets available on the Web.","title":"A taxonomy and evaluation of dense two-frame stereo correspondence algorithms","venue":"International Journal of Computer Vision","year":2001,"__v":0,"citationCount":2529},{"authors":["Yuri Boykov","Vladimir Kolmogorov"],"references":["01d5bd72-becb-4055-8874-f7c07244b763","1317365d-c46d-4c09-8261-9d07404e4908","1f520d1a-5870-477d-85d7-0f50be690ea7","1f86ba16-96b1-4b41-84c3-47837bc04da2","65f30c74-7499-4ca3-9a89-6b31655c5750","6886264a-2e7a-4a5a-ae62-c740bc483621","76845b3d-e45f-443c-a181-b1b75f17d47b","78ee5ccf-613d-4a4b-8858-33c1cf0ef461","7b8583e6-dbd3-4d2f-859a-f1de071886f2","7d408177-f7a0-466a-b8e1-46eba464b7c9","85471950-c85d-4494-ac99-30b5450ad095","8f4f3015-c03d-46e1-90fb-2c42ea2cb91f","942ceea1-92aa-4e72-94a7-bb65bb5889ed","95e54ec2-04d3-4558-bbcd-69cd0c44f58a","a6043444-3eb0-4dd0-90e4-e54bf5363250","aca296a6-e562-4234-9d5d-62093dbc2910","b74f8b0a-3956-40bb-9fa5-24d34ad705d4","bcfb1417-4781-4c66-a6a0-ca2c8e1261a6","c2dd1e3a-e1d4-456c-b1b8-6ddc2d66f1ee","dd8087bb-bde1-4b8e-8ef0-3f8d0aabce9b","eb24ab61-56e4-417c-8027-97c4760e8cfa","f5de6b41-0df8-4270-8211-a67a081dad45","f6706f16-c997-4b7f-a044-1d1a9f85dd51","fc9a9ab5-7585-419a-8d2f-cdddd99a5c25"],"_id":"3a8fbc53-3805-4e6f-9f45-6881b640eb5e","abstract":"Minimum cut/maximum flow algorithms on graphs have emerged as an increasingly useful tool for exactor approximate energy minimization in low-level vision. The combinatorial optimization literature provides many min-cut/max-flow algorithms with different polynomial time complexity. Their practical efficiency, however, has to date been studied mainly outside the scope of computer vision. The goal of this paper is to provide an experimental comparison of the efficiency of min-cut/max flow algorithms for applications in vision. We compare the running times of several standard algorithms, as well as a new algorithm that we have recently developed. The algorithms we study include both Goldberg-Tarjan style \"push -relabel\" methods and algorithms based on Ford-Fulkerson style \"augmenting paths.\" We benchmark these algorithms on a number of typical graphs in the contexts of image restoration, stereo, and segmentation. In many cases, our new algorithm works several times faster than any of the other methods, making near real-time performance possible. An implementation of our max-flow/min-cut algorithm is available upon request for research purposes.","title":"An experimental comparison of min-cut/max- flow algorithms for energy minimization in vision","venue":"IEEE Transactions on Pattern Analysis and Machine Intelligence","year":2004,"__v":0,"citationCount":1971},{"authors":["Vladimir Kolmogorov","Ramin Zabih"],"references":["004aa844-c144-4f34-b328-e054848d2c82","01d5bd72-becb-4055-8874-f7c07244b763","1317365d-c46d-4c09-8261-9d07404e4908","1b41d9a0-3857-4fb6-b7ba-d39da73c04dd","1bd0cfa8-b0e9-4ed1-973f-d251f147b4de","1f520d1a-5870-477d-85d7-0f50be690ea7","318a112e-0a86-4729-8605-200e06a2d6bd","37e76afb-f79f-41f8-b75d-28dadd7d5cd7","3a8fbc53-3805-4e6f-9f45-6881b640eb5e","477909c4-4d70-4a7d-a156-4fab18ed1434","6c9927be-dd3f-4a48-8ed6-b969a66e5c91","76845b3d-e45f-443c-a181-b1b75f17d47b","85471950-c85d-4494-ac99-30b5450ad095","8a4274f4-8925-4724-aca5-4f9c3455dc3e","8bf39ac5-01c0-4df7-99c3-12c96dc305e1","8f4f3015-c03d-46e1-90fb-2c42ea2cb91f","942ceea1-92aa-4e72-94a7-bb65bb5889ed","f37628db-beac-4a64-ab7b-cd0ce4f943a9","f6326193-ef92-4e64-8a4e-7439f8692fa1"],"_id":"78ee5ccf-613d-4a4b-8858-33c1cf0ef461","abstract":"We address the problem of computing the 3-dimensional shape of an arbitrary scene from a set of images taken at known viewpoints. Multi-camera scene reconstruction is a natural generalization of the stereo matching problem. However, it is much more difficult than stereo, primarily due to the difficulty of reasoning about visibility. In this paper, we take an approach that has yielded excellent results for stereo, namely energy minimization via graph cuts. We first give an energy minimization formulation of the multi-camera scene reconstruction problem. The energy that we minimize treats the input images symmetrically, handles visibility properly, and imposes spatial smoothness while preserving discontinuities. As the energy function is NP-hard to minimize exactly, we give a graph cut algorithm that computes a local minimum in a strong sense. We handle all camera configurations where voxel coloring can be used, which is a large and natural class. Experimental data demonstrates the effectiveness of our approach.","title":"Multi-camera Scene Reconstruction via Graph Cuts","venue":"european conference on computer vision","year":2002,"__v":0,"citationCount":362},{"authors":["Michael H. Lin","Carlo Tomasi"],"references":["0047b2cf-bd19-4f8a-979e-ef5cc5b4a43f","004aa844-c144-4f34-b328-e054848d2c82","01c0587f-e27b-47b4-adf8-7c7fd5912a23","01d5bd72-becb-4055-8874-f7c07244b763","0ab83a02-d072-493d-b259-7e14379d15f1","11666f79-0a9d-49a3-b327-d194e202c94f","12f47cd6-49b2-4ac8-9a94-9bdc9b782d14","1317365d-c46d-4c09-8261-9d07404e4908","19d9d23c-339d-4026-aff7-c81ee3daa0d7","1c09ef91-f69a-43e4-aaa7-571f3a143ea9","1f520d1a-5870-477d-85d7-0f50be690ea7","200c1972-9f6c-4e1b-9dbe-a1d29c7641cb","229c6b00-6eaf-4302-b843-09167f8082c5","2366f127-1dff-43c7-a8ea-576ee3eef49a","239a71ea-70f9-450c-9b3c-658faab40d9d","2f393a81-de8e-426c-b8ed-00b90baf096a","37e76afb-f79f-41f8-b75d-28dadd7d5cd7","3b1b6ffe-75aa-45d1-9f3e-dadd4479a272","3f4cc95c-5f47-4031-8671-e23ff4fe2ed2","48b2f9f3-f780-4f6b-95b9-b650bb93ef65","48e25c19-07a0-46c9-a659-e76db6e72d74","4d6cc0b7-557d-4594-8bc8-ab1ce0ac251e","4e66dcf4-0228-4e26-9219-3d026b66698d","55df9539-92c1-4080-b4b6-154771405001","598627d0-d01d-4398-a45e-1440d21fe4f2","62b07eb1-bcde-4d15-aa85-b10985d900b0","6b0002c3-d89e-41dc-9407-3c7a16e65c6b","712f3c82-078f-42a8-9f90-da62b4175b17","76845b3d-e45f-443c-a181-b1b75f17d47b","7781665f-ef39-4237-9857-63477d05f5ac","7b2670a6-3713-4e06-a2f1-b07e9792e017","7e130624-dee1-4b3d-bd66-c6febab5a5a0","85471950-c85d-4494-ac99-30b5450ad095","8a4274f4-8925-4724-aca5-4f9c3455dc3e","8f4f3015-c03d-46e1-90fb-2c42ea2cb91f","900c927f-8e6e-4290-8eac-63fef682460d","936e0ae4-e6e1-4b3b-9d0a-a6bff589fc7b","94acc1d1-4b4e-4796-9b58-8cf91b031e7e","9f91c3c3-2b1a-470a-bcdf-c5c26d7d7f0b","a57c6dbb-09d2-4c2e-86ba-02e47e78f5af","a70f96e5-7fcf-49d3-b45f-cea69d2cd020","a872c04a-47c6-4f4b-b0b9-3afbaa3538cf","b1c2251e-7b54-41e5-8130-10d9646e02da","be0f6fa3-438a-4d3e-b809-2a31857642fd","c9fa31f7-f6ce-49ea-b42c-8d03ae59dbe4","cae374ce-5b99-482e-950a-0b9e304eb498","d710fb4d-cec0-4728-be04-6523dfb5e6a8","db75527a-70d9-4c50-ab57-1c3304acc1fe","e70946b4-ce55-4f07-a2e4-63d80530a849","e927dff1-6ed4-45fd-8852-eb804e11e665","f27cb993-16cd-44f9-b0c8-6bbeb3ecf297","f39486db-a4d9-49b4-a659-44c63900a7d5","f4d90d70-135a-4d1c-bd61-693a2bf04253","f6706f16-c997-4b7f-a044-1d1a9f85dd51","fd8089f1-54b1-4dda-b7a9-f73c74960fd9"],"_id":"21cc7ac4-8d2a-4777-934a-fa1069ed73e1","abstract":"We propose a new binocular stereo algorithm that estimates scene structure as a collection of smooth surface patches. The disparities within each patch are modeled by a continuous-valued spline, while the extent of each patch is represented via a pixelwise partitioning of the images. Disparities and extents are alternately estimated in an iterative, energy minimization framework. Experimental results demonstrate that, for scenes consisting of smooth surfaces, the proposed algorithm significantly improves upon the state of the art.","title":"Surfaces with occlusions from layered stereo","venue":"IEEE Transactions on Pattern Analysis and Machine Intelligence","year":2004,"__v":0,"citationCount":58}],"offsprings":["5ffadf36-4496-4be6-b8a8-828fa37f7757","3a8fbc53-3805-4e6f-9f45-6881b640eb5e"]},"1545dfd3-2c25-4ff1-b43c-df4a2a501d06":{"authors":["Brad Karp","H. T. Kung"],"references":["7c9f8cd8-d0ef-4954-b4db-4a6c803459c2"],"_id":"1545dfd3-2c25-4ff1-b43c-df4a2a501d06","abstract":"We present Greedy Perimeter Stateless Routing (GPSR), a novel routing protocol for wireless datagram networks that uses the  positions  of routers and a packet's destination to make packet forwarding decisions. GPSR makes  greedy  forwarding decisions using only information about a router's immediate neighbors in the network topology. When a packet reaches a region where greedy forwarding is impossible, the algorithm recovers by routing around the  perimeter  of the region. By keeping state only about the local topology, GPSR scales better in per-router state than shortest-path and ad-hoc routing protocols as the number of network destinations increases. Under mobility's frequent topology changes, GPSR can use local topology information to find correct new routes quickly. We describe the GPSR protocol, and use extensive simulation of mobile wireless networks to compare its performance with that of Dynamic Source Routing. Our simulations demonstrate GPSR's scalability on densely deployed wireless networks.","title":"GPSR: greedy perimeter stateless routing for wireless networks","venue":"acm ieee international conference on mobile computing and networking","year":2000,"__v":0,"citationCount":3267,"parents":{"0b93552e-74e8-483f-82cb-5c04e1cd9232":0,"0d4d0363-07b5-43b6-976d-955e96044709":0,"4ac80067-bbea-4eaf-8b7a-89c97db7ecfe":0,"4e91bf76-c262-4d42-b8e2-1a3de3c6cac6":0,"60fb0dc2-bde3-4714-948e-de0ed12ab460":0,"6825e7be-db72-4377-a599-6667ef0bd553":0,"6a9c2062-e8eb-4584-8d40-35f8ed4e40d2":0,"7c9f8cd8-d0ef-4954-b4db-4a6c803459c2":25,"83a2eb55-b330-4e0c-8dc9-05e9466d5028":8.333333333333332,"9de43d04-c7fa-48a9-b092-67c2888745d4":0,"e4ee2d81-7629-4445-b4f3-55ef57bd42fd":41.66666666666667,"e877a51a-2c53-4362-ae62-5a0ad242ecf7":25},"keyword":{"0b93552e-74e8-483f-82cb-5c04e1cd9232":8.86468253968254,"0d4d0363-07b5-43b6-976d-955e96044709":10.075132275132278,"4ac80067-bbea-4eaf-8b7a-89c97db7ecfe":0,"4e91bf76-c262-4d42-b8e2-1a3de3c6cac6":0,"60fb0dc2-bde3-4714-948e-de0ed12ab460":9.889285714285716,"6825e7be-db72-4377-a599-6667ef0bd553":8.94920634920635,"6a9c2062-e8eb-4584-8d40-35f8ed4e40d2":0,"7c9f8cd8-d0ef-4954-b4db-4a6c803459c2":12.09484126984127,"83a2eb55-b330-4e0c-8dc9-05e9466d5028":11.622354497354499,"9de43d04-c7fa-48a9-b092-67c2888745d4":10.121164021164022,"e4ee2d81-7629-4445-b4f3-55ef57bd42fd":9.235714285714288,"e877a51a-2c53-4362-ae62-5a0ad242ecf7":9.398809523809524},"topic":["rout","gpsr","network","topolog","wireless"],"groups":[{"authors":["Josh Broch","David A. Maltz","David B. Johnson","Yih-Chun Hu","Jorjeta G. Jetcheva"],"references":["0b93552e-74e8-483f-82cb-5c04e1cd9232","185dfc84-5463-4022-b36f-7e95073d5042","1b0d9aea-0256-494f-a570-f04715825bb1","60fb0dc2-bde3-4714-948e-de0ed12ab460","795ac717-1d24-4688-84c5-984d615cfcc6","83a2eb55-b330-4e0c-8dc9-05e9466d5028"],"_id":"7c9f8cd8-d0ef-4954-b4db-4a6c803459c2","abstract":"An ad hoc network is a collection of wireless mobile nodes dynamically forming a temporary network without the use of any existing network infrastructure or centralized administration. Due to the limited transmission range of wireless network interfaces, multiple network \"hops\" may be needed for one node to exchange data with another across the network. In recent years, a variety of new routing protocols targeted specifically at this environment have been developed, but little performance information on each protocol and no realistic performance comparison between them is available. This paper presents the results of a detailed packet-level simulation comparing four multi-hop wireless ad hoc network routing protocols that cover a range of design choices: DSDV, TORA, DSR, and AODV. We have extended the ns-2 network simulator to accurately model the MAC and physical-layer behavior of the IEEE 802.11 wireless LAN standard, including a realistic wireless transmission channel model, and present the results of simulations of networks of 50 mobile nodes.","title":"A performance comparison of multi-hop wireless ad hoc network routing protocols","venue":"acm ieee international conference on mobile computing and networking","year":1998,"__v":0,"citationCount":2035},{"authors":["Jinyang Li","John Jannotti","Douglas S. J. De Couto","David R. Karger","Robert Morris"],"references":["0d4d0363-07b5-43b6-976d-955e96044709","1545dfd3-2c25-4ff1-b43c-df4a2a501d06","39adcd6c-0b60-430c-99ab-21cd9e98b385","60fb0dc2-bde3-4714-948e-de0ed12ab460","6eff83a4-db80-40ea-8c9f-8bda5f506c29","7c9f8cd8-d0ef-4954-b4db-4a6c803459c2","83a2eb55-b330-4e0c-8dc9-05e9466d5028","9de43d04-c7fa-48a9-b092-67c2888745d4","c7b0d60b-9956-4254-b6d3-26fb1f8782bb","e3af190a-754d-415d-a32d-f1d9999c599f","ff4259bb-5b84-4f51-b975-146794715d22"],"_id":"e4ee2d81-7629-4445-b4f3-55ef57bd42fd","abstract":"GLS is a new distributed location service which tracks mobile node locations. GLS combined with geographic forwarding allows the construction of ad hoc mobile networks that scale to a larger number of nodes than possible with previous work. GLS is decentralized and runs on the mobile nodes themselves, requiring no fixed infrastructure. Each mobile node periodically updates a small set of other nodes (its location servers) with its current location. A node sends its position updates to its location servers without knowing their actual identities, assisted by a predefined ordering of node identifiers and a predefined geographic hierarchy. Queries for a mobile node's location also use the predefined identifier ordering and spatial hierarchy to find a location server for that node.  Experiments using the  ns  simulator for up to 600 mobile nodes show that the storage and bandwidth requirements of GLS grow slowly with the size of the network. Furthermore, GLS tolerates node failures well: each failure has only a limited effect and query performance degrades gracefully as nodes fail and restart. The query performance of GLS is also relatively insensitive to node speeds. Simple geographic forwarding combined with GLS compares favorably with Dynamic Source Routing (DSR): in larger networks (over 200 nodes) our approach delivers more packets, but consumes fewer network resources.","title":"A scalable location service for geographic ad hoc routing","venue":"acm ieee international conference on mobile computing and networking","year":2000,"__v":0,"citationCount":786},{"authors":["David A. Maltz","Josh Broch","Jorjeta G. Jetcheva","David B. Johnson"],"references":["1b0d9aea-0256-494f-a570-f04715825bb1","60fb0dc2-bde3-4714-948e-de0ed12ab460","7c9f8cd8-d0ef-4954-b4db-4a6c803459c2","83a2eb55-b330-4e0c-8dc9-05e9466d5028"],"_id":"e877a51a-2c53-4362-ae62-5a0ad242ecf7","abstract":"A number of different routing protocols proposed for use in multihop wireless ad hoc networks are based in whole or in part on what can be described as on-demand behavior. By on-demand behavior, we mean approaches based only on reaction to the offered traffic being handled by the routing protocol. In this paper, we analyze the use of on-demand behavior in such protocols, focusing on its effect on the routing protocol's forwarding latency, overhead cost, and route caching correctness, drawing examples from detailed simulation of the dynamic source routing (DSR) protocol. We study the protocol's behavior and the changes introduced by variations on some of the mechanisms that make up the protocol, examining which mechanisms have the greatest impact and exploring the tradeoffs that exist between them.","title":"The effects of on-demand behavior in routing protocols for multihop wireless ad hoc networks","venue":"IEEE Journal on Selected Areas in Communications","year":1999,"__v":0,"citationCount":151}],"offsprings":["e1263ada-afda-498c-a37d-9b545293118a"]},"176a7436-78ea-4c2a-82e6-7930ab023bd1":{"authors":["Ross B. Girshick","Jeff Donahue","Trevor Darrell","Jitendra Malik"],"references":["2b6a3d0f-368f-45bb-be23-4e82f62fbbf7","83c737b8-e084-4766-ba6e-131e6a1c017c","ab3afb93-8ca0-4556-ae60-11199dc263c2","b944f77f-113b-4a02-ae5e-d4a124b8fd5b","dd83785a-dd19-41e3-9b25-ebabbd48d336","e2f7a74a-8430-4463-94ce-fe85dfd309f9","f2d49150-35de-4fd5-ac46-eb071d1cc73e"],"_id":"176a7436-78ea-4c2a-82e6-7930ab023bd1","abstract":"Object detection performance, as measured on the canonical PASCAL VOC dataset, has plateaued in the last few years. The best-performing methods are complex ensemble systems that typically combine multiple low-level image features with high-level context. In this paper, we propose a simple and scalable detection algorithm that improves mean average precision (mAP) by more than 30% relative to the previous best result on VOC 2012 -- achieving a mAP of 53.3%. Our approach combines two key insights: (1) one can apply high-capacity convolutional neural networks (CNNs) to bottom-up region proposals in order to localize and segment objects and (2) when labeled training data is scarce, supervised pre-training for an auxiliary task, followed by domain-specific fine-tuning, yields a significant performance boost. Since we combine region proposals with CNNs, we call our method R-CNN: Regions with CNN features. We also present experiments that provide insight into what the network learns, revealing a rich hierarchy of image features. Source code for the complete system is available at http://www.cs.berkeley.edu/~rbg/rcnn.","title":"Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation","venue":"computer vision and pattern recognition","year":2014,"__v":0,"citationCount":1815,"parents":{"0105e97e-ef22-402e-8ba6-5de027d57dbe":10.81081081081081,"1bbaae78-1bb8-4184-b01c-4216e6879c56":21.62162162162162,"2b6a3d0f-368f-45bb-be23-4e82f62fbbf7":2.7027027027027026,"2f4bbdb0-55cc-48e9-a986-71fc20a69a5c":8.108108108108109,"30d96b63-ab8b-4a93-904d-65e87ba32327":16.216216216216218,"3609ce2c-c21e-4e94-a17e-de31443ecb90":21.62162162162162,"414732f4-8fd6-4fdb-9039-553367150535":16.216216216216218,"493f502b-b1b8-412c-95fd-3c1103480f1d":40.54054054054054,"589efc91-a3df-4c70-a613-67f249d7b33f":8.108108108108109,"6e1c18af-5c7f-4915-a611-702a3d4b9c53":5.405405405405405,"725ff5fd-76fe-41b4-b50d-00405a51ac27":2.7027027027027026,"73dbdf1f-da95-4b8c-9109-c966e08c6f13":16.216216216216218,"83c737b8-e084-4766-ba6e-131e6a1c017c":5.405405405405405,"86c0687e-74fb-44b1-a467-7f469a1486b9":5.405405405405405,"95f28b74-9e22-4dc0-8acc-9cdf7e716b61":2.7027027027027026,"983a2eff-22fe-40d2-bb87-fea35e63db6c":0,"9be390e8-c4e6-41a2-b9b2-74de449f0768":10.81081081081081,"9d24b0a5-fc3e-486e-9706-da560154b63c":2.7027027027027026,"a0a69af2-8b51-455e-bbac-a1aa5b24bd8b":10.81081081081081,"a13418d7-3585-4888-a027-85e441bfd354":5.405405405405405,"a4382b8f-f7fd-4d84-93ba-04c068c9abf0":10.81081081081081,"ab3afb93-8ca0-4556-ae60-11199dc263c2":0,"ae3e7593-586f-495f-9416-4b50ed1fcd10":0,"b916e575-9eba-4989-ad10-00b615e358a6":18.91891891891892,"b944f77f-113b-4a02-ae5e-d4a124b8fd5b":0,"c7def717-ad62-4168-9ae3-5484a67399c1":8.108108108108109,"c812244d-0de8-4e3c-8133-1e834bc9dbd0":21.62162162162162,"d5e5a24d-f80e-4f1a-b48b-22403b653276":0,"d6e37fb1-5f7e-448e-847b-7d1f1271c574":2.7027027027027026,"daa22c50-e3a3-42f0-85b5-4cad99989511":18.91891891891892,"dd83785a-dd19-41e3-9b25-ebabbd48d336":2.7027027027027026,"e016d598-1090-4b61-98ab-f47c8650dfa7":8.108108108108109,"e2f7a74a-8430-4463-94ce-fe85dfd309f9":2.7027027027027026,"e407acd7-dfcf-4ee8-9140-6726c01abf4e":5.405405405405405,"e7f6e82d-380c-427b-98bc-5c79471a7336":18.91891891891892,"f1639cc6-356f-4170-9dea-9be79c84f899":16.216216216216218,"f2d49150-35de-4fd5-ac46-eb071d1cc73e":10.81081081081081},"keyword":{"0105e97e-ef22-402e-8ba6-5de027d57dbe":10.89126984126984,"1bbaae78-1bb8-4184-b01c-4216e6879c56":9.252380952380951,"2b6a3d0f-368f-45bb-be23-4e82f62fbbf7":8.155555555555555,"2f4bbdb0-55cc-48e9-a986-71fc20a69a5c":9.658333333333331,"30d96b63-ab8b-4a93-904d-65e87ba32327":9.833333333333332,"3609ce2c-c21e-4e94-a17e-de31443ecb90":10.396825396825395,"414732f4-8fd6-4fdb-9039-553367150535":10.02738095238095,"493f502b-b1b8-412c-95fd-3c1103480f1d":10.382407407407404,"589efc91-a3df-4c70-a613-67f249d7b33f":5.687777777777777,"6e1c18af-5c7f-4915-a611-702a3d4b9c53":9.675,"725ff5fd-76fe-41b4-b50d-00405a51ac27":8.854444444444445,"73dbdf1f-da95-4b8c-9109-c966e08c6f13":10.360317460317459,"83c737b8-e084-4766-ba6e-131e6a1c017c":8.80952380952381,"86c0687e-74fb-44b1-a467-7f469a1486b9":6.28015873015873,"95f28b74-9e22-4dc0-8acc-9cdf7e716b61":11.206349206349207,"983a2eff-22fe-40d2-bb87-fea35e63db6c":9.127777777777778,"9be390e8-c4e6-41a2-b9b2-74de449f0768":8.387698412698413,"9d24b0a5-fc3e-486e-9706-da560154b63c":7.467936507936507,"a0a69af2-8b51-455e-bbac-a1aa5b24bd8b":9.116269841269842,"a13418d7-3585-4888-a027-85e441bfd354":8.383333333333333,"a4382b8f-f7fd-4d84-93ba-04c068c9abf0":11.442063492063491,"ab3afb93-8ca0-4556-ae60-11199dc263c2":10.593650793650793,"ae3e7593-586f-495f-9416-4b50ed1fcd10":10.161825396825398,"b916e575-9eba-4989-ad10-00b615e358a6":7.4944444444444445,"b944f77f-113b-4a02-ae5e-d4a124b8fd5b":10.319444444444443,"c7def717-ad62-4168-9ae3-5484a67399c1":8.744444444444444,"c812244d-0de8-4e3c-8133-1e834bc9dbd0":8.43611111111111,"d5e5a24d-f80e-4f1a-b48b-22403b653276":10.797222222222222,"d6e37fb1-5f7e-448e-847b-7d1f1271c574":8.510714285714286,"daa22c50-e3a3-42f0-85b5-4cad99989511":10.275925925925925,"dd83785a-dd19-41e3-9b25-ebabbd48d336":8.777777777777777,"e016d598-1090-4b61-98ab-f47c8650dfa7":11.815555555555555,"e2f7a74a-8430-4463-94ce-fe85dfd309f9":9.488888888888889,"e407acd7-dfcf-4ee8-9140-6726c01abf4e":10.94888888888889,"e7f6e82d-380c-427b-98bc-5c79471a7336":13.072222222222221,"f1639cc6-356f-4170-9dea-9be79c84f899":11.269444444444442,"f2d49150-35de-4fd5-ac46-eb071d1cc73e":7.3},"topic":["region","propos","featur","combin","voc"],"groups":[{"authors":["Pablo Arbelaez","Jordi Pont-Tuset","Jonathan T. Barron","Ferran Marques","Jitendra Malik"],"references":["0105e97e-ef22-402e-8ba6-5de027d57dbe","1bbaae78-1bb8-4184-b01c-4216e6879c56","2b2dcade-5be5-4835-9c91-99b4f46aaee9","2c9215ba-a81e-4b11-b9fd-4e8976d87dbe","309f11f3-0575-4787-9f2d-d3888c5db5b1","31aebe02-5e72-4641-985c-1ad6e1dcfa49","414732f4-8fd6-4fdb-9039-553367150535","416bd4e9-b3ed-40f1-804a-ac926263d2e9","45beeef2-a57d-436d-8fc4-56136234b4b9","50deb9e0-e10b-40bd-a73f-c544285457e3","50deff86-c636-47d7-8c7b-526b536d428c","5986f96a-d1de-442d-9208-0bfbcde00b5a","708441ca-fc5d-41ca-8ab2-c7b705d451b9","7175bcf0-a1a7-44e5-b19a-854d026f05e1","7c53900b-0697-4120-8ea0-5fe8c4ada02f","8b8a2247-bd77-4736-b493-449734f56b9a","8c1a48b4-5ff9-4f68-8f30-403c26c130de","946b3ff3-1c0a-4c01-8f59-603ddf36d46e","a0a69af2-8b51-455e-bbac-a1aa5b24bd8b","c7def717-ad62-4168-9ae3-5484a67399c1","dd83785a-dd19-41e3-9b25-ebabbd48d336","e39211aa-1fef-4962-a561-02072ae48c68","e7f6e82d-380c-427b-98bc-5c79471a7336","e81865db-d005-4891-9263-45e7f34ab15a","f2215507-db87-4b3b-bf11-b3f3e78c2205","f2d49150-35de-4fd5-ac46-eb071d1cc73e"],"_id":"3609ce2c-c21e-4e94-a17e-de31443ecb90","abstract":"We propose a unified approach for bottom-up hierarchical image segmentation and object candidate generation for recognition, called Multiscale Combinatorial Grouping (MCG). For this purpose, we first develop a fast normalized cuts algorithm. We then propose a high-performance hierarchical segmenter that makes effective use of multiscale information. Finally, we propose a grouping strategy that combines our multiscale regions into highly-accurate object candidates by exploring efficiently their combinatorial space. We conduct extensive experiments on both the BSDS500 and on the PASCAL 2012 segmentation datasets, showing that MCG produces state-of-the-art contours, hierarchical regions and object candidates.","title":"Multiscale Combinatorial Grouping","venue":"computer vision and pattern recognition","year":2014,"__v":0,"citationCount":263},{"authors":["Olga Russakovsky","Jia Deng","Hao Su","Jonathan Krause","Sanjeev Satheesh","Sean Ma","Zhiheng Huang","Andrej Karpathy","Aditya Khosla","Michael S. Bernstein","Alexander C. Berg","Li Fei-Fei"],"references":["04c47f14-8533-41ff-bafd-affc1eb52287","051956bb-f64b-4fdb-87f8-3e2868b8b5d8","0b661216-1fcc-4a13-94ee-62958f986647","0cfe22b1-6883-4df2-ab04-7c94e9486b8f","0fb0a842-cb06-4b37-9738-a4d18a55ec23","1182c719-2ae0-49e4-ad7d-9baf94a5dc88","12f40b38-cd99-4801-8074-d765a29a2101","153c5014-dc7a-44a8-a93f-5cd27f1193df","176a7436-78ea-4c2a-82e6-7930ab023bd1","1fe06ec6-c5cb-4800-ba8f-4ea907fcba06","2398c5fc-8288-4fbd-8cc2-eff409812cb1","26316adf-569e-49bc-a289-c1ba311624f6","28414617-6b1f-4b81-8293-3109278684b1","2b6a3d0f-368f-45bb-be23-4e82f62fbbf7","2d94566b-ac2d-49b0-a867-2392c41a2172","2d9c1391-7c29-4b74-9c05-d45afeb103bb","2dfe0de0-38b2-4c0f-bea9-875c171eb328","2ead02c2-afd0-48df-947c-94f737aa8c1f","2f4bbdb0-55cc-48e9-a986-71fc20a69a5c","309f11f3-0575-4787-9f2d-d3888c5db5b1","30d96b63-ab8b-4a93-904d-65e87ba32327","32a53bab-1ede-4869-98ad-d2ff0c1e3367","3609ce2c-c21e-4e94-a17e-de31443ecb90","3b23400e-aa6d-4ee3-b17c-82c04d98d157","40e36f49-9f2f-4586-8899-a282fdd320d1","42b60ea2-1759-4fbd-9530-d3f2fa90f534","49b925b3-f7d8-4904-aa89-eebd5c80f287","4f8a4fdb-7ab9-454e-981d-b2b016613ac1","5700170c-68b7-48ce-8194-2daa5444b380","589efc91-a3df-4c70-a613-67f249d7b33f","5b8cd8f4-17c9-4ac3-ba05-ebeba7cd6691","654b9e17-96df-4227-bc81-f97e1ddda6d6","69a0f5ae-94ec-4c61-ad1c-d10057415b88","69a6a94a-6d69-404c-bf54-04a61ba3e6c0","69c13a6c-0e73-4603-a98c-6e04ebe04c5a","6a97a03d-7337-4f4a-a8db-714d81cff194","6cad2c4a-3568-42db-8c8d-cfd56105de0e","6d324aa1-fcc4-4808-ae21-472982517e5e","7cdd68ef-876b-4214-bd85-38dd01ac99c9","826bd128-4189-4e04-8e8d-d2ebfd68c432","837e056f-ea71-4be1-bde0-e3166cfee2fd","83c737b8-e084-4766-ba6e-131e6a1c017c","841394ee-e677-4024-8497-47bf880c6ab9","86b626a6-f948-45ea-8e92-8102e0dc5ef8","8a07711d-87a2-4929-9cb0-c3a3c05048ba","8db677a7-de9a-476b-ac75-169a962cf6cd","8ecbb404-d99e-4991-bde0-9caa49f8a3e8","8ee6231d-f5b8-41a2-b023-ae33f2c19535","95c111f4-55d0-455e-884a-4485ff03b494","97fa1c18-05bf-47c9-b72d-5d712b186ccd","983a2eff-22fe-40d2-bb87-fea35e63db6c","98801e79-fc9d-4c6a-a383-10e937c9d008","9f0be55e-7ea1-41b1-bb8d-c3822ead7fd8","a13418d7-3585-4888-a027-85e441bfd354","a698b4ae-145f-43d4-89be-e96321ce3850","a6ee5009-aebc-4cda-8ef9-d855297b949c","ab3afb93-8ca0-4556-ae60-11199dc263c2","ac5e3fe4-3b1d-412d-a03b-3247d39f62d5","accb8a46-f471-42e7-a776-4894ae8fe3fd","adea0a98-d74d-43be-a238-a1ef027c6a58","b1f03fb2-d9d9-4016-8596-29cc8c2800a5","b32a4dff-4928-4049-b545-1b20344ddb5b","b3e241a6-126f-40fb-a063-8ed7d0223a3c","b944f77f-113b-4a02-ae5e-d4a124b8fd5b","b9632516-3e2e-4cf7-a6d8-43f317d43488","bc39fa8d-788a-4ae6-9755-4cf59ecee2a5","c7def717-ad62-4168-9ae3-5484a67399c1","c812244d-0de8-4e3c-8133-1e834bc9dbd0","c9482f1f-6600-44a7-a69a-e63ef13cdff8","cb6dc6ec-fca0-4abe-a786-89c8aa42008c","d14a35f9-0443-4c4c-b53c-3cae7a27555d","e0296c28-35a4-41c1-9fd2-58e75d4819be","e0ac4812-7729-4a2d-8a1f-74b1b7c8eb5d","e2f7a74a-8430-4463-94ce-fe85dfd309f9","e3a5cec9-7e82-4c14-86ab-0d95a92712a7","e81dc85c-98d3-408c-9dee-6d43fa5b8911","f1639cc6-356f-4170-9dea-9be79c84f899","f2d49150-35de-4fd5-ac46-eb071d1cc73e","fbdfc1ca-09ef-47f8-a0d1-adaf626a8562"],"_id":"493f502b-b1b8-412c-95fd-3c1103480f1d","abstract":"The ImageNet Large Scale Visual Recognition Challenge is a benchmark in object category classification and detection on hundreds of object categories and millions of images. The challenge has been run annually from 2010 to present, attracting participation from more than fifty institutions. This paper describes the creation of this benchmark dataset and the advances in object recognition that have been possible as a result. We discuss the challenges of collecting large-scale ground truth annotation, highlight key breakthroughs in categorical object recognition, provide a detailed analysis of the current state of the field of large-scale image classification and object detection, and compare the state-of-the-art computer vision accuracy with human accuracy. We conclude with lessons learned in the 5 years of the challenge, and propose future directions and improvements.","title":"ImageNet Large Scale Visual Recognition Challenge","venue":"International Journal of Computer Vision","year":2015,"__v":0,"citationCount":1457}],"offsprings":["c93eac1a-7d9a-48ab-9fb4-389c85bea00e","051956bb-f64b-4fdb-87f8-3e2868b8b5d8","153c5014-dc7a-44a8-a93f-5cd27f1193df"]},"17d28db6-642c-4b81-aec6-0bcbcf71858d":{"authors":["David M. Brooks","Vivek Tiwari","Margaret Martonosi"],"references":["84f38277-cf2e-4362-b807-4208af039806"],"_id":"17d28db6-642c-4b81-aec6-0bcbcf71858d","abstract":"Power dissipation and thermal issues are increasingly significant in modern processors. As a result, it is crucial that power/performance tradeoffs be made more visible to chip architects and even compiler writers, in addition to circuit designers. Most existing power analysis tools achieve high accuracy by calculating power estimates for designs only after layout or floorplanning are complete. In addition to being available only late in the design process, such tools are often quite slow, which compounds the difficulty of running them for a large space of design possibilities.  This paper presents Wattch, a framework for analyzing and optimizing microprocessor power dissipation at the architecture-level. Wattch is 1000X or more faster than existing layout-level power tools, and yet maintains accuracy within 10% of their estimates as verified using industry tools on leading-edge designs. This paper presents several validations of Wattch's accuracy. In addition, we present three examples that demonstrate how architects or compiler writers might use Wattch to evaluate power consumption in their design process.  We see Wattch as a complement to existing lower-level tools; it allows architects to explore and cull the design space early on, using faster, higher-level tools. It also opens up the field of power-efficient computing to a wider range of researchers by providing a power evaluation methodology within the portable and familiar SimpleScalar framework.","title":"Wattch: a framework for architectural-level power analysis and optimizations","venue":"international symposium on computer architecture","year":2000,"__v":0,"citationCount":1646,"parents":{"002fbac4-ac07-45ce-b743-f00ac828c55f":0,"0043d673-3e68-4c8c-b1ae-c3ea92ac96db":0,"040a2555-8add-43e5-bcbf-ad0b3b56302e":0,"0c386eec-c686-494d-b329-a37070b1adca":0,"17c580d6-6131-4751-a262-42210d9ae51e":0,"414d70e1-aaea-4497-b9d4-2be46c1a864e":0,"6032e07b-d786-46b3-b6bc-89e44862a141":15.789473684210526,"619effd9-6bbf-4622-87fc-14dcdeaddbc9":5.263157894736842,"84f38277-cf2e-4362-b807-4208af039806":0,"85ed4071-b83a-474f-8a0c-b430867e2d21":0,"8fd30c8a-6dec-4c5c-87ea-ce9c152b428f":5.263157894736842,"a1bb44a1-44bd-4715-89c5-a7f83f46ff20":0,"aecd6a0c-f860-4678-9345-d2daaeb6f998":0,"bfecf026-43f1-4882-ae26-6d4bd4c786ab":5.263157894736842,"c1487927-eec1-46d3-9da7-2a5ed174574e":21.052631578947366,"c45f9822-b379-41d4-9f07-e84705407f16":5.263157894736842,"dd29c43d-f466-41a0-aba6-acba78ef504e":0,"f64f7ca0-479a-4a6f-80cb-8ef3cc4b06df":0,"fd93d01d-d1a3-4b15-ae20-c9b7bbbedff4":0},"keyword":{"002fbac4-ac07-45ce-b743-f00ac828c55f":9.141825396825398,"0043d673-3e68-4c8c-b1ae-c3ea92ac96db":9.084047619047617,"040a2555-8add-43e5-bcbf-ad0b3b56302e":11.614325396825397,"0c386eec-c686-494d-b329-a37070b1adca":0,"17c580d6-6131-4751-a262-42210d9ae51e":9.19063492063492,"414d70e1-aaea-4497-b9d4-2be46c1a864e":9.774338624338625,"6032e07b-d786-46b3-b6bc-89e44862a141":10.722619047619048,"619effd9-6bbf-4622-87fc-14dcdeaddbc9":9.670238095238096,"84f38277-cf2e-4362-b807-4208af039806":9.053174603174602,"85ed4071-b83a-474f-8a0c-b430867e2d21":8.086706349206349,"8fd30c8a-6dec-4c5c-87ea-ce9c152b428f":10.046230158730161,"a1bb44a1-44bd-4715-89c5-a7f83f46ff20":10.955714285714286,"aecd6a0c-f860-4678-9345-d2daaeb6f998":9.610728715728715,"bfecf026-43f1-4882-ae26-6d4bd4c786ab":10.308015873015874,"c1487927-eec1-46d3-9da7-2a5ed174574e":8.22206349206349,"c45f9822-b379-41d4-9f07-e84705407f16":9.050198412698412,"dd29c43d-f466-41a0-aba6-acba78ef504e":10.427222222222223,"f64f7ca0-479a-4a6f-80cb-8ef3cc4b06df":9.918452380952381,"fd93d01d-d1a3-4b15-ae20-c9b7bbbedff4":11.046349206349207},"topic":["power","design","tool","wattch","present"],"offsprings":[]},"1c7ddbd7-046a-4333-aa6b-c4ce698d6fad":{"authors":["Phan Minh Dung"],"references":[],"_id":"1c7ddbd7-046a-4333-aa6b-c4ce698d6fad","abstract":"The purpose of this paper is to study the fundamental mechanism, humans use in argumentation, and to explore ways to implement this mechanism on computers. We do so by first developing a theory for argumentation whose central notion is the acceptability of arguments. Then we argue for the “correctness” or “appropriateness” of our theory with two strong arguments. The first one shows that most of the major approaches to nonmonotonic reasoning in AI and logic programming are special forms of our theory of argumentation. The second argument illustrates how our theory can be used to investigate the logical structure of many practical problems. This argument is based on a result showing that our theory captures naturally the solutions of the theory of n-person games and of the well-known stable marriage problem. By showing that argumentation can be viewed as a special form of logic programming with negation as failure, we introduce a general logic-programming-based method for generating meta-interpreters for argumentation systems, a method very much similar to the compiler-compiler idea in conventional programming. Keyword: Argumentation; Nonmonotonic reasoning; Logic programming; n-person games; The stable marriage problem","title":"On the acceptability of arguments and its fundamental role in nonmonotonic reasoning, logic programming and n -person games","venue":"Artificial Intelligence","year":1995,"__v":0,"citationCount":1614,"parents":{"05f122c1-187e-4c72-b26e-4c3f2102a594":0,"05f59ebe-6fcf-435e-ad81-a13583c94c23":0,"09c344d2-f9cc-435c-80eb-999bddc32c7d":0,"153758bf-f8b0-4a5a-b4e2-ca2e3db564bf":0,"1c7e166d-94cb-4cdd-b23b-1fd26029ff3d":2.941176470588235,"1fdfbd1c-28c7-445d-9144-3bbd8a843f3b":0,"29a91d8a-fa15-4e14-8cb6-e069a252f755":0,"349b4cb0-7d84-4aa8-bd0c-055804f8db1f":0,"40a47468-7202-4911-a033-790b444f122c":0,"4d3d2f23-d40c-4e3a-a5d5-9c063d358cc0":2.941176470588235,"4d996c8b-b144-410a-a8c5-97e6ec25b289":0,"52f66d82-d2e9-46a4-8ef7-4358eb793a08":47.05882352941176,"57206df8-7b58-47ef-ae53-92f89db91a50":0,"5a568ce9-f7db-4f4c-a604-094cb719e5b4":2.941176470588235,"64c42a22-cee2-4a54-8e37-5b9380f3749b":2.941176470588235,"64ede27f-fa06-4572-9dc9-a86abacebeef":5.88235294117647,"6dcf9f47-7a83-40b6-890b-9f6bc8585986":5.88235294117647,"6dfd9077-2f59-4692-9fcc-f9e336591a15":0,"77bcbb3a-6ecb-41e5-8273-56fd75c66bbc":8.823529411764707,"78ceaf4a-8ebb-4f2e-b557-0fa445232572":5.88235294117647,"82abd140-4f16-48ba-8d35-0bbcdbd20141":2.941176470588235,"aec58e43-19ed-4496-b80f-7821ce5255db":2.941176470588235,"aee0bb9b-8576-494a-8c4c-af95e4268523":8.823529411764707,"afb35256-839c-474b-8aad-6c90880f9710":5.88235294117647,"c93b2858-ec9f-412b-b6f5-a14eff5de224":2.941176470588235,"c9e8d201-dd9d-4625-9d2c-c366c2413670":5.88235294117647,"ce5d4dd0-6a64-4f54-9a9a-2be92ef81861":8.823529411764707,"d988d6a6-240b-4641-a608-e2105d5dca33":5.88235294117647,"e22908da-10e5-49ec-93ed-2d7b1e1e8da3":0,"e2868c1e-86b7-48ed-941d-8bc430b013c3":0,"e5394fb6-2d09-4aee-943b-90895b4c6d9b":0,"f37f8fa1-8738-4eb5-adfd-25153d9950fb":0,"f77839ad-f2b4-4e46-a4bd-930c5780f9cb":0,"fb28f8b5-a42e-4738-a74a-03d05975f031":14.705882352941178},"keyword":{"05f122c1-187e-4c72-b26e-4c3f2102a594":7.715873015873016,"05f59ebe-6fcf-435e-ad81-a13583c94c23":12.668722943722942,"09c344d2-f9cc-435c-80eb-999bddc32c7d":9.343915343915345,"153758bf-f8b0-4a5a-b4e2-ca2e3db564bf":0,"1c7e166d-94cb-4cdd-b23b-1fd26029ff3d":10.176785714285716,"1fdfbd1c-28c7-445d-9144-3bbd8a843f3b":0,"29a91d8a-fa15-4e14-8cb6-e069a252f755":0,"349b4cb0-7d84-4aa8-bd0c-055804f8db1f":11.39623015873016,"40a47468-7202-4911-a033-790b444f122c":0,"4d3d2f23-d40c-4e3a-a5d5-9c063d358cc0":8.731904761904762,"4d996c8b-b144-410a-a8c5-97e6ec25b289":0,"52f66d82-d2e9-46a4-8ef7-4358eb793a08":13.172619047619046,"57206df8-7b58-47ef-ae53-92f89db91a50":0,"5a568ce9-f7db-4f4c-a604-094cb719e5b4":11.057142857142859,"64c42a22-cee2-4a54-8e37-5b9380f3749b":0,"64ede27f-fa06-4572-9dc9-a86abacebeef":10.898412698412697,"6dcf9f47-7a83-40b6-890b-9f6bc8585986":10.678650793650792,"6dfd9077-2f59-4692-9fcc-f9e336591a15":11.73035714285714,"77bcbb3a-6ecb-41e5-8273-56fd75c66bbc":10.542539682539683,"78ceaf4a-8ebb-4f2e-b557-0fa445232572":9.91984126984127,"82abd140-4f16-48ba-8d35-0bbcdbd20141":9.898809523809524,"aec58e43-19ed-4496-b80f-7821ce5255db":0,"aee0bb9b-8576-494a-8c4c-af95e4268523":8.07579365079365,"afb35256-839c-474b-8aad-6c90880f9710":0,"c93b2858-ec9f-412b-b6f5-a14eff5de224":12.10364357864358,"c9e8d201-dd9d-4625-9d2c-c366c2413670":10.503968253968255,"ce5d4dd0-6a64-4f54-9a9a-2be92ef81861":11.104576719576722,"d988d6a6-240b-4641-a608-e2105d5dca33":0,"e22908da-10e5-49ec-93ed-2d7b1e1e8da3":0,"e2868c1e-86b7-48ed-941d-8bc430b013c3":11.276719576719575,"e5394fb6-2d09-4aee-943b-90895b4c6d9b":10.27202380952381,"f37f8fa1-8738-4eb5-adfd-25153d9950fb":0,"f77839ad-f2b4-4e46-a4bd-930c5780f9cb":0,"fb28f8b5-a42e-4738-a74a-03d05975f031":12.125343915343915},"topic":["argument","theori","show","program","logic"],"groups":[{"authors":["Phan Minh Dung"],"references":["05f59ebe-6fcf-435e-ad81-a13583c94c23","153758bf-f8b0-4a5a-b4e2-ca2e3db564bf","1c7e166d-94cb-4cdd-b23b-1fd26029ff3d","2da2445c-da6e-4a0a-83b9-d857e06dc853","2fb3c8db-7934-409e-bc40-38d5caf78319","4062fafd-7b5e-4c5c-8e81-8ff891ac334f","64c42a22-cee2-4a54-8e37-5b9380f3749b","64ede27f-fa06-4572-9dc9-a86abacebeef","aec58e43-19ed-4496-b80f-7821ce5255db","aee0bb9b-8576-494a-8c4c-af95e4268523","afb35256-839c-474b-8aad-6c90880f9710","b19e5079-3587-4039-8b40-6b8b6a175763","c9e8d201-dd9d-4625-9d2c-c366c2413670","ce5d4dd0-6a64-4f54-9a9a-2be92ef81861","d988d6a6-240b-4641-a608-e2105d5dca33","e22908da-10e5-49ec-93ed-2d7b1e1e8da3","e2868c1e-86b7-48ed-941d-8bc430b013c3","e5394fb6-2d09-4aee-943b-90895b4c6d9b","f37f8fa1-8738-4eb5-adfd-25153d9950fb","fb28f8b5-a42e-4738-a74a-03d05975f031"],"_id":"52f66d82-d2e9-46a4-8ef7-4358eb793a08","abstract":"The purpose of this paper is to study the fundamental mechanism humans use in argumentation and its role in different major approaches to commonsense reasoning in AI and logic programming. We present three novel results: We develop a theory for argumentation in which the acceptability of arguments is precisely defined. We show that logic programming and nonmonotonic reasoning in AI are different forms of argumentation. We show that argumentation can be viewed as a special form of logic programming with negation as failure.#R##N##R##N#This result introduces a general method for generating metainterpreters for argumentation systems.","title":"On the acceptability of arguments and its fundamental role in nonmonotonic reasoning and logic programming","venue":"international joint conference on artificial intelligence","year":1993,"__v":0,"citationCount":40}],"offsprings":[]},"1ee4b656-7d2c-45e8-b2e8-b5633b992eeb":{"authors":["Wendi B. Heinzelman","Anantha P. Chandrakasan","Hari Balakrishnan"],"references":["23dd7fc0-1ebd-43ce-ab3e-43896512c209","afc06b7c-7fb3-4f88-942b-3076ed77920e"],"_id":"1ee4b656-7d2c-45e8-b2e8-b5633b992eeb","abstract":"Networking together hundreds or thousands of cheap microsensor nodes allows users to accurately monitor a remote environment by intelligently combining the data from the individual nodes. These networks require robust wireless communication protocols that are energy efficient and provide low latency. We develop and analyze low-energy adaptive clustering hierarchy (LEACH), a protocol architecture for microsensor networks that combines the ideas of energy-efficient cluster-based routing and media access together with application-specific data aggregation to achieve good performance in terms of system lifetime, latency, and application-perceived quality. LEACH includes a new, distributed cluster formation technique that enables self-organization of large numbers of nodes, algorithms for adapting clusters and rotating cluster head positions to evenly distribute the energy load among all the nodes, and techniques to enable distributed signal processing to save communication resources. Our results show that LEACH can improve system lifetime by an order of magnitude compared with general-purpose multihop approaches.","title":"An application-specific protocol architecture for wireless microsensor networks","venue":"IEEE Transactions on Wireless Communications","year":2002,"__v":0,"citationCount":2562,"parents":{"1081ae4c-2a85-4b47-a903-b5518ee62334":18.181818181818183,"23dd7fc0-1ebd-43ce-ab3e-43896512c209":9.090909090909092,"282f60bc-e000-420c-b8f7-6d52d645e2b9":0,"38b10094-82ce-4476-8845-d4e8d027942a":0,"38f54b84-5272-43df-8cde-a3e755b17dee":0,"55a6413a-4a9c-4e8d-957b-8c1a4e5d5f0b":0,"7845a1ac-4941-4d61-b361-a70ddab88fb7":0,"9dc99b87-9617-4871-94d8-d44eb595db13":0,"9e063b41-0ada-4db8-8846-6e5153a0de55":9.090909090909092,"afc06b7c-7fb3-4f88-942b-3076ed77920e":9.090909090909092,"e2baa34c-eba8-45fc-ac64-693761c9680b":0},"keyword":{"1081ae4c-2a85-4b47-a903-b5518ee62334":11.768783068783069,"23dd7fc0-1ebd-43ce-ab3e-43896512c209":11.734788359788363,"282f60bc-e000-420c-b8f7-6d52d645e2b9":11.615079365079367,"38b10094-82ce-4476-8845-d4e8d027942a":11.48386243386243,"38f54b84-5272-43df-8cde-a3e755b17dee":0,"55a6413a-4a9c-4e8d-957b-8c1a4e5d5f0b":0,"7845a1ac-4941-4d61-b361-a70ddab88fb7":10.269576719576719,"9dc99b87-9617-4871-94d8-d44eb595db13":11.236556036556037,"9e063b41-0ada-4db8-8846-6e5153a0de55":0,"afc06b7c-7fb3-4f88-942b-3076ed77920e":11.896296296296297,"e2baa34c-eba8-45fc-ac64-693761c9680b":13.16697931697932},"topic":["node","cluster","network","leach","distribut"],"offsprings":[]},"1f520d1a-5870-477d-85d7-0f50be690ea7":{"authors":["Daniel Scharstein","Richard Szeliski","Ramin Zabih"],"references":["3a8fbc53-3805-4e6f-9f45-6881b640eb5e","f0887f29-b2e1-4971-a369-4df8b83b8996"],"_id":"1f520d1a-5870-477d-85d7-0f50be690ea7","abstract":"Stereo matching is one of the most active research areas in computer vision. While a large number of algorithms for stereo correspondence have been developed, relatively little work has been done on characterizing their performance. In this paper, we present a taxonomy of dense, two-frame stereo methods designed to assess the different components and design decisions made in individual stereo algorithms. Using this taxonomy, we compare existing stereo methods and present experiments evaluating the performance of many different variants. In order to establish a common software platform and a collection of data sets for easy evaluation, we have designed a stand-alone, flexible C++ implementation that enables the evaluation of individual components and that can be easily extended to include new algorithms. We have also produced several new multiframe stereo data sets with ground truth, and are making both the code and data sets available on the Web.","title":"A taxonomy and evaluation of dense two-frame stereo correspondence algorithms","venue":"International Journal of Computer Vision","year":2001,"__v":0,"citationCount":2529,"parents":{"0047b2cf-bd19-4f8a-979e-ef5cc5b4a43f":1.1494252873563218,"004aa844-c144-4f34-b328-e054848d2c82":5.747126436781609,"019da994-fd26-4a39-a1a5-f6e52a18933a":4.597701149425287,"07c8a80e-0892-408f-9e56-4e77d9441a64":4.597701149425287,"0c3cac6b-305e-4f1c-8ab8-72c6a3a551fe":8.045977011494253,"0f9cfb03-c1f3-4a60-886e-08b07d5e005c":1.1494252873563218,"11666f79-0a9d-49a3-b327-d194e202c94f":4.597701149425287,"15a2345f-3667-4fde-b64e-30471b6ae9ee":1.1494252873563218,"16ccd666-4632-42fa-9e92-8cd740177e6b":6.896551724137931,"1b5dfcf4-8c22-4438-901c-5bed88fdda29":3.4482758620689653,"1c09ef91-f69a-43e4-aaa7-571f3a143ea9":2.2988505747126435,"1c9d9c56-5ae9-4d13-a4b2-9c0833676f70":3.4482758620689653,"200c1972-9f6c-4e1b-9dbe-a1d29c7641cb":21.839080459770116,"239a71ea-70f9-450c-9b3c-658faab40d9d":6.896551724137931,"25b0c9f9-0c8a-4f2a-b075-90d339b6faa3":0,"2bb7edd0-987a-4b75-916f-957764d7d0e0":4.597701149425287,"32148a0b-6ce4-4a1e-a1d2-98a96b27b24f":1.1494252873563218,"37e76afb-f79f-41f8-b75d-28dadd7d5cd7":1.1494252873563218,"3a8fbc53-3805-4e6f-9f45-6881b640eb5e":5.747126436781609,"3b1b6ffe-75aa-45d1-9f3e-dadd4479a272":10.344827586206897,"3f4cc95c-5f47-4031-8671-e23ff4fe2ed2":0,"4383b14b-805b-43d4-84a3-b70181605b18":4.597701149425287,"45ef6717-ea63-4be0-bb43-26747479ccbb":19.54022988505747,"48e25c19-07a0-46c9-a659-e76db6e72d74":11.494252873563218,"4d6cc0b7-557d-4594-8bc8-ab1ce0ac251e":20.689655172413794,"54b8ad0d-2246-4650-a09b-5f5b9705e0e6":0,"558f4de5-92d8-4e29-a667-3159dd43262a":11.494252873563218,"55df9539-92c1-4080-b4b6-154771405001":0,"598627d0-d01d-4398-a45e-1440d21fe4f2":5.747126436781609,"5be0f6b3-82ef-4371-99eb-f72853a7e1f3":0,"62aa6ba4-1331-4c57-99f5-978d580c9573":3.4482758620689653,"6c9927be-dd3f-4a48-8ed6-b969a66e5c91":9.195402298850574,"6e0d7a60-4787-4348-84a5-5b94664a5777":1.1494252873563218,"70d6f58b-91bb-4c01-9f18-e62dc01d087d":4.597701149425287,"712f3c82-078f-42a8-9f90-da62b4175b17":6.896551724137931,"76845b3d-e45f-443c-a181-b1b75f17d47b":17.24137931034483,"7781665f-ef39-4237-9857-63477d05f5ac":0,"78bbab5f-b63b-40cc-9c8a-2c146191d833":13.793103448275861,"7e130624-dee1-4b3d-bd66-c6febab5a5a0":0,"7e598ce4-7739-42dd-8761-eb8984ed2b19":2.2988505747126435,"850e99fb-725d-4f54-8e01-4791bfffb283":5.747126436781609,"85471950-c85d-4494-ac99-30b5450ad095":5.747126436781609,"8a4274f4-8925-4724-aca5-4f9c3455dc3e":5.747126436781609,"8f4f3015-c03d-46e1-90fb-2c42ea2cb91f":3.4482758620689653,"900c927f-8e6e-4290-8eac-63fef682460d":8.045977011494253,"90483bd3-a6a7-4799-93cf-af14e991335c":1.1494252873563218,"936e0ae4-e6e1-4b3b-9d0a-a6bff589fc7b":0,"942ceea1-92aa-4e72-94a7-bb65bb5889ed":4.597701149425287,"94acc1d1-4b4e-4796-9b58-8cf91b031e7e":12.643678160919542,"97fcbcf5-3e50-4d78-bbe3-18660872b887":4.597701149425287,"a36cd635-6811-4a18-a424-46fd4719ae31":0,"a57c6dbb-09d2-4c2e-86ba-02e47e78f5af":19.54022988505747,"a7da5f11-1302-4305-a67a-9503dea05eb7":1.1494252873563218,"a872c04a-47c6-4f4b-b0b9-3afbaa3538cf":5.747126436781609,"a8eade43-4ee6-4165-a08e-c92d0d748343":0,"b00ef6b5-66d3-480a-ae96-03c3ddf2e26e":2.2988505747126435,"b1139559-cdb8-4b39-b8a1-f2125166a223":5.747126436781609,"b1c2251e-7b54-41e5-8130-10d9646e02da":9.195402298850574,"b2ced9a5-3457-48b8-8d4c-66badd866d75":4.597701149425287,"bb138fb8-d3a9-497a-879d-b21aa7347b53":18.39080459770115,"be0f6fa3-438a-4d3e-b809-2a31857642fd":2.2988505747126435,"be7fa5a9-6fc4-4aea-8e18-6c206ab42d14":6.896551724137931,"bfeeb55f-4b90-4886-aa57-817ba8de7988":0,"c258aec7-ba1b-4228-b47b-a0900a1bcfe2":0,"c3ec3b14-75be-4b18-af66-195537226585":0,"c6977873-accf-4edd-a522-ad649fc8295a":1.1494252873563218,"c7423207-f332-480d-b5d1-7e96279e574c":3.4482758620689653,"cae374ce-5b99-482e-950a-0b9e304eb498":13.793103448275861,"d1538940-ff7f-4b82-9f1d-8972c0bdb4ef":17.24137931034483,"d46a67de-c591-4872-a836-47165538b63c":0,"d6edad4f-53c7-4a29-b484-05872a3cc82a":1.1494252873563218,"d8229968-5440-4e12-ae6e-d7ba4f8eb389":4.597701149425287,"df847368-a372-4190-aac2-98c4bb9d0ddb":1.1494252873563218,"e8a7d5ab-2a86-4f90-a193-c62c686d5ea7":0,"e927dff1-6ed4-45fd-8852-eb804e11e665":2.2988505747126435,"e9939b8b-6fcb-4ded-ac64-43c7fdfb52d6":0,"f0887f29-b2e1-4971-a369-4df8b83b8996":0,"f27cb993-16cd-44f9-b0c8-6bbeb3ecf297":5.747126436781609,"f37628db-beac-4a64-ab7b-cd0ce4f943a9":10.344827586206897,"f3868715-abb3-4115-b57b-dc6d874f02d1":4.597701149425287,"f39486db-a4d9-49b4-a659-44c63900a7d5":0,"f45d6bd0-f1a4-4f80-b6af-5e3b12bbac3a":1.1494252873563218,"f4d90d70-135a-4d1c-bd61-693a2bf04253":12.643678160919542,"f6326193-ef92-4e64-8a4e-7439f8692fa1":27.586206896551722,"f6706f16-c997-4b7f-a044-1d1a9f85dd51":10.344827586206897,"f7037864-4b92-437b-a90e-509d4ec350c8":3.4482758620689653,"fd99a7a7-0aa2-4607-91bd-975285af5ad1":1.1494252873563218},"keyword":{"0047b2cf-bd19-4f8a-979e-ef5cc5b4a43f":9.177777777777779,"004aa844-c144-4f34-b328-e054848d2c82":11.340370370370367,"019da994-fd26-4a39-a1a5-f6e52a18933a":10.941666666666668,"07c8a80e-0892-408f-9e56-4e77d9441a64":12.008888888888887,"0c3cac6b-305e-4f1c-8ab8-72c6a3a551fe":11.251161616161617,"0f9cfb03-c1f3-4a60-886e-08b07d5e005c":10.05544733044733,"11666f79-0a9d-49a3-b327-d194e202c94f":9.548888888888888,"15a2345f-3667-4fde-b64e-30471b6ae9ee":7.298148148148147,"16ccd666-4632-42fa-9e92-8cd740177e6b":8.125608465608465,"1b5dfcf4-8c22-4438-901c-5bed88fdda29":9.354285714285714,"1c09ef91-f69a-43e4-aaa7-571f3a143ea9":12.0547619047619,"1c9d9c56-5ae9-4d13-a4b2-9c0833676f70":8.496825396825397,"200c1972-9f6c-4e1b-9dbe-a1d29c7641cb":10.66388888888889,"239a71ea-70f9-450c-9b3c-658faab40d9d":9.113703703703703,"25b0c9f9-0c8a-4f2a-b075-90d339b6faa3":9.930952380952379,"2bb7edd0-987a-4b75-916f-957764d7d0e0":11.865555555555556,"32148a0b-6ce4-4a1e-a1d2-98a96b27b24f":9.287301587301586,"37e76afb-f79f-41f8-b75d-28dadd7d5cd7":12.29222222222222,"3a8fbc53-3805-4e6f-9f45-6881b640eb5e":10.149259259259257,"3b1b6ffe-75aa-45d1-9f3e-dadd4479a272":9.992592592592592,"3f4cc95c-5f47-4031-8671-e23ff4fe2ed2":0,"4383b14b-805b-43d4-84a3-b70181605b18":7.7664021164021175,"45ef6717-ea63-4be0-bb43-26747479ccbb":9.833703703703701,"48e25c19-07a0-46c9-a659-e76db6e72d74":8.222222222222221,"4d6cc0b7-557d-4594-8bc8-ab1ce0ac251e":11.585714285714284,"54b8ad0d-2246-4650-a09b-5f5b9705e0e6":11.827777777777776,"558f4de5-92d8-4e29-a667-3159dd43262a":10.009002849002849,"55df9539-92c1-4080-b4b6-154771405001":12.939246031746029,"598627d0-d01d-4398-a45e-1440d21fe4f2":11.941111111111109,"5be0f6b3-82ef-4371-99eb-f72853a7e1f3":8.666666666666666,"62aa6ba4-1331-4c57-99f5-978d580c9573":12.964365079365079,"6c9927be-dd3f-4a48-8ed6-b969a66e5c91":9.466666666666665,"6e0d7a60-4787-4348-84a5-5b94664a5777":8.500673400673401,"70d6f58b-91bb-4c01-9f18-e62dc01d087d":11.388095238095236,"712f3c82-078f-42a8-9f90-da62b4175b17":11.47063492063492,"76845b3d-e45f-443c-a181-b1b75f17d47b":11.837037037037035,"7781665f-ef39-4237-9857-63477d05f5ac":11.333333333333332,"78bbab5f-b63b-40cc-9c8a-2c146191d833":8.194871794871794,"7e130624-dee1-4b3d-bd66-c6febab5a5a0":8.04968253968254,"7e598ce4-7739-42dd-8761-eb8984ed2b19":0,"850e99fb-725d-4f54-8e01-4791bfffb283":9.517521367521367,"85471950-c85d-4494-ac99-30b5450ad095":8.565079365079367,"8a4274f4-8925-4724-aca5-4f9c3455dc3e":10.559444444444445,"8f4f3015-c03d-46e1-90fb-2c42ea2cb91f":11.598888888888887,"900c927f-8e6e-4290-8eac-63fef682460d":11.853703703703703,"90483bd3-a6a7-4799-93cf-af14e991335c":9.77222222222222,"936e0ae4-e6e1-4b3b-9d0a-a6bff589fc7b":12.764285714285712,"942ceea1-92aa-4e72-94a7-bb65bb5889ed":10.193333333333332,"94acc1d1-4b4e-4796-9b58-8cf91b031e7e":11.566666666666665,"97fcbcf5-3e50-4d78-bbe3-18660872b887":10.905555555555555,"a36cd635-6811-4a18-a424-46fd4719ae31":10.203306878306877,"a57c6dbb-09d2-4c2e-86ba-02e47e78f5af":11.02222222222222,"a7da5f11-1302-4305-a67a-9503dea05eb7":0,"a872c04a-47c6-4f4b-b0b9-3afbaa3538cf":12.316666666666665,"a8eade43-4ee6-4165-a08e-c92d0d748343":5.466666666666667,"b00ef6b5-66d3-480a-ae96-03c3ddf2e26e":6.810052910052911,"b1139559-cdb8-4b39-b8a1-f2125166a223":8.94838383838384,"b1c2251e-7b54-41e5-8130-10d9646e02da":10.993333333333332,"b2ced9a5-3457-48b8-8d4c-66badd866d75":8.016666666666667,"bb138fb8-d3a9-497a-879d-b21aa7347b53":9.318253968253968,"be0f6fa3-438a-4d3e-b809-2a31857642fd":9.989999999999998,"be7fa5a9-6fc4-4aea-8e18-6c206ab42d14":8.672857142857143,"bfeeb55f-4b90-4886-aa57-817ba8de7988":11.888253968253965,"c258aec7-ba1b-4228-b47b-a0900a1bcfe2":10.47175925925926,"c3ec3b14-75be-4b18-af66-195537226585":9.87063492063492,"c6977873-accf-4edd-a522-ad649fc8295a":8.584126984126984,"c7423207-f332-480d-b5d1-7e96279e574c":7.1873015873015875,"cae374ce-5b99-482e-950a-0b9e304eb498":7.363227513227513,"d1538940-ff7f-4b82-9f1d-8972c0bdb4ef":10.526084656084654,"d46a67de-c591-4872-a836-47165538b63c":7.286349206349207,"d6edad4f-53c7-4a29-b484-05872a3cc82a":6.072222222222223,"d8229968-5440-4e12-ae6e-d7ba4f8eb389":12.099047619047619,"df847368-a372-4190-aac2-98c4bb9d0ddb":12.015555555555556,"e8a7d5ab-2a86-4f90-a193-c62c686d5ea7":9.176190476190476,"e927dff1-6ed4-45fd-8852-eb804e11e665":0,"e9939b8b-6fcb-4ded-ac64-43c7fdfb52d6":11.341666666666667,"f0887f29-b2e1-4971-a369-4df8b83b8996":10.31111111111111,"f27cb993-16cd-44f9-b0c8-6bbeb3ecf297":6.820634920634922,"f37628db-beac-4a64-ab7b-cd0ce4f943a9":8.385555555555555,"f3868715-abb3-4115-b57b-dc6d874f02d1":11.76148148148148,"f39486db-a4d9-49b4-a659-44c63900a7d5":0,"f45d6bd0-f1a4-4f80-b6af-5e3b12bbac3a":0,"f4d90d70-135a-4d1c-bd61-693a2bf04253":6.895238095238096,"f6326193-ef92-4e64-8a4e-7439f8692fa1":9.527777777777777,"f6706f16-c997-4b7f-a044-1d1a9f85dd51":8.209682539682538,"f7037864-4b92-437b-a90e-509d4ec350c8":7.935925925925926,"fd99a7a7-0aa2-4607-91bd-975285af5ad1":0},"topic":["stereo","set","evalu","design","data"],"groups":[{"authors":["Richard Szeliski","Polina Golland"],"references":["0c7c7fe9-5688-4b80-885b-cbdd174463c1","11666f79-0a9d-49a3-b327-d194e202c94f","1c09ef91-f69a-43e4-aaa7-571f3a143ea9","1d1fe6e4-bf7f-4785-893a-04156d3cfa6a","200c1972-9f6c-4e1b-9dbe-a1d29c7641cb","25b0c9f9-0c8a-4f2a-b075-90d339b6faa3","26162728-24a2-4d03-bb17-871f59a2e39c","2f393a81-de8e-426c-b8ed-00b90baf096a","33fe8461-d465-4487-b9fa-8270a2d5865f","37e76afb-f79f-41f8-b75d-28dadd7d5cd7","4f9a9b5a-20a4-4cf2-b9aa-7649ce9b2a83","598627d0-d01d-4398-a45e-1440d21fe4f2","62aa6ba4-1331-4c57-99f5-978d580c9573","6694bc17-eca5-41d7-a781-e1cbbf512855","6738647a-1149-4e62-ad42-4d2b0fb1ccf6","7781665f-ef39-4237-9857-63477d05f5ac","7e598ce4-7739-42dd-8761-eb8984ed2b19","87a3e0c6-9219-41ee-8638-ea7a86fb8ef3","90483bd3-a6a7-4799-93cf-af14e991335c","a872c04a-47c6-4f4b-b0b9-3afbaa3538cf","adfbb287-2b5a-4f08-89ff-3acd1399b608","b2ced9a5-3457-48b8-8d4c-66badd866d75","b91bc2e6-b5dd-434f-94d4-14746c38f06a","be0f6fa3-438a-4d3e-b809-2a31857642fd","be5c002f-8d38-4043-b656-409ecd16a431","c3ec3b14-75be-4b18-af66-195537226585","c98e30a3-36d8-44d2-9945-337df58931a7","cb1807c9-7675-4fa7-9e07-4b03ab93b824","dc7a2caa-4e98-49bc-bca5-6f0bbe230d79","df847368-a372-4190-aac2-98c4bb9d0ddb","f3868715-abb3-4115-b57b-dc6d874f02d1","f39486db-a4d9-49b4-a659-44c63900a7d5","f7037864-4b92-437b-a90e-509d4ec350c8"],"_id":"4d6cc0b7-557d-4594-8bc8-ab1ce0ac251e","abstract":"This paper formulates and solves a new variant of the stereo correspondence problem: simultaneously recovering the disparities, true colors, and opacities of visible surface elements. This problem arises in newer applications of stereo reconstruction, such as view interpolation and the layering of real imagery with synthetic graphics for special effects and virtual studio applications. While this problem is intrinsically more difficult than traditional stereo correspondence, where only the disparities are being recovered, it provides a principled way of dealing with commonly occurring problems such as occlusions and the handling of mixed (foreground/background) pixels near depth discontinuities. It also provides a novel means for separating foreground and background objects (matting), without the use of a special blue screen. We formulate the problem as the recovery of colors and opacities in a generalized 3D (x, y, d) disparity space, and solve the problem using a combination of initial evidence aggregation followed by iterative energy minimization.","title":"Stereo Matching with Transparency and Matting","venue":"International Journal of Computer Vision","year":1999,"__v":0,"citationCount":52},{"authors":["Sing Bing Kang","Richard Szeliski","Jinxiang Chai"],"references":["004aa844-c144-4f34-b328-e054848d2c82","050a184c-1203-4e94-8da1-7dee5ced9777","0f302140-20a3-4065-8dd6-59176f2d4e27","13bed107-cfdb-4c83-88bd-282715b16017","1c09ef91-f69a-43e4-aaa7-571f3a143ea9","200c1972-9f6c-4e1b-9dbe-a1d29c7641cb","239a71ea-70f9-450c-9b3c-658faab40d9d","2728c7e3-fb40-4e67-bcef-7449d9258d49","2bb7edd0-987a-4b75-916f-957764d7d0e0","37e76afb-f79f-41f8-b75d-28dadd7d5cd7","45ea61a5-a990-4c11-9ce0-a0e1f67e7a5e","477ae58d-e2df-4c84-ba51-9d38518497bd","48e25c19-07a0-46c9-a659-e76db6e72d74","4d6cc0b7-557d-4594-8bc8-ab1ce0ac251e","598627d0-d01d-4398-a45e-1440d21fe4f2","62aa6ba4-1331-4c57-99f5-978d580c9573","732f1cb3-c0c3-40de-bdd0-40de75ec3a66","76845b3d-e45f-443c-a181-b1b75f17d47b","7781665f-ef39-4237-9857-63477d05f5ac","85471950-c85d-4494-ac99-30b5450ad095","8a4274f4-8925-4724-aca5-4f9c3455dc3e","8f4f3015-c03d-46e1-90fb-2c42ea2cb91f","90483bd3-a6a7-4799-93cf-af14e991335c","936e0ae4-e6e1-4b3b-9d0a-a6bff589fc7b","a7da5f11-1302-4305-a67a-9503dea05eb7","a872c04a-47c6-4f4b-b0b9-3afbaa3538cf","b1c2251e-7b54-41e5-8130-10d9646e02da","b91bc2e6-b5dd-434f-94d4-14746c38f06a","d6edad4f-53c7-4a29-b484-05872a3cc82a","f27cb993-16cd-44f9-b0c8-6bbeb3ecf297","f3868715-abb3-4115-b57b-dc6d874f02d1","f6706f16-c997-4b7f-a044-1d1a9f85dd51"],"_id":"f6326193-ef92-4e64-8a4e-7439f8692fa1","abstract":"While stereo matching was originally formulated as the recovery of 3D shape from a pair of images, it is now generally recognized that using more than two images can dramatically improve the quality of the reconstruction. Unfortunately, as more images are added, the prevalence of semi-occluded regions (pixels visible in some but not all images) also increases. We propose some novel techniques to deal with this problem. Our first idea is to use a combination of shiftable windows and a dynamically selected subset of the neighboring images to do the matches. Our second idea is to explicitly label occluded pixels within a global energy minimization framework, and to reason about visibility within this framework so that only truly visible pixels are matched. Experimental results show a dramatic improvement using the first idea over conventional multibaseline stereo, especially when used in conjunction with a global energy minimization technique. These results also show that explicit occlusion labeling and visibility reasoning do help, but not significantly, if the spatial and temporal selection is applied first.","title":"Handling occlusions in dense multi-view stereo","venue":"computer vision and pattern recognition","year":2001,"__v":0,"citationCount":144},{"authors":["Daniel Scharstein","Richard Szeliski"],"references":["0c3cac6b-305e-4f1c-8ab8-72c6a3a551fe","11666f79-0a9d-49a3-b327-d194e202c94f","15a2345f-3667-4fde-b64e-30471b6ae9ee","15f4332e-0202-4fea-8f81-fbaea42f74ba","1c09ef91-f69a-43e4-aaa7-571f3a143ea9","25b0c9f9-0c8a-4f2a-b075-90d339b6faa3","2f393a81-de8e-426c-b8ed-00b90baf096a","31918b7b-72fd-49a3-ad6b-e6bed1adc969","37e76afb-f79f-41f8-b75d-28dadd7d5cd7","3f4cc95c-5f47-4031-8671-e23ff4fe2ed2","62aa6ba4-1331-4c57-99f5-978d580c9573","6e0d7a60-4787-4348-84a5-5b94664a5777","936e0ae4-e6e1-4b3b-9d0a-a6bff589fc7b","9f91c3c3-2b1a-470a-bcdf-c5c26d7d7f0b","a872c04a-47c6-4f4b-b0b9-3afbaa3538cf","b2ced9a5-3457-48b8-8d4c-66badd866d75","b608af66-6368-44dc-a670-2a3e42561ee1","bbe48f21-3461-4e1f-ada4-1649e073fda7","be0f6fa3-438a-4d3e-b809-2a31857642fd","c5e300ab-2ad1-42c7-822c-b2adfe6c76d9","e927dff1-6ed4-45fd-8852-eb804e11e665","ed1583ea-7543-49c7-a884-1888532dbc0d","f27cb993-16cd-44f9-b0c8-6bbeb3ecf297","f3868715-abb3-4115-b57b-dc6d874f02d1","f39486db-a4d9-49b4-a659-44c63900a7d5","f45d6bd0-f1a4-4f80-b6af-5e3b12bbac3a","f7037864-4b92-437b-a90e-509d4ec350c8"],"_id":"200c1972-9f6c-4e1b-9dbe-a1d29c7641cb","abstract":"One of the central problems in stereo matching (and other image registration tasks) is the selection of optimal window sizes for comparing image regions. This paper addresses this problem with some novel algorithms based on iteratively diffusing support at different disparity hypotheses, and locally controlling the amount of diffusion based on the current quality of the disparity estimate. It also develops a novel Bayesian estimation technique, which significantly outperforms techniques based on area-based matching (SSD) and regular diffusion. We provide experimental results on both synthetic and real stereo image pairs.","title":"Stereo Matching with Nonlinear Diffusion","venue":"International Journal of Computer Vision","year":1998,"__v":0,"citationCount":143}],"offsprings":["83c737b8-e084-4766-ba6e-131e6a1c017c","1317365d-c46d-4c09-8261-9d07404e4908","3a8fbc53-3805-4e6f-9f45-6881b640eb5e"]},"222e8196-b98b-47bc-a679-641bbf57b770":{"authors":["Rudolf Ahlswede","Ning Cai","Shuo-Yen Robert Li","Raymond W. Yeung"],"references":["8cea470a-9c6d-4137-8f4c-acda7e0d1904"],"_id":"222e8196-b98b-47bc-a679-641bbf57b770","abstract":"We introduce a new class of problems called network information flow which is inspired by computer network applications. Consider a point-to-point communication network on which a number of information sources are to be multicast to certain sets of destinations. We assume that the information sources are mutually independent. The problem is to characterize the admissible coding rate region. This model subsumes all previously studied models along the same line. We study the problem with one information source, and we have obtained a simple characterization of the admissible coding rate region. Our result can be regarded as the max-flow min-cut theorem for network information flow. Contrary to one's intuition, our work reveals that it is in general not optimal to regard the information to be multicast as a \"fluid\" which can simply be routed or replicated. Rather, by employing coding at the nodes, which we refer to as network coding, bandwidth can in general be saved. This finding may have significant impact on future design of switching systems.","title":"Network information flow","venue":"IEEE Transactions on Information Theory","year":2000,"__v":0,"citationCount":3644,"parents":{"0c17b2f6-8003-44db-a49c-ee1e68638231":0,"13d0bf43-d9fc-49da-b3f4-7fe74b564b88":16.666666666666664,"51be9fc7-05b7-4d29-ba12-3b06e4ca65d6":33.33333333333333,"5bc92d76-0842-4d31-bc82-ebd177b228f4":0,"8cea470a-9c6d-4137-8f4c-acda7e0d1904":0,"f8efb7ea-8348-48ed-8814-0b2059ec7e51":33.33333333333333},"keyword":{"0c17b2f6-8003-44db-a49c-ee1e68638231":5.176031746031746,"13d0bf43-d9fc-49da-b3f4-7fe74b564b88":10.355555555555556,"51be9fc7-05b7-4d29-ba12-3b06e4ca65d6":11.933333333333334,"5bc92d76-0842-4d31-bc82-ebd177b228f4":6.973809523809523,"8cea470a-9c6d-4137-8f4c-acda7e0d1904":10.531825396825399,"f8efb7ea-8348-48ed-8814-0b2059ec7e51":10.97063492063492},"topic":["inform","network","code","sourc","problem"],"groups":[{"authors":["Raymond W. Yeung","Zhen Zhang"],"references":["13d0bf43-d9fc-49da-b3f4-7fe74b564b88","3d3c58ea-2c45-4e4b-b4e9-feaf467a0a71","3e85f3b3-5efa-42cb-800d-0a29060ec592","49a91265-1be5-4fac-aba4-267b8c712241","51be9fc7-05b7-4d29-ba12-3b06e4ca65d6","967c22e5-9ff2-4bff-9a9c-c24b205fb7bb","cad009a2-62a4-4814-afe5-748f3e4e0576"],"_id":"f8efb7ea-8348-48ed-8814-0b2059ec7e51","abstract":"Inspired by mobile satellite communications systems, we consider a source coding system which consists of multiple sources, multiple encoders, and multiple decoders. Each encoder has access to a certain subset of the sources, each decoder has access to certain subset of the encoders, and each decoder reconstructs a certain subset of the sources almost perfectly. The connectivity between the sources and the encoders, the connectivity between the encoders and the decoders, and the reconstruction requirements for the decoders are all arbitrary. Our goal is to characterize the admissible coding rate region. Despite the generality of the problem, we have developed an approach which enables us to study all cases on the same footing. We obtain inner and outer bounds of the admissible coding rate region in terms of /spl Gamma//sub N/* and /spl Gamma/~/sub N/*, respectively, which are fundamental regions in the entropy space defined by Yeung (1991). So far, there has not been a full characterization of /spl Gamma//sub N/*, so these bounds cannot be evaluated explicitly except for some special cases. Nevertheless, we obtain an alternative outer bound which can be evaluated explicitly. We show that this bound is tight for all the special cases for which the admissible coding rate region is known. The model we study in this paper is more general than all previously reported models on multilevel diversity coding, and the tools we use are new in multiuser information theory.","title":"Distributed source coding for satellite communications","venue":"IEEE Transactions on Information Theory","year":1999,"__v":0,"citationCount":76},{"authors":["Raymond W. Yeung"],"references":["0c17b2f6-8003-44db-a49c-ee1e68638231","393e02c9-758b-42e6-92d9-7033bf1a16cf","5bc92d76-0842-4d31-bc82-ebd177b228f4","7876701f-02e2-404a-88c1-bceeaf41c2cf","98f543e3-d61c-4099-ae96-237816472592","b90c5640-8e10-4f65-9193-c28af80f45e2","b9c3ab48-c632-4ec2-9e03-72c00b2d21ed","c9fe1641-6b7b-4525-8113-d842c73621c4","d4f25e48-2022-4d04-8fdc-db051636acad","e672f05a-b83b-4e18-9d67-ac6c214b6f64"],"_id":"51be9fc7-05b7-4d29-ba12-3b06e4ca65d6","abstract":"In a Diversity Coding System, an information source is encoded by a number of encoders. There are a number of decoders, each of which can access a certain subset of the encoders. We study a diversity coding problem in which there are two levels of decoders. The reconstructions of the source by decoders within the same level are identical, and are subject to the same distortion criterion. Our results imply a principle of superposition when the source consists of two independent data streams. Practical codes achieving zero error can easily be constructed for this special case. A class of open problems on this topic is also suggested. >","title":"Multilevel diversity coding with distortion","venue":"IEEE Transactions on Information Theory","year":1995,"__v":0,"citationCount":73}],"offsprings":[]},"237a87ca-d393-4173-a89d-fd2c5c1f3d37":{"authors":["Thomas Wiegand","Heiko Schwarz","Joch A","Faouzi Kossentini","Gary J. Sullivan"],"references":["94e25efe-d596-4767-99f0-d87f8c950f0c"],"_id":"237a87ca-d393-4173-a89d-fd2c5c1f3d37","abstract":"A unified approach to the coder control of video coding standards such as MPEG-2, H.263, MPEG-4, and the draft video coding standard H.264/AVC (advanced video coding) is presented. The performance of the various standards is compared by means of PSNR and subjective testing results. The results indicate that H.264/AVC compliant encoders typically achieve essentially the same reproduction quality as encoders that are compliant with the previous standards while typically requiring 60% or less of the bit rate.","title":"Rate-constrained coder control and comparison of video coding standards","venue":"IEEE Transactions on Circuits and Systems for Video Technology","year":2003,"__v":0,"citationCount":1998,"parents":{"21528d31-71fa-4244-a272-1df8a0492107":10,"260a8eb0-9e62-4156-b89b-bb8c9a48e962":0,"32e67a88-4535-4734-8e1b-b79d04ce064d":20,"37708b6d-80cd-4d60-bc32-9255c830032a":0,"40004921-c73a-4c14-b261-7581f3628da2":10,"7210fb5d-2d76-4639-9365-e3fe830307b4":10,"7b88373c-de8f-420b-ab8f-94c4da5753f8":30,"94e25efe-d596-4767-99f0-d87f8c950f0c":50,"bc5b0e19-28da-4859-922a-38c9735fea87":0,"d5327892-4102-4cd1-b8e2-87e3d0a3d279":20},"keyword":{"21528d31-71fa-4244-a272-1df8a0492107":8.616666666666665,"260a8eb0-9e62-4156-b89b-bb8c9a48e962":11.104208384208384,"32e67a88-4535-4734-8e1b-b79d04ce064d":9.467063492063494,"37708b6d-80cd-4d60-bc32-9255c830032a":7.761640211640211,"40004921-c73a-4c14-b261-7581f3628da2":8.312193362193362,"7210fb5d-2d76-4639-9365-e3fe830307b4":10.265555555555556,"7b88373c-de8f-420b-ab8f-94c4da5753f8":10.678571428571429,"94e25efe-d596-4767-99f0-d87f8c950f0c":9.619444444444444,"bc5b0e19-28da-4859-922a-38c9735fea87":10.145238095238096,"d5327892-4102-4cd1-b8e2-87e3d0a3d279":10.993253968253969},"topic":["standard","video","code","typic","result"],"groups":[{"authors":["Markus Flierl","Bernd Girod"],"references":["237a87ca-d393-4173-a89d-fd2c5c1f3d37","239d0c17-d44e-43ce-b0f3-18ebc8823de3","2eef0cb1-cc0c-48ee-9eea-2034711aa345","31907507-643d-4bf0-a6f2-8cec94d9d779","40004921-c73a-4c14-b261-7581f3628da2","59b905dd-c832-4d30-8e29-5062a0d6d8c9","7210fb5d-2d76-4639-9365-e3fe830307b4","8af0e559-c8c4-4960-a883-f6a23c840215","d5327892-4102-4cd1-b8e2-87e3d0a3d279"],"_id":"7b88373c-de8f-420b-ab8f-94c4da5753f8","abstract":"This paper reviews recent advances in using B pictures in the context of the draft H.264/AVC video-compression standard. We focus on reference picture selection and linearly combined motion-compensated prediction signals. We show that bidirectional prediction exploits partially the efficiency of combined prediction signals whereas multihypothesis prediction allows a more general form of B pictures. The general concept of linearly combined prediction signals chosen from an arbitrary set of reference pictures improves the H.264/AVC test model TML-9 which is used in the following. We outline H.264/AVC macroblock prediction modes for B pictures, classify them into four groups and compare their efficiency in terms of rate-distortion performance. When investigating multihypothesis prediction, we show that bidirectional prediction is a special case of this concept. Multihypothesis prediction allows also two combined forward prediction signals. Experimental results show that this case is also advantageous in terms of compression efficiency. The draft H.264/AVC video-compression standard offers improved entropy coding by context-based adaptive binary arithmetic coding. Simulations show that the gains by multihypothesis prediction and arithmetic coding are additive. B pictures establish an enhancement layer and are predicted from reference pictures that are provided by the base layer. The quality of the base layer influences the rate-distortion trade-off for B pictures. We demonstrate how the quality of the B pictures should be reduced to improve the overall rate-distortion performance of the scalable representation.","title":"Generalized B pictures and the draft H.264/AVC video-compression standard","venue":"IEEE Transactions on Circuits and Systems for Video Technology","year":2003,"__v":0,"citationCount":79},{"authors":["Thomas Wiegand","Gary J. Sullivan","Gisle Bjontegaard","Ajay Luthra"],"references":["1ea5125c-2c09-47c7-ba82-913bda694a3f","237a87ca-d393-4173-a89d-fd2c5c1f3d37","260a8eb0-9e62-4156-b89b-bb8c9a48e962","32e67a88-4535-4734-8e1b-b79d04ce064d","4aa6d2f8-2633-4e06-849f-f81badaac3d6","55ac55cc-c6ea-4f37-ad4a-e8d8322202d1","586b90e7-e84c-4129-8d7b-8c14cdf2ce78","696bf9e4-eb9d-4d3a-96b3-b41e18d4ac6f","7210fb5d-2d76-4639-9365-e3fe830307b4","7b88373c-de8f-420b-ab8f-94c4da5753f8","7ddd1b00-19c3-4b04-b002-6156433b9af0","d5327892-4102-4cd1-b8e2-87e3d0a3d279"],"_id":"94e25efe-d596-4767-99f0-d87f8c950f0c","abstract":"H.264/AVC is newest video coding standard of the ITU-T Video Coding Experts Group and the ISO/IEC Moving Picture Experts Group. The main goals of the H.264/AVC standardization effort have been enhanced compression performance and provision of a \"network-friendly\" video representation addressing \"conversational\" (video telephony) and \"nonconversational\" (storage, broadcast, or streaming) applications. H.264/AVC has achieved a significant improvement in rate-distortion efficiency relative to existing standards. This article provides an overview of the technical features of H.264/AVC, describes profiles and applications for the standard, and outlines the history of the standardization process.","title":"Overview of the H.264/AVC video coding standard","venue":"IEEE Transactions on Circuits and Systems for Video Technology","year":2003,"__v":0,"citationCount":2925}],"offsprings":["94e25efe-d596-4767-99f0-d87f8c950f0c","ff3e8103-1378-408b-adc2-c42b1c25b065"]},"23dc6e53-9579-4198-bb00-dedfd3e6071b":{"authors":["Eckart Zitzler","Lothar Thiele"],"references":["bac5da35-9009-41a3-b758-21aec812a9ee"],"_id":"23dc6e53-9579-4198-bb00-dedfd3e6071b","abstract":"Evolutionary algorithms (EAs) are often well-suited for optimization problems involving several, often conflicting objectives. Since 1985, various evolutionary approaches to multiobjective optimization have been developed that are capable of searching for multiple solutions concurrently in a single run. However, the few comparative studies of different methods presented up to now remain mostly qualitative and are often restricted to a few approaches. In this paper, four multiobjective EAs are compared quantitatively where an extended 0/1 knapsack problem is taken as a basis. Furthermore, we introduce a new evolutionary approach to multicriteria optimization, the strength Pareto EA (SPEA), that combines several features of previous multiobjective EAs in a unique manner. It is characterized by (a) storing nondominated solutions externally in a second, continuously updated population, (b) evaluating an individual's fitness dependent on the number of external nondominated points that dominate it, (c) preserving population diversity using the Pareto dominance relationship, and (d) incorporating a clustering procedure in order to reduce the nondominated set without destroying its characteristics. The proof-of-principle results obtained on two artificial problems as well as a larger problem, the synthesis of a digital hardware-software multiprocessor system, suggest that SPEA can be very effective in sampling from along the entire Pareto-optimal front and distributing the generated solutions over the tradeoff surface. Moreover, SPEA clearly outperforms the other four multiobjective EAs on the 0/1 knapsack problem.","title":"Multiobjective evolutionary algorithms: a comparative case study and the strength Pareto approach","venue":"IEEE Transactions on Evolutionary Computation","year":1999,"__v":0,"citationCount":2015,"parents":{"0cc8a4bb-8bb1-4526-ab1e-ae8ff4eccc6d":0,"1c7aa320-ee89-450e-a0ac-38486cfe8be4":13.043478260869565,"29ffb97b-88a2-4907-b712-d03d102e2718":4.3478260869565215,"32db0b6b-7326-4bd6-9404-fa88ce9e0746":8.695652173913043,"5aeaebb4-9204-460c-9cd4-4107bd99ad2c":8.695652173913043,"5c4cb3fc-9a25-4aa7-92ff-8044f9662c7d":0,"64f82efb-79b2-4973-88db-b71675ab2d9f":4.3478260869565215,"65feaeb3-d1c3-4796-ab43-90328771b70d":0,"6a6b9aa6-683f-4c7c-b06e-9c3018d10fd3":0,"85a50d96-0547-4411-96d0-b41762e114af":0,"8aad37e1-969d-4620-8cbb-50b7f3c5e587":8.695652173913043,"94902cd4-3f73-4bcc-b4b3-0e4ca27c66f2":4.3478260869565215,"98f53531-3c38-4728-b9da-6eb63244db0f":0,"991a324f-5d73-4d6b-a41d-b7784014902e":13.043478260869565,"9cf177c9-48f2-4743-823d-950b096f0008":17.391304347826086,"ab41c6f6-ade6-4f84-ace0-0743fd8ac46d":17.391304347826086,"b8be5256-00f7-4d83-bd1b-f13bfcdf0673":0,"bac5da35-9009-41a3-b758-21aec812a9ee":0,"c6fed450-131c-49e9-bf77-321ff0ea38bf":0,"c7be1be3-c355-4f8a-ac76-80034078f360":0,"cc462adc-4244-45c8-aa46-c40ff277cbbc":8.695652173913043,"d05c6688-882c-414f-8fcc-5ebe34a8b8f9":0,"dac137d4-c567-4291-9eff-b97fb87d46d7":17.391304347826086},"keyword":{"0cc8a4bb-8bb1-4526-ab1e-ae8ff4eccc6d":0,"1c7aa320-ee89-450e-a0ac-38486cfe8be4":9.61167388167388,"29ffb97b-88a2-4907-b712-d03d102e2718":10.105406445406445,"32db0b6b-7326-4bd6-9404-fa88ce9e0746":11.291955266955267,"5aeaebb4-9204-460c-9cd4-4107bd99ad2c":12.468982683982684,"5c4cb3fc-9a25-4aa7-92ff-8044f9662c7d":0,"64f82efb-79b2-4973-88db-b71675ab2d9f":0,"65feaeb3-d1c3-4796-ab43-90328771b70d":0,"6a6b9aa6-683f-4c7c-b06e-9c3018d10fd3":10.963311688311688,"85a50d96-0547-4411-96d0-b41762e114af":0,"8aad37e1-969d-4620-8cbb-50b7f3c5e587":12.467643097643096,"94902cd4-3f73-4bcc-b4b3-0e4ca27c66f2":0,"98f53531-3c38-4728-b9da-6eb63244db0f":10.212233044733045,"991a324f-5d73-4d6b-a41d-b7784014902e":9.71955266955267,"9cf177c9-48f2-4743-823d-950b096f0008":11.589761904761904,"ab41c6f6-ade6-4f84-ace0-0743fd8ac46d":9.71955266955267,"b8be5256-00f7-4d83-bd1b-f13bfcdf0673":0,"bac5da35-9009-41a3-b758-21aec812a9ee":12.093566618566616,"c6fed450-131c-49e9-bf77-321ff0ea38bf":0,"c7be1be3-c355-4f8a-ac76-80034078f360":0,"cc462adc-4244-45c8-aa46-c40ff277cbbc":10.746810966810965,"d05c6688-882c-414f-8fcc-5ebe34a8b8f9":0,"dac137d4-c567-4291-9eff-b97fb87d46d7":11.53481240981241},"topic":["problem","ea","multiobject","spea","solut"],"offsprings":[]},"26316adf-569e-49bc-a289-c1ba311624f6":{"authors":["Li Fei-Fei","Pietro Perona"],"references":["6018a516-8149-4bce-bc33-5449d86e58c2","ab3afb93-8ca0-4556-ae60-11199dc263c2"],"_id":"26316adf-569e-49bc-a289-c1ba311624f6","abstract":"We propose a novel approach to learn and recognize natural scene categories. Unlike previous work, it does not require experts to annotate the training set. We represent the image of a scene by a collection of local regions, denoted as codewords obtained by unsupervised learning. Each region is represented as part of a \"theme\". In previous work, such themes were learnt from hand-annotations of experts, while our method learns the theme distributions as well as the codewords distribution over the themes without supervision. We report satisfactory categorization performances on a large set of 13 categories of complex scenes.","title":"A Bayesian hierarchical model for learning natural scene categories","venue":"computer vision and pattern recognition","year":2005,"__v":0,"citationCount":1667,"parents":{"090af1dd-85e1-49f1-ae85-9928df7f709f":0,"1ed2cc94-3d0b-4718-80b6-2528e814c921":0,"473cf1a4-9f42-4e6d-b34f-77787f329079":0,"6018a516-8149-4bce-bc33-5449d86e58c2":0,"68d734f8-c860-43a0-9c2b-182e8a40e50d":0,"72c27d5a-23c5-4d1b-a000-280b87b368ee":20,"84c49073-b398-4149-bd5d-f65c76fa5c68":30,"904cbad5-94b6-4992-b1fa-4e68c56f18ab":10,"ab3afb93-8ca0-4556-ae60-11199dc263c2":10,"fc4a70a7-80c5-43c8-a68f-0a72a46ecce8":10},"keyword":{"090af1dd-85e1-49f1-ae85-9928df7f709f":10.944444444444446,"1ed2cc94-3d0b-4718-80b6-2528e814c921":10.940714285714286,"473cf1a4-9f42-4e6d-b34f-77787f329079":7.720317460317461,"6018a516-8149-4bce-bc33-5449d86e58c2":9.818888888888889,"68d734f8-c860-43a0-9c2b-182e8a40e50d":9.085079365079364,"72c27d5a-23c5-4d1b-a000-280b87b368ee":7.0545238095238085,"84c49073-b398-4149-bd5d-f65c76fa5c68":7.9750000000000005,"904cbad5-94b6-4992-b1fa-4e68c56f18ab":5.190079365079365,"ab3afb93-8ca0-4556-ae60-11199dc263c2":10.043968253968252,"fc4a70a7-80c5-43c8-a68f-0a72a46ecce8":9.197777777777777},"topic":["theme","scene","learn","work","set"],"groups":[{"authors":["Julia Vogel","Bernt Schiele"],"references":["1ed2cc94-3d0b-4718-80b6-2528e814c921","750b0ac1-2ac9-4273-a9c8-baad11e26fcd","904cbad5-94b6-4992-b1fa-4e68c56f18ab","ab3afb93-8ca0-4556-ae60-11199dc263c2","f448211a-7571-43a3-9189-95a7cc31d738"],"_id":"84c49073-b398-4149-bd5d-f65c76fa5c68","abstract":"We propose an approach to categorize real-world natural scenes based on a semantic typicality measure. The proposed typicality measure allows to grade the similarity of an image with respect to a scene category. We argue that such a graded decision is appropriate and justified both from a human's perspective as well as from the image-content point of view. The method combines bottom-up information of local semantic concepts with the typical semantic content of an image category. Using this learned category representation the proposed typicality measure also quantifies the semantic transitions between image categories such as coasts,rivers/lakes,forest, plains, mountains or sky/clouds. The method is evaluated quantitatively and qualitatively on a database of natural scenes. The experiments show that the typicality measure well represents the diversity of the given image categories as well as the ambiguity in human judgment of image categorization.","title":"A Semantic Typicality Measure for Natural Scene Categorization","venue":"Lecture Notes in Computer Science","year":2004,"__v":0,"citationCount":56}],"offsprings":["e0ac4812-7729-4a2d-8a1f-74b1b7c8eb5d"]},"2659531e-eb9d-4dd5-b46f-10f66a4819c6":{"authors":["Siavash M. Alamouti"],"references":[],"_id":"2659531e-eb9d-4dd5-b46f-10f66a4819c6","abstract":"This paper presents a simple two-branch transmit diversity scheme. Using two transmit antennas and one receive antenna the scheme provides the same diversity order as maximal-ratio receiver combining (MRRC) with one transmit antenna, and two receive antennas. It is also shown that the scheme may easily be generalized to two transmit antennas and M receive antennas to provide a diversity order of 2M. The new scheme does not require any bandwidth expansion or any feedback from the receiver to the transmitter and its computation complexity is similar to MRRC.","title":"A simple transmit diversity technique for wireless communications","venue":"IEEE Journal on Selected Areas in Communications","year":1998,"__v":0,"citationCount":5063,"parents":{"a23ab342-c57f-4763-ba97-128d90413ca9":50,"ebac2b26-3187-4435-88a2-049cb5463806":0},"keyword":{"a23ab342-c57f-4763-ba97-128d90413ca9":13.527777777777779,"ebac2b26-3187-4435-88a2-049cb5463806":0},"topic":["antenna","receiv","transmit","scheme","divers"],"groups":[{"authors":["Vahid Tarokh","Ayman Fawzy Naguib","N. Seshadri","A.R. Calderbank"],"references":["6b96ace2-e362-4610-941c-37b19dc90b61","6fc115f8-323a-4999-9e23-c0af2d8973a3","70900ce7-fd5e-4779-a73d-8bdc42cfb3ff","90609f26-928e-47a1-80f5-0d5a8e3a4858","ebac2b26-3187-4435-88a2-049cb5463806"],"_id":"a23ab342-c57f-4763-ba97-128d90413ca9","abstract":"The information capacity of wireless communication systems may be increased dramatically by employing multiple transmit and receive antennas. The goal of system design is to exploit this capacity in a practical way. An effective approach to increasing data rate over wireless channels is to employ space-time coding techniques appropriate to multiple transmit antennas. These space-time codes introduce temporal and spatial correlation into signals transmitted from different antennas, so as to provide diversity at the receiver, and coding gain over an uncoded system. For large number of transmit antennas and at high bandwidth efficiencies, the receiver may become too complex whenever correlation across transmit antennas is introduced. This paper dramatically reduces encoding and decoding complexity by partitioning antennas at the transmitter into small groups, and using individual space-time codes, called the component codes, to transmit information from each group of antennas. At the receiver, an individual space-time code is decoded by a novel linear processing technique that suppresses signals transmitted by other groups of antennas by treating them as interference. A simple receiver structure is derived that provides diversity and coding gain over uncoded systems. This combination of array processing at the receiver and coding techniques for multiple transmit antennas can provide reliable and very high data rate communication over narrowband wireless channels. A refinement of this basic structure gives rise to a multilayered space-time architecture that both generalizes and improves upon the layered space-time architecture proposed by Foschini (see Bell Labs Tech. J., vol.1, no.2, 1996).","title":"Combined array processing and space-time coding","venue":"IEEE Transactions on Information Theory","year":1999,"__v":0,"citationCount":224}],"offsprings":["6d25cd6f-4a67-41ed-9b6d-467c739f531e","720f59d2-acc3-4d5a-91c2-258d137d9647","b857298c-92c9-4f05-a704-3b9fc6be06e3","7ae0e791-2e2b-4504-a2fe-caa9b0589c44","324c0cc6-829c-4b4f-8ef4-5f2d9b34bf58"]},"2768199c-b9d6-4001-94d3-e6429c93bc5f":{"authors":["Reza Olfati-Saber","Richard M. Murray"],"references":["ea1d5c21-fba6-4fae-9fdc-ee7679ee46c9"],"_id":"2768199c-b9d6-4001-94d3-e6429c93bc5f","abstract":"In this paper, we discuss consensus problems for networks of dynamic agents with fixed and switching topologies. We analyze three cases: 1) directed networks with fixed topology; 2) directed networks with switching topology; and 3) undirected networks with communication time-delays and fixed topology. We introduce two consensus protocols for networks with and without time-delays and provide a convergence analysis in all three cases. We establish a direct connection between the algebraic connectivity (or Fiedler eigenvalue) of the network and the performance (or negotiation speed) of a linear consensus protocol. This required the generalization of the notion of algebraic connectivity of undirected graphs to digraphs. It turns out that balanced digraphs play a key role in addressing average-consensus problems. We introduce disagreement functions for convergence analysis of consensus protocols. A disagreement function is a Lyapunov function for the disagreement network dynamics. We proposed a simple disagreement function that is a common Lyapunov function for the disagreement dynamics of a directed network with switching topology. A distinctive feature of this work is to address consensus problems for networks with directed information flow. We provide analytical tools that rely on algebraic graph theory, matrix theory, and control theory. Simulations are provided that demonstrate the effectiveness of our theoretical results.","title":"Consensus problems in networks of agents with switching topology and time-delays","venue":"IEEE Transactions on Automatic Control","year":2004,"__v":0,"citationCount":2436,"parents":{"232cfed7-f88e-4545-b686-8b72b7a96480":8.333333333333332,"51a16a30-666c-4b4a-8962-ec187c59c399":8.333333333333332,"551b0ff9-7423-4376-a3a0-dd6a352c4079":25,"7f5dd462-46b9-429b-ba14-8a60d3d437a0":0,"ab35dc68-62bd-4c54-81d3-9a8406827489":16.666666666666664,"aeabc622-720d-44d0-888c-787e7d377f54":0,"b6a0562d-91b9-4b65-a395-0e705e24f3ba":0,"bf96410c-8b91-41bf-aff4-ed144c1b6e8c":16.666666666666664,"c6fb8895-3ef3-4207-a9bc-5b41a7a17a23":0,"d7b5aadf-ec30-4fb7-9224-7474169d3744":16.666666666666664,"ea1d5c21-fba6-4fae-9fdc-ee7679ee46c9":16.666666666666664,"fb3683fe-a6d4-4918-b96e-595abd299183":8.333333333333332},"keyword":{"232cfed7-f88e-4545-b686-8b72b7a96480":10.73888888888889,"51a16a30-666c-4b4a-8962-ec187c59c399":9.747619047619049,"551b0ff9-7423-4376-a3a0-dd6a352c4079":9.563994708994707,"7f5dd462-46b9-429b-ba14-8a60d3d437a0":10.88293650793651,"ab35dc68-62bd-4c54-81d3-9a8406827489":8.558730158730159,"aeabc622-720d-44d0-888c-787e7d377f54":10.328373015873018,"b6a0562d-91b9-4b65-a395-0e705e24f3ba":9.897380952380953,"bf96410c-8b91-41bf-aff4-ed144c1b6e8c":8.85218253968254,"c6fb8895-3ef3-4207-a9bc-5b41a7a17a23":10.586507936507937,"d7b5aadf-ec30-4fb7-9224-7474169d3744":10.625,"ea1d5c21-fba6-4fae-9fdc-ee7679ee46c9":9.786507936507935,"fb3683fe-a6d4-4918-b96e-595abd299183":0},"topic":["network","topolog","function","disagr","direct"],"groups":[{"authors":["Jorge Cortes","Francesco Bullo"],"references":["2768199c-b9d6-4001-94d3-e6429c93bc5f","ab0eaa81-81a5-4a3a-8b00-6e6bbc185ff6","aeabc622-720d-44d0-888c-787e7d377f54","b546dd1a-7e2d-4527-ba3c-2e6ce5e0a405","bf96410c-8b91-41bf-aff4-ed144c1b6e8c","d65d26b4-a0e0-4112-ae22-2f3a4b51d7b3","dce0df32-9d62-4942-b61b-48b4bc54ba36","e70541cd-3cdc-441e-a612-bdfaa5334fd5","ea1d5c21-fba6-4fae-9fdc-ee7679ee46c9","efed0c9f-6b90-4c0a-ba67-65d4b2bee0de"],"_id":"551b0ff9-7423-4376-a3a0-dd6a352c4079","abstract":"This paper discusses dynamical systems for disk-covering and sphere-packing problems. We present facility location functions from geometric optimization and characterize their differentiable properties. We design and analyze a collection of distributed control laws that are related to nonsmooth gradient systems. The resulting dynamical systems promise to be of use in coordination problems for networked robots; in this setting the distributed control laws correspond to local interactions between the robots. The technical approach relies on concepts from computational geometry, nonsmooth analysis, and the dynamical system approach to algorithms.","title":"Coordination and Geometric Optimization via Distributed Dynamical Systems","venue":"Siam Journal on Control and Optimization","year":2005,"__v":0,"citationCount":124}],"offsprings":["d9162547-fd7f-4605-855d-0a3173c4b08e"]},"288106a6-f48d-44c2-98fb-bd4c257d6ff5":{"authors":["Leslie Pack Kaelbling","Michael L. Littman","Andrew W. Moore"],"references":[],"_id":"288106a6-f48d-44c2-98fb-bd4c257d6ff5","abstract":"This paper surveys the field of reinforcement learning from a computer-science perspective. It is written to be accessible to researchers familiar with machine learning. Both the historical basis of the field and a broad selection of current work are summarized. Reinforcement learning is the problem faced by an agent that learns behavior through trial-and-error interactions with a dynamic environment. The work described here has a resemblance to work in psychology, but differs considerably in the details and in the use of the word \"reinforcement.\" The paper discusses central issues of reinforcement learning, including trading off exploration and exploitation, establishing the foundations of the field via Markov decision theory, learning from delayed reinforcement, constructing empirical models to accelerate learning, making use of generalization and hierarchy, and coping with hidden state. It concludes with a survey of some implemented systems and an assessment of the practical utility of current methods for reinforcement learning.","title":"Reinforcement learning: a survey","venue":"Journal of Artificial Intelligence Research","year":1996,"__v":0,"citationCount":1749,"parents":{"05444f91-7fe6-4d07-aa46-79d477e0f130":7.142857142857142,"0e4c1528-6e83-4e8e-b20d-397a4728e3d2":1.7857142857142856,"10faea31-cb77-4a47-8ec5-42f51c56c284":1.7857142857142856,"151d2baa-85a5-4887-875f-642639754055":14.285714285714285,"1637b27a-ff5d-4e85-923d-5238c274b11a":10.714285714285714,"1ad309e3-593b-4712-b170-1e199c96ba5a":3.571428571428571,"28c262c0-26b2-40c7-bf25-28b9a435659a":1.7857142857142856,"2d465068-d58d-48f9-aeec-5e672acf7817":5.357142857142857,"31752a13-73b4-42fd-b0b4-7cddad015f2c":0,"31a786d1-755c-45d7-b0e4-b59cd92eb313":0,"364e9408-59ce-4336-892e-2d1e640a8ede":5.357142857142857,"386089c6-1cfb-4f0b-89b5-042750055c6e":5.357142857142857,"3d25bc87-ad84-43e0-8cc0-c92c32219c88":3.571428571428571,"409eff52-88a4-4266-a9a0-ecfe6994d33b":1.7857142857142856,"412e9a82-8107-4a03-b6ac-e9a132cabfa3":1.7857142857142856,"4896a7bc-0d0f-4f49-96ea-e7c0ba415871":5.357142857142857,"50844c76-154a-4391-8617-de81cc672088":3.571428571428571,"593bb176-2e01-43fb-90fe-930b9b4d4b89":14.285714285714285,"5e152bf0-9d37-466d-9da8-83e760da43d6":3.571428571428571,"5f648781-20c9-4e94-9093-4f7dbaa063a0":16.071428571428573,"61a1f352-f948-4d71-8fc8-16a4a2dffcc7":1.7857142857142856,"62657d17-3eac-4489-8829-d6f5c9d46b45":5.357142857142857,"66c1e3d6-2e26-4f2b-8dea-b0dc10e88a8a":0,"6766a6c0-b501-482e-af98-d67bfa1c7c2b":1.7857142857142856,"6a6b9aa6-683f-4c7c-b06e-9c3018d10fd3":0,"70210fca-ae4c-4fd3-ac5a-efb569a6763a":1.7857142857142856,"75ea5f54-ccaa-4b36-962e-df2e2656b354":5.357142857142857,"782d8c51-9df1-4d5e-8a2c-ac267b2bca28":7.142857142857142,"7ae47b7e-a5ac-4747-b7da-f0ae5ff57ea6":0,"7d4aa8eb-58cc-4a7c-8f54-8498c9e309b5":3.571428571428571,"82e68274-75bd-45f2-bed4-c068404a6f0b":3.571428571428571,"858a31ca-db18-4121-bba3-996157c71f8a":8.928571428571429,"8592a41c-d6fe-4748-9c61-27fc71b8275a":3.571428571428571,"89fee555-83c3-43fe-8e0d-5c954f26f4aa":5.357142857142857,"8d1406b1-7d4b-4b31-9620-315e9b903a67":0,"8e2320ea-cb9e-4be0-8c92-bd27badd2837":0,"96ed0ede-83d6-4a80-b14c-a1c1d2e493bd":3.571428571428571,"a439c187-c5df-49f6-9970-31561dd93eb1":8.928571428571429,"ac5710de-30be-4c4b-88d0-85685416ec5d":5.357142857142857,"b3940c03-398b-4b47-99cb-ea15aa587373":5.357142857142857,"b43f6aec-23f0-47a2-a24c-83f22d6ad4f5":8.928571428571429,"c2d2c81a-8895-4360-a551-0c2fa777389b":0,"c56a99d6-baed-4ef2-b85d-b506aa5164bf":8.928571428571429,"cf8a9eb7-4701-4c1a-84ad-3d5b53117f60":3.571428571428571,"d1a9ecd3-34d5-4452-9865-b6bfc4699786":3.571428571428571,"d2f073a7-47a7-4d77-821b-8012e402f34f":3.571428571428571,"d3905afd-578f-46c4-b59b-4f31dab4db5d":1.7857142857142856,"d6ad61d1-aaee-40a0-8649-0c5537b24848":7.142857142857142,"d74bf856-0301-431c-a5cf-e5e0f61a528d":3.571428571428571,"e34232af-1ec2-445d-ac41-1abb4ddbe501":0,"e5a5b276-08b1-492a-bd50-04dfbbc1d2df":3.571428571428571,"e7a4dfe5-dd09-4984-9213-3449c71cb93a":0,"e7e1cf1d-a32b-4b4f-9f4e-019cc1b85f52":3.571428571428571,"e810b98f-6fd8-4473-9d20-ed0168863493":3.571428571428571,"f843a650-d219-431b-b914-b0d38da86e2c":7.142857142857142,"f8d30b25-c2fd-434e-aa65-648a87453124":7.142857142857142},"keyword":{"05444f91-7fe6-4d07-aa46-79d477e0f130":9.726613756613755,"0e4c1528-6e83-4e8e-b20d-397a4728e3d2":10.221693121693121,"10faea31-cb77-4a47-8ec5-42f51c56c284":11.311904761904762,"151d2baa-85a5-4887-875f-642639754055":12.406851851851853,"1637b27a-ff5d-4e85-923d-5238c274b11a":10.134722222222221,"1ad309e3-593b-4712-b170-1e199c96ba5a":7.9182539682539685,"28c262c0-26b2-40c7-bf25-28b9a435659a":10.73641414141414,"2d465068-d58d-48f9-aeec-5e672acf7817":12.799470899470899,"31752a13-73b4-42fd-b0b4-7cddad015f2c":10.823888888888888,"31a786d1-755c-45d7-b0e4-b59cd92eb313":7.549206349206348,"364e9408-59ce-4336-892e-2d1e640a8ede":10.636375661375661,"386089c6-1cfb-4f0b-89b5-042750055c6e":9.286111111111111,"3d25bc87-ad84-43e0-8cc0-c92c32219c88":7.366666666666665,"409eff52-88a4-4266-a9a0-ecfe6994d33b":0,"412e9a82-8107-4a03-b6ac-e9a132cabfa3":9.994444444444444,"4896a7bc-0d0f-4f49-96ea-e7c0ba415871":8.738055555555555,"50844c76-154a-4391-8617-de81cc672088":12.078439153439152,"593bb176-2e01-43fb-90fe-930b9b4d4b89":10.799074074074076,"5e152bf0-9d37-466d-9da8-83e760da43d6":8.339285714285714,"5f648781-20c9-4e94-9093-4f7dbaa063a0":11.889563492063495,"61a1f352-f948-4d71-8fc8-16a4a2dffcc7":12.799470899470899,"62657d17-3eac-4489-8829-d6f5c9d46b45":8.48202380952381,"66c1e3d6-2e26-4f2b-8dea-b0dc10e88a8a":11.050396825396824,"6766a6c0-b501-482e-af98-d67bfa1c7c2b":7.447301587301587,"6a6b9aa6-683f-4c7c-b06e-9c3018d10fd3":7.95515873015873,"70210fca-ae4c-4fd3-ac5a-efb569a6763a":11.797222222222222,"75ea5f54-ccaa-4b36-962e-df2e2656b354":8.191507936507936,"782d8c51-9df1-4d5e-8a2c-ac267b2bca28":9.137301587301588,"7ae47b7e-a5ac-4747-b7da-f0ae5ff57ea6":9.778597883597884,"7d4aa8eb-58cc-4a7c-8f54-8498c9e309b5":11.175252525252525,"82e68274-75bd-45f2-bed4-c068404a6f0b":9.819999999999999,"858a31ca-db18-4121-bba3-996157c71f8a":9.158611111111112,"8592a41c-d6fe-4748-9c61-27fc71b8275a":12.271296296296297,"89fee555-83c3-43fe-8e0d-5c954f26f4aa":11.330158730158733,"8d1406b1-7d4b-4b31-9620-315e9b903a67":9.08111111111111,"8e2320ea-cb9e-4be0-8c92-bd27badd2837":10.941666666666666,"96ed0ede-83d6-4a80-b14c-a1c1d2e493bd":10.360555555555555,"a439c187-c5df-49f6-9970-31561dd93eb1":10.266097883597885,"ac5710de-30be-4c4b-88d0-85685416ec5d":12.248730158730156,"b3940c03-398b-4b47-99cb-ea15aa587373":9.990277777777777,"b43f6aec-23f0-47a2-a24c-83f22d6ad4f5":11.169444444444443,"c2d2c81a-8895-4360-a551-0c2fa777389b":10.03888888888889,"c56a99d6-baed-4ef2-b85d-b506aa5164bf":10.392777777777777,"cf8a9eb7-4701-4c1a-84ad-3d5b53117f60":10.009444444444444,"d1a9ecd3-34d5-4452-9865-b6bfc4699786":10.871031746031745,"d2f073a7-47a7-4d77-821b-8012e402f34f":6.986507936507937,"d3905afd-578f-46c4-b59b-4f31dab4db5d":9.997407407407408,"d6ad61d1-aaee-40a0-8649-0c5537b24848":10.144444444444446,"d74bf856-0301-431c-a5cf-e5e0f61a528d":10.337222222222222,"e34232af-1ec2-445d-ac41-1abb4ddbe501":10.050462962962962,"e5a5b276-08b1-492a-bd50-04dfbbc1d2df":8.272222222222222,"e7a4dfe5-dd09-4984-9213-3449c71cb93a":0,"e7e1cf1d-a32b-4b4f-9f4e-019cc1b85f52":10.202142857142857,"e810b98f-6fd8-4473-9d20-ed0168863493":10.112169312169314,"f843a650-d219-431b-b914-b0d38da86e2c":0,"f8d30b25-c2fd-434e-aa65-648a87453124":11.7984126984127},"topic":["learn","reinforc","work","field","survei"],"offsprings":["c6082f75-3e21-463c-8368-988c9012e54c"]},"293971a9-15e0-4a32-9c76-8a9704e304c2":{"authors":["Marco Dorigo","Vittorio Maniezzo","Alberto Colorni"],"references":[],"_id":"293971a9-15e0-4a32-9c76-8a9704e304c2","abstract":"An analogy with the way ant colonies function has suggested the definition of a new computational paradigm, which we call ant system (AS). We propose it as a viable new approach to stochastic combinatorial optimization. The main characteristics of this model are positive feedback, distributed computation, and the use of a constructive greedy heuristic. Positive feedback accounts for rapid discovery of good solutions, distributed computation avoids premature convergence, and the greedy heuristic helps find acceptable solutions in the early stages of the search process. We apply the proposed methodology to the classical traveling salesman problem (TSP), and report simulation results. We also discuss parameter selection and the early setups of the model, and compare it with tabu search and simulated annealing using TSP. To demonstrate the robustness of the approach, we show how the ant system (AS) can be applied to other optimization problems like the asymmetric traveling salesman, the quadratic assignment and the job-shop scheduling. Finally we discuss the salient characteristics-global data structure revision, distributed communication and probabilistic transitions of the AS.","title":"Ant system: optimization by a colony of cooperating agents","venue":"systems man and cybernetics","year":1996,"__v":0,"citationCount":2593,"parents":{"050bbb75-2ea7-44e7-8b51-85cabc1540ca":0,"1e4e8925-3328-4af5-be88-56eef2f6aa8f":0,"5fff9a52-b624-48fe-bf88-ac96ed74e44b":0,"61090484-e601-43a8-9baa-001276e43ded":0,"6a6b9aa6-683f-4c7c-b06e-9c3018d10fd3":0,"75d7fba1-d1ec-427a-86c0-7bf2d5f799ad":0,"95d33a82-8050-4ca0-a34e-1053b7d28672":37.5,"b43f8a10-4a5e-4558-8c19-730859575203":37.5},"keyword":{"050bbb75-2ea7-44e7-8b51-85cabc1540ca":9.517222222222221,"1e4e8925-3328-4af5-be88-56eef2f6aa8f":11.12962962962963,"5fff9a52-b624-48fe-bf88-ac96ed74e44b":0,"61090484-e601-43a8-9baa-001276e43ded":10.000396825396825,"6a6b9aa6-683f-4c7c-b06e-9c3018d10fd3":9.363227513227514,"75d7fba1-d1ec-427a-86c0-7bf2d5f799ad":0,"95d33a82-8050-4ca0-a34e-1053b7d28672":9.944444444444445,"b43f8a10-4a5e-4558-8c19-730859575203":0},"topic":["distribut","comput","ant","tsp","travel"],"groups":[{"authors":["Vittorio Maniezzo","Alberto Colorni"],"references":["050bbb75-2ea7-44e7-8b51-85cabc1540ca","1e4e8925-3328-4af5-be88-56eef2f6aa8f","2107d620-10df-446b-8598-f7707b80f613","293971a9-15e0-4a32-9c76-8a9704e304c2","6718606f-0823-4bf3-8dfd-20e677a6c2de","7599acb1-c976-45cd-aee2-81f69f7ea11a","b43f8a10-4a5e-4558-8c19-730859575203","ef31669e-dab1-4b60-85f1-70b6532275ac"],"_id":"95d33a82-8050-4ca0-a34e-1053b7d28672","abstract":"In recent years, there has been growing interest in algorithms inspired by the observation of natural phenomena to define computational procedures that can solve complex problems. We describe a distributed heuristic algorithm that was inspired by the observation of the behavior of ant colonies, and we propose its use for the quadratic assignment problem. The results obtained in solving several classical instances of the problem are compared with those obtained from other evolutionary heuristics to evaluate the quality of the proposed system.","title":"The ant system applied to the quadratic assignment problem","venue":"IEEE Transactions on Knowledge and Data Engineering","year":1999,"__v":0,"citationCount":232},{"authors":["Alberto Colorni","Marco Dorigo","Vittorio Maniezzo"],"references":["0419c36b-27f3-4a26-85af-4d3183f426ab","1e4e8925-3328-4af5-be88-56eef2f6aa8f","5fff9a52-b624-48fe-bf88-ac96ed74e44b","75d7fba1-d1ec-427a-86c0-7bf2d5f799ad"],"_id":"b43f8a10-4a5e-4558-8c19-730859575203","title":"An Investigation of Some Properties of an Ant Algorithm","venue":"parallel problem solving from nature","year":1992,"abstract":"","__v":0,"citationCount":77}],"offsprings":["c6082f75-3e21-463c-8368-988c9012e54c"]},"2b6a3d0f-368f-45bb-be23-4e82f62fbbf7":{"authors":["Jia Deng","Wei Dong","Richard Socher","Li-Jia Li","Kai Li","Li Fei-Fei"],"references":["6c38b3b4-7562-493d-a40c-fe70abf039a7","b944f77f-113b-4a02-ae5e-d4a124b8fd5b"],"_id":"2b6a3d0f-368f-45bb-be23-4e82f62fbbf7","abstract":"The explosion of image data on the Internet has the potential to foster more sophisticated and robust models and algorithms to index, retrieve, organize and interact with images and multimedia data. But exactly how such data can be harnessed and organized remains a critical problem. We introduce here a new database called “ImageNet”, a large-scale ontology of images built upon the backbone of the WordNet structure. ImageNet aims to populate the majority of the 80,000 synsets of WordNet with an average of 500-1000 clean and full resolution images. This will result in tens of millions of annotated images organized by the semantic hierarchy of WordNet. This paper offers a detailed analysis of ImageNet in its current state: 12 subtrees with 5247 synsets and 3.2 million images in total. We show that ImageNet is much larger in scale and diversity and much more accurate than the current image datasets. Constructing such a large-scale database is a challenging task. We describe the data collection scheme with Amazon Mechanical Turk. Lastly, we illustrate the usefulness of ImageNet through three simple applications in object recognition, image classification and automatic object clustering. We hope that the scale, accuracy, diversity and hierarchical structure of ImageNet can offer unparalleled opportunities to researchers in the computer vision community and beyond.","title":"ImageNet: A large-scale hierarchical image database","venue":"computer vision and pattern recognition","year":2009,"__v":0,"citationCount":2307,"parents":{"23120ec2-cd0d-48ed-abef-567a3f9ea103":5.263157894736842,"32a53bab-1ede-4869-98ad-d2ff0c1e3367":15.789473684210526,"40f728c0-55b3-423b-aff5-a9b3ff27b7d5":0,"433969bb-d29f-4cac-83a5-ccfb5c6c7b4e":0,"52ebe1f5-baab-4da0-aaff-d6972b921e33":0,"595fc59f-a7b2-4eed-b62e-f18dcae4c3ce":5.263157894736842,"61447020-9a4b-4742-affd-fb5cde9d84ae":0,"6c38b3b4-7562-493d-a40c-fe70abf039a7":5.263157894736842,"72cadcf0-6129-4854-a912-a7399008393a":21.052631578947366,"80a2bee0-7dff-45f9-a1b6-b3f467738100":15.789473684210526,"98801e79-fc9d-4c6a-a383-10e937c9d008":0,"9aea2ad1-64c1-4e32-b991-1333e5b60a13":10.526315789473683,"a6ee5009-aebc-4cda-8ef9-d855297b949c":21.052631578947366,"b3e241a6-126f-40fb-a063-8ed7d0223a3c":15.789473684210526,"b944f77f-113b-4a02-ae5e-d4a124b8fd5b":0,"d20eb927-339a-4c81-8b54-1a49cd7b7ec0":5.263157894736842,"e012ba25-c703-4a1b-8d66-bdd2d9048de2":31.57894736842105,"ed72bc77-6dfd-47c7-99f6-2c609c264797":5.263157894736842,"ffa31d0c-ff37-4bf3-b213-6d8a968e6636":0},"keyword":{"23120ec2-cd0d-48ed-abef-567a3f9ea103":10.629047619047618,"32a53bab-1ede-4869-98ad-d2ff0c1e3367":11.16952380952381,"40f728c0-55b3-423b-aff5-a9b3ff27b7d5":10.286243386243388,"433969bb-d29f-4cac-83a5-ccfb5c6c7b4e":11.349947089947088,"52ebe1f5-baab-4da0-aaff-d6972b921e33":8.508531746031746,"595fc59f-a7b2-4eed-b62e-f18dcae4c3ce":8.15920634920635,"61447020-9a4b-4742-affd-fb5cde9d84ae":8.443730158730158,"6c38b3b4-7562-493d-a40c-fe70abf039a7":10.048015873015872,"72cadcf0-6129-4854-a912-a7399008393a":10.545370370370373,"80a2bee0-7dff-45f9-a1b6-b3f467738100":12.35047619047619,"98801e79-fc9d-4c6a-a383-10e937c9d008":9.515873015873016,"9aea2ad1-64c1-4e32-b991-1333e5b60a13":7.967460317460318,"a6ee5009-aebc-4cda-8ef9-d855297b949c":11.504126984126984,"b3e241a6-126f-40fb-a063-8ed7d0223a3c":6.424603174603175,"b944f77f-113b-4a02-ae5e-d4a124b8fd5b":9.028253968253969,"d20eb927-339a-4c81-8b54-1a49cd7b7ec0":8.691084656084657,"e012ba25-c703-4a1b-8d66-bdd2d9048de2":10.008730158730158,"ed72bc77-6dfd-47c7-99f6-2c609c264797":11.352380952380951,"ffa31d0c-ff37-4bf3-b213-6d8a968e6636":10.965555555555554},"topic":["imag","imagenet","data","wordnet","organ"],"groups":[{"authors":["Antonio Torralba","Rob Fergus","William T. Freeman"],"references":["05c86322-8109-4627-bddf-8d209db4aa83","26316adf-569e-49bc-a289-c1ba311624f6","2ae7a9b5-6231-45ca-9813-afc3a6b5f5ff","32a53bab-1ede-4869-98ad-d2ff0c1e3367","33cc6546-c12d-49a1-9238-85838bc6e54a","36bdf4fe-a0d3-43b8-b5d3-ebd7d7979117","4db6c10f-b1bb-49c2-b00c-bca8425aa979","5189a5de-2a99-461e-af6d-644d8783cca6","5ad7276f-f084-4a24-8187-57873f008c82","5ba52f6f-7991-46c8-a6a9-0391a3b67083","5d23a185-296b-4479-9881-b317fa0edfad","6018a516-8149-4bce-bc33-5449d86e58c2","6610284f-1f5a-4460-95d6-b0ad690e171d","6c38b3b4-7562-493d-a40c-fe70abf039a7","6cd18bdc-027b-4dcc-8b1c-5ef50756a070","80a2bee0-7dff-45f9-a1b6-b3f467738100","85dfd5b5-72bb-413d-9e78-74369aeb467e","875f9a92-af0a-4a1b-8d1a-6dc5cfba544e","8bc5f80f-af26-47b4-aa0a-aab3a2e6c503","ab3afb93-8ca0-4556-ae60-11199dc263c2","add97f68-d55e-40d1-ab31-a98aa45e1b8a","ae4a15da-5aec-4876-bec6-7c8ce40761b1","c32b12e9-a542-458d-8611-4a22e5193730","c61efabe-4f71-4d5c-a6cc-9e50be780411","cb99158c-9fde-4262-9a66-0b74cb0bd828","cd0f0446-a0c8-41bd-b3b5-4376c9463157","ce710175-7867-464e-aba0-2cc3f10af701","d02653f7-6854-4619-8a48-a3f1e47c9b84","e0ac4812-7729-4a2d-8a1f-74b1b7c8eb5d","e649a9fd-f6d9-4aac-b428-29b82c20a484","ed835ca3-7120-4646-afaf-20c04a57c698","f6c05d74-3145-49f9-89a8-d63d00d6f5b4","fbb30883-9a80-47e2-ad5a-b1d833c8081c","ffa31d0c-ff37-4bf3-b213-6d8a968e6636"],"_id":"a6ee5009-aebc-4cda-8ef9-d855297b949c","abstract":"With the advent of the Internet, billions of images are now freely available online and constitute a dense sampling of the visual world. Using a variety of non-parametric methods, we explore this world with the aid of a large dataset of 79,302,017 images collected from the Internet. Motivated by psychophysical results showing the remarkable tolerance of the human visual system to degradations in image resolution, the images in the dataset are stored as 32 x 32 color images. Each image is loosely labeled with one of the 75,062 non-abstract nouns in English, as listed in the Wordnet lexical database. Hence the image database gives a comprehensive coverage of all object categories and scenes. The semantic information from Wordnet can be used in conjunction with nearest-neighbor methods to perform object classification over a range of semantic levels minimizing the effects of labeling noise. For certain classes that are particularly prevalent in the dataset, such as people, we are able to demonstrate a recognition performance comparable to class-specific Viola-Jones style detectors.","title":"80 Million Tiny Images: A Large Data Set for Nonparametric Object and Scene Recognition","venue":"IEEE Transactions on Pattern Analysis and Machine Intelligence","year":2008,"__v":0,"citationCount":670},{"authors":["Brendan M. Collins","Jia Deng","Kai Li","Li Fei-Fei"],"references":["090af1dd-85e1-49f1-ae85-9928df7f709f","32a53bab-1ede-4869-98ad-d2ff0c1e3367","4b93bd2f-e323-4326-9aa0-a6b82e879647","581c910b-e86a-4452-bc41-6add2885fb56","595fc59f-a7b2-4eed-b62e-f18dcae4c3ce","5ba52f6f-7991-46c8-a6a9-0391a3b67083","80a2bee0-7dff-45f9-a1b6-b3f467738100","83c737b8-e084-4766-ba6e-131e6a1c017c","852d4703-36db-4c8c-814c-6cd2273b536b","9aea2ad1-64c1-4e32-b991-1333e5b60a13","b944f77f-113b-4a02-ae5e-d4a124b8fd5b","bff64cad-4b2d-4741-a214-119cefe01d03","c32b12e9-a542-458d-8611-4a22e5193730","c9482f1f-6600-44a7-a69a-e63ef13cdff8","e2593dfa-7bc9-41ec-af60-e2c2ca4ec6ca","fb366046-0620-4e4e-a7ac-409d8296a0ac","fe81612e-f699-467b-97ff-9e86560a7d78","ffa31d0c-ff37-4bf3-b213-6d8a968e6636"],"_id":"e012ba25-c703-4a1b-8d66-bdd2d9048de2","abstract":"As computer vision research considers more object categories and greater variation within object categories, it is clear that larger and more exhaustive datasets are necessary. However, the process of collecting such datasets is laborious and monotonous. We consider the setting in which many images have been automatically collected for a visual category (typically by automatic internet search), and we must separate relevant images from noise. We present a discriminative learning process which employs active, online learning to quickly classify many images with minimal user input. The principle advantage of this work over previous endeavors is its scalability. We demonstrate precision which is often superior to the state-of-the-art, with scalability which exceeds previous work.","title":"Towards Scalable Dataset Construction: An Active Learning Approach","venue":"european conference on computer vision","year":2008,"__v":0,"citationCount":60}],"offsprings":["e2f7a74a-8430-4463-94ce-fe85dfd309f9","176a7436-78ea-4c2a-82e6-7930ab023bd1","153c5014-dc7a-44a8-a93f-5cd27f1193df"]},"312e54ca-e7e9-4129-99f4-36f3aeff827e":{"authors":["John S. Breese","David Heckerman","Carl M. Kadie"],"references":[],"_id":"312e54ca-e7e9-4129-99f4-36f3aeff827e","abstract":"Collaborative filtering or recommender systems use a database about user preferences to predict additional topics or products a new user might like. In this paper we describe several algorithms designed for this task, including techniques based on correlation coefficients, vector-based similarity calculations, and statistical Bayesian methods. We compare the predictive accuracy of the various methods in a set of representative problem domains. We use two basic classes of evaluation metrics. The first characterizes accuracy over a set of individual predictions in terms of average absolute deviation. The second estimates the utility of a ranked list of suggested items. This metric uses an estimate of the probability that a user will see a recommendation in an ordered list.#R##N##R##N#Experiments were run for datasets associated with 3 application areas, 4 experimental protocols, and the 2 evaluation metr rics for the various algorithms. Results indicate that for a wide range of conditions, Bayesian networks with decision trees at each node and correlation methods outperform Bayesian-clustering and vector-similarity methods. Between correlation and Bayesian networks, the preferred method depends on the nature of the dataset, nature of the application (ranked versus one-by-one presentation), and the availability of votes with which to make predictions. Other considerations include the size of database, speed of predictions, and learning time.","title":"Empirical analysis of predictive algorithms for collaborative filtering","venue":"uncertainty in artificial intelligence","year":1998,"__v":0,"citationCount":2043,"parents":{"592e8a18-27bf-4561-89d2-01afb204534d":0,"a09f0ad5-dcbb-4010-8bfe-0b1ac1cc84b1":0,"c3a0fb0a-7b0e-4b05-962f-8a674429dda7":16.666666666666664,"c69ef004-087e-486c-97c9-9b4587d0b10a":0,"c7ce0fc7-4d38-4355-aa19-ab35527d2519":16.666666666666664,"e75d8e62-a86d-4241-953f-1b315005d920":0},"keyword":{"592e8a18-27bf-4561-89d2-01afb204534d":0,"a09f0ad5-dcbb-4010-8bfe-0b1ac1cc84b1":13.322751322751323,"c3a0fb0a-7b0e-4b05-962f-8a674429dda7":9.255317460317462,"c69ef004-087e-486c-97c9-9b4587d0b10a":13.997777777777777,"c7ce0fc7-4d38-4355-aa19-ab35527d2519":0,"e75d8e62-a86d-4241-953f-1b315005d920":0},"topic":["predict","method","user","correl","bayesian"],"offsprings":["feddae21-3c05-4743-80fa-b8e101f1b93f","0ea745c7-58b2-48e8-9115-42e9b0d20f2a"]},"324c0cc6-829c-4b4f-8ef4-5f2d9b34bf58":{"authors":["Vahid Tarokh","Hamid Jafarkhani","A.R. Calderbank"],"references":["2659531e-eb9d-4dd5-b46f-10f66a4819c6","748a2ab3-8b5f-4d0a-9e2d-af685089843a"],"_id":"324c0cc6-829c-4b4f-8ef4-5f2d9b34bf58","abstract":"We introduce space-time block coding, a new paradigm for communication over Rayleigh fading channels using multiple transmit antennas. Data is encoded using a space-time block code and the encoded data is split into n streams which are simultaneously transmitted using n transmit antennas. The received signal at each receive antenna is a linear superposition of the n transmitted signals perturbed by noise. Maximum-likelihood decoding is achieved in a simple way through decoupling of the signals transmitted from different antennas rather than joint detection. This uses the orthogonal structure of the space-time block code and gives a maximum-likelihood decoding algorithm which is based only on linear processing at the receiver. Space-time block codes are designed to achieve the maximum diversity order for a given number of transmit and receive antennas subject to the constraint of having a simple decoding algorithm. The classical mathematical framework of orthogonal designs is applied to construct space-time block codes. It is shown that space-time block codes constructed in this way only exist for few sporadic values of n. Subsequently, a generalization of orthogonal designs is shown to provide space-time block codes for both real and complex constellations for any number of transmit antennas. These codes achieve the maximum possible transmission rate for any number of transmit antennas using any arbitrary real constellation such as PAM. For an arbitrary complex constellation such as PSK and QAM, space-time block codes are designed that achieve 1/2 of the maximum possible transmission rate for any number of transmit antennas. For the specific cases of two, three, and four transmit antennas, space-time block codes are designed that achieve, respectively, all, 3/4, and 3/4 of maximum possible transmission rate using arbitrary complex constellations. The best tradeoff between the decoding delay and the number of transmit antennas is also computed and it is shown that many of the codes presented here are optimal in this sense as well.","title":"Space-time block codes from orthogonal designs","venue":"IEEE Transactions on Information Theory","year":1999,"__v":0,"citationCount":2924,"parents":{"1c0fc247-3ed3-471c-9976-0ee93bf82e98":40,"2659531e-eb9d-4dd5-b46f-10f66a4819c6":20,"70900ce7-fd5e-4779-a73d-8bdc42cfb3ff":0,"748a2ab3-8b5f-4d0a-9e2d-af685089843a":0,"ebac2b26-3187-4435-88a2-049cb5463806":20},"keyword":{"1c0fc247-3ed3-471c-9976-0ee93bf82e98":12.744444444444444,"2659531e-eb9d-4dd5-b46f-10f66a4819c6":11.474603174603175,"70900ce7-fd5e-4779-a73d-8bdc42cfb3ff":11.025396825396829,"748a2ab3-8b5f-4d0a-9e2d-af685089843a":11.003571428571432,"ebac2b26-3187-4435-88a2-049cb5463806":0},"topic":["transmit","code","antenna","spacetim","block"],"groups":[{"authors":["Vahid Tarokh","Ayman Fawzy Naguib","N. Seshadri","A.R. Calderbank"],"references":["3b1d2129-0052-4784-a04f-3d5318d511c6","7304d3ba-add0-42b8-99af-f5e5f9b6b73b","748a2ab3-8b5f-4d0a-9e2d-af685089843a","ae2484ac-64a1-4b9f-a99b-f4e2e7b5fb52","bda089d6-05fc-41fe-a427-41ee1d7a085b","ebac2b26-3187-4435-88a2-049cb5463806","fe2e6a43-3995-4fdd-b516-09bb4d46c337"],"_id":"1c0fc247-3ed3-471c-9976-0ee93bf82e98","abstract":"Space-time coding is a bandwidth and power efficient method of communication over fading channels that realizes the benefits of multiple transmit antennas. Specific codes have been constructed using design criteria derived for quasi-static flat Rayleigh or Rician fading, where channel state information is available at the receiver. It is evident that the practicality of space-time codes will be greatly enhanced if the derived design criteria remain valid in the absence of perfect channel state information. It is even more desirable that the design criteria not be unduly sensitive to frequency selectivity and to the Doppler spread. This paper presents a theoretical study of these issues beginning with the effect of channel estimation error. Here it is assumed that a channel estimator extracts fade coefficients at the receiver and for constellations with constant energy, it is proved that in the absence of ideal channel state information the design criteria for space-time codes is still valid. The analysis also demonstrates that standard channel estimation techniques can be used in conjunction with space-time codes provided that the number of transmit antennas is small. We also derive the maximum-likelihood detection metric in the presence of channel estimation errors. Next, the effect of multiple paths on the performance of space-time codes is studied for a slowly changing Rayleigh channel. It is proved that the presence of multiple paths does not decrease the diversity order guaranteed by the design criteria used to construct the space-time codes. Similar results hold for rapid fading channels with or without multiple paths. The conclusion is that the diversity order promised by space-time coding is achieved under a variety of mobility conditions and environmental effects.","title":"Space-time codes for high data rate wireless communication: performance criteria in the presence of channel estimation errors, mobility, and multiple paths","venue":"IEEE Transactions on Communications","year":1999,"__v":0,"citationCount":228}],"offsprings":["720f59d2-acc3-4d5a-91c2-258d137d9647","7ae0e791-2e2b-4504-a2fe-caa9b0589c44"]},"33abc1fc-50ea-4837-a4a0-65c1d4c0e0b7":{"authors":["Guang-Bin Huang","Qin-Yu Zhu","Chee Kheong Siew"],"references":["3704f939-09a2-4e9f-b851-1261bcd310df","feff8862-f47d-4591-a7cb-b62d7efc81a2"],"_id":"33abc1fc-50ea-4837-a4a0-65c1d4c0e0b7","abstract":"It is clear that the learning speed of feedforward neural networks is in general far slower than required and it has been a major bottleneck in their applications for past decades. Two key reasons behind may be: (1) the slow gradient-based learning algorithms are extensively used to train neural networks, and (2) all the parameters of the networks are tuned iteratively by using such learning algorithms. Unlike these conventional implementations, this paper proposes a new learning algorithm called extreme learning machine (ELM) for single-hidden layer feedforward neural networks (SLFNs) which randomly chooses hidden nodes and analytically determines the output weights of SLFNs. In theory, this algorithm tends to provide good generalization performance at extremely fast learning speed. The experimental results based on a few artificial and real benchmark function approximation and classification problems including very large complex applications show that the new algorithm can produce good generalization performance in most cases and can learn thousands of times faster than conventional popular learning algorithms for feedforward neural networks. 1","title":"Extreme learning machine: Theory and applications","venue":"Neurocomputing","year":2006,"__v":0,"citationCount":1615,"parents":{"10b4d11c-49da-44b3-ae05-1521fac3a8d9":25,"2fbd5702-e66a-49ee-b3ea-c623158fe49e":0,"309ec4e0-df41-4901-a61b-b445ce82c695":41.66666666666667,"3704f939-09a2-4e9f-b851-1261bcd310df":0,"3e33fbf3-27a8-4468-99de-e1c678b90ef3":33.33333333333333,"4f3c1df8-c580-4d11-9a30-38df09f08dba":0,"9110d0c7-0255-4389-818e-fb62dfd7c26c":0,"9a1a8b29-548b-4d02-9339-0c88c7d02ea9":8.333333333333332,"da76ef1c-bfc2-4a9d-a8f9-4dbfcd64b5e4":16.666666666666664,"f195e480-9858-4875-a984-877172c14dc8":16.666666666666664,"f83e6d25-aa57-494f-a9fe-272878b73ec9":25,"feff8862-f47d-4591-a7cb-b62d7efc81a2":0},"keyword":{"10b4d11c-49da-44b3-ae05-1521fac3a8d9":11.153042328042327,"2fbd5702-e66a-49ee-b3ea-c623158fe49e":9.958955026455026,"309ec4e0-df41-4901-a61b-b445ce82c695":14.046825396825394,"3704f939-09a2-4e9f-b851-1261bcd310df":13.53174603174603,"3e33fbf3-27a8-4468-99de-e1c678b90ef3":11.464021164021164,"4f3c1df8-c580-4d11-9a30-38df09f08dba":0,"9110d0c7-0255-4389-818e-fb62dfd7c26c":13.41599206349206,"9a1a8b29-548b-4d02-9339-0c88c7d02ea9":11.249136604136604,"da76ef1c-bfc2-4a9d-a8f9-4dbfcd64b5e4":13.299735449735449,"f195e480-9858-4875-a984-877172c14dc8":11.318121693121693,"f83e6d25-aa57-494f-a9fe-272878b73ec9":10.69527417027417,"feff8862-f47d-4591-a7cb-b62d7efc81a2":10.938359788359788},"topic":["learn","algorithm","network","neural","gener"],"groups":[{"authors":["Guang-Bin Huang","Chee Kheong Siew"],"references":["4f3c1df8-c580-4d11-9a30-38df09f08dba","6f1b2ee2-0d43-4936-8efc-1ea14cafd696","8af54182-bed5-4224-b11d-a5ec3bbbb069","a10295e7-57c2-4a69-82f2-112e11876a50","b90f9310-726f-4116-9322-6fc01ab598fd","c1b6b493-01ef-420f-be44-7bacfe34e846","f195e480-9858-4875-a984-877172c14dc8","f83e6d25-aa57-494f-a9fe-272878b73ec9","feff8862-f47d-4591-a7cb-b62d7efc81a2"],"_id":"3e33fbf3-27a8-4468-99de-e1c678b90ef3","abstract":"A new learning algorithm called extreme learning machine (ELM) has recently been proposed for single-hidden layer feedforward neural networks (SLFNs) to easily achieve good generalization performance at extremely fast learning speed. ELM randomly chooses the input weights and analytically determines the output weights of SLFNs. This paper shows that ELM can be extended to radial basis function (RBF) network case, which allows the centers and impact widths of RBF kernels to be randomly generated and the output weights to be simply analytically calculated instead of iteratively tuned. Interestingly, the experimental results show that the ELM algorithm for RBF networks can complete learning at extremely fast speed and produce generalization performance very close to that of SVM in many artificial and real benchmarking function approximation and classification problems. Since ELM does not require validation and human-intervened parameters for given network architectures, ELM can be easily used.","title":"Extreme learning machine: RBF network case","venue":"international conference on control, automation, robotics and vision","year":2004,"__v":0,"citationCount":84},{"authors":["Guang-Bin Huang"],"references":["0fff9597-d6b0-4400-91fc-67e77efc51e0","218bbeff-4fb3-4f75-a54f-b64448027830","2fbd5702-e66a-49ee-b3ea-c623158fe49e","30362782-d7cc-47e7-8f08-19f0ed193e5a","43b756da-10b0-40b6-90cc-a65de183a59c","6f1b2ee2-0d43-4936-8efc-1ea14cafd696","9a1a8b29-548b-4d02-9339-0c88c7d02ea9","a44e6859-4530-4975-ad06-2c23a81e77fd","b905b535-c7ef-41bd-b0c8-ffa85cba61eb","c6161152-ee7d-4169-b10e-eeb74525dfc7","dbf2051f-a22b-4752-86c8-38721a2be681","e0417228-375a-424f-8301-2428512a37f2","ea294286-3cc2-4979-a22b-2fbb78c2ef18","f195e480-9858-4875-a984-877172c14dc8"],"_id":"f83e6d25-aa57-494f-a9fe-272878b73ec9","abstract":"The problem of the necessary complexity of neural networks is of interest in applications. In this paper, learning capability and storage capacity of feedforward neural networks are considered. We markedly improve the recent results by introducing neural-network modularity logically. This paper rigorously proves in a constructive method that two-hidden-layer feedforward networks (TLFNs) with 2/spl radic/(m+2)N (/spl Lt/N) hidden neurons can learn any N distinct samples (x/sub i/, t/sub i/) with any arbitrarily small error, where m is the required number of output neurons. It implies that the required number of hidden neurons needed in feedforward networks can be decreased significantly, comparing with previous results. Conversely, a TLFN with Q hidden neurons can store at least Q/sup 2//4(m+2) any distinct data (x/sub i/, t/sub i/) with any desired precision.","title":"Learning capability and storage capacity of two-hidden-layer feedforward networks","venue":"IEEE Transactions on Neural Networks","year":2003,"__v":0,"citationCount":159},{"authors":["Guang-Bin Huang","Yan Qiu Chen","Haroon A. Babri"],"references":["0fff9597-d6b0-4400-91fc-67e77efc51e0","10392bfd-5200-4471-9b5f-9fa093218936","2fbd5702-e66a-49ee-b3ea-c623158fe49e","79fd8d7a-d3c0-4ebf-b775-70432690a66d","8d7bb750-adbb-4a71-813f-09fdfab8f7d0","9a1a8b29-548b-4d02-9339-0c88c7d02ea9","b905b535-c7ef-41bd-b0c8-ffa85cba61eb","bc8df9ba-f160-4793-b56b-0f588217c4be","dbf2051f-a22b-4752-86c8-38721a2be681","ee06eb12-1cf5-4b1c-88c2-1bfbe423ac68","f195e480-9858-4875-a984-877172c14dc8"],"_id":"10b4d11c-49da-44b3-ae05-1521fac3a8d9","abstract":"Multilayer perceptrons with hard-limiting (signum) activation functions can form complex decision regions. It is well known that a three-layer perceptron (two hidden layers) can form arbitrary disjoint decision regions and a two-layer perceptron (one hidden layer) can form single convex decision regions. This paper further proves that single hidden layer feedforward neural networks (SLFN) with any continuous bounded nonconstant activation function or any arbitrary bounded (continuous or not continuous) activation function which has unequal limits at infinities (not just perceptrons) can form disjoint decision regions with arbitrary shapes in multidimensional cases, SLFN with some unbounded activation function can also form disjoint decision regions with arbitrary shapes.","title":"Classification ability of single hidden layer feedforward neural networks","venue":"IEEE Transactions on Neural Networks","year":2000,"__v":0,"citationCount":54},{"authors":["Guang-Bin Huang","Qin-Yu Zhu","Chee Kheong Siew"],"references":["0fff9597-d6b0-4400-91fc-67e77efc51e0","10b4d11c-49da-44b3-ae05-1521fac3a8d9","1a642cf3-caad-4cc2-ae3d-82f46013a0be","31a97738-f371-4eaf-a94d-acac8d5638fc","33abc1fc-50ea-4837-a4a0-65c1d4c0e0b7","46915939-2db4-4ebd-98c3-4ca2b6afd3e1","62919d32-6537-457a-b309-38af4ef51e64","703c6500-131c-445b-a445-081ef6ef5bb4","8d7bb750-adbb-4a71-813f-09fdfab8f7d0","9110d0c7-0255-4389-818e-fb62dfd7c26c","99dfb508-10c1-4e15-bb7c-daa4b7fe1e07","a9d2a35b-0909-44b3-9f10-9fb1d4d8bd88","b239338c-eba9-41b3-ba2a-1e74bf5c1f29","b70d59ec-0e5d-4788-a872-12bc887e4d08","c7e02d38-901f-40a1-9a92-a7bd5c655b56","d66b584a-cda4-4c9a-9c86-c3eab8094ed2","da76ef1c-bfc2-4a9d-a8f9-4dbfcd64b5e4","dbf2051f-a22b-4752-86c8-38721a2be681","f195e480-9858-4875-a984-877172c14dc8","f5682fa8-ab91-41c4-a461-b18152eec0e1","f5bd8964-005c-4620-a35c-0c7651996d43","f83e6d25-aa57-494f-a9fe-272878b73ec9","f933aafb-6554-463a-99fc-42fb53533135"],"_id":"309ec4e0-df41-4901-a61b-b445ce82c695","abstract":"In some practical applications of neural networks, fast response to external events within an extremely short time is highly demanded and expected. However, the extensively used gradient-descent-based learning algorithms obviously cannot satisfy the real-time learning needs in many applications, especially for large-scale applications and/or when higher generalization performance is required. Based on Huang's constructive network model, this paper proposes a simple learning algorithm capable of real-time learning which can automatically select appropriate values of neural quantizers and analytically determine the parameters (weights and bias) of the network at one time only. The performance of the proposed algorithm has been systematically investigated on a large batch of benchmark real-world regression and classification problems. The experimental results demonstrate that our algorithm can not only produce good generalization performance but also have real-time learning and prediction capability. Thus, it may provide an alternative approach for the practical applications of neural networks where real-time learning and prediction implementation is required.","title":"Real-time learning capability of neural networks","venue":"IEEE Transactions on Neural Networks","year":2006,"__v":0,"citationCount":71}],"offsprings":[]},"36c05ec1-7f89-44d4-a180-49820c36e4a0":{"authors":["Ian T. Foster","Carl Kesselman"],"references":[],"_id":"36c05ec1-7f89-44d4-a180-49820c36e4a0","abstract":"The Globus system is intended to achieve a vertically integrated treatment of application, middleware, and net work. A low-level toolkit provides basic mechanisms such as communication, authentication, network information, and data access. These mechanisms are used to con struct various higher level metacomputing services, such as parallel programming tools and schedulers. The long- term goal is to build an adaptive wide area resource environment AWARE, an integrated set of higher level services that enable applications to adapt to heteroge neous and dynamically changing metacomputing environ ments. Preliminary versions of Globus components were deployed successfully as part of the I-WAY networking experiment.","title":"Globus: a Metacomputing Infrastructure Toolkit","venue":"ieee international conference on high performance computing data and analytics","year":1997,"__v":0,"citationCount":1754,"parents":{"08606bae-eb29-4180-875f-03406bc0d7f2":0,"08cdcea0-6512-49e6-bbe1-31ad93e7d9a9":6.666666666666667,"12fd0e5f-adf6-4d18-a425-d6d025f3442a":13.333333333333334,"2b943995-6311-4a05-a54c-ee4bf62546cb":0,"441d7697-8548-4ee5-8f6d-2765c8492b7a":0,"498b44be-36b0-47ee-a7d2-91b1dbb32705":0,"72ecd564-096e-46b7-b793-98e7f3023e97":40,"7e8ec8cf-3f94-4aff-8f24-09b5b0d7a066":6.666666666666667,"914e0245-e455-45da-88f5-c623aa1a320d":46.666666666666664,"9553fde5-7523-4944-abb2-ce12a6d02afc":0,"ae05fedb-6c1f-44f0-82c7-30f9b7a9bfbd":13.333333333333334,"b245f533-070a-455f-82ea-ab059202c010":33.33333333333333,"b7aff680-9ef4-44af-ab5b-b8ae8ae42c76":6.666666666666667,"d0811c1c-0eb1-4112-8dc1-1e33e795f7af":6.666666666666667,"e4e92e07-a222-4386-9f7b-cdcf1ddaf2f3":0},"keyword":{"08606bae-eb29-4180-875f-03406bc0d7f2":10.001746031746032,"08cdcea0-6512-49e6-bbe1-31ad93e7d9a9":11.11142857142857,"12fd0e5f-adf6-4d18-a425-d6d025f3442a":11.679761904761905,"2b943995-6311-4a05-a54c-ee4bf62546cb":8.573929773929775,"441d7697-8548-4ee5-8f6d-2765c8492b7a":12.916190476190476,"498b44be-36b0-47ee-a7d2-91b1dbb32705":10.284126984126985,"72ecd564-096e-46b7-b793-98e7f3023e97":10.922150072150073,"7e8ec8cf-3f94-4aff-8f24-09b5b0d7a066":11.553174603174602,"914e0245-e455-45da-88f5-c623aa1a320d":7.859788359788361,"9553fde5-7523-4944-abb2-ce12a6d02afc":9.084126984126984,"ae05fedb-6c1f-44f0-82c7-30f9b7a9bfbd":10.621547619047618,"b245f533-070a-455f-82ea-ab059202c010":10.691746031746032,"b7aff680-9ef4-44af-ab5b-b8ae8ae42c76":9.183333333333334,"d0811c1c-0eb1-4112-8dc1-1e33e795f7af":10.537169312169311,"e4e92e07-a222-4386-9f7b-cdcf1ddaf2f3":10.39079365079365},"topic":["servic","network","metacomput","mechan","level"],"groups":[{"authors":["Steven M. Fitzgerald","Ian T. Foster","Carl Kesselman","G. von Laszewski","Warren Smith","Steve Tuecke"],"references":["00d513a1-1284-478e-8bff-a09241f48d21","021ae941-78c4-4004-bc8c-01ebf484049e","08cdcea0-6512-49e6-bbe1-31ad93e7d9a9","12fd0e5f-adf6-4d18-a425-d6d025f3442a","36c05ec1-7f89-44d4-a180-49820c36e4a0","72ecd564-096e-46b7-b793-98e7f3023e97","9553fde5-7523-4944-abb2-ce12a6d02afc","b7aff680-9ef4-44af-ab5b-b8ae8ae42c76","d0811c1c-0eb1-4112-8dc1-1e33e795f7af","e4e92e07-a222-4386-9f7b-cdcf1ddaf2f3"],"_id":"914e0245-e455-45da-88f5-c623aa1a320d","abstract":"High-performance execution in distributed computing environments often requires careful selection and configuration not only of computers, networks, and other resources but also of the protocols and algorithms used by applications. Selection and configuration in turn require access to accurate, up-to-date information on the structure and state of available resources. Unfortunately no standard mechanism exists for organizing or accessing such information. Consequently different tools and applications adopt ad hoc mechanisms, or they compromise their portability and performance by using default configurations. We propose a Metacomputing Directory Service that provides efficient and scalable access to diverse, dynamic, and distributed information about resource structure and state. We define an extensible data model to represent required information and present a scalable, high-performance, distributed implementation. The data representation and application programming interface are adopted from the Lightweight Directory Access Protocol; the data model and implementation are new. We use the Globus distributed computing toolkit to illustrate how this directory service enables the development of more flexible and efficient distributed computing services and applications.","title":"A directory service for configuring high-performance distributed computations","venue":"high performance distributed computing","year":1997,"__v":0,"citationCount":237},{"authors":["Ian T. Foster","Nicholas T. Karonis","Carl Kesselman","G. Koenig","Steven Tuecke"],"references":["08cdcea0-6512-49e6-bbe1-31ad93e7d9a9","2b20c0f9-333c-48d6-b9ed-5b79fa3f1468","2b943995-6311-4a05-a54c-ee4bf62546cb","40ca5274-ead5-4bb6-8177-120d74ac8d55","832becf4-e081-4d2f-a2b7-4b99dfeef3f0","8364a171-8d7b-4c04-a5b8-2323201e32bf","8fe53aa2-00c8-4446-b440-e94556d65286","914e0245-e455-45da-88f5-c623aa1a320d","98f5e5de-e7d2-4d72-b64f-0860f79d0dba","ae05fedb-6c1f-44f0-82c7-30f9b7a9bfbd","b7aff680-9ef4-44af-ab5b-b8ae8ae42c76"],"_id":"b245f533-070a-455f-82ea-ab059202c010","abstract":"Applications that use high-speed networks to connect geographically distributed supercomputers, databases, and scientific instruments may operate over open networks and access valuable resources. Hence, they can require mechanisms for ensuring integrity and confidentiality of communications and for authenticating both users and resources. Security solutions developed for traditional client-server applications do not provide direct support for the program structures, programming tools, and performance requirements encountered in these applications. We address these requirements via a security-enhanced version of the Nexus communication library, which we use to provide secure versions of parallel libraries and languages, including the Message Passing Interface. These tools permit a fine degree of control over what, where, and when security mechanisms are applied. In particular, a single application can mix secure and nonsecure communication allowing the programmer to make fine-grained security/performance tradeoffs. We present performance results that quantify the performance of our infrastructure.","title":"A secure communications infrastructure for high-performance distributed computing","venue":"high performance distributed computing","year":1997,"__v":0,"citationCount":21},{"authors":["Ian T. Foster","Jonathan Geisler","Carl Kesselman","Steven Tuecke"],"references":["021ae941-78c4-4004-bc8c-01ebf484049e","08606bae-eb29-4180-875f-03406bc0d7f2","08cdcea0-6512-49e6-bbe1-31ad93e7d9a9","22dc34f7-bd6a-4f3f-822c-6fe8d6d2bf43","2b20c0f9-333c-48d6-b9ed-5b79fa3f1468","2b943995-6311-4a05-a54c-ee4bf62546cb","3a2bcf1e-4982-4c29-b033-7ac11d053a0f","40ca5274-ead5-4bb6-8177-120d74ac8d55","64a09e89-4b68-4289-8f07-6a9449554acb","832becf4-e081-4d2f-a2b7-4b99dfeef3f0","98f5e5de-e7d2-4d72-b64f-0860f79d0dba","9a5963e9-f610-4140-8613-4ef2128c08fc","b245f533-070a-455f-82ea-ab059202c010","b7aff680-9ef4-44af-ab5b-b8ae8ae42c76","c67c9508-e4b3-41ea-9e3c-8b9c0a5bd211","cfbcc46b-765c-4e3a-82fd-cb602cbf71db","e4e92e07-a222-4386-9f7b-cdcf1ddaf2f3","f1111fa8-7f44-4ffc-b437-3d08f5e158ba"],"_id":"72ecd564-096e-46b7-b793-98e7f3023e97","abstract":"Modern networked computing environments and applications often require?or can benefit from?the use of multiple communication substrates, transport mechanisms, and protocols, chosen according to where communication is directed, what is communicated, or when communication is performed. We propose techniques that allow multiple communication methods to be supported transparently in a single application, with either automatic or user-specified selection criteria guiding the methods used for each communication. We explain how communication link and remote service request mechanisms facilitate the specification and implementation of multimethod communication. These mechanisms have been implemented in the Nexus multithreaded runtime system, and we use this system to illustrate solutions to various problems that arise when multimethod communication is implemented. We also illustrate the application of our techniques by describing a multimethod, multithreaded implementation of the Message Passing Interface (MPI) standard, constructed by integrating Nexus with the Argonne MPICH library. Finally, we present the results of experimental studies that reveal performance characteristics of multimethod communication, the Nexus-based MPI implementation, and a large scientific application running in a heterogeneous networked environment.","title":"Managing Multiple Communication Methods in High-Performance Networked Computing Systems","venue":"Journal of Parallel and Distributed Computing","year":1997,"__v":0,"citationCount":49}],"offsprings":[]},"3704f939-09a2-4e9f-b851-1261bcd310df":{"authors":["Yoav Freund","Robert E. Schapire"],"references":[],"_id":"3704f939-09a2-4e9f-b851-1261bcd310df","abstract":"In an earlier paper, we introduced a new \"boosting\" algorithm called AdaBoost which, theoretically, can be used to significantly reduce the error of any learning algorithm that con- sistently generates classifiers whose performance is a little better than random guessing. We also introduced the related notion of a \"pseudo-loss\" which is a method for forcing a learning algorithm of multi-label concepts to concentrate on the labels that are hardest to discriminate. In this paper, we describe experiments we carried out to assess how well AdaBoost with and without pseudo-loss, performs on real learning problems. We performed two sets of experiments. The first set compared boosting to Breiman's \"bagging\" method when used to aggregate various classifiers (including decision trees and single attribute- value tests). We compared the performance of the two methods on a collection of machine-learning benchmarks. In the second set of experiments, we studied in more detail the performance of boosting using a nearest-neighbor classifier on an OCR problem.","title":"Experiments with a New Boosting Algorithm","venue":"international conference on machine learning","year":1996,"__v":0,"citationCount":2720,"parents":{"056e5059-9864-479b-8a2a-fb1cd3d2dd32":6.666666666666667,"0f115eea-2272-431f-9f21-6d6789b2bbc9":0,"1d48d76c-e82c-4ba5-a354-5db0b1ce05da":20,"29a79d67-73a4-4990-9880-f9cc5b56c6f2":6.666666666666667,"4e80450b-37ed-440c-87cc-d17d27e0d892":13.333333333333334,"6613541b-7a68-4fe9-b6a5-7873004d40aa":6.666666666666667,"7a10be82-6113-4f60-9e37-f35f2d9423c5":0,"8b2c0aff-4589-4e0f-aae4-4f84a4413406":0,"a4a75c4c-0572-4ba6-adc7-bdbbd6fbcd37":20,"cf740e2c-f5bf-4e0c-8375-2948d6dff2c7":0,"d8ddd4ae-16ab-4702-b4f5-65aff0e33533":0,"db26488d-78be-44b1-a343-e896f43c5d29":40,"ea3e7ab3-e7c2-4007-93db-5c459bf3f42e":20,"eca46fc4-e594-461f-83b8-aa5247e440ca":0,"fc603eb6-d237-4584-842c-c80805f31370":0},"keyword":{"056e5059-9864-479b-8a2a-fb1cd3d2dd32":9.575793650793651,"0f115eea-2272-431f-9f21-6d6789b2bbc9":0,"1d48d76c-e82c-4ba5-a354-5db0b1ce05da":10.627301587301588,"29a79d67-73a4-4990-9880-f9cc5b56c6f2":11.93968253968254,"4e80450b-37ed-440c-87cc-d17d27e0d892":10.909682539682537,"6613541b-7a68-4fe9-b6a5-7873004d40aa":8.275396825396825,"7a10be82-6113-4f60-9e37-f35f2d9423c5":10.53015873015873,"8b2c0aff-4589-4e0f-aae4-4f84a4413406":11.8515873015873,"a4a75c4c-0572-4ba6-adc7-bdbbd6fbcd37":0,"cf740e2c-f5bf-4e0c-8375-2948d6dff2c7":11.460317460317459,"d8ddd4ae-16ab-4702-b4f5-65aff0e33533":9.736904761904759,"db26488d-78be-44b1-a343-e896f43c5d29":0,"ea3e7ab3-e7c2-4007-93db-5c459bf3f42e":9.924999999999999,"eca46fc4-e594-461f-83b8-aa5247e440ca":10.56111111111111,"fc603eb6-d237-4584-842c-c80805f31370":10.86547619047619},"topic":["perform","set","method","learn","experi"],"groups":[{"authors":["Yoav Freund","Robert E. Schapire"],"references":["056e5059-9864-479b-8a2a-fb1cd3d2dd32","06d6d936-6a8d-43ba-8d6a-f032ee0c09c3","1d48d76c-e82c-4ba5-a354-5db0b1ce05da","1f61a4c8-87fa-45d9-bd6b-14c5b815f1bc","3704f939-09a2-4e9f-b851-1261bcd310df","505f493b-e09d-444d-9ee2-5e5db6a5b8ac","50d6ceff-8829-44e3-a8a0-96b69b1805b4","570585ca-59b2-489b-9945-ad3850ecd487","6613541b-7a68-4fe9-b6a5-7873004d40aa","a8f17d49-3bef-4ccb-8e4c-6fc27d99a8db","cf740e2c-f5bf-4e0c-8375-2948d6dff2c7","ea294286-3cc2-4979-a22b-2fbb78c2ef18","eca46fc4-e594-461f-83b8-aa5247e440ca","f00fc370-0854-4967-bc6a-83b6c49da8bf","fc603eb6-d237-4584-842c-c80805f31370"],"_id":"db26488d-78be-44b1-a343-e896f43c5d29","title":"A decision-theoretic generalization of on-line learning and an application to boosting","venue":"computational learning theory","year":1995,"abstract":"","__v":0,"citationCount":4344}],"offsprings":["7b57db11-7c4d-4d1e-aa62-3a5d7d1f7987","d130ecec-e5cf-4f59-b4f8-1cbda4b0c307","f6bd8b64-684d-429a-aab5-8ff3a2c23cd6","d28acb36-5766-4c1e-8d57-a55c2630bd90","33abc1fc-50ea-4837-a4a0-65c1d4c0e0b7","310cbba4-d88d-4bf4-a4f2-738f91b5f8c8"]},"3939cb96-d8c8-4ec4-8102-bbce2976aeee":{"authors":["Nissanka Bodhi Priyantha","Anit Chakraborty","Hari Balakrishnan"],"references":["f8a9df79-9be7-4333-a71c-327040f67fcd"],"_id":"3939cb96-d8c8-4ec4-8102-bbce2976aeee","abstract":"This paper presents the design, implementation, and evaluation of  Cricket , a location-support system for in-building, mobile, location-dependent applications. It allows applications running on mobile and static nodes to learn their physical location by using  listeners  that hear and analyze information from  beacons  spread throughout the building. Cricket is the result of several design goals, including user privacy, decentralized administration, network heterogeneity, and low cost. Rather than explicitly tracking user location, Cricket helps devices learn where they are and lets them decide whom to advertise this information to; it does not rely on any centralized management or control and there is no explicit coordination between beacons; it provides information to devices regardless of their type of network connectivity; and each Cricket device is made from off-the-shelf components and costs less than U.S. $10. We describe the randomized algorithm used by beacons to transmit information, the use of concurrent radio and ultrasonic signals to infer distance, the listener inference algorithms to overcome multipath and interference, and practical beacon configuration and positioning techniques that improve accuracy. Our experience with Cricket shows that several location-dependent applications such as in-building active maps and device control can be developed with little effort or manual configuration.","title":"The Cricket location-support system","venue":"acm ieee international conference on mobile computing and networking","year":2000,"__v":0,"citationCount":1687,"parents":{"31c5e39a-3f24-4d20-bf8c-3d00036baf95":0,"4f5530bf-de86-4f1d-a55f-24202a7aa691":42.857142857142854,"6500989e-b1e1-4b02-a921-21ec25685b73":14.285714285714285,"6825e7be-db72-4377-a599-6667ef0bd553":14.285714285714285,"883985ce-380b-435d-9cb8-0c961ebd2c28":14.285714285714285,"f8a9df79-9be7-4333-a71c-327040f67fcd":14.285714285714285,"fd51d78a-e2f5-46b6-b041-4dae9aebdc76":0},"keyword":{"31c5e39a-3f24-4d20-bf8c-3d00036baf95":0,"4f5530bf-de86-4f1d-a55f-24202a7aa691":10.033333333333333,"6500989e-b1e1-4b02-a921-21ec25685b73":11.48357142857143,"6825e7be-db72-4377-a599-6667ef0bd553":7.353968253968255,"883985ce-380b-435d-9cb8-0c961ebd2c28":11.068253968253968,"f8a9df79-9be7-4333-a71c-327040f67fcd":8.296825396825398,"fd51d78a-e2f5-46b6-b041-4dae9aebdc76":8.325},"topic":["cricket","inform","devic","beacon","applic"],"groups":[{"authors":["Nirupama Bulusu","John S. Heidemann","Deborah Estrin"],"references":["6825e7be-db72-4377-a599-6667ef0bd553","f8a9df79-9be7-4333-a71c-327040f67fcd","fd51d78a-e2f5-46b6-b041-4dae9aebdc76"],"_id":"4f5530bf-de86-4f1d-a55f-24202a7aa691","abstract":"Instrumenting the physical world through large networks of wireless sensor nodes, particularly for applications like environmental monitoring of water and soil, requires that these nodes be very small, lightweight, untethered, and unobtrusive. The problem of localization, that is, determining where a given node is physically located in a network, is a challenging one, and yet extremely crucial for many of these applications. Practical considerations such as the small size, form factor, cost and power constraints of nodes preclude the reliance on GPS of all nodes in these networks. We review localization techniques and evaluate the effectiveness of a very simple connectivity metric method for localization in outdoor environments that makes use of the inherent RF communications capabilities of these devices. A fixed number of reference points in the network with overlapping regions of coverage transmit periodic beacon signals. Nodes use a simple connectivity metric, which is more robust to environmental vagaries, to infer proximity to a given subset of these reference points. Nodes localize themselves to the centroid of their proximate reference points. The accuracy of localization is then dependent on the separation distance between two-adjacent reference points and the transmission range of these reference points. Initial experimental results show that the accuracy for 90 percent of our data points is within one-third of the separation distance. However, future work is needed to extend the technique to more cluttered environments.","title":"GPS-less low-cost outdoor localization for very small devices","venue":"IEEE Personal Communications","year":2000,"__v":0,"citationCount":1400}],"offsprings":["f3267c01-b670-4b7a-a3a5-79088c0d90ab"]},"3a8fbc53-3805-4e6f-9f45-6881b640eb5e":{"authors":["Yuri Boykov","Vladimir Kolmogorov"],"references":["1317365d-c46d-4c09-8261-9d07404e4908","1f520d1a-5870-477d-85d7-0f50be690ea7"],"_id":"3a8fbc53-3805-4e6f-9f45-6881b640eb5e","abstract":"Minimum cut/maximum flow algorithms on graphs have emerged as an increasingly useful tool for exactor approximate energy minimization in low-level vision. The combinatorial optimization literature provides many min-cut/max-flow algorithms with different polynomial time complexity. Their practical efficiency, however, has to date been studied mainly outside the scope of computer vision. The goal of this paper is to provide an experimental comparison of the efficiency of min-cut/max flow algorithms for applications in vision. We compare the running times of several standard algorithms, as well as a new algorithm that we have recently developed. The algorithms we study include both Goldberg-Tarjan style \"push -relabel\" methods and algorithms based on Ford-Fulkerson style \"augmenting paths.\" We benchmark these algorithms on a number of typical graphs in the contexts of image restoration, stereo, and segmentation. In many cases, our new algorithm works several times faster than any of the other methods, making near real-time performance possible. An implementation of our max-flow/min-cut algorithm is available upon request for research purposes.","title":"An experimental comparison of min-cut/max- flow algorithms for energy minimization in vision","venue":"IEEE Transactions on Pattern Analysis and Machine Intelligence","year":2004,"__v":0,"citationCount":1971,"parents":{"01d5bd72-becb-4055-8874-f7c07244b763":8.333333333333332,"1317365d-c46d-4c09-8261-9d07404e4908":50,"1f520d1a-5870-477d-85d7-0f50be690ea7":20.833333333333336,"1f86ba16-96b1-4b41-84c3-47837bc04da2":0,"65f30c74-7499-4ca3-9a89-6b31655c5750":12.5,"6886264a-2e7a-4a5a-ae62-c740bc483621":4.166666666666666,"76845b3d-e45f-443c-a181-b1b75f17d47b":8.333333333333332,"78ee5ccf-613d-4a4b-8858-33c1cf0ef461":29.166666666666668,"7b8583e6-dbd3-4d2f-859a-f1de071886f2":0,"7d408177-f7a0-466a-b8e1-46eba464b7c9":0,"85471950-c85d-4494-ac99-30b5450ad095":8.333333333333332,"8f4f3015-c03d-46e1-90fb-2c42ea2cb91f":0,"942ceea1-92aa-4e72-94a7-bb65bb5889ed":12.5,"95e54ec2-04d3-4558-bbcd-69cd0c44f58a":16.666666666666664,"a6043444-3eb0-4dd0-90e4-e54bf5363250":12.5,"aca296a6-e562-4234-9d5d-62093dbc2910":0,"b74f8b0a-3956-40bb-9fa5-24d34ad705d4":0,"bcfb1417-4781-4c66-a6a0-ca2c8e1261a6":4.166666666666666,"c2dd1e3a-e1d4-456c-b1b8-6ddc2d66f1ee":16.666666666666664,"dd8087bb-bde1-4b8e-8ef0-3f8d0aabce9b":0,"eb24ab61-56e4-417c-8027-97c4760e8cfa":12.5,"f5de6b41-0df8-4270-8211-a67a081dad45":0,"f6706f16-c997-4b7f-a044-1d1a9f85dd51":0,"fc9a9ab5-7585-419a-8d2f-cdddd99a5c25":0},"keyword":{"01d5bd72-becb-4055-8874-f7c07244b763":8.007142857142856,"1317365d-c46d-4c09-8261-9d07404e4908":7.85462962962963,"1f520d1a-5870-477d-85d7-0f50be690ea7":10.149259259259258,"1f86ba16-96b1-4b41-84c3-47837bc04da2":7.343518518518518,"65f30c74-7499-4ca3-9a89-6b31655c5750":9.296137566137567,"6886264a-2e7a-4a5a-ae62-c740bc483621":10.416825396825397,"76845b3d-e45f-443c-a181-b1b75f17d47b":12.074444444444444,"78ee5ccf-613d-4a4b-8858-33c1cf0ef461":11.505767195767197,"7b8583e6-dbd3-4d2f-859a-f1de071886f2":7.597751322751322,"7d408177-f7a0-466a-b8e1-46eba464b7c9":11.669232804232806,"85471950-c85d-4494-ac99-30b5450ad095":11.923174603174601,"8f4f3015-c03d-46e1-90fb-2c42ea2cb91f":10.15537037037037,"942ceea1-92aa-4e72-94a7-bb65bb5889ed":9.80185185185185,"95e54ec2-04d3-4558-bbcd-69cd0c44f58a":10.155026455026453,"a6043444-3eb0-4dd0-90e4-e54bf5363250":10.441507936507938,"aca296a6-e562-4234-9d5d-62093dbc2910":0,"b74f8b0a-3956-40bb-9fa5-24d34ad705d4":8.573359788359788,"bcfb1417-4781-4c66-a6a0-ca2c8e1261a6":0,"c2dd1e3a-e1d4-456c-b1b8-6ddc2d66f1ee":8.769470899470901,"dd8087bb-bde1-4b8e-8ef0-3f8d0aabce9b":10.511851851851851,"eb24ab61-56e4-417c-8027-97c4760e8cfa":9.166087061087062,"f5de6b41-0df8-4270-8211-a67a081dad45":9.345370370370368,"f6706f16-c997-4b7f-a044-1d1a9f85dd51":9.6310582010582,"fc9a9ab5-7585-419a-8d2f-cdddd99a5c25":8.666296296296295},"topic":["algorithm","vision","time","style","studi"],"groups":[{"authors":["Vladimir Kolmogorov","Ramin Zabih"],"references":["004aa844-c144-4f34-b328-e054848d2c82","01d5bd72-becb-4055-8874-f7c07244b763","1317365d-c46d-4c09-8261-9d07404e4908","1b41d9a0-3857-4fb6-b7ba-d39da73c04dd","1bd0cfa8-b0e9-4ed1-973f-d251f147b4de","1f520d1a-5870-477d-85d7-0f50be690ea7","318a112e-0a86-4729-8605-200e06a2d6bd","37e76afb-f79f-41f8-b75d-28dadd7d5cd7","3a8fbc53-3805-4e6f-9f45-6881b640eb5e","477909c4-4d70-4a7d-a156-4fab18ed1434","6c9927be-dd3f-4a48-8ed6-b969a66e5c91","76845b3d-e45f-443c-a181-b1b75f17d47b","85471950-c85d-4494-ac99-30b5450ad095","8a4274f4-8925-4724-aca5-4f9c3455dc3e","8bf39ac5-01c0-4df7-99c3-12c96dc305e1","8f4f3015-c03d-46e1-90fb-2c42ea2cb91f","942ceea1-92aa-4e72-94a7-bb65bb5889ed","f37628db-beac-4a64-ab7b-cd0ce4f943a9","f6326193-ef92-4e64-8a4e-7439f8692fa1"],"_id":"78ee5ccf-613d-4a4b-8858-33c1cf0ef461","abstract":"We address the problem of computing the 3-dimensional shape of an arbitrary scene from a set of images taken at known viewpoints. Multi-camera scene reconstruction is a natural generalization of the stereo matching problem. However, it is much more difficult than stereo, primarily due to the difficulty of reasoning about visibility. In this paper, we take an approach that has yielded excellent results for stereo, namely energy minimization via graph cuts. We first give an energy minimization formulation of the multi-camera scene reconstruction problem. The energy that we minimize treats the input images symmetrically, handles visibility properly, and imposes spatial smoothness while preserving discontinuities. As the energy function is NP-hard to minimize exactly, we give a graph cut algorithm that computes a local minimum in a strong sense. We handle all camera configurations where voxel coloring can be used, which is a large and natural class. Experimental data demonstrates the effectiveness of our approach.","title":"Multi-camera Scene Reconstruction via Graph Cuts","venue":"european conference on computer vision","year":2002,"__v":0,"citationCount":362},{"authors":["Vladimir Kolmogorov","R. Zabin"],"references":["004aa844-c144-4f34-b328-e054848d2c82","01d5bd72-becb-4055-8874-f7c07244b763","19d21680-6bc5-4f6c-960e-d4788a6d1940","1b41d9a0-3857-4fb6-b7ba-d39da73c04dd","1f520d1a-5870-477d-85d7-0f50be690ea7","21cc7ac4-8d2a-4777-934a-fa1069ed73e1","28a2d956-0a04-4141-96d5-4f687ffb49ce","3630ebbb-a82a-435e-a5eb-b33d9fad26c9","37e76afb-f79f-41f8-b75d-28dadd7d5cd7","3a8fbc53-3805-4e6f-9f45-6881b640eb5e","6c5c8a75-af91-4f49-a9d7-b483a1fbe977","76845b3d-e45f-443c-a181-b1b75f17d47b","78ee5ccf-613d-4a4b-8858-33c1cf0ef461","78f0682e-5ec4-47e5-b77a-6842fb2f3c10","79359cb0-3770-480a-943b-fabb0f8da236","85471950-c85d-4494-ac99-30b5450ad095","8bb2c446-0081-4404-a944-56a0d5dc2f15","8f4f3015-c03d-46e1-90fb-2c42ea2cb91f","942ceea1-92aa-4e72-94a7-bb65bb5889ed","95aa9aa5-0113-491a-9440-2e538b844a7d","95e54ec2-04d3-4558-bbcd-69cd0c44f58a","a57c6dbb-09d2-4c2e-86ba-02e47e78f5af","aca296a6-e562-4234-9d5d-62093dbc2910","b1c2251e-7b54-41e5-8130-10d9646e02da","c2dd1e3a-e1d4-456c-b1b8-6ddc2d66f1ee","c521b560-aaae-4d30-9007-8eeeafd83966","cdd6b1f4-012f-4678-be03-b58ef5d7f710","d17921a4-9dbf-4708-b55e-23b35cd54544","d389a332-89d1-4565-afd5-349296debb2e","dd8087bb-bde1-4b8e-8ef0-3f8d0aabce9b","e4add357-1166-4eb9-9d37-ebd77264ce41","f5de6b41-0df8-4270-8211-a67a081dad45","ff1de60e-c014-4436-a163-f1b7aacf5301"],"_id":"1317365d-c46d-4c09-8261-9d07404e4908","abstract":"In the last few years, several new algorithms based on graph cuts have been developed to solve energy minimization problems in computer vision. Each of these techniques constructs a graph such that the minimum cut on the graph also minimizes the energy. Yet, because these graph constructions are complex and highly specific to a particular energy function, graph cuts have seen limited application to date. In this paper, we give a characterization of the energy functions that can be minimized by graph cuts. Our results are restricted to functions of binary variables. However, our work generalizes many previous constructions and is easily applicable to vision problems that involve large numbers of labels, such as stereo, motion, image restoration, and scene reconstruction. We give a precise characterization of what energy functions can be minimized using graph cuts, among the energy functions that can be written as a sum of terms containing three or fewer binary variables. We also provide a general-purpose construction to minimize such an energy function. Finally, we give a necessary condition for any energy function of binary variables to be minimized by graph cuts. Researchers who are considering the use of graph cuts to optimize a particular energy function can use our results to determine if this is possible and then follow our construction to create the appropriate graph. A software implementation is freely available.","title":"What energy functions can be minimized via graph cuts","venue":"european conference on computer vision","year":2004,"__v":0,"citationCount":1574}],"offsprings":["1317365d-c46d-4c09-8261-9d07404e4908","1f520d1a-5870-477d-85d7-0f50be690ea7"]},"41cf9713-ed76-43a6-8e9f-538abc2f787c":{"authors":["Gerard J. Holzmann"],"references":[],"_id":"41cf9713-ed76-43a6-8e9f-538abc2f787c","abstract":"SPIN is an efficient verification system for models of distributed software systems. It has been used to detect design errors in applications ranging from high-level descriptions of distributed algorithms to detailed code for controlling telephone exchanges. The paper gives an overview of the design and structure of the verifier, reviews its theoretical foundation, and gives an overview of significant practical applications.","title":"The model checker SPIN","venue":"formal methods","year":1997,"__v":0,"citationCount":1779,"parents":{"0778ba99-f32e-4b8f-a4c9-426f9da0cd33":0,"0b0c42ea-53d7-4d14-a5fb-873f0d3fccb2":0,"0c5c351d-d204-4a2d-87d3-5f2fa84bce58":8.571428571428571,"0f9c4e13-9c23-43c9-86ac-3a8a3afd8f50":11.428571428571429,"1032851c-2be4-4c4b-940d-58d72e859366":0,"1b460d2f-f577-4265-b2e1-0c26ef0c76ba":8.571428571428571,"29597bd7-43bd-4d38-89f8-cc2393958ccc":2.857142857142857,"2b06ba16-aa1e-45b7-89c6-b2551a64ab3a":8.571428571428571,"2b53a7fd-c6f4-461c-801f-bb0c206a172a":0,"2bb33756-67db-4329-8c0d-f3c5fdab2367":0,"3491feb2-bf31-4fde-b199-b652007cd999":0,"41cbbdb0-a994-4696-891f-94b529c99ff6":37.142857142857146,"56af74f2-31af-4c23-86e7-e7fcf7c6177e":5.714285714285714,"5e03c8e0-f95c-4885-9839-cc9725ef9b15":2.857142857142857,"5fd2c45b-9be0-4805-a635-c23a04cf1f66":5.714285714285714,"608876a3-9221-4c57-b4a5-2cde6991b305":5.714285714285714,"6214b428-db9c-41e5-bca2-98a543de3a22":0,"62422955-6a62-4898-bede-a2fc7927bfa5":11.428571428571429,"6f938b95-5818-412d-a1e4-e5d06ab311c0":14.285714285714285,"7143bdd1-f606-4e65-98a0-05dd2f214b31":0,"74e3fd8b-f955-4fde-aad8-0a705f05e27e":0,"7683c315-f31d-46e6-b216-9c62cc56746a":2.857142857142857,"80b714f5-a550-4b64-bbfb-e8eb19657082":5.714285714285714,"9025113c-4621-496b-b114-dbdaa4630df1":5.714285714285714,"a57ffe4b-6269-4521-80c1-198859880b1f":5.714285714285714,"a5bc4e7a-b439-4baf-a190-89fd5317b214":2.857142857142857,"aaf915d7-9da1-4adf-810e-7f436401f03d":0,"ad5f422f-6763-4c74-b273-88ea1af7f518":0,"ae1b3c60-5da7-4b30-adb8-9a743340c05a":0,"b05ca4d9-5937-4736-b45a-a7387e236cb6":0,"e1470f3d-df1b-4ac1-87ac-1e45b9064a2f":0,"eac1c0cb-beaa-46f9-ac77-56961ddf420a":5.714285714285714,"f1a4eee0-1900-4c87-8030-6e72b7701d88":5.714285714285714,"f2e96810-33a2-40a3-980b-e38257d5cdf7":0,"fdb4cbb6-3fb9-494c-bef8-d3260ea29879":8.571428571428571},"keyword":{"0778ba99-f32e-4b8f-a4c9-426f9da0cd33":10.187962962962963,"0b0c42ea-53d7-4d14-a5fb-873f0d3fccb2":10.667592592592593,"0c5c351d-d204-4a2d-87d3-5f2fa84bce58":11.818888888888887,"0f9c4e13-9c23-43c9-86ac-3a8a3afd8f50":0,"1032851c-2be4-4c4b-940d-58d72e859366":0,"1b460d2f-f577-4265-b2e1-0c26ef0c76ba":0,"29597bd7-43bd-4d38-89f8-cc2393958ccc":10.714126984126983,"2b06ba16-aa1e-45b7-89c6-b2551a64ab3a":9.862830687830687,"2b53a7fd-c6f4-461c-801f-bb0c206a172a":8.65978835978836,"2bb33756-67db-4329-8c0d-f3c5fdab2367":12.226785714285713,"3491feb2-bf31-4fde-b199-b652007cd999":11.09477513227513,"41cbbdb0-a994-4696-891f-94b529c99ff6":10.319444444444445,"56af74f2-31af-4c23-86e7-e7fcf7c6177e":11.460555555555556,"5e03c8e0-f95c-4885-9839-cc9725ef9b15":10.669047619047618,"5fd2c45b-9be0-4805-a635-c23a04cf1f66":10.374867724867725,"608876a3-9221-4c57-b4a5-2cde6991b305":10.215277777777777,"6214b428-db9c-41e5-bca2-98a543de3a22":9.210449735449737,"62422955-6a62-4898-bede-a2fc7927bfa5":0,"6f938b95-5818-412d-a1e4-e5d06ab311c0":9.869444444444445,"7143bdd1-f606-4e65-98a0-05dd2f214b31":10.340476190476188,"74e3fd8b-f955-4fde-aad8-0a705f05e27e":10.794708994708994,"7683c315-f31d-46e6-b216-9c62cc56746a":11.514788359788358,"80b714f5-a550-4b64-bbfb-e8eb19657082":0,"9025113c-4621-496b-b114-dbdaa4630df1":0,"a57ffe4b-6269-4521-80c1-198859880b1f":11.944907407407408,"a5bc4e7a-b439-4baf-a190-89fd5317b214":9.84457671957672,"aaf915d7-9da1-4adf-810e-7f436401f03d":11.869444444444442,"ad5f422f-6763-4c74-b273-88ea1af7f518":11.131944444444443,"ae1b3c60-5da7-4b30-adb8-9a743340c05a":10.251666666666665,"b05ca4d9-5937-4736-b45a-a7387e236cb6":10.521666666666667,"e1470f3d-df1b-4ac1-87ac-1e45b9064a2f":0,"eac1c0cb-beaa-46f9-ac77-56961ddf420a":7.6421957671957665,"f1a4eee0-1900-4c87-8030-6e72b7701d88":0,"f2e96810-33a2-40a3-980b-e38257d5cdf7":10.299444444444445,"fdb4cbb6-3fb9-494c-bef8-d3260ea29879":0},"topic":["system","overview","distribut","design","applic"],"groups":[{"authors":["Gerard J. Holzmann"],"references":["0778ba99-f32e-4b8f-a4c9-426f9da0cd33","0c5c351d-d204-4a2d-87d3-5f2fa84bce58","0ce0ff68-9121-4fa1-a53f-c6c844d63ee8","2108e3cd-4604-4056-b50e-84fd2f5a7fff","2b53a7fd-c6f4-461c-801f-bb0c206a172a","2bb33756-67db-4329-8c0d-f3c5fdab2367","4814eca2-167a-48bd-a7e6-60150e7a54e3","56af74f2-31af-4c23-86e7-e7fcf7c6177e","5fd2c45b-9be0-4805-a635-c23a04cf1f66","62422955-6a62-4898-bede-a2fc7927bfa5","7143bdd1-f606-4e65-98a0-05dd2f214b31","74e3fd8b-f955-4fde-aad8-0a705f05e27e","7683c315-f31d-46e6-b216-9c62cc56746a","9025113c-4621-496b-b114-dbdaa4630df1","ad5f422f-6763-4c74-b273-88ea1af7f518","c711a3aa-9c7d-4b1e-b65c-4ba7d3190e6e","c9583818-6585-465d-ad8a-22ef2fc8a3ef","cd96c7ec-6ef4-4fa8-ae09-c552d0d914c7","fdb4cbb6-3fb9-494c-bef8-d3260ea29879"],"_id":"41cbbdb0-a994-4696-891f-94b529c99ff6","abstract":"SPIN is an efficient, automated verification tool that can be used to design robust software for distributed systems in general, and bug-free communications protocols in particular. This paper outlines the use of the tool to address protocol design problems. As an example we consider the verification of a published protocol for implementing synchronous rendezvous operations in a distributed system. We also briefly review some of the techniques that SPIN employs to address the computational complexity of larger verification problems.","title":"Research: Designing bug-free protocols with SPIN","venue":"Computer Communications","year":1997,"__v":0,"citationCount":3}],"offsprings":["9849d9c4-a97f-452f-882c-42a8c6cab0b5"]},"443fb8d3-09ba-45a2-98a6-597799c3e63c":{"authors":["Tony F. Chan","Luminita A. Vese"],"references":["82eb55e6-39a8-4968-8be6-e2bfbb439a40"],"_id":"443fb8d3-09ba-45a2-98a6-597799c3e63c","abstract":"We propose a new model for active contours to detect objects in a given image, based on techniques of curve evolution, Mumford-Shah (1989) functional for segmentation and level sets. Our model can detect objects whose boundaries are not necessarily defined by the gradient. We minimize an energy which can be seen as a particular case of the minimal partition problem. In the level set formulation, the problem becomes a \"mean-curvature flow\"-like evolving the active contour, which will stop on the desired boundary. However, the stopping term does not depend on the gradient of the image, as in the classical active contour models, but is instead related to a particular segmentation of the image. We give a numerical algorithm using finite differences. Finally, we present various experimental results and in particular some examples for which the classical snakes methods based on the gradient are not applicable. Also, the initial curve can be anywhere in the image, and interior contours are automatically detected.","title":"Active contours without edges","venue":"IEEE Transactions on Image Processing","year":2001,"__v":0,"citationCount":2938,"parents":{"1c63e1d5-b963-455b-829d-e4f3eb63a36a":0,"1e96fa03-e4db-46de-a2e0-848ee4e9ec3b":33.33333333333333,"2ccb01b5-e59c-4ff4-b627-a76a72c9738c":33.33333333333333,"6c341eb6-f901-4353-b5ff-8da4ce990d11":11.11111111111111,"6ef77fc2-226f-4673-ad9d-21c17900b333":44.44444444444444,"81952b4c-f188-447a-a87c-90d281c83256":0,"82eb55e6-39a8-4968-8be6-e2bfbb439a40":33.33333333333333,"a7956261-026b-437c-bda7-b57849df8131":33.33333333333333,"b2de99a5-01d1-4359-be11-10c2ce130a05":11.11111111111111},"keyword":{"1c63e1d5-b963-455b-829d-e4f3eb63a36a":11.352380952380951,"1e96fa03-e4db-46de-a2e0-848ee4e9ec3b":11.038412698412698,"2ccb01b5-e59c-4ff4-b627-a76a72c9738c":11.625,"6c341eb6-f901-4353-b5ff-8da4ce990d11":10.850529100529101,"6ef77fc2-226f-4673-ad9d-21c17900b333":9.221349206349208,"81952b4c-f188-447a-a87c-90d281c83256":8.71547619047619,"82eb55e6-39a8-4968-8be6-e2bfbb439a40":9.678333333333331,"a7956261-026b-437c-bda7-b57849df8131":11.205952380952379,"b2de99a5-01d1-4359-be11-10c2ce130a05":11.156547619047618},"topic":["imag","contour","model","gradient","detect"],"groups":[{"authors":["Nikos Paragios","Rachid Deriche"],"references":["037b9625-bad7-41d3-be15-3d6d109298c2","088d00cf-ed12-4552-8958-8b550401f355","0c7c7fe9-5688-4b80-885b-cbdd174463c1","1006b1ae-fddc-42d7-b7e2-b31438f39036","2558f9f6-ead3-4898-bded-766a122bb18a","2ccb01b5-e59c-4ff4-b627-a76a72c9738c","337646db-f706-434a-9060-981cefeb760e","38789949-6265-4b86-8551-57986485035f","7bb95c4d-378a-4d0d-9538-a10fdcf1c4a8","82eb55e6-39a8-4968-8be6-e2bfbb439a40","a7da5f11-1302-4305-a67a-9503dea05eb7","b2de99a5-01d1-4359-be11-10c2ce130a05","d5deaeda-e87c-42de-9d28-b18b29b13778","d9adae7a-ff3d-4250-9b39-d4b4eafc7544","ecc70973-d45e-45d9-a8b0-88f9967d6afa","f432ad5d-c144-4802-860f-e0df7ca0f167"],"_id":"1e96fa03-e4db-46de-a2e0-848ee4e9ec3b","abstract":"This paper proposes a new front propagation method to deal accurately with the challenging problem of tracking non-rigid moving objects. This is obtained by employing a geodesic active region model where the designed objective function is composed of boundary and region-based terms and optimizes the curve position with respect to motion and intensity properties. The main novelty of our approach is that we deal with the motion estimation (linear models are assumed) and the tracking problem simultaneously. In other words, the optimization problem contains a coupled set of unknown variables; the curve position and the corresponding motion model. The designed objective function is minimized using a gradient descent method; the curve is propagated towards the object boundaries under the influence of boundary, intensity and motion-based forces using a PDE, while given the curve position an incremental analytical solution is obtained for the motion model. Besides, this PDE is implemented using a level set approach where topological changes are naturally handled. Very promising experimental results are provided using real video sequences.","title":"Geodesic active regions for motion estimation and tracking","venue":"international conference on computer vision","year":1999,"__v":0,"citationCount":80},{"authors":["Satyanad Kichenassamy","Arun Kumar","Peter J. Olver","Allen Tannenbaum","Anthony J. Yezzi"],"references":["1c63e1d5-b963-455b-829d-e4f3eb63a36a","82eb55e6-39a8-4968-8be6-e2bfbb439a40","b2de99a5-01d1-4359-be11-10c2ce130a05","b608af66-6368-44dc-a670-2a3e42561ee1","d3b8e209-d1a4-4900-a51f-da5abd8aa096"],"_id":"2ccb01b5-e59c-4ff4-b627-a76a72c9738c","abstract":"In this paper, we analyze the geometric active contour models discussed previously from a curve evolution point of view and propose some modifications based on gradient flows relative to certain new feature-based Riemannian metrics. This leads to a novel snake paradigm in which the feature of interest may be considered to lie at the bottom of a potential well. Thus the snake is attracted very naturally and efficiently to the desired feature. Moreover, we consider some 3-D active surface models based on these ideas. >","title":"Gradient flows and geometric active contour models","venue":"international conference on computer vision","year":1995,"__v":0,"citationCount":325},{"authors":["Vicent Caselles","Ron Kimmel","Guillermo Sapiro"],"references":["050ca16f-ca2a-4614-b2a1-6f56154238c0","1aab9f45-5ddc-407d-813d-ef41f63e6208","1c63e1d5-b963-455b-829d-e4f3eb63a36a","270de21e-f73e-44bb-a424-43441369f827","2ccb01b5-e59c-4ff4-b627-a76a72c9738c","3620aa43-c845-4b25-9da5-61a5d4f85609","36800655-b2ff-4eb7-9070-c6be304c4baa","36dd023a-14a7-479a-89c6-26d731dc5ae3","3f4cc95c-5f47-4031-8671-e23ff4fe2ed2","5b255d3a-5639-41cf-886b-8377bea8193f","61aa50fc-f75b-4246-9235-5e8e1b2846bc","85a39731-9a54-4d2c-9b92-d8ba04b28763","893791c5-4414-4db6-a307-472768e36e3b","8c80ee9a-3e0f-40a6-965c-d0a0fc3aa9d9","a32162d0-5f52-44b4-8bb1-be62d003f5d0","b1d5effd-27a3-417f-8ac3-8988e00c4558","b2de99a5-01d1-4359-be11-10c2ce130a05","b3c68e31-fa5b-49c8-9fac-bf19a78e41b6","c5e1a14b-3106-4195-820a-3d57b17a590b","e500049d-e42e-43a5-8e0c-4f57cdf91fa7","e89b3a55-ab36-4ed2-ae8f-cf297b58efa8","ef330947-bc34-4f55-834b-40469ee33769","f18355d4-bc52-48c8-bae0-309cb9d4307a","f4353d3d-9909-40cb-be04-9fc4d5ef8635","fc33562a-70e0-4279-887a-de8bc085d565"],"_id":"82eb55e6-39a8-4968-8be6-e2bfbb439a40","abstract":"A novel scheme for the detection of object boundaries is presented. The technique is based on active contours deforming according to intrinsic geometric measures of the image. The evolving contours naturally split and merge, allowing the simultaneous detection of several objects and both interior and exterior boundaries. The proposed approach is based on the relation between active contours and the computation of geodesics or minimal distance curves. The minimal distance curve lays in a Riemannian space whose metric as defined by the image content. This geodesic approach for object segmentation allows to connect classical \"snakes\" based on energy minimization and geometric active contours based on the theory of curve evolution. Previous models of geometric active contours are improved as showed by a number of examples. Formal results concerning existence, uniqueness, stability, and correctness of the evolution are presented as well. >","title":"Geodesic active contours","venue":"international conference on computer vision","year":1995,"__v":0,"citationCount":2129},{"authors":["Chenyang Xu","Jerry L. Prince"],"references":["1c63e1d5-b963-455b-829d-e4f3eb63a36a","2348054d-64ba-4368-8843-516baee03da0","35e3b8e6-40f0-4ea2-afcd-cb362e806d72","5db3ae5d-1bff-439d-b83f-147ba7ccacbb","7bb95c4d-378a-4d0d-9538-a10fdcf1c4a8","82eb55e6-39a8-4968-8be6-e2bfbb439a40","a4597637-1c95-48bf-8bbd-50a645dceb8e","b2de99a5-01d1-4359-be11-10c2ce130a05","c349411e-b528-42ba-b046-b2598b22fff7","c5bcce65-b1e9-4b96-ae68-6d24f71c86b5","e068d506-2794-4b94-9fc8-b1e72f6130d6","ef330947-bc34-4f55-834b-40469ee33769","fa353e4b-34d1-4c26-9e6f-ca17219e3610"],"_id":"a7956261-026b-437c-bda7-b57849df8131","abstract":"Snakes, or active contours, are used extensively in computer vision and image processing applications, particularly to locate object boundaries. Problems associated with initialization and poor convergence to boundary concavities, however, have limited their utility. This paper presents a new external force for active contours, largely solving both problems. This external force, which we call gradient vector flow (GVF), is computed as a diffusion of the gradient vectors of a gray-level or binary edge map derived from the image. It differs fundamentally from traditional snake external forces in that it cannot be written as the negative gradient of a potential function, and the corresponding snake is formulated directly from a force balance condition rather than a variational formulation. Using several two-dimensional (2-D) examples and one three-dimensional (3-D) example, we show that GVF has a large capture range and is able to move snakes into boundary concavities.","title":"Snakes, shapes, and gradient vector flow","venue":"IEEE Transactions on Image Processing","year":1998,"__v":0,"citationCount":1403},{"authors":["Kaleem Siddiqi","Yves Bérubé Lauzière","Allen Tannenbaum","Steven W. Zucker"],"references":["1a403aa4-1324-4023-ab41-6c07d7d6f9d4","1c63e1d5-b963-455b-829d-e4f3eb63a36a","2ccb01b5-e59c-4ff4-b627-a76a72c9738c","82eb55e6-39a8-4968-8be6-e2bfbb439a40","b1486dfb-e35c-4935-b77b-ffaaf0ffe880","b2de99a5-01d1-4359-be11-10c2ce130a05","db122157-6d15-4434-aba1-753e8486b1c6","f18355d4-bc52-48c8-bae0-309cb9d4307a"],"_id":"6ef77fc2-226f-4673-ad9d-21c17900b333","abstract":"A number of active contour models have been proposed that unify the curve evolution framework with classical energy minimization techniques for segmentation, such as snakes. The essential idea is to evolve a curve (in two dimensions) or a surface (in three dimensions) under constraints from image forces so that it clings to features of interest in an intensity image. The evolution equation has been derived from first principles as the gradient flow that minimizes a modified length functional, tailored to features such as edges. However, because the flow may be slow to converge in practice, a constant (hyperbolic) term is added to keep the curve/surface moving in the desired direction. We derive a modification of this term based on the gradient flow derived from a weighted area functional, with image dependent weighting factor. When combined with the earlier modified length gradient flow, we obtain a partial differential equation (PDE) that offers a number of advantages, as illustrated by several examples of shape segmentation on medical images. In many cases the weighted area flow may be used on its own, with significant computational savings.","title":"Area and length minimizing flows for shape segmentation","venue":"IEEE Transactions on Image Processing","year":1998,"__v":0,"citationCount":118}],"offsprings":[]},"4502aa3d-d723-4034-9418-cd6b851b8f05":{"authors":["Laurent Eschenauer","Virgil D. Gligor"],"references":[],"_id":"4502aa3d-d723-4034-9418-cd6b851b8f05","abstract":"Distributed Sensor Networks (DSNs) are ad-hoc mobile networks that include sensor nodes with limited computation and communication capabilities. DSNs are dynamic in the sense that they allow addition and deletion of sensor nodes after deployment to grow the network or replace failing and unreliable nodes. DSNs may be deployed in hostile areas where communication is monitored and nodes are subject to capture and surreptitious use by an adversary. Hence DSNs require cryptographic protection of communications, sensor-capture detection, key revocation and sensor disabling. In this paper, we present a key-management scheme designed to satisfy both operational and security requirements of DSNs. The scheme includes selective distribution and revocation of keys to sensor nodes as well as node re-keying without substantial computation and communication capabilities. It relies on probabilistic key sharing among the nodes of a random graph and uses simple protocols for shared-key discovery and path-key establishment, and for key revocation, re-keying, and incremental addition of nodes. The security and network connectivity characteristics supported by the key-management scheme are discussed and simulation experiments presented.","title":"A key-management scheme for distributed sensor networks","venue":"computer and communications security","year":2002,"__v":0,"citationCount":1570,"parents":{"444cf452-d568-4bd1-9f3a-dfabce2e58b9":0,"44b5a29a-1726-4923-9426-149975f4ddb0":14.285714285714285,"4ac80067-bbea-4eaf-8b7a-89c97db7ecfe":0,"8fd84396-c216-4cf5-91df-9f35aa31bf77":0,"acbe3bb4-00c0-417b-bb06-dd37efe5b0c4":0,"d12eae1e-96c0-4d0b-97d3-7e8624d5587a":28.57142857142857,"db009a21-2f63-4336-b079-0fa8e1a6f609":0},"keyword":{"444cf452-d568-4bd1-9f3a-dfabce2e58b9":8.713492063492064,"44b5a29a-1726-4923-9426-149975f4ddb0":9.388095238095238,"4ac80067-bbea-4eaf-8b7a-89c97db7ecfe":0,"8fd84396-c216-4cf5-91df-9f35aa31bf77":0,"acbe3bb4-00c0-417b-bb06-dd37efe5b0c4":11.61111111111111,"d12eae1e-96c0-4d0b-97d3-7e8624d5587a":11.11190476190476,"db009a21-2f63-4336-b079-0fa8e1a6f609":10.538359788359788},"topic":["node","sensor","dsn","network","kei"],"groups":[{"authors":["Carlo Blundo","Luiz A. Frota Mattos","Douglas R. Stinson"],"references":["14af76af-3c82-4c16-9522-15d888f97c62","3c7ea825-9351-4475-830d-ccafe4fd3f30","44b5a29a-1726-4923-9426-149975f4ddb0","4f1cffbd-ce5c-412f-9209-48d241143e3d","80902a7d-4361-4179-8f62-c387d4a32815","db009a21-2f63-4336-b079-0fa8e1a6f609"],"_id":"d12eae1e-96c0-4d0b-97d3-7e8624d5587a","abstract":"In 1993, Beimel and Chor presented an unconditionally secure interactive protocol which allows a subset of users in a network to establish it common key. This scheme made use of a key predistribution scheme due to Blom.#R##N##R##N#In this paper, we describe some variations and generalizations of the Beimel-Chor scheme, including broadcast encryption schemes as well as interactive key distribution schemes. Our constructions use the key predistribution scheme of Blundo et al, which is a generalization of the Blom scheme. We obtain families of schemes in which the amount of secret information held by the network users can be traded off against, the amount of information that needs to be broadcast.#R##N##R##N#We also discuss lower bounds on the storage and communication requirements of protocols of these types. Some of our schemes are optimal (or close to optimal) with respect to these bounds.","title":"Trade-offs Between Communication and Storage in Unconditionally Secure Schemes for Broadcast Encryption and Interactive Key Distribution","venue":"international cryptology conference","year":1996,"__v":0,"citationCount":60}],"offsprings":[]},"45abd8c1-38ec-44e4-bd25-2e467ef30e6e":{"authors":["Ingemar J. Cox","Joe Kilian","Frank Thomson Leighton","Talal Shamoon"],"references":[],"_id":"45abd8c1-38ec-44e4-bd25-2e467ef30e6e","abstract":"This paper presents a secure (tamper-resistant) algorithm for watermarking images, and a methodology for digital watermarking that may be generalized to audio, video, and multimedia data. We advocate that a watermark should be constructed as an independent and identically distributed (i.i.d.) Gaussian random vector that is imperceptibly inserted in a spread-spectrum-like fashion into the perceptually most significant spectral components of the data. We argue that insertion of a watermark under this regime makes the watermark robust to signal processing operations (such as lossy compression, filtering, digital-analog and analog-digital conversion, requantization, etc.), and common geometric transformations (such as cropping, scaling, translation, and rotation) provided that the original image is available and that it can be successfully registered against the transformed watermarked image. In these cases, the watermark detector unambiguously identifies the owner. Further, the use of Gaussian noise, ensures strong resilience to multiple-document, or collusional, attacks. Experimental results are provided to support these claims, along with an exposition of pending open problems.","title":"Secure spread spectrum watermarking for multimedia","venue":"IEEE Transactions on Image Processing","year":1997,"__v":0,"citationCount":1946,"parents":{"035b1fad-f8b2-4f45-9a63-8affec667f2b":0,"05f73279-fa9c-48ef-a9c2-91ac38caaf23":0,"3fb43b00-905c-4a08-934d-198ea4eb66c3":0,"559445a0-b91d-4bf8-b5d9-a24ff3bedf83":14.285714285714285,"5d4c616b-ba71-4696-8661-20fb57a818ae":7.142857142857142,"76517414-efc0-44ee-818a-c0982b0bd089":28.57142857142857,"91d90544-e1a6-4997-8ab6-65146bb15423":21.428571428571427,"98c25bb8-cc3d-4cdc-9189-1a249c8d0cdf":0,"a36cd635-6811-4a18-a424-46fd4719ae31":0,"b5bc85f7-6555-42ae-8697-67a1ab3cfca6":0,"d1acd492-fbee-441b-860f-6570452ddd27":0,"d2001e65-710d-4714-a5b7-b2a4f1559a5f":0,"d23ae5f9-2910-4c70-82c1-94667142ae0d":0,"f218b1cf-588f-497e-b201-2e67f554cb36":21.428571428571427},"keyword":{"035b1fad-f8b2-4f45-9a63-8affec667f2b":0,"05f73279-fa9c-48ef-a9c2-91ac38caaf23":9.804761904761904,"3fb43b00-905c-4a08-934d-198ea4eb66c3":8.023148148148149,"559445a0-b91d-4bf8-b5d9-a24ff3bedf83":0,"5d4c616b-ba71-4696-8661-20fb57a818ae":9.601851851851851,"76517414-efc0-44ee-818a-c0982b0bd089":0,"91d90544-e1a6-4997-8ab6-65146bb15423":11.194444444444446,"98c25bb8-cc3d-4cdc-9189-1a249c8d0cdf":12.453703703703704,"a36cd635-6811-4a18-a424-46fd4719ae31":11.074735449735448,"b5bc85f7-6555-42ae-8697-67a1ab3cfca6":0,"d1acd492-fbee-441b-860f-6570452ddd27":12.402777777777779,"d2001e65-710d-4714-a5b7-b2a4f1559a5f":11.893518518518515,"d23ae5f9-2910-4c70-82c1-94667142ae0d":9.63888888888889,"f218b1cf-588f-497e-b201-2e67f554cb36":0},"topic":["watermark","imag","transform","insert","gaussian"],"groups":[{"authors":["Ingemar J. Cox","Joe Kilian","Tom Leighton","Talal Shamoon"],"references":["5d4c616b-ba71-4696-8661-20fb57a818ae","d2001e65-710d-4714-a5b7-b2a4f1559a5f","d23ae5f9-2910-4c70-82c1-94667142ae0d"],"_id":"91d90544-e1a6-4997-8ab6-65146bb15423","abstract":"We describe a digital watermarking method for use in audio, image, video and multimedia data. We argue that a watermark must be placed in perceptually significant components of a signal if it is to be robust to common signal distortions and malicious attack. However, it is well known that modification of these components can lead to perceptual degradation of the signal. To avoid this, we propose to insert a watermark into the spectral components of the data using techniques analogous to spread spectrum communications, hiding a narrow band signal in a wideband channel that is the data. The watermark is difficult for an attacker to remove, even when several individuals conspire together with independently watermarked copies of the data. It is also robust to common signal and geometric distortions such as digital-to-analog and analog-to-digital conversion, resampling, quantization, dithering, compression, rotation, translation, cropping and scaling. The same digital watermarking algorithm can be applied to all three media under consideration with only minor modifications, making it especially appropriate for multimedia products. Retrieval of the watermark unambiguously identifies the owner, and the watermark can be constructed to make counterfeiting almost impossible. We present experimental results to support these claims.","title":"Secure spread spectrum watermarking for images, audio and video","venue":"international conference on image processing","year":1996,"__v":0,"citationCount":200}],"offsprings":[]},"3c383c6f-3503-458d-bdd7-a34cb8f4515f":{"authors":["John Shawe-Taylor","Nello Cristianini"],"references":[],"_id":"3c383c6f-3503-458d-bdd7-a34cb8f4515f","abstract":"Kernel methods provide a powerful and unified framework for pattern discovery, motivating algorithms that can act on general types of data (e.g. strings, vectors or text) and look for general types of relations (e.g. rankings, classifications, regressions, clusters). The application areas range from neural networks and pattern recognition to machine learning and data mining. This book, developed from lectures and tutorials, fulfils two major roles: firstly it provides practitioners with a large toolkit of algorithms, kernels and solutions ready to use for standard pattern discovery problems in fields such as bioinformatics, text analysis, image analysis. Secondly it provides an easy introduction for students and researchers to the growing field of kernel-based pattern analysis, demonstrating with examples how to handcraft an algorithm or a kernel for a new specific application, and covering all the necessary conceptual and mathematical tools to do so.","title":"Kernel Methods for Pattern Analysis","venue":"international conference on tools with artificial intelligence","year":2003,"__v":0,"citationCount":1987,"parents":{"17f811d8-8607-4270-bbec-1cc7883edd68":20,"24627c32-96e9-4f6d-8193-059b20e2f57e":20,"505f493b-e09d-444d-9ee2-5e5db6a5b8ac":0,"69290a10-a7e0-4985-92e2-44eee6f57813":0,"92031bfe-7728-41ae-a9f9-f323b522ef7f":10,"ac5715dc-05ba-45b6-873d-b06316a7bfd3":10,"c5783311-9935-45b7-af55-b9dbdb289187":0,"cac70218-0dec-488b-9928-419491c6eaa6":0,"db26488d-78be-44b1-a343-e896f43c5d29":10,"ef781e5f-5519-4a20-93fc-25f7d14039a1":30},"keyword":{"17f811d8-8607-4270-bbec-1cc7883edd68":8.788439153439153,"24627c32-96e9-4f6d-8193-059b20e2f57e":12.37111111111111,"505f493b-e09d-444d-9ee2-5e5db6a5b8ac":11.65757080610022,"69290a10-a7e0-4985-92e2-44eee6f57813":9.024074074074075,"92031bfe-7728-41ae-a9f9-f323b522ef7f":10.883862433862433,"ac5715dc-05ba-45b6-873d-b06316a7bfd3":8.88015873015873,"c5783311-9935-45b7-af55-b9dbdb289187":6.616666666666665,"cac70218-0dec-488b-9928-419491c6eaa6":10.742592592592594,"db26488d-78be-44b1-a343-e896f43c5d29":0,"ef781e5f-5519-4a20-93fc-25f7d14039a1":10.558994708994708},"topic":["pattern","kernel","analysi","algorithm","type"],"groups":[{"authors":["John Shawe-Taylor","Nello Cristianini"],"references":["0aa1672c-d63f-4968-92e1-336177a1a47e","17f811d8-8607-4270-bbec-1cc7883edd68","1b0c9eb0-d8e8-49bf-80a6-14f408b845b5","1b2e0d5e-adfe-40f5-8b77-36d03ec7c5d2","1f73723c-b904-4d93-8045-d8de3772fb27","24627c32-96e9-4f6d-8193-059b20e2f57e","29e06cb4-0ae3-4c7b-863a-d63ced9b1fa2","3b579a69-f762-4472-bf15-9a896f668081","4a29b56b-b74e-4945-9017-61a7ab844fd9","50dd56db-151d-4d62-8576-65f0ef6f381b","5ee879b9-9364-4d66-a1b4-41b9ad487485","69290a10-a7e0-4985-92e2-44eee6f57813","8af54182-bed5-4224-b11d-a5ec3bbbb069","94d945a1-ed15-4c62-a4b5-3045007aa516","97684b69-4da6-4fb3-b40c-32c58752f708","bb0530f9-f248-43b4-a465-d738806b20f4","dd5a3ef5-9d44-4dde-bcdb-dc4d17c69073","f006e236-59ad-4647-a59f-4f46dc2c85be"],"_id":"ef781e5f-5519-4a20-93fc-25f7d14039a1","abstract":"Generalization bounds depending on the margin of a classifier are a relatively new development. They provide an explanation of the performance of state-of-the-art learning systems such as support vector machines (SVMs) and Adaboost. The difficulty with these bounds has been either their lack of robustness or their looseness. The question of whether the generalization of a classifier can be more tightly bounded in terms of a robust measure of the distribution of margin values has remained open for some time. The paper answers this open question in the affirmative and, furthermore, the analysis leads to bounds that motivate the previously heuristic soft margin SVM algorithms as well as justifying the use of the quadratic loss in neural network training algorithms. The results are extended to give bounds for the probability of failing to achieve a target accuracy in regression prediction, with a statistical analysis of ridge regression and Gaussian processes as a special case. The analysis presented in the paper has also lead to new boosting algorithms described elsewhere.","title":"On the generalization of soft margin algorithms","venue":"IEEE Transactions on Information Theory","year":2002,"__v":0,"citationCount":30},{"authors":["John Shawe-Taylor","Peter L. Bartlett","Robert C. Williamson","Martin Anthony"],"references":["007cf08c-7de6-437c-ae53-8b41e276a9a6","13ad2583-bc27-4f65-81c1-a4d2d211cfa7","2653fe86-c496-460f-b902-42bff2101a9b","28d369a6-262d-41a0-a075-f931780cfd0d","3b579a69-f762-4472-bf15-9a896f668081","4a4aaf60-3c7c-4692-b50d-756680a32666","50dd56db-151d-4d62-8576-65f0ef6f381b","52958d61-f940-4ec8-8ee0-fc2898166ff5","59b13e19-3295-4a32-b0ac-04b42af656ba","69290a10-a7e0-4985-92e2-44eee6f57813","6fe13464-786c-4668-8c16-5b0461042e78","78bf672c-20ca-4bf8-9192-193eea2abd1f","7a33a45a-dbc3-4d8e-a5ae-6b3c8b21a6ed","97048a44-a841-4e49-ad9d-4a322ceb5db6","b70971da-e6ea-4e0f-9742-f60a259c6c63","b7b8d8c6-1f40-43a9-adb4-11a488743354","baabcffe-cedb-4a58-9592-1d4b3651e1f9","c6eb4f74-fb55-4fb3-85ac-5e9e95ee9f8a","c87f28bf-a14e-4547-a833-548cd88d5c2b","cac70218-0dec-488b-9928-419491c6eaa6","d1769ea5-e381-45f0-935c-ad19585718ea","e0cbdcfd-80c2-4ec2-9c0b-0bcb85843511","e85a4f52-0e1c-447b-98b4-33ec8b9ee6f3","ea98bd3b-fe01-4584-b5bc-4b7eacf78d47","f006e236-59ad-4647-a59f-4f46dc2c85be","fd0b4dea-6e59-444f-8d1e-0f2a4e6b75b6"],"_id":"24627c32-96e9-4f6d-8193-059b20e2f57e","abstract":"The paper introduces some generalizations of Vapnik's (1982) method of structural risk minimization (SRM). As well as making explicit some of the details on SRM, it provides a result that allows one to trade off errors on the training sample against improved generalization performance. It then considers the more general case when the hierarchy of classes is chosen in response to the data. A result is presented on the generalization performance of classifiers with a \"large margin\". This theoretically explains the impressive generalization performance of the maximal margin hyperplane algorithm of Vapnik and co-workers (which is the basis for their support vector machines). The paper concludes with a more general result in terms of \"luckiness\" functions, which provides a quite general way for exploiting serendipitous simplicity in observed data to obtain better prediction accuracy from small training sets. Four examples are given of such functions, including the Vapnik-Chervonenkis (1971) dimension measured on the sample.","title":"Structural risk minimization over data-dependent hierarchies","venue":"IEEE Transactions on Information Theory","year":1998,"__v":0,"citationCount":211}],"offsprings":[]},"51af4708-b81c-4362-b4ee-7bdf7ace609f":{"authors":["John R. Douceur"],"references":[],"_id":"51af4708-b81c-4362-b4ee-7bdf7ace609f","abstract":"Large-scale peer-to-peer systems face security threats from faulty or hostile remote computing elements. To resist these threats, many such systems employ redundancy. However, if a single faulty entity can present multiple identities, it can control a substantial fraction of the system, thereby undermining this redundancy. One approach to preventing these \"Sybil attacks\" is to have a trusted agency certify identities. This paper shows that, without a logically centralized authority, Sybil attacks are always possible except under extreme and unrealistic assumptions of resource parity and coordination among entities.","title":"The Sybil Attack","venue":"international workshop on peer to peer systems","year":2002,"__v":0,"citationCount":1511,"parents":{"19919bce-f848-407c-8b3f-3860509f6b1d":0,"1c729f22-9928-4703-92a0-8819569a1bbb":4.761904761904762,"1dda408f-2203-4793-bfa8-2fab15bce7cf":0,"1e7e39e3-3221-46e0-a63d-46c5a68a2508":4.761904761904762,"42c70869-0dad-4629-93b5-a2d9e29071a7":0,"532a17ef-5f37-4ead-9f4d-2fd31369966e":0,"5e354aca-2d93-43f7-8e80-6bc4eb96e7d9":19.047619047619047,"65c674fe-fc63-4ba0-a6c9-6a0153454889":9.523809523809524,"84f6b537-d4c6-4037-8dc1-5c7ed09ae42d":0,"85fcfea7-7537-48ad-b341-088d1df85666":4.761904761904762,"a3a44806-1b80-4340-a0e2-b0be96f09fc8":0,"ac0db18c-141b-499a-9499-bc11ed2a61bc":9.523809523809524,"b68fc787-7817-421e-8e66-8a98ab9db1ad":0,"b7d7ec53-f079-4bd7-a795-8b6fe77f2db6":19.047619047619047,"c0ea675b-2479-48ae-817e-3ecedd175ecf":0,"cb9366cf-ed14-4458-9bcd-756bf6359983":9.523809523809524,"ccc96384-6f47-49ab-8694-5b0240c32c26":0,"d893a420-a00d-4756-b447-2862ed178eaa":0,"e7b8eca5-008a-47f1-ba38-ed1341349c53":0,"e918eea0-d18d-4007-b811-ddb842286269":0,"ea1c24ee-716a-47b5-bf9b-76fcbca6ea16":9.523809523809524},"keyword":{"19919bce-f848-407c-8b3f-3860509f6b1d":7.712777777777777,"1c729f22-9928-4703-92a0-8819569a1bbb":9.122222222222224,"1dda408f-2203-4793-bfa8-2fab15bce7cf":9.277777777777779,"1e7e39e3-3221-46e0-a63d-46c5a68a2508":0,"42c70869-0dad-4629-93b5-a2d9e29071a7":11.101111111111113,"532a17ef-5f37-4ead-9f4d-2fd31369966e":10.635238095238096,"5e354aca-2d93-43f7-8e80-6bc4eb96e7d9":8.243333333333332,"65c674fe-fc63-4ba0-a6c9-6a0153454889":10.812592592592594,"84f6b537-d4c6-4037-8dc1-5c7ed09ae42d":8.620000000000001,"85fcfea7-7537-48ad-b341-088d1df85666":11.035952380952383,"a3a44806-1b80-4340-a0e2-b0be96f09fc8":9.705555555555556,"ac0db18c-141b-499a-9499-bc11ed2a61bc":10.119444444444445,"b68fc787-7817-421e-8e66-8a98ab9db1ad":7.125079365079366,"b7d7ec53-f079-4bd7-a795-8b6fe77f2db6":6.855555555555556,"c0ea675b-2479-48ae-817e-3ecedd175ecf":0,"cb9366cf-ed14-4458-9bcd-756bf6359983":10.723703703703702,"ccc96384-6f47-49ab-8694-5b0240c32c26":11.158412698412697,"d893a420-a00d-4756-b447-2862ed178eaa":12.31222222222222,"e7b8eca5-008a-47f1-ba38-ed1341349c53":10.25656204906205,"e918eea0-d18d-4007-b811-ddb842286269":10.498888888888889,"ea1c24ee-716a-47b5-bf9b-76fcbca6ea16":9.546137566137565},"topic":["system","threat","sybil","redund","ident"],"offsprings":["cb5922c5-575b-4b50-8d58-809f8256e948"]},"9849d9c4-a97f-452f-882c-42a8c6cab0b5":{"authors":["Rajeev Alur","Kousha Etessami","P. Madhusudan"],"references":["41cf9713-ed76-43a6-8e9f-538abc2f787c"],"_id":"9849d9c4-a97f-452f-882c-42a8c6cab0b5","abstract":"Model checking of linear temporal logic (LTL) specifications with respect to pushdown systems has been shown to be a useful tool for analysis of programs with potentially recursive procedures. LTL, how- ever, can specify only regular properties, and properties such as correct- ness of procedures with respect to pre and post conditions, that require matching of calls and returns, are not regular. We introduce a tempo- ral logic of calls and returns (CaRet) for specification and algorithmic verification of correctness requirements of structured programs. The for- mulas of CaRet are interpreted over sequences of propositional valu- ations tagged with special symbols call and ret. Besides the standard global temporal modalities, CaRet admits the abstract-next operator that allows a path to jump from a call to the matching return. This op- erator can be used to specify a variety of non-regular properties such as partial and total correctness of program blocks with respect to pre and post conditions. The abstract versions of the other temporal modalities can be used to specify regular properties of local paths within a proce- dure that skip over calls to other procedures. CaRet also admits the caller modality that jumps to the most recent pending call, and such caller modalities allow specification of a variety of security properties that involve inspection of the call-stack. Even though verifying context- free properties of pushdown systems is undecidable, we show that model checking CaRet formulas against a pushdown model is decidable. We present a tableau construction that reduces our model checking problem to the emptiness problem for a Buchi pushdown system. The complexity of model checking CaRet formulas is the same as that of checking LTL formulas, namely, polynomial in the model and singly exponential in the size of the specification.","title":"A Temporal Logic of Nested Calls and Returns","venue":"tools and algorithms for construction and analysis of systems","year":2004,"__v":0,"citationCount":3137,"parents":{"029ec76f-4b8c-476a-8c77-3036d6b7b1f6":0,"09fc7b5d-9220-4088-bdac-eb79cddc9675":0,"0d4cc186-9c63-429b-85e4-83b606481524":12.5,"16866840-a628-4b75-b3fd-b6321ac5afea":8.333333333333332,"1df30cd7-1d70-4a9c-b95b-0ff4deff5fbd":0,"28248831-d840-4a54-9fab-fe549977fe00":12.5,"2bb33756-67db-4329-8c0d-f3c5fdab2367":0,"31a873fd-bc11-430f-91ef-b8e4aa0a7c87":0,"35c8c06c-2ad0-46b4-9e92-2d684f3abd94":0,"39373ca0-3987-4dca-8c7a-182f1db17b4a":4.166666666666666,"41cf9713-ed76-43a6-8e9f-538abc2f787c":8.333333333333332,"509473ba-ad2f-4706-89fc-4e537252a8b8":8.333333333333332,"74e3fd8b-f955-4fde-aad8-0a705f05e27e":0,"877fd32f-56eb-4dac-a62f-df6a3694858e":0,"8f36f079-bc77-4428-acbd-e49eac0a6636":8.333333333333332,"9f006832-e8b6-4b96-b096-f1e58098d961":12.5,"bb28e8ef-624e-44cc-a791-53152af76e4d":25,"d8f45444-76c1-4b84-b909-918211b4bab4":4.166666666666666,"db1dbd30-7a91-4089-8928-a5bf06978d0d":0,"e2e62de3-82aa-40a1-8377-c191f3dc715c":0,"e4be6d6e-c041-4c30-aa59-0537278842b8":20.833333333333336,"f3d52f51-d5a2-472f-8f8a-71fe5ec8609d":16.666666666666664,"f5f1b6cd-64e7-428f-bd7a-90c92ed50bde":4.166666666666666,"fcc366e1-ddca-43df-ae8e-0b068926dc2f":0},"keyword":{"029ec76f-4b8c-476a-8c77-3036d6b7b1f6":7.7861111111111105,"09fc7b5d-9220-4088-bdac-eb79cddc9675":8.405555555555555,"0d4cc186-9c63-429b-85e4-83b606481524":7.259166666666667,"16866840-a628-4b75-b3fd-b6321ac5afea":7.1722222222222225,"1df30cd7-1d70-4a9c-b95b-0ff4deff5fbd":10.244444444444444,"28248831-d840-4a54-9fab-fe549977fe00":10.769444444444446,"2bb33756-67db-4329-8c0d-f3c5fdab2367":10.99126984126984,"31a873fd-bc11-430f-91ef-b8e4aa0a7c87":0,"35c8c06c-2ad0-46b4-9e92-2d684f3abd94":9.877738095238094,"39373ca0-3987-4dca-8c7a-182f1db17b4a":8.100833333333334,"41cf9713-ed76-43a6-8e9f-538abc2f787c":9.391666666666666,"509473ba-ad2f-4706-89fc-4e537252a8b8":9.581349206349204,"74e3fd8b-f955-4fde-aad8-0a705f05e27e":9.680952380952382,"877fd32f-56eb-4dac-a62f-df6a3694858e":0,"8f36f079-bc77-4428-acbd-e49eac0a6636":12.620555555555555,"9f006832-e8b6-4b96-b096-f1e58098d961":10.203174603174602,"bb28e8ef-624e-44cc-a791-53152af76e4d":10.279444444444445,"d8f45444-76c1-4b84-b909-918211b4bab4":8.211111111111112,"db1dbd30-7a91-4089-8928-a5bf06978d0d":0,"e2e62de3-82aa-40a1-8377-c191f3dc715c":8.655753968253968,"e4be6d6e-c041-4c30-aa59-0537278842b8":9.364365079365081,"f3d52f51-d5a2-472f-8f8a-71fe5ec8609d":12.484126984126984,"f5f1b6cd-64e7-428f-bd7a-90c92ed50bde":10.563359788359788,"fcc366e1-ddca-43df-ae8e-0b068926dc2f":0},"topic":["properti","model","caret","call","check"],"groups":[{"authors":["Rajeev Alur","Michael Benedikt","Kousha Etessami","Patrice Godefroid","Thomas W. Reps","Mihalis Yannakakis"],"references":["0d261b6a-c94a-4d5e-b44e-eb6ae46581fc","1414d6d0-ceae-425f-89b2-192442eb3f2b","261f3c61-02bc-4383-86b5-bf9b1a003190","28248831-d840-4a54-9fab-fe549977fe00","28a3f98b-0a26-4df5-97db-4aa3ca3bad16","31a873fd-bc11-430f-91ef-b8e4aa0a7c87","3639eec3-bb22-4498-a709-d34a5e6ed4c7","509473ba-ad2f-4706-89fc-4e537252a8b8","5e4f5f95-a58e-4c3e-b017-610425069a0c","8136f742-fabf-4dde-84c5-cca4c71d1057","86d78cf2-9421-4059-8122-e9d0414c8fa1","8aa57ab8-5135-4d74-8791-07fe51486a57","9849d9c4-a97f-452f-882c-42a8c6cab0b5","9db1ef3c-499c-4f7b-9366-f64a8f1b90f1","a1d3c7e9-7a8e-4f09-b912-51ef52200564","a2d395e2-b3b9-45fc-ae54-c157d0f3f315","c4b0caf0-7af5-4ce6-9ba2-305a02a1a07b","cb8c117f-5fc4-43a0-9dd7-bb668ba8b248","d6285e34-13fa-4327-b4f9-203181baa8c6","d8ad6c17-792b-4b59-9554-b295218e517e","d8f45444-76c1-4b84-b909-918211b4bab4","e2e62de3-82aa-40a1-8377-c191f3dc715c","e4be6d6e-c041-4c30-aa59-0537278842b8","f190832c-e721-4ec1-a7b0-66283702c29a","f9fbe00e-2980-4c0e-a9b1-4e62fd5fa383","fa07d114-8d42-4663-a53e-448e910206eb"],"_id":"bb28e8ef-624e-44cc-a791-53152af76e4d","abstract":"Recursive state machines (RSMs) enhance the power of ordinary state machines by allowing vertices to correspond either to ordinary states or to potentially recursive invocations of other state machines. RSMs can model the control flow in sequential imperative programs containing recursive procedure calls. They can be viewed as a visual notation extending Statecharts-like hierarchical state machines, where concurrency is disallowed but recursion is allowed. They are also related to various models of pushdown systems studied in the verification and program analysis communities.After introducing RSMs and comparing their expressiveness with other models, we focus on whether verification can be efficiently performed for RSMs. Our first goal is to examine the verification of linear time properties of RSMs. We begin this study by dealing with two key components for algorithmic analysis and model checking, namely, reachability (Is a target state reachable from initial states?) and cycle detection (Is there a reachable cycle containing an accepting state?). We show that both these problems can be solved in time  O ( n θ 2 ) and space  O ( n θ), where  n  is the size of the recursive machine and θ is the maximum, over all component state machines, of the minimum of the number of entries and the number of exits of each component. From this, we easily derive algorithms for linear time temporal logic model checking with the same complexity in the model. We then turn to properties in the branching time logic CTL*, and again demonstrate a bound linear in the size of the state machine, but only for the case of RSMs with a single exit node.","title":"Analysis of recursive state machines","venue":"ACM Transactions on Programming Languages and Systems","year":2005,"__v":0,"citationCount":140}],"offsprings":[]},"aa767a83-de19-4421-bfb4-f63808992758":{"authors":["Janez Demšar"],"references":[],"_id":"aa767a83-de19-4421-bfb4-f63808992758","abstract":"While methods for comparing two learning algorithms on a single data set have been scrutinized for quite some time already, the issue of statistical tests for comparisons of more algorithms on multiple data sets, which is even more essential to typical machine learning studies, has been all but ignored. This article reviews the current practice and then theoretically and empirically examines several suitable tests. Based on that, we recommend a set of simple, yet safe and robust non-parametric tests for statistical comparisons of classifiers: the Wilcoxon signed ranks test for comparison of two classifiers and the Friedman test with the corresponding post-hoc tests for comparison of more classifiers over multiple data sets. Results of the latter can also be neatly presented with the newly introduced CD (critical difference) diagrams.","title":"Statistical Comparisons of Classifiers over Multiple Data Sets","venue":"Journal of Machine Learning Research","year":2006,"__v":0,"citationCount":2751,"parents":{"056e5059-9864-479b-8a2a-fb1cd3d2dd32":0,"2c962c64-02d3-4f07-a5a8-62ba4ebc9b72":7.6923076923076925,"31a4f270-4929-4364-b8ca-66577c7f1517":0,"37cd167c-ab59-495a-b5b1-b9f841dea87c":0,"393d1d75-8679-423a-844b-d49e9937e4cc":0,"4b87b8df-828e-453c-b168-3c28f4cc9f7b":0,"513b3123-12c0-442f-b76f-d1291cfa35f5":7.6923076923076925,"594b4fe8-54fe-4f3c-aa4f-cdec07b9be2b":0,"6950a3d3-a17f-49d9-a87c-0f2e8126fc33":0,"b9111683-1151-4542-8a10-d1eeb730087e":0,"d20df5c3-667b-42d4-a128-d5f0b649cc32":0,"d697bd65-fc9d-43e5-8bdc-6d068cb6badf":0,"defc400c-738c-4e62-8943-7ffbab6bad9b":7.6923076923076925},"keyword":{"056e5059-9864-479b-8a2a-fb1cd3d2dd32":12.15373015873016,"2c962c64-02d3-4f07-a5a8-62ba4ebc9b72":9.167063492063495,"31a4f270-4929-4364-b8ca-66577c7f1517":8.799206349206349,"37cd167c-ab59-495a-b5b1-b9f841dea87c":7.9833333333333325,"393d1d75-8679-423a-844b-d49e9937e4cc":9.930555555555557,"4b87b8df-828e-453c-b168-3c28f4cc9f7b":8.846825396825395,"513b3123-12c0-442f-b76f-d1291cfa35f5":10.122222222222224,"594b4fe8-54fe-4f3c-aa4f-cdec07b9be2b":0,"6950a3d3-a17f-49d9-a87c-0f2e8126fc33":0,"b9111683-1151-4542-8a10-d1eeb730087e":0,"d20df5c3-667b-42d4-a128-d5f0b649cc32":0,"d697bd65-fc9d-43e5-8bdc-6d068cb6badf":11.438888888888892,"defc400c-738c-4e62-8943-7ffbab6bad9b":11.500000000000002},"topic":["test","set","comparison","data","classifi"],"offsprings":["83c737b8-e084-4766-ba6e-131e6a1c017c"]},"ab3afb93-8ca0-4556-ae60-11199dc263c2":{"authors":["Aude Oliva","Antonio Torralba"],"references":[],"_id":"ab3afb93-8ca0-4556-ae60-11199dc263c2","abstract":"In this paper, we propose a computational model of the recognition of real world scenes that bypasses the segmentation and the processing of individual objects or regions. The procedure is based on a very low dimensional representation of the scene, that we term the Spatial Envelope. We propose a set of perceptual dimensions (naturalness, openness, roughness, expansion, ruggedness) that represent the dominant spatial structure of a scene. Then, we show that these dimensions may be reliably estimated using spectral and coarsely localized information. The model generates a multidimensional space in which scenes sharing membership in semantic categories (e.g., streets, highways, coasts) are projected closed together. The performance of the spatial envelope model shows that specific information about object shape or identity is not a requirement for scene categorization and that modeling a holistic representation of the scene informs about its probable semantic category.","title":"Modeling the Shape of the Scene: A Holistic Representation of the Spatial Envelope","venue":"International Journal of Computer Vision","year":2001,"__v":0,"citationCount":2402,"parents":{"1ed2cc94-3d0b-4718-80b6-2528e814c921":0,"30614910-26a5-495c-8bb7-0f723c47db69":0,"4a29b56b-b74e-4945-9017-61a7ab844fd9":0,"58986749-f7f2-4c0c-a0f8-37180df48756":5.88235294117647,"5a6136c8-c73c-4a55-b231-d293bf1b12ee":0,"5eb1916a-bbf2-4413-b5ba-589c62877ac0":0,"65a76574-1ea8-4b1d-8d29-efe42d06446c":0,"6bc07db2-08e3-45a9-99c0-10391f57f6df":5.88235294117647,"6e8cc926-79a1-4676-a2bd-f9d49f3144cf":0,"82d0ec51-e40e-4602-b969-fc0b44464ac3":29.411764705882355,"94ce3d32-4057-4002-a3ef-6f87b0582802":0,"99f2c01b-6d49-4a93-8723-155698197ed6":0,"c027a810-02a3-415b-83ad-e48144273475":0,"cfe61dfb-59d6-4ee4-9324-e591f8cef78f":5.88235294117647,"d12c8fca-a82c-45db-b29c-8fc7a47fce2e":5.88235294117647,"ece37585-dc4e-492a-9f3c-0a143b0a5ab8":0,"f62a1da3-7675-446c-a327-86391e9cb02b":5.88235294117647},"keyword":{"1ed2cc94-3d0b-4718-80b6-2528e814c921":11.923849206349205,"30614910-26a5-495c-8bb7-0f723c47db69":9.542222222222222,"4a29b56b-b74e-4945-9017-61a7ab844fd9":6.0626984126984125,"58986749-f7f2-4c0c-a0f8-37180df48756":9.938382173382173,"5a6136c8-c73c-4a55-b231-d293bf1b12ee":9.256111111111112,"5eb1916a-bbf2-4413-b5ba-589c62877ac0":10.249603174603173,"65a76574-1ea8-4b1d-8d29-efe42d06446c":9.331111111111111,"6bc07db2-08e3-45a9-99c0-10391f57f6df":8.816825396825397,"6e8cc926-79a1-4676-a2bd-f9d49f3144cf":11.712698412698412,"82d0ec51-e40e-4602-b969-fc0b44464ac3":12.31579365079365,"94ce3d32-4057-4002-a3ef-6f87b0582802":10.184047619047618,"99f2c01b-6d49-4a93-8723-155698197ed6":6.892857142857142,"c027a810-02a3-415b-83ad-e48144273475":11.118253968253969,"cfe61dfb-59d6-4ee4-9324-e591f8cef78f":7.871428571428571,"d12c8fca-a82c-45db-b29c-8fc7a47fce2e":9.897380952380953,"ece37585-dc4e-492a-9f3c-0a143b0a5ab8":7.707142857142857,"f62a1da3-7675-446c-a327-86391e9cb02b":10.883835978835977},"topic":["scene","model","spatial","inform","show"],"groups":[{"authors":["Antonio Torralba","Pawan Sinha"],"references":["1ed2cc94-3d0b-4718-80b6-2528e814c921","65a76574-1ea8-4b1d-8d29-efe42d06446c","6d121e97-e351-4cf9-8c44-d7ab3ce9d9fe","6e8cc926-79a1-4676-a2bd-f9d49f3144cf","899de8c7-9cd9-4dd5-82f1-ad9acb801f8e","94ce3d32-4057-4002-a3ef-6f87b0582802","a15cddb4-131e-4c80-ac81-e67febff8f4a","ab3afb93-8ca0-4556-ae60-11199dc263c2","c027a810-02a3-415b-83ad-e48144273475","ff0d990e-90f3-4973-8541-5f7e595710aa"],"_id":"82d0ec51-e40e-4602-b969-fc0b44464ac3","abstract":"There is general consensus that context can be a rich source of information about an object's identity, location and scale. However the issue of how to formalize centextual influences is still largely open. Here we introduce a simple probabilistic framework for modeling the relationship between context and object properties. We represent global context information in terms of the spatial layout of spectral components. The resulting scheme serves as an effective procedure for context driven focus of attention and scale-selection on real-world scenes. Based on a simple holistic analysis of an image, the scheme is able to accurately predict object locations and sizes.","title":"Statistical context priming for object detection","venue":"international conference on computer vision","year":2001,"__v":0,"citationCount":86}],"offsprings":["e0ac4812-7729-4a2d-8a1f-74b1b7c8eb5d","176a7436-78ea-4c2a-82e6-7930ab023bd1","26316adf-569e-49bc-a289-c1ba311624f6"]},"bc95970b-34c5-4860-a832-41bc04a50889":{"authors":["Advaith Siddharthan"],"references":[],"_id":"bc95970b-34c5-4860-a832-41bc04a50889","abstract":"Statistical approaches to processing natural language text have become dominant in recent years. This foundational text is the first comprehensive introduction to statistical natural language processing (NLP) to appear. The book contains all the theory and algorithms needed for building NLP tools. It provides broad but rigorous coverage of mathematical and linguistic foundations, as well as detailed discussion of statistical methods, allowing students and researchers to construct their own implementations. The book covers collocation finding, word sense disambiguation, probabilistic parsing, information retrieval, and other applications.","title":"Christopher D. Manning and Hinrich Schutze. Foundations of Statistical Natural Language Processing . MIT Press, 2000. ISBN 0-262-13360-1. 620 pp. $64.95/£44.95 (cloth).","venue":"Natural Language Engineering","year":2002,"__v":0,"citationCount":2801,"parents":{"2a7e8624-15f9-41b2-a2bc-6d9bfce0949d":0,"3cc7d99b-2563-47ab-a83a-3555a2bf2736":0,"aa9af505-b437-4081-ba4a-97f0355a7f9e":33.33333333333333},"keyword":{"2a7e8624-15f9-41b2-a2bc-6d9bfce0949d":6.427777777777777,"3cc7d99b-2563-47ab-a83a-3555a2bf2736":10.602777777777778,"aa9af505-b437-4081-ba4a-97f0355a7f9e":8.594444444444445},"topic":["statist","text","process","nlp","natur"],"groups":[{"authors":["Raymond J. Mooney"],"references":["082583e3-fdb9-49d2-b745-ebc4595a0229","0c35895c-9f13-4678-80f3-9310652446e0","1a8e6293-8d68-4544-916a-66e329ba73b7","1efb5ce8-895e-4a26-8eb4-d297def26751","28e70562-4760-4398-bbf3-04ecbcb2aca3","2e6f4f88-170e-48de-a270-b4a93d3cb8ad","396c29a2-5683-48d0-9a41-e131dbaea36f","3cc7d99b-2563-47ab-a83a-3555a2bf2736","43e502f4-87f2-4672-9217-823cf6c56e56","4516543e-c8bb-4b21-818e-dad61ff606d0","51f1493d-ce3b-4589-8373-55940026fecd","5880d47f-8b99-416d-a743-28d6b49f7ba9","5f155e51-9d82-44f3-b177-36e5fe39346b","62549bc2-e0b3-46e8-8d32-390dded105d5","6ff708cd-67c6-46a2-8670-36ccc78bbcc9","768eea6d-8e82-4bbf-8bdd-1f2338ded29f","76f3c558-4e06-4f2e-99af-a5172fab5cc4","78067f92-12b9-460e-9c82-3c39e601b3f5","7a10be82-6113-4f60-9e37-f35f2d9423c5","8374220b-6655-4c96-a530-6a399500928a","851e654a-5405-448a-a8a6-2297ccab9954","86dafb65-1d2e-42d9-8982-4d520b6da774","8aebcfe5-c07c-4bc9-bf5f-48d59a1673f7","8d8f4685-16b1-429c-a6f9-c8a6edbc23ac","90cc5b69-db76-4753-997e-1961d8d97ec7","95ab1af8-1541-453a-aaa8-89ccaf4179ea","9e3b81fd-8fcc-4923-bf46-27669684d305","ac237969-3fd5-4303-83b7-a67e02afe976","b228ed81-8db3-4048-873e-70e8ddb40c90","bb4cbdf3-429f-48a4-a3b2-7f6dc12ec41a","c3eacd0b-ee81-4a1d-8cbf-ea5d9d7f626f","ca46649f-54c3-4138-ac4b-abd784e99f0d","e9abffef-c6bf-44da-a673-be480773dbbb","f5132ee6-d57b-40e4-b7e5-c5c3a56ce7b0","f51b782d-815b-4b0d-b9d6-8e676b413969"],"_id":"aa9af505-b437-4081-ba4a-97f0355a7f9e","abstract":"This paper describes an experimental comparison of seven different learning algorithms on the problem of learning to disambiguate the meaning of a word from context. The algorithms tested include statistical, neural-network, decision-tree, rule-based, and case-based classification techniques. The specific problem tested involves disambiguating six senses of the word ``line'' using the words in the current and proceeding sentence as context. The statistical and neural-network methods perform the best on this particular problem and we discuss a potential reason for this observed difference. We also discuss the role of bias in machine learning and its importance in explaining performance differences observed on specific problems.","title":"Comparative Experiments on Disambiguating Word Senses: An Illustration of the Role of Bias in Machine Learning","venue":"arXiv: Computation and Language","year":1996,"__v":0,"citationCount":82}],"offsprings":["4adb467d-dacf-4019-b0d5-28ce1f323cf4"]},"e4b468aa-2b23-4229-8872-f9286464a19f":{"authors":["Rainer Storn","Kenneth V. Price"],"references":[],"_id":"e4b468aa-2b23-4229-8872-f9286464a19f","abstract":"A new heuristic approach for minimizing possibly nonlinear and non-differentiable continuous space functions is presented. By means of an extensive testbed it is demonstrated that the new method converges faster and with more certainty than many other acclaimed global optimization methods. The new method requires few control variables, is robust, easy to use, and lends itself very well to parallel computation.","title":"Differential Evolution – A Simple and Efficient Heuristic for Global Optimization over Continuous Spaces","venue":"Journal of Global Optimization","year":1997,"__v":0,"citationCount":4063,"parents":{"3f47353b-c0ba-43b9-9a6b-42162391093c":25,"6a6b9aa6-683f-4c7c-b06e-9c3018d10fd3":0,"7ce8db5b-267e-40b1-9921-0f3ed995de67":25,"f40bce89-0858-4be1-832d-ba8b8f0099da":0},"keyword":{"3f47353b-c0ba-43b9-9a6b-42162391093c":10.34468253968254,"6a6b9aa6-683f-4c7c-b06e-9c3018d10fd3":9.954563492063492,"7ce8db5b-267e-40b1-9921-0f3ed995de67":10.596111111111112,"f40bce89-0858-4be1-832d-ba8b8f0099da":10.509523809523811},"topic":["method","variabl","testb","space","robust"],"groups":[{"authors":["Heinz Mühlenbein","Dirk Schlierkamp-Voosen"],"references":["07a6c6fe-fb9f-4334-8e0d-806fdf8da85d","58810840-1a9c-4e06-9553-80406ebb9f7a","5e56873e-d84c-476c-9083-1e0f52bc9527","6a6b9aa6-683f-4c7c-b06e-9c3018d10fd3","781b5118-8ec2-44a2-b747-6bf3bf31557e","7e1eeb34-62a7-41b7-8c1d-9cce0b528102","858a4272-c06a-4689-82e8-ac71be713972","d1ac813f-0f58-4079-89c0-30862425aa68"],"_id":"7ce8db5b-267e-40b1-9921-0f3ed995de67","abstract":"In this paper a new genetic algorithm called the Breeder Genetic Algorithm (BGA) is introduced. The BGA is based on artificial selection similar to that used by human breeders. A predictive model for the BGA is presented that is derived from quantitative genetics. The model is used to predict the behavior of the BGA for simple test functions. Different mutation schemes are compared by computing the expected progress to the solution. The numerical performance of the BGA is demonstrated on a test suite of multimodal functions. The number of function evaluations needed to locate the optimum scales only as n ln(n) where n is the number of parameters. Results up to n = 1000 are reported.","title":"Predictive models for the breeder genetic algorithm i. continuous parameter optimization","venue":"electronic commerce","year":1993,"__v":0,"citationCount":409},{"authors":["Rainer Storn","Kenneth V. Price"],"references":["f40bce89-0858-4be1-832d-ba8b8f0099da"],"_id":"3f47353b-c0ba-43b9-9a6b-42162391093c","abstract":"Differential Evolution (DE) has recently proven to be an efficient method for optimizing real-valued multi-modal objective functions. Besides its good convergence properties and suitability for parallelization, DE's main assets are its conceptual simplicity and ease of use. This paper describes two variants of DE which were used to minimize the real test functions of the ICEC'96 contest.","title":"Minimizing the real functions of the ICEC'96 contest by differential evolution","venue":"","year":1996,"__v":0,"citationCount":120}],"offsprings":[]},"12f40b38-cd99-4801-8074-d765a29a2101":{"authors":["Tomas Mikolov","Kai Chen","Greg Corrado","Jeffrey Dean"],"references":[],"_id":"12f40b38-cd99-4801-8074-d765a29a2101","abstract":"We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.","title":"Efficient Estimation of Word Representations in Vector Space","venue":"arXiv: Computation and Language","year":2013,"__v":0,"citationCount":1585,"parents":{"033f5f9b-d487-49dc-b4a0-aef9b9433d19":29.166666666666668,"0ab80338-6f6b-4322-b7a1-c90bd7eaa5e8":4.166666666666666,"0df95054-6f57-4e89-9c50-1b9dd870a263":16.666666666666664,"19c0e5d2-d5f3-4bd4-aba1-e9e975a9b580":12.5,"2ef8d7bb-3451-49fe-ba1d-70dc6a9786ab":0,"31b724c0-ae79-4477-ab75-3b62e2133bdb":0,"3ba1f3f1-7616-46bf-8857-1f5dbafd45d5":16.666666666666664,"47e20669-55b1-4e50-9ef2-e9f0496ce79a":4.166666666666666,"54554fcd-dd8c-457a-8f80-33dd5a0a5648":37.5,"6666464e-18c5-4fa6-95f7-b8fa84a097a3":12.5,"77b79c16-03f5-4c75-994e-38a9e0cc7bfe":12.5,"7aa454b2-47c6-4117-b823-1df65289e8e7":4.166666666666666,"88103971-d06c-4f2b-9338-e16c51ff5632":12.5,"967cfa49-e7cc-420c-be14-8f6ac66e1655":4.166666666666666,"998e48b9-7d74-42c5-ac15-a0cd80c345b0":29.166666666666668,"9ae57829-6d27-49e0-92bf-32e43c35f2e0":20.833333333333336,"a28cc94c-15a1-4c90-866c-f97f3f86cb20":0,"cfc571c4-574d-4835-ac41-ead585c71d29":12.5,"d0bbf973-4708-42b7-a2a0-04b564023015":25,"d34584d4-44fd-4172-a54b-ec903cbe1584":12.5,"e45a03a2-923b-40d7-8ad9-f60b0fe9c5f8":25,"f26a8a8a-9ad6-4dc1-8ae2-a59be1f80267":8.333333333333332,"f8af71de-30f9-4288-a169-13ab19bf89fb":8.333333333333332,"fec1b0f3-30d2-4877-8db9-2844eb9f8e2e":12.5},"keyword":{"033f5f9b-d487-49dc-b4a0-aef9b9433d19":10.606878306878306,"0ab80338-6f6b-4322-b7a1-c90bd7eaa5e8":7.528888888888888,"0df95054-6f57-4e89-9c50-1b9dd870a263":8.667486772486772,"19c0e5d2-d5f3-4bd4-aba1-e9e975a9b580":9.815873015873015,"2ef8d7bb-3451-49fe-ba1d-70dc6a9786ab":8.411005291005292,"31b724c0-ae79-4477-ab75-3b62e2133bdb":10.600000000000001,"3ba1f3f1-7616-46bf-8857-1f5dbafd45d5":10.362962962962962,"47e20669-55b1-4e50-9ef2-e9f0496ce79a":6.03068783068783,"54554fcd-dd8c-457a-8f80-33dd5a0a5648":7.922513227513229,"6666464e-18c5-4fa6-95f7-b8fa84a097a3":0,"77b79c16-03f5-4c75-994e-38a9e0cc7bfe":8.603703703703705,"7aa454b2-47c6-4117-b823-1df65289e8e7":10.115079365079366,"88103971-d06c-4f2b-9338-e16c51ff5632":9.444708994708993,"967cfa49-e7cc-420c-be14-8f6ac66e1655":8.576719576719574,"998e48b9-7d74-42c5-ac15-a0cd80c345b0":11.843650793650795,"9ae57829-6d27-49e0-92bf-32e43c35f2e0":10.211428571428572,"a28cc94c-15a1-4c90-866c-f97f3f86cb20":8.414867724867724,"cfc571c4-574d-4835-ac41-ead585c71d29":5.43941798941799,"d0bbf973-4708-42b7-a2a0-04b564023015":10.83419312169312,"d34584d4-44fd-4172-a54b-ec903cbe1584":6.061640211640212,"e45a03a2-923b-40d7-8ad9-f60b0fe9c5f8":10.517460317460317,"f26a8a8a-9ad6-4dc1-8ae2-a59be1f80267":8.953174603174604,"f8af71de-30f9-4288-a169-13ab19bf89fb":11.231349206349208,"fec1b0f3-30d2-4877-8db9-2844eb9f8e2e":9.51746031746032},"topic":["word","vector","set","similar","represent"],"groups":[{"authors":["Eric H. Huang","Richard Socher","Christopher D. Manning","Andrew Y. Ng"],"references":["0d60a7b8-b904-4dd3-ad20-73f403c407f7","14471266-0193-47a6-98ef-1650eaf192f7","19c0e5d2-d5f3-4bd4-aba1-e9e975a9b580","357628ef-a0a2-4821-b2f8-d8f47b46cb1e","47e20669-55b1-4e50-9ef2-e9f0496ce79a","492f4525-17a3-43b4-88cc-2cb691dad52b","4adb467d-dacf-4019-b0d5-28ce1f323cf4","540f653d-dc81-4160-9755-3cd96bc46bb0","68453f24-4276-4d0c-b37e-19d23af549be","6d6fc75f-6ca1-4aa2-b9cd-ccc6da6825e4","7196c9a8-d95d-493f-a6e4-9b1f653c3a01","73f6b15e-509c-4f2f-9160-35cab954ce59","7aa454b2-47c6-4117-b823-1df65289e8e7","84a92de5-64da-487c-8095-01d2ef64c113","8c399240-2ea8-4663-a59e-7a00807b3707","967cfa49-e7cc-420c-be14-8f6ac66e1655","9b4e6c65-da64-4ffe-8f2b-810d7f1efb54","aa70d058-ba2d-409f-a20e-fcf8239a069e","b46fdfbf-a80e-407d-b2b0-ad6872b0ac77","bb9af860-3fa7-4d14-adfa-e1ac1ad4f4b9","c136d093-7e80-48e4-8b9d-602cad03f29e","c97280f8-ddb4-4c31-b0ed-22514813a3da","d0bbf973-4708-42b7-a2a0-04b564023015","d4fba3ac-d845-4450-88ce-32ff60f7a358","d8612e0b-5495-4a39-9629-86a460a390fa","dcceb85e-fe74-4cd9-a668-048cc84e3844","e1fb6fae-859f-4498-b587-1a7d23b27e45","e789ffa3-b53a-4c12-97d4-13680c7dafa1","f8af71de-30f9-4288-a169-13ab19bf89fb"],"_id":"e45a03a2-923b-40d7-8ad9-f60b0fe9c5f8","abstract":"Unsupervised word representations are very useful in NLP tasks both as inputs to learning algorithms and as extra word features in NLP systems. However, most of these models are built with only local context and one representation per word. This is problematic because words are often polysemous and global context can also provide useful information for learning word meanings. We present a new neural network architecture which 1) learns word embeddings that better capture the semantics of words by incorporating both local and global document context, and 2) accounts for homonymy and polysemy by learning multiple embeddings per word. We introduce a new dataset with human judgments on pairs of words in sentential context, and evaluate our model on it, showing that our model outperforms competitive baselines and other neural language models.","title":"Improving Word Representations via Global Context and Multiple Word Prototypes","venue":"meeting of the association for computational linguistics","year":2012,"__v":0,"citationCount":299},{"authors":["Tomas Mikolov","Anoop Deoras","Daniel Povey","Lukas Burget","Jan Cernocky"],"references":["0df95054-6f57-4e89-9c50-1b9dd870a263","111a25a1-44ca-44fb-bca8-51e8157463d3","2024cecc-3c3a-4ed6-abb5-011633f2f3fe","393d1887-e68a-4fa8-b01e-8e41fce2f866","40c1f32d-2e92-4172-a714-db0efed14973","61d3f2f6-1b70-4630-bb62-5d3961e1340e","6666464e-18c5-4fa6-95f7-b8fa84a097a3","75e639dd-3cdb-452f-b5e8-60677f3f7c94","7aa454b2-47c6-4117-b823-1df65289e8e7","7ff7b392-bab1-4a61-a47a-fb9a79e8297e","88103971-d06c-4f2b-9338-e16c51ff5632","967cfa49-e7cc-420c-be14-8f6ac66e1655","a0a2060c-3c21-42c8-bab4-044a1c3461ad","a98bf926-765e-43e9-9c61-1c213692a258","b241b294-4de6-4424-affc-f5fa268939fd","c4ce3e24-58a6-46f1-975e-9209228cdc6f","c6a882d8-dc37-4e7b-b36f-74f48a370f65","cfc571c4-574d-4835-ac41-ead585c71d29","d0d18692-434c-4c7a-b4d8-33ff328f3e3e","fec1b0f3-30d2-4877-8db9-2844eb9f8e2e"],"_id":"033f5f9b-d487-49dc-b4a0-aef9b9433d19","abstract":"We describe how to effectively train neural network based language models on large data sets. Fast convergence during training and better overall performance is observed when the training data are sorted by their relevance. We introduce hash-based implementation of a maximum entropy model, that can be trained as a part of the neural network model. This leads to significant reduction of computational complexity. We achieved around 10% relative reduction of word error rate on English Broadcast News speech recognition task, against large 4-gram model trained on 400M tokens.","title":"Strategies for training large scale neural network language models","venue":"ieee automatic speech recognition and understanding workshop","year":2011,"__v":0,"citationCount":95},{"authors":["Tomas Mikolov","Wen-tau Yih","Geoffrey Zweig"],"references":["033f5f9b-d487-49dc-b4a0-aef9b9433d19","0ab80338-6f6b-4322-b7a1-c90bd7eaa5e8","0df95054-6f57-4e89-9c50-1b9dd870a263","1035d56c-06b3-40bb-93c7-6306b24bac93","312c1b21-3869-482d-92e9-a1fa7f32d871","51f1493d-ce3b-4589-8373-55940026fecd","6666464e-18c5-4fa6-95f7-b8fa84a097a3","68d3ca1d-f8f5-4910-a55e-19c384a4ab03","7aa454b2-47c6-4117-b823-1df65289e8e7","903c64fd-faea-4997-b1d4-2598fe4f9446","967cfa49-e7cc-420c-be14-8f6ac66e1655","a0a2060c-3c21-42c8-bab4-044a1c3461ad","ac14afe6-de4d-4056-b2ac-0f6e36f369a2","cfc571c4-574d-4835-ac41-ead585c71d29","e8528559-d600-4dcb-8438-4e291b93fbb4","f130610a-d6d8-4001-964b-8d4e5333b65f"],"_id":"998e48b9-7d74-42c5-ac15-a0cd80c345b0","abstract":"Continuous space language models have recently demonstrated outstanding results across a variety of tasks. In this paper, we examine the vector-space word representations that are implicitly learned by the input-layer weights. We find that these representations are surprisingly good at capturing syntactic and semantic regularities in language, and that each relationship is characterized by a relation-specific vector offset. This allows vector-oriented reasoning based on the offsets between words. For example, the male/female relationship is automatically learned, and with the induced vector representations, “King Man + Woman” results in a vector very close to “Queen.” We demonstrate that the word vectors capture syntactic regularities by means of syntactic analogy questions (provided with this paper), and are able to correctly answer almost 40% of the questions. We demonstrate that the word vectors capture semantic regularities by using the vector offset method to answer SemEval-2012 Task 2 questions. Remarkably, this method outperforms the best previous systems.","title":"Linguistic Regularities in Continuous Space Word Representations","venue":"north american chapter of the association for computational linguistics","year":2013,"__v":0,"citationCount":438},{"authors":["Joseph P. Turian","Lev-Arie Ratinov","Yoshua Bengio"],"references":["017a5844-664a-410a-9adf-50c1fdae5895","0b1f5092-4b64-4d5e-8bf7-15295db41f4f","131f2b3b-adf0-41af-a84f-b0941e93ffeb","1e6f4b1f-7bfe-4b8c-9a60-c9f0bea232f7","281f79f4-729c-4cbb-9793-18b21a4b4315","47e20669-55b1-4e50-9ef2-e9f0496ce79a","4a29e0cd-d551-48f2-9cc3-193f9b7c4cfa","4ffd7d10-c575-40e6-a814-0bb4590c8ecb","5347be4c-bbac-4674-83b8-60dd8175588c","558dee29-ba49-4949-bbb8-ac8bb76541fd","58bb3a79-ab62-4d7d-ba89-2be701314cfc","5f4627e0-5d97-43b2-bce3-1ee1f3e2edc9","6666464e-18c5-4fa6-95f7-b8fa84a097a3","69df0789-a06f-4166-9c34-93047de2673d","6e476858-35d3-49b4-a164-a578b30a1a4a","77b79c16-03f5-4c75-994e-38a9e0cc7bfe","7aa454b2-47c6-4117-b823-1df65289e8e7","967cfa49-e7cc-420c-be14-8f6ac66e1655","9cb3b11c-4d43-4cce-92cb-a886510c94bd","b46fdfbf-a80e-407d-b2b0-ad6872b0ac77","bc1cf646-43d9-4fb8-a1ce-c8f5ea5c18b9","c4042c31-dc3f-41c4-94d9-61e00c4e5b1b","c8949213-75b6-4238-a17c-a5b13597b5d2","cb52a956-2990-4c3d-8cd0-d6a5a581a124","d0d18692-434c-4c7a-b4d8-33ff328f3e3e","d338cf1b-865d-4ed3-b430-3bfa393eddfd","d6180de9-bf4c-4a20-ac58-bba3c01353bc","f06e7fdb-8cbf-4b3f-aaca-807af12c0d70","f3a20c90-cedd-48a9-b773-52170b398931","f8af71de-30f9-4288-a169-13ab19bf89fb","ffd59f06-8287-49cc-8dd6-d1e0a4cadb3a"],"_id":"d0bbf973-4708-42b7-a2a0-04b564023015","abstract":"If we take an existing supervised NLP system, a simple and general way to improve accuracy is to use unsupervised word representations as extra word features. We evaluate Brown clusters, Collobert and Weston (2008) embeddings, and HLBL (Mnih & Hinton, 2009) embeddings of words on both NER and chunking. We use near state-of-the-art supervised baselines, and find that each of the three word representations improves the accuracy of these baselines. We find further improvements by combining different word representations. You can download our word features, for off-the-shelf use in existing NLP systems, as well as our code, here: http://metaoptimize.com/projects/wordreprs/","title":"Word Representations: A Simple and General Method for Semi-Supervised Learning","venue":"meeting of the association for computational linguistics","year":2010,"__v":0,"citationCount":565},{"authors":["Andriy Mnih","Yee Whye Teh"],"references":["01f443e7-ea4c-48a7-8081-745c3fa62769","17c02aa7-8aab-435a-8a86-7c0762fa1f41","357628ef-a0a2-4821-b2f8-d8f47b46cb1e","47e20669-55b1-4e50-9ef2-e9f0496ce79a","4eec767c-9f1d-49e4-a329-8f8c57a1421a","5317fbe4-f12c-414c-93e3-2bb094131ddd","6666464e-18c5-4fa6-95f7-b8fa84a097a3","77b79c16-03f5-4c75-994e-38a9e0cc7bfe","7aa454b2-47c6-4117-b823-1df65289e8e7","88103971-d06c-4f2b-9338-e16c51ff5632","8e39b3d3-dda8-4f1f-98bd-5d6b5141ad23","967cfa49-e7cc-420c-be14-8f6ac66e1655","9cb3b11c-4d43-4cce-92cb-a886510c94bd","b241b294-4de6-4424-affc-f5fa268939fd","bee4b074-8873-423a-8351-996134b99621","bef405c3-0ed8-476e-890f-d7d8603535cf","cfc571c4-574d-4835-ac41-ead585c71d29","d0bbf973-4708-42b7-a2a0-04b564023015","e1d4b584-e576-484f-a17c-36918cd19162","f8af71de-30f9-4288-a169-13ab19bf89fb"],"_id":"54554fcd-dd8c-457a-8f80-33dd5a0a5648","abstract":"In spite of their superior performance, neural probabilistic language models (NPLMs) remain far less widely used than n-gram models due to their notoriously long training times, which are measured in weeks even for moderately-sized datasets. Training NPLMs is computationally expensive because they are explicitly normalized, which leads to having to consider all words in the vocabulary when computing the log-likelihood gradients.#R##N##R##N#We propose a fast and simple algorithm for training NPLMs based on noise-contrastive estimation, a newly introduced procedure for estimating unnormalized continuous distributions. We investigate the behaviour of the algorithm on the Penn Treebank corpus and show that it reduces the training times by more than an order of magnitude without affecting the quality of the resulting models. The algorithm is also more efficient and much more stable than importance sampling because it requires far fewer noise samples to perform well.#R##N##R##N#We demonstrate the scalability of the proposed approach by training several neural language models on a 47M-word corpus with a 80K-word vocabulary, obtaining state-of-the-art results on the Microsoft Research Sentence Completion Challenge dataset.","title":"A fast and simple algorithm for training neural probabilistic language models","venue":"international conference on machine learning","year":2012,"__v":0,"citationCount":123}],"offsprings":["c186e8f6-42e1-4bb8-8fe3-039e0cd02532"]},"8bb47288-c305-4131-9a23-3635d1bc15ad":{"authors":["Michael E. Tipping"],"references":[],"_id":"8bb47288-c305-4131-9a23-3635d1bc15ad","abstract":"This paper introduces a general Bayesian framework for obtaining sparse solutions to regression and classification tasks utilising models linear in the parameters. Although this framework is fully general, we illustrate our approach with a particular specialisation that we denote the 'relevance vector machine' (RVM), a model of identical functional form to the popular and state-of-the-art 'support vector machine' (SVM). We demonstrate that by exploiting a probabilistic Bayesian learning framework, we can derive accurate prediction models which typically utilise dramatically fewer basis functions than a comparable SVM while offering a number of additional advantages. These include the benefits of probabilistic predictions, automatic estimation of 'nuisance' parameters, and the facility to utilise arbitrary basis functions (e.g. non-'Mercer' kernels). We detail the Bayesian framework and associated learning algorithm for the RVM, and give some illustrative examples of its application along with some comparative benchmarks. We offer some explanation for the exceptional degree of sparsity obtained, and discuss and demonstrate some of the advantageous features, and potential extensions, of Bayesian relevance learning.","title":"Sparse bayesian learning and the relevance vector machine","venue":"Journal of Machine Learning Research","year":2001,"__v":0,"citationCount":1556,"parents":{"1ef607fe-5348-4658-8964-25a57fc49270":11.11111111111111,"28739c79-b8a3-4655-91df-86df90be925b":11.11111111111111,"423d87a4-6743-4306-b751-8e3beb1d5dec":11.11111111111111,"46868983-27e4-4045-9756-c163a0a9e396":11.11111111111111,"47a93521-1448-4694-9c00-f29ff91f9062":5.555555555555555,"4a29b56b-b74e-4945-9017-61a7ab844fd9":0,"4f6b8262-e72c-454d-9e64-067d274cfcd6":11.11111111111111,"549f0527-0f13-4447-9dc0-ca699e2dc219":11.11111111111111,"5dedaf52-0a62-4822-b9eb-4b86acca6842":0,"7267264c-6420-42c8-b031-fd85fa63006d":11.11111111111111,"777b6ece-6daf-466b-945d-1fef13660575":11.11111111111111,"7dee8610-7878-451d-aa5c-30f315d8c3f9":11.11111111111111,"8be8b196-5437-4edc-9823-d4779b4774a5":16.666666666666664,"d46e68dc-dbb7-4296-8f40-f3c513b432bc":0,"e7d28b36-e5dc-4f2f-8135-4204b0d10c8e":11.11111111111111,"f006e236-59ad-4647-a59f-4f46dc2c85be":0,"f15b056f-a577-4391-9724-a5be885e2bd2":11.11111111111111,"f255fe78-83e5-4d24-a7db-6853adcc7d24":0},"keyword":{"1ef607fe-5348-4658-8964-25a57fc49270":11.41425925925926,"28739c79-b8a3-4655-91df-86df90be925b":8.381164021164022,"423d87a4-6743-4306-b751-8e3beb1d5dec":7.1322222222222225,"46868983-27e4-4045-9756-c163a0a9e396":11.68666666666667,"47a93521-1448-4694-9c00-f29ff91f9062":9.647751322751324,"4a29b56b-b74e-4945-9017-61a7ab844fd9":7.244179894179895,"4f6b8262-e72c-454d-9e64-067d274cfcd6":10.782407407407407,"549f0527-0f13-4447-9dc0-ca699e2dc219":11.089814814814813,"5dedaf52-0a62-4822-b9eb-4b86acca6842":8.536402116402117,"7267264c-6420-42c8-b031-fd85fa63006d":11.097354497354498,"777b6ece-6daf-466b-945d-1fef13660575":11.092671957671955,"7dee8610-7878-451d-aa5c-30f315d8c3f9":8.569444444444443,"8be8b196-5437-4edc-9823-d4779b4774a5":10.425925925925924,"d46e68dc-dbb7-4296-8f40-f3c513b432bc":0,"e7d28b36-e5dc-4f2f-8135-4204b0d10c8e":8.2555291005291,"f006e236-59ad-4647-a59f-4f46dc2c85be":11.553703703703702,"f15b056f-a577-4391-9724-a5be885e2bd2":7.6037037037037045,"f255fe78-83e5-4d24-a7db-6853adcc7d24":11.215740740740742},"topic":["framework","bayesian","utilis","model","learn"],"offsprings":["3ed17ffd-b416-470a-973a-77d7085a3503"]},"e3a40536-5580-4c24-b273-4fa4dab2579e":{"authors":["Martin Ester","H.-P. Kriegel","Jiirg Sander","Xu Xiaowei"],"references":[],"_id":"e3a40536-5580-4c24-b273-4fa4dab2579e","abstract":"Clustering algorithms are attractive for the task of class identification in spatial databases. However, the application to large spatial databases rises the following requirements for clustering algorithms: minimal requirements of domain knowledge to determine the input parameters, discovery of clusters with arbitrary shape and good efficiency on large databases. The well-known clustering algorithms offer no solution to the combination of these requirements. In this paper, we present the new clustering algorithm DBSCAN relying on a density-based notion of clusters which is designed to discover clusters of arbitrary shape. DB SCAN requires only one input parameter and supports the user in determining an appropriate value for it. We performed an experimental evaluation of the effectiveness and efficiency of DBSCAN using synthetic data and real data of the SEQUOIA 2000 benchmark. The results of our experiments demonstrate that (1) DBSCAN is significantly more effective in discovering clusters of arbitrary shape than the well-known algorithm CLARANS, and that (2) DBSCAN outperforms CLARANS by a factor of more than 100 in terms of efficiency.","title":"A density-based algorithm for discovering clusters in large spatial databases with noise","venue":"knowledge discovery and data mining","year":1996,"__v":0,"citationCount":3487,"parents":{"1017d9d4-9a4c-423d-ad40-6d9bebbd6b31":0,"1266d021-429c-4325-9eef-5feaf7ee5858":0,"141da6cb-d099-409c-8f2e-d5690bcc05db":50,"36a903d1-afc0-434d-b423-050a58d44df9":16.666666666666664,"5f79215b-40d5-4d63-a0e8-389c297af5dd":0,"bdb8d83d-1771-4399-b593-d43be5a9f892":0},"keyword":{"1017d9d4-9a4c-423d-ad40-6d9bebbd6b31":0,"1266d021-429c-4325-9eef-5feaf7ee5858":11.184153439153441,"141da6cb-d099-409c-8f2e-d5690bcc05db":11.09984126984127,"36a903d1-afc0-434d-b423-050a58d44df9":8.173227513227511,"5f79215b-40d5-4d63-a0e8-389c297af5dd":10.216402116402117,"bdb8d83d-1771-4399-b593-d43be5a9f892":0},"topic":["cluster","algorithm","requir","dbscan","shape"],"groups":[{"authors":["Martin Ester","Hans-Peter Kriegel","Xiaowei Xu"],"references":["1012cd0d-9eaf-423b-875e-f82f94628434","1266d021-429c-4325-9eef-5feaf7ee5858","5f79215b-40d5-4d63-a0e8-389c297af5dd","6ba61a12-c296-44a6-8f0d-024d7a7616e9","7000a6d7-e48a-4db0-98e9-55895310e851","a3a1815f-b66a-44a9-b751-287ce5e9257c","bdb8d83d-1771-4399-b593-d43be5a9f892","c16c2977-7c76-4d59-a55e-e23e4728f19b"],"_id":"141da6cb-d099-409c-8f2e-d5690bcc05db","abstract":"Both the number and the size of spatial databases are rapidly growing because of the large amount of data obtained from satellite images, X-ray crystallography or other scientific equipment. Therefore, automated knowledge discovery becomes more and more important in spatial databases. So far, most of the methods for knowledge discovery in databases (KDD) have been based on relational database systems. In this paper, we address the task of class identification in spatial databases using clustering techniques. We present an interface to the database management system (DBMS), which is crucial for the efficiency of KDD on large databases. This interface is based on a spatial access method, the R*-tree. It clusters the objects according to their spatial neighborhood and supports efficient processing of spatial queries. Furthermore, we propose a method for spatial data sampling as part of the focusing component, significantly reducing the number of objects to be clustered. Thus, we achieve a considerable speed-up for clustering in large databases. We have applied the proposed techniques to real data from a large protein database used for predicting protein-protein docking. A performance evaluation on this database indicates that clustering on large spatial databases can be performed both efficiently and effectively using our approach.","title":"A database interface for clustering in large spatial databases","venue":"knowledge discovery and data mining","year":1995,"__v":0,"citationCount":67}],"offsprings":["5a4a1b04-b36f-402c-a87f-0779098ef050"]},"f225f439-4389-4312-a503-f8c1b0aa02de":{"authors":["Herbert Bay","Tinne Tuytelaars","Luc J. Van Gool"],"references":["6018a516-8149-4bce-bc33-5449d86e58c2","60285266-7da2-474e-b05a-b380c836f665","8d8e7d51-3223-4776-bf6a-40306774b8a1","b944f77f-113b-4a02-ae5e-d4a124b8fd5b","e649a9fd-f6d9-4aac-b428-29b82c20a484","ffa029cf-7240-4723-8339-51fac57f9f28"],"_id":"f225f439-4389-4312-a503-f8c1b0aa02de","abstract":"In this paper, we present a novel scale- and rotation-invariant interest point detector and descriptor, coined SURF (Speeded Up Robust Features). It approximates or even outperforms previously proposed schemes with respect to repeatability, distinctiveness, and robustness, yet can be computed and compared much faster.#R##N##R##N#This is achieved by relying on integral images for image convolutions; by building on the strengths of the leading existing detectors and descriptors (in casu, using a Hessian matrix-based measure for the detector, and a distribution-based descriptor); and by simplifying these methods to the essential. This leads to a combination of novel detection, description, and matching steps. The paper presents experimental results on a standard evaluation set, as well as on imagery obtained in the context of a real-life object recognition application. Both show SURF's strong performance.","title":"SURF: speeded up robust features","venue":"european conference on computer vision","year":2006,"__v":0,"citationCount":3617,"parents":{"0b86c956-29dc-4979-b046-f2ec971d8ac8":17.391304347826086,"21c67dad-f0eb-4479-afe7-fdf4a71eef01":47.82608695652174,"2d6c9f60-ea78-44a8-b5f9-6964575dd196":4.3478260869565215,"2fa58737-dfec-48e8-a1d5-dc96c510d44f":17.391304347826086,"34758e0a-3def-447b-9c5e-e82a206426b5":0,"36800655-b2ff-4eb7-9070-c6be304c4baa":0,"3c1e64c0-8e48-45d3-96e8-f2c3252b4b83":0,"472cc3e6-8149-41ef-b4c4-fa9e6a60b66f":8.695652173913043,"473cf1a4-9f42-4e6d-b34f-77787f329079":4.3478260869565215,"509e1ae2-768b-4417-bebe-d90cf1e0fdae":13.043478260869565,"5f84f09f-7644-447c-89e1-8dc9ee334197":13.043478260869565,"6018a516-8149-4bce-bc33-5449d86e58c2":0,"60285266-7da2-474e-b05a-b380c836f665":17.391304347826086,"6fe37c18-8dc5-4baa-b6e0-5546353907bb":43.47826086956522,"774c108a-4002-4123-861f-edd3b7ccb0e7":0,"7ab7b36d-baae-4b21-89fc-69389fcabc44":8.695652173913043,"8d8e7d51-3223-4776-bf6a-40306774b8a1":56.52173913043478,"9f5f1500-0df7-4675-8290-b47979bcad38":13.043478260869565,"a5254ae0-1ce1-4390-b9f8-8d5a3dcb1e62":30.434782608695656,"b944f77f-113b-4a02-ae5e-d4a124b8fd5b":26.08695652173913,"e649a9fd-f6d9-4aac-b428-29b82c20a484":4.3478260869565215,"ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d":21.73913043478261,"ffa029cf-7240-4723-8339-51fac57f9f28":43.47826086956522},"keyword":{"0b86c956-29dc-4979-b046-f2ec971d8ac8":11.049814814814814,"21c67dad-f0eb-4479-afe7-fdf4a71eef01":8.387380952380953,"2d6c9f60-ea78-44a8-b5f9-6964575dd196":11.337777777777776,"2fa58737-dfec-48e8-a1d5-dc96c510d44f":7.3668650793650805,"34758e0a-3def-447b-9c5e-e82a206426b5":0,"36800655-b2ff-4eb7-9070-c6be304c4baa":12.054047619047617,"3c1e64c0-8e48-45d3-96e8-f2c3252b4b83":10.812023809523808,"472cc3e6-8149-41ef-b4c4-fa9e6a60b66f":9.356349206349206,"473cf1a4-9f42-4e6d-b34f-77787f329079":10.157460317460316,"509e1ae2-768b-4417-bebe-d90cf1e0fdae":10.226507936507936,"5f84f09f-7644-447c-89e1-8dc9ee334197":7.4355158730158735,"6018a516-8149-4bce-bc33-5449d86e58c2":9.095119047619047,"60285266-7da2-474e-b05a-b380c836f665":10.580158730158729,"6fe37c18-8dc5-4baa-b6e0-5546353907bb":12.972539682539681,"774c108a-4002-4123-861f-edd3b7ccb0e7":8.864351851851852,"7ab7b36d-baae-4b21-89fc-69389fcabc44":6.206746031746032,"8d8e7d51-3223-4776-bf6a-40306774b8a1":14.334285714285713,"9f5f1500-0df7-4675-8290-b47979bcad38":9.217777777777778,"a5254ae0-1ce1-4390-b9f8-8d5a3dcb1e62":10.138174603174601,"b944f77f-113b-4a02-ae5e-d4a124b8fd5b":11.093055555555555,"e649a9fd-f6d9-4aac-b428-29b82c20a484":9.26857142857143,"ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d":9.541851851851852,"ffa029cf-7240-4723-8339-51fac57f9f28":9.66388888888889},"topic":["detector","descriptor","surf","robust","present"],"groups":[{"authors":["Krystian Mikolajczyk","Tinne Tuytelaars","C. Schmid","Andrew Zisserman","Jir i Matas","Frederik Schaffalitzky","Timor Kadir","L. Van Gool"],"references":["085204a8-62ca-4a3c-8098-4f75d62d1ae4","0aae4e44-abdb-4948-9462-61f6e52162ba","0bc5747a-2caf-4996-a55b-6ec5e7273636","0d287faa-99bb-42df-98a7-24fcd601b9a4","1dc84769-ff4c-4de6-a1c9-8d3af9299701","21a8e8fd-0172-4e9a-8474-7024eb0bf979","2beaa150-6293-4f05-ba04-8e001993e766","2d6c9f60-ea78-44a8-b5f9-6964575dd196","2dfac644-329c-46f4-a508-749ccb2d7c85","34758e0a-3def-447b-9c5e-e82a206426b5","4e58f9b5-8562-4f17-830f-f055449867fc","50212652-4999-4f13-82d6-a37eb2862a73","509e1ae2-768b-4417-bebe-d90cf1e0fdae","5149d3c0-5ac9-47ba-9fb0-3d2ef757b0e8","5172d9aa-41cc-40dc-949a-cde3d9f05f31","5f1992df-975f-49e7-bd88-aee0740317cf","6018a516-8149-4bce-bc33-5449d86e58c2","60285266-7da2-474e-b05a-b380c836f665","6842d04f-2b92-4298-aee8-92babc53f7c4","6fe37c18-8dc5-4baa-b6e0-5546353907bb","7283fa2b-1f6a-4138-a3da-4bf69809a1a9","776d4b4d-d49f-439f-9db5-7c5c3ce68db3","7ab7b36d-baae-4b21-89fc-69389fcabc44","8ab773a4-49b4-4755-a070-4ab1b1710690","8d8e7d51-3223-4776-bf6a-40306774b8a1","9b480902-c7fd-4d9f-ac9c-3c2fe3aa9c2c","a0be9da4-c423-4f87-a387-822fe304aa03","ab7b7857-e48d-4b94-8bfa-bc9ed61d5853","b25e7392-e9f9-4600-8ab0-a76252f1633a","b3e60214-b54c-4e8f-9315-a6975c760f4c","b944f77f-113b-4a02-ae5e-d4a124b8fd5b","b9e63aeb-aa46-40a0-9b06-01e2270cea70","c455fb04-4566-4648-ad6f-3cf2245e507c","cf9198ae-7e03-401f-a52b-94689ba30a36","ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d","fc9638b8-572c-4b23-aab2-92e2dd3b79f8","ffa029cf-7240-4723-8339-51fac57f9f28"],"_id":"21c67dad-f0eb-4479-afe7-fdf4a71eef01","abstract":"The paper gives a snapshot of the state of the art in affine covariant region detectors, and compares their performance on a set of test images under varying imaging conditions. Six types of detectors are included: detectors based on affine normalization around Harris (Mikolajczyk and Schmid, 2002; Schaffalitzky and Zisserman, 2002) and Hessian points (Mikolajczyk and Schmid, 2002), a detector of `maximally stable extremal regions', proposed by Matas et al. (2002); an edge-based region detector (Tuytelaars and Van Gool, 1999) and a detector based on intensity extrema (Tuytelaars and Van Gool, 2000), and a detector of `salient regions', proposed by Kadir, Zisserman and Brady (2004). The performance is measured against changes in viewpoint, scale, illumination, defocus and image compression.#R##N##R##N#The objective of this paper is also to establish a reference test set of images and performance software, so that future detectors can be evaluated in the same framework.","title":"A Comparison of Affine Region Detectors","venue":"International Journal of Computer Vision","year":2005,"__v":0,"citationCount":1317},{"authors":["Krystian Mikolajczyk","Cordelia Schmid"],"references":["0d287faa-99bb-42df-98a7-24fcd601b9a4","1c016f4a-20fb-44b5-84ad-96c10cb8e61b","2beaa150-6293-4f05-ba04-8e001993e766","2d6c9f60-ea78-44a8-b5f9-6964575dd196","33711daf-2a44-4f42-8466-c7801f29959b","34758e0a-3def-447b-9c5e-e82a206426b5","36800655-b2ff-4eb7-9070-c6be304c4baa","457f15ab-c8e1-461d-b768-e044d88f1917","473cf1a4-9f42-4e6d-b34f-77787f329079","509e1ae2-768b-4417-bebe-d90cf1e0fdae","5149d3c0-5ac9-47ba-9fb0-3d2ef757b0e8","58d0cc4d-9deb-4188-98d2-7ca475ca7221","5f1992df-975f-49e7-bd88-aee0740317cf","5f84f09f-7644-447c-89e1-8dc9ee334197","6018a516-8149-4bce-bc33-5449d86e58c2","60285266-7da2-474e-b05a-b380c836f665","643913d9-b72a-4ee3-9c3f-63c1249e9a3c","64ea9dde-3bd8-4868-9c0b-f15556e67ad5","7283fa2b-1f6a-4138-a3da-4bf69809a1a9","79050acb-3012-4d4b-af60-66040a28043d","7a9f04e3-2883-4204-8fb3-7db1ce5ddc09","7ab7b36d-baae-4b21-89fc-69389fcabc44","899de8c7-9cd9-4dd5-82f1-ad9acb801f8e","8ab773a4-49b4-4755-a070-4ab1b1710690","a00704dc-a2fa-4267-b7a6-427167d99521","a0be9da4-c423-4f87-a387-822fe304aa03","a72802aa-e1ab-4f52-bae8-703d68f9b220","b3e60214-b54c-4e8f-9315-a6975c760f4c","c591c440-b19b-4d7b-b067-cd8c366b7d6d","cc6caca8-1564-4cf8-88a3-f0733c46e0dd","d4e9734a-a4e7-4c19-be20-c32f55d4d26f","e86ce68d-0d77-4f44-a212-518e7d8f394b","eeb31134-612a-42bf-a6c2-8b7d7c17e694","ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d"],"_id":"ffa029cf-7240-4723-8339-51fac57f9f28","abstract":"In this paper we propose a novel approach for detecting interest points invariant to scale and affine transformations. Our scale and affine invariant detectors are based on the following recent results: (1) Interest points extracted with the Harris detector can be adapted to affine transformations and give repeatable results (geometrically stable). (2) The characteristic scale of a local structure is indicated by a local extremum over scale of normalized derivatives (the Laplacian). (3) The affine shape of a point neighborhood is estimated based on the second moment matrix.#R##N##R##N#Our scale invariant detector computes a multi-scale representation for the Harris interest point detector and then selects points at which a local measure (the Laplacian) is maximal over scales. This provides a set of distinctive points which are invariant to scale, rotation and translation as well as robust to illumination changes and limited changes of viewpoint. The characteristic scale determines a scale invariant region for each point. We extend the scale invariant detector to affine invariance by estimating the affine shape of a point neighborhood. An iterative algorithm modifies location, scale and neighborhood of each point and converges to affine invariant points. This method can deal with significant affine transformations including large scale changes. The characteristic scale and the affine shape of neighborhood determine an affine invariant region for each point.#R##N##R##N#We present a comparative evaluation of different detectors and show that our approach provides better results than existing methods. The performance of our detector is also confirmed by excellent matching resultss the image is described by a set of scale/affine invariant descriptors computed on the regions associated with our points.","title":"Scale & Affine Invariant Interest Point Detectors","venue":"International Journal of Computer Vision","year":2004,"__v":0,"citationCount":1525},{"authors":["Krystian Mikolajczyk","Cordelia Schmid"],"references":["00a4e16f-6b65-4ad2-bedc-b19d9cbc2cfe","09346dc3-f4d0-43a4-8f0b-27e02bcd336e","0aae4e44-abdb-4948-9462-61f6e52162ba","0d287faa-99bb-42df-98a7-24fcd601b9a4","19195bc1-7aff-4dd3-91cc-25402c343a19","21a8e8fd-0172-4e9a-8474-7024eb0bf979","21c67dad-f0eb-4479-afe7-fdf4a71eef01","2d6c9f60-ea78-44a8-b5f9-6964575dd196","33711daf-2a44-4f42-8466-c7801f29959b","34758e0a-3def-447b-9c5e-e82a206426b5","36800655-b2ff-4eb7-9070-c6be304c4baa","509e1ae2-768b-4417-bebe-d90cf1e0fdae","5149d3c0-5ac9-47ba-9fb0-3d2ef757b0e8","5f1992df-975f-49e7-bd88-aee0740317cf","6018a516-8149-4bce-bc33-5449d86e58c2","60285266-7da2-474e-b05a-b380c836f665","608a581a-0e03-435a-9067-c0e0982567af","683dd26d-5c59-4feb-9fbd-2bcf3cc1942f","853b29ea-c6d1-497e-bad3-b608d370e7e2","a5254ae0-1ce1-4390-b9f8-8d5a3dcb1e62","b4685927-0ad9-466b-b2c6-2e1764475726","b592576f-ff29-4a68-9b2f-8a8ad02e9c70","b944f77f-113b-4a02-ae5e-d4a124b8fd5b","c455fb04-4566-4648-ad6f-3cf2245e507c","e2204e92-e6dc-4884-9bbc-200029491fc7","e927dff1-6ed4-45fd-8852-eb804e11e665","ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d","fc9638b8-572c-4b23-aab2-92e2dd3b79f8"],"_id":"6fe37c18-8dc5-4baa-b6e0-5546353907bb","abstract":"In this paper we compare the performance of interest point descriptors. Many different descriptors have been proposed in the literature. However, it is unclear which descriptors are more appropriate and how their performance depends on the interest point detector. The descriptors should be distinctive and at the same time robust to changes in viewing conditions as well as to errors of the point detector. Our evaluation uses as criterion detection rate with respect to false positive rate and is carried out for different image transformations. We compare SIFT descriptors (Lowe, 1999), steerable filters (Freeman and Adelson, 1991), differential invariants (Koenderink ad van Doorn, 1987), complex filters (Schaffalitzky and Zisserman, 2002), moment invariants (Van Gool et al., 1996) and cross-correlation for different types of interest points. In this evaluation, we observe that the ranking of the descriptors does not depend on the point detector and that SIFT descriptors perform best. Steerable filters come second ; they can be considered a good choice given the low dimensionality.","title":"A performance evaluation of local descriptors","venue":"computer vision and pattern recognition","year":2003,"__v":0,"citationCount":683},{"authors":["Yan Ke","Rahul Sukthankar"],"references":["28005624-c0e8-4c62-b585-6e362c3dc8d5","34758e0a-3def-447b-9c5e-e82a206426b5","36800655-b2ff-4eb7-9070-c6be304c4baa","509e1ae2-768b-4417-bebe-d90cf1e0fdae","6018a516-8149-4bce-bc33-5449d86e58c2","608a581a-0e03-435a-9067-c0e0982567af","6fe37c18-8dc5-4baa-b6e0-5546353907bb","7ab7b36d-baae-4b21-89fc-69389fcabc44","aec2ffaf-e691-4884-9304-7d7e14733b2e","b944f77f-113b-4a02-ae5e-d4a124b8fd5b","c455fb04-4566-4648-ad6f-3cf2245e507c","d7b1fba1-b5f8-4377-88a8-d2fc69f723b7"],"_id":"a5254ae0-1ce1-4390-b9f8-8d5a3dcb1e62","abstract":"Stable local feature detection and representation is a fundamental component of many image registration and object recognition algorithms. Mikolajczyk and Schmid (June 2003) recently evaluated a variety of approaches and identified the SIFT [D. G. Lowe, 1999] algorithm as being the most resistant to common image deformations. This paper examines (and improves upon) the local image descriptor used by SIFT. Like SIFT, our descriptors encode the salient aspects of the image gradient in the feature point's neighborhood; however, instead of using SIFT's smoothed weighted histograms, we apply principal components analysis (PCA) to the normalized gradient patch. Our experiments demonstrate that the PCA-based local descriptors are more distinctive, more robust to image deformations, and more compact than the standard SIFT representation. We also present results showing that using these descriptors in an image retrieval application results in increased accuracy and faster matching.","title":"PCA-SIFT: a more distinctive representation for local image descriptors","venue":"computer vision and pattern recognition","year":2004,"__v":0,"citationCount":1138},{"authors":["David G. Lowe"],"references":["00a4e16f-6b65-4ad2-bedc-b19d9cbc2cfe","01a0f825-a308-455b-93fc-e62defc0e3b0","035f8537-61a7-4c4f-b9fe-120f913a38b0","03a42efa-a19c-4b19-a881-9c7ff63865ce","05c3e696-6add-4b0d-b867-e6f1c98deb9b","2fa2e5ba-11d3-4691-91e1-807b8ef7d8a5","32d9eaee-c68f-4479-aa67-837d3cc91a05","34758e0a-3def-447b-9c5e-e82a206426b5","5437c0a0-8f20-49c3-86e5-9d860f3e4f04","5dcd5949-faa9-4af3-8c6f-b285dd3b6566","5f1992df-975f-49e7-bd88-aee0740317cf","5f84f09f-7644-447c-89e1-8dc9ee334197","6018a516-8149-4bce-bc33-5449d86e58c2","60285266-7da2-474e-b05a-b380c836f665","768eea6d-8e82-4bbf-8bdd-1f2338ded29f","791e9257-d7a0-41fe-b471-bde48f3c4a04","7ab7b36d-baae-4b21-89fc-69389fcabc44","7b3f5f5b-a965-4656-9a6f-2f9740625176","899de8c7-9cd9-4dd5-82f1-ad9acb801f8e","a00704dc-a2fa-4267-b7a6-427167d99521","a0fa7ae2-61e5-48a9-be10-86440416129f","a748e0f4-ee6f-41ad-a2a5-1a5a6751086d","b3e60214-b54c-4e8f-9315-a6975c760f4c","b4685927-0ad9-466b-b2c6-2e1764475726","c455fb04-4566-4648-ad6f-3cf2245e507c","ccdefe89-9b16-4c22-8bb8-bd314ccad6e1","d20995f6-529c-41c6-b75e-a169b005fb5c","d9b9f667-9d8a-4723-a6c4-c19b941acd46","df9fe96c-752e-49be-a8c4-8b098ab51e22","ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d","f6272ea9-0360-47ed-90a5-651ea958143f"],"_id":"b944f77f-113b-4a02-ae5e-d4a124b8fd5b","abstract":"This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance.","title":"Distinctive Image Features from Scale-Invariant Keypoints","venue":"International Journal of Computer Vision","year":2004,"__v":0,"citationCount":16229},{"authors":["Krystian Mikolajczyk","Cordelia Schmid"],"references":["00a4e16f-6b65-4ad2-bedc-b19d9cbc2cfe","09346dc3-f4d0-43a4-8f0b-27e02bcd336e","0aae4e44-abdb-4948-9462-61f6e52162ba","0d287faa-99bb-42df-98a7-24fcd601b9a4","19195bc1-7aff-4dd3-91cc-25402c343a19","21a8e8fd-0172-4e9a-8474-7024eb0bf979","21c67dad-f0eb-4479-afe7-fdf4a71eef01","2d6c9f60-ea78-44a8-b5f9-6964575dd196","33711daf-2a44-4f42-8466-c7801f29959b","34758e0a-3def-447b-9c5e-e82a206426b5","36800655-b2ff-4eb7-9070-c6be304c4baa","37031566-2033-44cb-a87e-91a9bb37996f","3b744649-d7a0-46c3-b242-9e0060d8ecfa","4e58f9b5-8562-4f17-830f-f055449867fc","509e1ae2-768b-4417-bebe-d90cf1e0fdae","5149d3c0-5ac9-47ba-9fb0-3d2ef757b0e8","568f1994-f91e-413e-92fd-87dbbb9642a8","5f1992df-975f-49e7-bd88-aee0740317cf","6018a516-8149-4bce-bc33-5449d86e58c2","60285266-7da2-474e-b05a-b380c836f665","608a581a-0e03-435a-9067-c0e0982567af","683dd26d-5c59-4feb-9fbd-2bcf3cc1942f","6fe37c18-8dc5-4baa-b6e0-5546353907bb","72c27d5a-23c5-4d1b-a000-280b87b368ee","7ab7b36d-baae-4b21-89fc-69389fcabc44","853b29ea-c6d1-497e-bad3-b608d370e7e2","a5254ae0-1ce1-4390-b9f8-8d5a3dcb1e62","a8c6ead3-d61a-4f6a-a702-08743f19eec9","b4685927-0ad9-466b-b2c6-2e1764475726","b592576f-ff29-4a68-9b2f-8a8ad02e9c70","b944f77f-113b-4a02-ae5e-d4a124b8fd5b","c455fb04-4566-4648-ad6f-3cf2245e507c","e2204e92-e6dc-4884-9bbc-200029491fc7","e927dff1-6ed4-45fd-8852-eb804e11e665","ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d","fc9638b8-572c-4b23-aab2-92e2dd3b79f8","ffa029cf-7240-4723-8339-51fac57f9f28"],"_id":"8d8e7d51-3223-4776-bf6a-40306774b8a1","abstract":"In this paper, we compare the performance of descriptors computed for local interest regions, as, for example, extracted by the Harris-Affine detector [Mikolajczyk, K and Schmid, C, 2004]. Many different descriptors have been proposed in the literature. It is unclear which descriptors are more appropriate and how their performance depends on the interest region detector. The descriptors should be distinctive and at the same time robust to changes in viewing conditions as well as to errors of the detector. Our evaluation uses as criterion recall with respect to precision and is carried out for different image transformations. We compare shape context [Belongie, S, et al., April 2002], steerable filters [Freeman, W and Adelson, E, Setp. 1991], PCA-SIFT [Ke, Y and Sukthankar, R, 2004], differential invariants [Koenderink, J and van Doorn, A, 1987], spin images [Lazebnik, S, et al., 2003], SIFT [Lowe, D. G., 1999], complex filters [Schaffalitzky, F and Zisserman, A, 2002], moment invariants [Van Gool, L, et al., 1996], and cross-correlation for different types of interest regions. We also propose an extension of the SIFT descriptor and show that it outperforms the original method. Furthermore, we observe that the ranking of the descriptors is mostly independent of the interest region detector and that the SIFT-based descriptors perform best. Moments and steerable filters show the best performance among the low dimensional descriptors.","title":"A performance evaluation of local descriptors","venue":"IEEE Transactions on Pattern Analysis and Machine Intelligence","year":2005,"__v":0,"citationCount":2762}],"offsprings":["50252efa-a843-4cc6-a591-22f527ee3d6c"]},"fcb41378-32f7-4aab-8458-fc5a99d74f92":{"authors":["Ron Kohavi"],"references":[],"_id":"fcb41378-32f7-4aab-8458-fc5a99d74f92","abstract":"We review accuracy estimation methods and compare the two most common methods crossvalidation and bootstrap. Recent experimental results on artificial data and theoretical re cults in restricted settings have shown that for selecting a good classifier from a set of classifiers (model selection), ten-fold cross-validation may be better than the more expensive leaveone-out cross-validation. We report on a largescale experiment--over half a million runs of C4.5 and a Naive-Bayes algorithm--to estimate the effects of different parameters on these algrithms on real-world datasets. For crossvalidation we vary the number of folds and whether the folds are stratified or not, for bootstrap, we vary the number of bootstrap samples. Our results indicate that for real-word datasets similar to ours, The best method to use for model selection is ten fold stratified cross validation even if computation power allows using more folds.","title":"A study of cross-validation and bootstrap for accuracy estimation and model selection","venue":"international joint conference on artificial intelligence","year":1995,"__v":0,"citationCount":1946,"parents":{"28e70562-4760-4398-bbf3-04ecbcb2aca3":0,"3a90b5d2-3377-4ffa-9545-9ef332679370":0,"842c30d5-98b6-463d-9a23-4841a3e07eb9":0,"bece5a13-22f4-4a10-b975-81acbda11207":20,"e69a0393-544b-4ff2-ac35-ef2ed82282b4":20},"keyword":{"28e70562-4760-4398-bbf3-04ecbcb2aca3":11.219444444444447,"3a90b5d2-3377-4ffa-9545-9ef332679370":9.53915343915344,"842c30d5-98b6-463d-9a23-4841a3e07eb9":11.279629629629628,"bece5a13-22f4-4a10-b975-81acbda11207":9.932685185185182,"e69a0393-544b-4ff2-ac35-ef2ed82282b4":10.116084656084656},"topic":["fold","crossvalid","select","method","bootstrap"],"offsprings":["685b313d-8a77-481e-9456-e405a1d29549"]},"153c5014-dc7a-44a8-a93f-5cd27f1193df":{"authors":["Karen Simonyan","Andrew Zisserman"],"references":["051956bb-f64b-4fdb-87f8-3e2868b8b5d8","176a7436-78ea-4c2a-82e6-7930ab023bd1","2b6a3d0f-368f-45bb-be23-4e82f62fbbf7","e2f7a74a-8430-4463-94ce-fe85dfd309f9"],"_id":"153c5014-dc7a-44a8-a93f-5cd27f1193df","abstract":"Abstract: In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.","title":"Very Deep Convolutional Networks for Large-Scale Image Recognition","venue":"international conference on learning representations","year":2015,"__v":0,"citationCount":2515,"parents":{"04cb0d83-273e-498f-af4f-3c5b0554dbfb":15.625,"051956bb-f64b-4fdb-87f8-3e2868b8b5d8":25,"0fb0a842-cb06-4b37-9738-a4d18a55ec23":9.375,"176a7436-78ea-4c2a-82e6-7930ab023bd1":15.625,"1ce76b6e-e1b0-4c1e-8f24-282b4f686fc5":12.5,"28d47fcd-4f94-4de9-b57b-99ba4545b867":25,"2b6a3d0f-368f-45bb-be23-4e82f62fbbf7":0,"2d9c1391-7c29-4b74-9c05-d45afeb103bb":50,"32fac192-89d7-4cb2-b6c6-f1a4e5fc9bbf":18.75,"3b23400e-aa6d-4ee3-b17c-82c04d98d157":37.5,"493f502b-b1b8-412c-95fd-3c1103480f1d":46.875,"5edc47ab-a53e-4cb1-8003-de5dc5cc7fb3":6.25,"65404116-7ed8-404b-a87a-e578deb8d7cb":6.25,"6a97a03d-7337-4f4a-a8db-714d81cff194":28.125,"6d324aa1-fcc4-4808-ae21-472982517e5e":15.625,"8ee6231d-f5b8-41a2-b023-ae33f2c19535":15.625,"97fa1c18-05bf-47c9-b72d-5d712b186ccd":0,"ae3e7593-586f-495f-9416-4b50ed1fcd10":0,"b9632516-3e2e-4cf7-a6d8-43f317d43488":3.125,"bf248c6c-2c05-4101-9a38-35460518f9d7":21.875,"c812244d-0de8-4e3c-8133-1e834bc9dbd0":15.625,"c9482f1f-6600-44a7-a69a-e63ef13cdff8":0,"ca9cac9c-5952-467c-b8ef-2542bab992c6":15.625,"d41cbe23-f9c1-40ea-89eb-bc7b840432f1":18.75,"db8d3f57-09f9-4b09-a057-3e97e2a2b7fc":25,"dc59f316-9db3-49b6-9b19-70a1d4977d86":25,"e2f7a74a-8430-4463-94ce-fe85dfd309f9":6.25,"ec0ca0bd-9848-4f47-b6d9-8ef37fd9b3ca":6.25,"eecae39b-f612-4235-8071-448e80a32fe2":12.5,"f26a8a8a-9ad6-4dc1-8ae2-a59be1f80267":6.25,"f64b5ccd-849a-4ac1-97ff-f34842543115":12.5,"fbdfc1ca-09ef-47f8-a0d1-adaf626a8562":3.125},"keyword":{"04cb0d83-273e-498f-af4f-3c5b0554dbfb":9.832777777777778,"051956bb-f64b-4fdb-87f8-3e2868b8b5d8":10.17137566137566,"0fb0a842-cb06-4b37-9738-a4d18a55ec23":8.18037037037037,"176a7436-78ea-4c2a-82e6-7930ab023bd1":10.05238095238095,"1ce76b6e-e1b0-4c1e-8f24-282b4f686fc5":10.22632275132275,"28d47fcd-4f94-4de9-b57b-99ba4545b867":8.073544973544973,"2b6a3d0f-368f-45bb-be23-4e82f62fbbf7":5.8082275132275125,"2d9c1391-7c29-4b74-9c05-d45afeb103bb":9.182010582010582,"32fac192-89d7-4cb2-b6c6-f1a4e5fc9bbf":8.287354497354498,"3b23400e-aa6d-4ee3-b17c-82c04d98d157":9.91283068783069,"493f502b-b1b8-412c-95fd-3c1103480f1d":9.011243386243386,"5edc47ab-a53e-4cb1-8003-de5dc5cc7fb3":7.466084656084655,"65404116-7ed8-404b-a87a-e578deb8d7cb":10.78222222222222,"6a97a03d-7337-4f4a-a8db-714d81cff194":8.851587301587301,"6d324aa1-fcc4-4808-ae21-472982517e5e":6.210939153439153,"8ee6231d-f5b8-41a2-b023-ae33f2c19535":10.918650793650793,"97fa1c18-05bf-47c9-b72d-5d712b186ccd":7.6489417989418,"ae3e7593-586f-495f-9416-4b50ed1fcd10":11.188571428571427,"b9632516-3e2e-4cf7-a6d8-43f317d43488":8.809060846560847,"bf248c6c-2c05-4101-9a38-35460518f9d7":11.249894179894179,"c812244d-0de8-4e3c-8133-1e834bc9dbd0":9.189100529100529,"c9482f1f-6600-44a7-a69a-e63ef13cdff8":10.531216931216932,"ca9cac9c-5952-467c-b8ef-2542bab992c6":9.53148148148148,"d41cbe23-f9c1-40ea-89eb-bc7b840432f1":10.111719576719578,"db8d3f57-09f9-4b09-a057-3e97e2a2b7fc":6.417089947089947,"dc59f316-9db3-49b6-9b19-70a1d4977d86":7.7173280423280435,"e2f7a74a-8430-4463-94ce-fe85dfd309f9":8.98941798941799,"ec0ca0bd-9848-4f47-b6d9-8ef37fd9b3ca":10.427452177452176,"eecae39b-f612-4235-8071-448e80a32fe2":6.267063492063492,"f26a8a8a-9ad6-4dc1-8ae2-a59be1f80267":9.086190476190476,"f64b5ccd-849a-4ac1-97ff-f34842543115":6.938902116402116,"fbdfc1ca-09ef-47f8-a0d1-adaf626a8562":5.691216931216931},"topic":["depth","show","represent","network","convolut"],"groups":[{"authors":["Olga Russakovsky","Jia Deng","Hao Su","Jonathan Krause","Sanjeev Satheesh","Sean Ma","Zhiheng Huang","Andrej Karpathy","Aditya Khosla","Michael S. Bernstein","Alexander C. Berg","Li Fei-Fei"],"references":["04c47f14-8533-41ff-bafd-affc1eb52287","051956bb-f64b-4fdb-87f8-3e2868b8b5d8","0b661216-1fcc-4a13-94ee-62958f986647","0cfe22b1-6883-4df2-ab04-7c94e9486b8f","0fb0a842-cb06-4b37-9738-a4d18a55ec23","1182c719-2ae0-49e4-ad7d-9baf94a5dc88","12f40b38-cd99-4801-8074-d765a29a2101","153c5014-dc7a-44a8-a93f-5cd27f1193df","176a7436-78ea-4c2a-82e6-7930ab023bd1","1fe06ec6-c5cb-4800-ba8f-4ea907fcba06","2398c5fc-8288-4fbd-8cc2-eff409812cb1","26316adf-569e-49bc-a289-c1ba311624f6","28414617-6b1f-4b81-8293-3109278684b1","2b6a3d0f-368f-45bb-be23-4e82f62fbbf7","2d94566b-ac2d-49b0-a867-2392c41a2172","2d9c1391-7c29-4b74-9c05-d45afeb103bb","2dfe0de0-38b2-4c0f-bea9-875c171eb328","2ead02c2-afd0-48df-947c-94f737aa8c1f","2f4bbdb0-55cc-48e9-a986-71fc20a69a5c","309f11f3-0575-4787-9f2d-d3888c5db5b1","30d96b63-ab8b-4a93-904d-65e87ba32327","32a53bab-1ede-4869-98ad-d2ff0c1e3367","3609ce2c-c21e-4e94-a17e-de31443ecb90","3b23400e-aa6d-4ee3-b17c-82c04d98d157","40e36f49-9f2f-4586-8899-a282fdd320d1","42b60ea2-1759-4fbd-9530-d3f2fa90f534","49b925b3-f7d8-4904-aa89-eebd5c80f287","4f8a4fdb-7ab9-454e-981d-b2b016613ac1","5700170c-68b7-48ce-8194-2daa5444b380","589efc91-a3df-4c70-a613-67f249d7b33f","5b8cd8f4-17c9-4ac3-ba05-ebeba7cd6691","654b9e17-96df-4227-bc81-f97e1ddda6d6","69a0f5ae-94ec-4c61-ad1c-d10057415b88","69a6a94a-6d69-404c-bf54-04a61ba3e6c0","69c13a6c-0e73-4603-a98c-6e04ebe04c5a","6a97a03d-7337-4f4a-a8db-714d81cff194","6cad2c4a-3568-42db-8c8d-cfd56105de0e","6d324aa1-fcc4-4808-ae21-472982517e5e","7cdd68ef-876b-4214-bd85-38dd01ac99c9","826bd128-4189-4e04-8e8d-d2ebfd68c432","837e056f-ea71-4be1-bde0-e3166cfee2fd","83c737b8-e084-4766-ba6e-131e6a1c017c","841394ee-e677-4024-8497-47bf880c6ab9","86b626a6-f948-45ea-8e92-8102e0dc5ef8","8a07711d-87a2-4929-9cb0-c3a3c05048ba","8db677a7-de9a-476b-ac75-169a962cf6cd","8ecbb404-d99e-4991-bde0-9caa49f8a3e8","8ee6231d-f5b8-41a2-b023-ae33f2c19535","95c111f4-55d0-455e-884a-4485ff03b494","97fa1c18-05bf-47c9-b72d-5d712b186ccd","983a2eff-22fe-40d2-bb87-fea35e63db6c","98801e79-fc9d-4c6a-a383-10e937c9d008","9f0be55e-7ea1-41b1-bb8d-c3822ead7fd8","a13418d7-3585-4888-a027-85e441bfd354","a698b4ae-145f-43d4-89be-e96321ce3850","a6ee5009-aebc-4cda-8ef9-d855297b949c","ab3afb93-8ca0-4556-ae60-11199dc263c2","ac5e3fe4-3b1d-412d-a03b-3247d39f62d5","accb8a46-f471-42e7-a776-4894ae8fe3fd","adea0a98-d74d-43be-a238-a1ef027c6a58","b1f03fb2-d9d9-4016-8596-29cc8c2800a5","b32a4dff-4928-4049-b545-1b20344ddb5b","b3e241a6-126f-40fb-a063-8ed7d0223a3c","b944f77f-113b-4a02-ae5e-d4a124b8fd5b","b9632516-3e2e-4cf7-a6d8-43f317d43488","bc39fa8d-788a-4ae6-9755-4cf59ecee2a5","c7def717-ad62-4168-9ae3-5484a67399c1","c812244d-0de8-4e3c-8133-1e834bc9dbd0","c9482f1f-6600-44a7-a69a-e63ef13cdff8","cb6dc6ec-fca0-4abe-a786-89c8aa42008c","d14a35f9-0443-4c4c-b53c-3cae7a27555d","e0296c28-35a4-41c1-9fd2-58e75d4819be","e0ac4812-7729-4a2d-8a1f-74b1b7c8eb5d","e2f7a74a-8430-4463-94ce-fe85dfd309f9","e3a5cec9-7e82-4c14-86ab-0d95a92712a7","e81dc85c-98d3-408c-9dee-6d43fa5b8911","f1639cc6-356f-4170-9dea-9be79c84f899","f2d49150-35de-4fd5-ac46-eb071d1cc73e","fbdfc1ca-09ef-47f8-a0d1-adaf626a8562"],"_id":"493f502b-b1b8-412c-95fd-3c1103480f1d","abstract":"The ImageNet Large Scale Visual Recognition Challenge is a benchmark in object category classification and detection on hundreds of object categories and millions of images. The challenge has been run annually from 2010 to present, attracting participation from more than fifty institutions. This paper describes the creation of this benchmark dataset and the advances in object recognition that have been possible as a result. We discuss the challenges of collecting large-scale ground truth annotation, highlight key breakthroughs in categorical object recognition, provide a detailed analysis of the current state of the field of large-scale image classification and object detection, and compare the state-of-the-art computer vision accuracy with human accuracy. We conclude with lessons learned in the 5 years of the challenge, and propose future directions and improvements.","title":"ImageNet Large Scale Visual Recognition Challenge","venue":"International Journal of Computer Vision","year":2015,"__v":0,"citationCount":1457},{"authors":["Christian Szegedy","Wei Liu","Yangqing Jia","Pierre Sermanet","Scott E. Reed","Dragomir Anguelov","Dumitru Erhan","Vincent Vanhoucke","Andrew Rabinovich"],"references":["0fb0a842-cb06-4b37-9738-a4d18a55ec23","176a7436-78ea-4c2a-82e6-7930ab023bd1","2d94566b-ac2d-49b0-a867-2392c41a2172","3b2f341e-55fc-48ff-ab91-a26e0f8ce761","5913b912-d090-4aa7-8e5b-9e7e59076119","6a97a03d-7337-4f4a-a8db-714d81cff194","6d324aa1-fcc4-4808-ae21-472982517e5e","708441ca-fc5d-41ca-8ab2-c7b705d451b9","73dbdf1f-da95-4b8c-9109-c966e08c6f13","88d1f7c7-bec0-4e01-a7c2-e2a895ee36d4","a1494dfe-ca52-4757-9a07-d0a0df32490e","a4d9008a-d15b-4d87-a173-bef2f4b0d453","ae3e7593-586f-495f-9416-4b50ed1fcd10","b9632516-3e2e-4cf7-a6d8-43f317d43488","cbf3ea5c-fa19-43b7-96ae-2fce79cca09b","cd035d3b-0a73-4c0d-b813-0632409612ad","e2f7a74a-8430-4463-94ce-fe85dfd309f9","f26a8a8a-9ad6-4dc1-8ae2-a59be1f80267"],"_id":"051956bb-f64b-4fdb-87f8-3e2868b8b5d8","abstract":"We propose a deep convolutional neural network architecture codenamed Inception that achieves the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC14). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. By a carefully crafted design, we increased the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation used in our submission for ILSVRC14 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classification and detection.","title":"Going deeper with convolutions","venue":"computer vision and pattern recognition","year":2015,"__v":0,"citationCount":1580},{"authors":["Matthew D. Zeiler","Rob Fergus"],"references":["04c47f14-8533-41ff-bafd-affc1eb52287","176a7436-78ea-4c2a-82e6-7930ab023bd1","195ac389-5a07-4fd4-9c12-be42420720bc","1d4f35b8-af72-4b23-b999-74de292d696b","2a28e4be-93ec-4d51-8399-cd9d9fdee560","2b6a3d0f-368f-45bb-be23-4e82f62fbbf7","2d94566b-ac2d-49b0-a867-2392c41a2172","32c1bdf2-cea7-4d60-8289-2207eaa41a77","39ca24c1-da5a-42fc-888c-d75069728d5e","433969bb-d29f-4cac-83a5-ccfb5c6c7b4e","483ca5b5-59c1-46f2-8cc3-cfa197377206","4bbacb77-1097-4cc5-b001-6554ea01fb75","4dba26db-f090-4ac6-90dd-091680676a81","5c4e8000-7daa-4665-a85d-9e4071b6fa19","5fbd2ca9-c4fa-4087-aa39-42dc03acd8ae","6d324aa1-fcc4-4808-ae21-472982517e5e","78b0ba4b-b8a0-4689-9972-cabab721ab40","7936f72d-c9e4-4e3d-af8e-5df00782eb95","837e056f-ea71-4be1-bde0-e3166cfee2fd","88af66e6-c531-4f6a-a952-9dbdbcd28a67","89f10062-acf1-4171-b882-f3222c3a357e","8b3efecd-c21c-4d30-8eb3-dc721aad3bdd","8fa0a362-6522-48fc-bd5e-24de00ed6511","97fa1c18-05bf-47c9-b72d-5d712b186ccd","983a2eff-22fe-40d2-bb87-fea35e63db6c","9cf78907-bf80-49bd-96c3-fdf5f91383ee","a4786a29-ac24-40f1-815d-5fa12f7f86cc","ae3e7593-586f-495f-9416-4b50ed1fcd10","ae71e737-e28a-4e5d-8446-78c53b6d4fbd","aff1fa6e-bac4-4e55-8450-5bc014634855","b23e0c5f-62cd-4555-acfd-90cb73d16fab","c01540df-7322-4824-beea-7c716be7f3ed","c46d7dde-33df-4406-8df8-2c70e13cc5d2","c812244d-0de8-4e3c-8133-1e834bc9dbd0","d35b5e50-db29-4ef8-aa29-37a3dd451b80","db8d3f57-09f9-4b09-a057-3e97e2a2b7fc","e1a24833-9195-46f6-831f-f4c19189fb3a","e2f7a74a-8430-4463-94ce-fe85dfd309f9","ee289120-5e7f-4cde-98a0-a523e5150994","f64b5ccd-849a-4ac1-97ff-f34842543115"],"_id":"6a97a03d-7337-4f4a-a8db-714d81cff194","abstract":"Large Convolutional Network models have recently demon- strated impressive classification performance on the ImageNet bench- mark Krizhevsky et al. (18). However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we explore both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the oper- ation of the classifier. Used in a diagnostic role, these visualizations allow us to find model architectures that outperform Krizhevsky et al. on the ImageNet classification benchmark. We also perform an ablation study to discover the performance contribution from different model layers. We show our ImageNet model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-of- the-art results on Caltech-101 and Caltech-256 datasets.","title":"Visualizing and Understanding Convolutional Networks","venue":"european conference on computer vision","year":2013,"__v":0,"citationCount":925},{"authors":["Kaiming He","Xiangyu Zhang","Shaoqing Ren","Jian Sun"],"references":["04c47f14-8533-41ff-bafd-affc1eb52287","051956bb-f64b-4fdb-87f8-3e2868b8b5d8","098c508f-2a87-4fe6-9642-4e3b2d2aacff","0fb0a842-cb06-4b37-9738-a4d18a55ec23","153c5014-dc7a-44a8-a93f-5cd27f1193df","176a7436-78ea-4c2a-82e6-7930ab023bd1","1a0d45f7-5297-4c21-99e1-f65a548c0dda","1f556c88-b553-4c75-b243-92d8200f8149","285dd088-2a2f-46cb-8d9d-294951c79b0d","2b6a3d0f-368f-45bb-be23-4e82f62fbbf7","30d96b63-ab8b-4a93-904d-65e87ba32327","3b23400e-aa6d-4ee3-b17c-82c04d98d157","493f502b-b1b8-412c-95fd-3c1103480f1d","5922611d-9333-486f-9eeb-1d8c063c99f2","6a97a03d-7337-4f4a-a8db-714d81cff194","6cc9ce42-33dd-4b18-87b9-42247d5dc57a","6d324aa1-fcc4-4808-ae21-472982517e5e","6d3bd422-9563-4b8b-ad73-473fb89c81dd","708441ca-fc5d-41ca-8ab2-c7b705d451b9","73dbdf1f-da95-4b8c-9109-c966e08c6f13","7cdd68ef-876b-4214-bd85-38dd01ac99c9","83c737b8-e084-4766-ba6e-131e6a1c017c","a5dca015-0a1d-43ac-a2a2-17b22e7787be","a641f3ab-ecb8-4ae9-8728-49b0e2bd26e6","acf46750-428a-4f63-95b2-aabf1d40b6b6","ae3e7593-586f-495f-9416-4b50ed1fcd10","b944f77f-113b-4a02-ae5e-d4a124b8fd5b","b9632516-3e2e-4cf7-a6d8-43f317d43488","bf248c6c-2c05-4101-9a38-35460518f9d7","c1b6b493-01ef-420f-be44-7bacfe34e846","c812244d-0de8-4e3c-8133-1e834bc9dbd0","c8b04e55-edb2-41f3-ad55-53bb372e47ab","c9482f1f-6600-44a7-a69a-e63ef13cdff8","db8d3f57-09f9-4b09-a057-3e97e2a2b7fc","dd83785a-dd19-41e3-9b25-ebabbd48d336","e0ac4812-7729-4a2d-8a1f-74b1b7c8eb5d","e2f7a74a-8430-4463-94ce-fe85dfd309f9","eb65e474-adef-464f-8a9d-ca65646f9eb7","ef0667a4-5c6a-4811-9479-12a505bc379a","f2d49150-35de-4fd5-ac46-eb071d1cc73e","f92350aa-bbb5-47c4-a132-d1b8c98b5f2e","fbdfc1ca-09ef-47f8-a0d1-adaf626a8562"],"_id":"2d9c1391-7c29-4b74-9c05-d45afeb103bb","abstract":"Existing deep convolutional neural networks (CNNs) require a fixed-size (e.g., 224  $\\times$      224) input image. This requirement is “artificial” and may reduce the recognition accuracy for the images or sub-images of an arbitrary size/scale. In this work, we equip the networks with another pooling strategy, “spatial pyramid pooling”, to eliminate the above requirement. The new network structure, called SPP-net, can generate a fixed-length representation regardless of image size/scale. Pyramid pooling is also robust to object deformations. With these advantages, SPP-net should in general improve all CNN-based image classification methods. On the ImageNet 2012 dataset, we demonstrate that SPP-net boosts the accuracy of a variety of CNN architectures despite their different designs. On the Pascal VOC 2007 and Caltech101 datasets, SPP-net achieves state-of-the-art classification results using a single full-image representation and no fine-tuning. The power of SPP-net is also significant in object detection. Using SPP-net, we compute the feature maps from the entire image only once, and then pool features in arbitrary regions (sub-images) to generate fixed-length representations for training the detectors. This method avoids repeatedly computing the convolutional features. In processing test images, our method is 24-102   $\\times$       faster than the R-CNN method, while achieving better or comparable accuracy on Pascal VOC 2007. In ImageNet Large Scale Visual Recognition Challenge (ILSVRC) 2014, our methods rank #2 in object detection and #3 in image classification among all 38 teams. This manuscript also introduces the improvement made for this competition.","title":"Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition","venue":"IEEE Transactions on Pattern Analysis and Machine Intelligence","year":2015,"__v":0,"citationCount":406},{"authors":["Sean Bell","Paul Upchurch","Noah Snavely","Kavita Bala"],"references":["051956bb-f64b-4fdb-87f8-3e2868b8b5d8","090af1dd-85e1-49f1-ae85-9928df7f709f","0c710d83-4db0-4d18-b943-b23ec0d2063a","0fb0a842-cb06-4b37-9738-a4d18a55ec23","153c5014-dc7a-44a8-a93f-5cd27f1193df","176a7436-78ea-4c2a-82e6-7930ab023bd1","1bafd4ea-35e8-4433-9481-1865482725db","29b27984-ff06-4c52-a744-a205bad37fc4","32a53bab-1ede-4869-98ad-d2ff0c1e3367","493f502b-b1b8-412c-95fd-3c1103480f1d","49639d64-360f-4be1-b5f8-035d167b1f16","555574ea-625c-4bd0-9829-ba3a103eb70d","6886aa45-e906-49d1-b0fe-4ecce739df0f","6a97a03d-7337-4f4a-a8db-714d81cff194","725ff5fd-76fe-41b4-b50d-00405a51ac27","826bd128-4189-4e04-8e8d-d2ebfd68c432","83c737b8-e084-4766-ba6e-131e6a1c017c","861f8721-e382-4ae0-9dbf-64124f09e401","8db677a7-de9a-476b-ac75-169a962cf6cd","a318732e-eb60-4e0d-b505-b9a9f525583d","ae3e7593-586f-495f-9416-4b50ed1fcd10","ae862793-16ce-4fb3-82c4-ada0abe0ad01","b1f03fb2-d9d9-4016-8596-29cc8c2800a5","c2372449-96ad-4264-bf09-733d67164dd1","c93eac1a-7d9a-48ab-9fb4-389c85bea00e","cc756b7f-d8bf-42f2-b552-26c1dd0856f3","d161425d-22ea-4919-a2bc-cb283704192b","d823f3c2-8013-4c94-96c8-b90912d364e2","db8d3f57-09f9-4b09-a057-3e97e2a2b7fc","e2f7a74a-8430-4463-94ce-fe85dfd309f9","e46b1853-c375-4277-afa5-6d1278b90736","e66dc403-1628-477c-8f42-9683752e6132"],"_id":"dc59f316-9db3-49b6-9b19-70a1d4977d86","abstract":"Recognizing materials in real-world images is a challenging task. Real-world materials have rich surface texture, geometry, lighting conditions, and clutter, which combine to make the problem particularly difficult. In this paper, we introduce a new, large-scale, open dataset of materials in the wild, the Materials in Context Database (MINC), and combine this dataset with deep learning to achieve material recognition and segmentation of images in the wild. MINC is an order of magnitude larger than previous material databases, while being more diverse and well-sampled across its 23 categories. Using MINC, we train convolutional neural networks (CNNs) for two tasks: classifying materials from patches, and simultaneous material recognition and segmentation in full images. For patch-based classification on MINC we found that the best performing CNN architectures can achieve 85.2% mean class accuracy. We convert these trained CNN classifiers into an efficient fully convolutional framework combined with a fully connected conditional random field (CRF) to predict the material at every pixel in an image, achieving 73.1% mean class accuracy. Our experiments demonstrate that having a large, well-sampled dataset such as MINC is crucial for real-world material recognition and segmentation.","title":"Material recognition in the wild with the Materials in Context Database","venue":"computer vision and pattern recognition","year":2015,"__v":0,"citationCount":41},{"authors":["Ken Chatfield","Karen Simonyan","Andrea Vedaldi","Andrew Zisserman"],"references":["0fb0a842-cb06-4b37-9738-a4d18a55ec23","176a7436-78ea-4c2a-82e6-7930ab023bd1","1a0d45f7-5297-4c21-99e1-f65a548c0dda","1bd2029f-3807-4cfa-a9d3-5774748f6b14","1fe06ec6-c5cb-4800-ba8f-4ea907fcba06","285dd088-2a2f-46cb-8d9d-294951c79b0d","2b6a3d0f-368f-45bb-be23-4e82f62fbbf7","2d9c1391-7c29-4b74-9c05-d45afeb103bb","5a7c9d23-6d10-431b-92af-541e4bbb86e3","6a97a03d-7337-4f4a-a8db-714d81cff194","83c737b8-e084-4766-ba6e-131e6a1c017c","86abadf3-518f-4c5f-9151-02f84c7ac2b5","96dcae85-af7b-4374-bff5-c83c02d32276","ad8a85d1-a858-42c6-a2e3-d41a51296a12","ae3e7593-586f-495f-9416-4b50ed1fcd10","bf248c6c-2c05-4101-9a38-35460518f9d7","c812244d-0de8-4e3c-8133-1e834bc9dbd0","c8b04e55-edb2-41f3-ad55-53bb372e47ab","c9482f1f-6600-44a7-a69a-e63ef13cdff8","cad02c75-c67e-4472-a691-422c096956a6","db8d3f57-09f9-4b09-a057-3e97e2a2b7fc","e0ac4812-7729-4a2d-8a1f-74b1b7c8eb5d","e2f7a74a-8430-4463-94ce-fe85dfd309f9","fbdfc1ca-09ef-47f8-a0d1-adaf626a8562"],"_id":"3b23400e-aa6d-4ee3-b17c-82c04d98d157","abstract":"The latest generation of Convolutional Neural Networks (CNN) have achieved impressive results in challenging benchmarks on image recognition and object detection, significantly raising the interest of the community in these methods. Nevertheless, it is still unclear how different CNN methods compare with each other and with previous state-of-the-art shallow representations such as the Bag-of-Visual-Words and the Improved Fisher Vector. This paper conducts a rigorous evaluation of these new techniques, exploring different deep architectures and comparing them on a common ground, identifying and disclosing important implementation details. We identify several useful properties of CNN-based representations, including the fact that the dimensionality of the CNN output layer can be reduced significantly without having an adverse effect on performance. We also identify aspects of deep and shallow methods that can be successfully shared. In particular, we show that the data augmentation techniques commonly applied to CNN-based methods can also be applied to shallow methods, and result in an analogous performance boost. Source code and models to reproduce the experiments in the paper is made publicly available.","title":"Return of the Devil in the Details: Delving Deep into Convolutional Nets","venue":"british machine vision conference","year":2014,"__v":0,"citationCount":565},{"authors":["Jonathan Long","Evan Shelhamer","Trevor Darrell"],"references":["031bbeb0-4dc1-46f9-9984-109c3b3eefae","051956bb-f64b-4fdb-87f8-3e2868b8b5d8","0fb0a842-cb06-4b37-9738-a4d18a55ec23","11cb036e-3726-4600-ab1d-76a56dc20ff9","125e92b0-d879-43ac-bf56-9408a6fea183","153c5014-dc7a-44a8-a93f-5cd27f1193df","176a7436-78ea-4c2a-82e6-7930ab023bd1","1ee6c6af-f18f-4b88-8d66-db763bc6f864","2210e13b-7cad-4ebc-b2af-766259837df3","2d9c1391-7c29-4b74-9c05-d45afeb103bb","37239af4-60de-4422-a8f2-e5c5d3328e72","39f4337b-1dcf-400d-80d0-f3cd0929dee3","40e36f49-9f2f-4586-8899-a282fdd320d1","42efaf01-c82e-4d9f-a09a-bcc7a89e9593","5308ba84-354d-4c47-9f05-8806376145c6","5c711b5d-fa38-4a5b-91b7-c1c3ecb35ba1","62de2ab7-adfd-4b2f-b7c9-3d91ebb1f0ee","6a97a03d-7337-4f4a-a8db-714d81cff194","6cf44c56-1512-400c-a232-1451b3055294","705269ad-19ac-4d26-964c-67326d868761","725ff5fd-76fe-41b4-b50d-00405a51ac27","72640ec0-e5e8-4b68-9508-f8a7edfcc343","7cdbd474-7695-4264-bef5-66e30d074b35","83c737b8-e084-4766-ba6e-131e6a1c017c","84e105e6-d8f4-4438-8626-d0a3dfabf423","8829ee6d-e131-40aa-8d53-4ca7af85702c","8b2111e2-eb0d-4749-bef9-67bda3459fc0","a4382b8f-f7fd-4d84-93ba-04c068c9abf0","a8c95c0c-ca1d-4d01-8d03-e655500c9b55","a9c7a42b-6b20-4ec5-b682-384a678bb804","ae3e7593-586f-495f-9416-4b50ed1fcd10","c514bd88-79ab-423e-a87d-4dd339ab6375","c5a5fcd1-3fba-4978-85b9-639b620e1170","c812244d-0de8-4e3c-8133-1e834bc9dbd0","c8b04e55-edb2-41f3-ad55-53bb372e47ab","c93eac1a-7d9a-48ab-9fb4-389c85bea00e","ca5e1b4b-e10e-4487-ab04-22e8f4ab5202","cb9226f0-c153-4c70-92c0-05d825e1b65a","cccb4b4b-ce7f-4b1f-b68c-cab108f3cecf","d2de642b-7044-4d04-85ea-1e05eea964c6","da4ad8b3-5257-487d-9102-5672be35d3f9","e016d598-1090-4b61-98ab-f47c8650dfa7","e2f7a74a-8430-4463-94ce-fe85dfd309f9","e7f6e82d-380c-427b-98bc-5c79471a7336","e9bbaf5f-2560-4ac6-83a4-d0b4559398c4","ecd6bd43-b662-46db-8e10-bc1833f16d14","f001c62f-1a32-4b6f-b1c7-afee1bb1cf9c","f79125f0-7685-423b-a9a5-bff3e1d0f9df","f96b05ce-e0b1-4c26-929e-1fe675c4b4e3","faf59f35-86db-47aa-98cc-8fa5de633c3e","fe2241f3-445e-4663-874c-75623e7ffbcd"],"_id":"28d47fcd-4f94-4de9-b57b-99ba4545b867","abstract":"Convolutional networks are powerful visual models that yield hierarchies of features. We show that convolutional networks by themselves, trained end-to-end, pixels-to-pixels, exceed the state-of-the-art in semantic segmentation. Our key insight is to build “fully convolutional” networks that take input of arbitrary size and produce correspondingly-sized output with efficient inference and learning. We define and detail the space of fully convolutional networks, explain their application to spatially dense prediction tasks, and draw connections to prior models. We adapt contemporary classification networks (AlexNet [20], the VGG net [31], and GoogLeNet [32]) into fully convolutional networks and transfer their learned representations by fine-tuning [3] to the segmentation task. We then define a skip architecture that combines semantic information from a deep, coarse layer with appearance information from a shallow, fine layer to produce accurate and detailed segmentations. Our fully convolutional network achieves state-of-the-art segmentation of PASCAL VOC (20% relative improvement to 62.2% mean IU on 2012), NYUDv2, and SIFT Flow, while inference takes less than one fifth of a second for a typical image.","title":"Fully convolutional networks for semantic segmentation","venue":"computer vision and pattern recognition","year":2015,"__v":0,"citationCount":976},{"authors":["Ali Sharif Razavian","Hossein Azizpour","Josephine Sullivan","Stefan Carlsson"],"references":["031b2cac-bd70-45b5-96ff-1d228dfa8e28","096b2319-7282-4964-9136-52bc12348bc3","0d25593e-6f5c-4c13-9714-1b7c0bea1492","0fb0a842-cb06-4b37-9738-a4d18a55ec23","14a87495-d809-4665-8e7a-2414fb85a21f","176a7436-78ea-4c2a-82e6-7930ab023bd1","1ac5e6cd-8290-439e-8e3d-c6221bc2400c","1bd2029f-3807-4cfa-a9d3-5774748f6b14","1fe06ec6-c5cb-4800-ba8f-4ea907fcba06","285dd088-2a2f-46cb-8d9d-294951c79b0d","2868fc0e-e80c-435b-b9a1-a8bf7a9628ee","3024f5d1-e300-458e-8bab-e418c45cdae2","3b2f341e-55fc-48ff-ab91-a26e0f8ce761","3b8b60e3-6ef4-419e-aff3-9c7cf021d7bc","42df4133-3d89-43bf-a44b-a6cb57281151","493f502b-b1b8-412c-95fd-3c1103480f1d","4b3ac374-dda8-40ab-b386-e4d856ef48da","4d1bf1ee-d4c4-4faa-9d13-dff3e65af340","5922611d-9333-486f-9eeb-1d8c063c99f2","68917b47-9242-4b69-8d18-54084eabd159","6a97a03d-7337-4f4a-a8db-714d81cff194","6c38b3b4-7562-493d-a40c-fe70abf039a7","6cdbc5d1-e1d0-4675-84c6-6ed716b11d4f","6df06759-1794-4499-bcf1-6dd7dd723498","6e083300-a74c-43f0-8a56-4e7c015e3892","7f824682-4844-4351-8a72-d6fb2af2b1a3","83c737b8-e084-4766-ba6e-131e6a1c017c","88514745-f903-4187-8267-f1d24743461a","9272fb14-2dab-4c5c-b2b1-0a72662d6a7b","9837abf2-827f-45e7-9d4c-033402cc2fa6","98c3a1b5-9fb9-4342-8db3-cb16a068f344","9c9562cb-34a8-4878-b212-2a4647af9b7e","a5dca015-0a1d-43ac-a2a2-17b22e7787be","acf46750-428a-4f63-95b2-aabf1d40b6b6","b19db595-91d0-460b-ae23-5ed027879c51","c1b6b493-01ef-420f-be44-7bacfe34e846","c7ebfaff-f006-4192-9681-33b9085606c6","c812244d-0de8-4e3c-8133-1e834bc9dbd0","d0697e1c-8d74-4d42-a767-af849994044f","db8d3f57-09f9-4b09-a057-3e97e2a2b7fc","e16196fc-ad79-42a7-a19c-92256a179a78","e2f7a74a-8430-4463-94ce-fe85dfd309f9","e850c4c4-203c-4e23-8ac8-a9b9067432b5","e92f3b0d-66cc-42da-9f5f-7ae43be31387","eb5f1301-3952-4bf0-a6e5-04539941d883","efac2ac3-7d5c-4ffe-ab1e-91b38beb116a","f592195b-ced2-408d-a5c0-86a57aba9947","f83df0ca-872d-48df-a31a-266af228a904","faf1d751-b559-4522-bf50-6d88a04d8bd1"],"_id":"bf248c6c-2c05-4101-9a38-35460518f9d7","abstract":"Recent results indicate that the generic descriptors extracted from the convolutional neural networks are very powerful. This paper adds to the mounting evidence that this is indeed the case. We report on a series of experiments conducted for different recognition tasks using the publicly available code and model of the OverFeat network which was trained to perform object classification on ILSVRC13. We use features extracted from the OverFeat network as a generic image representation to tackle the diverse range of recognition tasks of object image classification, scene recognition, fine grained recognition, attribute detection and image retrieval applied to a diverse set of datasets. We selected these tasks and datasets as they gradually move further away from the original task and data the OverFeat network was trained to solve. Astonishingly, we report consistent superior results compared to the highly tuned state-of-the-art systems in all the visual classification tasks on various datasets. For instance retrieval it consistently outperforms low memory footprint methods except for sculptures dataset. The results are achieved using a linear SVM classifier (or L2 distance in case of retrieval) applied to a feature representation of size 4096 extracted from a layer in the net. The representations are further modified using simple augmentation techniques e.g. jittering. The results strongly suggest that features obtained from deep learning with convolutional nets should be the primary candidate in most visual recognition tasks.","title":"CNN Features Off-the-Shelf: An Astounding Baseline for Recognition","venue":"computer vision and pattern recognition","year":2014,"__v":0,"citationCount":680}],"offsprings":[]},"9b19a579-dc25-4dc8-8139-fd9f264983ac":{"authors":["William H. DeLone","Ephraim R. McLean"],"references":[],"_id":"9b19a579-dc25-4dc8-8139-fd9f264983ac","abstract":"Ten years ago, we presented the DeLone and McLean Information Systems (IS) Success Model as a framework and model for measuring the complex-dependent variable in IS research. In this paper, we discuss many of the important IS success research contributions of the last decade, focusing especially on research efforts that apply, validate, challenge, and propose enhancements to our original model. Based on our evaluation of those contributions, we propose minor refinements to the model and propose an updated DeLone and McLean IS Success Model. We discuss the utility of the updated model for measuring e-commerce system success. Finally, we make a series of recommendations regarding current and future measurement of IS success.","title":"The DeLone and McLean Model of Information Systems Success: A Ten-Year Update","venue":"Journal of Management Information Systems","year":2003,"__v":0,"citationCount":1591,"parents":{"02cfa09e-936c-4f58-ada2-70b1071739d6":12.5,"08c36e81-bb0d-41da-b021-8a75ee6cd4f6":15.625,"10899ad6-f266-43eb-9714-c0380346c2c7":6.25,"1d2f5c2a-19fa-458e-affb-6e7961ae9b8d":0,"1fad4a57-0f95-409c-aea8-5086e61cefd8":6.25,"2a7662fe-dc6f-4c83-8af5-a49a65eeb0d9":0,"2df731d1-37e4-4afb-a9b0-60a5361a79ff":3.125,"31de0370-c768-492d-9a3c-b13af24e769c":0,"39b4d0e3-b883-467c-be97-0874e2916be6":3.125,"48781111-6d37-40ba-af55-6ff34568dea7":18.75,"5cf5c9ae-8465-4cf4-b8fe-21036964b328":6.25,"6a5737b2-6b6e-4b6b-a536-7d2f71857606":0,"7244017f-2a87-46ca-ab3d-ddf19bf400a5":6.25,"7407954e-a728-48e9-8856-088577845de8":3.125,"767eacbf-fb87-44f8-bd87-9a4440413602":6.25,"7da2811c-a6df-4fd7-8c30-712957115c82":0,"7efe57f2-cda9-444f-8f2d-32358949189a":6.25,"849ca63d-26a8-43d7-a285-936686fec78f":9.375,"881edf4e-5fbe-4f6c-9251-662c115ad0b4":9.375,"94174c22-88d1-40a6-8d25-abd0b7dc9b1c":12.5,"96b80cd5-4598-4686-ada2-53cb9cbf3e01":0,"96ee5761-c815-430f-a696-1afe9191dee5":15.625,"976c0433-5e93-451d-9a38-d46fca9694df":0,"9a88bd99-be9c-4b50-9439-7bade12de6fa":9.375,"a4387341-c1e1-496d-8ba2-44ed88c33191":3.125,"a7f1c411-10cf-42d5-a62b-3323c6db9226":3.125,"b541380f-8e36-4fd8-91b3-04cf1f8d2736":0,"c8de318c-325c-4669-bf2f-77f7a06e4c3f":3.125,"ccfdd717-9474-41ed-af61-5019726be57f":6.25,"d2f8e7b6-6290-486c-981b-44db12bce30e":15.625,"d5707c9f-323b-4336-8c0f-fa28062045b3":6.25,"d9430896-2615-4ed8-b9c5-be111fbac9ba":9.375},"keyword":{"02cfa09e-936c-4f58-ada2-70b1071739d6":0,"08c36e81-bb0d-41da-b021-8a75ee6cd4f6":13.101349206349209,"10899ad6-f266-43eb-9714-c0380346c2c7":14.008095238095239,"1d2f5c2a-19fa-458e-affb-6e7961ae9b8d":0,"1fad4a57-0f95-409c-aea8-5086e61cefd8":9.257592592592593,"2a7662fe-dc6f-4c83-8af5-a49a65eeb0d9":0,"2df731d1-37e4-4afb-a9b0-60a5361a79ff":11.991825396825396,"31de0370-c768-492d-9a3c-b13af24e769c":10.890634920634922,"39b4d0e3-b883-467c-be97-0874e2916be6":9.454761904761904,"48781111-6d37-40ba-af55-6ff34568dea7":9.97420634920635,"5cf5c9ae-8465-4cf4-b8fe-21036964b328":9.56031746031746,"6a5737b2-6b6e-4b6b-a536-7d2f71857606":10.757539682539681,"7244017f-2a87-46ca-ab3d-ddf19bf400a5":10.67063492063492,"7407954e-a728-48e9-8856-088577845de8":12.097619047619052,"767eacbf-fb87-44f8-bd87-9a4440413602":10.596031746031745,"7da2811c-a6df-4fd7-8c30-712957115c82":0,"7efe57f2-cda9-444f-8f2d-32358949189a":8.322380952380952,"849ca63d-26a8-43d7-a285-936686fec78f":9.563227513227513,"881edf4e-5fbe-4f6c-9251-662c115ad0b4":9.741137566137565,"94174c22-88d1-40a6-8d25-abd0b7dc9b1c":11.177910052910052,"96b80cd5-4598-4686-ada2-53cb9cbf3e01":0,"96ee5761-c815-430f-a696-1afe9191dee5":6.773412698412699,"976c0433-5e93-451d-9a38-d46fca9694df":11.646825396825395,"9a88bd99-be9c-4b50-9439-7bade12de6fa":10.297216117216118,"a4387341-c1e1-496d-8ba2-44ed88c33191":10.20621693121693,"a7f1c411-10cf-42d5-a62b-3323c6db9226":11.655317460317459,"b541380f-8e36-4fd8-91b3-04cf1f8d2736":12.351746031746034,"c8de318c-325c-4669-bf2f-77f7a06e4c3f":11.019682539682542,"ccfdd717-9474-41ed-af61-5019726be57f":9.339285714285715,"d2f8e7b6-6290-486c-981b-44db12bce30e":11.66468253968254,"d5707c9f-323b-4336-8c0f-fa28062045b3":10.888121693121692,"d9430896-2615-4ed8-b9c5-be111fbac9ba":13.856865079365079},"topic":["model","success","research","propos","measur"],"offsprings":["885cfaf9-43e5-4101-9554-40962d09fe53"]},"de8e60ab-025a-49af-9441-1f796cd0444c":{"authors":["Gregory D. Abowd","Anind K. Dey","Peter J. Brown","Nigel Davies","Mark E. Smith","Pete Steggles"],"references":[],"_id":"de8e60ab-025a-49af-9441-1f796cd0444c","abstract":"We define context as any information that can be used to characterize the situation of an entity, where an entity can be a person, place, or physical or computational object. We define context-awareness or context-aware computing as the use of context to provide task-relevant information and/or services to a user. Three important context-awareness behaviours are the presentation of information and services to a user, automatic execution of a service and tagging of context to information for later retrieval. Some of the main challenges in the area of context-aware computing are : - the development of a taxonomy and uniform representation of context types; - infrastructure to promote the design, implementation and evolution of context-aware applications; - a discovery of compelling context-aware applications that assist our everyday interactions with ubiquitous computational services.","title":"Towards a Better Understanding of Context and Context-Awareness","venue":"ubiquitous computing","year":1999,"__v":0,"citationCount":1631,"parents":{"0d19e770-eb9c-4890-9807-939c6c131eb7":26.666666666666668,"1633fbd6-26d8-411e-82c4-f36ce9ad46f8":6.666666666666667,"1e734af1-095c-4236-a3ec-abb2745bc363":0,"2165417b-540b-4823-a4a1-437716c243d5":13.333333333333334,"4db4ccc0-67a6-48d1-a558-f5bba181650a":6.666666666666667,"6825e7be-db72-4377-a599-6667ef0bd553":20,"6aa879d4-554d-47ff-b457-6c4b586c6971":13.333333333333334,"779000e1-bfe6-40f7-ac5a-f0f9dab2f9d9":33.33333333333333,"78c32f28-ce79-4586-b40c-2803c6dac693":6.666666666666667,"8b374059-8866-461b-b1f9-2f6a3dcb6f04":13.333333333333334,"963c8ea1-c5fa-4d7e-88ae-60ef6e9425b5":0,"b0c2f1b7-9de5-4e2c-a335-641ea33f7c60":6.666666666666667,"d7825e13-b803-413c-924c-7aea5e2a1159":6.666666666666667,"dacc7ab9-ec61-4302-be84-9396bbfebe74":26.666666666666668,"fd51d78a-e2f5-46b6-b041-4dae9aebdc76":0},"keyword":{"0d19e770-eb9c-4890-9807-939c6c131eb7":11.471176046176044,"1633fbd6-26d8-411e-82c4-f36ce9ad46f8":11.897835497835496,"1e734af1-095c-4236-a3ec-abb2745bc363":0,"2165417b-540b-4823-a4a1-437716c243d5":11.94877344877345,"4db4ccc0-67a6-48d1-a558-f5bba181650a":10.605064935064934,"6825e7be-db72-4377-a599-6667ef0bd553":11.79004329004329,"6aa879d4-554d-47ff-b457-6c4b586c6971":11.183225108225107,"779000e1-bfe6-40f7-ac5a-f0f9dab2f9d9":9.75838383838384,"78c32f28-ce79-4586-b40c-2803c6dac693":11.019985569985568,"8b374059-8866-461b-b1f9-2f6a3dcb6f04":9.032597402597403,"963c8ea1-c5fa-4d7e-88ae-60ef6e9425b5":0,"b0c2f1b7-9de5-4e2c-a335-641ea33f7c60":10.76002886002886,"d7825e13-b803-413c-924c-7aea5e2a1159":12.491197691197693,"dacc7ab9-ec61-4302-be84-9396bbfebe74":11.136075036075036,"fd51d78a-e2f5-46b6-b041-4dae9aebdc76":10.095093795093796},"topic":["contextawar","servic","inform","context","comput"],"groups":[{"authors":["Daniel Salber","Anind K. Dey","Gregory D. Abowd"],"references":["2165417b-540b-4823-a4a1-437716c243d5","2dee1a34-616b-492a-8ecd-2fdcfb4c2fe1","78c32f28-ce79-4586-b40c-2803c6dac693","801d0a81-4e59-4846-a8cb-2bcef8439c36","8b374059-8866-461b-b1f9-2f6a3dcb6f04","9ebf2cbd-ae53-487a-8410-d2a5c706f133","bd15a90c-b09f-45c8-93b4-2603ed03b6f8","c0f1624b-01b1-4c38-98ad-884784da680d","d7825e13-b803-413c-924c-7aea5e2a1159","fd51d78a-e2f5-46b6-b041-4dae9aebdc76"],"_id":"779000e1-bfe6-40f7-ac5a-f0f9dab2f9d9","abstract":"Context-enabled applications are just emerging and promisericher interaction by taking environmental context into account.However, they are difficult to build due to their distributednature and the use of unconventional sensors. The concepts oftoolkits and widget libraries in graphical user interfaces has beentremendously successtil, allowing programmers to leverage offexisting building blocks to build interactive systems more easily.We introduce the concept of context widgets that mediate betweenthe environment and the application in the same way graphicalwidgets mediate between the user and the application. We illustratethe concept of context widgets with the beginnings of a widgetlibrary we have developed for sensing presence, identity andactivity of people and things. We assess the success of ourapproach with two example context-enabled applications we havebuilt and an existing application to which we have addedcontext-sensing capabilities.","title":"The context toolkit: aiding the development of context-enabled applications","venue":"human factors in computing systems","year":1999,"__v":0,"citationCount":588},{"authors":["Peter J. Brown"],"references":["23f66d97-4abf-479f-8af5-ec833d850a24","5c12901d-1da5-43b1-bbcc-8fd9fe83fe4d","6825e7be-db72-4377-a599-6667ef0bd553","8b374059-8866-461b-b1f9-2f6a3dcb6f04","a2dfea6f-d3b9-4e85-9145-8700646fbca4","bd15a90c-b09f-45c8-93b4-2603ed03b6f8","d7825e13-b803-413c-924c-7aea5e2a1159","fd51d78a-e2f5-46b6-b041-4dae9aebdc76"],"_id":"dacc7ab9-ec61-4302-be84-9396bbfebe74","abstract":"With the increased availability of personal computers with attached sensors to capture their environment, there is a big opportunity forcontext-aware applications; these automatically provide information and/or take actions according to the user's present context, as detected by sensors. When well designed, these applications provide an opportunity to tailor the provision of information closely to the user's current needs. A sub-set of context-aware applications arediscrete applications, where discrete pieces of information are attached to individual contexts, to be triggered when the user enters those contexts. The advantage of discrete applications is that authoring them can be solely a creative process rather than a programming process: it can be a task akin to creating simple web pages. This paper looks at a general system that can be used in any discrete context-aware application. It propounds a general triggering rule, and investigates how this rule applies in practical applications.","title":"Triggering information by context","venue":"Personal and Ubiquitous Computing","year":1998,"__v":0,"citationCount":26},{"authors":["Jason Pascoe"],"references":["2165417b-540b-4823-a4a1-437716c243d5","4f60dbc7-9647-4b91-b96f-9f77d07fea7c","73f7e769-eee7-4863-a5db-b9c5eecc23e0","816ea88f-9788-487e-a83d-fc027806a635","8b374059-8866-461b-b1f9-2f6a3dcb6f04","d7825e13-b803-413c-924c-7aea5e2a1159","e9ad62a7-612c-4581-ac73-8b008c5f797a","fd51d78a-e2f5-46b6-b041-4dae9aebdc76"],"_id":"0d19e770-eb9c-4890-9807-939c6c131eb7","abstract":"Context-awareness has an increasingly important role to play in the development of wearable computing systems. In order to better define this role we have identified four generic contextual capabilities: sensing, adaptation, resource discovery, and augmentation. A prototype application has been constructed to explore how some of these capabilities could be deployed in a wearable system designed to aid an ecologist's observations of giraffe in a Kenyan game reserve. However, despite the benefits of context-awareness demonstrated in this prototype, widespread innovation of these capabilities is currently stifled by the difficulty in obtaining the contextual data. To remedy this situation the Contextual Information Service (CIS) is introduced. Installed on the user's wearable computer, the CIS provides a common point of access for clients to obtain, manipulate and model contextual information independently of the underlying plethora of data formats and sensor interface mechanisms.","title":"Adding generic contextual capabilities to wearable computers","venue":"","year":1998,"__v":0,"citationCount":185}],"offsprings":["081b1c58-3040-4c57-9758-d213c6646b83"]},"01b486c4-8955-403b-a0c6-1de74298b215":{"authors":["Alexander J. Smola","Bernhard Schölkopf"],"references":["50dd56db-151d-4d62-8576-65f0ef6f381b","91979159-37d8-410f-a245-a33ef80a092b","94898e1d-1e50-41ab-9dcc-2c2e030cddd0","c1b6b493-01ef-420f-be44-7bacfe34e846"],"_id":"01b486c4-8955-403b-a0c6-1de74298b215","abstract":"In this tutorial we give an overview of the basic ideas underlying Support Vector (SV) machines for function estimation. Furthermore, we include a summary of currently used algorithms for training SV machines, covering both the quadratic (or convex) programming part and advanced methods for dealing with large datasets. Finally, we mention some modifications and extensions that have been applied to the standard SV algorithm, and discuss the aspect of regularization from a SV perspective.","title":"A tutorial on support vector regression","venue":"Statistics and Computing","year":2004,"__v":0,"citationCount":1779,"parents":{"049edc28-e3d9-4855-bd54-9a2b9f534502":6.382978723404255,"08dcb9a2-1d9e-4094-a9ed-144d4343167e":0,"0d9f5547-6e05-4ad1-ad8b-3e91b842b9ec":6.382978723404255,"186ea3a7-0ce3-41a1-8380-c3d10543f451":8.51063829787234,"1ef607fe-5348-4658-8964-25a57fc49270":10.638297872340425,"228ed709-35de-4f7e-95dc-bfff3966dbec":0,"24627c32-96e9-4f6d-8193-059b20e2f57e":6.382978723404255,"29e06cb4-0ae3-4c7b-863a-d63ced9b1fa2":14.893617021276595,"33184e74-4574-4856-a969-e497fdc2fec8":6.382978723404255,"3c0c4358-9b5f-48d0-af58-e6b49a79e381":4.25531914893617,"3e2664f4-109e-4b0b-b86f-2e7a26b241cf":14.893617021276595,"43bace0d-86ee-4b71-b97d-95cad43e940c":4.25531914893617,"4a19318b-d54f-49cf-a42e-915f1f855927":0,"50dd56db-151d-4d62-8576-65f0ef6f381b":2.127659574468085,"549f0527-0f13-4447-9dc0-ca699e2dc219":23.404255319148938,"56f68d8b-36ca-422e-b721-c1f17ac7a78d":8.51063829787234,"5dedaf52-0a62-4822-b9eb-4b86acca6842":0,"69290a10-a7e0-4985-92e2-44eee6f57813":2.127659574468085,"77c65a8b-e4ed-4cd2-8093-283d2b8e7b2d":2.127659574468085,"7c6a970a-0d6f-4e4b-b50e-6c6fbd23a9ab":17.02127659574468,"87969fc2-8332-4ee5-b6b0-e1b26d01ebd4":4.25531914893617,"8af54182-bed5-4224-b11d-a5ec3bbbb069":0,"8be8b196-5437-4edc-9823-d4779b4774a5":2.127659574468085,"8dacb95e-ec6f-40a8-bc7d-3c5b1a524455":0,"91979159-37d8-410f-a245-a33ef80a092b":36.17021276595745,"9437974b-d98e-4251-a66b-9733698cda4d":2.127659574468085,"94898e1d-1e50-41ab-9dcc-2c2e030cddd0":12.76595744680851,"a1672ee6-07fc-47af-b677-c0490292db39":4.25531914893617,"a2e5c222-c380-42d7-8846-cbc232f46a69":12.76595744680851,"b0afa6ff-6528-4701-800b-5dc0b5411b0c":0,"b25d230c-cf98-48d6-a351-a208f7c9ee07":21.27659574468085,"b90f9310-726f-4116-9322-6fc01ab598fd":2.127659574468085,"c1b6b493-01ef-420f-be44-7bacfe34e846":14.893617021276595,"c1f94cf8-05cf-4c5f-a8cf-c13cb0d618eb":8.51063829787234,"c3e70a91-2303-4d28-a5e0-80ce3ae972c6":4.25531914893617,"cb4fbf1c-02e4-4ca9-995d-29f5282fdb4a":10.638297872340425,"d46e68dc-dbb7-4296-8f40-f3c513b432bc":0,"d9025720-9705-478f-97b5-f2346e961d27":2.127659574468085,"dd5a3ef5-9d44-4dde-bcdb-dc4d17c69073":34.04255319148936,"e49c48a2-c08b-40f0-93fd-f7198af91509":2.127659574468085,"ef187358-8753-42e6-8fc5-ced3770e71b1":0,"f006e236-59ad-4647-a59f-4f46dc2c85be":0,"f15b056f-a577-4391-9724-a5be885e2bd2":17.02127659574468,"f5ee7f6c-2f89-4d50-b6c0-cac4c5e57736":0,"f6c418d7-c420-492f-8d24-de3827674b93":0,"f75fb99d-feb6-4bf7-9c66-63e0ac597252":4.25531914893617,"f924ff4d-16ca-46f4-9306-69ddc08603f2":6.382978723404255},"keyword":{"049edc28-e3d9-4855-bd54-9a2b9f534502":9.350608465608465,"08dcb9a2-1d9e-4094-a9ed-144d4343167e":0,"0d9f5547-6e05-4ad1-ad8b-3e91b842b9ec":0,"186ea3a7-0ce3-41a1-8380-c3d10543f451":0,"1ef607fe-5348-4658-8964-25a57fc49270":11.59100529100529,"228ed709-35de-4f7e-95dc-bfff3966dbec":10.267857142857142,"24627c32-96e9-4f6d-8193-059b20e2f57e":9.504920634920637,"29e06cb4-0ae3-4c7b-863a-d63ced9b1fa2":8.998148148148148,"33184e74-4574-4856-a969-e497fdc2fec8":9.441666666666666,"3c0c4358-9b5f-48d0-af58-e6b49a79e381":11.667592592592591,"3e2664f4-109e-4b0b-b86f-2e7a26b241cf":10.594841269841268,"43bace0d-86ee-4b71-b97d-95cad43e940c":9.4260582010582,"4a19318b-d54f-49cf-a42e-915f1f855927":12.403015873015873,"50dd56db-151d-4d62-8576-65f0ef6f381b":10.334540089540088,"549f0527-0f13-4447-9dc0-ca699e2dc219":10.446031746031743,"56f68d8b-36ca-422e-b721-c1f17ac7a78d":10.643518518518519,"5dedaf52-0a62-4822-b9eb-4b86acca6842":11.851587301587298,"69290a10-a7e0-4985-92e2-44eee6f57813":7.732671957671958,"77c65a8b-e4ed-4cd2-8093-283d2b8e7b2d":7.6762962962962975,"7c6a970a-0d6f-4e4b-b50e-6c6fbd23a9ab":11.55074074074074,"87969fc2-8332-4ee5-b6b0-e1b26d01ebd4":8.494074074074074,"8af54182-bed5-4224-b11d-a5ec3bbbb069":11.147169312169313,"8be8b196-5437-4edc-9823-d4779b4774a5":10.606481481481481,"8dacb95e-ec6f-40a8-bc7d-3c5b1a524455":0,"91979159-37d8-410f-a245-a33ef80a092b":9.740476190476189,"9437974b-d98e-4251-a66b-9733698cda4d":8.796296296296296,"94898e1d-1e50-41ab-9dcc-2c2e030cddd0":10.18037037037037,"a1672ee6-07fc-47af-b677-c0490292db39":9.678703703703702,"a2e5c222-c380-42d7-8846-cbc232f46a69":8.576322751322751,"b0afa6ff-6528-4701-800b-5dc0b5411b0c":8.810132275132275,"b25d230c-cf98-48d6-a351-a208f7c9ee07":6.9296296296296305,"b90f9310-726f-4116-9322-6fc01ab598fd":10.697777777777778,"c1b6b493-01ef-420f-be44-7bacfe34e846":9.15185185185185,"c1f94cf8-05cf-4c5f-a8cf-c13cb0d618eb":11.10806878306878,"c3e70a91-2303-4d28-a5e0-80ce3ae972c6":10.241666666666665,"cb4fbf1c-02e4-4ca9-995d-29f5282fdb4a":10.904166666666667,"d46e68dc-dbb7-4296-8f40-f3c513b432bc":0,"d9025720-9705-478f-97b5-f2346e961d27":9.523148148148149,"dd5a3ef5-9d44-4dde-bcdb-dc4d17c69073":11.58227513227513,"e49c48a2-c08b-40f0-93fd-f7198af91509":10.574894179894178,"ef187358-8753-42e6-8fc5-ced3770e71b1":9.554973544973544,"f006e236-59ad-4647-a59f-4f46dc2c85be":9.268015873015873,"f15b056f-a577-4391-9724-a5be885e2bd2":9.032222222222224,"f5ee7f6c-2f89-4d50-b6c0-cac4c5e57736":0,"f6c418d7-c420-492f-8d24-de3827674b93":0,"f75fb99d-feb6-4bf7-9c66-63e0ac597252":0,"f924ff4d-16ca-46f4-9306-69ddc08603f2":11.218253968253967},"topic":["sv","machin","algorithm","vector","tutori"],"groups":[{"authors":["Christopher J. C. Burges"],"references":["0d9f5547-6e05-4ad1-ad8b-3e91b842b9ec","186ea3a7-0ce3-41a1-8380-c3d10543f451","24627c32-96e9-4f6d-8193-059b20e2f57e","3e2664f4-109e-4b0b-b86f-2e7a26b241cf","50dd56db-151d-4d62-8576-65f0ef6f381b","549f0527-0f13-4447-9dc0-ca699e2dc219","56f68d8b-36ca-422e-b721-c1f17ac7a78d","5dedaf52-0a62-4822-b9eb-4b86acca6842","5ffac6f9-2456-42cf-830c-9049ce37c899","79b2c6a4-bc06-40b4-96ae-0d7da88fdaa9","87969fc2-8332-4ee5-b6b0-e1b26d01ebd4","8af54182-bed5-4224-b11d-a5ec3bbbb069","94898e1d-1e50-41ab-9dcc-2c2e030cddd0","b25d230c-cf98-48d6-a351-a208f7c9ee07","c1f94cf8-05cf-4c5f-a8cf-c13cb0d618eb","cb4fbf1c-02e4-4ca9-995d-29f5282fdb4a","d46e68dc-dbb7-4296-8f40-f3c513b432bc","da4534a6-897c-4431-89ef-cd326bfaf9a8","e85a4f52-0e1c-447b-98b4-33ec8b9ee6f3","f006e236-59ad-4647-a59f-4f46dc2c85be","f6c418d7-c420-492f-8d24-de3827674b93","fd0b4dea-6e59-444f-8d1e-0f2a4e6b75b6"],"_id":"91979159-37d8-410f-a245-a33ef80a092b","abstract":"The tutorial starts with an overview of the concepts of VC dimension and structural risk minimization. We then describe linear Support Vector Machines (SVMs) for separable and non-separable data, working through a non-trivial example in detail. We describe a mechanical analogy, and discuss when SVM solutions are unique and when they are global. We describe how support vector training can be practically implemented, and discuss in detail the kernel mapping technique which is used to construct SVM solutions which are nonlinear in the data. We show how Support Vector machines can have very large (even infinite) VC dimension by computing the VC dimension for homogeneous polynomial and Gaussian radial basis function kernels. While very high VC dimension would normally bode ill for generalization performance, and while at present there exists no theory which shows that good generalization performance is guaranteed for SVMs, there are several arguments which support the observed high accuracy of SVMs, which we review. Results of some experiments which were inspired by these arguments are also presented. We give numerous examples and proofs of most of the key theorems. There is new material, and I hope that the reader will find that even old material is cast in a fresh light.","title":"A Tutorial on Support Vector Machines for Pattern Recognition","venue":"Data Mining and Knowledge Discovery","year":1998,"__v":0,"citationCount":4878},{"authors":["Bernhard Schölkopf","Alexander J. Smola","Robert C. Williamson","Peter L. Bartlett"],"references":["049edc28-e3d9-4855-bd54-9a2b9f534502","09ddc504-bc30-4a5e-b29f-09644e174375","24627c32-96e9-4f6d-8193-059b20e2f57e","29e06cb4-0ae3-4c7b-863a-d63ced9b1fa2","2cbdd97b-393f-4def-b945-b0694dea2db8","3e2664f4-109e-4b0b-b86f-2e7a26b241cf","45c5de6e-c600-4ed4-af53-e9f29f6286dc","50dd56db-151d-4d62-8576-65f0ef6f381b","549f0527-0f13-4447-9dc0-ca699e2dc219","7c6a970a-0d6f-4e4b-b50e-6c6fbd23a9ab","8656626a-3247-42f0-8d96-4661709b62f1","87969fc2-8332-4ee5-b6b0-e1b26d01ebd4","91979159-37d8-410f-a245-a33ef80a092b","94898e1d-1e50-41ab-9dcc-2c2e030cddd0","a2e5c222-c380-42d7-8846-cbc232f46a69","b25d230c-cf98-48d6-a351-a208f7c9ee07","b49b6e49-b084-4255-96f8-09c1de7bc1d2","c1f94cf8-05cf-4c5f-a8cf-c13cb0d618eb","c2fa09e5-7373-41b0-be44-10557724d064","c3464e8d-25d3-43b3-b786-19f9eb7700ab","c358ee37-4afb-4603-9b65-59d2536d0866","cb4fbf1c-02e4-4ca9-995d-29f5282fdb4a","d9b4e383-db58-4760-8292-c390cdf5a86b","dab15bfb-fb2c-4cc4-b6f0-6fb7d19a73c2","ef781e5f-5519-4a20-93fc-25f7d14039a1","f006e236-59ad-4647-a59f-4f46dc2c85be","f6c418d7-c420-492f-8d24-de3827674b93"],"_id":"dd5a3ef5-9d44-4dde-bcdb-dc4d17c69073","abstract":"We propose a new class of support vector algorithms for regression and classification. In these algorithms, a parameter ν lets one effectively control the number of support vectors. While this can be useful in its own right, the parameterization has the additional benefit of enabling us to eliminate one of the other free parameters of the algorithm: the accuracy parameter epsilon in the regression case, and the regularization constant C in the classification case. We describe the algorithms, give some theoretical results concerning the meaning and the choice of ν, and report experimental results.","title":"New Support Vector Algorithms","venue":"Neural Computation","year":2000,"__v":0,"citationCount":781},{"authors":["Alexander J. Smola","Bernhard Schölkopf","Klaus-Robert Müller"],"references":["3e2664f4-109e-4b0b-b86f-2e7a26b241cf","4a19318b-d54f-49cf-a42e-915f1f855927","50dd56db-151d-4d62-8576-65f0ef6f381b","56f68d8b-36ca-422e-b721-c1f17ac7a78d","5dedaf52-0a62-4822-b9eb-4b86acca6842","79b2c6a4-bc06-40b4-96ae-0d7da88fdaa9","86d97800-98df-445d-84a7-23e24b20884d","87969fc2-8332-4ee5-b6b0-e1b26d01ebd4","94898e1d-1e50-41ab-9dcc-2c2e030cddd0","9844913d-6cf1-49fc-b070-eaead4a894da","9a3d89a3-cf57-4db1-8cab-d3d7fef4d065","b25d230c-cf98-48d6-a351-a208f7c9ee07","be07152f-940c-40c7-bb8d-e04316f94cac","cb4fbf1c-02e4-4ca9-995d-29f5282fdb4a","f006e236-59ad-4647-a59f-4f46dc2c85be","f6c418d7-c420-492f-8d24-de3827674b93","fde7e6db-a925-440e-b27f-3f162da5f793"],"_id":"549f0527-0f13-4447-9dc0-ca699e2dc219","abstract":"In this paper a correspondence is derived between regularization operators used in regularization networks and support vector kernels. We prove that the Green's Functions associated with regularization operators are suitable support vector kernels with equivalent regularization properties. Moreover, the paper provides an analysis of currently used support vector kernels in the view of regularization theory and corresponding operators associated with the classes of both polynomial kernels and translation invariant kernels. The latter are also analyzed on periodical domains. As a by-product we show that a large number of radial basis functions, namely conditionally positive definite functions, may be used as support vector kernels.","title":"The connection between regularization operators and support vector kernels","venue":"Neural Networks","year":1998,"__v":0,"citationCount":197}],"offsprings":[]},"081b1c58-3040-4c57-9758-d213c6646b83":{"authors":["Anind K. Dey"],"references":["de8e60ab-025a-49af-9441-1f796cd0444c"],"_id":"081b1c58-3040-4c57-9758-d213c6646b83","abstract":"Context is a poorly used source of information in our computing environments. As a result, we have an impoverished understanding of what context is and how it can be used. In this paper, we provide an operational definition of context and discuss the different ways in which context can be used by context-aware applications. We also present the Context Toolkit, an architecture that supports the building of these context-aware applications. We discuss the features and abstractions in the toolkit that make the task of building applications easier. Finally, we introduce a new abstraction, a situation which we believe will provide additional support to application designers.","title":"Understanding and Using Context","venue":"ubiquitous computing","year":2001,"__v":0,"citationCount":1811,"parents":{"0d19e770-eb9c-4890-9807-939c6c131eb7":20,"6825e7be-db72-4377-a599-6667ef0bd553":20,"779000e1-bfe6-40f7-ac5a-f0f9dab2f9d9":20,"d7825e13-b803-413c-924c-7aea5e2a1159":0,"de8e60ab-025a-49af-9441-1f796cd0444c":80},"keyword":{"0d19e770-eb9c-4890-9807-939c6c131eb7":9.492460317460317,"6825e7be-db72-4377-a599-6667ef0bd553":9.292857142857143,"779000e1-bfe6-40f7-ac5a-f0f9dab2f9d9":10.941269841269843,"d7825e13-b803-413c-924c-7aea5e2a1159":11.74095238095238,"de8e60ab-025a-49af-9441-1f796cd0444c":11.308297258297257},"topic":["context","applic","toolkit","support","provid"],"groups":[{"authors":["Gregory D. Abowd","Anind K. Dey","Peter J. Brown","Nigel Davies","Mark E. Smith","Pete Steggles"],"references":["0d19e770-eb9c-4890-9807-939c6c131eb7","1633fbd6-26d8-411e-82c4-f36ce9ad46f8","1e734af1-095c-4236-a3ec-abb2745bc363","2165417b-540b-4823-a4a1-437716c243d5","4db4ccc0-67a6-48d1-a558-f5bba181650a","6825e7be-db72-4377-a599-6667ef0bd553","6aa879d4-554d-47ff-b457-6c4b586c6971","779000e1-bfe6-40f7-ac5a-f0f9dab2f9d9","78c32f28-ce79-4586-b40c-2803c6dac693","8b374059-8866-461b-b1f9-2f6a3dcb6f04","963c8ea1-c5fa-4d7e-88ae-60ef6e9425b5","b0c2f1b7-9de5-4e2c-a335-641ea33f7c60","d7825e13-b803-413c-924c-7aea5e2a1159","dacc7ab9-ec61-4302-be84-9396bbfebe74","fd51d78a-e2f5-46b6-b041-4dae9aebdc76"],"_id":"de8e60ab-025a-49af-9441-1f796cd0444c","abstract":"We define context as any information that can be used to characterize the situation of an entity, where an entity can be a person, place, or physical or computational object. We define context-awareness or context-aware computing as the use of context to provide task-relevant information and/or services to a user. Three important context-awareness behaviours are the presentation of information and services to a user, automatic execution of a service and tagging of context to information for later retrieval. Some of the main challenges in the area of context-aware computing are : - the development of a taxonomy and uniform representation of context types; - infrastructure to promote the design, implementation and evolution of context-aware applications; - a discovery of compelling context-aware applications that assist our everyday interactions with ubiquitous computational services.","title":"Towards a Better Understanding of Context and Context-Awareness","venue":"ubiquitous computing","year":1999,"__v":0,"citationCount":1631}],"offsprings":[]},"0ea745c7-58b2-48e8-9115-42e9b0d20f2a":{"authors":["Jonathan L. Herlocker","Joseph A. Konstan","Loren G. Terveen","John Riedl"],"references":["312e54ca-e7e9-4129-99f4-36f3aeff827e"],"_id":"0ea745c7-58b2-48e8-9115-42e9b0d20f2a","abstract":"Recommender systems have been evaluated in many, often incomparable, ways. In this article, we review the key decisions in evaluating collaborative filtering recommender systems: the user tasks being evaluated, the types of analysis and datasets being used, the ways in which prediction quality is measured, the evaluation of prediction attributes other than quality, and the user-based evaluation of the system as a whole. In addition to reviewing the evaluation strategies used by prior researchers, we present empirical results from the analysis of various accuracy metrics on one content domain where all the tested metrics collapsed roughly into three equivalence classes. Metrics within each equivalency class were strongly correlated, while metrics from different equivalency classes were uncorrelated.","title":"Evaluating collaborative filtering recommender systems","venue":"ACM Transactions on Information Systems","year":2004,"__v":0,"citationCount":1987,"parents":{"05f5fba9-e7ca-4c46-be79-df57944a8b41":0,"126f597c-4efc-49f4-9758-086b767f9fe3":32.5,"1406f119-82cd-4cbb-9231-f885212a724e":5,"2ac8fe14-27ce-4e39-b256-08fd95887484":12.5,"30119eca-9d54-4d87-88b0-04cadda25ea0":17.5,"312e54ca-e7e9-4129-99f4-36f3aeff827e":2.5,"3f8e14d5-4655-4c61-8636-99eb5cc99411":25,"44e91111-b413-4143-85a9-81872a97fa9d":10,"454b7a62-ff47-4263-822b-2a1a938b489f":25,"464c5e0a-2de4-4aa6-a0f6-56cb5ef6740d":20,"48632bf4-3e9f-4e98-b8f6-c08aaf7f2b58":7.5,"48a1dbbd-b496-4b37-b3ba-db144c654d23":22.5,"4a2b8b20-c8bc-4e0a-b7db-9dec439951d5":0,"5ee83a3b-d5f8-4532-97dd-c0579bed0d17":7.5,"60c814e2-c4d1-47d7-9a5a-68f4141505ae":5,"694f475e-f6c4-4105-b645-84c7d592db30":22.5,"749790a4-8bdf-4ad8-8ae9-9e9e8f57a898":0,"78113af6-9abc-46e5-bb78-80049f5770b5":2.5,"7d15ffdf-ec35-4498-b794-c186147b39eb":15,"7f2f7b7d-3e6c-4196-9056-a943b3e96c2f":15,"812c314c-9742-46fa-b1e8-5c7d640f1322":2.5,"822235e6-6abe-442b-b761-b51795df418a":12.5,"93fbc138-713f-402a-a554-89f111ddfcd8":5,"9863baf6-d69f-495a-8d5a-71442adea84e":10,"98b23182-8f51-428a-a4af-a91d280471ca":32.5,"9ae0142d-b12f-42b1-ac48-d655fdec233f":7.5,"a04df34d-8c30-4d8a-89fc-781660703e95":22.5,"bb237c57-3c58-492f-af1e-3e19a35115a6":0,"c69ef004-087e-486c-97c9-9b4587d0b10a":2.5,"ca25acbc-7ec2-453c-911f-077a06d76ebf":20,"cff1b7c3-dc60-4ac0-a016-0e4b5070310a":10,"d1fcfcd1-faa8-4ba3-a0d2-50fb53a9f47f":30,"d69f9422-3d82-4095-aa7c-b7f3513778ba":15,"daca38ab-f534-42d6-956c-130a321cd40d":15,"df338255-a225-4c0e-931d-4a011d141184":5,"e5e1e41c-774c-4bb4-a087-bcd02fd37b0f":7.5,"e9f47fc0-2e5e-4d5f-a7a9-3650e65a1722":5,"ed4c0d5d-5152-4915-b9bd-d0bd25f82674":25,"f454a778-621e-4e96-8501-7d72fb0d6103":2.5,"f68eb690-34df-4271-acc4-802cb273de83":0},"keyword":{"05f5fba9-e7ca-4c46-be79-df57944a8b41":0,"126f597c-4efc-49f4-9758-086b767f9fe3":9.87265873015873,"1406f119-82cd-4cbb-9231-f885212a724e":0,"2ac8fe14-27ce-4e39-b256-08fd95887484":11.219034391534388,"30119eca-9d54-4d87-88b0-04cadda25ea0":7.995502645502646,"312e54ca-e7e9-4129-99f4-36f3aeff827e":10.691746031746034,"3f8e14d5-4655-4c61-8636-99eb5cc99411":0,"44e91111-b413-4143-85a9-81872a97fa9d":0,"454b7a62-ff47-4263-822b-2a1a938b489f":9.615343915343914,"464c5e0a-2de4-4aa6-a0f6-56cb5ef6740d":10.455105820105818,"48632bf4-3e9f-4e98-b8f6-c08aaf7f2b58":10.107010582010581,"48a1dbbd-b496-4b37-b3ba-db144c654d23":10.685343915343912,"4a2b8b20-c8bc-4e0a-b7db-9dec439951d5":10.597698412698414,"5ee83a3b-d5f8-4532-97dd-c0579bed0d17":10.091137566137565,"60c814e2-c4d1-47d7-9a5a-68f4141505ae":0,"694f475e-f6c4-4105-b645-84c7d592db30":7.658095238095239,"749790a4-8bdf-4ad8-8ae9-9e9e8f57a898":8.716798941798942,"78113af6-9abc-46e5-bb78-80049f5770b5":6.963492063492064,"7d15ffdf-ec35-4498-b794-c186147b39eb":0,"7f2f7b7d-3e6c-4196-9056-a943b3e96c2f":7.9149470899470895,"812c314c-9742-46fa-b1e8-5c7d640f1322":0,"822235e6-6abe-442b-b761-b51795df418a":9.902486772486771,"93fbc138-713f-402a-a554-89f111ddfcd8":10.785052910052912,"9863baf6-d69f-495a-8d5a-71442adea84e":9.316031746031747,"98b23182-8f51-428a-a4af-a91d280471ca":0,"9ae0142d-b12f-42b1-ac48-d655fdec233f":0,"a04df34d-8c30-4d8a-89fc-781660703e95":8.07420634920635,"bb237c57-3c58-492f-af1e-3e19a35115a6":12.726984126984126,"c69ef004-087e-486c-97c9-9b4587d0b10a":9.964444444444444,"ca25acbc-7ec2-453c-911f-077a06d76ebf":9.291772486772485,"cff1b7c3-dc60-4ac0-a016-0e4b5070310a":9.631746031746031,"d1fcfcd1-faa8-4ba3-a0d2-50fb53a9f47f":10.41137566137566,"d69f9422-3d82-4095-aa7c-b7f3513778ba":10.407834757834758,"daca38ab-f534-42d6-956c-130a321cd40d":8.779761904761905,"df338255-a225-4c0e-931d-4a011d141184":10.512301587301586,"e5e1e41c-774c-4bb4-a087-bcd02fd37b0f":0,"e9f47fc0-2e5e-4d5f-a7a9-3650e65a1722":8.738492063492064,"ed4c0d5d-5152-4915-b9bd-d0bd25f82674":0,"f454a778-621e-4e96-8501-7d72fb0d6103":10.529232804232802,"f68eb690-34df-4271-acc4-802cb273de83":10.267619047619046},"topic":["evalu","metric","system","equival","class"],"groups":[{"authors":["Andrew I. Schein","Alexandrin Popescul","Lyle H. Ungar","David M. Pennock"],"references":["05234ed3-29a1-4a96-970c-44ebdf1a2fe6","28903e7b-aa3b-4840-b634-916029ed6c77","290e0375-d2ad-4bec-a94f-f05e1580125b","30119eca-9d54-4d87-88b0-04cadda25ea0","312e54ca-e7e9-4129-99f4-36f3aeff827e","3f8e14d5-4655-4c61-8636-99eb5cc99411","44e91111-b413-4143-85a9-81872a97fa9d","5ee83a3b-d5f8-4532-97dd-c0579bed0d17","60c814e2-c4d1-47d7-9a5a-68f4141505ae","694f475e-f6c4-4105-b645-84c7d592db30","6a6d14f3-83d4-4df4-bd27-94455c216c4f","812c314c-9742-46fa-b1e8-5c7d640f1322","8c3149bc-5c9e-44bc-a58a-1ce8d92208d5","8fb19592-ccce-4deb-a158-45dd7bba6d5a","8fda5d41-ef91-4e72-848f-7da042d1f9aa","98b23182-8f51-428a-a4af-a91d280471ca","b99db203-5c26-4182-bdc1-df188456f9f9","c69ef004-087e-486c-97c9-9b4587d0b10a","e5e1e41c-774c-4bb4-a087-bcd02fd37b0f","e75d8e62-a86d-4241-953f-1b315005d920","ed4c0d5d-5152-4915-b9bd-d0bd25f82674"],"_id":"d1fcfcd1-faa8-4ba3-a0d2-50fb53a9f47f","abstract":"We have developed a method for recommending items that combines content and collaborative data under a single probabilistic framework. We benchmark our algorithm against a naive Bayes classifier on the   cold-start  problem, where we wish to recommend items that no one in the community has yet rated. We systematically explore three testing methodologies using a publicly available data set, and explain how these methods apply to specific real-world applications. We advocate heuristic recommenders when benchmarking to give competent baseline performance. We introduce a new performance metric, the CROC curve, and demonstrate empirically that the various components of our testing strategy combine to obtain deeper understanding of the performance characteristics of recommender systems. Though the emphasis of our testing is on  cold-start  recommending, our methods for recommending and evaluation are general.","title":"Methods and metrics for cold-start recommendations","venue":"international acm sigir conference on research and development in information retrieval","year":2002,"__v":0,"citationCount":538},{"authors":["Jonathan L. Herlocker","Joseph A. Konstan","John Riedl"],"references":["1406f119-82cd-4cbb-9231-f885212a724e","30119eca-9d54-4d87-88b0-04cadda25ea0","312e54ca-e7e9-4129-99f4-36f3aeff827e","3f8e14d5-4655-4c61-8636-99eb5cc99411","48a1dbbd-b496-4b37-b3ba-db144c654d23","5ee83a3b-d5f8-4532-97dd-c0579bed0d17","60c814e2-c4d1-47d7-9a5a-68f4141505ae","694f475e-f6c4-4105-b645-84c7d592db30","7d15ffdf-ec35-4498-b794-c186147b39eb","812c314c-9742-46fa-b1e8-5c7d640f1322","8fb19592-ccce-4deb-a158-45dd7bba6d5a","8fda5d41-ef91-4e72-848f-7da042d1f9aa","c69ef004-087e-486c-97c9-9b4587d0b10a","e5e1e41c-774c-4bb4-a087-bcd02fd37b0f","ed4c0d5d-5152-4915-b9bd-d0bd25f82674"],"_id":"126f597c-4efc-49f4-9758-086b767f9fe3","abstract":"Collaborative filtering systems predict a user's interest in new items based on the recommendations of other people with similar interests. Instead of performing content indexing or content analysis, collaborative filtering systems rely entirely on interest ratings from members of a participating community. Since predictions are based on human ratings, collaborative filtering systems have the potential to provide filtering based on complex attributes, such as quality, taste, or aesthetics. Many implementations of collaborative filtering apply some variation of the neighborhood-based prediction algorithm. Many variations of similarity metrics, weighting approaches, combination measures, and rating normalization have appeared in each implementation. For these parameters and others, there is no consensus as to which choice of technique is most appropriate for what situations, nor how significant an effect on accuracy each parameter has. Consequently, every person implementing a collaborative filtering system must make hard design choices with little guidance. This article provides a set of recommendations to guide design of neighborhood-based prediction systems, based on the results of an empirical study. We apply an analysis framework that divides the neighborhood-based prediction approach into three components and then examines variants of the key parameters in each component. The three components identified are similarity computation, neighbor selection, and rating combination.","title":"An Empirical Analysis of Design Choices in Neighborhood-Based Collaborative Filtering Algorithms","venue":"Information Retrieval","year":2002,"__v":0,"citationCount":242},{"authors":["Ken Goldberg","Theresa M. Roeder","Dhruv Gupta","C. Perkins"],"references":["021a5e01-a0e8-4b1a-ad48-2fd23430efc3","05f5fba9-e7ca-4c46-be79-df57944a8b41","28903e7b-aa3b-4840-b634-916029ed6c77","312e54ca-e7e9-4129-99f4-36f3aeff827e","44e91111-b413-4143-85a9-81872a97fa9d","60c814e2-c4d1-47d7-9a5a-68f4141505ae","6119b461-7a82-44c1-9e2f-63c3f725b8af","71d3749b-3e35-461b-86c8-920c42d5ebe8","822235e6-6abe-442b-b761-b51795df418a","98b23182-8f51-428a-a4af-a91d280471ca","ac14afe6-de4d-4056-b2ac-0f6e36f369a2","c69ef004-087e-486c-97c9-9b4587d0b10a","e5e1e41c-774c-4bb4-a087-bcd02fd37b0f","ed4c0d5d-5152-4915-b9bd-d0bd25f82674"],"_id":"48a1dbbd-b496-4b37-b3ba-db144c654d23","abstract":"Eigentaste is a collaborative filtering algorithm that uses i>universal queries to elicit real-valued user ratings on a common set of items and applies principal component analysis (PCA) to the resulting dense subset of the ratings matrix. PCA facilitates dimensionality reduction for offline clustering of users and rapid computation of recommendations. For a database of i>n users, standard nearest-neighbor techniques require i>O(i>n) processing time to compute recommendations, whereas Eigentaste requires i>O(1) (constant) time. We compare Eigentaste to alternative algorithms using data from i>Jester, an online joke recommending system.#R##N##R##N#Jester has collected approximately 2,500,000 ratings from 57,000 users. We use the Normalized Mean Absolute Error (NMAE) measure to compare performance of different algorithms. In the Appendix we use Uniform and Normal distribution models to derive analytic estimates of NMAE when predictions are random. On the Jester dataset, Eigentaste computes recommendations two orders of magnitude faster with no loss of accuracy. Jester is online at: http://eigentaste.berkeley.edu","title":"Eigentaste: A Constant Time Collaborative Filtering Algorithm","venue":"Information Retrieval","year":2001,"__v":0,"citationCount":491},{"authors":["Badrul M. Sarwar","George Karypis","Joseph A. Konstan","John Riedl"],"references":["05f5fba9-e7ca-4c46-be79-df57944a8b41","1406f119-82cd-4cbb-9231-f885212a724e","312e54ca-e7e9-4129-99f4-36f3aeff827e","3f8e14d5-4655-4c61-8636-99eb5cc99411","41350086-4320-45bb-a93c-be68975bfff5","44e91111-b413-4143-85a9-81872a97fa9d","5e441d2d-7810-42bb-97f5-6f9542d11f0b","5ee83a3b-d5f8-4532-97dd-c0579bed0d17","60c814e2-c4d1-47d7-9a5a-68f4141505ae","694f475e-f6c4-4105-b645-84c7d592db30","6e425bce-a497-4c63-9eb0-b038e660a54f","7d15ffdf-ec35-4498-b794-c186147b39eb","812c314c-9742-46fa-b1e8-5c7d640f1322","ac14afe6-de4d-4056-b2ac-0f6e36f369a2","c69ef004-087e-486c-97c9-9b4587d0b10a","c7ce0fc7-4d38-4355-aa19-ab35527d2519","d3ca543b-a6d3-4dac-af08-b8e591340aaf","da744ec1-ac83-4fe7-bff2-0ff5fa621460","e5e1e41c-774c-4bb4-a087-bcd02fd37b0f","ed4c0d5d-5152-4915-b9bd-d0bd25f82674"],"_id":"98b23182-8f51-428a-a4af-a91d280471ca","title":"Item-based collaborative filtering recommendation algorithms","venue":"international world wide web conferences","year":2001,"abstract":"","__v":0,"citationCount":2377},{"authors":["Dan Cosley","Shyong K. Lam","Istvan Albert","Joseph A. Konstan","John Riedl"],"references":["30119eca-9d54-4d87-88b0-04cadda25ea0","312e54ca-e7e9-4129-99f4-36f3aeff827e","48a1dbbd-b496-4b37-b3ba-db144c654d23","60c814e2-c4d1-47d7-9a5a-68f4141505ae","812c314c-9742-46fa-b1e8-5c7d640f1322","822235e6-6abe-442b-b761-b51795df418a","9863baf6-d69f-495a-8d5a-71442adea84e","98b23182-8f51-428a-a4af-a91d280471ca","c69ef004-087e-486c-97c9-9b4587d0b10a","d29c4aa5-1049-41e7-925f-73527afbb3e4","f68eb690-34df-4271-acc4-802cb273de83"],"_id":"454b7a62-ff47-4263-822b-2a1a938b489f","abstract":"Recommender systems use people's opinions about items in an information domain to help people choose other items. These systems have succeeded in domains as diverse as movies, news articles, Web pages, and wines. The psychological literature on conformity suggests that in the course of helping people make choices, these systems probably affect users' opinions of the items. If opinions are influenced by recommendations, they might be less valuable for making recommendations for other users. Further, manipulators who seek to make the system generate artificially high or low recommendations might benefit if their efforts influence users to change the opinions they contribute to the recommender. We study two aspects of recommender system interfaces that may affect users' opinions: the rating scale and the display of predictions at the time users rate items. We find that users rate fairly consistently across rating scales. Users can be manipulated, though, tending to rate toward the prediction the system shows, whether the prediction is accurate or not. However, users can detect systems that manipulate predictions. We discuss how designers of recommender systems might react to these findings.","title":"Is seeing believing?: how recommender system interfaces affect users' opinions","venue":"human factors in computing systems","year":2003,"__v":0,"citationCount":178}],"offsprings":["feddae21-3c05-4743-80fa-b8e101f1b93f"]},"1a24e9c7-d0ce-4be4-8e3a-c849b4630851":{"authors":["Michalis Faloutsos","Petros Faloutsos","Christos Faloutsos"],"references":["afd4c865-5c81-424b-82c3-1dcb6150ea6d"],"_id":"1a24e9c7-d0ce-4be4-8e3a-c849b4630851","abstract":"Despite the apparent randomness of the Internet, we discover some surprisingly simple power-laws of the Internet topology. These power-laws hold for three snapshots of the Internet, between November 1997 and December 1998, despite a 45% growth of its size during that period. We show that our power-laws fit the real data very well resulting in correlation coefficients of 96% or higher.Our observations provide a novel perspective of the structure of the Internet. The power-laws describe concisely skewed distributions of graph properties such as the node outdegree. In addition, these power-laws can be used to estimate important parameters such as the average neighborhood size, and facilitate the design and the performance analysis of protocols. Furthermore, we can use them to generate and select realistic topologies for simulation purposes.","title":"On power-law relationships of the Internet topology","venue":"acm special interest group on data communication","year":1999,"__v":0,"citationCount":1710,"parents":{"221a51ba-b64d-4bf4-b9b9-968b9d7bd99e":0,"2222f1f9-b357-45ef-8943-ae096e660c5f":6.25,"28af31e8-07f0-4017-acb1-45246f5b4f90":6.25,"7d371899-f6a5-4e16-8365-835827db041e":0,"990beb01-03d1-4b11-8e01-6e4ec6015124":0,"9d57305f-9744-4504-8f35-943f05094d17":6.25,"afd4c865-5c81-424b-82c3-1dcb6150ea6d":6.25,"b5287e1f-d05b-45b9-a342-d7d2cd318420":12.5,"c82d6f8e-5ad6-4317-af5a-86d4b6bcf225":25,"d7124e3a-a4cd-4a58-ba02-f77c773458ea":25,"ea1ce8d0-7a36-489a-8f13-e6a5e2960b2c":0,"ee15fb5d-9b11-4b42-9853-c16acfbec29e":0,"ef3894e7-7d06-4e66-8e47-782d6ceceb6a":0,"f353f651-1349-46f5-b1aa-a81b29654522":0,"f59ab5a3-c1d7-4287-9780-2b04d99e7f5c":6.25,"fe936596-cab6-4eae-9188-4ab9f238780c":18.75},"keyword":{"221a51ba-b64d-4bf4-b9b9-968b9d7bd99e":8.145277777777778,"2222f1f9-b357-45ef-8943-ae096e660c5f":8.906746031746032,"28af31e8-07f0-4017-acb1-45246f5b4f90":7.948412698412699,"7d371899-f6a5-4e16-8365-835827db041e":0,"990beb01-03d1-4b11-8e01-6e4ec6015124":0,"9d57305f-9744-4504-8f35-943f05094d17":7.977063492063492,"afd4c865-5c81-424b-82c3-1dcb6150ea6d":7.878968253968255,"b5287e1f-d05b-45b9-a342-d7d2cd318420":7.72830687830688,"c82d6f8e-5ad6-4317-af5a-86d4b6bcf225":7.9146825396825395,"d7124e3a-a4cd-4a58-ba02-f77c773458ea":9.921216931216932,"ea1ce8d0-7a36-489a-8f13-e6a5e2960b2c":8.450396825396826,"ee15fb5d-9b11-4b42-9853-c16acfbec29e":7.061309523809523,"ef3894e7-7d06-4e66-8e47-782d6ceceb6a":10.364854497354496,"f353f651-1349-46f5-b1aa-a81b29654522":9.34706349206349,"f59ab5a3-c1d7-4287-9780-2b04d99e7f5c":9.755291005291006,"fe936596-cab6-4eae-9188-4ab9f238780c":8.986190476190478},"topic":["powerlaw","internet","topolog","size"],"groups":[{"authors":["Mark Crovella","Azer Bestavros"],"references":["07194702-1044-48fa-8e3d-e95631650f36","19c730f7-24d3-4c1f-9c85-af826d0509b5","2222f1f9-b357-45ef-8943-ae096e660c5f","259ff48c-d0b9-4fd4-8275-8169c6152224","3bb9b6ca-18dd-4d95-8c16-e7003ef32df4","5520e73e-d943-43fd-a6f2-88032a1ee589","6ed13d45-3965-4a51-bc0c-c7a49f49af56","716a3f63-879a-428c-811a-3e2956a2bf79","7d371899-f6a5-4e16-8365-835827db041e","8b51fe8b-c1ad-4111-8b61-feca677128b0","a94edbe6-d0a8-491b-b435-353a0eb06144","afd4c865-5c81-424b-82c3-1dcb6150ea6d","d3c5128e-d2ee-43d3-a65b-04d71b3e13c8","f937db79-5393-4c80-a20a-68e3551e379a","fe936596-cab6-4eae-9188-4ab9f238780c"],"_id":"c82d6f8e-5ad6-4317-af5a-86d4b6bcf225","abstract":"Recently the notion of  self-similarity  has been shown to apply to wide-area and local-area network traffic. In this paper we examine the mechanisms that give rise to the self-similarity of network traffic. We present a hypothesized explanation for the possible self-similarity of traffic by using a particular subset of wide area traffic: traffic due to the World Wide Web (WWW). Using an extensive set of traces of actual user executions of NCSA Mosaic, reflecting over half a million requests for WWW documents, we examine the dependence structure of WWW traffic. While our measurements are not conclusive, we show evidence that WWW traffic exhibits behavior that is consistent with self-similar traffic models. Then we show that the self-similarity in such traffic can be explained based on the underlying distributions of WWW document sizes, the effects of caching and user preference in file transfer, the effect of user \"think time\", and the superimposition of many such transfers in a local area network. To do this we rely on empirically measured distributions both from our traces and from data independently collected at over thirty WWW sites.","title":"Self-similarity in World Wide Web traffic: evidence and possible causes","venue":"measurement and modeling of computer systems","year":1996,"__v":0,"citationCount":486},{"authors":["Vern Paxson","Sally Floyd"],"references":["125299a0-d010-4913-bdd8-690ea40a7cd5","14dbcb0a-b6a3-4407-9a3c-0ce575e268c9","19c730f7-24d3-4c1f-9c85-af826d0509b5","2222f1f9-b357-45ef-8943-ae096e660c5f","2915a22c-b1dd-46e9-9082-40793a90abf9","3340d505-a639-4a69-bf18-c7e03981d858","3d9b719d-1c68-4f2c-93d6-5b1931c4e683","4b5c9003-da3b-4a1c-9ddd-0262278668e5","54cab52f-3f01-490e-baea-dd8b09eb83ee","5d7d8304-f78d-4332-aefd-4f4d8d78f0e1","614e739e-0d4e-436a-bce1-f8d83234c666","afd4c865-5c81-424b-82c3-1dcb6150ea6d","c0c6c887-c30a-4e7a-82c7-57da507b4606","c82d6f8e-5ad6-4317-af5a-86d4b6bcf225","c94a3952-f1f2-4a1e-9254-96f195ca7e5b","d2a57597-5f45-4c41-8020-03cdfc0ebb3f","d3c5128e-d2ee-43d3-a65b-04d71b3e13c8","d515523f-a419-4f04-aed3-b3d909db139c","fe936596-cab6-4eae-9188-4ab9f238780c"],"_id":"d7124e3a-a4cd-4a58-ba02-f77c773458ea","abstract":"Simulating how the global Internet data network behaves is an immensely challenging undertaking because of the network's great heterogeneity and rapid change. The heterogeneity ranges from the individual links that carry the network's traffic, to the protocols that interoperate over the links, to the “mix” of different applications used at a site and the levels of congestion (load) seen on different links. We discuss two key strategies for developing meaningful simulations in the face of these difficulties: searching for invariants and judiciously exploring the simulation parameter space. We finish with a look at a collaborative effort to build a common simulation environment for conducting Internet studies.","title":"Why we don't know how to simulate the Internet","venue":"winter simulation conference","year":1997,"__v":0,"citationCount":125}],"offsprings":["b0ef6e4d-4c86-4b10-9e0a-7b630ca8d7f7"]},"1ae994d8-ddfa-4f61-bf18-8ea62039101f":{"authors":["Rajkumar Buyya","Chee Shin Yeo","Srikumar Venugopal","James Broberg","Ivona Brandic"],"references":["78991392-db9c-45a4-86a2-b4ce93ab0ec0"],"_id":"1ae994d8-ddfa-4f61-bf18-8ea62039101f","abstract":"With the significant advances in Information and Communications Technology (ICT) over the last half century, there is an increasingly perceived vision that computing will one day be the 5th utility (after water, electricity, gas, and telephony). This computing utility, like all other four existing utilities, will provide the basic level of computing service that is considered essential to meet the everyday needs of the general community. To deliver this vision, a number of computing paradigms have been proposed, of which the latest one is known as Cloud computing. Hence, in this paper, we define Cloud computing and provide the architecture for creating Clouds with market-oriented resource allocation by leveraging technologies such as Virtual Machines (VMs). We also provide insights on market-based resource management strategies that encompass both customer-driven service management and computational risk management to sustain Service Level Agreement (SLA)-oriented resource allocation. In addition, we reveal our early thoughts on interconnecting Clouds for dynamically creating global Cloud exchanges and markets. Then, we present some representative Cloud platforms, especially those developed in industries, along with our current work towards realizing market-oriented resource allocation of Clouds as realized in Aneka enterprise Cloud technology. Furthermore, we highlight the difference between High Performance Computing (HPC) workload and Internet-based services workload. We also describe a meta-negotiation infrastructure to establish global Cloud exchanges and markets, and illustrate a case study of harnessing 'Storage Clouds' for high performance content delivery. Finally, we conclude with the need for convergence of competing IT paradigms to deliver our 21st century vision.","title":"Cloud computing and emerging IT platforms: Vision, hype, and reality for delivering computing as the 5th utility","venue":"Future Generation Computer Systems","year":2009,"__v":0,"citationCount":1505,"parents":{"020e47f2-7841-4ca9-8ae8-b83431f23be7":0,"0a10ecde-584b-4a89-a2e6-29a944fa64e3":0,"1b123618-4ba6-48d8-adfb-d51c75868124":6.25,"207dd038-9c35-461a-8046-1d50ec427d35":6.25,"28b3cd98-6acb-40ce-8c44-438ecddcddf8":25,"2e56bac1-27a4-4fee-aeb4-70503a948eeb":0,"2e9e2b3c-2443-4348-84d5-10a0cab15f58":0,"3006a216-950c-4c6a-81df-dee7f80ec75c":6.25,"30969775-5574-4f00-b581-7e43131e9b31":3.125,"37b8e0cd-5ca8-4b15-86ab-fbb01930ad06":0,"39939d86-9a0b-4094-a2b8-ada08992790d":3.125,"47160c82-a249-4904-bb61-e3081e452a88":0,"52394ff3-caaf-4309-a561-7ad5a097c2dc":21.875,"59ad7942-e573-40df-b0fd-8a1879169669":0,"59af7e25-c0ee-4af5-acea-a58dfe4ccac4":0,"671503e8-ed63-43f0-9ad6-90e59cf6573c":0,"6bc12474-6685-4e15-acc6-46cad9acdeef":3.125,"6dc992eb-3348-4bc0-bfae-4dd2b5c9fab0":12.5,"7113a88b-ebca-4e38-8540-5b9a34cb90a0":0,"78991392-db9c-45a4-86a2-b4ce93ab0ec0":0,"8801d522-5703-486e-bd5a-00c0ee0b8b79":0,"93e3b47e-91ef-45a1-9afd-c770f1c35d98":6.25,"9558f1d8-969d-41b4-bcff-d1d0faa61595":3.125,"9904c691-f4f9-4526-b2a6-0c31b0f8e89b":6.25,"a42cfbc0-1630-49de-a11a-2592e91d0b31":15.625,"ab0a584e-e700-4a4c-988f-6afecfba123e":25,"af857501-1243-4d28-84ba-b1ca84a6302f":0,"b5a9419f-84cf-4c0c-b81a-016a59959179":0,"e1baec80-4657-4289-bab0-96b2c00e8616":3.125,"f46fb76f-512f-4958-a911-aaa5ebafe41c":6.25,"f63d3a8d-5fbc-4ffa-a9cb-5d288709a007":0,"f64d7831-876e-4d02-84ac-5210e04ad0ab":0},"keyword":{"020e47f2-7841-4ca9-8ae8-b83431f23be7":10.463492063492062,"0a10ecde-584b-4a89-a2e6-29a944fa64e3":10.516507936507937,"1b123618-4ba6-48d8-adfb-d51c75868124":9.783333333333333,"207dd038-9c35-461a-8046-1d50ec427d35":11.674603174603174,"28b3cd98-6acb-40ce-8c44-438ecddcddf8":10.194444444444445,"2e56bac1-27a4-4fee-aeb4-70503a948eeb":7.292063492063493,"2e9e2b3c-2443-4348-84d5-10a0cab15f58":10.75132275132275,"3006a216-950c-4c6a-81df-dee7f80ec75c":10.250793650793648,"30969775-5574-4f00-b581-7e43131e9b31":9.61984126984127,"37b8e0cd-5ca8-4b15-86ab-fbb01930ad06":9.526984126984129,"39939d86-9a0b-4094-a2b8-ada08992790d":11.26006105006105,"47160c82-a249-4904-bb61-e3081e452a88":9.252380952380953,"52394ff3-caaf-4309-a561-7ad5a097c2dc":10.783333333333331,"59ad7942-e573-40df-b0fd-8a1879169669":10.939444444444444,"59af7e25-c0ee-4af5-acea-a58dfe4ccac4":9.01984126984127,"671503e8-ed63-43f0-9ad6-90e59cf6573c":9.700396825396826,"6bc12474-6685-4e15-acc6-46cad9acdeef":12.10972222222222,"6dc992eb-3348-4bc0-bfae-4dd2b5c9fab0":11.667222222222222,"7113a88b-ebca-4e38-8540-5b9a34cb90a0":8.102645502645503,"78991392-db9c-45a4-86a2-b4ce93ab0ec0":11.414285714285713,"8801d522-5703-486e-bd5a-00c0ee0b8b79":10.870793650793653,"93e3b47e-91ef-45a1-9afd-c770f1c35d98":10.93472222222222,"9558f1d8-969d-41b4-bcff-d1d0faa61595":10.184920634920633,"9904c691-f4f9-4526-b2a6-0c31b0f8e89b":10.233492063492065,"a42cfbc0-1630-49de-a11a-2592e91d0b31":8.807142857142859,"ab0a584e-e700-4a4c-988f-6afecfba123e":11.327460317460318,"af857501-1243-4d28-84ba-b1ca84a6302f":8.693650793650791,"b5a9419f-84cf-4c0c-b81a-016a59959179":7.066666666666667,"e1baec80-4657-4289-bab0-96b2c00e8616":10.17936507936508,"f46fb76f-512f-4958-a911-aaa5ebafe41c":0,"f63d3a8d-5fbc-4ffa-a9cb-5d288709a007":12.57126984126984,"f64d7831-876e-4d02-84ac-5210e04ad0ab":7.940873015873017},"topic":["cloud","comput","servic","resourc","vision"],"groups":[{"authors":["Rajkumar Buyya","Chee Shin Yeo","Srikumar Venugopal"],"references":["020e47f2-7841-4ca9-8ae8-b83431f23be7","0a10ecde-584b-4a89-a2e6-29a944fa64e3","207dd038-9c35-461a-8046-1d50ec427d35","3006a216-950c-4c6a-81df-dee7f80ec75c","52394ff3-caaf-4309-a561-7ad5a097c2dc","9904c691-f4f9-4526-b2a6-0c31b0f8e89b","c50a91a1-94c7-4b34-91c5-35796c337bc0","e1baec80-4657-4289-bab0-96b2c00e8616","f46fb76f-512f-4958-a911-aaa5ebafe41c"],"_id":"ab0a584e-e700-4a4c-988f-6afecfba123e","abstract":"This keynote paper: presents a 21 st  century vision of computing; identifies various computing paradigms promising to deliver the vision of computing utilities; defines Cloud computing and provides the architecture for creating market-oriented Clouds by leveraging technologies such as VMs; provides thoughts on market-based resource management strategies that encompass both customer-driven service management and computational risk management to sustain SLA-oriented resource allocation; presents some representative Cloud platforms especially those developed in industries along with our current work towards realising market-oriented resource allocation of Clouds by leveraging the 3rd generation Aneka enterprise Grid technology; reveals our early thoughts on interconnecting Clouds for dynamically creating an atmospheric computing environment along with pointers to future community research; and concludes with the need for convergence of competing IT paradigms for delivering our 21 st  century vision.","title":"Market-Oriented Cloud Computing: Vision, Hype, and Reality for Delivering IT Services as Computing Utilities","venue":"high performance computing and communications","year":2008,"__v":0,"citationCount":584},{"authors":["James Broberg","Srikumar Venugopal","Rajkumar Buyya"],"references":["020e47f2-7841-4ca9-8ae8-b83431f23be7","0b1f663b-3914-47a8-806b-4ac4ef021625","12ed96e7-0fe6-4fb8-a5d2-76d9ad238b68","14dba817-d309-49de-92e4-ab07d89a2342","207dd038-9c35-461a-8046-1d50ec427d35","2e8618d2-e4c0-450f-b5e0-65875d562925","3006a216-950c-4c6a-81df-dee7f80ec75c","37533132-cf3b-4be4-b496-5a24f3ec7e00","39939d86-9a0b-4094-a2b8-ada08992790d","3aea21a2-c4f3-4693-8367-f37a058ce20b","3feec742-da31-413c-8e3e-0b1ef604c680","499cddf6-45e5-46ca-b194-b55500c32bb6","569b777f-eb40-4fa8-9567-c5844c8c3522","5c1c366a-617b-48d4-8f04-33923ec93ced","60dc9d54-f694-4990-9012-beac1fd555e7","6e5cd660-d8fd-43c2-9a92-39de9d43e16a","72864dbd-eb79-43bf-a86a-df193e48f8a3","78991392-db9c-45a4-86a2-b4ce93ab0ec0","86cba0a1-ed5a-4c22-903d-3216ff4d7f15","88356a1b-93ab-43f4-8eeb-02314e96e6fd","8e17fcc2-0f75-4bd0-9043-6212ef8a2e2a","93e3b47e-91ef-45a1-9afd-c770f1c35d98","9829c17b-ffed-42d8-90a4-cc2d4635ba2e","985fd44c-c4d6-4cbb-8ade-f9435fc0f669","9904c691-f4f9-4526-b2a6-0c31b0f8e89b","9d438476-9e4a-49a7-b43f-e0518d394e04","a9fa643b-b654-444e-be77-57f917651f1b","b56130b6-8d64-4e5c-9c82-1e60193bad60","bc2cbff0-ba2b-40e7-bcb4-38fafbbed8ea","bd297839-add8-42ab-8e12-83514f0d128f","c7bf74ee-739c-45c6-9713-6a0eeb08e76d","d51aa9fe-d2ca-4bfc-a21d-e87fe4394106","e701864b-6066-416f-92e9-3cfb35a8b300","f0036f4e-9d9e-4f6e-a7bc-c4827a3ff334","f437ace4-19f4-4889-9292-e0e8544656e6","f63d3a8d-5fbc-4ffa-a9cb-5d288709a007","f796a6f7-6892-4867-81a8-4cefed489f82","fac42389-c3d3-4938-9189-4ef02f02a703"],"_id":"28b3cd98-6acb-40ce-8c44-438ecddcddf8","abstract":"Traditional resource management techniques (resource allocation, admission control and scheduling) have been found to be inadequate for many shared Grid and distributed systems, that consist of autonomous and dynamic distributed resources contributed by multiple organisations. They provide no incentive for users to request resources judiciously and appropriately, and do not accurately capture the true value, importance and deadline (the utility) of a user’s job. Furthermore, they provide no compensation for resource providers to contribute their computing resources to shared Grids, as traditional approaches have a user-centric focus on maximising throughput and minimising waiting time rather than maximising a providers own benefit. Consequently, researchers and practitioners have been examining the appropriateness of ‘market-inspired’ resource management techniques to address these limitations. Such techniques aim to smooth out access patterns and reduce the chance of transient overload, by providing a framework for users to be truthful about their resource requirements and job deadlines, and offering incentives for service providers to prioritise urgent, high utility jobs over low utility jobs. We examine the recent innovations in these systems (from 2000–2007), looking at the state-of-the-art in price setting and negotiation, Grid economy management and utility-driven scheduling and resource allocation, and identify the advantages and limitations of these systems. We then look to the future of these systems, examining the emerging ‘Catallaxy’ market paradigm. Finally we consider the future directions that need to be pursued to address the limitations of the current generation of market oriented Grids and Utility Computing systems.","title":"Market-oriented Grids and Utility Computing: The State-of-the-art and Future Directions","venue":"Journal of Grid Computing","year":2008,"__v":0,"citationCount":83},{"authors":["Srikumar Venugopal","Xingchen Chu","Rajkumar Buyya"],"references":["07153e7e-1de2-4a2d-8af6-17b420613d9a","0a95cf80-ba78-4298-84ef-1e5a38919984","28b3cd98-6acb-40ce-8c44-438ecddcddf8","30969775-5574-4f00-b581-7e43131e9b31","37533132-cf3b-4be4-b496-5a24f3ec7e00","4730cf22-f153-43e3-bf74-cbb71f426e32","5579edf8-dd22-4f2e-b46f-e3004292df7d","6538c46f-44c8-4b12-a02e-393a4ad15764","671503e8-ed63-43f0-9ad6-90e59cf6573c","7113a88b-ebca-4e38-8540-5b9a34cb90a0","93e3b47e-91ef-45a1-9afd-c770f1c35d98","944f064e-76d3-472e-9811-057d0ba5b3eb","9904c691-f4f9-4526-b2a6-0c31b0f8e89b","9cfdf9ac-7a3a-4b04-b74a-5891812b728c","a156857e-6528-4d28-af83-a993b7cc412e","a31c89f5-3065-4573-8304-f5fc637ac7ad","bb9cb8c2-ce39-4b21-bd99-eceef47ac05c","bd535b4e-2430-4a2c-9d12-59c39884e554","e1baec80-4657-4289-bab0-96b2c00e8616","f563ee83-12bc-4b05-a9a8-57eb62cfc097"],"_id":"52394ff3-caaf-4309-a561-7ad5a097c2dc","abstract":"Service level agreements (SLAs) between grid users and providers have been proposed as mechanisms for ensuring that the users' quality of service (QoS) requirements are met, and that the provider is able to realise utility from its infrastructure. This paper presents a bilateral protocol for SLA negotiation using the alternate offers mechanism wherein a party is able to respond to an offer by modifying some of its terms to generate a counter offer. We apply this protocol to the negotiation between a resource broker and a provider for advance reservation of compute nodes, and implement and evaluate it on a real grid system.","title":"A Negotiation Mechanism for Advance Resource Reservations Using the Alternate Offers Protocol","venue":"international workshop on quality of service","year":2008,"__v":0,"citationCount":46}],"offsprings":[]},"1eddb4e0-a074-4189-a370-e53724a96bbd":{"authors":["Viveck R. Cadambe","Syed Ali Jafar"],"references":[],"_id":"1eddb4e0-a074-4189-a370-e53724a96bbd","abstract":"For the fully connected K user wireless interference channel where the channel coefficients are time-varying and are drawn from a continuous distribution, the sum capacity is characterized as C(SNR)=K/2log(SNR)+o(log(SNR)) . Thus, the K user time-varying interference channel almost surely has K/2 degrees of freedom. Achievability is based on the idea of interference alignment. Examples are also provided of fully connected K user interference channels with constant (not time-varying) coefficients where the capacity is exactly achieved by interference alignment at all SNR values.","title":"Interference Alignment and Degrees of Freedom of the $K$ -User Interference Channel","venue":"IEEE Transactions on Information Theory","year":2008,"__v":0,"citationCount":1636,"parents":{"307a1739-c232-44cb-af85-695dd925cc10":50,"502cc517-7d2d-4a60-92a4-ab075e50875c":35.714285714285715,"57b95744-6447-4510-b26f-d85de7fe2c4c":14.285714285714285,"75728c7b-5878-4201-ad14-24390d818f0c":57.14285714285714,"80bd3411-e248-48fa-944f-b842018e19aa":14.285714285714285,"985e8fba-08e3-4dcc-bac9-da93ff4e761d":14.285714285714285,"a5566cd7-1efe-4316-b379-6e7a161473b2":7.142857142857142,"ac8fef31-1313-437e-ba52-260e1da2c447":0,"b904053f-f245-46eb-a749-e31c53c6c59b":14.285714285714285,"c3785862-e6d4-4668-bea7-7a9b053ae184":0,"cac3fc3f-ffc3-4b8f-a77d-078358ea6e4c":7.142857142857142,"d03c481d-ce53-415b-b250-d4f745ecbf6d":28.57142857142857,"ef7f9375-533e-4ffa-bf30-68c0ed58be5e":0,"ff06b6b1-6408-438b-a879-3ff2d59452c0":14.285714285714285},"keyword":{"307a1739-c232-44cb-af85-695dd925cc10":8.944999999999999,"502cc517-7d2d-4a60-92a4-ab075e50875c":8.652579365079363,"57b95744-6447-4510-b26f-d85de7fe2c4c":11.00456349206349,"75728c7b-5878-4201-ad14-24390d818f0c":10.441031746031745,"80bd3411-e248-48fa-944f-b842018e19aa":10.11484126984127,"985e8fba-08e3-4dcc-bac9-da93ff4e761d":10.675396825396824,"a5566cd7-1efe-4316-b379-6e7a161473b2":9.102645502645501,"ac8fef31-1313-437e-ba52-260e1da2c447":10.779761904761905,"b904053f-f245-46eb-a749-e31c53c6c59b":11.115873015873017,"c3785862-e6d4-4668-bea7-7a9b053ae184":10.516031746031747,"cac3fc3f-ffc3-4b8f-a77d-078358ea6e4c":10.6234126984127,"d03c481d-ce53-415b-b250-d4f745ecbf6d":9.245238095238095,"ef7f9375-533e-4ffa-bf30-68c0ed58be5e":10.417460317460316,"ff06b6b1-6408-438b-a879-3ff2d59452c0":11.73677248677249},"topic":["interfer","channel","user","timevari","fulli"],"groups":[{"authors":["V.S. Annapureddy","V.V. Veeravalli"],"references":["307a1739-c232-44cb-af85-695dd925cc10","481fb332-01fa-49ba-8aa3-9e476dcc1a61","502cc517-7d2d-4a60-92a4-ab075e50875c","696d4b01-be76-4542-920c-bb9085cbb523","80bd3411-e248-48fa-944f-b842018e19aa","8e2696c6-5405-4ece-9931-c2a75315e3a2","985e8fba-08e3-4dcc-bac9-da93ff4e761d","a1e1fe5d-31e1-4538-9cdc-95e700dc91b2","ac8fef31-1313-437e-ba52-260e1da2c447","ae28f74e-cf77-496d-979e-0988449a6051","b35262e0-8810-4eef-8f49-0892fbedb391","b904053f-f245-46eb-a749-e31c53c6c59b","c0182f5d-8299-4bef-996e-8d563f77124e","c8cedf3a-c232-4f6e-b8c3-804fb77d6666","cac3fc3f-ffc3-4b8f-a77d-078358ea6e4c","d03c481d-ce53-415b-b250-d4f745ecbf6d","ee765b7c-84c3-4328-8b4f-1589765543ff"],"_id":"75728c7b-5878-4201-ad14-24390d818f0c","abstract":"Establishing the capacity region of a Gaussian interference network is an open problem in information theory. Recent progress on this problem has led to the characterization of the capacity region of a general two-user Gaussian interference channel within one bit. In this paper, we develop new, improved outer bounds on the capacity region. Using these bounds, we show that  treating   interference   as   noise  achieves the  sum   capacity  of the two-user Gaussian interference channel in a  low-interference   regime , where the interference parameters are below certain thresholds. We then generalize our techniques and results to Gaussian interference networks with more than two users. In particular, we demonstrate that the total interference threshold, below which treating interference as noise achieves the sum capacity, increases with the number of users.","title":"Gaussian Interference Networks: Sum Capacity in the Low-Interference Regime and New Outer Bounds on the Capacity Region","venue":"IEEE Transactions on Information Theory","year":2009,"__v":0,"citationCount":237},{"authors":["Raul Hernan Etkin","David Tse","Hua Wang"],"references":["7213d99b-7f5c-4877-85e4-4a9c2afa2482","80bd3411-e248-48fa-944f-b842018e19aa","985e8fba-08e3-4dcc-bac9-da93ff4e761d","a1e1fe5d-31e1-4538-9cdc-95e700dc91b2","ac8fef31-1313-437e-ba52-260e1da2c447","ae28f74e-cf77-496d-979e-0988449a6051","c43832e1-b3e2-415f-9f39-4ad8e609262d","c88c63da-72fc-4b3f-bc71-c0265d719e94","cac3fc3f-ffc3-4b8f-a77d-078358ea6e4c","efdaa1b9-49a6-478b-bd97-427e703d5904"],"_id":"d03c481d-ce53-415b-b250-d4f745ecbf6d","abstract":"The capacity of the two-user Gaussian interference channel has been open for 30 years. The understanding on this problem has been limited. The best known achievable region is due to Han and Kobayashi but its characterization is very complicated. It is also not known how tight the existing outer bounds are. In this work, we show that the existing outer bounds can in fact be arbitrarily loose in some parameter ranges, and by deriving new outer bounds, we show that a very simple and explicit Han-Kobayashi type scheme can achieve to within a single bit per second per hertz (bit/s/Hz) of the capacity for all values of the channel parameters. We also show that the scheme is asymptotically optimal at certain high signal-to-noise ratio (SNR) regimes. Using our results, we provide a natural generalization of the point-to-point classical notion of degrees of freedom to interference-limited scenarios.","title":"Gaussian Interference Channel Capacity to Within One Bit","venue":"IEEE Transactions on Information Theory","year":2008,"__v":0,"citationCount":728},{"authors":["Xiaohu Shang","Gerhard Kramer","Biao Chen"],"references":["33cbee2d-14db-46e4-a438-af5e4b1b7ffb","481fb332-01fa-49ba-8aa3-9e476dcc1a61","502cc517-7d2d-4a60-92a4-ab075e50875c","75728c7b-5878-4201-ad14-24390d818f0c","80bd3411-e248-48fa-944f-b842018e19aa","81f3c4bb-29d9-43b2-92ab-0d196070c5bc","8e2696c6-5405-4ece-9931-c2a75315e3a2","985e8fba-08e3-4dcc-bac9-da93ff4e761d","ac8fef31-1313-437e-ba52-260e1da2c447","ae28f74e-cf77-496d-979e-0988449a6051","b35262e0-8810-4eef-8f49-0892fbedb391","c0182f5d-8299-4bef-996e-8d563f77124e","cac3fc3f-ffc3-4b8f-a77d-078358ea6e4c","d03c481d-ce53-415b-b250-d4f745ecbf6d"],"_id":"307a1739-c232-44cb-af85-695dd925cc10","abstract":"A new outer bound on the capacity region of Gaussian interference channels is developed. The bound combines and improves existing genie-aided methods and is shown to give the sum-rate capacity for noisy interference as defined in this paper. Specifically, it is shown that if the channel crosstalk coefficient magnitudes lie below thresholds defined by the power constraints then single-user detection at each receiver is sum-rate optimal, i.e., treating the interference as noise incurs no loss in performance. This is the first capacity result for the Gaussian interference channel with weak to moderate interference. Furthermore, for certain mixed (weak and strong) interference scenarios, the new outer bounds give a corner point of the capacity region.","title":"A New Outer Bound and the Noisy-Interference Sum–Rate Capacity for Gaussian Interference Channels","venue":"IEEE Transactions on Information Theory","year":2009,"__v":0,"citationCount":250},{"authors":["Abolfazl S. Motahari","Amir K. Khandani"],"references":["307a1739-c232-44cb-af85-695dd925cc10","3ca0a9b1-ff6a-4a66-b946-14774ce403a8","696d4b01-be76-4542-920c-bb9085cbb523","80bd3411-e248-48fa-944f-b842018e19aa","8e2696c6-5405-4ece-9931-c2a75315e3a2","985e8fba-08e3-4dcc-bac9-da93ff4e761d","a1e1fe5d-31e1-4538-9cdc-95e700dc91b2","ae28f74e-cf77-496d-979e-0988449a6051","cac3fc3f-ffc3-4b8f-a77d-078358ea6e4c","d03c481d-ce53-415b-b250-d4f745ecbf6d"],"_id":"502cc517-7d2d-4a60-92a4-ab075e50875c","abstract":"The capacity region of the two-user Gaussian interference channel (IC) is studied. Two classes of channels are considered: weak and mixed Gaussian IC. For the weak Gaussian IC, a new outer bound on the capacity region is obtained that outperforms previously known outer bounds. The sum capacity for a certain range of channel parameters is derived. For this range, it is proved that using Gaussian codebooks and treating interference as noise is optimal. It is shown that when Gaussian codebooks are used, the full Han-Kobayashi (HK) achievable rate region can be obtained by using the naive HK achievable scheme over three frequency bands. For the mixed Gaussian IC, a new outer bound is obtained that outperforms previously known outer bounds. For this case, the sum capacity for the entire range of channel parameters is derived. It is proved that the full HK achievable rate region using Gaussian codebooks is equivalent to that of the one-sided Gaussian IC for a particular range of channel parameters.","title":"Capacity bounds for the Gaussian Interference Channel","venue":"international symposium on information theory","year":2008,"__v":0,"citationCount":220}],"offsprings":[]},"310cbba4-d88d-4bf4-a4f2-738f91b5f8c8":{"authors":["Yoav Freund","Robert E. Schapire"],"references":["3704f939-09a2-4e9f-b851-1261bcd310df"],"_id":"310cbba4-d88d-4bf4-a4f2-738f91b5f8c8","abstract":"In the first part of the paper we consider the problem of dynamically apportioning resources among a set of options in a worst-case on-line framework. The model we study can be interpreted as a broad, abstract extension of the well-studied on-line prediction model to a general decision-theoretic setting. We show that the multiplicative weight-update Littlestone?Warmuth rule can be adapted to this model, yielding bounds that are slightly weaker in some cases, but applicable to a considerably more general class of learning problems. We show how the resulting learning algorithm can be applied to a variety of problems, including gambling, multiple-outcome prediction, repeated games, and prediction of points in Rn. In the second part of the paper we apply the multiplicative weight-update technique to derive a new boosting algorithm. This boosting algorithm does not require any prior knowledge about the performance of the weak learning algorithm. We also study generalizations of the new boosting algorithm to the problem of learning functions whose range, rather than being binary, is an arbitrary finite set or a bounded segment of the real line.","title":"A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting","venue":"symposium on the theory of computing","year":1997,"__v":0,"citationCount":2948,"parents":{"06d6d936-6a8d-43ba-8d6a-f032ee0c09c3":14.285714285714285,"1d48d76c-e82c-4ba5-a354-5db0b1ce05da":14.285714285714285,"3704f939-09a2-4e9f-b851-1261bcd310df":35.714285714285715,"505f493b-e09d-444d-9ee2-5e5db6a5b8ac":0,"50d6ceff-8829-44e3-a8a0-96b69b1805b4":0,"570585ca-59b2-489b-9945-ad3850ecd487":7.142857142857142,"6613541b-7a68-4fe9-b6a5-7873004d40aa":0,"a1ab7d2c-d2d3-4662-a988-0e51a4a08b76":0,"a8f17d49-3bef-4ccb-8e4c-6fc27d99a8db":0,"cf740e2c-f5bf-4e0c-8375-2948d6dff2c7":0,"ea294286-3cc2-4979-a22b-2fbb78c2ef18":7.142857142857142,"eca46fc4-e594-461f-83b8-aa5247e440ca":0,"f00fc370-0854-4967-bc6a-83b6c49da8bf":7.142857142857142,"fc603eb6-d237-4584-842c-c80805f31370":0},"keyword":{"06d6d936-6a8d-43ba-8d6a-f032ee0c09c3":9.896904761904763,"1d48d76c-e82c-4ba5-a354-5db0b1ce05da":12.282328042328043,"3704f939-09a2-4e9f-b851-1261bcd310df":12.912698412698411,"505f493b-e09d-444d-9ee2-5e5db6a5b8ac":11.408403361344536,"50d6ceff-8829-44e3-a8a0-96b69b1805b4":11.693650793650793,"570585ca-59b2-489b-9945-ad3850ecd487":11.292592592592591,"6613541b-7a68-4fe9-b6a5-7873004d40aa":10.808465608465609,"a1ab7d2c-d2d3-4662-a988-0e51a4a08b76":8.709563492063491,"a8f17d49-3bef-4ccb-8e4c-6fc27d99a8db":11.792592592592593,"cf740e2c-f5bf-4e0c-8375-2948d6dff2c7":11.471693121693121,"ea294286-3cc2-4979-a22b-2fbb78c2ef18":12.163095238095236,"eca46fc4-e594-461f-83b8-aa5247e440ca":11.454232804232802,"f00fc370-0854-4967-bc6a-83b6c49da8bf":10.440608465608467,"fc603eb6-d237-4584-842c-c80805f31370":12.470502645502645},"topic":["algorithm","problem","learn","set","predict"],"groups":[{"authors":["Yoav Freund","Robert E. Schapire"],"references":["056e5059-9864-479b-8a2a-fb1cd3d2dd32","0f115eea-2272-431f-9f21-6d6789b2bbc9","1d48d76c-e82c-4ba5-a354-5db0b1ce05da","29a79d67-73a4-4990-9880-f9cc5b56c6f2","4e80450b-37ed-440c-87cc-d17d27e0d892","6613541b-7a68-4fe9-b6a5-7873004d40aa","7a10be82-6113-4f60-9e37-f35f2d9423c5","8b2c0aff-4589-4e0f-aae4-4f84a4413406","a4a75c4c-0572-4ba6-adc7-bdbbd6fbcd37","cf740e2c-f5bf-4e0c-8375-2948d6dff2c7","d8ddd4ae-16ab-4702-b4f5-65aff0e33533","db26488d-78be-44b1-a343-e896f43c5d29","ea3e7ab3-e7c2-4007-93db-5c459bf3f42e","eca46fc4-e594-461f-83b8-aa5247e440ca","fc603eb6-d237-4584-842c-c80805f31370"],"_id":"3704f939-09a2-4e9f-b851-1261bcd310df","abstract":"In an earlier paper, we introduced a new \"boosting\" algorithm called AdaBoost which, theoretically, can be used to significantly reduce the error of any learning algorithm that con- sistently generates classifiers whose performance is a little better than random guessing. We also introduced the related notion of a \"pseudo-loss\" which is a method for forcing a learning algorithm of multi-label concepts to concentrate on the labels that are hardest to discriminate. In this paper, we describe experiments we carried out to assess how well AdaBoost with and without pseudo-loss, performs on real learning problems. We performed two sets of experiments. The first set compared boosting to Breiman's \"bagging\" method when used to aggregate various classifiers (including decision trees and single attribute- value tests). We compared the performance of the two methods on a collection of machine-learning benchmarks. In the second set of experiments, we studied in more detail the performance of boosting using a nearest-neighbor classifier on an OCR problem.","title":"Experiments with a New Boosting Algorithm","venue":"international conference on machine learning","year":1996,"__v":0,"citationCount":2720}],"offsprings":["8b8a2247-bd77-4736-b493-449734f56b9a","e649a9fd-f6d9-4aac-b428-29b82c20a484","d1ba534e-3f80-4366-bb83-be16006f9e18"]},"32d158dc-6f9f-426a-973b-8edc5e4c5dad":{"authors":["Wenyi Zhao","R. Chellappa","P.J. Phillips","Avi Rosenfeld"],"references":["56f4b72a-ec39-47ac-8220-899296e7fb18","5e8b0e8a-d687-4333-bfe9-73b4c1bebde5","923f5d0a-23a3-4fb1-bee7-ec72122709a4","bf03f268-de9d-4a80-aee1-200990056503","e649a9fd-f6d9-4aac-b428-29b82c20a484"],"_id":"32d158dc-6f9f-426a-973b-8edc5e4c5dad","abstract":"As one of the most successful applications of image analysis and understanding, face recognition has recently received significant attention, especially during the past several years. At least two reasons account for this trend: the first is the wide range of commercial and law enforcement applications, and the second is the availability of feasible technologies after 30 years of research. Even though current machine recognition systems have reached a certain level of maturity, their success is limited by the conditions imposed by many real applications. For example, recognition of face images acquired in an outdoor environment with changes in illumination and/or pose remains a largely unsolved problem. In other words, current systems are still far away from the capability of the human perception system.This paper provides an up-to-date critical survey of still- and video-based face recognition research. There are two underlying motivations for us to write this survey paper: the first is to provide an up-to-date review of the existing literature, and the second is to offer some insights into the studies of machine recognition of faces. To provide a comprehensive survey, we not only categorize existing recognition techniques but also present detailed descriptions of representative methods within each category. In addition, relevant topics such as psychophysical studies, system evaluation, and issues of illumination and pose variation are covered.","title":"Face recognition: A literature survey","venue":"ACM Computing Surveys","year":2003,"__v":0,"citationCount":2475,"parents":{"00909251-9935-44f3-94a1-629023b5015b":1.2658227848101267,"019fb6c8-c81b-4ef9-94be-18083093da48":1.2658227848101267,"037b9625-bad7-41d3-be15-3d6d109298c2":1.2658227848101267,"077f6588-d157-408b-981f-3b3db91d21c9":10.126582278481013,"0f9ab580-e0a8-409c-9555-0f46dee18c62":0,"0fa84c94-ae45-44d3-bd37-aa3d48158977":7.59493670886076,"123dbd0e-74f1-428b-9f16-00d04583f937":3.79746835443038,"14c4dfa0-37fe-45d6-a608-dfc3f7c2e3f8":0,"1863ec2a-4485-4bf6-80c4-6dfce4a8d627":5.063291139240507,"1ba94a3f-ba8a-4aff-8151-3a855803711c":5.063291139240507,"1bfa187e-2966-4a8f-ad71-f62a12204971":1.2658227848101267,"20df996a-f7d5-41ba-8895-a6caeabec865":5.063291139240507,"27505f5b-d81f-4b85-b85e-bd357aaa8468":20.253164556962027,"291af141-8d36-44eb-a734-79dd03e99fab":3.79746835443038,"291bceb3-9d76-46ce-b9ea-5dbef5dc2560":1.2658227848101267,"31694e30-f279-4014-8a46-cf76272cd058":3.79746835443038,"33d74862-6527-4c30-be0c-95226a3f8a3a":0,"34f6453a-5555-46cf-af48-ac1576ccb367":2.5316455696202533,"3a2861b4-a6f7-4ab0-9f88-480006b53bb0":3.79746835443038,"40f728c0-55b3-423b-aff5-a9b3ff27b7d5":3.79746835443038,"44a9fc14-1bf4-489e-add7-84abc2cb3561":0,"4775c95c-c5bc-4a74-a653-e8c94a6e3baa":1.2658227848101267,"4eb97838-8c8a-461f-b23e-8da4ac3488a2":0,"54a5822c-e405-44ad-84e3-cea51e7349c2":11.39240506329114,"552d8ea6-1cb0-44db-ba2c-eec5016ef5df":2.5316455696202533,"56cd3fdb-73ff-431e-8945-d673f9469f33":18.9873417721519,"56f4b72a-ec39-47ac-8220-899296e7fb18":3.79746835443038,"580cb16b-97bf-43ed-8850-85b5918bdb83":0,"5e8b0e8a-d687-4333-bfe9-73b4c1bebde5":18.9873417721519,"5eb1916a-bbf2-4413-b5ba-589c62877ac0":2.5316455696202533,"5ebbd1f5-dfe5-4eec-9883-b8b5efea366c":1.2658227848101267,"5fda5f10-7c36-497e-b8b9-31e3a13daf6a":0,"61e615e7-f78f-4f1e-b604-343ecf4b2ec9":2.5316455696202533,"62683f45-98a9-44a3-a3ea-219079aae364":0,"64fa74e8-db02-4190-87d7-bf23e9859a7c":0,"6affa0b1-4908-4f5d-9e72-66e66e8a96ef":6.329113924050633,"6e8cc926-79a1-4676-a2bd-f9d49f3144cf":5.063291139240507,"6f10ee49-5baf-4f79-aab2-105ae01326db":1.2658227848101267,"6f3c082f-288f-4588-8f53-9476a60cfad7":0,"762c9918-e579-42ef-80e5-4e464870a017":2.5316455696202533,"7d738632-dc5d-4ec9-a4cd-1d1a74d33166":6.329113924050633,"810f7115-00c6-42b2-bf8c-142b2a35ed57":6.329113924050633,"85114f9d-70a8-4940-83aa-af504b75acf8":0,"853b9534-32ab-4bf8-a328-1f4c18cf3a1b":1.2658227848101267,"8835551e-08fe-468f-8523-3bc1752f41f3":6.329113924050633,"8fbd241e-236d-4a82-9471-0d854326e3cb":0,"9025d4f2-c1f7-4aa1-9632-a859a845a2d4":6.329113924050633,"912aabff-def4-4026-9eb9-9d04cb8fabb1":3.79746835443038,"923f5d0a-23a3-4fb1-bee7-ec72122709a4":0,"94a0b002-578e-4581-ad1d-8fc52a7052ea":1.2658227848101267,"9702775a-a8c7-4089-b0f8-418ccdcb8dba":1.2658227848101267,"971f156e-04ee-449a-86b1-82b37d50a9ce":6.329113924050633,"9b9c96fb-f880-49fd-bdae-651407dc2e30":1.2658227848101267,"9e33c655-8bd8-40ce-a32d-f4a2d1335bd1":1.2658227848101267,"9f8626c6-acdb-460a-ace2-050d880219e1":1.2658227848101267,"a2c0b7ee-74df-44b9-a22a-111d84bcc8ee":3.79746835443038,"aafd7a81-b545-4ae8-8b9a-cf61896fc6d3":1.2658227848101267,"adda2917-0ddc-4d6e-b7b3-86c043022042":1.2658227848101267,"b1295c0c-9c1c-41d7-8cd2-74ed1557481c":3.79746835443038,"b5c70352-d0a3-4a6b-b961-ed59491ad43f":0,"bf03f268-de9d-4a80-aee1-200990056503":2.5316455696202533,"c95f638a-4ce3-4cba-8028-24d2b213ad18":2.5316455696202533,"ce79b8ff-a84b-4138-badd-4e59d7b87737":0,"ce9c0c07-83af-4fb7-9491-38255660025c":2.5316455696202533,"cf3b633a-6201-492c-8de3-9af4e03c8f97":0,"d3aa43bb-afc8-4ad6-89d3-8f50d2cc277d":11.39240506329114,"d56847b7-c010-4782-9ef0-f48bb01908dd":0,"d5e5a24d-f80e-4f1a-b48b-22403b653276":2.5316455696202533,"d6e37fb1-5f7e-448e-847b-7d1f1271c574":3.79746835443038,"d75d2735-844d-4446-ac4e-1677e338e624":8.860759493670885,"de9218ee-1982-455b-96c4-f28718f76a2f":11.39240506329114,"e17d0924-0ffb-4392-91a5-1d9e2748d3ae":7.59493670886076,"e308777d-43e0-4041-92b2-0c43715b5227":2.5316455696202533,"e649a9fd-f6d9-4aac-b428-29b82c20a484":2.5316455696202533,"eb63b82d-5108-4abf-8ee7-2d11bc1998a0":3.79746835443038,"ece4f56c-b724-40cf-b23c-d4ec101cf4de":7.59493670886076,"ed59a2e5-7330-4e07-9edf-cc80872135d0":5.063291139240507,"f191f982-a057-4358-bceb-57a3298b533e":0,"fa8167b1-8d7a-482c-b0d6-07ca5db8d823":2.5316455696202533},"keyword":{"00909251-9935-44f3-94a1-629023b5015b":8.061111111111112,"019fb6c8-c81b-4ef9-94be-18083093da48":11.905555555555555,"037b9625-bad7-41d3-be15-3d6d109298c2":0,"077f6588-d157-408b-981f-3b3db91d21c9":11.90111111111111,"0f9ab580-e0a8-409c-9555-0f46dee18c62":0,"0fa84c94-ae45-44d3-bd37-aa3d48158977":8.727777777777776,"123dbd0e-74f1-428b-9f16-00d04583f937":11.357142857142854,"14c4dfa0-37fe-45d6-a608-dfc3f7c2e3f8":11.849603174603175,"1863ec2a-4485-4bf6-80c4-6dfce4a8d627":10.163888888888888,"1ba94a3f-ba8a-4aff-8151-3a855803711c":9.272222222222222,"1bfa187e-2966-4a8f-ad71-f62a12204971":11.053571428571427,"20df996a-f7d5-41ba-8895-a6caeabec865":11.558597883597878,"27505f5b-d81f-4b85-b85e-bd357aaa8468":10.03690476190476,"291af141-8d36-44eb-a734-79dd03e99fab":7.7250000000000005,"291bceb3-9d76-46ce-b9ea-5dbef5dc2560":11.117857142857144,"31694e30-f279-4014-8a46-cf76272cd058":9.319444444444445,"33d74862-6527-4c30-be0c-95226a3f8a3a":9.532539682539682,"34f6453a-5555-46cf-af48-ac1576ccb367":11.934444444444441,"3a2861b4-a6f7-4ab0-9f88-480006b53bb0":10.241666666666665,"40f728c0-55b3-423b-aff5-a9b3ff27b7d5":11.953571428571427,"44a9fc14-1bf4-489e-add7-84abc2cb3561":10.270833333333332,"4775c95c-c5bc-4a74-a653-e8c94a6e3baa":10.603737373737374,"4eb97838-8c8a-461f-b23e-8da4ac3488a2":9.816137566137565,"54a5822c-e405-44ad-84e3-cea51e7349c2":10.752777777777775,"552d8ea6-1cb0-44db-ba2c-eec5016ef5df":11.877777777777778,"56cd3fdb-73ff-431e-8945-d673f9469f33":11.844444444444443,"56f4b72a-ec39-47ac-8220-899296e7fb18":10.403174603174602,"580cb16b-97bf-43ed-8850-85b5918bdb83":10.662301587301586,"5e8b0e8a-d687-4333-bfe9-73b4c1bebde5":10.180555555555552,"5eb1916a-bbf2-4413-b5ba-589c62877ac0":10.653835978835978,"5ebbd1f5-dfe5-4eec-9883-b8b5efea366c":11.114999999999997,"5fda5f10-7c36-497e-b8b9-31e3a13daf6a":9.101388888888888,"61e615e7-f78f-4f1e-b604-343ecf4b2ec9":11.449074074074073,"62683f45-98a9-44a3-a3ea-219079aae364":9.075000000000001,"64fa74e8-db02-4190-87d7-bf23e9859a7c":8.385317460317461,"6affa0b1-4908-4f5d-9e72-66e66e8a96ef":11.84431216931217,"6e8cc926-79a1-4676-a2bd-f9d49f3144cf":11.02857142857143,"6f10ee49-5baf-4f79-aab2-105ae01326db":9.807142857142855,"6f3c082f-288f-4588-8f53-9476a60cfad7":0,"762c9918-e579-42ef-80e5-4e464870a017":11.709523809523807,"7d738632-dc5d-4ec9-a4cd-1d1a74d33166":9.915873015873016,"810f7115-00c6-42b2-bf8c-142b2a35ed57":7.999999999999999,"85114f9d-70a8-4940-83aa-af504b75acf8":12.150833333333331,"853b9534-32ab-4bf8-a328-1f4c18cf3a1b":11.079629629629629,"8835551e-08fe-468f-8523-3bc1752f41f3":11.019166666666667,"8fbd241e-236d-4a82-9471-0d854326e3cb":11.152777777777775,"9025d4f2-c1f7-4aa1-9632-a859a845a2d4":11.24,"912aabff-def4-4026-9eb9-9d04cb8fabb1":12.117460317460317,"923f5d0a-23a3-4fb1-bee7-ec72122709a4":9.483333333333333,"94a0b002-578e-4581-ad1d-8fc52a7052ea":11.240873015873014,"9702775a-a8c7-4089-b0f8-418ccdcb8dba":9.513888888888888,"971f156e-04ee-449a-86b1-82b37d50a9ce":11.480555555555556,"9b9c96fb-f880-49fd-bdae-651407dc2e30":9.138888888888888,"9e33c655-8bd8-40ce-a32d-f4a2d1335bd1":0,"9f8626c6-acdb-460a-ace2-050d880219e1":10.716666666666667,"a2c0b7ee-74df-44b9-a22a-111d84bcc8ee":9.411031746031744,"aafd7a81-b545-4ae8-8b9a-cf61896fc6d3":9.087301587301589,"adda2917-0ddc-4d6e-b7b3-86c043022042":9.736111111111109,"b1295c0c-9c1c-41d7-8cd2-74ed1557481c":9.483333333333334,"b5c70352-d0a3-4a6b-b961-ed59491ad43f":10.397817460317462,"bf03f268-de9d-4a80-aee1-200990056503":10.412301587301588,"c95f638a-4ce3-4cba-8028-24d2b213ad18":12.85111111111111,"ce79b8ff-a84b-4138-badd-4e59d7b87737":10.18611111111111,"ce9c0c07-83af-4fb7-9491-38255660025c":8.727777777777778,"cf3b633a-6201-492c-8de3-9af4e03c8f97":10.02222222222222,"d3aa43bb-afc8-4ad6-89d3-8f50d2cc277d":10.570238095238096,"d56847b7-c010-4782-9ef0-f48bb01908dd":8.013329725829726,"d5e5a24d-f80e-4f1a-b48b-22403b653276":9.497222222222222,"d6e37fb1-5f7e-448e-847b-7d1f1271c574":12.540079365079364,"d75d2735-844d-4446-ac4e-1677e338e624":7.844444444444445,"de9218ee-1982-455b-96c4-f28718f76a2f":10.257936507936506,"e17d0924-0ffb-4392-91a5-1d9e2748d3ae":11.503703703703703,"e308777d-43e0-4041-92b2-0c43715b5227":11.83333333333333,"e649a9fd-f6d9-4aac-b428-29b82c20a484":10.994444444444445,"eb63b82d-5108-4abf-8ee7-2d11bc1998a0":10.236111111111112,"ece4f56c-b724-40cf-b23c-d4ec101cf4de":10.642103174603173,"ed59a2e5-7330-4e07-9edf-cc80872135d0":10.036111111111111,"f191f982-a057-4358-bceb-57a3298b533e":9.484848484848484,"fa8167b1-8d7a-482c-b0d6-07ca5db8d823":7.5166666666666675},"topic":["recognit","system","face","survei","applic"],"offsprings":["7236dbb7-f0b2-4e28-bb7c-6de187c32d64","e3a5cec9-7e82-4c14-86ab-0d95a92712a7"]},"352838dd-9583-402f-be39-52df4810a25f":{"authors":["Jeffrey O. Kephart","David M. Chess"],"references":[],"_id":"352838dd-9583-402f-be39-52df4810a25f","abstract":"A 2001 IBM manifesto observed that a looming software complexity crisis -caused by applications and environments that number into the tens of millions of lines of code - threatened to halt progress in computing. The manifesto noted the almost impossible difficulty of managing current and planned computing systems, which require integrating several heterogeneous environments into corporate-wide computing systems that extend into the Internet. Autonomic computing, perhaps the most attractive approach to solving this problem, creates systems that can manage themselves when given high-level objectives from administrators. Systems manage themselves according to an administrator's goals. New components integrate as effortlessly as a new cell establishes itself in the human body. These ideas are not science fiction, but elements of the grand challenge to create self-managing computing systems.","title":"The vision of autonomic computing","venue":"IEEE Computer","year":2003,"__v":0,"citationCount":2599,"parents":{"4e2f6f85-f3ba-483a-9477-fbda0c7f816a":0,"609fabe4-129f-4c4c-8905-2f9896534c89":0,"c47bdbf7-c79e-4bb9-8a24-ebc0b2993d56":0,"c72d3bde-7cca-46a2-8d0b-66bc5e1d23c7":0,"e1dea621-611f-4569-9d9e-1d4a20d665d3":0},"keyword":{"4e2f6f85-f3ba-483a-9477-fbda0c7f816a":0,"609fabe4-129f-4c4c-8905-2f9896534c89":9.61148148148148,"c47bdbf7-c79e-4bb9-8a24-ebc0b2993d56":9.17137566137566,"c72d3bde-7cca-46a2-8d0b-66bc5e1d23c7":12.38642857142857,"e1dea621-611f-4569-9d9e-1d4a20d665d3":9.660714285714285},"topic":["system","comput","manag","manifesto","integr"],"offsprings":[]},"38135245-8eff-4078-af6a-ea559ffa660b":{"authors":["A.K. Jain","M. N. Murty","Patrick J. Flynn"],"references":["010793c8-fedb-49ee-88bc-1e20f8bae870"],"_id":"38135245-8eff-4078-af6a-ea559ffa660b","abstract":"Clustering is the unsupervised classification of patterns (observations, data items, or feature vectors) into groups (clusters). The clustering problem has been addressed in many contexts and by researchers in many disciplines; this reflects its broad appeal and usefulness as one of the steps in exploratory data analysis. However, clustering is a difficult problem combinatorially, and differences in assumptions and contexts in different communities has made the transfer of useful generic concepts and methodologies slow to occur. This paper presents an overviewof pattern clustering methods from a statistical pattern recognition perspective, with a goal of providing useful advice and references to fundamental concepts accessible to the broad community of clustering practitioners. We present a taxonomy of clustering techniques, and identify cross-cutting themes and recent advances. We also describe some important applications of clustering algorithms such as image segmentation, object recognition, and information retrieval.","title":"Data clustering: a review","venue":"ACM Computing Surveys","year":1999,"__v":0,"citationCount":4114,"parents":{"010793c8-fedb-49ee-88bc-1e20f8bae870":3.225806451612903,"04263041-e3e9-4353-9bda-5b5e458158d6":1.0752688172043012,"0c547504-d1a7-48ae-889c-22a6d1dac253":2.1505376344086025,"0cd2901a-4aaa-4b9c-8782-6084757f3408":0,"0f1d44b8-f383-4544-a1cc-f8b10c5c5c95":0,"0f9ecc62-8c0b-49a6-a8c9-223bcec3cc21":4.301075268817205,"1017d9d4-9a4c-423d-ad40-6d9bebbd6b31":0,"126446a1-730e-44dc-858b-e5c768bd81ac":0,"15e5ed2a-3259-4cff-93db-9ea9247b1069":0,"169e3271-71dc-44c9-807e-abad97a8979c":1.0752688172043012,"1b337fa3-6479-46ba-bdf0-b5cb03e02038":2.1505376344086025,"1be1f8bd-1bbe-4824-b4f3-e324bc6ecc9c":0,"1edfc050-3153-4557-8f83-0d165ef6d5ca":1.0752688172043012,"2523a03b-5af6-4e63-8f96-d49976e03a25":0,"29f99416-4afc-4293-b569-93c89a934d6c":3.225806451612903,"2c2864a7-fcb9-400e-938d-34d584c8d62f":0,"37526cc3-79f9-444a-9076-7e4c56810dd0":2.1505376344086025,"376bc429-65c2-4ade-828b-ba111dcd2360":0,"3b60b9c0-b0f5-413d-951c-19c880b78b44":0,"3e9f67d5-de11-418b-b001-34148e80ed75":1.0752688172043012,"3ec1b558-1e7c-4288-9861-c8337413e376":1.0752688172043012,"3f3108eb-2f59-48b9-be4b-d2e0d0b38115":0,"3f41919f-3934-4eb1-ba4f-c23191491cc0":5.376344086021505,"3f832194-791f-4cc3-abcd-bbad4498c06f":0,"43e0a314-c4a4-4d89-b0a1-b0c929ba8f9b":0,"4a57e315-21d3-420a-96e3-6d1f1589e372":0,"4aaa373d-ccf1-4c6e-b830-1460e64e685f":0,"4ddd74c4-5807-4ebf-9d97-99cd116aeae1":0,"4de1d97e-e9bb-41c0-b995-6eef3a551ac8":4.301075268817205,"4fc133ce-8d42-4668-81d2-4f7d843789a8":6.451612903225806,"539ece79-493b-48eb-8134-4947154b6783":1.0752688172043012,"598c7f2c-85fc-48d1-8204-f164b53660fa":1.0752688172043012,"6a6b9aa6-683f-4c7c-b06e-9c3018d10fd3":0,"6c1b1bca-1937-47d7-ae27-9db7df7e6f50":2.1505376344086025,"70e86498-0a19-465c-8b73-49c2769b1a53":2.1505376344086025,"75cc7292-f243-4a93-bfeb-a40e1c7503c3":0,"76f221bf-6a1c-449f-b365-e6d5a2feff67":2.1505376344086025,"7a41e483-5f5a-42a5-9f35-f8db5a701527":0,"7b8583e6-dbd3-4d2f-859a-f1de071886f2":2.1505376344086025,"7e1eeb34-62a7-41b7-8c1d-9cce0b528102":0,"80cd25cc-685b-4678-91a2-9f20f658695c":2.1505376344086025,"81251c93-acf8-4031-8acc-4b570c5759cc":2.1505376344086025,"8225a69d-2fa5-4196-836d-a1a407343077":0,"83b34430-abc8-48b0-b656-d3da12e2ff81":0,"8859baf1-a021-4832-9a3f-72e52aa10fc7":1.0752688172043012,"88b09a96-d7eb-4974-8aa3-458d4db09a3b":2.1505376344086025,"8cb77f48-21ae-4aeb-8b3c-c4ffeff0a0df":1.0752688172043012,"8e6ac143-8d42-4cdf-9ea3-d5439b6a5959":2.1505376344086025,"8f9b43a0-1ead-4809-bca2-fcd02cd879c4":0,"94a0b002-578e-4581-ad1d-8fc52a7052ea":0,"9d0aa5e3-f94c-4334-9c07-486d3c513368":0,"9d112b22-f7cc-49aa-8c08-88469cae944c":1.0752688172043012,"a7118e96-8f8c-4294-9abb-e12647db7127":2.1505376344086025,"a82b710e-0d00-4298-ac40-bad0692b6791":2.1505376344086025,"a8b91475-cd52-4d80-8a05-d04215e869b8":0,"a9004718-5b18-417f-ba57-1e6139dfe7c0":0,"ac370fe9-1a4c-46ad-96aa-3a44ab0a2840":0,"b03abbe3-5413-4ef2-a723-24dc15712c3e":3.225806451612903,"b0b6b57f-86c1-42d7-899e-5fc6a30b5e7b":1.0752688172043012,"b483c81c-ffc0-4304-ad74-047550d2ec35":5.376344086021505,"b491465e-23ee-4cdb-9b86-5ef1d66b2123":1.0752688172043012,"b4da63d9-a2c5-4e3c-8c81-dd5d77444c5a":0,"b606e951-c35c-41f4-a510-bd59dca301a2":1.0752688172043012,"b62a32f3-eb04-429f-93ca-f20dadf916a5":0,"b6917ae7-cad2-4fa7-9ad9-9bb18ce6567a":2.1505376344086025,"bcc3d060-ec38-4d1f-9df8-360d026e17b6":0,"bdb8d83d-1771-4399-b593-d43be5a9f892":0,"c1c2b024-2157-460a-aefb-118a9263928b":2.1505376344086025,"c58844c2-c15c-459b-a2bd-49299124f34e":0,"c7fac587-c91b-4df1-ada7-18ad00ba850a":1.0752688172043012,"c88e73cb-f426-4aac-900b-0a2b3f820f63":2.1505376344086025,"ca4d053d-7efd-43d0-bce5-2ccb98ae3451":0,"cbbfb0c6-ddfe-4b2e-a9b0-b1313eb31d6d":0,"cf4df540-285d-410a-bbbe-19c3ac2f34f2":0,"cfea5778-a9a5-464c-b7d4-f7d54eb26966":2.1505376344086025,"d353984d-d376-43f1-ad08-0f3199f7b993":0,"d4d4286f-609d-42cb-a3a5-47f057ff4a7e":1.0752688172043012,"d554787a-ad86-4f31-9bc2-944ab44b7c7f":10.75268817204301,"d5e049f8-9188-4087-a38f-9d2d2ac0f449":1.0752688172043012,"d970fa22-4ef3-48f8-97f6-ede84caf24dd":3.225806451612903,"d9752a5a-1603-45cc-9a21-7997750d429f":0,"dc43cb07-2f66-49d3-8ea5-df204aafce10":0,"dde5d677-b994-4729-9307-ea602c58a734":2.1505376344086025,"e02b8c93-d055-4c1e-bc0a-e7629bd94866":3.225806451612903,"e36de564-d697-4c12-b099-772a5001db05":1.0752688172043012,"e4209f92-6f22-406c-9d10-10ebccb8bbc2":0,"e5c0e024-a545-4df1-9b72-6f9562231d71":1.0752688172043012,"eb141c7c-b6d9-48d4-8e96-150d4f59bac5":0,"f505afb8-a7c5-408f-a1bd-1c8c3ac332d1":1.0752688172043012,"f56c05c5-6a35-46ee-9bde-a2633ae998c5":1.0752688172043012,"f5788ee3-cabb-48ba-9873-d04544ba8319":1.0752688172043012,"fc132efc-b72b-4b33-ab52-2aa944d2a2ce":1.0752688172043012,"fdb43c84-e9de-4ded-99dc-3c1917892d05":3.225806451612903},"keyword":{"010793c8-fedb-49ee-88bc-1e20f8bae870":10.609920634920634,"04263041-e3e9-4353-9bda-5b5e458158d6":9.683333333333334,"0c547504-d1a7-48ae-889c-22a6d1dac253":11.792460317460318,"0cd2901a-4aaa-4b9c-8782-6084757f3408":0,"0f1d44b8-f383-4544-a1cc-f8b10c5c5c95":13.276984126984125,"0f9ecc62-8c0b-49a6-a8c9-223bcec3cc21":10.59920634920635,"1017d9d4-9a4c-423d-ad40-6d9bebbd6b31":0,"126446a1-730e-44dc-858b-e5c768bd81ac":13.712301587301587,"15e5ed2a-3259-4cff-93db-9ea9247b1069":7.807936507936508,"169e3271-71dc-44c9-807e-abad97a8979c":12.923148148148147,"1b337fa3-6479-46ba-bdf0-b5cb03e02038":12.726322751322751,"1be1f8bd-1bbe-4824-b4f3-e324bc6ecc9c":14.114417989417992,"1edfc050-3153-4557-8f83-0d165ef6d5ca":12.621031746031747,"2523a03b-5af6-4e63-8f96-d49976e03a25":9.961507936507935,"29f99416-4afc-4293-b569-93c89a934d6c":9.891666666666667,"2c2864a7-fcb9-400e-938d-34d584c8d62f":10.122619047619047,"37526cc3-79f9-444a-9076-7e4c56810dd0":13.654761904761909,"376bc429-65c2-4ade-828b-ba111dcd2360":0,"3b60b9c0-b0f5-413d-951c-19c880b78b44":11.80654761904762,"3e9f67d5-de11-418b-b001-34148e80ed75":10.464682539682538,"3ec1b558-1e7c-4288-9861-c8337413e376":15.3406746031746,"3f3108eb-2f59-48b9-be4b-d2e0d0b38115":11.153809523809523,"3f41919f-3934-4eb1-ba4f-c23191491cc0":10.657936507936508,"3f832194-791f-4cc3-abcd-bbad4498c06f":14.018253968253966,"43e0a314-c4a4-4d89-b0a1-b0c929ba8f9b":8.636587301587301,"4a57e315-21d3-420a-96e3-6d1f1589e372":11.597710622710624,"4aaa373d-ccf1-4c6e-b830-1460e64e685f":10.348809523809523,"4ddd74c4-5807-4ebf-9d97-99cd116aeae1":12.537830687830686,"4de1d97e-e9bb-41c0-b995-6eef3a551ac8":0,"4fc133ce-8d42-4668-81d2-4f7d843789a8":14.434814814814812,"539ece79-493b-48eb-8134-4947154b6783":12.237037037037036,"598c7f2c-85fc-48d1-8204-f164b53660fa":13.34206349206349,"6a6b9aa6-683f-4c7c-b06e-9c3018d10fd3":13.551190476190477,"6c1b1bca-1937-47d7-ae27-9db7df7e6f50":10.935714285714285,"70e86498-0a19-465c-8b73-49c2769b1a53":11.153174603174602,"75cc7292-f243-4a93-bfeb-a40e1c7503c3":12.534722222222221,"76f221bf-6a1c-449f-b365-e6d5a2feff67":12.156349206349207,"7a41e483-5f5a-42a5-9f35-f8db5a701527":10.981349206349206,"7b8583e6-dbd3-4d2f-859a-f1de071886f2":10.389021164021166,"7e1eeb34-62a7-41b7-8c1d-9cce0b528102":11.261111111111111,"80cd25cc-685b-4678-91a2-9f20f658695c":12.765608465608466,"81251c93-acf8-4031-8acc-4b570c5759cc":10.245317460317462,"8225a69d-2fa5-4196-836d-a1a407343077":12.96494708994709,"83b34430-abc8-48b0-b656-d3da12e2ff81":8.959523809523809,"8859baf1-a021-4832-9a3f-72e52aa10fc7":11.205820105820104,"88b09a96-d7eb-4974-8aa3-458d4db09a3b":11.10595238095238,"8cb77f48-21ae-4aeb-8b3c-c4ffeff0a0df":11.388095238095236,"8e6ac143-8d42-4cdf-9ea3-d5439b6a5959":9.683333333333334,"8f9b43a0-1ead-4809-bca2-fcd02cd879c4":12.429166666666665,"94a0b002-578e-4581-ad1d-8fc52a7052ea":11.590079365079363,"9d0aa5e3-f94c-4334-9c07-486d3c513368":11.75132275132275,"9d112b22-f7cc-49aa-8c08-88469cae944c":13.655555555555555,"a7118e96-8f8c-4294-9abb-e12647db7127":9.718253968253967,"a82b710e-0d00-4298-ac40-bad0692b6791":14.009126984126985,"a8b91475-cd52-4d80-8a05-d04215e869b8":11.255952380952378,"a9004718-5b18-417f-ba57-1e6139dfe7c0":10.572222222222221,"ac370fe9-1a4c-46ad-96aa-3a44ab0a2840":12.348015873015873,"b03abbe3-5413-4ef2-a723-24dc15712c3e":11.193650793650795,"b0b6b57f-86c1-42d7-899e-5fc6a30b5e7b":9.784126984126983,"b483c81c-ffc0-4304-ad74-047550d2ec35":11.31547619047619,"b491465e-23ee-4cdb-9b86-5ef1d66b2123":11.557539682539682,"b4da63d9-a2c5-4e3c-8c81-dd5d77444c5a":10.298809523809524,"b606e951-c35c-41f4-a510-bd59dca301a2":13.870238095238095,"b62a32f3-eb04-429f-93ca-f20dadf916a5":0,"b6917ae7-cad2-4fa7-9ad9-9bb18ce6567a":12.99179894179894,"bcc3d060-ec38-4d1f-9df8-360d026e17b6":13.550555555555555,"bdb8d83d-1771-4399-b593-d43be5a9f892":0,"c1c2b024-2157-460a-aefb-118a9263928b":11.763227513227513,"c58844c2-c15c-459b-a2bd-49299124f34e":11.943783068783068,"c7fac587-c91b-4df1-ada7-18ad00ba850a":11.063492063492063,"c88e73cb-f426-4aac-900b-0a2b3f820f63":11.925,"ca4d053d-7efd-43d0-bce5-2ccb98ae3451":9.396428571428572,"cbbfb0c6-ddfe-4b2e-a9b0-b1313eb31d6d":0,"cf4df540-285d-410a-bbbe-19c3ac2f34f2":10.921825396825396,"cfea5778-a9a5-464c-b7d4-f7d54eb26966":10.978174603174603,"d353984d-d376-43f1-ad08-0f3199f7b993":11.236507936507936,"d4d4286f-609d-42cb-a3a5-47f057ff4a7e":11.035515873015873,"d554787a-ad86-4f31-9bc2-944ab44b7c7f":11.447619047619048,"d5e049f8-9188-4087-a38f-9d2d2ac0f449":13.339417989417992,"d970fa22-4ef3-48f8-97f6-ede84caf24dd":10.090277777777777,"d9752a5a-1603-45cc-9a21-7997750d429f":9.819708994708993,"dc43cb07-2f66-49d3-8ea5-df204aafce10":0,"dde5d677-b994-4729-9307-ea602c58a734":11.637037037037038,"e02b8c93-d055-4c1e-bc0a-e7629bd94866":11.162936507936507,"e36de564-d697-4c12-b099-772a5001db05":9.82063492063492,"e4209f92-6f22-406c-9d10-10ebccb8bbc2":10.55873015873016,"e5c0e024-a545-4df1-9b72-6f9562231d71":11.284126984126983,"eb141c7c-b6d9-48d4-8e96-150d4f59bac5":11.27694805194805,"f505afb8-a7c5-408f-a1bd-1c8c3ac332d1":11.748809523809518,"f56c05c5-6a35-46ee-9bde-a2633ae998c5":11.082777777777777,"f5788ee3-cabb-48ba-9873-d04544ba8319":13.66441798941799,"fc132efc-b72b-4b33-ab52-2aa944d2a2ce":11.773412698412697,"fdb43c84-e9de-4ded-99dc-3c1917892d05":12.60846560846561},"topic":["cluster","pattern","recognit","problem","present"],"offsprings":["b0ef6e4d-4c86-4b10-9e0a-7b630ca8d7f7"]},"3ed17ffd-b416-470a-973a-77d7085a3503":{"authors":["Alper Yilmaz","Omar Javed","Mubarak Shah"],"references":["79da913e-c4d6-4d89-831c-f68f7976dcfc","82eb55e6-39a8-4968-8be6-e2bfbb439a40","8bb47288-c305-4131-9a23-3635d1bc15ad","8d8e7d51-3223-4776-bf6a-40306774b8a1","b944f77f-113b-4a02-ae5e-d4a124b8fd5b","bf03f268-de9d-4a80-aee1-200990056503","c8f80ea6-4602-458c-9a70-daf1c646c89b"],"_id":"3ed17ffd-b416-470a-973a-77d7085a3503","abstract":"The goal of this article is to review the state-of-the-art tracking methods, classify them into different categories, and identify new trends. Object tracking, in general, is a challenging problem. Difficulties in tracking objects can arise due to abrupt object motion, changing appearance patterns of both the object and the scene, nonrigid object structures, object-to-object and object-to-scene occlusions, and camera motion. Tracking is usually performed in the context of higher-level applications that require the location and/or shape of the object in every frame. Typically, assumptions are made to constrain the tracking problem in the context of a particular application. In this survey, we categorize the tracking methods on the basis of the object and motion representations used, provide detailed descriptions of representative methods in each category, and examine their pros and cons. Moreover, we discuss the important issues related to tracking including the use of appropriate image features, selection of motion models, and detection of objects.","title":"Object tracking: A survey","venue":"ACM Computing Surveys","year":2006,"__v":0,"citationCount":1577,"parents":{"01df6660-e54b-4cab-a20e-179393feb854":0.9900990099009901,"0266a6dc-9cac-428b-95de-3e44a3948640":3.9603960396039604,"088d00cf-ed12-4552-8958-8b550401f355":1.9801980198019802,"0e28e139-d1c1-49aa-9e29-aa74dc697a2e":1.9801980198019802,"0efce57f-45b7-41af-9712-d97317c006e3":0.9900990099009901,"0ff3b52b-7fd7-4d42-95ed-24b882367d3c":2.9702970297029703,"10741541-6022-4249-ba45-9f1e105cbc16":0.9900990099009901,"107983ba-765c-48df-addd-402abfb3c62e":0,"108c473e-db74-4339-822e-e17a74d2f329":0.9900990099009901,"16143b20-4cf5-4917-8c1a-6aadd3f3d5de":0.9900990099009901,"1769a3bf-41eb-4aed-9cc6-e4c702002084":0,"1c63e1d5-b963-455b-829d-e4f3eb63a36a":0,"1e6d4c29-98e4-4007-a16c-3a295919c19d":0.9900990099009901,"20334ede-d00f-48aa-999d-6d45f7ea71fd":2.9702970297029703,"25628852-b94d-441b-b3ad-0457653b60ae":0.9900990099009901,"261aefde-fbe5-494f-afd7-c771aff03127":0,"276c4b24-bf26-4171-b5d4-43bf0b5f2651":2.9702970297029703,"2807e6ff-b9a5-49ec-8b9f-892aee014156":0,"307653a4-8b07-4144-8634-849d5fbe289a":0.9900990099009901,"32148a0b-6ce4-4a1e-a1d2-98a96b27b24f":0.9900990099009901,"324598a3-3988-4560-82c9-3e0676990cd4":0,"32bfd04a-8c34-468e-b942-bdb8786d9095":0,"34758e0a-3def-447b-9c5e-e82a206426b5":0,"3595fa71-68db-476e-9cb7-ad6ece6f446e":0,"36020288-2888-4236-acdb-2f1068743e61":0,"367e0d1d-430f-46fb-aeea-448768eb8928":1.9801980198019802,"38ee39c0-6cd5-4092-8c29-105bc4ab5866":0.9900990099009901,"3a4b16cb-d234-42fd-8f6e-4d9aac88a589":0.9900990099009901,"3b73d81b-b823-4a1f-af36-e13d7b8f5751":0,"3c0e138e-0465-4abd-b713-47ca068e9e11":1.9801980198019802,"416f2b46-222e-436e-9a56-acf0da93a565":4.9504950495049505,"417d1684-e1ae-4fc4-8505-74db0d282011":0,"43530fe4-10a9-4ddf-b61d-8844f0ff3f04":1.9801980198019802,"47b9294c-b421-4574-b69d-48944b5bb098":0.9900990099009901,"4b4d25b8-76dd-43d5-bb5c-ca55894243f9":0.9900990099009901,"4da644de-16b1-4905-a054-3fb42bcc4e83":0,"4db6c10f-b1bb-49c2-b00c-bca8425aa979":0.9900990099009901,"504af9f2-1981-4066-b835-1b69f6536b0f":0,"56e7d0cf-d95d-4778-b6bd-0cd88a2ee974":3.9603960396039604,"5f70f18c-5f9c-442e-ae2c-ee6aadecab95":0,"625820f0-4c67-43ad-af6e-02022bb85445":0,"6300a64b-4e61-472d-8e92-4daaf85c2163":0,"68254e69-8e76-4c1a-b9d5-b4edaa975998":0.9900990099009901,"6ac8de77-cf28-431f-929e-8bdca575ff58":0.9900990099009901,"6c1db879-bba3-4a35-9221-380d720d465c":3.9603960396039604,"6e8cc926-79a1-4676-a2bd-f9d49f3144cf":0.9900990099009901,"6f2d104f-beaa-43a5-91ed-ec0e34eb1f57":0.9900990099009901,"6fe37c18-8dc5-4baa-b6e0-5546353907bb":2.9702970297029703,"72857c83-ed5d-402b-be07-acbff3f8b087":1.9801980198019802,"72bad13d-d204-40c6-acf6-d4ba8b940e0a":2.9702970297029703,"732f1cb3-c0c3-40de-bdd0-40de75ec3a66":0.9900990099009901,"73e6f6ab-a277-414b-9b36-35eed6c12a89":1.9801980198019802,"789b292f-81b1-4586-9971-57ccd6a12dcb":0,"78bc8abc-dd21-47f3-88bd-6103f7307523":11.881188118811881,"79da913e-c4d6-4d89-831c-f68f7976dcfc":12.871287128712872,"7b8583e6-dbd3-4d2f-859a-f1de071886f2":0,"7ccbdf09-a84e-4ad2-ab20-cb28b6c41155":0,"82eb55e6-39a8-4968-8be6-e2bfbb439a40":0.9900990099009901,"8a405e4c-c227-4e12-9a81-accf5b808c8c":1.9801980198019802,"8aa8c8c0-54cb-4bfd-b31d-bc5c784380d5":1.9801980198019802,"8bb47288-c305-4131-9a23-3635d1bc15ad":0.9900990099009901,"8c6ad04a-7a4c-4c59-9a38-6e40f0a29408":1.9801980198019802,"8d8e7d51-3223-4776-bf6a-40306774b8a1":3.9603960396039604,"8f4b93ce-9d3c-43df-be5a-908c7718e14c":3.9603960396039604,"9403b568-311c-4754-998d-9dcee582b2fa":2.9702970297029703,"95fdc823-57bc-4e49-8e5b-8fac0c4cfb7f":0,"9cef868f-eb6d-4189-acd1-43eac87cf81e":0,"9dee56d9-8fd5-414c-83ae-31551b20ae88":1.9801980198019802,"9e4ce720-a6e2-4d63-b768-559b69adf32f":0,"9e6cedf8-7002-4d43-9856-ad1a511b7997":0,"9e782ace-7971-4a8b-bed8-6d01fbbb88e1":1.9801980198019802,"a6c211bd-6b52-4e7c-9ab5-f8ad62f48bf4":0.9900990099009901,"a728900b-bca1-4f30-a9e4-80d846e92971":0,"b81c977b-7ef7-4ac0-9844-75da32394086":1.9801980198019802,"b944f77f-113b-4a02-ae5e-d4a124b8fd5b":1.9801980198019802,"bf03f268-de9d-4a80-aee1-200990056503":0.9900990099009901,"c73da248-279d-49f6-b0b3-68331e28f057":0.9900990099009901,"c8a617d5-66fb-4f12-bd3d-cf049da09293":0.9900990099009901,"c8f80ea6-4602-458c-9a70-daf1c646c89b":2.9702970297029703,"c98f4c93-0a9a-43ce-b37e-7508f842010d":0.9900990099009901,"cae374ce-5b99-482e-950a-0b9e304eb498":3.9603960396039604,"d6e37fb1-5f7e-448e-847b-7d1f1271c574":0.9900990099009901,"d8fe555f-d2ab-4a08-b9e7-ad7e98bab1ff":4.9504950495049505,"db26488d-78be-44b1-a343-e896f43c5d29":0,"de95e0f6-1008-488e-b280-e65a3b00b71e":0,"de9c11b7-388a-444d-901b-39cc87e8d901":0,"e0af11a9-b7e7-4d50-927d-14cc136f484b":1.9801980198019802,"e3fefce2-e693-46cf-bdc0-552876cb4843":0,"e50fe8f1-83b9-409d-88e0-11ff1eedb423":2.9702970297029703,"ea1ba5e1-b764-40bf-a74e-9a624698ca13":2.9702970297029703,"ed835ca3-7120-4646-afaf-20c04a57c698":1.9801980198019802,"ed8a19b2-66f3-47c1-8990-373bccc750e4":3.9603960396039604,"ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d":0.9900990099009901,"f006e236-59ad-4647-a59f-4f46dc2c85be":0,"f3868715-abb3-4115-b57b-dc6d874f02d1":0,"f3b51b45-8c69-4b93-b3cb-c252fcad0b1a":0,"f3eb4ac3-9302-42aa-be89-7cf746f286fd":1.9801980198019802,"f45b1e53-6ece-40d9-8b84-6d3b77ea7a7d":0.9900990099009901,"f5627848-0c4a-4274-b6af-267cf4c6ba6e":0.9900990099009901,"f7bb14b5-cb30-43e7-aab5-39088c5097a9":0,"ff102bfc-bf7e-41d7-bcc5-0a8cd247b246":0},"keyword":{"01df6660-e54b-4cab-a20e-179393feb854":9.093412698412699,"0266a6dc-9cac-428b-95de-3e44a3948640":11.465158730158729,"088d00cf-ed12-4552-8958-8b550401f355":10.093121693121693,"0e28e139-d1c1-49aa-9e29-aa74dc697a2e":9.692539682539682,"0efce57f-45b7-41af-9712-d97317c006e3":13.692539682539685,"0ff3b52b-7fd7-4d42-95ed-24b882367d3c":13.901851851851852,"10741541-6022-4249-ba45-9f1e105cbc16":13.1084126984127,"107983ba-765c-48df-addd-402abfb3c62e":10.831428571428575,"108c473e-db74-4339-822e-e17a74d2f329":12.417248677248677,"16143b20-4cf5-4917-8c1a-6aadd3f3d5de":11.481428571428573,"1769a3bf-41eb-4aed-9cc6-e4c702002084":8.740079365079366,"1c63e1d5-b963-455b-829d-e4f3eb63a36a":8.040476190476191,"1e6d4c29-98e4-4007-a16c-3a295919c19d":11.885555555555555,"20334ede-d00f-48aa-999d-6d45f7ea71fd":12.81931216931217,"25628852-b94d-441b-b3ad-0457653b60ae":11.465079365079365,"261aefde-fbe5-494f-afd7-c771aff03127":0,"276c4b24-bf26-4171-b5d4-43bf0b5f2651":12.46111111111111,"2807e6ff-b9a5-49ec-8b9f-892aee014156":10.377460317460319,"307653a4-8b07-4144-8634-849d5fbe289a":11.281984126984126,"32148a0b-6ce4-4a1e-a1d2-98a96b27b24f":11.483253968253967,"324598a3-3988-4560-82c9-3e0676990cd4":10.28420634920635,"32bfd04a-8c34-468e-b942-bdb8786d9095":0,"34758e0a-3def-447b-9c5e-e82a206426b5":0,"3595fa71-68db-476e-9cb7-ad6ece6f446e":10.974603174603175,"36020288-2888-4236-acdb-2f1068743e61":10.272460317460316,"367e0d1d-430f-46fb-aeea-448768eb8928":10.526984126984127,"38ee39c0-6cd5-4092-8c29-105bc4ab5866":12.010000000000002,"3a4b16cb-d234-42fd-8f6e-4d9aac88a589":11.036666666666667,"3b73d81b-b823-4a1f-af36-e13d7b8f5751":9.613492063492064,"3c0e138e-0465-4abd-b713-47ca068e9e11":10.43968253968254,"416f2b46-222e-436e-9a56-acf0da93a565":11.642857142857142,"417d1684-e1ae-4fc4-8505-74db0d282011":10.579841269841268,"43530fe4-10a9-4ddf-b61d-8844f0ff3f04":10.974074074074073,"47b9294c-b421-4574-b69d-48944b5bb098":12.456825396825398,"4b4d25b8-76dd-43d5-bb5c-ca55894243f9":11.822222222222221,"4da644de-16b1-4905-a054-3fb42bcc4e83":11.11674603174603,"4db6c10f-b1bb-49c2-b00c-bca8425aa979":9.820396825396827,"504af9f2-1981-4066-b835-1b69f6536b0f":9.80642857142857,"56e7d0cf-d95d-4778-b6bd-0cd88a2ee974":10.032089947089947,"5f70f18c-5f9c-442e-ae2c-ee6aadecab95":9.436507936507937,"625820f0-4c67-43ad-af6e-02022bb85445":11.760555555555555,"6300a64b-4e61-472d-8e92-4daaf85c2163":9.957169312169313,"68254e69-8e76-4c1a-b9d5-b4edaa975998":12.156031746031747,"6ac8de77-cf28-431f-929e-8bdca575ff58":12.719444444444445,"6c1db879-bba3-4a35-9221-380d720d465c":9.71857142857143,"6e8cc926-79a1-4676-a2bd-f9d49f3144cf":8.928015873015873,"6f2d104f-beaa-43a5-91ed-ec0e34eb1f57":11.50793650793651,"6fe37c18-8dc5-4baa-b6e0-5546353907bb":10.997380952380952,"72857c83-ed5d-402b-be07-acbff3f8b087":9.98063492063492,"72bad13d-d204-40c6-acf6-d4ba8b940e0a":8.684920634920635,"732f1cb3-c0c3-40de-bdd0-40de75ec3a66":12.26666666666667,"73e6f6ab-a277-414b-9b36-35eed6c12a89":9.621269841269843,"789b292f-81b1-4586-9971-57ccd6a12dcb":8.990873015873017,"78bc8abc-dd21-47f3-88bd-6103f7307523":11.003174603174605,"79da913e-c4d6-4d89-831c-f68f7976dcfc":11.731587301587302,"7b8583e6-dbd3-4d2f-859a-f1de071886f2":7.405026455026456,"7ccbdf09-a84e-4ad2-ab20-cb28b6c41155":8.992724867724867,"82eb55e6-39a8-4968-8be6-e2bfbb439a40":9.78,"8a405e4c-c227-4e12-9a81-accf5b808c8c":8.744179894179894,"8aa8c8c0-54cb-4bfd-b31d-bc5c784380d5":12.238888888888887,"8bb47288-c305-4131-9a23-3635d1bc15ad":11.61026455026455,"8c6ad04a-7a4c-4c59-9a38-6e40f0a29408":10.654603174603176,"8d8e7d51-3223-4776-bf6a-40306774b8a1":12.200396825396826,"8f4b93ce-9d3c-43df-be5a-908c7718e14c":12.838756613756614,"9403b568-311c-4754-998d-9dcee582b2fa":11.486534391534391,"95fdc823-57bc-4e49-8e5b-8fac0c4cfb7f":12.166666666666668,"9cef868f-eb6d-4189-acd1-43eac87cf81e":8.927460317460318,"9dee56d9-8fd5-414c-83ae-31551b20ae88":9.481216931216931,"9e4ce720-a6e2-4d63-b768-559b69adf32f":13.3524531024531,"9e6cedf8-7002-4d43-9856-ad1a511b7997":11.860396825396823,"9e782ace-7971-4a8b-bed8-6d01fbbb88e1":12.133597883597885,"a6c211bd-6b52-4e7c-9ab5-f8ad62f48bf4":12.666666666666668,"a728900b-bca1-4f30-a9e4-80d846e92971":10.687301587301588,"b81c977b-7ef7-4ac0-9844-75da32394086":12.285238095238096,"b944f77f-113b-4a02-ae5e-d4a124b8fd5b":12.707936507936509,"bf03f268-de9d-4a80-aee1-200990056503":10.381031746031747,"c73da248-279d-49f6-b0b3-68331e28f057":9.703174603174604,"c8a617d5-66fb-4f12-bd3d-cf049da09293":11.194126984126983,"c8f80ea6-4602-458c-9a70-daf1c646c89b":9.06047619047619,"c98f4c93-0a9a-43ce-b37e-7508f842010d":12.226349206349205,"cae374ce-5b99-482e-950a-0b9e304eb498":12.752116402116402,"d6e37fb1-5f7e-448e-847b-7d1f1271c574":11.484761904761905,"d8fe555f-d2ab-4a08-b9e7-ad7e98bab1ff":10.97904761904762,"db26488d-78be-44b1-a343-e896f43c5d29":0,"de95e0f6-1008-488e-b280-e65a3b00b71e":9.863174603174604,"de9c11b7-388a-444d-901b-39cc87e8d901":12.352380952380951,"e0af11a9-b7e7-4d50-927d-14cc136f484b":9.42857142857143,"e3fefce2-e693-46cf-bdc0-552876cb4843":9.884920634920636,"e50fe8f1-83b9-409d-88e0-11ff1eedb423":9.631746031746031,"ea1ba5e1-b764-40bf-a74e-9a624698ca13":11.549841269841268,"ed835ca3-7120-4646-afaf-20c04a57c698":9.237037037037037,"ed8a19b2-66f3-47c1-8990-373bccc750e4":12.85873015873016,"ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d":7.570449735449735,"f006e236-59ad-4647-a59f-4f46dc2c85be":11.107380952380954,"f3868715-abb3-4115-b57b-dc6d874f02d1":9.308201058201059,"f3b51b45-8c69-4b93-b3cb-c252fcad0b1a":11.595873015873014,"f3eb4ac3-9302-42aa-be89-7cf746f286fd":10.516666666666666,"f45b1e53-6ece-40d9-8b84-6d3b77ea7a7d":9.676137566137566,"f5627848-0c4a-4274-b6af-267cf4c6ba6e":11.755555555555555,"f7bb14b5-cb30-43e7-aab5-39088c5097a9":0,"ff102bfc-bf7e-41d7-bcc5-0a8cd247b246":11.723650793650796},"topic":["object","track","motion","method","problem"],"offsprings":[]},"45beeef2-a57d-436d-8fc4-56136234b4b9":{"authors":["Pedro F. Felzenszwalb","Daniel P. Huttenlocher"],"references":[],"_id":"45beeef2-a57d-436d-8fc4-56136234b4b9","abstract":"This paper addresses the problem of segmenting an image into regions. We define a predicate for measuring the evidence for a boundary between two regions using a graph-based representation of the image. We then develop an efficient segmentation algorithm based on this predicate, and show that although this algorithm makes greedy decisions it produces segmentations that satisfy global properties. We apply the algorithm to image segmentation using two different kinds of local neighborhoods in constructing the graph, and illustrate the results with both real and synthetic images. The algorithm runs in time nearly linear in the number of graph edges and is also fast in practice. An important characteristic of the method is its ability to preserve detail in low-variability image regions while ignoring detail in high-variability regions.","title":"Efficient Graph-Based Image Segmentation","venue":"International Journal of Computer Vision","year":2004,"__v":0,"citationCount":2057,"parents":{"01df6660-e54b-4cab-a20e-179393feb854":16.666666666666664,"1017d9d4-9a4c-423d-ad40-6d9bebbd6b31":0,"2ea16f6a-9fb7-4cbb-b632-4297abca8665":33.33333333333333,"49eba48a-b4c4-49f7-992d-5da76f32072b":0,"61ee16bb-d279-4a22-ab21-463bb86eb01c":16.666666666666664,"6e184d1b-925b-4918-b354-a2647e8fd945":8.333333333333332,"6e96e01e-749d-4247-8802-9d10bc66c0ce":0,"7b8583e6-dbd3-4d2f-859a-f1de071886f2":8.333333333333332,"9438a773-c15c-4ef2-a97c-54f643ce6082":16.666666666666664,"d20995f6-529c-41c6-b75e-a169b005fb5c":0,"d78003db-ad8a-48d2-be57-1c50e95cef72":16.666666666666664,"ee8ff75d-caec-42e9-aa07-cbe4fdd7541b":8.333333333333332},"keyword":{"01df6660-e54b-4cab-a20e-179393feb854":11.432566137566138,"1017d9d4-9a4c-423d-ad40-6d9bebbd6b31":0,"2ea16f6a-9fb7-4cbb-b632-4297abca8665":13.212962962962965,"49eba48a-b4c4-49f7-992d-5da76f32072b":12.257671957671958,"61ee16bb-d279-4a22-ab21-463bb86eb01c":10.754761904761905,"6e184d1b-925b-4918-b354-a2647e8fd945":10.347830687830688,"6e96e01e-749d-4247-8802-9d10bc66c0ce":13.422751322751322,"7b8583e6-dbd3-4d2f-859a-f1de071886f2":11.268650793650794,"9438a773-c15c-4ef2-a97c-54f643ce6082":12.35899470899471,"d20995f6-529c-41c6-b75e-a169b005fb5c":0,"d78003db-ad8a-48d2-be57-1c50e95cef72":13.025230880230882,"ee8ff75d-caec-42e9-aa07-cbe4fdd7541b":11.182870370370374},"topic":["imag","segment","region","algorithm","predic"],"groups":[],"offsprings":[]}}